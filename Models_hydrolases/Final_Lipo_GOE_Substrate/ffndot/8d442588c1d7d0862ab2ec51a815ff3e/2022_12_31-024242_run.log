2022-12-31 07:14:52,210 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/8d442588c1d7d0862ab2ec51a815ff3e/2022_12_31-024242",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 3,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-31 07:14:52,218 INFO: Starting stage: BUILD FEATURIZERS
2022-12-31 07:14:52,220 INFO:   Creating esm representation model
2022-12-31 07:14:52,220 INFO:   Done esm representation model
2022-12-31 07:14:52,220 INFO: Done with stage: BUILD FEATURIZERS
2022-12-31 07:14:52,220 INFO: Starting stage: BUILDING DATASET
2022-12-31 07:14:52,279 INFO: Done with stage: BUILDING DATASET
2022-12-31 07:14:52,279 INFO: Starting stage: FEATURIZING DATA
2022-12-31 07:14:52,279 INFO:   Featurizing proteins
2022-12-31 07:14:52,281 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-31 07:14:52,311 INFO:   Loaded feature cache of size 489
2022-12-31 07:14:52,312 INFO:   Starting to pool ESM Embeddings
2022-12-31 07:14:52,413 INFO:   Featurizing molecules
2022-12-31 07:14:52,415 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-31 07:14:52,418 INFO:   Loaded feature cache of size 498
2022-12-31 07:14:53,883 INFO: Done with stage: FEATURIZING DATA
2022-12-31 07:14:53,883 INFO: Starting stage: RUNNING SPLITS
2022-12-31 07:14:53,892 INFO:   Leaving out SEQ value Fold_0
2022-12-31 07:14:53,907 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 07:14:53,907 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:14:54,617 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:14:54,617 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:14:54,691 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:14:54,691 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:14:54,691 INFO:     No hyperparam tuning for this model
2022-12-31 07:14:54,691 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:14:54,691 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:14:54,692 INFO:     None feature selector for col prot
2022-12-31 07:14:54,692 INFO:     None feature selector for col prot
2022-12-31 07:14:54,692 INFO:     None feature selector for col prot
2022-12-31 07:14:54,693 INFO:     None feature selector for col chem
2022-12-31 07:14:54,693 INFO:     None feature selector for col chem
2022-12-31 07:14:54,693 INFO:     None feature selector for col chem
2022-12-31 07:14:54,693 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:14:54,693 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:14:54,695 INFO:     Number of params in model 224011
2022-12-31 07:14:54,695 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:14:54,696 INFO:   Starting stage: TRAINING
2022-12-31 07:14:56,342 INFO:     Val loss before train {'Reaction outcome loss': 1.033826716740926, 'Total loss': 1.033826716740926}
2022-12-31 07:14:56,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:56,343 INFO:     Epoch: 0
2022-12-31 07:14:57,936 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5856796363989513, 'Total loss': 0.5856796363989513} | train loss {'Reaction outcome loss': 0.7815543287621313, 'Total loss': 0.7815543287621313}
2022-12-31 07:14:57,936 INFO:     Found new best model at epoch 0
2022-12-31 07:14:57,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:57,937 INFO:     Epoch: 1
2022-12-31 07:14:59,564 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4936482061942418, 'Total loss': 0.4936482061942418} | train loss {'Reaction outcome loss': 0.5187403828233152, 'Total loss': 0.5187403828233152}
2022-12-31 07:14:59,564 INFO:     Found new best model at epoch 1
2022-12-31 07:14:59,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:14:59,565 INFO:     Epoch: 2
2022-12-31 07:15:01,169 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4660654942194621, 'Total loss': 0.4660654942194621} | train loss {'Reaction outcome loss': 0.4512950497450846, 'Total loss': 0.4512950497450846}
2022-12-31 07:15:01,169 INFO:     Found new best model at epoch 2
2022-12-31 07:15:01,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:01,170 INFO:     Epoch: 3
2022-12-31 07:15:02,775 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4619076311588287, 'Total loss': 0.4619076311588287} | train loss {'Reaction outcome loss': 0.40936300057522107, 'Total loss': 0.40936300057522107}
2022-12-31 07:15:02,776 INFO:     Found new best model at epoch 3
2022-12-31 07:15:02,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:02,777 INFO:     Epoch: 4
2022-12-31 07:15:04,405 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44313371082146963, 'Total loss': 0.44313371082146963} | train loss {'Reaction outcome loss': 0.3813323597713705, 'Total loss': 0.3813323597713705}
2022-12-31 07:15:04,405 INFO:     Found new best model at epoch 4
2022-12-31 07:15:04,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:04,406 INFO:     Epoch: 5
2022-12-31 07:15:06,006 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42520201404889424, 'Total loss': 0.42520201404889424} | train loss {'Reaction outcome loss': 0.3549483420647981, 'Total loss': 0.3549483420647981}
2022-12-31 07:15:06,007 INFO:     Found new best model at epoch 5
2022-12-31 07:15:06,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:06,008 INFO:     Epoch: 6
2022-12-31 07:15:07,619 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44935901562372843, 'Total loss': 0.44935901562372843} | train loss {'Reaction outcome loss': 0.33706341978612836, 'Total loss': 0.33706341978612836}
2022-12-31 07:15:07,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:07,619 INFO:     Epoch: 7
2022-12-31 07:15:09,227 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4292652974526087, 'Total loss': 0.4292652974526087} | train loss {'Reaction outcome loss': 0.3214315504872755, 'Total loss': 0.3214315504872755}
2022-12-31 07:15:09,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:09,228 INFO:     Epoch: 8
2022-12-31 07:15:10,824 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43384766976038613, 'Total loss': 0.43384766976038613} | train loss {'Reaction outcome loss': 0.3052186173670021, 'Total loss': 0.3052186173670021}
2022-12-31 07:15:10,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:10,824 INFO:     Epoch: 9
2022-12-31 07:15:12,434 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4218283991018931, 'Total loss': 0.4218283991018931} | train loss {'Reaction outcome loss': 0.2942437387375168, 'Total loss': 0.2942437387375168}
2022-12-31 07:15:12,434 INFO:     Found new best model at epoch 9
2022-12-31 07:15:12,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:12,435 INFO:     Epoch: 10
2022-12-31 07:15:14,039 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4227783878644307, 'Total loss': 0.4227783878644307} | train loss {'Reaction outcome loss': 0.2835192611584297, 'Total loss': 0.2835192611584297}
2022-12-31 07:15:14,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:14,039 INFO:     Epoch: 11
2022-12-31 07:15:15,682 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42177699208259584, 'Total loss': 0.42177699208259584} | train loss {'Reaction outcome loss': 0.26991390859906056, 'Total loss': 0.26991390859906056}
2022-12-31 07:15:15,683 INFO:     Found new best model at epoch 11
2022-12-31 07:15:15,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:15,684 INFO:     Epoch: 12
2022-12-31 07:15:17,289 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4735047370195389, 'Total loss': 0.4735047370195389} | train loss {'Reaction outcome loss': 0.2584201162442183, 'Total loss': 0.2584201162442183}
2022-12-31 07:15:17,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:17,290 INFO:     Epoch: 13
2022-12-31 07:15:18,930 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4371065929532051, 'Total loss': 0.4371065929532051} | train loss {'Reaction outcome loss': 0.2480912675992364, 'Total loss': 0.2480912675992364}
2022-12-31 07:15:18,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:18,931 INFO:     Epoch: 14
2022-12-31 07:15:20,537 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4321829756100973, 'Total loss': 0.4321829756100973} | train loss {'Reaction outcome loss': 0.2390506817880786, 'Total loss': 0.2390506817880786}
2022-12-31 07:15:20,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:20,537 INFO:     Epoch: 15
2022-12-31 07:15:22,142 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4597588996092478, 'Total loss': 0.4597588996092478} | train loss {'Reaction outcome loss': 0.23207903968600127, 'Total loss': 0.23207903968600127}
2022-12-31 07:15:22,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:22,143 INFO:     Epoch: 16
2022-12-31 07:15:23,767 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4666526734828949, 'Total loss': 0.4666526734828949} | train loss {'Reaction outcome loss': 0.2247699133424095, 'Total loss': 0.2247699133424095}
2022-12-31 07:15:23,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:23,767 INFO:     Epoch: 17
2022-12-31 07:15:25,375 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44621218542257945, 'Total loss': 0.44621218542257945} | train loss {'Reaction outcome loss': 0.21934343058097383, 'Total loss': 0.21934343058097383}
2022-12-31 07:15:25,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:25,375 INFO:     Epoch: 18
2022-12-31 07:15:26,985 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.490618696808815, 'Total loss': 0.490618696808815} | train loss {'Reaction outcome loss': 0.21278310047237428, 'Total loss': 0.21278310047237428}
2022-12-31 07:15:26,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:26,986 INFO:     Epoch: 19
2022-12-31 07:15:28,599 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4366426020860672, 'Total loss': 0.4366426020860672} | train loss {'Reaction outcome loss': 0.2059523489585508, 'Total loss': 0.2059523489585508}
2022-12-31 07:15:28,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:28,599 INFO:     Epoch: 20
2022-12-31 07:15:30,194 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46492111484209697, 'Total loss': 0.46492111484209697} | train loss {'Reaction outcome loss': 0.19956380169755086, 'Total loss': 0.19956380169755086}
2022-12-31 07:15:30,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:30,194 INFO:     Epoch: 21
2022-12-31 07:15:31,838 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44550270165006317, 'Total loss': 0.44550270165006317} | train loss {'Reaction outcome loss': 0.19632230437063908, 'Total loss': 0.19632230437063908}
2022-12-31 07:15:31,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:31,838 INFO:     Epoch: 22
2022-12-31 07:15:33,442 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48503958284854887, 'Total loss': 0.48503958284854887} | train loss {'Reaction outcome loss': 0.1889745271440609, 'Total loss': 0.1889745271440609}
2022-12-31 07:15:33,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:33,443 INFO:     Epoch: 23
2022-12-31 07:15:35,051 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.447709775964419, 'Total loss': 0.447709775964419} | train loss {'Reaction outcome loss': 0.18981039133127575, 'Total loss': 0.18981039133127575}
2022-12-31 07:15:35,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:35,052 INFO:     Epoch: 24
2022-12-31 07:15:36,658 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4562892109155655, 'Total loss': 0.4562892109155655} | train loss {'Reaction outcome loss': 0.1846332352799483, 'Total loss': 0.1846332352799483}
2022-12-31 07:15:36,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:36,658 INFO:     Epoch: 25
2022-12-31 07:15:38,263 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4599009543657303, 'Total loss': 0.4599009543657303} | train loss {'Reaction outcome loss': 0.18092978225625206, 'Total loss': 0.18092978225625206}
2022-12-31 07:15:38,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:38,264 INFO:     Epoch: 26
2022-12-31 07:15:39,906 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4820302645365397, 'Total loss': 0.4820302645365397} | train loss {'Reaction outcome loss': 0.17719272838653008, 'Total loss': 0.17719272838653008}
2022-12-31 07:15:39,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:39,906 INFO:     Epoch: 27
2022-12-31 07:15:41,535 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4735607162117958, 'Total loss': 0.4735607162117958} | train loss {'Reaction outcome loss': 0.17556519890306416, 'Total loss': 0.17556519890306416}
2022-12-31 07:15:41,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:41,535 INFO:     Epoch: 28
2022-12-31 07:15:43,178 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5187099605798722, 'Total loss': 0.5187099605798722} | train loss {'Reaction outcome loss': 0.17045137408997987, 'Total loss': 0.17045137408997987}
2022-12-31 07:15:43,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:43,178 INFO:     Epoch: 29
2022-12-31 07:15:44,820 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46718966563542685, 'Total loss': 0.46718966563542685} | train loss {'Reaction outcome loss': 0.17117596414083472, 'Total loss': 0.17117596414083472}
2022-12-31 07:15:44,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:44,820 INFO:     Epoch: 30
2022-12-31 07:15:46,462 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5091928790012995, 'Total loss': 0.5091928790012995} | train loss {'Reaction outcome loss': 0.16181469958057224, 'Total loss': 0.16181469958057224}
2022-12-31 07:15:46,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:46,463 INFO:     Epoch: 31
2022-12-31 07:15:48,079 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5012995004653931, 'Total loss': 0.5012995004653931} | train loss {'Reaction outcome loss': 0.16279972205450247, 'Total loss': 0.16279972205450247}
2022-12-31 07:15:48,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:48,079 INFO:     Epoch: 32
2022-12-31 07:15:49,691 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46840407848358157, 'Total loss': 0.46840407848358157} | train loss {'Reaction outcome loss': 0.15848153663778697, 'Total loss': 0.15848153663778697}
2022-12-31 07:15:49,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:49,691 INFO:     Epoch: 33
2022-12-31 07:15:51,293 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4861983279387156, 'Total loss': 0.4861983279387156} | train loss {'Reaction outcome loss': 0.155662027651601, 'Total loss': 0.155662027651601}
2022-12-31 07:15:51,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:51,293 INFO:     Epoch: 34
2022-12-31 07:15:52,905 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45919543703397114, 'Total loss': 0.45919543703397114} | train loss {'Reaction outcome loss': 0.1558796557403364, 'Total loss': 0.1558796557403364}
2022-12-31 07:15:52,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:52,906 INFO:     Epoch: 35
2022-12-31 07:15:54,516 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46290354082981744, 'Total loss': 0.46290354082981744} | train loss {'Reaction outcome loss': 0.1526148091872042, 'Total loss': 0.1526148091872042}
2022-12-31 07:15:54,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:54,516 INFO:     Epoch: 36
2022-12-31 07:15:56,124 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45268126428127287, 'Total loss': 0.45268126428127287} | train loss {'Reaction outcome loss': 0.15422790875017042, 'Total loss': 0.15422790875017042}
2022-12-31 07:15:56,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:56,125 INFO:     Epoch: 37
2022-12-31 07:15:57,729 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4783006995916367, 'Total loss': 0.4783006995916367} | train loss {'Reaction outcome loss': 0.15299651559592384, 'Total loss': 0.15299651559592384}
2022-12-31 07:15:57,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:57,731 INFO:     Epoch: 38
2022-12-31 07:15:59,340 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46585499197244645, 'Total loss': 0.46585499197244645} | train loss {'Reaction outcome loss': 0.14522014411111728, 'Total loss': 0.14522014411111728}
2022-12-31 07:15:59,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:15:59,341 INFO:     Epoch: 39
2022-12-31 07:16:00,958 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4491318166255951, 'Total loss': 0.4491318166255951} | train loss {'Reaction outcome loss': 0.1471618511594641, 'Total loss': 0.1471618511594641}
2022-12-31 07:16:00,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:00,959 INFO:     Epoch: 40
2022-12-31 07:16:02,601 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43775194759170216, 'Total loss': 0.43775194759170216} | train loss {'Reaction outcome loss': 0.14421449539562067, 'Total loss': 0.14421449539562067}
2022-12-31 07:16:02,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:02,602 INFO:     Epoch: 41
2022-12-31 07:16:04,245 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48326261242230734, 'Total loss': 0.48326261242230734} | train loss {'Reaction outcome loss': 0.1391150733616353, 'Total loss': 0.1391150733616353}
2022-12-31 07:16:04,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:04,246 INFO:     Epoch: 42
2022-12-31 07:16:05,848 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5033420026302338, 'Total loss': 0.5033420026302338} | train loss {'Reaction outcome loss': 0.14028966818482447, 'Total loss': 0.14028966818482447}
2022-12-31 07:16:05,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:05,848 INFO:     Epoch: 43
2022-12-31 07:16:07,458 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4949749986330668, 'Total loss': 0.4949749986330668} | train loss {'Reaction outcome loss': 0.1438650528835508, 'Total loss': 0.1438650528835508}
2022-12-31 07:16:07,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:07,459 INFO:     Epoch: 44
2022-12-31 07:16:09,063 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.480484801530838, 'Total loss': 0.480484801530838} | train loss {'Reaction outcome loss': 0.1424169203628114, 'Total loss': 0.1424169203628114}
2022-12-31 07:16:09,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:09,063 INFO:     Epoch: 45
2022-12-31 07:16:10,674 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4641741394996643, 'Total loss': 0.4641741394996643} | train loss {'Reaction outcome loss': 0.13895945360324594, 'Total loss': 0.13895945360324594}
2022-12-31 07:16:10,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:10,674 INFO:     Epoch: 46
2022-12-31 07:16:12,287 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4699600060780843, 'Total loss': 0.4699600060780843} | train loss {'Reaction outcome loss': 0.13651923987598263, 'Total loss': 0.13651923987598263}
2022-12-31 07:16:12,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:12,287 INFO:     Epoch: 47
2022-12-31 07:16:13,908 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4476049949725469, 'Total loss': 0.4476049949725469} | train loss {'Reaction outcome loss': 0.13537097859772898, 'Total loss': 0.13537097859772898}
2022-12-31 07:16:13,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:13,908 INFO:     Epoch: 48
2022-12-31 07:16:15,517 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5007576237122218, 'Total loss': 0.5007576237122218} | train loss {'Reaction outcome loss': 0.1318266152919376, 'Total loss': 0.1318266152919376}
2022-12-31 07:16:15,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:15,517 INFO:     Epoch: 49
2022-12-31 07:16:17,133 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4372213792676727, 'Total loss': 0.4372213792676727} | train loss {'Reaction outcome loss': 0.13329206549668268, 'Total loss': 0.13329206549668268}
2022-12-31 07:16:17,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:17,134 INFO:     Epoch: 50
2022-12-31 07:16:18,756 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4987207939227422, 'Total loss': 0.4987207939227422} | train loss {'Reaction outcome loss': 0.12918392404565934, 'Total loss': 0.12918392404565934}
2022-12-31 07:16:18,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:18,756 INFO:     Epoch: 51
2022-12-31 07:16:20,401 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4815111070871353, 'Total loss': 0.4815111070871353} | train loss {'Reaction outcome loss': 0.13045258099902354, 'Total loss': 0.13045258099902354}
2022-12-31 07:16:20,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:20,401 INFO:     Epoch: 52
2022-12-31 07:16:21,997 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46193540953099727, 'Total loss': 0.46193540953099727} | train loss {'Reaction outcome loss': 0.13215481416209712, 'Total loss': 0.13215481416209712}
2022-12-31 07:16:21,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:21,997 INFO:     Epoch: 53
2022-12-31 07:16:23,638 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47396792074044547, 'Total loss': 0.47396792074044547} | train loss {'Reaction outcome loss': 0.12992740336177877, 'Total loss': 0.12992740336177877}
2022-12-31 07:16:23,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:23,638 INFO:     Epoch: 54
2022-12-31 07:16:25,242 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4622790773709615, 'Total loss': 0.4622790773709615} | train loss {'Reaction outcome loss': 0.1293365714675832, 'Total loss': 0.1293365714675832}
2022-12-31 07:16:25,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:25,242 INFO:     Epoch: 55
2022-12-31 07:16:26,851 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48769521415233613, 'Total loss': 0.48769521415233613} | train loss {'Reaction outcome loss': 0.13200889044567507, 'Total loss': 0.13200889044567507}
2022-12-31 07:16:26,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:26,851 INFO:     Epoch: 56
2022-12-31 07:16:28,482 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49160179098447165, 'Total loss': 0.49160179098447165} | train loss {'Reaction outcome loss': 0.12995560579650076, 'Total loss': 0.12995560579650076}
2022-12-31 07:16:28,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:28,483 INFO:     Epoch: 57
2022-12-31 07:16:30,087 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48607616821924843, 'Total loss': 0.48607616821924843} | train loss {'Reaction outcome loss': 0.12508065793526807, 'Total loss': 0.12508065793526807}
2022-12-31 07:16:30,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:30,087 INFO:     Epoch: 58
2022-12-31 07:16:31,734 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4742613216241201, 'Total loss': 0.4742613216241201} | train loss {'Reaction outcome loss': 0.12677132007546532, 'Total loss': 0.12677132007546532}
2022-12-31 07:16:31,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:31,734 INFO:     Epoch: 59
2022-12-31 07:16:33,353 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4831632981697718, 'Total loss': 0.4831632981697718} | train loss {'Reaction outcome loss': 0.12921000978885552, 'Total loss': 0.12921000978885552}
2022-12-31 07:16:33,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:33,353 INFO:     Epoch: 60
2022-12-31 07:16:34,998 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48561306099096935, 'Total loss': 0.48561306099096935} | train loss {'Reaction outcome loss': 0.12415858946617815, 'Total loss': 0.12415858946617815}
2022-12-31 07:16:34,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:34,999 INFO:     Epoch: 61
2022-12-31 07:16:36,590 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4745051940282186, 'Total loss': 0.4745051940282186} | train loss {'Reaction outcome loss': 0.12145212233312182, 'Total loss': 0.12145212233312182}
2022-12-31 07:16:36,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:36,590 INFO:     Epoch: 62
2022-12-31 07:16:38,200 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4741998215516408, 'Total loss': 0.4741998215516408} | train loss {'Reaction outcome loss': 0.12423924030224373, 'Total loss': 0.12423924030224373}
2022-12-31 07:16:38,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:38,200 INFO:     Epoch: 63
2022-12-31 07:16:39,807 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48416859892507397, 'Total loss': 0.48416859892507397} | train loss {'Reaction outcome loss': 0.12161441184341526, 'Total loss': 0.12161441184341526}
2022-12-31 07:16:39,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:39,808 INFO:     Epoch: 64
2022-12-31 07:16:41,414 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47089859992265704, 'Total loss': 0.47089859992265704} | train loss {'Reaction outcome loss': 0.12147758229065946, 'Total loss': 0.12147758229065946}
2022-12-31 07:16:41,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:41,414 INFO:     Epoch: 65
2022-12-31 07:16:43,015 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5117714812358221, 'Total loss': 0.5117714812358221} | train loss {'Reaction outcome loss': 0.12106518524156494, 'Total loss': 0.12106518524156494}
2022-12-31 07:16:43,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:43,016 INFO:     Epoch: 66
2022-12-31 07:16:44,663 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5196515818436941, 'Total loss': 0.5196515818436941} | train loss {'Reaction outcome loss': 0.11989921751183086, 'Total loss': 0.11989921751183086}
2022-12-31 07:16:44,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:44,663 INFO:     Epoch: 67
2022-12-31 07:16:46,286 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4762937178214391, 'Total loss': 0.4762937178214391} | train loss {'Reaction outcome loss': 0.12732443215509692, 'Total loss': 0.12732443215509692}
2022-12-31 07:16:46,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:46,286 INFO:     Epoch: 68
2022-12-31 07:16:47,937 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49573411146799723, 'Total loss': 0.49573411146799723} | train loss {'Reaction outcome loss': 0.1197680518791871, 'Total loss': 0.1197680518791871}
2022-12-31 07:16:47,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:47,938 INFO:     Epoch: 69
2022-12-31 07:16:49,553 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5171316196521123, 'Total loss': 0.5171316196521123} | train loss {'Reaction outcome loss': 0.11963590970876944, 'Total loss': 0.11963590970876944}
2022-12-31 07:16:49,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:49,553 INFO:     Epoch: 70
2022-12-31 07:16:51,191 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45452853143215177, 'Total loss': 0.45452853143215177} | train loss {'Reaction outcome loss': 0.11706371156536316, 'Total loss': 0.11706371156536316}
2022-12-31 07:16:51,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:51,192 INFO:     Epoch: 71
2022-12-31 07:16:52,796 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46577756802241005, 'Total loss': 0.46577756802241005} | train loss {'Reaction outcome loss': 0.11921247822017624, 'Total loss': 0.11921247822017624}
2022-12-31 07:16:52,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:52,797 INFO:     Epoch: 72
2022-12-31 07:16:54,403 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48280889391899107, 'Total loss': 0.48280889391899107} | train loss {'Reaction outcome loss': 0.11476121318437868, 'Total loss': 0.11476121318437868}
2022-12-31 07:16:54,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:54,403 INFO:     Epoch: 73
2022-12-31 07:16:56,000 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4435008196781079, 'Total loss': 0.4435008196781079} | train loss {'Reaction outcome loss': 0.12296888772944063, 'Total loss': 0.12296888772944063}
2022-12-31 07:16:56,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:56,000 INFO:     Epoch: 74
2022-12-31 07:16:57,644 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4907037079334259, 'Total loss': 0.4907037079334259} | train loss {'Reaction outcome loss': 0.11191348159931354, 'Total loss': 0.11191348159931354}
2022-12-31 07:16:57,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:57,644 INFO:     Epoch: 75
2022-12-31 07:16:59,288 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46673057476679486, 'Total loss': 0.46673057476679486} | train loss {'Reaction outcome loss': 0.11247567653710588, 'Total loss': 0.11247567653710588}
2022-12-31 07:16:59,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:16:59,289 INFO:     Epoch: 76
2022-12-31 07:17:00,902 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43915130918224654, 'Total loss': 0.43915130918224654} | train loss {'Reaction outcome loss': 0.11503931631473995, 'Total loss': 0.11503931631473995}
2022-12-31 07:17:00,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:00,902 INFO:     Epoch: 77
2022-12-31 07:17:02,530 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4627437233924866, 'Total loss': 0.4627437233924866} | train loss {'Reaction outcome loss': 0.11738576379490781, 'Total loss': 0.11738576379490781}
2022-12-31 07:17:02,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:02,530 INFO:     Epoch: 78
2022-12-31 07:17:04,160 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49119621912638345, 'Total loss': 0.49119621912638345} | train loss {'Reaction outcome loss': 0.11992000305731763, 'Total loss': 0.11992000305731763}
2022-12-31 07:17:04,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:04,161 INFO:     Epoch: 79
2022-12-31 07:17:05,807 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5196098426977793, 'Total loss': 0.5196098426977793} | train loss {'Reaction outcome loss': 0.11856911050653829, 'Total loss': 0.11856911050653829}
2022-12-31 07:17:05,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:05,808 INFO:     Epoch: 80
2022-12-31 07:17:07,413 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5173521955808004, 'Total loss': 0.5173521955808004} | train loss {'Reaction outcome loss': 0.11349171821382784, 'Total loss': 0.11349171821382784}
2022-12-31 07:17:07,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:07,413 INFO:     Epoch: 81
2022-12-31 07:17:09,061 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.453963207701842, 'Total loss': 0.453963207701842} | train loss {'Reaction outcome loss': 0.11779440983433973, 'Total loss': 0.11779440983433973}
2022-12-31 07:17:09,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:09,061 INFO:     Epoch: 82
2022-12-31 07:17:10,669 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5203918466965357, 'Total loss': 0.5203918466965357} | train loss {'Reaction outcome loss': 0.11665381375365914, 'Total loss': 0.11665381375365914}
2022-12-31 07:17:10,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:10,670 INFO:     Epoch: 83
2022-12-31 07:17:12,283 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47925400535265605, 'Total loss': 0.47925400535265605} | train loss {'Reaction outcome loss': 0.1120056653627273, 'Total loss': 0.1120056653627273}
2022-12-31 07:17:12,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:12,283 INFO:     Epoch: 84
2022-12-31 07:17:13,883 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5020158727963765, 'Total loss': 0.5020158727963765} | train loss {'Reaction outcome loss': 0.11369519760907242, 'Total loss': 0.11369519760907242}
2022-12-31 07:17:13,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:13,883 INFO:     Epoch: 85
2022-12-31 07:17:15,492 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5059844255447388, 'Total loss': 0.5059844255447388} | train loss {'Reaction outcome loss': 0.11155175753347166, 'Total loss': 0.11155175753347166}
2022-12-31 07:17:15,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:15,492 INFO:     Epoch: 86
2022-12-31 07:17:17,106 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44876558730999627, 'Total loss': 0.44876558730999627} | train loss {'Reaction outcome loss': 0.10913437584840655, 'Total loss': 0.10913437584840655}
2022-12-31 07:17:17,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:17,106 INFO:     Epoch: 87
2022-12-31 07:17:18,707 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4819653550783793, 'Total loss': 0.4819653550783793} | train loss {'Reaction outcome loss': 0.11263592363652455, 'Total loss': 0.11263592363652455}
2022-12-31 07:17:18,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:18,708 INFO:     Epoch: 88
2022-12-31 07:17:20,315 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.475508850812912, 'Total loss': 0.475508850812912} | train loss {'Reaction outcome loss': 0.10867930537570718, 'Total loss': 0.10867930537570718}
2022-12-31 07:17:20,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:20,315 INFO:     Epoch: 89
2022-12-31 07:17:21,913 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46492346276839575, 'Total loss': 0.46492346276839575} | train loss {'Reaction outcome loss': 0.11069479969248258, 'Total loss': 0.11069479969248258}
2022-12-31 07:17:21,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:21,914 INFO:     Epoch: 90
2022-12-31 07:17:23,507 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4776512960592906, 'Total loss': 0.4776512960592906} | train loss {'Reaction outcome loss': 0.11458266212992138, 'Total loss': 0.11458266212992138}
2022-12-31 07:17:23,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:23,507 INFO:     Epoch: 91
2022-12-31 07:17:25,154 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5205642541249593, 'Total loss': 0.5205642541249593} | train loss {'Reaction outcome loss': 0.11063031873907962, 'Total loss': 0.11063031873907962}
2022-12-31 07:17:25,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:25,154 INFO:     Epoch: 92
2022-12-31 07:17:26,801 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4984453280766805, 'Total loss': 0.4984453280766805} | train loss {'Reaction outcome loss': 0.1117524186152651, 'Total loss': 0.1117524186152651}
2022-12-31 07:17:26,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:26,801 INFO:     Epoch: 93
2022-12-31 07:17:28,415 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4644599944353104, 'Total loss': 0.4644599944353104} | train loss {'Reaction outcome loss': 0.10769011201371094, 'Total loss': 0.10769011201371094}
2022-12-31 07:17:28,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:28,415 INFO:     Epoch: 94
2022-12-31 07:17:30,031 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4261744095866258, 'Total loss': 0.4261744095866258} | train loss {'Reaction outcome loss': 0.11159932091252217, 'Total loss': 0.11159932091252217}
2022-12-31 07:17:30,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:30,033 INFO:     Epoch: 95
2022-12-31 07:17:31,638 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5176363527774811, 'Total loss': 0.5176363527774811} | train loss {'Reaction outcome loss': 0.10702022634644484, 'Total loss': 0.10702022634644484}
2022-12-31 07:17:31,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:31,638 INFO:     Epoch: 96
2022-12-31 07:17:33,285 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5093523065249125, 'Total loss': 0.5093523065249125} | train loss {'Reaction outcome loss': 0.10807018407412392, 'Total loss': 0.10807018407412392}
2022-12-31 07:17:33,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:33,285 INFO:     Epoch: 97
2022-12-31 07:17:34,915 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48075664148976405, 'Total loss': 0.48075664148976405} | train loss {'Reaction outcome loss': 0.11294921250133724, 'Total loss': 0.11294921250133724}
2022-12-31 07:17:34,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:34,915 INFO:     Epoch: 98
2022-12-31 07:17:36,540 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5168422192335129, 'Total loss': 0.5168422192335129} | train loss {'Reaction outcome loss': 0.11339181063580753, 'Total loss': 0.11339181063580753}
2022-12-31 07:17:36,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:36,541 INFO:     Epoch: 99
2022-12-31 07:17:38,154 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4572653780380885, 'Total loss': 0.4572653780380885} | train loss {'Reaction outcome loss': 0.11359563016677242, 'Total loss': 0.11359563016677242}
2022-12-31 07:17:38,154 INFO:     Best model found after epoch 12 of 100.
2022-12-31 07:17:38,154 INFO:   Done with stage: TRAINING
2022-12-31 07:17:38,154 INFO:   Starting stage: EVALUATION
2022-12-31 07:17:38,299 INFO:   Done with stage: EVALUATION
2022-12-31 07:17:38,299 INFO:   Leaving out SEQ value Fold_1
2022-12-31 07:17:38,312 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:17:38,312 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:17:38,979 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:17:38,979 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:17:39,049 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:17:39,049 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:17:39,049 INFO:     No hyperparam tuning for this model
2022-12-31 07:17:39,049 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:17:39,049 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:17:39,050 INFO:     None feature selector for col prot
2022-12-31 07:17:39,050 INFO:     None feature selector for col prot
2022-12-31 07:17:39,050 INFO:     None feature selector for col prot
2022-12-31 07:17:39,051 INFO:     None feature selector for col chem
2022-12-31 07:17:39,051 INFO:     None feature selector for col chem
2022-12-31 07:17:39,051 INFO:     None feature selector for col chem
2022-12-31 07:17:39,051 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:17:39,051 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:17:39,053 INFO:     Number of params in model 224011
2022-12-31 07:17:39,056 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:17:39,056 INFO:   Starting stage: TRAINING
2022-12-31 07:17:39,104 INFO:     Val loss before train {'Reaction outcome loss': 1.0299384395281475, 'Total loss': 1.0299384395281475}
2022-12-31 07:17:39,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:39,104 INFO:     Epoch: 0
2022-12-31 07:17:40,740 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6254990220069885, 'Total loss': 0.6254990220069885} | train loss {'Reaction outcome loss': 0.7834641578188841, 'Total loss': 0.7834641578188841}
2022-12-31 07:17:40,740 INFO:     Found new best model at epoch 0
2022-12-31 07:17:40,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:40,741 INFO:     Epoch: 1
2022-12-31 07:17:42,364 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5534140994151433, 'Total loss': 0.5534140994151433} | train loss {'Reaction outcome loss': 0.5466721805649392, 'Total loss': 0.5466721805649392}
2022-12-31 07:17:42,365 INFO:     Found new best model at epoch 1
2022-12-31 07:17:42,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:42,366 INFO:     Epoch: 2
2022-12-31 07:17:43,992 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4982900569836299, 'Total loss': 0.4982900569836299} | train loss {'Reaction outcome loss': 0.4510469512501057, 'Total loss': 0.4510469512501057}
2022-12-31 07:17:43,992 INFO:     Found new best model at epoch 2
2022-12-31 07:17:43,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:43,993 INFO:     Epoch: 3
2022-12-31 07:17:45,620 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5081384201844533, 'Total loss': 0.5081384201844533} | train loss {'Reaction outcome loss': 0.4126651517075041, 'Total loss': 0.4126651517075041}
2022-12-31 07:17:45,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:45,620 INFO:     Epoch: 4
2022-12-31 07:17:47,240 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5074791133403778, 'Total loss': 0.5074791133403778} | train loss {'Reaction outcome loss': 0.38680299868186313, 'Total loss': 0.38680299868186313}
2022-12-31 07:17:47,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:47,240 INFO:     Epoch: 5
2022-12-31 07:17:48,867 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5139720737934113, 'Total loss': 0.5139720737934113} | train loss {'Reaction outcome loss': 0.36429219051354966, 'Total loss': 0.36429219051354966}
2022-12-31 07:17:48,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:48,868 INFO:     Epoch: 6
2022-12-31 07:17:50,158 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4690481121341387, 'Total loss': 0.4690481121341387} | train loss {'Reaction outcome loss': 0.335704836597079, 'Total loss': 0.335704836597079}
2022-12-31 07:17:50,158 INFO:     Found new best model at epoch 6
2022-12-31 07:17:50,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:50,159 INFO:     Epoch: 7
2022-12-31 07:17:51,281 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4526966497302055, 'Total loss': 0.4526966497302055} | train loss {'Reaction outcome loss': 0.31691708711677813, 'Total loss': 0.31691708711677813}
2022-12-31 07:17:51,281 INFO:     Found new best model at epoch 7
2022-12-31 07:17:51,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:51,282 INFO:     Epoch: 8
2022-12-31 07:17:52,398 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4740892738103867, 'Total loss': 0.4740892738103867} | train loss {'Reaction outcome loss': 0.2992320880546923, 'Total loss': 0.2992320880546923}
2022-12-31 07:17:52,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:52,398 INFO:     Epoch: 9
2022-12-31 07:17:53,536 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4892105162143707, 'Total loss': 0.4892105162143707} | train loss {'Reaction outcome loss': 0.281739184249486, 'Total loss': 0.281739184249486}
2022-12-31 07:17:53,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:53,536 INFO:     Epoch: 10
2022-12-31 07:17:54,952 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46142432689666746, 'Total loss': 0.46142432689666746} | train loss {'Reaction outcome loss': 0.272259978703743, 'Total loss': 0.272259978703743}
2022-12-31 07:17:54,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:54,952 INFO:     Epoch: 11
2022-12-31 07:17:56,575 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46164482335249585, 'Total loss': 0.46164482335249585} | train loss {'Reaction outcome loss': 0.2630718251321409, 'Total loss': 0.2630718251321409}
2022-12-31 07:17:56,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:56,575 INFO:     Epoch: 12
2022-12-31 07:17:58,201 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46124935348828633, 'Total loss': 0.46124935348828633} | train loss {'Reaction outcome loss': 0.24991813139564803, 'Total loss': 0.24991813139564803}
2022-12-31 07:17:58,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:58,201 INFO:     Epoch: 13
2022-12-31 07:17:59,826 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45950013026595116, 'Total loss': 0.45950013026595116} | train loss {'Reaction outcome loss': 0.23962947408216534, 'Total loss': 0.23962947408216534}
2022-12-31 07:17:59,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:17:59,827 INFO:     Epoch: 14
2022-12-31 07:18:01,451 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48308581312497456, 'Total loss': 0.48308581312497456} | train loss {'Reaction outcome loss': 0.23743425057256135, 'Total loss': 0.23743425057256135}
2022-12-31 07:18:01,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:01,452 INFO:     Epoch: 15
2022-12-31 07:18:03,094 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45277206897735595, 'Total loss': 0.45277206897735595} | train loss {'Reaction outcome loss': 0.22772175724537153, 'Total loss': 0.22772175724537153}
2022-12-31 07:18:03,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:03,094 INFO:     Epoch: 16
2022-12-31 07:18:04,742 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46437453627586367, 'Total loss': 0.46437453627586367} | train loss {'Reaction outcome loss': 0.21970770745268225, 'Total loss': 0.21970770745268225}
2022-12-31 07:18:04,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:04,742 INFO:     Epoch: 17
2022-12-31 07:18:06,405 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4608748217423757, 'Total loss': 0.4608748217423757} | train loss {'Reaction outcome loss': 0.21323255596718704, 'Total loss': 0.21323255596718704}
2022-12-31 07:18:06,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:06,405 INFO:     Epoch: 18
2022-12-31 07:18:08,067 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44677813947200773, 'Total loss': 0.44677813947200773} | train loss {'Reaction outcome loss': 0.20765831629894133, 'Total loss': 0.20765831629894133}
2022-12-31 07:18:08,068 INFO:     Found new best model at epoch 18
2022-12-31 07:18:08,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:08,069 INFO:     Epoch: 19
2022-12-31 07:18:09,689 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4754046191771825, 'Total loss': 0.4754046191771825} | train loss {'Reaction outcome loss': 0.20084653905781824, 'Total loss': 0.20084653905781824}
2022-12-31 07:18:09,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:09,689 INFO:     Epoch: 20
2022-12-31 07:18:11,338 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44945548673470814, 'Total loss': 0.44945548673470814} | train loss {'Reaction outcome loss': 0.19571652653816063, 'Total loss': 0.19571652653816063}
2022-12-31 07:18:11,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:11,339 INFO:     Epoch: 21
2022-12-31 07:18:12,988 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45785018702348074, 'Total loss': 0.45785018702348074} | train loss {'Reaction outcome loss': 0.22487299874352384, 'Total loss': 0.22487299874352384}
2022-12-31 07:18:12,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:12,988 INFO:     Epoch: 22
2022-12-31 07:18:14,648 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4744518419106801, 'Total loss': 0.4744518419106801} | train loss {'Reaction outcome loss': 0.18939703429813284, 'Total loss': 0.18939703429813284}
2022-12-31 07:18:14,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:14,648 INFO:     Epoch: 23
2022-12-31 07:18:16,310 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4490220526854197, 'Total loss': 0.4490220526854197} | train loss {'Reaction outcome loss': 0.18207998122080174, 'Total loss': 0.18207998122080174}
2022-12-31 07:18:16,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:16,310 INFO:     Epoch: 24
2022-12-31 07:18:17,973 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47415901223818463, 'Total loss': 0.47415901223818463} | train loss {'Reaction outcome loss': 0.1768162540646027, 'Total loss': 0.1768162540646027}
2022-12-31 07:18:17,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:17,973 INFO:     Epoch: 25
2022-12-31 07:18:19,636 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4783276965220769, 'Total loss': 0.4783276965220769} | train loss {'Reaction outcome loss': 0.17396467027741153, 'Total loss': 0.17396467027741153}
2022-12-31 07:18:19,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:19,637 INFO:     Epoch: 26
2022-12-31 07:18:21,273 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46086892286936443, 'Total loss': 0.46086892286936443} | train loss {'Reaction outcome loss': 0.1687990901101211, 'Total loss': 0.1687990901101211}
2022-12-31 07:18:21,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:21,274 INFO:     Epoch: 27
2022-12-31 07:18:22,900 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48260034422079723, 'Total loss': 0.48260034422079723} | train loss {'Reaction outcome loss': 0.16864600540640717, 'Total loss': 0.16864600540640717}
2022-12-31 07:18:22,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:22,900 INFO:     Epoch: 28
2022-12-31 07:18:24,567 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45781510770320893, 'Total loss': 0.45781510770320893} | train loss {'Reaction outcome loss': 0.16456222078978908, 'Total loss': 0.16456222078978908}
2022-12-31 07:18:24,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:24,567 INFO:     Epoch: 29
2022-12-31 07:18:26,228 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49651307861010235, 'Total loss': 0.49651307861010235} | train loss {'Reaction outcome loss': 0.16197188091768033, 'Total loss': 0.16197188091768033}
2022-12-31 07:18:26,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:26,229 INFO:     Epoch: 30
2022-12-31 07:18:27,859 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4588154822587967, 'Total loss': 0.4588154822587967} | train loss {'Reaction outcome loss': 0.15907513786025473, 'Total loss': 0.15907513786025473}
2022-12-31 07:18:27,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:27,860 INFO:     Epoch: 31
2022-12-31 07:18:29,521 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.476379756629467, 'Total loss': 0.476379756629467} | train loss {'Reaction outcome loss': 0.15258324164961526, 'Total loss': 0.15258324164961526}
2022-12-31 07:18:29,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:29,521 INFO:     Epoch: 32
2022-12-31 07:18:31,132 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.49267324805259705, 'Total loss': 0.49267324805259705} | train loss {'Reaction outcome loss': 0.15301665517272076, 'Total loss': 0.15301665517272076}
2022-12-31 07:18:31,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:31,132 INFO:     Epoch: 33
2022-12-31 07:18:32,768 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44902231395244596, 'Total loss': 0.44902231395244596} | train loss {'Reaction outcome loss': 0.15196153689644037, 'Total loss': 0.15196153689644037}
2022-12-31 07:18:32,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:32,768 INFO:     Epoch: 34
2022-12-31 07:18:34,396 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48844428261121114, 'Total loss': 0.48844428261121114} | train loss {'Reaction outcome loss': 0.14779120819498465, 'Total loss': 0.14779120819498465}
2022-12-31 07:18:34,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:34,396 INFO:     Epoch: 35
2022-12-31 07:18:36,023 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46492326458295186, 'Total loss': 0.46492326458295186} | train loss {'Reaction outcome loss': 0.1447823103129243, 'Total loss': 0.1447823103129243}
2022-12-31 07:18:36,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:36,025 INFO:     Epoch: 36
2022-12-31 07:18:37,652 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47844066421190895, 'Total loss': 0.47844066421190895} | train loss {'Reaction outcome loss': 0.14445105633711902, 'Total loss': 0.14445105633711902}
2022-12-31 07:18:37,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:37,653 INFO:     Epoch: 37
2022-12-31 07:18:39,268 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4667581871151924, 'Total loss': 0.4667581871151924} | train loss {'Reaction outcome loss': 0.14302759440750748, 'Total loss': 0.14302759440750748}
2022-12-31 07:18:39,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:39,268 INFO:     Epoch: 38
2022-12-31 07:18:40,890 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5014950434366862, 'Total loss': 0.5014950434366862} | train loss {'Reaction outcome loss': 0.1439012279367054, 'Total loss': 0.1439012279367054}
2022-12-31 07:18:40,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:40,890 INFO:     Epoch: 39
2022-12-31 07:18:42,505 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5145195007324219, 'Total loss': 0.5145195007324219} | train loss {'Reaction outcome loss': 0.14236758271179834, 'Total loss': 0.14236758271179834}
2022-12-31 07:18:42,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:42,505 INFO:     Epoch: 40
2022-12-31 07:18:44,119 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4976648529370626, 'Total loss': 0.4976648529370626} | train loss {'Reaction outcome loss': 0.13991264434720296, 'Total loss': 0.13991264434720296}
2022-12-31 07:18:44,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:44,119 INFO:     Epoch: 41
2022-12-31 07:18:45,730 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45793326050043104, 'Total loss': 0.45793326050043104} | train loss {'Reaction outcome loss': 0.1378412142369901, 'Total loss': 0.1378412142369901}
2022-12-31 07:18:45,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:45,731 INFO:     Epoch: 42
2022-12-31 07:18:47,391 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4856539915005366, 'Total loss': 0.4856539915005366} | train loss {'Reaction outcome loss': 0.1326762953073667, 'Total loss': 0.1326762953073667}
2022-12-31 07:18:47,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:47,392 INFO:     Epoch: 43
2022-12-31 07:18:49,017 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47076644202073414, 'Total loss': 0.47076644202073414} | train loss {'Reaction outcome loss': 0.13281076042793744, 'Total loss': 0.13281076042793744}
2022-12-31 07:18:49,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:49,018 INFO:     Epoch: 44
2022-12-31 07:18:50,632 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4816050072511037, 'Total loss': 0.4816050072511037} | train loss {'Reaction outcome loss': 0.13261530285134263, 'Total loss': 0.13261530285134263}
2022-12-31 07:18:50,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:50,632 INFO:     Epoch: 45
2022-12-31 07:18:52,254 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48637530555327735, 'Total loss': 0.48637530555327735} | train loss {'Reaction outcome loss': 0.13807077637360687, 'Total loss': 0.13807077637360687}
2022-12-31 07:18:52,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:52,255 INFO:     Epoch: 46
2022-12-31 07:18:53,915 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4832840899626414, 'Total loss': 0.4832840899626414} | train loss {'Reaction outcome loss': 0.13169679956078745, 'Total loss': 0.13169679956078745}
2022-12-31 07:18:53,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:53,916 INFO:     Epoch: 47
2022-12-31 07:18:55,575 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4668133815129598, 'Total loss': 0.4668133815129598} | train loss {'Reaction outcome loss': 0.12936607561710264, 'Total loss': 0.12936607561710264}
2022-12-31 07:18:55,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:55,576 INFO:     Epoch: 48
2022-12-31 07:18:57,196 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48061492989460625, 'Total loss': 0.48061492989460625} | train loss {'Reaction outcome loss': 0.12757356799725592, 'Total loss': 0.12757356799725592}
2022-12-31 07:18:57,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:57,197 INFO:     Epoch: 49
2022-12-31 07:18:58,834 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4802066534757614, 'Total loss': 0.4802066534757614} | train loss {'Reaction outcome loss': 0.1268842814311358, 'Total loss': 0.1268842814311358}
2022-12-31 07:18:58,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:18:58,834 INFO:     Epoch: 50
2022-12-31 07:19:00,495 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4792871614297231, 'Total loss': 0.4792871614297231} | train loss {'Reaction outcome loss': 0.12770216234797693, 'Total loss': 0.12770216234797693}
2022-12-31 07:19:00,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:00,495 INFO:     Epoch: 51
2022-12-31 07:19:02,156 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4901562715570132, 'Total loss': 0.4901562715570132} | train loss {'Reaction outcome loss': 0.1235051311740645, 'Total loss': 0.1235051311740645}
2022-12-31 07:19:02,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:02,156 INFO:     Epoch: 52
2022-12-31 07:19:03,817 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45465233623981477, 'Total loss': 0.45465233623981477} | train loss {'Reaction outcome loss': 0.12617472523192375, 'Total loss': 0.12617472523192375}
2022-12-31 07:19:03,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:03,817 INFO:     Epoch: 53
2022-12-31 07:19:05,440 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4993649164835612, 'Total loss': 0.4993649164835612} | train loss {'Reaction outcome loss': 0.12667574519392752, 'Total loss': 0.12667574519392752}
2022-12-31 07:19:05,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:05,440 INFO:     Epoch: 54
2022-12-31 07:19:07,069 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4949077248573303, 'Total loss': 0.4949077248573303} | train loss {'Reaction outcome loss': 0.129368833383563, 'Total loss': 0.129368833383563}
2022-12-31 07:19:07,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:07,070 INFO:     Epoch: 55
2022-12-31 07:19:08,690 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5128150532643, 'Total loss': 0.5128150532643} | train loss {'Reaction outcome loss': 0.12469756079625095, 'Total loss': 0.12469756079625095}
2022-12-31 07:19:08,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:08,690 INFO:     Epoch: 56
2022-12-31 07:19:10,320 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45889728218317033, 'Total loss': 0.45889728218317033} | train loss {'Reaction outcome loss': 0.1228930915341429, 'Total loss': 0.1228930915341429}
2022-12-31 07:19:10,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:10,320 INFO:     Epoch: 57
2022-12-31 07:19:11,960 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49937518735726677, 'Total loss': 0.49937518735726677} | train loss {'Reaction outcome loss': 0.11948329283468319, 'Total loss': 0.11948329283468319}
2022-12-31 07:19:11,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:11,960 INFO:     Epoch: 58
2022-12-31 07:19:13,579 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48553334871927895, 'Total loss': 0.48553334871927895} | train loss {'Reaction outcome loss': 0.12025399598043304, 'Total loss': 0.12025399598043304}
2022-12-31 07:19:13,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:13,580 INFO:     Epoch: 59
2022-12-31 07:19:15,197 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4715722585717837, 'Total loss': 0.4715722585717837} | train loss {'Reaction outcome loss': 0.11670788680835952, 'Total loss': 0.11670788680835952}
2022-12-31 07:19:15,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:15,198 INFO:     Epoch: 60
2022-12-31 07:19:16,813 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4883491297562917, 'Total loss': 0.4883491297562917} | train loss {'Reaction outcome loss': 0.11800069219695972, 'Total loss': 0.11800069219695972}
2022-12-31 07:19:16,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:16,813 INFO:     Epoch: 61
2022-12-31 07:19:18,431 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48965659737586975, 'Total loss': 0.48965659737586975} | train loss {'Reaction outcome loss': 0.1325423919928574, 'Total loss': 0.1325423919928574}
2022-12-31 07:19:18,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:18,431 INFO:     Epoch: 62
2022-12-31 07:19:20,068 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47381517142057417, 'Total loss': 0.47381517142057417} | train loss {'Reaction outcome loss': 0.12162961573272511, 'Total loss': 0.12162961573272511}
2022-12-31 07:19:20,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:20,068 INFO:     Epoch: 63
2022-12-31 07:19:21,729 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49707989891370136, 'Total loss': 0.49707989891370136} | train loss {'Reaction outcome loss': 0.11478038072343316, 'Total loss': 0.11478038072343316}
2022-12-31 07:19:21,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:21,730 INFO:     Epoch: 64
2022-12-31 07:19:23,390 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4702602078517278, 'Total loss': 0.4702602078517278} | train loss {'Reaction outcome loss': 0.11501099455937577, 'Total loss': 0.11501099455937577}
2022-12-31 07:19:23,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:23,391 INFO:     Epoch: 65
2022-12-31 07:19:25,004 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4763313700755437, 'Total loss': 0.4763313700755437} | train loss {'Reaction outcome loss': 0.11574513158138845, 'Total loss': 0.11574513158138845}
2022-12-31 07:19:25,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:25,004 INFO:     Epoch: 66
2022-12-31 07:19:26,617 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4676963955163956, 'Total loss': 0.4676963955163956} | train loss {'Reaction outcome loss': 0.12013653379466817, 'Total loss': 0.12013653379466817}
2022-12-31 07:19:26,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:26,618 INFO:     Epoch: 67
2022-12-31 07:19:28,236 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48259913523991904, 'Total loss': 0.48259913523991904} | train loss {'Reaction outcome loss': 0.11858979449006375, 'Total loss': 0.11858979449006375}
2022-12-31 07:19:28,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:28,236 INFO:     Epoch: 68
2022-12-31 07:19:29,898 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5067299087842305, 'Total loss': 0.5067299087842305} | train loss {'Reaction outcome loss': 0.1167445678016731, 'Total loss': 0.1167445678016731}
2022-12-31 07:19:29,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:29,898 INFO:     Epoch: 69
2022-12-31 07:19:31,519 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4656811108191808, 'Total loss': 0.4656811108191808} | train loss {'Reaction outcome loss': 0.12021000333218093, 'Total loss': 0.12021000333218093}
2022-12-31 07:19:31,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:31,519 INFO:     Epoch: 70
2022-12-31 07:19:33,179 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4755571941534678, 'Total loss': 0.4755571941534678} | train loss {'Reaction outcome loss': 0.11417150387664467, 'Total loss': 0.11417150387664467}
2022-12-31 07:19:33,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:33,179 INFO:     Epoch: 71
2022-12-31 07:19:34,799 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4883402079343796, 'Total loss': 0.4883402079343796} | train loss {'Reaction outcome loss': 0.11270316745714704, 'Total loss': 0.11270316745714704}
2022-12-31 07:19:34,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:34,799 INFO:     Epoch: 72
2022-12-31 07:19:36,420 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5050649444262186, 'Total loss': 0.5050649444262186} | train loss {'Reaction outcome loss': 0.11589969528680397, 'Total loss': 0.11589969528680397}
2022-12-31 07:19:36,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:36,420 INFO:     Epoch: 73
2022-12-31 07:19:38,049 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47893387973308565, 'Total loss': 0.47893387973308565} | train loss {'Reaction outcome loss': 0.11205982631688222, 'Total loss': 0.11205982631688222}
2022-12-31 07:19:38,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:38,050 INFO:     Epoch: 74
2022-12-31 07:19:39,678 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4994145433108012, 'Total loss': 0.4994145433108012} | train loss {'Reaction outcome loss': 0.11769458108946033, 'Total loss': 0.11769458108946033}
2022-12-31 07:19:39,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:39,678 INFO:     Epoch: 75
2022-12-31 07:19:41,304 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4623757253090541, 'Total loss': 0.4623757253090541} | train loss {'Reaction outcome loss': 0.11797185882176933, 'Total loss': 0.11797185882176933}
2022-12-31 07:19:41,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:41,304 INFO:     Epoch: 76
2022-12-31 07:19:42,925 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44193651030460995, 'Total loss': 0.44193651030460995} | train loss {'Reaction outcome loss': 0.11634130582409115, 'Total loss': 0.11634130582409115}
2022-12-31 07:19:42,926 INFO:     Found new best model at epoch 76
2022-12-31 07:19:42,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:42,927 INFO:     Epoch: 77
2022-12-31 07:19:44,545 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48657560609281064, 'Total loss': 0.48657560609281064} | train loss {'Reaction outcome loss': 0.11684002105924436, 'Total loss': 0.11684002105924436}
2022-12-31 07:19:44,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:44,546 INFO:     Epoch: 78
2022-12-31 07:19:46,167 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5136990547180176, 'Total loss': 0.5136990547180176} | train loss {'Reaction outcome loss': 0.11310797299865229, 'Total loss': 0.11310797299865229}
2022-12-31 07:19:46,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:46,167 INFO:     Epoch: 79
2022-12-31 07:19:47,785 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45423718268672625, 'Total loss': 0.45423718268672625} | train loss {'Reaction outcome loss': 0.11286453643233339, 'Total loss': 0.11286453643233339}
2022-12-31 07:19:47,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:47,786 INFO:     Epoch: 80
2022-12-31 07:19:49,447 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49704900234937666, 'Total loss': 0.49704900234937666} | train loss {'Reaction outcome loss': 0.11252475963809284, 'Total loss': 0.11252475963809284}
2022-12-31 07:19:49,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:49,447 INFO:     Epoch: 81
2022-12-31 07:19:51,108 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45803717772165936, 'Total loss': 0.45803717772165936} | train loss {'Reaction outcome loss': 0.11402946564255441, 'Total loss': 0.11402946564255441}
2022-12-31 07:19:51,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:51,109 INFO:     Epoch: 82
2022-12-31 07:19:52,725 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4806290989120801, 'Total loss': 0.4806290989120801} | train loss {'Reaction outcome loss': 0.11167240022167908, 'Total loss': 0.11167240022167908}
2022-12-31 07:19:52,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:52,725 INFO:     Epoch: 83
2022-12-31 07:19:54,369 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4894513815641403, 'Total loss': 0.4894513815641403} | train loss {'Reaction outcome loss': 0.10792865622773905, 'Total loss': 0.10792865622773905}
2022-12-31 07:19:54,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:54,369 INFO:     Epoch: 84
2022-12-31 07:19:55,985 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5161897748708725, 'Total loss': 0.5161897748708725} | train loss {'Reaction outcome loss': 0.11037945145011216, 'Total loss': 0.11037945145011216}
2022-12-31 07:19:55,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:55,986 INFO:     Epoch: 85
2022-12-31 07:19:57,604 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49273903866608937, 'Total loss': 0.49273903866608937} | train loss {'Reaction outcome loss': 0.11506733522514549, 'Total loss': 0.11506733522514549}
2022-12-31 07:19:57,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:57,605 INFO:     Epoch: 86
2022-12-31 07:19:59,222 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4872931845486164, 'Total loss': 0.4872931845486164} | train loss {'Reaction outcome loss': 0.11223707064034871, 'Total loss': 0.11223707064034871}
2022-12-31 07:19:59,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:19:59,222 INFO:     Epoch: 87
2022-12-31 07:20:00,879 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47370983560880026, 'Total loss': 0.47370983560880026} | train loss {'Reaction outcome loss': 0.11576778393842635, 'Total loss': 0.11576778393842635}
2022-12-31 07:20:00,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:00,880 INFO:     Epoch: 88
2022-12-31 07:20:02,491 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4722584625085195, 'Total loss': 0.4722584625085195} | train loss {'Reaction outcome loss': 0.11697124848243497, 'Total loss': 0.11697124848243497}
2022-12-31 07:20:02,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:02,491 INFO:     Epoch: 89
2022-12-31 07:20:04,118 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47942316184441247, 'Total loss': 0.47942316184441247} | train loss {'Reaction outcome loss': 0.11138689201557693, 'Total loss': 0.11138689201557693}
2022-12-31 07:20:04,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:04,118 INFO:     Epoch: 90
2022-12-31 07:20:05,746 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4983029901981354, 'Total loss': 0.4983029901981354} | train loss {'Reaction outcome loss': 0.11046103956312806, 'Total loss': 0.11046103956312806}
2022-12-31 07:20:05,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:05,746 INFO:     Epoch: 91
2022-12-31 07:20:07,372 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4984150687853495, 'Total loss': 0.4984150687853495} | train loss {'Reaction outcome loss': 0.10795984647999528, 'Total loss': 0.10795984647999528}
2022-12-31 07:20:07,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:07,372 INFO:     Epoch: 92
2022-12-31 07:20:08,995 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47190098067124686, 'Total loss': 0.47190098067124686} | train loss {'Reaction outcome loss': 0.1109246350179487, 'Total loss': 0.1109246350179487}
2022-12-31 07:20:08,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:08,997 INFO:     Epoch: 93
2022-12-31 07:20:10,613 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48537019491195676, 'Total loss': 0.48537019491195676} | train loss {'Reaction outcome loss': 0.10761113143846582, 'Total loss': 0.10761113143846582}
2022-12-31 07:20:10,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:10,613 INFO:     Epoch: 94
2022-12-31 07:20:12,227 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4383559895058473, 'Total loss': 0.4383559895058473} | train loss {'Reaction outcome loss': 0.10720879295547053, 'Total loss': 0.10720879295547053}
2022-12-31 07:20:12,227 INFO:     Found new best model at epoch 94
2022-12-31 07:20:12,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:12,228 INFO:     Epoch: 95
2022-12-31 07:20:13,852 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46033888508876164, 'Total loss': 0.46033888508876164} | train loss {'Reaction outcome loss': 0.11480087865408901, 'Total loss': 0.11480087865408901}
2022-12-31 07:20:13,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:13,852 INFO:     Epoch: 96
2022-12-31 07:20:15,513 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48162861267725626, 'Total loss': 0.48162861267725626} | train loss {'Reaction outcome loss': 0.12041377741595329, 'Total loss': 0.12041377741595329}
2022-12-31 07:20:15,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:15,514 INFO:     Epoch: 97
2022-12-31 07:20:17,140 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4556528945763906, 'Total loss': 0.4556528945763906} | train loss {'Reaction outcome loss': 0.11310437153912536, 'Total loss': 0.11310437153912536}
2022-12-31 07:20:17,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:17,140 INFO:     Epoch: 98
2022-12-31 07:20:18,802 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4561938837170601, 'Total loss': 0.4561938837170601} | train loss {'Reaction outcome loss': 0.10557304047154213, 'Total loss': 0.10557304047154213}
2022-12-31 07:20:18,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:18,802 INFO:     Epoch: 99
2022-12-31 07:20:20,426 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45313920378684996, 'Total loss': 0.45313920378684996} | train loss {'Reaction outcome loss': 0.10484489174121046, 'Total loss': 0.10484489174121046}
2022-12-31 07:20:20,426 INFO:     Best model found after epoch 95 of 100.
2022-12-31 07:20:20,427 INFO:   Done with stage: TRAINING
2022-12-31 07:20:20,427 INFO:   Starting stage: EVALUATION
2022-12-31 07:20:20,557 INFO:   Done with stage: EVALUATION
2022-12-31 07:20:20,558 INFO:   Leaving out SEQ value Fold_2
2022-12-31 07:20:20,570 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 07:20:20,571 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:20:21,224 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:20:21,224 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:20:21,293 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:20:21,293 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:20:21,293 INFO:     No hyperparam tuning for this model
2022-12-31 07:20:21,293 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:20:21,293 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:20:21,294 INFO:     None feature selector for col prot
2022-12-31 07:20:21,294 INFO:     None feature selector for col prot
2022-12-31 07:20:21,294 INFO:     None feature selector for col prot
2022-12-31 07:20:21,295 INFO:     None feature selector for col chem
2022-12-31 07:20:21,295 INFO:     None feature selector for col chem
2022-12-31 07:20:21,295 INFO:     None feature selector for col chem
2022-12-31 07:20:21,295 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:20:21,295 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:20:21,297 INFO:     Number of params in model 224011
2022-12-31 07:20:21,300 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:20:21,300 INFO:   Starting stage: TRAINING
2022-12-31 07:20:21,345 INFO:     Val loss before train {'Reaction outcome loss': 0.9461528738339742, 'Total loss': 0.9461528738339742}
2022-12-31 07:20:21,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:21,345 INFO:     Epoch: 0
2022-12-31 07:20:22,942 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5884999712308248, 'Total loss': 0.5884999712308248} | train loss {'Reaction outcome loss': 0.8009590941034394, 'Total loss': 0.8009590941034394}
2022-12-31 07:20:22,942 INFO:     Found new best model at epoch 0
2022-12-31 07:20:22,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:22,943 INFO:     Epoch: 1
2022-12-31 07:20:24,543 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5095963835716247, 'Total loss': 0.5095963835716247} | train loss {'Reaction outcome loss': 0.5161000748912057, 'Total loss': 0.5161000748912057}
2022-12-31 07:20:24,543 INFO:     Found new best model at epoch 1
2022-12-31 07:20:24,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:24,545 INFO:     Epoch: 2
2022-12-31 07:20:26,143 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4523317808906237, 'Total loss': 0.4523317808906237} | train loss {'Reaction outcome loss': 0.44127493512717797, 'Total loss': 0.44127493512717797}
2022-12-31 07:20:26,143 INFO:     Found new best model at epoch 2
2022-12-31 07:20:26,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:26,144 INFO:     Epoch: 3
2022-12-31 07:20:27,736 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4302629053592682, 'Total loss': 0.4302629053592682} | train loss {'Reaction outcome loss': 0.40151262558969386, 'Total loss': 0.40151262558969386}
2022-12-31 07:20:27,737 INFO:     Found new best model at epoch 3
2022-12-31 07:20:27,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:27,738 INFO:     Epoch: 4
2022-12-31 07:20:29,324 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.41839700639247895, 'Total loss': 0.41839700639247895} | train loss {'Reaction outcome loss': 0.3758288793838941, 'Total loss': 0.3758288793838941}
2022-12-31 07:20:29,325 INFO:     Found new best model at epoch 4
2022-12-31 07:20:29,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:29,326 INFO:     Epoch: 5
2022-12-31 07:20:30,931 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4332526922225952, 'Total loss': 0.4332526922225952} | train loss {'Reaction outcome loss': 0.35371759959629606, 'Total loss': 0.35371759959629606}
2022-12-31 07:20:30,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:30,931 INFO:     Epoch: 6
2022-12-31 07:20:32,574 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.443856147925059, 'Total loss': 0.443856147925059} | train loss {'Reaction outcome loss': 0.33348464583739257, 'Total loss': 0.33348464583739257}
2022-12-31 07:20:32,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:32,574 INFO:     Epoch: 7
2022-12-31 07:20:34,198 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47129736344019574, 'Total loss': 0.47129736344019574} | train loss {'Reaction outcome loss': 0.3171449652548893, 'Total loss': 0.3171449652548893}
2022-12-31 07:20:34,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:34,199 INFO:     Epoch: 8
2022-12-31 07:20:35,841 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41309958696365356, 'Total loss': 0.41309958696365356} | train loss {'Reaction outcome loss': 0.30227456457448965, 'Total loss': 0.30227456457448965}
2022-12-31 07:20:35,841 INFO:     Found new best model at epoch 8
2022-12-31 07:20:35,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:35,842 INFO:     Epoch: 9
2022-12-31 07:20:37,436 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40232520798842114, 'Total loss': 0.40232520798842114} | train loss {'Reaction outcome loss': 0.2865177284851124, 'Total loss': 0.2865177284851124}
2022-12-31 07:20:37,436 INFO:     Found new best model at epoch 9
2022-12-31 07:20:37,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:37,437 INFO:     Epoch: 10
2022-12-31 07:20:39,054 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4275538663069407, 'Total loss': 0.4275538663069407} | train loss {'Reaction outcome loss': 0.2784444320769537, 'Total loss': 0.2784444320769537}
2022-12-31 07:20:39,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:39,055 INFO:     Epoch: 11
2022-12-31 07:20:40,702 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43437551458676654, 'Total loss': 0.43437551458676654} | train loss {'Reaction outcome loss': 0.27085527474053833, 'Total loss': 0.27085527474053833}
2022-12-31 07:20:40,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:40,702 INFO:     Epoch: 12
2022-12-31 07:20:42,305 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42962467968463897, 'Total loss': 0.42962467968463897} | train loss {'Reaction outcome loss': 0.2550644652692826, 'Total loss': 0.2550644652692826}
2022-12-31 07:20:42,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:42,305 INFO:     Epoch: 13
2022-12-31 07:20:43,949 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42669433504343035, 'Total loss': 0.42669433504343035} | train loss {'Reaction outcome loss': 0.2483256258507133, 'Total loss': 0.2483256258507133}
2022-12-31 07:20:43,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:43,951 INFO:     Epoch: 14
2022-12-31 07:20:45,552 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43269770642121635, 'Total loss': 0.43269770642121635} | train loss {'Reaction outcome loss': 0.24052210480329536, 'Total loss': 0.24052210480329536}
2022-12-31 07:20:45,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:45,552 INFO:     Epoch: 15
2022-12-31 07:20:47,160 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45554580092430114, 'Total loss': 0.45554580092430114} | train loss {'Reaction outcome loss': 0.2291797869821717, 'Total loss': 0.2291797869821717}
2022-12-31 07:20:47,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:47,160 INFO:     Epoch: 16
2022-12-31 07:20:48,764 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44645047585169473, 'Total loss': 0.44645047585169473} | train loss {'Reaction outcome loss': 0.22902115469887144, 'Total loss': 0.22902115469887144}
2022-12-31 07:20:48,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:48,764 INFO:     Epoch: 17
2022-12-31 07:20:50,375 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4203555623690287, 'Total loss': 0.4203555623690287} | train loss {'Reaction outcome loss': 0.21962417533873638, 'Total loss': 0.21962417533873638}
2022-12-31 07:20:50,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:50,376 INFO:     Epoch: 18
2022-12-31 07:20:51,986 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4357753296693166, 'Total loss': 0.4357753296693166} | train loss {'Reaction outcome loss': 0.21890516723113837, 'Total loss': 0.21890516723113837}
2022-12-31 07:20:51,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:51,987 INFO:     Epoch: 19
2022-12-31 07:20:53,597 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4231229960918427, 'Total loss': 0.4231229960918427} | train loss {'Reaction outcome loss': 0.2086513474747375, 'Total loss': 0.2086513474747375}
2022-12-31 07:20:53,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:53,597 INFO:     Epoch: 20
2022-12-31 07:20:55,202 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45388604601224264, 'Total loss': 0.45388604601224264} | train loss {'Reaction outcome loss': 0.2071502745192457, 'Total loss': 0.2071502745192457}
2022-12-31 07:20:55,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:55,202 INFO:     Epoch: 21
2022-12-31 07:20:56,803 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41773997048536937, 'Total loss': 0.41773997048536937} | train loss {'Reaction outcome loss': 0.2051467075602803, 'Total loss': 0.2051467075602803}
2022-12-31 07:20:56,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:56,803 INFO:     Epoch: 22
2022-12-31 07:20:58,418 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42258551040043435, 'Total loss': 0.42258551040043435} | train loss {'Reaction outcome loss': 0.1967892116174484, 'Total loss': 0.1967892116174484}
2022-12-31 07:20:58,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:20:58,419 INFO:     Epoch: 23
2022-12-31 07:21:00,033 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4335236916939417, 'Total loss': 0.4335236916939417} | train loss {'Reaction outcome loss': 0.1935171434185007, 'Total loss': 0.1935171434185007}
2022-12-31 07:21:00,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:00,033 INFO:     Epoch: 24
2022-12-31 07:21:01,644 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45619395772616067, 'Total loss': 0.45619395772616067} | train loss {'Reaction outcome loss': 0.18802564566948146, 'Total loss': 0.18802564566948146}
2022-12-31 07:21:01,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:01,644 INFO:     Epoch: 25
2022-12-31 07:21:03,250 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4359930803378423, 'Total loss': 0.4359930803378423} | train loss {'Reaction outcome loss': 0.18773451556994036, 'Total loss': 0.18773451556994036}
2022-12-31 07:21:03,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:03,251 INFO:     Epoch: 26
2022-12-31 07:21:04,853 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4279259691635768, 'Total loss': 0.4279259691635768} | train loss {'Reaction outcome loss': 0.18691898174856827, 'Total loss': 0.18691898174856827}
2022-12-31 07:21:04,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:04,854 INFO:     Epoch: 27
2022-12-31 07:21:06,453 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45470772782961527, 'Total loss': 0.45470772782961527} | train loss {'Reaction outcome loss': 0.1822039246722892, 'Total loss': 0.1822039246722892}
2022-12-31 07:21:06,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:06,453 INFO:     Epoch: 28
2022-12-31 07:21:08,065 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44362530211607615, 'Total loss': 0.44362530211607615} | train loss {'Reaction outcome loss': 0.18138686159536951, 'Total loss': 0.18138686159536951}
2022-12-31 07:21:08,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:08,066 INFO:     Epoch: 29
2022-12-31 07:21:09,673 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4420609623193741, 'Total loss': 0.4420609623193741} | train loss {'Reaction outcome loss': 0.17497373703225846, 'Total loss': 0.17497373703225846}
2022-12-31 07:21:09,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:09,674 INFO:     Epoch: 30
2022-12-31 07:21:11,291 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41863431135813395, 'Total loss': 0.41863431135813395} | train loss {'Reaction outcome loss': 0.17404154086342224, 'Total loss': 0.17404154086342224}
2022-12-31 07:21:11,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:11,292 INFO:     Epoch: 31
2022-12-31 07:21:12,902 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44268251260121666, 'Total loss': 0.44268251260121666} | train loss {'Reaction outcome loss': 0.17422210939583324, 'Total loss': 0.17422210939583324}
2022-12-31 07:21:12,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:12,902 INFO:     Epoch: 32
2022-12-31 07:21:14,505 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4546609958012899, 'Total loss': 0.4546609958012899} | train loss {'Reaction outcome loss': 0.16680279945538484, 'Total loss': 0.16680279945538484}
2022-12-31 07:21:14,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:14,505 INFO:     Epoch: 33
2022-12-31 07:21:16,111 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4513927698135376, 'Total loss': 0.4513927698135376} | train loss {'Reaction outcome loss': 0.1642425544150583, 'Total loss': 0.1642425544150583}
2022-12-31 07:21:16,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:16,112 INFO:     Epoch: 34
2022-12-31 07:21:17,723 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44133888483047484, 'Total loss': 0.44133888483047484} | train loss {'Reaction outcome loss': 0.16189182534704716, 'Total loss': 0.16189182534704716}
2022-12-31 07:21:17,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:17,723 INFO:     Epoch: 35
2022-12-31 07:21:19,337 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4203142980734507, 'Total loss': 0.4203142980734507} | train loss {'Reaction outcome loss': 0.1607154957411108, 'Total loss': 0.1607154957411108}
2022-12-31 07:21:19,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:19,337 INFO:     Epoch: 36
2022-12-31 07:21:20,948 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45818387866020205, 'Total loss': 0.45818387866020205} | train loss {'Reaction outcome loss': 0.16321606528962324, 'Total loss': 0.16321606528962324}
2022-12-31 07:21:20,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:20,949 INFO:     Epoch: 37
2022-12-31 07:21:22,545 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47236794730027515, 'Total loss': 0.47236794730027515} | train loss {'Reaction outcome loss': 0.15973248056071254, 'Total loss': 0.15973248056071254}
2022-12-31 07:21:22,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:22,545 INFO:     Epoch: 38
2022-12-31 07:21:24,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4342727190504471, 'Total loss': 0.4342727190504471} | train loss {'Reaction outcome loss': 0.15770244944990772, 'Total loss': 0.15770244944990772}
2022-12-31 07:21:24,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:24,145 INFO:     Epoch: 39
2022-12-31 07:21:25,764 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4492013027270635, 'Total loss': 0.4492013027270635} | train loss {'Reaction outcome loss': 0.15471645686843674, 'Total loss': 0.15471645686843674}
2022-12-31 07:21:25,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:25,764 INFO:     Epoch: 40
2022-12-31 07:21:27,409 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47612156967322034, 'Total loss': 0.47612156967322034} | train loss {'Reaction outcome loss': 0.15120187542663935, 'Total loss': 0.15120187542663935}
2022-12-31 07:21:27,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:27,410 INFO:     Epoch: 41
2022-12-31 07:21:29,019 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47260506451129913, 'Total loss': 0.47260506451129913} | train loss {'Reaction outcome loss': 0.15519930831849194, 'Total loss': 0.15519930831849194}
2022-12-31 07:21:29,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:29,019 INFO:     Epoch: 42
2022-12-31 07:21:30,664 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.483477795124054, 'Total loss': 0.483477795124054} | train loss {'Reaction outcome loss': 0.14977808660339742, 'Total loss': 0.14977808660339742}
2022-12-31 07:21:30,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:30,664 INFO:     Epoch: 43
2022-12-31 07:21:32,273 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45849274496237435, 'Total loss': 0.45849274496237435} | train loss {'Reaction outcome loss': 0.150338618748313, 'Total loss': 0.150338618748313}
2022-12-31 07:21:32,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:32,273 INFO:     Epoch: 44
2022-12-31 07:21:33,872 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48891543249289193, 'Total loss': 0.48891543249289193} | train loss {'Reaction outcome loss': 0.15051060616151318, 'Total loss': 0.15051060616151318}
2022-12-31 07:21:33,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:33,873 INFO:     Epoch: 45
2022-12-31 07:21:35,479 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4070277035236359, 'Total loss': 0.4070277035236359} | train loss {'Reaction outcome loss': 0.1447820733523085, 'Total loss': 0.1447820733523085}
2022-12-31 07:21:35,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:35,479 INFO:     Epoch: 46
2022-12-31 07:21:37,087 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4609928816556931, 'Total loss': 0.4609928816556931} | train loss {'Reaction outcome loss': 0.14542794474929352, 'Total loss': 0.14542794474929352}
2022-12-31 07:21:37,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:37,088 INFO:     Epoch: 47
2022-12-31 07:21:38,695 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.483351997534434, 'Total loss': 0.483351997534434} | train loss {'Reaction outcome loss': 0.14268292977914707, 'Total loss': 0.14268292977914707}
2022-12-31 07:21:38,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:38,695 INFO:     Epoch: 48
2022-12-31 07:21:40,305 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.450452646613121, 'Total loss': 0.450452646613121} | train loss {'Reaction outcome loss': 0.14196236270749363, 'Total loss': 0.14196236270749363}
2022-12-31 07:21:40,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:40,306 INFO:     Epoch: 49
2022-12-31 07:21:41,902 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46772533158461255, 'Total loss': 0.46772533158461255} | train loss {'Reaction outcome loss': 0.13945653159921859, 'Total loss': 0.13945653159921859}
2022-12-31 07:21:41,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:41,902 INFO:     Epoch: 50
2022-12-31 07:21:43,534 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4415787816047668, 'Total loss': 0.4415787816047668} | train loss {'Reaction outcome loss': 0.14035554470548972, 'Total loss': 0.14035554470548972}
2022-12-31 07:21:43,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:43,534 INFO:     Epoch: 51
2022-12-31 07:21:45,179 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41303358947237334, 'Total loss': 0.41303358947237334} | train loss {'Reaction outcome loss': 0.13811263283237052, 'Total loss': 0.13811263283237052}
2022-12-31 07:21:45,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:45,179 INFO:     Epoch: 52
2022-12-31 07:21:46,822 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45225276897350947, 'Total loss': 0.45225276897350947} | train loss {'Reaction outcome loss': 0.14287305635232955, 'Total loss': 0.14287305635232955}
2022-12-31 07:21:46,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:46,823 INFO:     Epoch: 53
2022-12-31 07:21:48,466 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48672074675559995, 'Total loss': 0.48672074675559995} | train loss {'Reaction outcome loss': 0.1384545911151247, 'Total loss': 0.1384545911151247}
2022-12-31 07:21:48,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:48,467 INFO:     Epoch: 54
2022-12-31 07:21:50,099 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44415735801060996, 'Total loss': 0.44415735801060996} | train loss {'Reaction outcome loss': 0.135139756593785, 'Total loss': 0.135139756593785}
2022-12-31 07:21:50,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:50,099 INFO:     Epoch: 55
2022-12-31 07:21:51,729 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46157212257385255, 'Total loss': 0.46157212257385255} | train loss {'Reaction outcome loss': 0.13233077900327278, 'Total loss': 0.13233077900327278}
2022-12-31 07:21:51,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:51,730 INFO:     Epoch: 56
2022-12-31 07:21:53,336 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4383744006355604, 'Total loss': 0.4383744006355604} | train loss {'Reaction outcome loss': 0.13257796771060198, 'Total loss': 0.13257796771060198}
2022-12-31 07:21:53,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:53,337 INFO:     Epoch: 57
2022-12-31 07:21:54,942 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45691545406977335, 'Total loss': 0.45691545406977335} | train loss {'Reaction outcome loss': 0.13698282739405107, 'Total loss': 0.13698282739405107}
2022-12-31 07:21:54,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:54,942 INFO:     Epoch: 58
2022-12-31 07:21:56,548 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4529141140480836, 'Total loss': 0.4529141140480836} | train loss {'Reaction outcome loss': 0.13218027985937922, 'Total loss': 0.13218027985937922}
2022-12-31 07:21:56,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:56,550 INFO:     Epoch: 59
2022-12-31 07:21:58,155 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4553211192289988, 'Total loss': 0.4553211192289988} | train loss {'Reaction outcome loss': 0.13354575890372253, 'Total loss': 0.13354575890372253}
2022-12-31 07:21:58,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:58,156 INFO:     Epoch: 60
2022-12-31 07:21:59,768 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4483769694964091, 'Total loss': 0.4483769694964091} | train loss {'Reaction outcome loss': 0.13445474199384397, 'Total loss': 0.13445474199384397}
2022-12-31 07:21:59,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:21:59,769 INFO:     Epoch: 61
2022-12-31 07:22:01,383 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44854168097178143, 'Total loss': 0.44854168097178143} | train loss {'Reaction outcome loss': 0.12910066479510005, 'Total loss': 0.12910066479510005}
2022-12-31 07:22:01,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:01,384 INFO:     Epoch: 62
2022-12-31 07:22:03,028 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46603662918011346, 'Total loss': 0.46603662918011346} | train loss {'Reaction outcome loss': 0.1291390215549891, 'Total loss': 0.1291390215549891}
2022-12-31 07:22:03,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:03,029 INFO:     Epoch: 63
2022-12-31 07:22:04,627 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4401494314273198, 'Total loss': 0.4401494314273198} | train loss {'Reaction outcome loss': 0.13139774332559861, 'Total loss': 0.13139774332559861}
2022-12-31 07:22:04,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:04,628 INFO:     Epoch: 64
2022-12-31 07:22:06,270 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4582836747169495, 'Total loss': 0.4582836747169495} | train loss {'Reaction outcome loss': 0.12639484042642918, 'Total loss': 0.12639484042642918}
2022-12-31 07:22:06,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:06,270 INFO:     Epoch: 65
2022-12-31 07:22:07,915 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.431982130308946, 'Total loss': 0.431982130308946} | train loss {'Reaction outcome loss': 0.1264470062293658, 'Total loss': 0.1264470062293658}
2022-12-31 07:22:07,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:07,915 INFO:     Epoch: 66
2022-12-31 07:22:09,525 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48092573682467143, 'Total loss': 0.48092573682467143} | train loss {'Reaction outcome loss': 0.12854796218866613, 'Total loss': 0.12854796218866613}
2022-12-31 07:22:09,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:09,525 INFO:     Epoch: 67
2022-12-31 07:22:11,124 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4295730575919151, 'Total loss': 0.4295730575919151} | train loss {'Reaction outcome loss': 0.1259268060558554, 'Total loss': 0.1259268060558554}
2022-12-31 07:22:11,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:11,124 INFO:     Epoch: 68
2022-12-31 07:22:12,768 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4701498915751775, 'Total loss': 0.4701498915751775} | train loss {'Reaction outcome loss': 0.12300697020715573, 'Total loss': 0.12300697020715573}
2022-12-31 07:22:12,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:12,768 INFO:     Epoch: 69
2022-12-31 07:22:14,411 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4590584129095078, 'Total loss': 0.4590584129095078} | train loss {'Reaction outcome loss': 0.1217446847666983, 'Total loss': 0.1217446847666983}
2022-12-31 07:22:14,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:14,412 INFO:     Epoch: 70
2022-12-31 07:22:16,055 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4776948471864065, 'Total loss': 0.4776948471864065} | train loss {'Reaction outcome loss': 0.1272645084931082, 'Total loss': 0.1272645084931082}
2022-12-31 07:22:16,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:16,056 INFO:     Epoch: 71
2022-12-31 07:22:17,658 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.467498912413915, 'Total loss': 0.467498912413915} | train loss {'Reaction outcome loss': 0.125960892712827, 'Total loss': 0.125960892712827}
2022-12-31 07:22:17,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:17,658 INFO:     Epoch: 72
2022-12-31 07:22:19,286 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45467866758505504, 'Total loss': 0.45467866758505504} | train loss {'Reaction outcome loss': 0.12085865611285516, 'Total loss': 0.12085865611285516}
2022-12-31 07:22:19,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:19,287 INFO:     Epoch: 73
2022-12-31 07:22:20,930 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45022330383459724, 'Total loss': 0.45022330383459724} | train loss {'Reaction outcome loss': 0.11893550677552492, 'Total loss': 0.11893550677552492}
2022-12-31 07:22:20,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:20,930 INFO:     Epoch: 74
2022-12-31 07:22:22,533 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4827908833821615, 'Total loss': 0.4827908833821615} | train loss {'Reaction outcome loss': 0.12025401061025513, 'Total loss': 0.12025401061025513}
2022-12-31 07:22:22,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:22,533 INFO:     Epoch: 75
2022-12-31 07:22:24,176 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4504422605037689, 'Total loss': 0.4504422605037689} | train loss {'Reaction outcome loss': 0.12455886924270909, 'Total loss': 0.12455886924270909}
2022-12-31 07:22:24,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:24,176 INFO:     Epoch: 76
2022-12-31 07:22:25,780 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4603310296932856, 'Total loss': 0.4603310296932856} | train loss {'Reaction outcome loss': 0.11973671502205151, 'Total loss': 0.11973671502205151}
2022-12-31 07:22:25,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:25,780 INFO:     Epoch: 77
2022-12-31 07:22:27,395 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4879212468862534, 'Total loss': 0.4879212468862534} | train loss {'Reaction outcome loss': 0.12124253263963121, 'Total loss': 0.12124253263963121}
2022-12-31 07:22:27,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:27,396 INFO:     Epoch: 78
2022-12-31 07:22:28,992 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4652769575516383, 'Total loss': 0.4652769575516383} | train loss {'Reaction outcome loss': 0.11860141865209754, 'Total loss': 0.11860141865209754}
2022-12-31 07:22:28,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:28,992 INFO:     Epoch: 79
2022-12-31 07:22:30,605 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4398004581530889, 'Total loss': 0.4398004581530889} | train loss {'Reaction outcome loss': 0.11717398501352677, 'Total loss': 0.11717398501352677}
2022-12-31 07:22:30,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:30,605 INFO:     Epoch: 80
2022-12-31 07:22:32,218 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4910257120927175, 'Total loss': 0.4910257120927175} | train loss {'Reaction outcome loss': 0.11715781369379588, 'Total loss': 0.11715781369379588}
2022-12-31 07:22:32,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:32,219 INFO:     Epoch: 81
2022-12-31 07:22:33,821 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46951674620310463, 'Total loss': 0.46951674620310463} | train loss {'Reaction outcome loss': 0.1218630581933855, 'Total loss': 0.1218630581933855}
2022-12-31 07:22:33,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:33,822 INFO:     Epoch: 82
2022-12-31 07:22:35,468 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4406580249468485, 'Total loss': 0.4406580249468485} | train loss {'Reaction outcome loss': 0.12078647487097498, 'Total loss': 0.12078647487097498}
2022-12-31 07:22:35,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:35,468 INFO:     Epoch: 83
2022-12-31 07:22:37,100 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49894723693529763, 'Total loss': 0.49894723693529763} | train loss {'Reaction outcome loss': 0.11685889068608865, 'Total loss': 0.11685889068608865}
2022-12-31 07:22:37,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:37,101 INFO:     Epoch: 84
2022-12-31 07:22:38,729 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43885648548603057, 'Total loss': 0.43885648548603057} | train loss {'Reaction outcome loss': 0.12695757348615772, 'Total loss': 0.12695757348615772}
2022-12-31 07:22:38,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:38,730 INFO:     Epoch: 85
2022-12-31 07:22:40,339 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4277525285879771, 'Total loss': 0.4277525285879771} | train loss {'Reaction outcome loss': 0.11312282206695322, 'Total loss': 0.11312282206695322}
2022-12-31 07:22:40,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:40,339 INFO:     Epoch: 86
2022-12-31 07:22:41,987 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45208443800608317, 'Total loss': 0.45208443800608317} | train loss {'Reaction outcome loss': 0.10939658318062896, 'Total loss': 0.10939658318062896}
2022-12-31 07:22:41,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:41,988 INFO:     Epoch: 87
2022-12-31 07:22:43,635 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4685824046532313, 'Total loss': 0.4685824046532313} | train loss {'Reaction outcome loss': 0.10997708094214181, 'Total loss': 0.10997708094214181}
2022-12-31 07:22:43,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:43,635 INFO:     Epoch: 88
2022-12-31 07:22:45,268 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4576361487309138, 'Total loss': 0.4576361487309138} | train loss {'Reaction outcome loss': 0.11526405965165669, 'Total loss': 0.11526405965165669}
2022-12-31 07:22:45,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:45,269 INFO:     Epoch: 89
2022-12-31 07:22:46,882 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46838395098845165, 'Total loss': 0.46838395098845165} | train loss {'Reaction outcome loss': 0.11195375112605183, 'Total loss': 0.11195375112605183}
2022-12-31 07:22:46,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:46,883 INFO:     Epoch: 90
2022-12-31 07:22:48,494 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5014213239153226, 'Total loss': 0.5014213239153226} | train loss {'Reaction outcome loss': 0.11023995717526874, 'Total loss': 0.11023995717526874}
2022-12-31 07:22:48,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:48,495 INFO:     Epoch: 91
2022-12-31 07:22:50,107 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48715916474660237, 'Total loss': 0.48715916474660237} | train loss {'Reaction outcome loss': 0.11371688273540892, 'Total loss': 0.11371688273540892}
2022-12-31 07:22:50,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:50,108 INFO:     Epoch: 92
2022-12-31 07:22:51,721 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48613853653271993, 'Total loss': 0.48613853653271993} | train loss {'Reaction outcome loss': 0.11263726705057553, 'Total loss': 0.11263726705057553}
2022-12-31 07:22:51,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:51,722 INFO:     Epoch: 93
2022-12-31 07:22:53,336 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48762447039286294, 'Total loss': 0.48762447039286294} | train loss {'Reaction outcome loss': 0.11239263316831337, 'Total loss': 0.11239263316831337}
2022-12-31 07:22:53,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:53,336 INFO:     Epoch: 94
2022-12-31 07:22:54,704 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4574649025996526, 'Total loss': 0.4574649025996526} | train loss {'Reaction outcome loss': 0.11648359173574509, 'Total loss': 0.11648359173574509}
2022-12-31 07:22:54,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:54,704 INFO:     Epoch: 95
2022-12-31 07:22:55,847 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.454257274667422, 'Total loss': 0.454257274667422} | train loss {'Reaction outcome loss': 0.11250696738758859, 'Total loss': 0.11250696738758859}
2022-12-31 07:22:55,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:55,847 INFO:     Epoch: 96
2022-12-31 07:22:56,985 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45952997406323753, 'Total loss': 0.45952997406323753} | train loss {'Reaction outcome loss': 0.10836285553725894, 'Total loss': 0.10836285553725894}
2022-12-31 07:22:56,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:56,985 INFO:     Epoch: 97
2022-12-31 07:22:58,126 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46920664310455323, 'Total loss': 0.46920664310455323} | train loss {'Reaction outcome loss': 0.11140896047161886, 'Total loss': 0.11140896047161886}
2022-12-31 07:22:58,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:58,126 INFO:     Epoch: 98
2022-12-31 07:22:59,496 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4393526295820872, 'Total loss': 0.4393526295820872} | train loss {'Reaction outcome loss': 0.10635705595842866, 'Total loss': 0.10635705595842866}
2022-12-31 07:22:59,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:22:59,496 INFO:     Epoch: 99
2022-12-31 07:23:01,139 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5089579910039902, 'Total loss': 0.5089579910039902} | train loss {'Reaction outcome loss': 0.11246327713179664, 'Total loss': 0.11246327713179664}
2022-12-31 07:23:01,140 INFO:     Best model found after epoch 10 of 100.
2022-12-31 07:23:01,140 INFO:   Done with stage: TRAINING
2022-12-31 07:23:01,140 INFO:   Starting stage: EVALUATION
2022-12-31 07:23:01,284 INFO:   Done with stage: EVALUATION
2022-12-31 07:23:01,284 INFO:   Leaving out SEQ value Fold_3
2022-12-31 07:23:01,297 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 07:23:01,297 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:23:01,959 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:23:01,959 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:23:02,027 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:23:02,027 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:23:02,027 INFO:     No hyperparam tuning for this model
2022-12-31 07:23:02,027 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:23:02,027 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:23:02,028 INFO:     None feature selector for col prot
2022-12-31 07:23:02,028 INFO:     None feature selector for col prot
2022-12-31 07:23:02,028 INFO:     None feature selector for col prot
2022-12-31 07:23:02,028 INFO:     None feature selector for col chem
2022-12-31 07:23:02,029 INFO:     None feature selector for col chem
2022-12-31 07:23:02,029 INFO:     None feature selector for col chem
2022-12-31 07:23:02,029 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:23:02,029 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:23:02,031 INFO:     Number of params in model 224011
2022-12-31 07:23:02,034 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:23:02,034 INFO:   Starting stage: TRAINING
2022-12-31 07:23:02,078 INFO:     Val loss before train {'Reaction outcome loss': 1.0061647097269695, 'Total loss': 1.0061647097269695}
2022-12-31 07:23:02,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:02,079 INFO:     Epoch: 0
2022-12-31 07:23:03,662 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.481405633687973, 'Total loss': 0.481405633687973} | train loss {'Reaction outcome loss': 0.7811007467803041, 'Total loss': 0.7811007467803041}
2022-12-31 07:23:03,662 INFO:     Found new best model at epoch 0
2022-12-31 07:23:03,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:03,663 INFO:     Epoch: 1
2022-12-31 07:23:05,253 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45043400923411053, 'Total loss': 0.45043400923411053} | train loss {'Reaction outcome loss': 0.49110665735943293, 'Total loss': 0.49110665735943293}
2022-12-31 07:23:05,253 INFO:     Found new best model at epoch 1
2022-12-31 07:23:05,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:05,254 INFO:     Epoch: 2
2022-12-31 07:23:06,841 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.426277232170105, 'Total loss': 0.426277232170105} | train loss {'Reaction outcome loss': 0.4188184935833255, 'Total loss': 0.4188184935833255}
2022-12-31 07:23:06,842 INFO:     Found new best model at epoch 2
2022-12-31 07:23:06,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:06,843 INFO:     Epoch: 3
2022-12-31 07:23:08,423 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3906796216964722, 'Total loss': 0.3906796216964722} | train loss {'Reaction outcome loss': 0.38063715351573657, 'Total loss': 0.38063715351573657}
2022-12-31 07:23:08,424 INFO:     Found new best model at epoch 3
2022-12-31 07:23:08,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:08,425 INFO:     Epoch: 4
2022-12-31 07:23:10,011 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40722663899262745, 'Total loss': 0.40722663899262745} | train loss {'Reaction outcome loss': 0.35355711843804677, 'Total loss': 0.35355711843804677}
2022-12-31 07:23:10,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:10,011 INFO:     Epoch: 5
2022-12-31 07:23:11,640 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3501953383286794, 'Total loss': 0.3501953383286794} | train loss {'Reaction outcome loss': 0.32846742714463123, 'Total loss': 0.32846742714463123}
2022-12-31 07:23:11,640 INFO:     Found new best model at epoch 5
2022-12-31 07:23:11,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:11,641 INFO:     Epoch: 6
2022-12-31 07:23:13,226 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3495321502288183, 'Total loss': 0.3495321502288183} | train loss {'Reaction outcome loss': 0.30675741726347, 'Total loss': 0.30675741726347}
2022-12-31 07:23:13,226 INFO:     Found new best model at epoch 6
2022-12-31 07:23:13,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:13,227 INFO:     Epoch: 7
2022-12-31 07:23:14,820 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3693928907314936, 'Total loss': 0.3693928907314936} | train loss {'Reaction outcome loss': 0.2914906632485095, 'Total loss': 0.2914906632485095}
2022-12-31 07:23:14,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:14,821 INFO:     Epoch: 8
2022-12-31 07:23:16,411 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3925734003384908, 'Total loss': 0.3925734003384908} | train loss {'Reaction outcome loss': 0.27372636229514635, 'Total loss': 0.27372636229514635}
2022-12-31 07:23:16,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:16,411 INFO:     Epoch: 9
2022-12-31 07:23:17,995 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4186838537454605, 'Total loss': 0.4186838537454605} | train loss {'Reaction outcome loss': 0.2562802817081393, 'Total loss': 0.2562802817081393}
2022-12-31 07:23:17,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:17,995 INFO:     Epoch: 10
2022-12-31 07:23:19,586 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.35267430494228996, 'Total loss': 0.35267430494228996} | train loss {'Reaction outcome loss': 0.24656174439125836, 'Total loss': 0.24656174439125836}
2022-12-31 07:23:19,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:19,586 INFO:     Epoch: 11
2022-12-31 07:23:21,197 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34863438581426937, 'Total loss': 0.34863438581426937} | train loss {'Reaction outcome loss': 0.23066138051367774, 'Total loss': 0.23066138051367774}
2022-12-31 07:23:21,197 INFO:     Found new best model at epoch 11
2022-12-31 07:23:21,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:21,198 INFO:     Epoch: 12
2022-12-31 07:23:22,796 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3481623411178589, 'Total loss': 0.3481623411178589} | train loss {'Reaction outcome loss': 0.22144656265463777, 'Total loss': 0.22144656265463777}
2022-12-31 07:23:22,796 INFO:     Found new best model at epoch 12
2022-12-31 07:23:22,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:22,797 INFO:     Epoch: 13
2022-12-31 07:23:24,391 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3815041253964106, 'Total loss': 0.3815041253964106} | train loss {'Reaction outcome loss': 0.21211197587396827, 'Total loss': 0.21211197587396827}
2022-12-31 07:23:24,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:24,391 INFO:     Epoch: 14
2022-12-31 07:23:26,006 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3449871812170992, 'Total loss': 0.3449871812170992} | train loss {'Reaction outcome loss': 0.2032711838279263, 'Total loss': 0.2032711838279263}
2022-12-31 07:23:26,007 INFO:     Found new best model at epoch 14
2022-12-31 07:23:26,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:26,008 INFO:     Epoch: 15
2022-12-31 07:23:27,594 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3953035439054171, 'Total loss': 0.3953035439054171} | train loss {'Reaction outcome loss': 0.19848420622851357, 'Total loss': 0.19848420622851357}
2022-12-31 07:23:27,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:27,595 INFO:     Epoch: 16
2022-12-31 07:23:29,180 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35709352493286134, 'Total loss': 0.35709352493286134} | train loss {'Reaction outcome loss': 0.18986790439258314, 'Total loss': 0.18986790439258314}
2022-12-31 07:23:29,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:29,180 INFO:     Epoch: 17
2022-12-31 07:23:30,777 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.35436812341213225, 'Total loss': 0.35436812341213225} | train loss {'Reaction outcome loss': 0.18554215032153684, 'Total loss': 0.18554215032153684}
2022-12-31 07:23:30,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:30,777 INFO:     Epoch: 18
2022-12-31 07:23:32,369 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3848244736591975, 'Total loss': 0.3848244736591975} | train loss {'Reaction outcome loss': 0.1796914663688173, 'Total loss': 0.1796914663688173}
2022-12-31 07:23:32,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:32,369 INFO:     Epoch: 19
2022-12-31 07:23:33,961 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4357270767291387, 'Total loss': 0.4357270767291387} | train loss {'Reaction outcome loss': 0.17256009386254412, 'Total loss': 0.17256009386254412}
2022-12-31 07:23:33,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:33,962 INFO:     Epoch: 20
2022-12-31 07:23:35,545 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36522031724452975, 'Total loss': 0.36522031724452975} | train loss {'Reaction outcome loss': 0.16802700538861795, 'Total loss': 0.16802700538861795}
2022-12-31 07:23:35,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:35,545 INFO:     Epoch: 21
2022-12-31 07:23:37,178 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3869171589612961, 'Total loss': 0.3869171589612961} | train loss {'Reaction outcome loss': 0.16318124834434353, 'Total loss': 0.16318124834434353}
2022-12-31 07:23:37,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:37,179 INFO:     Epoch: 22
2022-12-31 07:23:38,813 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3557049885392189, 'Total loss': 0.3557049885392189} | train loss {'Reaction outcome loss': 0.16114574631614217, 'Total loss': 0.16114574631614217}
2022-12-31 07:23:38,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:38,813 INFO:     Epoch: 23
2022-12-31 07:23:40,430 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37403625703106325, 'Total loss': 0.37403625703106325} | train loss {'Reaction outcome loss': 0.15649219223975144, 'Total loss': 0.15649219223975144}
2022-12-31 07:23:40,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:40,431 INFO:     Epoch: 24
2022-12-31 07:23:42,023 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42545029520988464, 'Total loss': 0.42545029520988464} | train loss {'Reaction outcome loss': 0.15081476320502282, 'Total loss': 0.15081476320502282}
2022-12-31 07:23:42,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:42,023 INFO:     Epoch: 25
2022-12-31 07:23:43,613 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3992993324995041, 'Total loss': 0.3992993324995041} | train loss {'Reaction outcome loss': 0.14633526942757993, 'Total loss': 0.14633526942757993}
2022-12-31 07:23:43,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:43,614 INFO:     Epoch: 26
2022-12-31 07:23:45,197 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40799910500645636, 'Total loss': 0.40799910500645636} | train loss {'Reaction outcome loss': 0.1487820630814069, 'Total loss': 0.1487820630814069}
2022-12-31 07:23:45,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:45,197 INFO:     Epoch: 27
2022-12-31 07:23:46,809 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38271222126980625, 'Total loss': 0.38271222126980625} | train loss {'Reaction outcome loss': 0.14799612900414041, 'Total loss': 0.14799612900414041}
2022-12-31 07:23:46,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:46,809 INFO:     Epoch: 28
2022-12-31 07:23:48,397 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38395339672764145, 'Total loss': 0.38395339672764145} | train loss {'Reaction outcome loss': 0.145359903323117, 'Total loss': 0.145359903323117}
2022-12-31 07:23:48,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:48,398 INFO:     Epoch: 29
2022-12-31 07:23:50,031 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3854930758786698, 'Total loss': 0.3854930758786698} | train loss {'Reaction outcome loss': 0.14125066769835143, 'Total loss': 0.14125066769835143}
2022-12-31 07:23:50,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:50,032 INFO:     Epoch: 30
2022-12-31 07:23:51,627 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4016148914893468, 'Total loss': 0.4016148914893468} | train loss {'Reaction outcome loss': 0.13778491014429123, 'Total loss': 0.13778491014429123}
2022-12-31 07:23:51,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:51,628 INFO:     Epoch: 31
2022-12-31 07:23:53,248 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3728282759897411, 'Total loss': 0.3728282759897411} | train loss {'Reaction outcome loss': 0.1382467446769708, 'Total loss': 0.1382467446769708}
2022-12-31 07:23:53,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:53,248 INFO:     Epoch: 32
2022-12-31 07:23:54,883 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40585095485051476, 'Total loss': 0.40585095485051476} | train loss {'Reaction outcome loss': 0.1350092593119978, 'Total loss': 0.1350092593119978}
2022-12-31 07:23:54,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:54,883 INFO:     Epoch: 33
2022-12-31 07:23:56,517 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4250230190654596, 'Total loss': 0.4250230190654596} | train loss {'Reaction outcome loss': 0.13161315468253354, 'Total loss': 0.13161315468253354}
2022-12-31 07:23:56,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:56,517 INFO:     Epoch: 34
2022-12-31 07:23:58,121 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3602241939554612, 'Total loss': 0.3602241939554612} | train loss {'Reaction outcome loss': 0.13691041714810798, 'Total loss': 0.13691041714810798}
2022-12-31 07:23:58,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:58,121 INFO:     Epoch: 35
2022-12-31 07:23:59,754 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42082641397913295, 'Total loss': 0.42082641397913295} | train loss {'Reaction outcome loss': 0.13090647154958485, 'Total loss': 0.13090647154958485}
2022-12-31 07:23:59,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:23:59,754 INFO:     Epoch: 36
2022-12-31 07:24:01,387 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3844963113466899, 'Total loss': 0.3844963113466899} | train loss {'Reaction outcome loss': 0.13298636387064502, 'Total loss': 0.13298636387064502}
2022-12-31 07:24:01,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:01,388 INFO:     Epoch: 37
2022-12-31 07:24:02,995 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4170657590031624, 'Total loss': 0.4170657590031624} | train loss {'Reaction outcome loss': 0.1263623541011389, 'Total loss': 0.1263623541011389}
2022-12-31 07:24:02,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:02,996 INFO:     Epoch: 38
2022-12-31 07:24:04,604 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4127537856499354, 'Total loss': 0.4127537856499354} | train loss {'Reaction outcome loss': 0.12493565564157229, 'Total loss': 0.12493565564157229}
2022-12-31 07:24:04,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:04,604 INFO:     Epoch: 39
2022-12-31 07:24:06,199 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41164740969737373, 'Total loss': 0.41164740969737373} | train loss {'Reaction outcome loss': 0.12430048459192318, 'Total loss': 0.12430048459192318}
2022-12-31 07:24:06,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:06,199 INFO:     Epoch: 40
2022-12-31 07:24:07,791 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3723659537732601, 'Total loss': 0.3723659537732601} | train loss {'Reaction outcome loss': 0.12308169313194402, 'Total loss': 0.12308169313194402}
2022-12-31 07:24:07,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:07,791 INFO:     Epoch: 41
2022-12-31 07:24:09,423 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4007203280925751, 'Total loss': 0.4007203280925751} | train loss {'Reaction outcome loss': 0.12196275936542732, 'Total loss': 0.12196275936542732}
2022-12-31 07:24:09,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:09,423 INFO:     Epoch: 42
2022-12-31 07:24:11,057 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37628929746182016, 'Total loss': 0.37628929746182016} | train loss {'Reaction outcome loss': 0.12414106948995392, 'Total loss': 0.12414106948995392}
2022-12-31 07:24:11,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:11,058 INFO:     Epoch: 43
2022-12-31 07:24:12,658 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38341351350148517, 'Total loss': 0.38341351350148517} | train loss {'Reaction outcome loss': 0.12236993131485538, 'Total loss': 0.12236993131485538}
2022-12-31 07:24:12,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:12,659 INFO:     Epoch: 44
2022-12-31 07:24:14,268 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.412836409608523, 'Total loss': 0.412836409608523} | train loss {'Reaction outcome loss': 0.12136599179047995, 'Total loss': 0.12136599179047995}
2022-12-31 07:24:14,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:14,269 INFO:     Epoch: 45
2022-12-31 07:24:15,854 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44540279507637026, 'Total loss': 0.44540279507637026} | train loss {'Reaction outcome loss': 0.11994644006494282, 'Total loss': 0.11994644006494282}
2022-12-31 07:24:15,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:15,854 INFO:     Epoch: 46
2022-12-31 07:24:17,479 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3900952768822511, 'Total loss': 0.3900952768822511} | train loss {'Reaction outcome loss': 0.12125205418363048, 'Total loss': 0.12125205418363048}
2022-12-31 07:24:17,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:17,479 INFO:     Epoch: 47
2022-12-31 07:24:19,167 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36343814780314765, 'Total loss': 0.36343814780314765} | train loss {'Reaction outcome loss': 0.11865238497906615, 'Total loss': 0.11865238497906615}
2022-12-31 07:24:19,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:19,167 INFO:     Epoch: 48
2022-12-31 07:24:20,840 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4030860851208369, 'Total loss': 0.4030860851208369} | train loss {'Reaction outcome loss': 0.11700214942353623, 'Total loss': 0.11700214942353623}
2022-12-31 07:24:20,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:20,841 INFO:     Epoch: 49
2022-12-31 07:24:22,476 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37949424045315633, 'Total loss': 0.37949424045315633} | train loss {'Reaction outcome loss': 0.11589378718032443, 'Total loss': 0.11589378718032443}
2022-12-31 07:24:22,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:22,476 INFO:     Epoch: 50
2022-12-31 07:24:24,110 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4142247711618741, 'Total loss': 0.4142247711618741} | train loss {'Reaction outcome loss': 0.1174001579836176, 'Total loss': 0.1174001579836176}
2022-12-31 07:24:24,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:24,110 INFO:     Epoch: 51
2022-12-31 07:24:25,714 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39204826653003694, 'Total loss': 0.39204826653003694} | train loss {'Reaction outcome loss': 0.11468724149358339, 'Total loss': 0.11468724149358339}
2022-12-31 07:24:25,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:25,714 INFO:     Epoch: 52
2022-12-31 07:24:27,348 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42318789958953856, 'Total loss': 0.42318789958953856} | train loss {'Reaction outcome loss': 0.11155296963849191, 'Total loss': 0.11155296963849191}
2022-12-31 07:24:27,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:27,348 INFO:     Epoch: 53
2022-12-31 07:24:28,982 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4237516651550929, 'Total loss': 0.4237516651550929} | train loss {'Reaction outcome loss': 0.11675496177740972, 'Total loss': 0.11675496177740972}
2022-12-31 07:24:28,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:28,982 INFO:     Epoch: 54
2022-12-31 07:24:30,590 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.36708855082591374, 'Total loss': 0.36708855082591374} | train loss {'Reaction outcome loss': 0.11799858442062643, 'Total loss': 0.11799858442062643}
2022-12-31 07:24:30,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:30,590 INFO:     Epoch: 55
2022-12-31 07:24:32,182 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39466677655776344, 'Total loss': 0.39466677655776344} | train loss {'Reaction outcome loss': 0.11502833245150278, 'Total loss': 0.11502833245150278}
2022-12-31 07:24:32,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:32,183 INFO:     Epoch: 56
2022-12-31 07:24:33,774 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4128176135321458, 'Total loss': 0.4128176135321458} | train loss {'Reaction outcome loss': 0.11491434517354324, 'Total loss': 0.11491434517354324}
2022-12-31 07:24:33,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:33,775 INFO:     Epoch: 57
2022-12-31 07:24:35,387 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37132897675037385, 'Total loss': 0.37132897675037385} | train loss {'Reaction outcome loss': 0.112702612326965, 'Total loss': 0.112702612326965}
2022-12-31 07:24:35,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:35,388 INFO:     Epoch: 58
2022-12-31 07:24:37,021 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3638100895778431, 'Total loss': 0.3638100895778431} | train loss {'Reaction outcome loss': 0.11195124037618787, 'Total loss': 0.11195124037618787}
2022-12-31 07:24:37,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:37,021 INFO:     Epoch: 59
2022-12-31 07:24:38,607 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4294913589954376, 'Total loss': 0.4294913589954376} | train loss {'Reaction outcome loss': 0.11328705489752312, 'Total loss': 0.11328705489752312}
2022-12-31 07:24:38,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:38,608 INFO:     Epoch: 60
2022-12-31 07:24:40,210 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4071499501665433, 'Total loss': 0.4071499501665433} | train loss {'Reaction outcome loss': 0.11042108137600426, 'Total loss': 0.11042108137600426}
2022-12-31 07:24:40,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:40,211 INFO:     Epoch: 61
2022-12-31 07:24:41,815 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4116227547327677, 'Total loss': 0.4116227547327677} | train loss {'Reaction outcome loss': 0.10862529326773272, 'Total loss': 0.10862529326773272}
2022-12-31 07:24:41,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:41,815 INFO:     Epoch: 62
2022-12-31 07:24:43,413 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3581591894229253, 'Total loss': 0.3581591894229253} | train loss {'Reaction outcome loss': 0.10573576688611831, 'Total loss': 0.10573576688611831}
2022-12-31 07:24:43,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:43,413 INFO:     Epoch: 63
2022-12-31 07:24:45,042 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36664316306511563, 'Total loss': 0.36664316306511563} | train loss {'Reaction outcome loss': 0.11046628167893999, 'Total loss': 0.11046628167893999}
2022-12-31 07:24:45,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:45,043 INFO:     Epoch: 64
2022-12-31 07:24:46,629 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4203469132383664, 'Total loss': 0.4203469132383664} | train loss {'Reaction outcome loss': 0.11033602101157843, 'Total loss': 0.11033602101157843}
2022-12-31 07:24:46,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:46,629 INFO:     Epoch: 65
2022-12-31 07:24:48,259 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3875571221113205, 'Total loss': 0.3875571221113205} | train loss {'Reaction outcome loss': 0.10848569979966786, 'Total loss': 0.10848569979966786}
2022-12-31 07:24:48,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:48,259 INFO:     Epoch: 66
2022-12-31 07:24:49,855 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44102113246917723, 'Total loss': 0.44102113246917723} | train loss {'Reaction outcome loss': 0.10880426555224161, 'Total loss': 0.10880426555224161}
2022-12-31 07:24:49,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:49,855 INFO:     Epoch: 67
2022-12-31 07:24:51,465 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42809354066848754, 'Total loss': 0.42809354066848754} | train loss {'Reaction outcome loss': 0.10850630586836281, 'Total loss': 0.10850630586836281}
2022-12-31 07:24:51,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:51,466 INFO:     Epoch: 68
2022-12-31 07:24:53,054 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40477607399225235, 'Total loss': 0.40477607399225235} | train loss {'Reaction outcome loss': 0.10571397675331888, 'Total loss': 0.10571397675331888}
2022-12-31 07:24:53,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:53,054 INFO:     Epoch: 69
2022-12-31 07:24:54,693 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.412881712988019, 'Total loss': 0.412881712988019} | train loss {'Reaction outcome loss': 0.10319241063284423, 'Total loss': 0.10319241063284423}
2022-12-31 07:24:54,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:54,693 INFO:     Epoch: 70
2022-12-31 07:24:56,290 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4494989842176437, 'Total loss': 0.4494989842176437} | train loss {'Reaction outcome loss': 0.10368090509385475, 'Total loss': 0.10368090509385475}
2022-12-31 07:24:56,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:56,290 INFO:     Epoch: 71
2022-12-31 07:24:57,912 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3747374943612764, 'Total loss': 0.3747374943612764} | train loss {'Reaction outcome loss': 0.1031256118055598, 'Total loss': 0.1031256118055598}
2022-12-31 07:24:57,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:57,912 INFO:     Epoch: 72
2022-12-31 07:24:59,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39297048238416515, 'Total loss': 0.39297048238416515} | train loss {'Reaction outcome loss': 0.10498300335813328, 'Total loss': 0.10498300335813328}
2022-12-31 07:24:59,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:24:59,510 INFO:     Epoch: 73
2022-12-31 07:25:01,148 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38075246214866637, 'Total loss': 0.38075246214866637} | train loss {'Reaction outcome loss': 0.11230174446396007, 'Total loss': 0.11230174446396007}
2022-12-31 07:25:01,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:01,148 INFO:     Epoch: 74
2022-12-31 07:25:02,741 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.439757044116656, 'Total loss': 0.439757044116656} | train loss {'Reaction outcome loss': 0.11315136309713125, 'Total loss': 0.11315136309713125}
2022-12-31 07:25:02,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:02,741 INFO:     Epoch: 75
2022-12-31 07:25:04,376 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38459621568520863, 'Total loss': 0.38459621568520863} | train loss {'Reaction outcome loss': 0.10566108056423135, 'Total loss': 0.10566108056423135}
2022-12-31 07:25:04,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:04,377 INFO:     Epoch: 76
2022-12-31 07:25:05,969 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40746456334988274, 'Total loss': 0.40746456334988274} | train loss {'Reaction outcome loss': 0.10289060670497563, 'Total loss': 0.10289060670497563}
2022-12-31 07:25:05,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:05,969 INFO:     Epoch: 77
2022-12-31 07:25:07,568 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46130638420581815, 'Total loss': 0.46130638420581815} | train loss {'Reaction outcome loss': 0.10511502708786089, 'Total loss': 0.10511502708786089}
2022-12-31 07:25:07,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:07,569 INFO:     Epoch: 78
2022-12-31 07:25:09,163 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39708308478196463, 'Total loss': 0.39708308478196463} | train loss {'Reaction outcome loss': 0.10500938563205549, 'Total loss': 0.10500938563205549}
2022-12-31 07:25:09,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:09,163 INFO:     Epoch: 79
2022-12-31 07:25:10,758 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40846399863560995, 'Total loss': 0.40846399863560995} | train loss {'Reaction outcome loss': 0.09739310834281889, 'Total loss': 0.09739310834281889}
2022-12-31 07:25:10,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:10,758 INFO:     Epoch: 80
2022-12-31 07:25:12,380 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44186198314030967, 'Total loss': 0.44186198314030967} | train loss {'Reaction outcome loss': 0.09926481712506431, 'Total loss': 0.09926481712506431}
2022-12-31 07:25:12,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:12,380 INFO:     Epoch: 81
2022-12-31 07:25:14,014 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4238486409187317, 'Total loss': 0.4238486409187317} | train loss {'Reaction outcome loss': 0.10711320670754597, 'Total loss': 0.10711320670754597}
2022-12-31 07:25:14,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:14,014 INFO:     Epoch: 82
2022-12-31 07:25:15,650 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4039722740650177, 'Total loss': 0.4039722740650177} | train loss {'Reaction outcome loss': 0.10378555659414355, 'Total loss': 0.10378555659414355}
2022-12-31 07:25:15,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:15,651 INFO:     Epoch: 83
2022-12-31 07:25:17,273 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4047881503899892, 'Total loss': 0.4047881503899892} | train loss {'Reaction outcome loss': 0.09948169391746615, 'Total loss': 0.09948169391746615}
2022-12-31 07:25:17,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:17,273 INFO:     Epoch: 84
2022-12-31 07:25:18,907 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40035435954729715, 'Total loss': 0.40035435954729715} | train loss {'Reaction outcome loss': 0.098921291802484, 'Total loss': 0.098921291802484}
2022-12-31 07:25:18,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:18,907 INFO:     Epoch: 85
2022-12-31 07:25:20,498 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3970132132371267, 'Total loss': 0.3970132132371267} | train loss {'Reaction outcome loss': 0.09992039862958323, 'Total loss': 0.09992039862958323}
2022-12-31 07:25:20,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:20,498 INFO:     Epoch: 86
2022-12-31 07:25:22,091 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38045202669066686, 'Total loss': 0.38045202669066686} | train loss {'Reaction outcome loss': 0.09784983588052687, 'Total loss': 0.09784983588052687}
2022-12-31 07:25:22,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:22,092 INFO:     Epoch: 87
2022-12-31 07:25:23,681 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42473340382178626, 'Total loss': 0.42473340382178626} | train loss {'Reaction outcome loss': 0.1035391897636696, 'Total loss': 0.1035391897636696}
2022-12-31 07:25:23,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:23,682 INFO:     Epoch: 88
2022-12-31 07:25:25,297 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40468855649232865, 'Total loss': 0.40468855649232865} | train loss {'Reaction outcome loss': 0.10291428715884135, 'Total loss': 0.10291428715884135}
2022-12-31 07:25:25,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:25,297 INFO:     Epoch: 89
2022-12-31 07:25:26,909 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4211063772439957, 'Total loss': 0.4211063772439957} | train loss {'Reaction outcome loss': 0.10092724761942821, 'Total loss': 0.10092724761942821}
2022-12-31 07:25:26,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:26,909 INFO:     Epoch: 90
2022-12-31 07:25:28,500 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3827219077075521, 'Total loss': 0.3827219077075521} | train loss {'Reaction outcome loss': 0.10078440473640056, 'Total loss': 0.10078440473640056}
2022-12-31 07:25:28,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:28,500 INFO:     Epoch: 91
2022-12-31 07:25:30,105 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40482222934563955, 'Total loss': 0.40482222934563955} | train loss {'Reaction outcome loss': 0.10649694305177902, 'Total loss': 0.10649694305177902}
2022-12-31 07:25:30,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:30,106 INFO:     Epoch: 92
2022-12-31 07:25:31,713 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40144145091374717, 'Total loss': 0.40144145091374717} | train loss {'Reaction outcome loss': 0.09952699723636312, 'Total loss': 0.09952699723636312}
2022-12-31 07:25:31,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:31,713 INFO:     Epoch: 93
2022-12-31 07:25:33,310 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38535220324993136, 'Total loss': 0.38535220324993136} | train loss {'Reaction outcome loss': 0.09420766803647333, 'Total loss': 0.09420766803647333}
2022-12-31 07:25:33,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:33,310 INFO:     Epoch: 94
2022-12-31 07:25:34,902 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.398170301814874, 'Total loss': 0.398170301814874} | train loss {'Reaction outcome loss': 0.09848735504010452, 'Total loss': 0.09848735504010452}
2022-12-31 07:25:34,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:34,902 INFO:     Epoch: 95
2022-12-31 07:25:36,497 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39087263196706773, 'Total loss': 0.39087263196706773} | train loss {'Reaction outcome loss': 0.09907602133122839, 'Total loss': 0.09907602133122839}
2022-12-31 07:25:36,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:36,498 INFO:     Epoch: 96
2022-12-31 07:25:38,093 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4091196115594357, 'Total loss': 0.4091196115594357} | train loss {'Reaction outcome loss': 0.10557473528910277, 'Total loss': 0.10557473528910277}
2022-12-31 07:25:38,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:38,094 INFO:     Epoch: 97
2022-12-31 07:25:39,681 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4151005993286769, 'Total loss': 0.4151005993286769} | train loss {'Reaction outcome loss': 0.1045741436614679, 'Total loss': 0.1045741436614679}
2022-12-31 07:25:39,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:39,681 INFO:     Epoch: 98
2022-12-31 07:25:41,276 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43968362162510555, 'Total loss': 0.43968362162510555} | train loss {'Reaction outcome loss': 0.10426765694832807, 'Total loss': 0.10426765694832807}
2022-12-31 07:25:41,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:41,276 INFO:     Epoch: 99
2022-12-31 07:25:42,872 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41545160512129464, 'Total loss': 0.41545160512129464} | train loss {'Reaction outcome loss': 0.09801253264879883, 'Total loss': 0.09801253264879883}
2022-12-31 07:25:42,872 INFO:     Best model found after epoch 15 of 100.
2022-12-31 07:25:42,872 INFO:   Done with stage: TRAINING
2022-12-31 07:25:42,872 INFO:   Starting stage: EVALUATION
2022-12-31 07:25:43,022 INFO:   Done with stage: EVALUATION
2022-12-31 07:25:43,022 INFO:   Leaving out SEQ value Fold_4
2022-12-31 07:25:43,035 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:25:43,035 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:25:43,685 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:25:43,685 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:25:43,753 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:25:43,753 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:25:43,754 INFO:     No hyperparam tuning for this model
2022-12-31 07:25:43,754 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:25:43,754 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:25:43,754 INFO:     None feature selector for col prot
2022-12-31 07:25:43,755 INFO:     None feature selector for col prot
2022-12-31 07:25:43,755 INFO:     None feature selector for col prot
2022-12-31 07:25:43,755 INFO:     None feature selector for col chem
2022-12-31 07:25:43,755 INFO:     None feature selector for col chem
2022-12-31 07:25:43,755 INFO:     None feature selector for col chem
2022-12-31 07:25:43,755 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:25:43,755 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:25:43,757 INFO:     Number of params in model 224011
2022-12-31 07:25:43,761 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:25:43,761 INFO:   Starting stage: TRAINING
2022-12-31 07:25:43,805 INFO:     Val loss before train {'Reaction outcome loss': 1.0956944664319357, 'Total loss': 1.0956944664319357}
2022-12-31 07:25:43,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:43,805 INFO:     Epoch: 0
2022-12-31 07:25:45,427 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5430155913035075, 'Total loss': 0.5430155913035075} | train loss {'Reaction outcome loss': 0.7880037129811093, 'Total loss': 0.7880037129811093}
2022-12-31 07:25:45,427 INFO:     Found new best model at epoch 0
2022-12-31 07:25:45,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:45,428 INFO:     Epoch: 1
2022-12-31 07:25:47,047 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4553883771101634, 'Total loss': 0.4553883771101634} | train loss {'Reaction outcome loss': 0.5141050447558012, 'Total loss': 0.5141050447558012}
2022-12-31 07:25:47,048 INFO:     Found new best model at epoch 1
2022-12-31 07:25:47,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:47,049 INFO:     Epoch: 2
2022-12-31 07:25:48,665 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4338111619154612, 'Total loss': 0.4338111619154612} | train loss {'Reaction outcome loss': 0.4442304903211113, 'Total loss': 0.4442304903211113}
2022-12-31 07:25:48,665 INFO:     Found new best model at epoch 2
2022-12-31 07:25:48,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:48,666 INFO:     Epoch: 3
2022-12-31 07:25:50,285 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4222964117924372, 'Total loss': 0.4222964117924372} | train loss {'Reaction outcome loss': 0.39812551140358415, 'Total loss': 0.39812551140358415}
2022-12-31 07:25:50,285 INFO:     Found new best model at epoch 3
2022-12-31 07:25:50,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:50,286 INFO:     Epoch: 4
2022-12-31 07:25:51,907 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39574295083681743, 'Total loss': 0.39574295083681743} | train loss {'Reaction outcome loss': 0.37764735287730244, 'Total loss': 0.37764735287730244}
2022-12-31 07:25:51,908 INFO:     Found new best model at epoch 4
2022-12-31 07:25:51,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:51,909 INFO:     Epoch: 5
2022-12-31 07:25:53,533 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41471000015735626, 'Total loss': 0.41471000015735626} | train loss {'Reaction outcome loss': 0.36141762295122043, 'Total loss': 0.36141762295122043}
2022-12-31 07:25:53,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:53,534 INFO:     Epoch: 6
2022-12-31 07:25:55,160 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3811820109685262, 'Total loss': 0.3811820109685262} | train loss {'Reaction outcome loss': 0.3375507923167037, 'Total loss': 0.3375507923167037}
2022-12-31 07:25:55,161 INFO:     Found new best model at epoch 6
2022-12-31 07:25:55,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:55,162 INFO:     Epoch: 7
2022-12-31 07:25:56,778 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38226829866568246, 'Total loss': 0.38226829866568246} | train loss {'Reaction outcome loss': 0.31863950012036407, 'Total loss': 0.31863950012036407}
2022-12-31 07:25:56,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:56,778 INFO:     Epoch: 8
2022-12-31 07:25:58,443 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3654144451022148, 'Total loss': 0.3654144451022148} | train loss {'Reaction outcome loss': 0.30526376028369734, 'Total loss': 0.30526376028369734}
2022-12-31 07:25:58,443 INFO:     Found new best model at epoch 8
2022-12-31 07:25:58,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:25:58,444 INFO:     Epoch: 9
2022-12-31 07:26:00,072 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39023047536611555, 'Total loss': 0.39023047536611555} | train loss {'Reaction outcome loss': 0.2898054090902155, 'Total loss': 0.2898054090902155}
2022-12-31 07:26:00,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:00,073 INFO:     Epoch: 10
2022-12-31 07:26:01,705 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39149913589159646, 'Total loss': 0.39149913589159646} | train loss {'Reaction outcome loss': 0.2785934132109521, 'Total loss': 0.2785934132109521}
2022-12-31 07:26:01,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:01,705 INFO:     Epoch: 11
2022-12-31 07:26:03,327 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36106916069984435, 'Total loss': 0.36106916069984435} | train loss {'Reaction outcome loss': 0.2652265716481623, 'Total loss': 0.2652265716481623}
2022-12-31 07:26:03,327 INFO:     Found new best model at epoch 11
2022-12-31 07:26:03,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:03,328 INFO:     Epoch: 12
2022-12-31 07:26:04,951 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3874497224887212, 'Total loss': 0.3874497224887212} | train loss {'Reaction outcome loss': 0.2719705581692034, 'Total loss': 0.2719705581692034}
2022-12-31 07:26:04,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:04,952 INFO:     Epoch: 13
2022-12-31 07:26:06,575 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35633717974026996, 'Total loss': 0.35633717974026996} | train loss {'Reaction outcome loss': 0.26652649249487126, 'Total loss': 0.26652649249487126}
2022-12-31 07:26:06,575 INFO:     Found new best model at epoch 13
2022-12-31 07:26:06,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:06,576 INFO:     Epoch: 14
2022-12-31 07:26:08,206 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3596236828714609, 'Total loss': 0.3596236828714609} | train loss {'Reaction outcome loss': 0.2432375557474333, 'Total loss': 0.2432375557474333}
2022-12-31 07:26:08,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:08,206 INFO:     Epoch: 15
2022-12-31 07:26:09,837 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3592305024464925, 'Total loss': 0.3592305024464925} | train loss {'Reaction outcome loss': 0.22962593533541792, 'Total loss': 0.22962593533541792}
2022-12-31 07:26:09,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:09,838 INFO:     Epoch: 16
2022-12-31 07:26:11,460 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37382942537466685, 'Total loss': 0.37382942537466685} | train loss {'Reaction outcome loss': 0.22390900960907448, 'Total loss': 0.22390900960907448}
2022-12-31 07:26:11,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:11,460 INFO:     Epoch: 17
2022-12-31 07:26:13,092 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4041217237710953, 'Total loss': 0.4041217237710953} | train loss {'Reaction outcome loss': 0.2175814081957746, 'Total loss': 0.2175814081957746}
2022-12-31 07:26:13,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:13,092 INFO:     Epoch: 18
2022-12-31 07:26:14,714 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37176528126001357, 'Total loss': 0.37176528126001357} | train loss {'Reaction outcome loss': 0.21584978260848994, 'Total loss': 0.21584978260848994}
2022-12-31 07:26:14,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:14,714 INFO:     Epoch: 19
2022-12-31 07:26:16,345 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3730729560057322, 'Total loss': 0.3730729560057322} | train loss {'Reaction outcome loss': 0.2067901287883364, 'Total loss': 0.2067901287883364}
2022-12-31 07:26:16,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:16,345 INFO:     Epoch: 20
2022-12-31 07:26:17,975 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40289540539185204, 'Total loss': 0.40289540539185204} | train loss {'Reaction outcome loss': 0.2010629288295446, 'Total loss': 0.2010629288295446}
2022-12-31 07:26:17,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:17,977 INFO:     Epoch: 21
2022-12-31 07:26:19,597 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3845640912652016, 'Total loss': 0.3845640912652016} | train loss {'Reaction outcome loss': 0.19922230957561862, 'Total loss': 0.19922230957561862}
2022-12-31 07:26:19,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:19,597 INFO:     Epoch: 22
2022-12-31 07:26:21,226 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36455807586510974, 'Total loss': 0.36455807586510974} | train loss {'Reaction outcome loss': 0.2036690144340737, 'Total loss': 0.2036690144340737}
2022-12-31 07:26:21,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:21,226 INFO:     Epoch: 23
2022-12-31 07:26:22,855 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40042230586210886, 'Total loss': 0.40042230586210886} | train loss {'Reaction outcome loss': 0.2212032536112204, 'Total loss': 0.2212032536112204}
2022-12-31 07:26:22,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:22,855 INFO:     Epoch: 24
2022-12-31 07:26:24,492 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3744059483210246, 'Total loss': 0.3744059483210246} | train loss {'Reaction outcome loss': 0.18603427904199107, 'Total loss': 0.18603427904199107}
2022-12-31 07:26:24,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:24,493 INFO:     Epoch: 25
2022-12-31 07:26:26,111 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3922371496756872, 'Total loss': 0.3922371496756872} | train loss {'Reaction outcome loss': 0.18238698549406684, 'Total loss': 0.18238698549406684}
2022-12-31 07:26:26,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:26,111 INFO:     Epoch: 26
2022-12-31 07:26:27,775 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36334483822186786, 'Total loss': 0.36334483822186786} | train loss {'Reaction outcome loss': 0.1820131045314011, 'Total loss': 0.1820131045314011}
2022-12-31 07:26:27,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:27,775 INFO:     Epoch: 27
2022-12-31 07:26:29,401 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3689819643894831, 'Total loss': 0.3689819643894831} | train loss {'Reaction outcome loss': 0.1832155465836758, 'Total loss': 0.1832155465836758}
2022-12-31 07:26:29,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:29,401 INFO:     Epoch: 28
2022-12-31 07:26:31,031 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37803238481283186, 'Total loss': 0.37803238481283186} | train loss {'Reaction outcome loss': 0.17647829275307048, 'Total loss': 0.17647829275307048}
2022-12-31 07:26:31,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:31,031 INFO:     Epoch: 29
2022-12-31 07:26:32,655 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35877199470996857, 'Total loss': 0.35877199470996857} | train loss {'Reaction outcome loss': 0.16912832207626838, 'Total loss': 0.16912832207626838}
2022-12-31 07:26:32,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:32,656 INFO:     Epoch: 30
2022-12-31 07:26:34,270 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38911510556936263, 'Total loss': 0.38911510556936263} | train loss {'Reaction outcome loss': 0.16790349669020582, 'Total loss': 0.16790349669020582}
2022-12-31 07:26:34,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:34,270 INFO:     Epoch: 31
2022-12-31 07:26:35,931 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3638661528627078, 'Total loss': 0.3638661528627078} | train loss {'Reaction outcome loss': 0.1676475510378267, 'Total loss': 0.1676475510378267}
2022-12-31 07:26:35,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:35,931 INFO:     Epoch: 32
2022-12-31 07:26:37,553 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39514168600241345, 'Total loss': 0.39514168600241345} | train loss {'Reaction outcome loss': 0.16362442344805037, 'Total loss': 0.16362442344805037}
2022-12-31 07:26:37,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:37,554 INFO:     Epoch: 33
2022-12-31 07:26:39,231 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3565061390399933, 'Total loss': 0.3565061390399933} | train loss {'Reaction outcome loss': 0.16216635944853636, 'Total loss': 0.16216635944853636}
2022-12-31 07:26:39,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:39,232 INFO:     Epoch: 34
2022-12-31 07:26:40,906 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.391291880607605, 'Total loss': 0.391291880607605} | train loss {'Reaction outcome loss': 0.15886706359721586, 'Total loss': 0.15886706359721586}
2022-12-31 07:26:40,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:40,906 INFO:     Epoch: 35
2022-12-31 07:26:42,568 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3595935543378194, 'Total loss': 0.3595935543378194} | train loss {'Reaction outcome loss': 0.15799009007890202, 'Total loss': 0.15799009007890202}
2022-12-31 07:26:42,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:42,568 INFO:     Epoch: 36
2022-12-31 07:26:44,185 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39217091103394824, 'Total loss': 0.39217091103394824} | train loss {'Reaction outcome loss': 0.15634669617587782, 'Total loss': 0.15634669617587782}
2022-12-31 07:26:44,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:44,185 INFO:     Epoch: 37
2022-12-31 07:26:45,801 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36810933152834574, 'Total loss': 0.36810933152834574} | train loss {'Reaction outcome loss': 0.16533842621214243, 'Total loss': 0.16533842621214243}
2022-12-31 07:26:45,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:45,801 INFO:     Epoch: 38
2022-12-31 07:26:47,413 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3661425277590752, 'Total loss': 0.3661425277590752} | train loss {'Reaction outcome loss': 0.15067751421441283, 'Total loss': 0.15067751421441283}
2022-12-31 07:26:47,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:47,413 INFO:     Epoch: 39
2022-12-31 07:26:49,078 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3724561711152395, 'Total loss': 0.3724561711152395} | train loss {'Reaction outcome loss': 0.14813843311951158, 'Total loss': 0.14813843311951158}
2022-12-31 07:26:49,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:49,078 INFO:     Epoch: 40
2022-12-31 07:26:50,694 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3746772746245066, 'Total loss': 0.3746772746245066} | train loss {'Reaction outcome loss': 0.14622165954273625, 'Total loss': 0.14622165954273625}
2022-12-31 07:26:50,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:50,694 INFO:     Epoch: 41
2022-12-31 07:26:52,313 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.364896809309721, 'Total loss': 0.364896809309721} | train loss {'Reaction outcome loss': 0.14380286128489653, 'Total loss': 0.14380286128489653}
2022-12-31 07:26:52,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:52,313 INFO:     Epoch: 42
2022-12-31 07:26:53,980 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38149049977461497, 'Total loss': 0.38149049977461497} | train loss {'Reaction outcome loss': 0.14900201640135702, 'Total loss': 0.14900201640135702}
2022-12-31 07:26:53,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:53,981 INFO:     Epoch: 43
2022-12-31 07:26:55,593 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3746188163757324, 'Total loss': 0.3746188163757324} | train loss {'Reaction outcome loss': 0.14071832065536766, 'Total loss': 0.14071832065536766}
2022-12-31 07:26:55,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:55,593 INFO:     Epoch: 44
2022-12-31 07:26:57,218 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3675855944554011, 'Total loss': 0.3675855944554011} | train loss {'Reaction outcome loss': 0.1419273737402113, 'Total loss': 0.1419273737402113}
2022-12-31 07:26:57,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:57,219 INFO:     Epoch: 45
2022-12-31 07:26:58,850 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38667499522368115, 'Total loss': 0.38667499522368115} | train loss {'Reaction outcome loss': 0.14617810165172146, 'Total loss': 0.14617810165172146}
2022-12-31 07:26:58,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:26:58,850 INFO:     Epoch: 46
2022-12-31 07:27:00,473 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3835725856324037, 'Total loss': 0.3835725856324037} | train loss {'Reaction outcome loss': 0.16853296169437523, 'Total loss': 0.16853296169437523}
2022-12-31 07:27:00,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:00,474 INFO:     Epoch: 47
2022-12-31 07:27:02,100 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36363450487454735, 'Total loss': 0.36363450487454735} | train loss {'Reaction outcome loss': 0.13888026169413512, 'Total loss': 0.13888026169413512}
2022-12-31 07:27:02,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:02,100 INFO:     Epoch: 48
2022-12-31 07:27:03,725 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38542643586794534, 'Total loss': 0.38542643586794534} | train loss {'Reaction outcome loss': 0.13504113712300803, 'Total loss': 0.13504113712300803}
2022-12-31 07:27:03,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:03,726 INFO:     Epoch: 49
2022-12-31 07:27:05,350 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3962383004526297, 'Total loss': 0.3962383004526297} | train loss {'Reaction outcome loss': 0.13716035579547178, 'Total loss': 0.13716035579547178}
2022-12-31 07:27:05,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:05,350 INFO:     Epoch: 50
2022-12-31 07:27:06,984 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3688517918189367, 'Total loss': 0.3688517918189367} | train loss {'Reaction outcome loss': 0.13212436192965918, 'Total loss': 0.13212436192965918}
2022-12-31 07:27:06,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:06,984 INFO:     Epoch: 51
2022-12-31 07:27:08,617 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3948757529258728, 'Total loss': 0.3948757529258728} | train loss {'Reaction outcome loss': 0.13176634722048472, 'Total loss': 0.13176634722048472}
2022-12-31 07:27:08,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:08,617 INFO:     Epoch: 52
2022-12-31 07:27:10,260 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36874677886565527, 'Total loss': 0.36874677886565527} | train loss {'Reaction outcome loss': 0.13171495334871366, 'Total loss': 0.13171495334871366}
2022-12-31 07:27:10,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:10,260 INFO:     Epoch: 53
2022-12-31 07:27:11,874 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39349042922258376, 'Total loss': 0.39349042922258376} | train loss {'Reaction outcome loss': 0.12862364180277244, 'Total loss': 0.12862364180277244}
2022-12-31 07:27:11,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:11,874 INFO:     Epoch: 54
2022-12-31 07:27:13,488 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3894155740737915, 'Total loss': 0.3894155740737915} | train loss {'Reaction outcome loss': 0.13022511441492193, 'Total loss': 0.13022511441492193}
2022-12-31 07:27:13,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:13,488 INFO:     Epoch: 55
2022-12-31 07:27:15,099 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38117739583055177, 'Total loss': 0.38117739583055177} | train loss {'Reaction outcome loss': 0.12878920877633587, 'Total loss': 0.12878920877633587}
2022-12-31 07:27:15,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:15,099 INFO:     Epoch: 56
2022-12-31 07:27:16,716 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3936455031236013, 'Total loss': 0.3936455031236013} | train loss {'Reaction outcome loss': 0.12572091022625304, 'Total loss': 0.12572091022625304}
2022-12-31 07:27:16,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:16,716 INFO:     Epoch: 57
2022-12-31 07:27:18,334 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36536922405163447, 'Total loss': 0.36536922405163447} | train loss {'Reaction outcome loss': 0.12594666013678035, 'Total loss': 0.12594666013678035}
2022-12-31 07:27:18,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:18,334 INFO:     Epoch: 58
2022-12-31 07:27:19,949 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4298334240913391, 'Total loss': 0.4298334240913391} | train loss {'Reaction outcome loss': 0.1276189344319299, 'Total loss': 0.1276189344319299}
2022-12-31 07:27:19,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:19,949 INFO:     Epoch: 59
2022-12-31 07:27:21,611 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3768864485590408, 'Total loss': 0.3768864485590408} | train loss {'Reaction outcome loss': 0.1286999657601447, 'Total loss': 0.1286999657601447}
2022-12-31 07:27:21,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:21,612 INFO:     Epoch: 60
2022-12-31 07:27:23,234 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3962958296140035, 'Total loss': 0.3962958296140035} | train loss {'Reaction outcome loss': 0.12180182090715802, 'Total loss': 0.12180182090715802}
2022-12-31 07:27:23,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:23,235 INFO:     Epoch: 61
2022-12-31 07:27:24,897 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39941398104031883, 'Total loss': 0.39941398104031883} | train loss {'Reaction outcome loss': 0.12610180474576485, 'Total loss': 0.12610180474576485}
2022-12-31 07:27:24,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:24,898 INFO:     Epoch: 62
2022-12-31 07:27:26,561 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4142557164033254, 'Total loss': 0.4142557164033254} | train loss {'Reaction outcome loss': 0.1278423798739559, 'Total loss': 0.1278423798739559}
2022-12-31 07:27:26,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:26,562 INFO:     Epoch: 63
2022-12-31 07:27:28,192 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3841355122625828, 'Total loss': 0.3841355122625828} | train loss {'Reaction outcome loss': 0.13047164884781431, 'Total loss': 0.13047164884781431}
2022-12-31 07:27:28,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:28,192 INFO:     Epoch: 64
2022-12-31 07:27:29,854 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.429074568549792, 'Total loss': 0.429074568549792} | train loss {'Reaction outcome loss': 0.12590085231678802, 'Total loss': 0.12590085231678802}
2022-12-31 07:27:29,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:29,856 INFO:     Epoch: 65
2022-12-31 07:27:31,473 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3637902354200681, 'Total loss': 0.3637902354200681} | train loss {'Reaction outcome loss': 0.12259444248785797, 'Total loss': 0.12259444248785797}
2022-12-31 07:27:31,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:31,474 INFO:     Epoch: 66
2022-12-31 07:27:33,103 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3936329702536265, 'Total loss': 0.3936329702536265} | train loss {'Reaction outcome loss': 0.12286046786112306, 'Total loss': 0.12286046786112306}
2022-12-31 07:27:33,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:33,104 INFO:     Epoch: 67
2022-12-31 07:27:34,733 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37663252303997674, 'Total loss': 0.37663252303997674} | train loss {'Reaction outcome loss': 0.12196643032186093, 'Total loss': 0.12196643032186093}
2022-12-31 07:27:34,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:34,733 INFO:     Epoch: 68
2022-12-31 07:27:36,363 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3867924526333809, 'Total loss': 0.3867924526333809} | train loss {'Reaction outcome loss': 0.12754401195612128, 'Total loss': 0.12754401195612128}
2022-12-31 07:27:36,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:36,364 INFO:     Epoch: 69
2022-12-31 07:27:37,984 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.399800385038058, 'Total loss': 0.399800385038058} | train loss {'Reaction outcome loss': 0.13423032067763363, 'Total loss': 0.13423032067763363}
2022-12-31 07:27:37,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:37,985 INFO:     Epoch: 70
2022-12-31 07:27:39,614 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3980568657318751, 'Total loss': 0.3980568657318751} | train loss {'Reaction outcome loss': 0.121162868399815, 'Total loss': 0.121162868399815}
2022-12-31 07:27:39,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:39,615 INFO:     Epoch: 71
2022-12-31 07:27:41,237 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39007636656363803, 'Total loss': 0.39007636656363803} | train loss {'Reaction outcome loss': 0.1164028977273383, 'Total loss': 0.1164028977273383}
2022-12-31 07:27:41,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:41,237 INFO:     Epoch: 72
2022-12-31 07:27:42,855 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41231027046839397, 'Total loss': 0.41231027046839397} | train loss {'Reaction outcome loss': 0.11802793498339968, 'Total loss': 0.11802793498339968}
2022-12-31 07:27:42,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:42,855 INFO:     Epoch: 73
2022-12-31 07:27:44,472 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40803129474322003, 'Total loss': 0.40803129474322003} | train loss {'Reaction outcome loss': 0.11814284763987297, 'Total loss': 0.11814284763987297}
2022-12-31 07:27:44,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:44,472 INFO:     Epoch: 74
2022-12-31 07:27:46,094 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41936604579289755, 'Total loss': 0.41936604579289755} | train loss {'Reaction outcome loss': 0.11880138174097553, 'Total loss': 0.11880138174097553}
2022-12-31 07:27:46,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:46,094 INFO:     Epoch: 75
2022-12-31 07:27:47,759 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40058131019274396, 'Total loss': 0.40058131019274396} | train loss {'Reaction outcome loss': 0.13570373182427947, 'Total loss': 0.13570373182427947}
2022-12-31 07:27:47,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:47,759 INFO:     Epoch: 76
2022-12-31 07:27:49,377 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4119761327902476, 'Total loss': 0.4119761327902476} | train loss {'Reaction outcome loss': 0.1172102388425602, 'Total loss': 0.1172102388425602}
2022-12-31 07:27:49,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:49,378 INFO:     Epoch: 77
2022-12-31 07:27:50,987 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44746918181578316, 'Total loss': 0.44746918181578316} | train loss {'Reaction outcome loss': 0.11508280893669007, 'Total loss': 0.11508280893669007}
2022-12-31 07:27:50,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:50,988 INFO:     Epoch: 78
2022-12-31 07:27:52,605 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3738054980834325, 'Total loss': 0.3738054980834325} | train loss {'Reaction outcome loss': 0.1182651422802592, 'Total loss': 0.1182651422802592}
2022-12-31 07:27:52,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:52,605 INFO:     Epoch: 79
2022-12-31 07:27:54,272 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39930847187836965, 'Total loss': 0.39930847187836965} | train loss {'Reaction outcome loss': 0.11377618272888577, 'Total loss': 0.11377618272888577}
2022-12-31 07:27:54,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:54,272 INFO:     Epoch: 80
2022-12-31 07:27:55,891 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3997490108013153, 'Total loss': 0.3997490108013153} | train loss {'Reaction outcome loss': 0.11397255608724241, 'Total loss': 0.11397255608724241}
2022-12-31 07:27:55,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:55,892 INFO:     Epoch: 81
2022-12-31 07:27:57,510 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4056956301132838, 'Total loss': 0.4056956301132838} | train loss {'Reaction outcome loss': 0.11713350781070218, 'Total loss': 0.11713350781070218}
2022-12-31 07:27:57,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:57,510 INFO:     Epoch: 82
2022-12-31 07:27:59,129 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3656644771496455, 'Total loss': 0.3656644771496455} | train loss {'Reaction outcome loss': 0.11922454790586978, 'Total loss': 0.11922454790586978}
2022-12-31 07:27:59,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:27:59,129 INFO:     Epoch: 83
2022-12-31 07:28:00,742 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3910037726163864, 'Total loss': 0.3910037726163864} | train loss {'Reaction outcome loss': 0.11394147215131839, 'Total loss': 0.11394147215131839}
2022-12-31 07:28:00,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:00,742 INFO:     Epoch: 84
2022-12-31 07:28:02,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3887202486395836, 'Total loss': 0.3887202486395836} | train loss {'Reaction outcome loss': 0.11349062846789636, 'Total loss': 0.11349062846789636}
2022-12-31 07:28:02,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:02,365 INFO:     Epoch: 85
2022-12-31 07:28:03,989 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38469203213850656, 'Total loss': 0.38469203213850656} | train loss {'Reaction outcome loss': 0.1158215089927198, 'Total loss': 0.1158215089927198}
2022-12-31 07:28:03,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:03,989 INFO:     Epoch: 86
2022-12-31 07:28:05,657 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39401001830895743, 'Total loss': 0.39401001830895743} | train loss {'Reaction outcome loss': 0.1137712543258322, 'Total loss': 0.1137712543258322}
2022-12-31 07:28:05,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:05,659 INFO:     Epoch: 87
2022-12-31 07:28:07,282 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4064263996978601, 'Total loss': 0.4064263996978601} | train loss {'Reaction outcome loss': 0.10755941541055622, 'Total loss': 0.10755941541055622}
2022-12-31 07:28:07,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:07,283 INFO:     Epoch: 88
2022-12-31 07:28:08,918 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46182568470637003, 'Total loss': 0.46182568470637003} | train loss {'Reaction outcome loss': 0.10996632905258541, 'Total loss': 0.10996632905258541}
2022-12-31 07:28:08,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:08,918 INFO:     Epoch: 89
2022-12-31 07:28:10,575 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4028782327969869, 'Total loss': 0.4028782327969869} | train loss {'Reaction outcome loss': 0.11278111483029468, 'Total loss': 0.11278111483029468}
2022-12-31 07:28:10,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:10,575 INFO:     Epoch: 90
2022-12-31 07:28:12,207 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4104806294043859, 'Total loss': 0.4104806294043859} | train loss {'Reaction outcome loss': 0.11238921235528086, 'Total loss': 0.11238921235528086}
2022-12-31 07:28:12,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:12,208 INFO:     Epoch: 91
2022-12-31 07:28:13,832 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3662005508939425, 'Total loss': 0.3662005508939425} | train loss {'Reaction outcome loss': 0.10775944877557618, 'Total loss': 0.10775944877557618}
2022-12-31 07:28:13,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:13,832 INFO:     Epoch: 92
2022-12-31 07:28:15,465 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39437426378329593, 'Total loss': 0.39437426378329593} | train loss {'Reaction outcome loss': 0.11168397026114585, 'Total loss': 0.11168397026114585}
2022-12-31 07:28:15,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:15,466 INFO:     Epoch: 93
2022-12-31 07:28:17,099 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.374735659857591, 'Total loss': 0.374735659857591} | train loss {'Reaction outcome loss': 0.11274511666250993, 'Total loss': 0.11274511666250993}
2022-12-31 07:28:17,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:17,099 INFO:     Epoch: 94
2022-12-31 07:28:18,722 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3884016911188761, 'Total loss': 0.3884016911188761} | train loss {'Reaction outcome loss': 0.11085560887485095, 'Total loss': 0.11085560887485095}
2022-12-31 07:28:18,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:18,723 INFO:     Epoch: 95
2022-12-31 07:28:20,356 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38794633944829304, 'Total loss': 0.38794633944829304} | train loss {'Reaction outcome loss': 0.10616817705812391, 'Total loss': 0.10616817705812391}
2022-12-31 07:28:20,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:20,356 INFO:     Epoch: 96
2022-12-31 07:28:21,990 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3682977298895518, 'Total loss': 0.3682977298895518} | train loss {'Reaction outcome loss': 0.107451464483123, 'Total loss': 0.107451464483123}
2022-12-31 07:28:21,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:21,990 INFO:     Epoch: 97
2022-12-31 07:28:23,641 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4023640702944249, 'Total loss': 0.4023640702944249} | train loss {'Reaction outcome loss': 0.12751791780254385, 'Total loss': 0.12751791780254385}
2022-12-31 07:28:23,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:23,641 INFO:     Epoch: 98
2022-12-31 07:28:25,305 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39809778332710266, 'Total loss': 0.39809778332710266} | train loss {'Reaction outcome loss': 0.1147608729450545, 'Total loss': 0.1147608729450545}
2022-12-31 07:28:25,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:25,306 INFO:     Epoch: 99
2022-12-31 07:28:26,914 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4044250133136908, 'Total loss': 0.4044250133136908} | train loss {'Reaction outcome loss': 0.11150325283887323, 'Total loss': 0.11150325283887323}
2022-12-31 07:28:26,914 INFO:     Best model found after epoch 14 of 100.
2022-12-31 07:28:26,915 INFO:   Done with stage: TRAINING
2022-12-31 07:28:26,915 INFO:   Starting stage: EVALUATION
2022-12-31 07:28:27,045 INFO:   Done with stage: EVALUATION
2022-12-31 07:28:27,046 INFO:   Leaving out SEQ value Fold_5
2022-12-31 07:28:27,058 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:28:27,058 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:28:27,695 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:28:27,695 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:28:27,762 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:28:27,763 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:28:27,763 INFO:     No hyperparam tuning for this model
2022-12-31 07:28:27,763 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:28:27,763 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:28:27,763 INFO:     None feature selector for col prot
2022-12-31 07:28:27,764 INFO:     None feature selector for col prot
2022-12-31 07:28:27,764 INFO:     None feature selector for col prot
2022-12-31 07:28:27,764 INFO:     None feature selector for col chem
2022-12-31 07:28:27,764 INFO:     None feature selector for col chem
2022-12-31 07:28:27,764 INFO:     None feature selector for col chem
2022-12-31 07:28:27,764 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:28:27,765 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:28:27,766 INFO:     Number of params in model 224011
2022-12-31 07:28:27,770 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:28:27,770 INFO:   Starting stage: TRAINING
2022-12-31 07:28:27,813 INFO:     Val loss before train {'Reaction outcome loss': 1.0586798310279846, 'Total loss': 1.0586798310279846}
2022-12-31 07:28:27,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:27,813 INFO:     Epoch: 0
2022-12-31 07:28:29,423 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5980389257272084, 'Total loss': 0.5980389257272084} | train loss {'Reaction outcome loss': 0.7606669638400384, 'Total loss': 0.7606669638400384}
2022-12-31 07:28:29,423 INFO:     Found new best model at epoch 0
2022-12-31 07:28:29,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:29,424 INFO:     Epoch: 1
2022-12-31 07:28:31,043 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5299570182959239, 'Total loss': 0.5299570182959239} | train loss {'Reaction outcome loss': 0.5063560833965522, 'Total loss': 0.5063560833965522}
2022-12-31 07:28:31,043 INFO:     Found new best model at epoch 1
2022-12-31 07:28:31,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:31,044 INFO:     Epoch: 2
2022-12-31 07:28:32,662 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5037639876206715, 'Total loss': 0.5037639876206715} | train loss {'Reaction outcome loss': 0.4440929329029514, 'Total loss': 0.4440929329029514}
2022-12-31 07:28:32,662 INFO:     Found new best model at epoch 2
2022-12-31 07:28:32,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:32,663 INFO:     Epoch: 3
2022-12-31 07:28:34,276 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5041521469751994, 'Total loss': 0.5041521469751994} | train loss {'Reaction outcome loss': 0.40556209493914375, 'Total loss': 0.40556209493914375}
2022-12-31 07:28:34,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:34,276 INFO:     Epoch: 4
2022-12-31 07:28:35,886 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.495313815275828, 'Total loss': 0.495313815275828} | train loss {'Reaction outcome loss': 0.37816660341037356, 'Total loss': 0.37816660341037356}
2022-12-31 07:28:35,886 INFO:     Found new best model at epoch 4
2022-12-31 07:28:35,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:35,887 INFO:     Epoch: 5
2022-12-31 07:28:37,501 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.511658267180125, 'Total loss': 0.511658267180125} | train loss {'Reaction outcome loss': 0.3625791494122087, 'Total loss': 0.3625791494122087}
2022-12-31 07:28:37,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:37,501 INFO:     Epoch: 6
2022-12-31 07:28:39,116 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5051634738842646, 'Total loss': 0.5051634738842646} | train loss {'Reaction outcome loss': 0.3319417061199825, 'Total loss': 0.3319417061199825}
2022-12-31 07:28:39,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:39,116 INFO:     Epoch: 7
2022-12-31 07:28:40,728 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4857837031284968, 'Total loss': 0.4857837031284968} | train loss {'Reaction outcome loss': 0.3160763939005741, 'Total loss': 0.3160763939005741}
2022-12-31 07:28:40,729 INFO:     Found new best model at epoch 7
2022-12-31 07:28:40,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:40,730 INFO:     Epoch: 8
2022-12-31 07:28:42,355 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.553521986802419, 'Total loss': 0.553521986802419} | train loss {'Reaction outcome loss': 0.31148544383113796, 'Total loss': 0.31148544383113796}
2022-12-31 07:28:42,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:42,355 INFO:     Epoch: 9
2022-12-31 07:28:43,982 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5190145969390869, 'Total loss': 0.5190145969390869} | train loss {'Reaction outcome loss': 0.31789054116782517, 'Total loss': 0.31789054116782517}
2022-12-31 07:28:43,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:43,983 INFO:     Epoch: 10
2022-12-31 07:28:45,609 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5252534369627635, 'Total loss': 0.5252534369627635} | train loss {'Reaction outcome loss': 0.27871080421829136, 'Total loss': 0.27871080421829136}
2022-12-31 07:28:45,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:45,610 INFO:     Epoch: 11
2022-12-31 07:28:47,259 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4986610064903895, 'Total loss': 0.4986610064903895} | train loss {'Reaction outcome loss': 0.26920275738044386, 'Total loss': 0.26920275738044386}
2022-12-31 07:28:47,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:47,260 INFO:     Epoch: 12
2022-12-31 07:28:48,873 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4950419326623281, 'Total loss': 0.4950419326623281} | train loss {'Reaction outcome loss': 0.26126001055176923, 'Total loss': 0.26126001055176923}
2022-12-31 07:28:48,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:48,873 INFO:     Epoch: 13
2022-12-31 07:28:50,482 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5104308605194092, 'Total loss': 0.5104308605194092} | train loss {'Reaction outcome loss': 0.2647544549157222, 'Total loss': 0.2647544549157222}
2022-12-31 07:28:50,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:50,482 INFO:     Epoch: 14
2022-12-31 07:28:52,144 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4825633972883224, 'Total loss': 0.4825633972883224} | train loss {'Reaction outcome loss': 0.281896547211901, 'Total loss': 0.281896547211901}
2022-12-31 07:28:52,144 INFO:     Found new best model at epoch 14
2022-12-31 07:28:52,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:52,145 INFO:     Epoch: 15
2022-12-31 07:28:53,763 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47856318950653076, 'Total loss': 0.47856318950653076} | train loss {'Reaction outcome loss': 0.2502877006604188, 'Total loss': 0.2502877006604188}
2022-12-31 07:28:53,763 INFO:     Found new best model at epoch 15
2022-12-31 07:28:53,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:53,764 INFO:     Epoch: 16
2022-12-31 07:28:55,377 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5044731875260671, 'Total loss': 0.5044731875260671} | train loss {'Reaction outcome loss': 0.23496361263771204, 'Total loss': 0.23496361263771204}
2022-12-31 07:28:55,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:55,377 INFO:     Epoch: 17
2022-12-31 07:28:57,038 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.533982229232788, 'Total loss': 0.533982229232788} | train loss {'Reaction outcome loss': 0.2306953388911822, 'Total loss': 0.2306953388911822}
2022-12-31 07:28:57,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:57,039 INFO:     Epoch: 18
2022-12-31 07:28:58,680 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.537484222650528, 'Total loss': 0.537484222650528} | train loss {'Reaction outcome loss': 0.21742437685927565, 'Total loss': 0.21742437685927565}
2022-12-31 07:28:58,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:28:58,680 INFO:     Epoch: 19
2022-12-31 07:29:00,341 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4955988715092341, 'Total loss': 0.4955988715092341} | train loss {'Reaction outcome loss': 0.2130709885006476, 'Total loss': 0.2130709885006476}
2022-12-31 07:29:00,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:00,342 INFO:     Epoch: 20
2022-12-31 07:29:01,958 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5070879777272542, 'Total loss': 0.5070879777272542} | train loss {'Reaction outcome loss': 0.21034923218784557, 'Total loss': 0.21034923218784557}
2022-12-31 07:29:01,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:01,959 INFO:     Epoch: 21
2022-12-31 07:29:03,589 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.526466178894043, 'Total loss': 0.526466178894043} | train loss {'Reaction outcome loss': 0.21788392428214243, 'Total loss': 0.21788392428214243}
2022-12-31 07:29:03,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:03,590 INFO:     Epoch: 22
2022-12-31 07:29:05,212 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.508783397078514, 'Total loss': 0.508783397078514} | train loss {'Reaction outcome loss': 0.23056553378853056, 'Total loss': 0.23056553378853056}
2022-12-31 07:29:05,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:05,213 INFO:     Epoch: 23
2022-12-31 07:29:06,838 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5187393352389336, 'Total loss': 0.5187393352389336} | train loss {'Reaction outcome loss': 0.2031679840088211, 'Total loss': 0.2031679840088211}
2022-12-31 07:29:06,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:06,838 INFO:     Epoch: 24
2022-12-31 07:29:08,456 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5003455877304077, 'Total loss': 0.5003455877304077} | train loss {'Reaction outcome loss': 0.19513896408666304, 'Total loss': 0.19513896408666304}
2022-12-31 07:29:08,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:08,456 INFO:     Epoch: 25
2022-12-31 07:29:10,081 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.488793949286143, 'Total loss': 0.488793949286143} | train loss {'Reaction outcome loss': 0.19045322763386008, 'Total loss': 0.19045322763386008}
2022-12-31 07:29:10,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:10,081 INFO:     Epoch: 26
2022-12-31 07:29:11,702 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5192441980044047, 'Total loss': 0.5192441980044047} | train loss {'Reaction outcome loss': 0.18467045264264595, 'Total loss': 0.18467045264264595}
2022-12-31 07:29:11,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:11,703 INFO:     Epoch: 27
2022-12-31 07:29:13,325 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5170557796955109, 'Total loss': 0.5170557796955109} | train loss {'Reaction outcome loss': 0.18492357512065832, 'Total loss': 0.18492357512065832}
2022-12-31 07:29:13,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:13,325 INFO:     Epoch: 28
2022-12-31 07:29:14,987 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49786332448323567, 'Total loss': 0.49786332448323567} | train loss {'Reaction outcome loss': 0.18337089368614598, 'Total loss': 0.18337089368614598}
2022-12-31 07:29:14,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:14,987 INFO:     Epoch: 29
2022-12-31 07:29:16,604 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5170528451601665, 'Total loss': 0.5170528451601665} | train loss {'Reaction outcome loss': 0.18064317559027046, 'Total loss': 0.18064317559027046}
2022-12-31 07:29:16,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:16,604 INFO:     Epoch: 30
2022-12-31 07:29:18,266 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.520551378528277, 'Total loss': 0.520551378528277} | train loss {'Reaction outcome loss': 0.17350899768264397, 'Total loss': 0.17350899768264397}
2022-12-31 07:29:18,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:18,267 INFO:     Epoch: 31
2022-12-31 07:29:19,885 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5389888485272726, 'Total loss': 0.5389888485272726} | train loss {'Reaction outcome loss': 0.1713554902015713, 'Total loss': 0.1713554902015713}
2022-12-31 07:29:19,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:19,885 INFO:     Epoch: 32
2022-12-31 07:29:21,522 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5261947393417359, 'Total loss': 0.5261947393417359} | train loss {'Reaction outcome loss': 0.17746132363730716, 'Total loss': 0.17746132363730716}
2022-12-31 07:29:21,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:21,522 INFO:     Epoch: 33
2022-12-31 07:29:23,146 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5482816994190216, 'Total loss': 0.5482816994190216} | train loss {'Reaction outcome loss': 0.1662547563918043, 'Total loss': 0.1662547563918043}
2022-12-31 07:29:23,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:23,146 INFO:     Epoch: 34
2022-12-31 07:29:24,768 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49629701326290765, 'Total loss': 0.49629701326290765} | train loss {'Reaction outcome loss': 0.16796587344994635, 'Total loss': 0.16796587344994635}
2022-12-31 07:29:24,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:24,768 INFO:     Epoch: 35
2022-12-31 07:29:26,384 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5537764728069305, 'Total loss': 0.5537764728069305} | train loss {'Reaction outcome loss': 0.16372377438086044, 'Total loss': 0.16372377438086044}
2022-12-31 07:29:26,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:26,384 INFO:     Epoch: 36
2022-12-31 07:29:28,008 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5318277448415756, 'Total loss': 0.5318277448415756} | train loss {'Reaction outcome loss': 0.15998661104587908, 'Total loss': 0.15998661104587908}
2022-12-31 07:29:28,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:28,009 INFO:     Epoch: 37
2022-12-31 07:29:29,632 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5712393919626871, 'Total loss': 0.5712393919626871} | train loss {'Reaction outcome loss': 0.1626525889488234, 'Total loss': 0.1626525889488234}
2022-12-31 07:29:29,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:29,633 INFO:     Epoch: 38
2022-12-31 07:29:31,247 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5495682140191396, 'Total loss': 0.5495682140191396} | train loss {'Reaction outcome loss': 0.1560590279818364, 'Total loss': 0.1560590279818364}
2022-12-31 07:29:31,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:31,248 INFO:     Epoch: 39
2022-12-31 07:29:32,872 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5703879475593567, 'Total loss': 0.5703879475593567} | train loss {'Reaction outcome loss': 0.15415103575551126, 'Total loss': 0.15415103575551126}
2022-12-31 07:29:32,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:32,873 INFO:     Epoch: 40
2022-12-31 07:29:34,495 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5062163650989533, 'Total loss': 0.5062163650989533} | train loss {'Reaction outcome loss': 0.1531235272182064, 'Total loss': 0.1531235272182064}
2022-12-31 07:29:34,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:34,495 INFO:     Epoch: 41
2022-12-31 07:29:36,142 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5485391994317372, 'Total loss': 0.5485391994317372} | train loss {'Reaction outcome loss': 0.1497476975571877, 'Total loss': 0.1497476975571877}
2022-12-31 07:29:36,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:36,142 INFO:     Epoch: 42
2022-12-31 07:29:37,759 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5174765845139822, 'Total loss': 0.5174765845139822} | train loss {'Reaction outcome loss': 0.14879219630012708, 'Total loss': 0.14879219630012708}
2022-12-31 07:29:37,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:37,759 INFO:     Epoch: 43
2022-12-31 07:29:39,399 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5758629421393077, 'Total loss': 0.5758629421393077} | train loss {'Reaction outcome loss': 0.15002897031777335, 'Total loss': 0.15002897031777335}
2022-12-31 07:29:39,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:39,400 INFO:     Epoch: 44
2022-12-31 07:29:41,002 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5571433325608571, 'Total loss': 0.5571433325608571} | train loss {'Reaction outcome loss': 0.14770731593792638, 'Total loss': 0.14770731593792638}
2022-12-31 07:29:41,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:41,002 INFO:     Epoch: 45
2022-12-31 07:29:42,662 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5622712771097819, 'Total loss': 0.5622712771097819} | train loss {'Reaction outcome loss': 0.14765138831838462, 'Total loss': 0.14765138831838462}
2022-12-31 07:29:42,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:42,663 INFO:     Epoch: 46
2022-12-31 07:29:44,278 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5644534915685654, 'Total loss': 0.5644534915685654} | train loss {'Reaction outcome loss': 0.14459576005310407, 'Total loss': 0.14459576005310407}
2022-12-31 07:29:44,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:44,278 INFO:     Epoch: 47
2022-12-31 07:29:45,938 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5709253390630086, 'Total loss': 0.5709253390630086} | train loss {'Reaction outcome loss': 0.14475826942288078, 'Total loss': 0.14475826942288078}
2022-12-31 07:29:45,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:45,939 INFO:     Epoch: 48
2022-12-31 07:29:47,551 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5572842955589294, 'Total loss': 0.5572842955589294} | train loss {'Reaction outcome loss': 0.14448103016458344, 'Total loss': 0.14448103016458344}
2022-12-31 07:29:47,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:47,552 INFO:     Epoch: 49
2022-12-31 07:29:49,164 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5398334960142771, 'Total loss': 0.5398334960142771} | train loss {'Reaction outcome loss': 0.14280853589909806, 'Total loss': 0.14280853589909806}
2022-12-31 07:29:49,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:49,164 INFO:     Epoch: 50
2022-12-31 07:29:50,790 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5382411062717438, 'Total loss': 0.5382411062717438} | train loss {'Reaction outcome loss': 0.142980343044695, 'Total loss': 0.142980343044695}
2022-12-31 07:29:50,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:50,790 INFO:     Epoch: 51
2022-12-31 07:29:52,416 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5400009890397389, 'Total loss': 0.5400009890397389} | train loss {'Reaction outcome loss': 0.13646297063258686, 'Total loss': 0.13646297063258686}
2022-12-31 07:29:52,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:52,416 INFO:     Epoch: 52
2022-12-31 07:29:54,033 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5042706916729609, 'Total loss': 0.5042706916729609} | train loss {'Reaction outcome loss': 0.13660639907449376, 'Total loss': 0.13660639907449376}
2022-12-31 07:29:54,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:54,034 INFO:     Epoch: 53
2022-12-31 07:29:55,660 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5414969931046169, 'Total loss': 0.5414969931046169} | train loss {'Reaction outcome loss': 0.13458910831790147, 'Total loss': 0.13458910831790147}
2022-12-31 07:29:55,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:55,660 INFO:     Epoch: 54
2022-12-31 07:29:57,280 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5176931023597717, 'Total loss': 0.5176931023597717} | train loss {'Reaction outcome loss': 0.13509828861864714, 'Total loss': 0.13509828861864714}
2022-12-31 07:29:57,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:57,281 INFO:     Epoch: 55
2022-12-31 07:29:58,887 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5533924400806427, 'Total loss': 0.5533924400806427} | train loss {'Reaction outcome loss': 0.1333715013242744, 'Total loss': 0.1333715013242744}
2022-12-31 07:29:58,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:29:58,888 INFO:     Epoch: 56
2022-12-31 07:30:00,548 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5532252430915833, 'Total loss': 0.5532252430915833} | train loss {'Reaction outcome loss': 0.13637089693456536, 'Total loss': 0.13637089693456536}
2022-12-31 07:30:00,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:00,549 INFO:     Epoch: 57
2022-12-31 07:30:02,161 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5600240190823873, 'Total loss': 0.5600240190823873} | train loss {'Reaction outcome loss': 0.1332997138126065, 'Total loss': 0.1332997138126065}
2022-12-31 07:30:02,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:02,161 INFO:     Epoch: 58
2022-12-31 07:30:03,784 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.585699200630188, 'Total loss': 0.585699200630188} | train loss {'Reaction outcome loss': 0.1339355202635752, 'Total loss': 0.1339355202635752}
2022-12-31 07:30:03,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:03,784 INFO:     Epoch: 59
2022-12-31 07:30:05,406 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5607701927423477, 'Total loss': 0.5607701927423477} | train loss {'Reaction outcome loss': 0.13351962072909743, 'Total loss': 0.13351962072909743}
2022-12-31 07:30:05,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:05,406 INFO:     Epoch: 60
2022-12-31 07:30:07,020 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5560988843441009, 'Total loss': 0.5560988843441009} | train loss {'Reaction outcome loss': 0.13227171374592875, 'Total loss': 0.13227171374592875}
2022-12-31 07:30:07,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:07,021 INFO:     Epoch: 61
2022-12-31 07:30:08,646 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5549662292003632, 'Total loss': 0.5549662292003632} | train loss {'Reaction outcome loss': 0.1334018585562328, 'Total loss': 0.1334018585562328}
2022-12-31 07:30:08,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:08,646 INFO:     Epoch: 62
2022-12-31 07:30:10,272 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5536295970280966, 'Total loss': 0.5536295970280966} | train loss {'Reaction outcome loss': 0.13226505221994728, 'Total loss': 0.13226505221994728}
2022-12-31 07:30:10,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:10,272 INFO:     Epoch: 63
2022-12-31 07:30:11,904 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5698173145453135, 'Total loss': 0.5698173145453135} | train loss {'Reaction outcome loss': 0.13191732698096134, 'Total loss': 0.13191732698096134}
2022-12-31 07:30:11,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:11,904 INFO:     Epoch: 64
2022-12-31 07:30:13,566 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5557389577229818, 'Total loss': 0.5557389577229818} | train loss {'Reaction outcome loss': 0.12698880102675172, 'Total loss': 0.12698880102675172}
2022-12-31 07:30:13,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:13,566 INFO:     Epoch: 65
2022-12-31 07:30:15,181 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5391514907280605, 'Total loss': 0.5391514907280605} | train loss {'Reaction outcome loss': 0.12876383426730859, 'Total loss': 0.12876383426730859}
2022-12-31 07:30:15,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:15,182 INFO:     Epoch: 66
2022-12-31 07:30:16,829 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5572473555803299, 'Total loss': 0.5572473555803299} | train loss {'Reaction outcome loss': 0.1262344408154393, 'Total loss': 0.1262344408154393}
2022-12-31 07:30:16,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:16,829 INFO:     Epoch: 67
2022-12-31 07:30:18,449 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5644109557072322, 'Total loss': 0.5644109557072322} | train loss {'Reaction outcome loss': 0.1285739736597769, 'Total loss': 0.1285739736597769}
2022-12-31 07:30:18,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:18,449 INFO:     Epoch: 68
2022-12-31 07:30:20,112 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5421809196472168, 'Total loss': 0.5421809196472168} | train loss {'Reaction outcome loss': 0.12564873605303242, 'Total loss': 0.12564873605303242}
2022-12-31 07:30:20,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:20,112 INFO:     Epoch: 69
2022-12-31 07:30:21,719 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.534799799323082, 'Total loss': 0.534799799323082} | train loss {'Reaction outcome loss': 0.12507603108710813, 'Total loss': 0.12507603108710813}
2022-12-31 07:30:21,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:21,719 INFO:     Epoch: 70
2022-12-31 07:30:23,382 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5734215060869853, 'Total loss': 0.5734215060869853} | train loss {'Reaction outcome loss': 0.12455774080834986, 'Total loss': 0.12455774080834986}
2022-12-31 07:30:23,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:23,383 INFO:     Epoch: 71
2022-12-31 07:30:24,996 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5445517480373383, 'Total loss': 0.5445517480373383} | train loss {'Reaction outcome loss': 0.12445495667558082, 'Total loss': 0.12445495667558082}
2022-12-31 07:30:24,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:24,996 INFO:     Epoch: 72
2022-12-31 07:30:26,662 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.52549649477005, 'Total loss': 0.52549649477005} | train loss {'Reaction outcome loss': 0.14020283505543257, 'Total loss': 0.14020283505543257}
2022-12-31 07:30:26,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:26,662 INFO:     Epoch: 73
2022-12-31 07:30:28,281 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5574864904085796, 'Total loss': 0.5574864904085796} | train loss {'Reaction outcome loss': 0.1305434146885038, 'Total loss': 0.1305434146885038}
2022-12-31 07:30:28,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:28,281 INFO:     Epoch: 74
2022-12-31 07:30:29,990 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5335803925991058, 'Total loss': 0.5335803925991058} | train loss {'Reaction outcome loss': 0.13426981950212485, 'Total loss': 0.13426981950212485}
2022-12-31 07:30:29,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:29,991 INFO:     Epoch: 75
2022-12-31 07:30:31,605 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.532699532310168, 'Total loss': 0.532699532310168} | train loss {'Reaction outcome loss': 0.14446221350690525, 'Total loss': 0.14446221350690525}
2022-12-31 07:30:31,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:31,606 INFO:     Epoch: 76
2022-12-31 07:30:33,224 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5720989167690277, 'Total loss': 0.5720989167690277} | train loss {'Reaction outcome loss': 0.12742475946467585, 'Total loss': 0.12742475946467585}
2022-12-31 07:30:33,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:33,224 INFO:     Epoch: 77
2022-12-31 07:30:34,844 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5238096942504247, 'Total loss': 0.5238096942504247} | train loss {'Reaction outcome loss': 0.1263772762882265, 'Total loss': 0.1263772762882265}
2022-12-31 07:30:34,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:34,844 INFO:     Epoch: 78
2022-12-31 07:30:36,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5380595455567042, 'Total loss': 0.5380595455567042} | train loss {'Reaction outcome loss': 0.11956852148305978, 'Total loss': 0.11956852148305978}
2022-12-31 07:30:36,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:36,461 INFO:     Epoch: 79
2022-12-31 07:30:38,078 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5392142097155254, 'Total loss': 0.5392142097155254} | train loss {'Reaction outcome loss': 0.12139969989083761, 'Total loss': 0.12139969989083761}
2022-12-31 07:30:38,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:38,079 INFO:     Epoch: 80
2022-12-31 07:30:39,701 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5635961433251698, 'Total loss': 0.5635961433251698} | train loss {'Reaction outcome loss': 0.1204871970761439, 'Total loss': 0.1204871970761439}
2022-12-31 07:30:39,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:39,702 INFO:     Epoch: 81
2022-12-31 07:30:41,421 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5287103861570358, 'Total loss': 0.5287103861570358} | train loss {'Reaction outcome loss': 0.1201800124715811, 'Total loss': 0.1201800124715811}
2022-12-31 07:30:41,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:41,422 INFO:     Epoch: 82
2022-12-31 07:30:43,029 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5439142952362697, 'Total loss': 0.5439142952362697} | train loss {'Reaction outcome loss': 0.11746877997580484, 'Total loss': 0.11746877997580484}
2022-12-31 07:30:43,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:43,030 INFO:     Epoch: 83
2022-12-31 07:30:44,655 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5539552181959152, 'Total loss': 0.5539552181959152} | train loss {'Reaction outcome loss': 0.12143528958420022, 'Total loss': 0.12143528958420022}
2022-12-31 07:30:44,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:44,655 INFO:     Epoch: 84
2022-12-31 07:30:46,280 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5175100227197011, 'Total loss': 0.5175100227197011} | train loss {'Reaction outcome loss': 0.12189927292639777, 'Total loss': 0.12189927292639777}
2022-12-31 07:30:46,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:46,280 INFO:     Epoch: 85
2022-12-31 07:30:47,906 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5331665486097336, 'Total loss': 0.5331665486097336} | train loss {'Reaction outcome loss': 0.11932871078011964, 'Total loss': 0.11932871078011964}
2022-12-31 07:30:47,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:47,906 INFO:     Epoch: 86
2022-12-31 07:30:49,612 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5530561963717143, 'Total loss': 0.5530561963717143} | train loss {'Reaction outcome loss': 0.11887270980810873, 'Total loss': 0.11887270980810873}
2022-12-31 07:30:49,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:49,613 INFO:     Epoch: 87
2022-12-31 07:30:51,285 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5337936148047447, 'Total loss': 0.5337936148047447} | train loss {'Reaction outcome loss': 0.11816528856676693, 'Total loss': 0.11816528856676693}
2022-12-31 07:30:51,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:51,285 INFO:     Epoch: 88
2022-12-31 07:30:52,918 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5434727301200231, 'Total loss': 0.5434727301200231} | train loss {'Reaction outcome loss': 0.11680033241250583, 'Total loss': 0.11680033241250583}
2022-12-31 07:30:52,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:52,918 INFO:     Epoch: 89
2022-12-31 07:30:54,544 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5569607853889466, 'Total loss': 0.5569607853889466} | train loss {'Reaction outcome loss': 0.11879409913334699, 'Total loss': 0.11879409913334699}
2022-12-31 07:30:54,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:54,544 INFO:     Epoch: 90
2022-12-31 07:30:56,170 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.584334459900856, 'Total loss': 0.584334459900856} | train loss {'Reaction outcome loss': 0.11864155966390356, 'Total loss': 0.11864155966390356}
2022-12-31 07:30:56,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:56,170 INFO:     Epoch: 91
2022-12-31 07:30:57,784 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5409025371074676, 'Total loss': 0.5409025371074676} | train loss {'Reaction outcome loss': 0.11406422898163208, 'Total loss': 0.11406422898163208}
2022-12-31 07:30:57,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:57,784 INFO:     Epoch: 92
2022-12-31 07:30:59,411 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5125178893407186, 'Total loss': 0.5125178893407186} | train loss {'Reaction outcome loss': 0.11508892377141687, 'Total loss': 0.11508892377141687}
2022-12-31 07:30:59,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:30:59,412 INFO:     Epoch: 93
2022-12-31 07:31:01,039 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5465587874253591, 'Total loss': 0.5465587874253591} | train loss {'Reaction outcome loss': 0.12733620361161782, 'Total loss': 0.12733620361161782}
2022-12-31 07:31:01,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:01,040 INFO:     Epoch: 94
2022-12-31 07:31:02,659 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5281697114308676, 'Total loss': 0.5281697114308676} | train loss {'Reaction outcome loss': 0.14860387985757278, 'Total loss': 0.14860387985757278}
2022-12-31 07:31:02,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:02,659 INFO:     Epoch: 95
2022-12-31 07:31:04,285 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5415203561385472, 'Total loss': 0.5415203561385472} | train loss {'Reaction outcome loss': 0.12299518254788025, 'Total loss': 0.12299518254788025}
2022-12-31 07:31:04,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:04,285 INFO:     Epoch: 96
2022-12-31 07:31:05,908 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5249286770820618, 'Total loss': 0.5249286770820618} | train loss {'Reaction outcome loss': 0.12055376289683171, 'Total loss': 0.12055376289683171}
2022-12-31 07:31:05,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:05,909 INFO:     Epoch: 97
2022-12-31 07:31:07,515 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5486693908770879, 'Total loss': 0.5486693908770879} | train loss {'Reaction outcome loss': 0.11602325215017777, 'Total loss': 0.11602325215017777}
2022-12-31 07:31:07,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:07,515 INFO:     Epoch: 98
2022-12-31 07:31:09,178 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5509142895539602, 'Total loss': 0.5509142895539602} | train loss {'Reaction outcome loss': 0.10929603226427191, 'Total loss': 0.10929603226427191}
2022-12-31 07:31:09,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:09,178 INFO:     Epoch: 99
2022-12-31 07:31:10,787 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5172126988569895, 'Total loss': 0.5172126988569895} | train loss {'Reaction outcome loss': 0.11455915360525926, 'Total loss': 0.11455915360525926}
2022-12-31 07:31:10,787 INFO:     Best model found after epoch 16 of 100.
2022-12-31 07:31:10,787 INFO:   Done with stage: TRAINING
2022-12-31 07:31:10,787 INFO:   Starting stage: EVALUATION
2022-12-31 07:31:10,920 INFO:   Done with stage: EVALUATION
2022-12-31 07:31:10,920 INFO:   Leaving out SEQ value Fold_6
2022-12-31 07:31:10,933 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 07:31:10,933 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:31:11,581 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:31:11,581 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:31:11,649 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:31:11,649 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:31:11,649 INFO:     No hyperparam tuning for this model
2022-12-31 07:31:11,649 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:31:11,649 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:31:11,650 INFO:     None feature selector for col prot
2022-12-31 07:31:11,650 INFO:     None feature selector for col prot
2022-12-31 07:31:11,650 INFO:     None feature selector for col prot
2022-12-31 07:31:11,651 INFO:     None feature selector for col chem
2022-12-31 07:31:11,651 INFO:     None feature selector for col chem
2022-12-31 07:31:11,651 INFO:     None feature selector for col chem
2022-12-31 07:31:11,651 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:31:11,651 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:31:11,653 INFO:     Number of params in model 224011
2022-12-31 07:31:11,656 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:31:11,656 INFO:   Starting stage: TRAINING
2022-12-31 07:31:11,701 INFO:     Val loss before train {'Reaction outcome loss': 1.0355058630307516, 'Total loss': 1.0355058630307516}
2022-12-31 07:31:11,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:11,701 INFO:     Epoch: 0
2022-12-31 07:31:13,331 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5760777711868286, 'Total loss': 0.5760777711868286} | train loss {'Reaction outcome loss': 0.780299924448509, 'Total loss': 0.780299924448509}
2022-12-31 07:31:13,331 INFO:     Found new best model at epoch 0
2022-12-31 07:31:13,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:13,332 INFO:     Epoch: 1
2022-12-31 07:31:14,954 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49978052377700805, 'Total loss': 0.49978052377700805} | train loss {'Reaction outcome loss': 0.5177399834032954, 'Total loss': 0.5177399834032954}
2022-12-31 07:31:14,954 INFO:     Found new best model at epoch 1
2022-12-31 07:31:14,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:14,955 INFO:     Epoch: 2
2022-12-31 07:31:16,581 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49932904839515685, 'Total loss': 0.49932904839515685} | train loss {'Reaction outcome loss': 0.446724737594274, 'Total loss': 0.446724737594274}
2022-12-31 07:31:16,581 INFO:     Found new best model at epoch 2
2022-12-31 07:31:16,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:16,582 INFO:     Epoch: 3
2022-12-31 07:31:18,209 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47495345075925194, 'Total loss': 0.47495345075925194} | train loss {'Reaction outcome loss': 0.4076381372523222, 'Total loss': 0.4076381372523222}
2022-12-31 07:31:18,210 INFO:     Found new best model at epoch 3
2022-12-31 07:31:18,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:18,211 INFO:     Epoch: 4
2022-12-31 07:31:19,841 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47232054273287455, 'Total loss': 0.47232054273287455} | train loss {'Reaction outcome loss': 0.3772756671970071, 'Total loss': 0.3772756671970071}
2022-12-31 07:31:19,841 INFO:     Found new best model at epoch 4
2022-12-31 07:31:19,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:19,842 INFO:     Epoch: 5
2022-12-31 07:31:21,474 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4771299878756205, 'Total loss': 0.4771299878756205} | train loss {'Reaction outcome loss': 0.3579790174745911, 'Total loss': 0.3579790174745911}
2022-12-31 07:31:21,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:21,474 INFO:     Epoch: 6
2022-12-31 07:31:23,106 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47655072311560315, 'Total loss': 0.47655072311560315} | train loss {'Reaction outcome loss': 0.33663385417917574, 'Total loss': 0.33663385417917574}
2022-12-31 07:31:23,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:23,106 INFO:     Epoch: 7
2022-12-31 07:31:24,732 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47904107968012494, 'Total loss': 0.47904107968012494} | train loss {'Reaction outcome loss': 0.3223606867292082, 'Total loss': 0.3223606867292082}
2022-12-31 07:31:24,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:24,732 INFO:     Epoch: 8
2022-12-31 07:31:26,366 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45609900255997976, 'Total loss': 0.45609900255997976} | train loss {'Reaction outcome loss': 0.3064089958902301, 'Total loss': 0.3064089958902301}
2022-12-31 07:31:26,366 INFO:     Found new best model at epoch 8
2022-12-31 07:31:26,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:26,367 INFO:     Epoch: 9
2022-12-31 07:31:27,999 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4736880312363307, 'Total loss': 0.4736880312363307} | train loss {'Reaction outcome loss': 0.29373748729590476, 'Total loss': 0.29373748729590476}
2022-12-31 07:31:27,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:27,999 INFO:     Epoch: 10
2022-12-31 07:31:29,609 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4744541098674138, 'Total loss': 0.4744541098674138} | train loss {'Reaction outcome loss': 0.28016125807531905, 'Total loss': 0.28016125807531905}
2022-12-31 07:31:29,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:29,609 INFO:     Epoch: 11
2022-12-31 07:31:31,230 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4633831113576889, 'Total loss': 0.4633831113576889} | train loss {'Reaction outcome loss': 0.27145391140496256, 'Total loss': 0.27145391140496256}
2022-12-31 07:31:31,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:31,230 INFO:     Epoch: 12
2022-12-31 07:31:32,852 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4862732648849487, 'Total loss': 0.4862732648849487} | train loss {'Reaction outcome loss': 0.258765853201762, 'Total loss': 0.258765853201762}
2022-12-31 07:31:32,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:32,852 INFO:     Epoch: 13
2022-12-31 07:31:34,472 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45468842883904775, 'Total loss': 0.45468842883904775} | train loss {'Reaction outcome loss': 0.25047461969596385, 'Total loss': 0.25047461969596385}
2022-12-31 07:31:34,473 INFO:     Found new best model at epoch 13
2022-12-31 07:31:34,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:34,474 INFO:     Epoch: 14
2022-12-31 07:31:36,146 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4743398557106654, 'Total loss': 0.4743398557106654} | train loss {'Reaction outcome loss': 0.24496794136960584, 'Total loss': 0.24496794136960584}
2022-12-31 07:31:36,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:36,146 INFO:     Epoch: 15
2022-12-31 07:31:37,762 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46735321283340453, 'Total loss': 0.46735321283340453} | train loss {'Reaction outcome loss': 0.23780520940838307, 'Total loss': 0.23780520940838307}
2022-12-31 07:31:37,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:37,762 INFO:     Epoch: 16
2022-12-31 07:31:39,383 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47809520761171975, 'Total loss': 0.47809520761171975} | train loss {'Reaction outcome loss': 0.22936217629414604, 'Total loss': 0.22936217629414604}
2022-12-31 07:31:39,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:39,383 INFO:     Epoch: 17
2022-12-31 07:31:41,053 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49379730423291524, 'Total loss': 0.49379730423291524} | train loss {'Reaction outcome loss': 0.22529019615764223, 'Total loss': 0.22529019615764223}
2022-12-31 07:31:41,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:41,054 INFO:     Epoch: 18
2022-12-31 07:31:42,676 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.476086954275767, 'Total loss': 0.476086954275767} | train loss {'Reaction outcome loss': 0.21753263309436585, 'Total loss': 0.21753263309436585}
2022-12-31 07:31:42,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:42,677 INFO:     Epoch: 19
2022-12-31 07:31:44,347 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46722018321355185, 'Total loss': 0.46722018321355185} | train loss {'Reaction outcome loss': 0.2124516905591376, 'Total loss': 0.2124516905591376}
2022-12-31 07:31:44,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:44,347 INFO:     Epoch: 20
2022-12-31 07:31:46,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5054649025201797, 'Total loss': 0.5054649025201797} | train loss {'Reaction outcome loss': 0.20884079190260235, 'Total loss': 0.20884079190260235}
2022-12-31 07:31:46,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:46,019 INFO:     Epoch: 21
2022-12-31 07:31:47,651 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47181081970532734, 'Total loss': 0.47181081970532734} | train loss {'Reaction outcome loss': 0.20717502919627548, 'Total loss': 0.20717502919627548}
2022-12-31 07:31:47,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:47,651 INFO:     Epoch: 22
2022-12-31 07:31:49,322 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4886473755041758, 'Total loss': 0.4886473755041758} | train loss {'Reaction outcome loss': 0.20203963794916976, 'Total loss': 0.20203963794916976}
2022-12-31 07:31:49,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:49,322 INFO:     Epoch: 23
2022-12-31 07:31:50,993 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4788868953784307, 'Total loss': 0.4788868953784307} | train loss {'Reaction outcome loss': 0.19519054837901453, 'Total loss': 0.19519054837901453}
2022-12-31 07:31:50,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:50,993 INFO:     Epoch: 24
2022-12-31 07:31:52,643 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.531180489063263, 'Total loss': 0.531180489063263} | train loss {'Reaction outcome loss': 0.19080499142058704, 'Total loss': 0.19080499142058704}
2022-12-31 07:31:52,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:52,644 INFO:     Epoch: 25
2022-12-31 07:31:54,315 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49024976094563805, 'Total loss': 0.49024976094563805} | train loss {'Reaction outcome loss': 0.18797646905379606, 'Total loss': 0.18797646905379606}
2022-12-31 07:31:54,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:54,316 INFO:     Epoch: 26
2022-12-31 07:31:55,946 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4999330759048462, 'Total loss': 0.4999330759048462} | train loss {'Reaction outcome loss': 0.18665901295141407, 'Total loss': 0.18665901295141407}
2022-12-31 07:31:55,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:55,946 INFO:     Epoch: 27
2022-12-31 07:31:57,588 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4849639485279719, 'Total loss': 0.4849639485279719} | train loss {'Reaction outcome loss': 0.18363896197562077, 'Total loss': 0.18363896197562077}
2022-12-31 07:31:57,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:57,588 INFO:     Epoch: 28
2022-12-31 07:31:59,232 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5137440919876098, 'Total loss': 0.5137440919876098} | train loss {'Reaction outcome loss': 0.1794294492956856, 'Total loss': 0.1794294492956856}
2022-12-31 07:31:59,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:31:59,232 INFO:     Epoch: 29
2022-12-31 07:32:00,868 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48343484501043954, 'Total loss': 0.48343484501043954} | train loss {'Reaction outcome loss': 0.17644718788322128, 'Total loss': 0.17644718788322128}
2022-12-31 07:32:00,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:00,868 INFO:     Epoch: 30
2022-12-31 07:32:02,511 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4715631127357483, 'Total loss': 0.4715631127357483} | train loss {'Reaction outcome loss': 0.17272849874537344, 'Total loss': 0.17272849874537344}
2022-12-31 07:32:02,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:02,511 INFO:     Epoch: 31
2022-12-31 07:32:04,151 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5100862463315328, 'Total loss': 0.5100862463315328} | train loss {'Reaction outcome loss': 0.17090399750585697, 'Total loss': 0.17090399750585697}
2022-12-31 07:32:04,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:04,151 INFO:     Epoch: 32
2022-12-31 07:32:05,765 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5200476954380672, 'Total loss': 0.5200476954380672} | train loss {'Reaction outcome loss': 0.16903638507538754, 'Total loss': 0.16903638507538754}
2022-12-31 07:32:05,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:05,766 INFO:     Epoch: 33
2022-12-31 07:32:07,386 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5076919317245483, 'Total loss': 0.5076919317245483} | train loss {'Reaction outcome loss': 0.1645702266870638, 'Total loss': 0.1645702266870638}
2022-12-31 07:32:07,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:07,386 INFO:     Epoch: 34
2022-12-31 07:32:09,009 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5073840310176213, 'Total loss': 0.5073840310176213} | train loss {'Reaction outcome loss': 0.16415787173522509, 'Total loss': 0.16415787173522509}
2022-12-31 07:32:09,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:09,009 INFO:     Epoch: 35
2022-12-31 07:32:10,633 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4999441862106323, 'Total loss': 0.4999441862106323} | train loss {'Reaction outcome loss': 0.15836889260458603, 'Total loss': 0.15836889260458603}
2022-12-31 07:32:10,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:10,633 INFO:     Epoch: 36
2022-12-31 07:32:12,275 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49974903762340545, 'Total loss': 0.49974903762340545} | train loss {'Reaction outcome loss': 0.15815666438305637, 'Total loss': 0.15815666438305637}
2022-12-31 07:32:12,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:12,275 INFO:     Epoch: 37
2022-12-31 07:32:13,911 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4802944223086039, 'Total loss': 0.4802944223086039} | train loss {'Reaction outcome loss': 0.15834340003288824, 'Total loss': 0.15834340003288824}
2022-12-31 07:32:13,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:13,911 INFO:     Epoch: 38
2022-12-31 07:32:15,524 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4880263527234395, 'Total loss': 0.4880263527234395} | train loss {'Reaction outcome loss': 0.15619643313628673, 'Total loss': 0.15619643313628673}
2022-12-31 07:32:15,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:15,525 INFO:     Epoch: 39
2022-12-31 07:32:17,143 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5028285562992096, 'Total loss': 0.5028285562992096} | train loss {'Reaction outcome loss': 0.15141907625492085, 'Total loss': 0.15141907625492085}
2022-12-31 07:32:17,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:17,143 INFO:     Epoch: 40
2022-12-31 07:32:18,754 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4728728691736857, 'Total loss': 0.4728728691736857} | train loss {'Reaction outcome loss': 0.15474945281225422, 'Total loss': 0.15474945281225422}
2022-12-31 07:32:18,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:18,755 INFO:     Epoch: 41
2022-12-31 07:32:20,369 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5121665020783742, 'Total loss': 0.5121665020783742} | train loss {'Reaction outcome loss': 0.1513503242405098, 'Total loss': 0.1513503242405098}
2022-12-31 07:32:20,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:20,370 INFO:     Epoch: 42
2022-12-31 07:32:21,985 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4832458237806956, 'Total loss': 0.4832458237806956} | train loss {'Reaction outcome loss': 0.14965975991978112, 'Total loss': 0.14965975991978112}
2022-12-31 07:32:21,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:21,985 INFO:     Epoch: 43
2022-12-31 07:32:23,602 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.527338715394338, 'Total loss': 0.527338715394338} | train loss {'Reaction outcome loss': 0.14855849838038968, 'Total loss': 0.14855849838038968}
2022-12-31 07:32:23,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:23,602 INFO:     Epoch: 44
2022-12-31 07:32:25,234 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4979381064573924, 'Total loss': 0.4979381064573924} | train loss {'Reaction outcome loss': 0.14550659557743947, 'Total loss': 0.14550659557743947}
2022-12-31 07:32:25,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:25,235 INFO:     Epoch: 45
2022-12-31 07:32:26,865 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4903912882010142, 'Total loss': 0.4903912882010142} | train loss {'Reaction outcome loss': 0.14586076828641042, 'Total loss': 0.14586076828641042}
2022-12-31 07:32:26,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:26,866 INFO:     Epoch: 46
2022-12-31 07:32:28,490 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.520645022392273, 'Total loss': 0.520645022392273} | train loss {'Reaction outcome loss': 0.15010980359322326, 'Total loss': 0.15010980359322326}
2022-12-31 07:32:28,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:28,490 INFO:     Epoch: 47
2022-12-31 07:32:30,122 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5329692840576172, 'Total loss': 0.5329692840576172} | train loss {'Reaction outcome loss': 0.14122553798454118, 'Total loss': 0.14122553798454118}
2022-12-31 07:32:30,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:30,122 INFO:     Epoch: 48
2022-12-31 07:32:31,755 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5020873139301936, 'Total loss': 0.5020873139301936} | train loss {'Reaction outcome loss': 0.14058192866427374, 'Total loss': 0.14058192866427374}
2022-12-31 07:32:31,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:31,755 INFO:     Epoch: 49
2022-12-31 07:32:33,377 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5224435860912006, 'Total loss': 0.5224435860912006} | train loss {'Reaction outcome loss': 0.14377833521228942, 'Total loss': 0.14377833521228942}
2022-12-31 07:32:33,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:33,377 INFO:     Epoch: 50
2022-12-31 07:32:35,011 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48867213328679404, 'Total loss': 0.48867213328679404} | train loss {'Reaction outcome loss': 0.1419147070873838, 'Total loss': 0.1419147070873838}
2022-12-31 07:32:35,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:35,011 INFO:     Epoch: 51
2022-12-31 07:32:36,644 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5004446039597193, 'Total loss': 0.5004446039597193} | train loss {'Reaction outcome loss': 0.140719326266797, 'Total loss': 0.140719326266797}
2022-12-31 07:32:36,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:36,644 INFO:     Epoch: 52
2022-12-31 07:32:38,298 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5318650444348653, 'Total loss': 0.5318650444348653} | train loss {'Reaction outcome loss': 0.13748473821658413, 'Total loss': 0.13748473821658413}
2022-12-31 07:32:38,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:38,298 INFO:     Epoch: 53
2022-12-31 07:32:39,909 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47793243527412416, 'Total loss': 0.47793243527412416} | train loss {'Reaction outcome loss': 0.14052605168853588, 'Total loss': 0.14052605168853588}
2022-12-31 07:32:39,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:39,909 INFO:     Epoch: 54
2022-12-31 07:32:41,524 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.494736244281133, 'Total loss': 0.494736244281133} | train loss {'Reaction outcome loss': 0.1363606915039276, 'Total loss': 0.1363606915039276}
2022-12-31 07:32:41,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:41,525 INFO:     Epoch: 55
2022-12-31 07:32:43,134 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5245694413781166, 'Total loss': 0.5245694413781166} | train loss {'Reaction outcome loss': 0.13619996952599028, 'Total loss': 0.13619996952599028}
2022-12-31 07:32:43,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:43,134 INFO:     Epoch: 56
2022-12-31 07:32:44,750 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47552371794978776, 'Total loss': 0.47552371794978776} | train loss {'Reaction outcome loss': 0.13523523300375104, 'Total loss': 0.13523523300375104}
2022-12-31 07:32:44,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:44,750 INFO:     Epoch: 57
2022-12-31 07:32:46,392 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49590931832790375, 'Total loss': 0.49590931832790375} | train loss {'Reaction outcome loss': 0.13706252287185686, 'Total loss': 0.13706252287185686}
2022-12-31 07:32:46,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:46,392 INFO:     Epoch: 58
2022-12-31 07:32:48,025 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49947323302427926, 'Total loss': 0.49947323302427926} | train loss {'Reaction outcome loss': 0.13559160953293478, 'Total loss': 0.13559160953293478}
2022-12-31 07:32:48,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:48,026 INFO:     Epoch: 59
2022-12-31 07:32:49,658 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5007373670736949, 'Total loss': 0.5007373670736949} | train loss {'Reaction outcome loss': 0.13206752318055084, 'Total loss': 0.13206752318055084}
2022-12-31 07:32:49,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:49,658 INFO:     Epoch: 60
2022-12-31 07:32:51,285 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4768921544154485, 'Total loss': 0.4768921544154485} | train loss {'Reaction outcome loss': 0.13483144844703995, 'Total loss': 0.13483144844703995}
2022-12-31 07:32:51,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:51,285 INFO:     Epoch: 61
2022-12-31 07:32:52,921 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5075938731431962, 'Total loss': 0.5075938731431962} | train loss {'Reaction outcome loss': 0.13153236004816443, 'Total loss': 0.13153236004816443}
2022-12-31 07:32:52,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:52,921 INFO:     Epoch: 62
2022-12-31 07:32:54,556 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4936288038889567, 'Total loss': 0.4936288038889567} | train loss {'Reaction outcome loss': 0.13302376983680558, 'Total loss': 0.13302376983680558}
2022-12-31 07:32:54,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:54,556 INFO:     Epoch: 63
2022-12-31 07:32:56,181 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5204605599244435, 'Total loss': 0.5204605599244435} | train loss {'Reaction outcome loss': 0.13171246104843456, 'Total loss': 0.13171246104843456}
2022-12-31 07:32:56,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:56,182 INFO:     Epoch: 64
2022-12-31 07:32:57,815 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5446834961573283, 'Total loss': 0.5446834961573283} | train loss {'Reaction outcome loss': 0.13148665734287687, 'Total loss': 0.13148665734287687}
2022-12-31 07:32:57,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:57,816 INFO:     Epoch: 65
2022-12-31 07:32:59,438 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5264570564031601, 'Total loss': 0.5264570564031601} | train loss {'Reaction outcome loss': 0.13039464918923455, 'Total loss': 0.13039464918923455}
2022-12-31 07:32:59,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:32:59,438 INFO:     Epoch: 66
2022-12-31 07:33:01,073 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5075575490792592, 'Total loss': 0.5075575490792592} | train loss {'Reaction outcome loss': 0.13118707240871844, 'Total loss': 0.13118707240871844}
2022-12-31 07:33:01,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:01,074 INFO:     Epoch: 67
2022-12-31 07:33:02,708 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48984431425730385, 'Total loss': 0.48984431425730385} | train loss {'Reaction outcome loss': 0.1260718981254617, 'Total loss': 0.1260718981254617}
2022-12-31 07:33:02,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:02,708 INFO:     Epoch: 68
2022-12-31 07:33:04,276 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5114718198776245, 'Total loss': 0.5114718198776245} | train loss {'Reaction outcome loss': 0.12750576924371268, 'Total loss': 0.12750576924371268}
2022-12-31 07:33:04,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:04,276 INFO:     Epoch: 69
2022-12-31 07:33:05,391 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5067674676577251, 'Total loss': 0.5067674676577251} | train loss {'Reaction outcome loss': 0.1287174030368482, 'Total loss': 0.1287174030368482}
2022-12-31 07:33:05,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:05,391 INFO:     Epoch: 70
2022-12-31 07:33:06,501 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5257680654525757, 'Total loss': 0.5257680654525757} | train loss {'Reaction outcome loss': 0.12968049653963815, 'Total loss': 0.12968049653963815}
2022-12-31 07:33:06,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:06,501 INFO:     Epoch: 71
2022-12-31 07:33:07,630 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5115225777029991, 'Total loss': 0.5115225777029991} | train loss {'Reaction outcome loss': 0.12615423320896843, 'Total loss': 0.12615423320896843}
2022-12-31 07:33:07,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:07,630 INFO:     Epoch: 72
2022-12-31 07:33:08,813 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5244881878296535, 'Total loss': 0.5244881878296535} | train loss {'Reaction outcome loss': 0.12740123988085492, 'Total loss': 0.12740123988085492}
2022-12-31 07:33:08,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:08,813 INFO:     Epoch: 73
2022-12-31 07:33:10,481 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47040681342283885, 'Total loss': 0.47040681342283885} | train loss {'Reaction outcome loss': 0.13275982510123657, 'Total loss': 0.13275982510123657}
2022-12-31 07:33:10,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:10,481 INFO:     Epoch: 74
2022-12-31 07:33:12,102 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5126347770293553, 'Total loss': 0.5126347770293553} | train loss {'Reaction outcome loss': 0.12060375057584488, 'Total loss': 0.12060375057584488}
2022-12-31 07:33:12,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:12,102 INFO:     Epoch: 75
2022-12-31 07:33:13,768 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5000695625940959, 'Total loss': 0.5000695625940959} | train loss {'Reaction outcome loss': 0.11887635178578217, 'Total loss': 0.11887635178578217}
2022-12-31 07:33:13,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:13,768 INFO:     Epoch: 76
2022-12-31 07:33:15,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5112476746241251, 'Total loss': 0.5112476746241251} | train loss {'Reaction outcome loss': 0.1291374352891738, 'Total loss': 0.1291374352891738}
2022-12-31 07:33:15,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:15,427 INFO:     Epoch: 77
2022-12-31 07:33:17,084 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5477267920970916, 'Total loss': 0.5477267920970916} | train loss {'Reaction outcome loss': 0.12679965800642698, 'Total loss': 0.12679965800642698}
2022-12-31 07:33:17,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:17,085 INFO:     Epoch: 78
2022-12-31 07:33:18,715 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5166257401307424, 'Total loss': 0.5166257401307424} | train loss {'Reaction outcome loss': 0.12135214479942721, 'Total loss': 0.12135214479942721}
2022-12-31 07:33:18,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:18,716 INFO:     Epoch: 79
2022-12-31 07:33:20,348 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47903171479701995, 'Total loss': 0.47903171479701995} | train loss {'Reaction outcome loss': 0.12062670191790277, 'Total loss': 0.12062670191790277}
2022-12-31 07:33:20,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:20,349 INFO:     Epoch: 80
2022-12-31 07:33:21,980 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5434780180454254, 'Total loss': 0.5434780180454254} | train loss {'Reaction outcome loss': 0.1212451846577523, 'Total loss': 0.1212451846577523}
2022-12-31 07:33:21,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:21,981 INFO:     Epoch: 81
2022-12-31 07:33:23,615 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5075436194737752, 'Total loss': 0.5075436194737752} | train loss {'Reaction outcome loss': 0.12440060576447538, 'Total loss': 0.12440060576447538}
2022-12-31 07:33:23,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:23,615 INFO:     Epoch: 82
2022-12-31 07:33:25,239 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5027342995007833, 'Total loss': 0.5027342995007833} | train loss {'Reaction outcome loss': 0.1189918764816456, 'Total loss': 0.1189918764816456}
2022-12-31 07:33:25,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:25,239 INFO:     Epoch: 83
2022-12-31 07:33:26,873 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48826323946317035, 'Total loss': 0.48826323946317035} | train loss {'Reaction outcome loss': 0.1188855990195909, 'Total loss': 0.1188855990195909}
2022-12-31 07:33:26,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:26,873 INFO:     Epoch: 84
2022-12-31 07:33:28,490 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5119182666142782, 'Total loss': 0.5119182666142782} | train loss {'Reaction outcome loss': 0.1193593432067722, 'Total loss': 0.1193593432067722}
2022-12-31 07:33:28,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:28,490 INFO:     Epoch: 85
2022-12-31 07:33:30,118 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4900995910167694, 'Total loss': 0.4900995910167694} | train loss {'Reaction outcome loss': 0.12222648655242599, 'Total loss': 0.12222648655242599}
2022-12-31 07:33:30,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:30,118 INFO:     Epoch: 86
2022-12-31 07:33:31,746 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.510899485150973, 'Total loss': 0.510899485150973} | train loss {'Reaction outcome loss': 0.11821651416376824, 'Total loss': 0.11821651416376824}
2022-12-31 07:33:31,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:31,746 INFO:     Epoch: 87
2022-12-31 07:33:33,374 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5002102526525657, 'Total loss': 0.5002102526525657} | train loss {'Reaction outcome loss': 0.12301601067064363, 'Total loss': 0.12301601067064363}
2022-12-31 07:33:33,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:33,374 INFO:     Epoch: 88
2022-12-31 07:33:35,001 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.536080406109492, 'Total loss': 0.536080406109492} | train loss {'Reaction outcome loss': 0.12028421857982659, 'Total loss': 0.12028421857982659}
2022-12-31 07:33:35,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:35,001 INFO:     Epoch: 89
2022-12-31 07:33:36,636 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4902437488238017, 'Total loss': 0.4902437488238017} | train loss {'Reaction outcome loss': 0.11860568773351099, 'Total loss': 0.11860568773351099}
2022-12-31 07:33:36,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:36,636 INFO:     Epoch: 90
2022-12-31 07:33:38,258 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5222834457953771, 'Total loss': 0.5222834457953771} | train loss {'Reaction outcome loss': 0.12076031028155224, 'Total loss': 0.12076031028155224}
2022-12-31 07:33:38,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:38,258 INFO:     Epoch: 91
2022-12-31 07:33:39,884 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5027371962865194, 'Total loss': 0.5027371962865194} | train loss {'Reaction outcome loss': 0.11593147777928718, 'Total loss': 0.11593147777928718}
2022-12-31 07:33:39,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:39,884 INFO:     Epoch: 92
2022-12-31 07:33:41,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47568466564019524, 'Total loss': 0.47568466564019524} | train loss {'Reaction outcome loss': 0.11540403605744727, 'Total loss': 0.11540403605744727}
2022-12-31 07:33:41,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:41,553 INFO:     Epoch: 93
2022-12-31 07:33:43,189 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5069056630134583, 'Total loss': 0.5069056630134583} | train loss {'Reaction outcome loss': 0.11392293807492332, 'Total loss': 0.11392293807492332}
2022-12-31 07:33:43,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:43,190 INFO:     Epoch: 94
2022-12-31 07:33:44,856 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5205540806055069, 'Total loss': 0.5205540806055069} | train loss {'Reaction outcome loss': 0.11309322924101019, 'Total loss': 0.11309322924101019}
2022-12-31 07:33:44,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:44,856 INFO:     Epoch: 95
2022-12-31 07:33:46,476 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5219717184702556, 'Total loss': 0.5219717184702556} | train loss {'Reaction outcome loss': 0.11936536202012202, 'Total loss': 0.11936536202012202}
2022-12-31 07:33:46,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:46,476 INFO:     Epoch: 96
2022-12-31 07:33:48,096 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5107355693976084, 'Total loss': 0.5107355693976084} | train loss {'Reaction outcome loss': 0.11728101813600866, 'Total loss': 0.11728101813600866}
2022-12-31 07:33:48,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:48,097 INFO:     Epoch: 97
2022-12-31 07:33:49,718 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5094278365373611, 'Total loss': 0.5094278365373611} | train loss {'Reaction outcome loss': 0.1153457189510015, 'Total loss': 0.1153457189510015}
2022-12-31 07:33:49,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:49,719 INFO:     Epoch: 98
2022-12-31 07:33:51,386 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5161520431439082, 'Total loss': 0.5161520431439082} | train loss {'Reaction outcome loss': 0.12266353164238028, 'Total loss': 0.12266353164238028}
2022-12-31 07:33:51,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:51,386 INFO:     Epoch: 99
2022-12-31 07:33:52,999 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5120877027511597, 'Total loss': 0.5120877027511597} | train loss {'Reaction outcome loss': 0.11541019937541296, 'Total loss': 0.11541019937541296}
2022-12-31 07:33:52,999 INFO:     Best model found after epoch 14 of 100.
2022-12-31 07:33:52,999 INFO:   Done with stage: TRAINING
2022-12-31 07:33:52,999 INFO:   Starting stage: EVALUATION
2022-12-31 07:33:53,126 INFO:   Done with stage: EVALUATION
2022-12-31 07:33:53,127 INFO:   Leaving out SEQ value Fold_7
2022-12-31 07:33:53,139 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:33:53,139 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:33:53,788 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:33:53,788 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:33:53,855 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:33:53,855 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:33:53,855 INFO:     No hyperparam tuning for this model
2022-12-31 07:33:53,855 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:33:53,855 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:33:53,856 INFO:     None feature selector for col prot
2022-12-31 07:33:53,856 INFO:     None feature selector for col prot
2022-12-31 07:33:53,856 INFO:     None feature selector for col prot
2022-12-31 07:33:53,857 INFO:     None feature selector for col chem
2022-12-31 07:33:53,857 INFO:     None feature selector for col chem
2022-12-31 07:33:53,857 INFO:     None feature selector for col chem
2022-12-31 07:33:53,857 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:33:53,857 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:33:53,859 INFO:     Number of params in model 224011
2022-12-31 07:33:53,862 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:33:53,862 INFO:   Starting stage: TRAINING
2022-12-31 07:33:53,908 INFO:     Val loss before train {'Reaction outcome loss': 0.9763909498850505, 'Total loss': 0.9763909498850505}
2022-12-31 07:33:53,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:53,908 INFO:     Epoch: 0
2022-12-31 07:33:55,562 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5668622473875682, 'Total loss': 0.5668622473875682} | train loss {'Reaction outcome loss': 0.7755876827809581, 'Total loss': 0.7755876827809581}
2022-12-31 07:33:55,562 INFO:     Found new best model at epoch 0
2022-12-31 07:33:55,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:55,563 INFO:     Epoch: 1
2022-12-31 07:33:57,225 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49573259154955546, 'Total loss': 0.49573259154955546} | train loss {'Reaction outcome loss': 0.5004972340851226, 'Total loss': 0.5004972340851226}
2022-12-31 07:33:57,226 INFO:     Found new best model at epoch 1
2022-12-31 07:33:57,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:57,227 INFO:     Epoch: 2
2022-12-31 07:33:58,836 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4469358414411545, 'Total loss': 0.4469358414411545} | train loss {'Reaction outcome loss': 0.4384466059222493, 'Total loss': 0.4384466059222493}
2022-12-31 07:33:58,836 INFO:     Found new best model at epoch 2
2022-12-31 07:33:58,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:33:58,837 INFO:     Epoch: 3
2022-12-31 07:34:00,443 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45075295567512513, 'Total loss': 0.45075295567512513} | train loss {'Reaction outcome loss': 0.4060581719259853, 'Total loss': 0.4060581719259853}
2022-12-31 07:34:00,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:00,444 INFO:     Epoch: 4
2022-12-31 07:34:02,049 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4317286998033524, 'Total loss': 0.4317286998033524} | train loss {'Reaction outcome loss': 0.39738080069503706, 'Total loss': 0.39738080069503706}
2022-12-31 07:34:02,049 INFO:     Found new best model at epoch 4
2022-12-31 07:34:02,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:02,050 INFO:     Epoch: 5
2022-12-31 07:34:03,663 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42146168847878773, 'Total loss': 0.42146168847878773} | train loss {'Reaction outcome loss': 0.35356739759542205, 'Total loss': 0.35356739759542205}
2022-12-31 07:34:03,663 INFO:     Found new best model at epoch 5
2022-12-31 07:34:03,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:03,664 INFO:     Epoch: 6
2022-12-31 07:34:05,275 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42381415963172914, 'Total loss': 0.42381415963172914} | train loss {'Reaction outcome loss': 0.33250301696555823, 'Total loss': 0.33250301696555823}
2022-12-31 07:34:05,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:05,275 INFO:     Epoch: 7
2022-12-31 07:34:06,888 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41288373023271563, 'Total loss': 0.41288373023271563} | train loss {'Reaction outcome loss': 0.3138882233288841, 'Total loss': 0.3138882233288841}
2022-12-31 07:34:06,888 INFO:     Found new best model at epoch 7
2022-12-31 07:34:06,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:06,889 INFO:     Epoch: 8
2022-12-31 07:34:08,502 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4256947537263234, 'Total loss': 0.4256947537263234} | train loss {'Reaction outcome loss': 0.3018548589577709, 'Total loss': 0.3018548589577709}
2022-12-31 07:34:08,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:08,503 INFO:     Epoch: 9
2022-12-31 07:34:10,114 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43276301920413973, 'Total loss': 0.43276301920413973} | train loss {'Reaction outcome loss': 0.289142819026998, 'Total loss': 0.289142819026998}
2022-12-31 07:34:10,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:10,114 INFO:     Epoch: 10
2022-12-31 07:34:11,740 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4222174863020579, 'Total loss': 0.4222174863020579} | train loss {'Reaction outcome loss': 0.2807248382680658, 'Total loss': 0.2807248382680658}
2022-12-31 07:34:11,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:11,741 INFO:     Epoch: 11
2022-12-31 07:34:13,378 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4228431367004911, 'Total loss': 0.4228431367004911} | train loss {'Reaction outcome loss': 0.2657814302205014, 'Total loss': 0.2657814302205014}
2022-12-31 07:34:13,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:13,379 INFO:     Epoch: 12
2022-12-31 07:34:15,046 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4216774841149648, 'Total loss': 0.4216774841149648} | train loss {'Reaction outcome loss': 0.2539857938311574, 'Total loss': 0.2539857938311574}
2022-12-31 07:34:15,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:15,046 INFO:     Epoch: 13
2022-12-31 07:34:16,712 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4343918969233831, 'Total loss': 0.4343918969233831} | train loss {'Reaction outcome loss': 0.2444761669359413, 'Total loss': 0.2444761669359413}
2022-12-31 07:34:16,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:16,712 INFO:     Epoch: 14
2022-12-31 07:34:18,371 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4540385405222575, 'Total loss': 0.4540385405222575} | train loss {'Reaction outcome loss': 0.23542086874553259, 'Total loss': 0.23542086874553259}
2022-12-31 07:34:18,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:18,372 INFO:     Epoch: 15
2022-12-31 07:34:20,011 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43768916130065916, 'Total loss': 0.43768916130065916} | train loss {'Reaction outcome loss': 0.23295847335290434, 'Total loss': 0.23295847335290434}
2022-12-31 07:34:20,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:20,011 INFO:     Epoch: 16
2022-12-31 07:34:21,621 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4630171368519465, 'Total loss': 0.4630171368519465} | train loss {'Reaction outcome loss': 0.22168575039983768, 'Total loss': 0.22168575039983768}
2022-12-31 07:34:21,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:21,621 INFO:     Epoch: 17
2022-12-31 07:34:23,293 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46975857615470884, 'Total loss': 0.46975857615470884} | train loss {'Reaction outcome loss': 0.22211818294464677, 'Total loss': 0.22211818294464677}
2022-12-31 07:34:23,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:23,294 INFO:     Epoch: 18
2022-12-31 07:34:24,919 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44475142856438954, 'Total loss': 0.44475142856438954} | train loss {'Reaction outcome loss': 0.23249837645815444, 'Total loss': 0.23249837645815444}
2022-12-31 07:34:24,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:24,919 INFO:     Epoch: 19
2022-12-31 07:34:26,579 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4403442680835724, 'Total loss': 0.4403442680835724} | train loss {'Reaction outcome loss': 0.20576305274574924, 'Total loss': 0.20576305274574924}
2022-12-31 07:34:26,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:26,579 INFO:     Epoch: 20
2022-12-31 07:34:28,187 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4612276077270508, 'Total loss': 0.4612276077270508} | train loss {'Reaction outcome loss': 0.1992699107479142, 'Total loss': 0.1992699107479142}
2022-12-31 07:34:28,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:28,188 INFO:     Epoch: 21
2022-12-31 07:34:29,810 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48198144833246864, 'Total loss': 0.48198144833246864} | train loss {'Reaction outcome loss': 0.19537645408654233, 'Total loss': 0.19537645408654233}
2022-12-31 07:34:29,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:29,811 INFO:     Epoch: 22
2022-12-31 07:34:31,427 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4708397438128789, 'Total loss': 0.4708397438128789} | train loss {'Reaction outcome loss': 0.20649341329851228, 'Total loss': 0.20649341329851228}
2022-12-31 07:34:31,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:31,427 INFO:     Epoch: 23
2022-12-31 07:34:33,039 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46703174511591594, 'Total loss': 0.46703174511591594} | train loss {'Reaction outcome loss': 0.19020259540285106, 'Total loss': 0.19020259540285106}
2022-12-31 07:34:33,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:33,039 INFO:     Epoch: 24
2022-12-31 07:34:34,698 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.452365110317866, 'Total loss': 0.452365110317866} | train loss {'Reaction outcome loss': 0.18332775028935377, 'Total loss': 0.18332775028935377}
2022-12-31 07:34:34,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:34,698 INFO:     Epoch: 25
2022-12-31 07:34:36,357 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4911572108666102, 'Total loss': 0.4911572108666102} | train loss {'Reaction outcome loss': 0.17683776113899777, 'Total loss': 0.17683776113899777}
2022-12-31 07:34:36,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:36,358 INFO:     Epoch: 26
2022-12-31 07:34:37,962 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46847303708394367, 'Total loss': 0.46847303708394367} | train loss {'Reaction outcome loss': 0.17730321101059773, 'Total loss': 0.17730321101059773}
2022-12-31 07:34:37,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:37,962 INFO:     Epoch: 27
2022-12-31 07:34:39,574 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4639403240134319, 'Total loss': 0.4639403240134319} | train loss {'Reaction outcome loss': 0.17200495905590418, 'Total loss': 0.17200495905590418}
2022-12-31 07:34:39,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:39,574 INFO:     Epoch: 28
2022-12-31 07:34:41,184 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48340461353460945, 'Total loss': 0.48340461353460945} | train loss {'Reaction outcome loss': 0.1973077717297913, 'Total loss': 0.1973077717297913}
2022-12-31 07:34:41,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:41,184 INFO:     Epoch: 29
2022-12-31 07:34:42,844 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4614371607700984, 'Total loss': 0.4614371607700984} | train loss {'Reaction outcome loss': 0.17272773523480914, 'Total loss': 0.17272773523480914}
2022-12-31 07:34:42,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:42,845 INFO:     Epoch: 30
2022-12-31 07:34:44,464 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49286647538344064, 'Total loss': 0.49286647538344064} | train loss {'Reaction outcome loss': 0.17134658211432616, 'Total loss': 0.17134658211432616}
2022-12-31 07:34:44,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:44,464 INFO:     Epoch: 31
2022-12-31 07:34:46,124 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4596615477775534, 'Total loss': 0.4596615477775534} | train loss {'Reaction outcome loss': 0.1644997366566331, 'Total loss': 0.1644997366566331}
2022-12-31 07:34:46,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:46,124 INFO:     Epoch: 32
2022-12-31 07:34:47,742 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4878096769253413, 'Total loss': 0.4878096769253413} | train loss {'Reaction outcome loss': 0.16233451544953362, 'Total loss': 0.16233451544953362}
2022-12-31 07:34:47,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:47,743 INFO:     Epoch: 33
2022-12-31 07:34:49,381 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4794952983657519, 'Total loss': 0.4794952983657519} | train loss {'Reaction outcome loss': 0.16138618342823896, 'Total loss': 0.16138618342823896}
2022-12-31 07:34:49,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:49,381 INFO:     Epoch: 34
2022-12-31 07:34:51,042 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4964806318283081, 'Total loss': 0.4964806318283081} | train loss {'Reaction outcome loss': 0.1593661139849101, 'Total loss': 0.1593661139849101}
2022-12-31 07:34:51,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:51,042 INFO:     Epoch: 35
2022-12-31 07:34:52,655 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4621754308541616, 'Total loss': 0.4621754308541616} | train loss {'Reaction outcome loss': 0.1566113663907806, 'Total loss': 0.1566113663907806}
2022-12-31 07:34:52,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:52,656 INFO:     Epoch: 36
2022-12-31 07:34:54,316 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5107581635316213, 'Total loss': 0.5107581635316213} | train loss {'Reaction outcome loss': 0.15767844578089274, 'Total loss': 0.15767844578089274}
2022-12-31 07:34:54,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:54,317 INFO:     Epoch: 37
2022-12-31 07:34:55,967 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4602793042858442, 'Total loss': 0.4602793042858442} | train loss {'Reaction outcome loss': 0.1650447247840297, 'Total loss': 0.1650447247840297}
2022-12-31 07:34:55,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:55,967 INFO:     Epoch: 38
2022-12-31 07:34:57,579 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49509161015351616, 'Total loss': 0.49509161015351616} | train loss {'Reaction outcome loss': 0.15800752333007698, 'Total loss': 0.15800752333007698}
2022-12-31 07:34:57,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:57,580 INFO:     Epoch: 39
2022-12-31 07:34:59,198 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47391265630722046, 'Total loss': 0.47391265630722046} | train loss {'Reaction outcome loss': 0.15390886976113677, 'Total loss': 0.15390886976113677}
2022-12-31 07:34:59,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:34:59,199 INFO:     Epoch: 40
2022-12-31 07:35:00,858 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4730972995360692, 'Total loss': 0.4730972995360692} | train loss {'Reaction outcome loss': 0.1507126008384545, 'Total loss': 0.1507126008384545}
2022-12-31 07:35:00,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:00,859 INFO:     Epoch: 41
2022-12-31 07:35:02,474 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48519423405329387, 'Total loss': 0.48519423405329387} | train loss {'Reaction outcome loss': 0.15149472588759175, 'Total loss': 0.15149472588759175}
2022-12-31 07:35:02,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:02,474 INFO:     Epoch: 42
2022-12-31 07:35:04,093 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4742639511823654, 'Total loss': 0.4742639511823654} | train loss {'Reaction outcome loss': 0.15747500693702232, 'Total loss': 0.15747500693702232}
2022-12-31 07:35:04,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:04,093 INFO:     Epoch: 43
2022-12-31 07:35:05,711 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4821416060129801, 'Total loss': 0.4821416060129801} | train loss {'Reaction outcome loss': 0.1746348663371569, 'Total loss': 0.1746348663371569}
2022-12-31 07:35:05,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:05,712 INFO:     Epoch: 44
2022-12-31 07:35:07,328 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48608589470386504, 'Total loss': 0.48608589470386504} | train loss {'Reaction outcome loss': 0.14935698682793241, 'Total loss': 0.14935698682793241}
2022-12-31 07:35:07,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:07,328 INFO:     Epoch: 45
2022-12-31 07:35:08,991 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49640557964642845, 'Total loss': 0.49640557964642845} | train loss {'Reaction outcome loss': 0.14447998167083098, 'Total loss': 0.14447998167083098}
2022-12-31 07:35:08,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:08,992 INFO:     Epoch: 46
2022-12-31 07:35:10,613 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4944516619046529, 'Total loss': 0.4944516619046529} | train loss {'Reaction outcome loss': 0.14187417645513525, 'Total loss': 0.14187417645513525}
2022-12-31 07:35:10,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:10,613 INFO:     Epoch: 47
2022-12-31 07:35:12,233 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4984431862831116, 'Total loss': 0.4984431862831116} | train loss {'Reaction outcome loss': 0.14004477276804222, 'Total loss': 0.14004477276804222}
2022-12-31 07:35:12,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:12,233 INFO:     Epoch: 48
2022-12-31 07:35:13,851 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4946126292149226, 'Total loss': 0.4946126292149226} | train loss {'Reaction outcome loss': 0.14180027016276575, 'Total loss': 0.14180027016276575}
2022-12-31 07:35:13,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:13,852 INFO:     Epoch: 49
2022-12-31 07:35:15,464 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5159897983074189, 'Total loss': 0.5159897983074189} | train loss {'Reaction outcome loss': 0.15099771233445095, 'Total loss': 0.15099771233445095}
2022-12-31 07:35:15,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:15,464 INFO:     Epoch: 50
2022-12-31 07:35:17,089 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5053934395313263, 'Total loss': 0.5053934395313263} | train loss {'Reaction outcome loss': 0.13490745731278497, 'Total loss': 0.13490745731278497}
2022-12-31 07:35:17,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:17,090 INFO:     Epoch: 51
2022-12-31 07:35:18,752 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4980407724777857, 'Total loss': 0.4980407724777857} | train loss {'Reaction outcome loss': 0.13447263303712226, 'Total loss': 0.13447263303712226}
2022-12-31 07:35:18,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:18,752 INFO:     Epoch: 52
2022-12-31 07:35:20,367 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45732618172963463, 'Total loss': 0.45732618172963463} | train loss {'Reaction outcome loss': 0.13819075651811188, 'Total loss': 0.13819075651811188}
2022-12-31 07:35:20,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:20,367 INFO:     Epoch: 53
2022-12-31 07:35:22,027 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4756060962254802, 'Total loss': 0.4756060962254802} | train loss {'Reaction outcome loss': 0.13545277073221834, 'Total loss': 0.13545277073221834}
2022-12-31 07:35:22,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:22,028 INFO:     Epoch: 54
2022-12-31 07:35:23,661 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4948373814423879, 'Total loss': 0.4948373814423879} | train loss {'Reaction outcome loss': 0.13324931944362764, 'Total loss': 0.13324931944362764}
2022-12-31 07:35:23,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:23,662 INFO:     Epoch: 55
2022-12-31 07:35:25,282 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49659957488377887, 'Total loss': 0.49659957488377887} | train loss {'Reaction outcome loss': 0.13435456172594745, 'Total loss': 0.13435456172594745}
2022-12-31 07:35:25,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:25,284 INFO:     Epoch: 56
2022-12-31 07:35:26,930 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48556068738301594, 'Total loss': 0.48556068738301594} | train loss {'Reaction outcome loss': 0.1317010863011362, 'Total loss': 0.1317010863011362}
2022-12-31 07:35:26,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:26,930 INFO:     Epoch: 57
2022-12-31 07:35:28,592 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5068711052338283, 'Total loss': 0.5068711052338283} | train loss {'Reaction outcome loss': 0.1288078861202255, 'Total loss': 0.1288078861202255}
2022-12-31 07:35:28,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:28,592 INFO:     Epoch: 58
2022-12-31 07:35:30,209 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49252980947494507, 'Total loss': 0.49252980947494507} | train loss {'Reaction outcome loss': 0.12766335726184375, 'Total loss': 0.12766335726184375}
2022-12-31 07:35:30,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:30,210 INFO:     Epoch: 59
2022-12-31 07:35:31,871 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4904183357954025, 'Total loss': 0.4904183357954025} | train loss {'Reaction outcome loss': 0.13154100335415694, 'Total loss': 0.13154100335415694}
2022-12-31 07:35:31,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:31,872 INFO:     Epoch: 60
2022-12-31 07:35:33,506 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5375491827726364, 'Total loss': 0.5375491827726364} | train loss {'Reaction outcome loss': 0.13115044937644532, 'Total loss': 0.13115044937644532}
2022-12-31 07:35:33,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:33,506 INFO:     Epoch: 61
2022-12-31 07:35:35,119 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48507823993762333, 'Total loss': 0.48507823993762333} | train loss {'Reaction outcome loss': 0.13153771871358017, 'Total loss': 0.13153771871358017}
2022-12-31 07:35:35,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:35,120 INFO:     Epoch: 62
2022-12-31 07:35:36,740 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4681732565164566, 'Total loss': 0.4681732565164566} | train loss {'Reaction outcome loss': 0.12895805416564396, 'Total loss': 0.12895805416564396}
2022-12-31 07:35:36,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:36,740 INFO:     Epoch: 63
2022-12-31 07:35:38,359 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5222503681977589, 'Total loss': 0.5222503681977589} | train loss {'Reaction outcome loss': 0.12800324596194684, 'Total loss': 0.12800324596194684}
2022-12-31 07:35:38,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:38,359 INFO:     Epoch: 64
2022-12-31 07:35:39,978 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49615604877471925, 'Total loss': 0.49615604877471925} | train loss {'Reaction outcome loss': 0.1269714522101255, 'Total loss': 0.1269714522101255}
2022-12-31 07:35:39,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:39,978 INFO:     Epoch: 65
2022-12-31 07:35:41,590 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4772055367628733, 'Total loss': 0.4772055367628733} | train loss {'Reaction outcome loss': 0.12445227872197301, 'Total loss': 0.12445227872197301}
2022-12-31 07:35:41,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:41,590 INFO:     Epoch: 66
2022-12-31 07:35:43,209 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5123785177866618, 'Total loss': 0.5123785177866618} | train loss {'Reaction outcome loss': 0.12674664022853138, 'Total loss': 0.12674664022853138}
2022-12-31 07:35:43,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:43,209 INFO:     Epoch: 67
2022-12-31 07:35:44,819 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4973466416200002, 'Total loss': 0.4973466416200002} | train loss {'Reaction outcome loss': 0.13905898835055533, 'Total loss': 0.13905898835055533}
2022-12-31 07:35:44,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:44,820 INFO:     Epoch: 68
2022-12-31 07:35:46,438 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49070585568745934, 'Total loss': 0.49070585568745934} | train loss {'Reaction outcome loss': 0.12614835450675446, 'Total loss': 0.12614835450675446}
2022-12-31 07:35:46,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:46,438 INFO:     Epoch: 69
2022-12-31 07:35:48,050 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4897198051214218, 'Total loss': 0.4897198051214218} | train loss {'Reaction outcome loss': 0.1241884869506211, 'Total loss': 0.1241884869506211}
2022-12-31 07:35:48,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:48,050 INFO:     Epoch: 70
2022-12-31 07:35:49,667 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48568913886944454, 'Total loss': 0.48568913886944454} | train loss {'Reaction outcome loss': 0.12064149656815562, 'Total loss': 0.12064149656815562}
2022-12-31 07:35:49,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:49,667 INFO:     Epoch: 71
2022-12-31 07:35:51,279 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4696961537003517, 'Total loss': 0.4696961537003517} | train loss {'Reaction outcome loss': 0.12112156376390529, 'Total loss': 0.12112156376390529}
2022-12-31 07:35:51,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:51,279 INFO:     Epoch: 72
2022-12-31 07:35:52,923 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49472613831361134, 'Total loss': 0.49472613831361134} | train loss {'Reaction outcome loss': 0.12210872742951429, 'Total loss': 0.12210872742951429}
2022-12-31 07:35:52,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:52,924 INFO:     Epoch: 73
2022-12-31 07:35:54,538 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4875316709280014, 'Total loss': 0.4875316709280014} | train loss {'Reaction outcome loss': 0.12627564463753885, 'Total loss': 0.12627564463753885}
2022-12-31 07:35:54,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:54,538 INFO:     Epoch: 74
2022-12-31 07:35:56,199 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4689200888077418, 'Total loss': 0.4689200888077418} | train loss {'Reaction outcome loss': 0.12265405462602612, 'Total loss': 0.12265405462602612}
2022-12-31 07:35:56,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:56,200 INFO:     Epoch: 75
2022-12-31 07:35:57,813 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5330623944600423, 'Total loss': 0.5330623944600423} | train loss {'Reaction outcome loss': 0.12320348615901532, 'Total loss': 0.12320348615901532}
2022-12-31 07:35:57,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:57,813 INFO:     Epoch: 76
2022-12-31 07:35:59,459 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4993824621041616, 'Total loss': 0.4993824621041616} | train loss {'Reaction outcome loss': 0.1228625576070466, 'Total loss': 0.1228625576070466}
2022-12-31 07:35:59,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:35:59,459 INFO:     Epoch: 77
2022-12-31 07:36:01,119 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.533903710047404, 'Total loss': 0.533903710047404} | train loss {'Reaction outcome loss': 0.12090884200855119, 'Total loss': 0.12090884200855119}
2022-12-31 07:36:01,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:01,120 INFO:     Epoch: 78
2022-12-31 07:36:02,745 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4894448722402255, 'Total loss': 0.4894448722402255} | train loss {'Reaction outcome loss': 0.12104382328760803, 'Total loss': 0.12104382328760803}
2022-12-31 07:36:02,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:02,746 INFO:     Epoch: 79
2022-12-31 07:36:04,364 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5184509515762329, 'Total loss': 0.5184509515762329} | train loss {'Reaction outcome loss': 0.12356507575421584, 'Total loss': 0.12356507575421584}
2022-12-31 07:36:04,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:04,364 INFO:     Epoch: 80
2022-12-31 07:36:05,982 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48679195791482927, 'Total loss': 0.48679195791482927} | train loss {'Reaction outcome loss': 0.11715872806625144, 'Total loss': 0.11715872806625144}
2022-12-31 07:36:05,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:05,982 INFO:     Epoch: 81
2022-12-31 07:36:07,600 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5072495236992836, 'Total loss': 0.5072495236992836} | train loss {'Reaction outcome loss': 0.11752869195492088, 'Total loss': 0.11752869195492088}
2022-12-31 07:36:07,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:07,600 INFO:     Epoch: 82
2022-12-31 07:36:09,233 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4906854887803396, 'Total loss': 0.4906854887803396} | train loss {'Reaction outcome loss': 0.12058719572029164, 'Total loss': 0.12058719572029164}
2022-12-31 07:36:09,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:09,233 INFO:     Epoch: 83
2022-12-31 07:36:10,895 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5103423217932384, 'Total loss': 0.5103423217932384} | train loss {'Reaction outcome loss': 0.12239526320810738, 'Total loss': 0.12239526320810738}
2022-12-31 07:36:10,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:10,895 INFO:     Epoch: 84
2022-12-31 07:36:12,506 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4948755860328674, 'Total loss': 0.4948755860328674} | train loss {'Reaction outcome loss': 0.11987083091309245, 'Total loss': 0.11987083091309245}
2022-12-31 07:36:12,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:12,506 INFO:     Epoch: 85
2022-12-31 07:36:14,168 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.504735474785169, 'Total loss': 0.504735474785169} | train loss {'Reaction outcome loss': 0.11581195739394837, 'Total loss': 0.11581195739394837}
2022-12-31 07:36:14,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:14,168 INFO:     Epoch: 86
2022-12-31 07:36:15,787 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5112931807835897, 'Total loss': 0.5112931807835897} | train loss {'Reaction outcome loss': 0.11983107205837175, 'Total loss': 0.11983107205837175}
2022-12-31 07:36:15,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:15,788 INFO:     Epoch: 87
2022-12-31 07:36:17,400 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49257720907529196, 'Total loss': 0.49257720907529196} | train loss {'Reaction outcome loss': 0.11880732880208465, 'Total loss': 0.11880732880208465}
2022-12-31 07:36:17,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:17,400 INFO:     Epoch: 88
2022-12-31 07:36:19,013 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49839264849821724, 'Total loss': 0.49839264849821724} | train loss {'Reaction outcome loss': 0.11994288939614847, 'Total loss': 0.11994288939614847}
2022-12-31 07:36:19,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:19,013 INFO:     Epoch: 89
2022-12-31 07:36:20,638 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.529637998342514, 'Total loss': 0.529637998342514} | train loss {'Reaction outcome loss': 0.11914208851627284, 'Total loss': 0.11914208851627284}
2022-12-31 07:36:20,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:20,638 INFO:     Epoch: 90
2022-12-31 07:36:22,298 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4746034532785416, 'Total loss': 0.4746034532785416} | train loss {'Reaction outcome loss': 0.12527279148681386, 'Total loss': 0.12527279148681386}
2022-12-31 07:36:22,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:22,298 INFO:     Epoch: 91
2022-12-31 07:36:23,916 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5088068395853043, 'Total loss': 0.5088068395853043} | train loss {'Reaction outcome loss': 0.11651542491913922, 'Total loss': 0.11651542491913922}
2022-12-31 07:36:23,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:23,916 INFO:     Epoch: 92
2022-12-31 07:36:25,577 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48619176745414733, 'Total loss': 0.48619176745414733} | train loss {'Reaction outcome loss': 0.11392243704123783, 'Total loss': 0.11392243704123783}
2022-12-31 07:36:25,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:25,577 INFO:     Epoch: 93
2022-12-31 07:36:27,183 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4669352223475774, 'Total loss': 0.4669352223475774} | train loss {'Reaction outcome loss': 0.11587466600600316, 'Total loss': 0.11587466600600316}
2022-12-31 07:36:27,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:27,183 INFO:     Epoch: 94
2022-12-31 07:36:28,806 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5181223372618358, 'Total loss': 0.5181223372618358} | train loss {'Reaction outcome loss': 0.11416932459131045, 'Total loss': 0.11416932459131045}
2022-12-31 07:36:28,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:28,806 INFO:     Epoch: 95
2022-12-31 07:36:30,419 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.502588594208161, 'Total loss': 0.502588594208161} | train loss {'Reaction outcome loss': 0.1214588759844512, 'Total loss': 0.1214588759844512}
2022-12-31 07:36:30,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:30,419 INFO:     Epoch: 96
2022-12-31 07:36:32,040 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48190560936927795, 'Total loss': 0.48190560936927795} | train loss {'Reaction outcome loss': 0.11883655005215626, 'Total loss': 0.11883655005215626}
2022-12-31 07:36:32,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:32,042 INFO:     Epoch: 97
2022-12-31 07:36:33,662 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5299521818757057, 'Total loss': 0.5299521818757057} | train loss {'Reaction outcome loss': 0.11434161743280762, 'Total loss': 0.11434161743280762}
2022-12-31 07:36:33,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:33,662 INFO:     Epoch: 98
2022-12-31 07:36:35,284 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5321790635585785, 'Total loss': 0.5321790635585785} | train loss {'Reaction outcome loss': 0.11681956110942997, 'Total loss': 0.11681956110942997}
2022-12-31 07:36:35,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:35,284 INFO:     Epoch: 99
2022-12-31 07:36:36,924 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5097909847895304, 'Total loss': 0.5097909847895304} | train loss {'Reaction outcome loss': 0.1126052622642854, 'Total loss': 0.1126052622642854}
2022-12-31 07:36:36,924 INFO:     Best model found after epoch 8 of 100.
2022-12-31 07:36:36,924 INFO:   Done with stage: TRAINING
2022-12-31 07:36:36,924 INFO:   Starting stage: EVALUATION
2022-12-31 07:36:37,055 INFO:   Done with stage: EVALUATION
2022-12-31 07:36:37,055 INFO:   Leaving out SEQ value Fold_8
2022-12-31 07:36:37,068 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 07:36:37,068 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:36:37,717 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:36:37,718 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:36:37,785 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:36:37,785 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:36:37,785 INFO:     No hyperparam tuning for this model
2022-12-31 07:36:37,785 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:36:37,785 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:36:37,786 INFO:     None feature selector for col prot
2022-12-31 07:36:37,786 INFO:     None feature selector for col prot
2022-12-31 07:36:37,786 INFO:     None feature selector for col prot
2022-12-31 07:36:37,787 INFO:     None feature selector for col chem
2022-12-31 07:36:37,787 INFO:     None feature selector for col chem
2022-12-31 07:36:37,787 INFO:     None feature selector for col chem
2022-12-31 07:36:37,787 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:36:37,787 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:36:37,789 INFO:     Number of params in model 224011
2022-12-31 07:36:37,792 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:36:37,792 INFO:   Starting stage: TRAINING
2022-12-31 07:36:37,837 INFO:     Val loss before train {'Reaction outcome loss': 1.078869112332662, 'Total loss': 1.078869112332662}
2022-12-31 07:36:37,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:37,837 INFO:     Epoch: 0
2022-12-31 07:36:39,451 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5928105135758718, 'Total loss': 0.5928105135758718} | train loss {'Reaction outcome loss': 0.7728622120532749, 'Total loss': 0.7728622120532749}
2022-12-31 07:36:39,452 INFO:     Found new best model at epoch 0
2022-12-31 07:36:39,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:39,453 INFO:     Epoch: 1
2022-12-31 07:36:41,079 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.531254643201828, 'Total loss': 0.531254643201828} | train loss {'Reaction outcome loss': 0.5061565809193931, 'Total loss': 0.5061565809193931}
2022-12-31 07:36:41,079 INFO:     Found new best model at epoch 1
2022-12-31 07:36:41,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:41,080 INFO:     Epoch: 2
2022-12-31 07:36:42,704 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5104594687620799, 'Total loss': 0.5104594687620799} | train loss {'Reaction outcome loss': 0.4394561276646728, 'Total loss': 0.4394561276646728}
2022-12-31 07:36:42,704 INFO:     Found new best model at epoch 2
2022-12-31 07:36:42,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:42,705 INFO:     Epoch: 3
2022-12-31 07:36:44,330 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4956629057725271, 'Total loss': 0.4956629057725271} | train loss {'Reaction outcome loss': 0.39765105436855275, 'Total loss': 0.39765105436855275}
2022-12-31 07:36:44,331 INFO:     Found new best model at epoch 3
2022-12-31 07:36:44,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:44,332 INFO:     Epoch: 4
2022-12-31 07:36:45,948 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5091008186340332, 'Total loss': 0.5091008186340332} | train loss {'Reaction outcome loss': 0.3682457395839347, 'Total loss': 0.3682457395839347}
2022-12-31 07:36:45,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:45,949 INFO:     Epoch: 5
2022-12-31 07:36:47,589 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4619828850030899, 'Total loss': 0.4619828850030899} | train loss {'Reaction outcome loss': 0.3473387518998518, 'Total loss': 0.3473387518998518}
2022-12-31 07:36:47,590 INFO:     Found new best model at epoch 5
2022-12-31 07:36:47,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:47,591 INFO:     Epoch: 6
2022-12-31 07:36:49,220 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4956344832976659, 'Total loss': 0.4956344832976659} | train loss {'Reaction outcome loss': 0.3239741627436252, 'Total loss': 0.3239741627436252}
2022-12-31 07:36:49,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:49,220 INFO:     Epoch: 7
2022-12-31 07:36:50,852 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4907349020242691, 'Total loss': 0.4907349020242691} | train loss {'Reaction outcome loss': 0.308575449840902, 'Total loss': 0.308575449840902}
2022-12-31 07:36:50,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:50,853 INFO:     Epoch: 8
2022-12-31 07:36:52,488 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5099126160144806, 'Total loss': 0.5099126160144806} | train loss {'Reaction outcome loss': 0.29409421445122697, 'Total loss': 0.29409421445122697}
2022-12-31 07:36:52,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:52,489 INFO:     Epoch: 9
2022-12-31 07:36:54,126 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5000403602917989, 'Total loss': 0.5000403602917989} | train loss {'Reaction outcome loss': 0.28254896526087064, 'Total loss': 0.28254896526087064}
2022-12-31 07:36:54,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:54,126 INFO:     Epoch: 10
2022-12-31 07:36:55,792 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5323691795269648, 'Total loss': 0.5323691795269648} | train loss {'Reaction outcome loss': 0.2698102694556171, 'Total loss': 0.2698102694556171}
2022-12-31 07:36:55,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:55,792 INFO:     Epoch: 11
2022-12-31 07:36:57,421 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5213607430458069, 'Total loss': 0.5213607430458069} | train loss {'Reaction outcome loss': 0.26277458242776164, 'Total loss': 0.26277458242776164}
2022-12-31 07:36:57,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:57,421 INFO:     Epoch: 12
2022-12-31 07:36:59,056 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5224424918492635, 'Total loss': 0.5224424918492635} | train loss {'Reaction outcome loss': 0.24766759077483783, 'Total loss': 0.24766759077483783}
2022-12-31 07:36:59,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:36:59,056 INFO:     Epoch: 13
2022-12-31 07:37:00,691 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49284087618192035, 'Total loss': 0.49284087618192035} | train loss {'Reaction outcome loss': 0.23800092681381677, 'Total loss': 0.23800092681381677}
2022-12-31 07:37:00,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:00,692 INFO:     Epoch: 14
2022-12-31 07:37:02,324 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5142018973827363, 'Total loss': 0.5142018973827363} | train loss {'Reaction outcome loss': 0.22948788750634297, 'Total loss': 0.22948788750634297}
2022-12-31 07:37:02,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:02,324 INFO:     Epoch: 15
2022-12-31 07:37:03,976 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5482400218645732, 'Total loss': 0.5482400218645732} | train loss {'Reaction outcome loss': 0.22201128328212333, 'Total loss': 0.22201128328212333}
2022-12-31 07:37:03,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:03,976 INFO:     Epoch: 16
2022-12-31 07:37:05,625 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5049530903498332, 'Total loss': 0.5049530903498332} | train loss {'Reaction outcome loss': 0.21758428291293258, 'Total loss': 0.21758428291293258}
2022-12-31 07:37:05,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:05,625 INFO:     Epoch: 17
2022-12-31 07:37:07,264 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5229079405466716, 'Total loss': 0.5229079405466716} | train loss {'Reaction outcome loss': 0.2155961119015079, 'Total loss': 0.2155961119015079}
2022-12-31 07:37:07,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:07,265 INFO:     Epoch: 18
2022-12-31 07:37:08,901 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5418862124284108, 'Total loss': 0.5418862124284108} | train loss {'Reaction outcome loss': 0.20567017597304355, 'Total loss': 0.20567017597304355}
2022-12-31 07:37:08,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:08,901 INFO:     Epoch: 19
2022-12-31 07:37:10,537 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5179962406555811, 'Total loss': 0.5179962406555811} | train loss {'Reaction outcome loss': 0.2026860603477658, 'Total loss': 0.2026860603477658}
2022-12-31 07:37:10,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:10,538 INFO:     Epoch: 20
2022-12-31 07:37:12,166 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.547329451640447, 'Total loss': 0.547329451640447} | train loss {'Reaction outcome loss': 0.1920732712366413, 'Total loss': 0.1920732712366413}
2022-12-31 07:37:12,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:12,166 INFO:     Epoch: 21
2022-12-31 07:37:13,805 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5321777651707331, 'Total loss': 0.5321777651707331} | train loss {'Reaction outcome loss': 0.19218344833123555, 'Total loss': 0.19218344833123555}
2022-12-31 07:37:13,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:13,806 INFO:     Epoch: 22
2022-12-31 07:37:15,433 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5393462876478831, 'Total loss': 0.5393462876478831} | train loss {'Reaction outcome loss': 0.18545394390149023, 'Total loss': 0.18545394390149023}
2022-12-31 07:37:15,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:15,433 INFO:     Epoch: 23
2022-12-31 07:37:17,071 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.504594357808431, 'Total loss': 0.504594357808431} | train loss {'Reaction outcome loss': 0.17947667643145426, 'Total loss': 0.17947667643145426}
2022-12-31 07:37:17,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:17,071 INFO:     Epoch: 24
2022-12-31 07:37:18,693 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5027698894341787, 'Total loss': 0.5027698894341787} | train loss {'Reaction outcome loss': 0.18062644989804671, 'Total loss': 0.18062644989804671}
2022-12-31 07:37:18,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:18,693 INFO:     Epoch: 25
2022-12-31 07:37:20,330 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4997887392838796, 'Total loss': 0.4997887392838796} | train loss {'Reaction outcome loss': 0.17410521806362303, 'Total loss': 0.17410521806362303}
2022-12-31 07:37:20,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:20,330 INFO:     Epoch: 26
2022-12-31 07:37:21,958 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5210931797822317, 'Total loss': 0.5210931797822317} | train loss {'Reaction outcome loss': 0.16916893388309417, 'Total loss': 0.16916893388309417}
2022-12-31 07:37:21,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:21,958 INFO:     Epoch: 27
2022-12-31 07:37:23,583 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5064231038093567, 'Total loss': 0.5064231038093567} | train loss {'Reaction outcome loss': 0.16903706803406834, 'Total loss': 0.16903706803406834}
2022-12-31 07:37:23,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:23,583 INFO:     Epoch: 28
2022-12-31 07:37:25,219 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5437405129273732, 'Total loss': 0.5437405129273732} | train loss {'Reaction outcome loss': 0.16488773109801516, 'Total loss': 0.16488773109801516}
2022-12-31 07:37:25,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:25,219 INFO:     Epoch: 29
2022-12-31 07:37:26,856 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5283897409836451, 'Total loss': 0.5283897409836451} | train loss {'Reaction outcome loss': 0.16661672399039734, 'Total loss': 0.16661672399039734}
2022-12-31 07:37:26,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:26,857 INFO:     Epoch: 30
2022-12-31 07:37:28,492 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.500887378056844, 'Total loss': 0.500887378056844} | train loss {'Reaction outcome loss': 0.15944195887753035, 'Total loss': 0.15944195887753035}
2022-12-31 07:37:28,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:28,493 INFO:     Epoch: 31
2022-12-31 07:37:30,114 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47131028498212496, 'Total loss': 0.47131028498212496} | train loss {'Reaction outcome loss': 0.15640505847423622, 'Total loss': 0.15640505847423622}
2022-12-31 07:37:30,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:30,114 INFO:     Epoch: 32
2022-12-31 07:37:31,745 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5058515548706055, 'Total loss': 0.5058515548706055} | train loss {'Reaction outcome loss': 0.15426135984407435, 'Total loss': 0.15426135984407435}
2022-12-31 07:37:31,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:31,745 INFO:     Epoch: 33
2022-12-31 07:37:33,361 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.522555007537206, 'Total loss': 0.522555007537206} | train loss {'Reaction outcome loss': 0.15383834664504772, 'Total loss': 0.15383834664504772}
2022-12-31 07:37:33,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:33,362 INFO:     Epoch: 34
2022-12-31 07:37:34,995 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5271336456139882, 'Total loss': 0.5271336456139882} | train loss {'Reaction outcome loss': 0.14971923266809822, 'Total loss': 0.14971923266809822}
2022-12-31 07:37:34,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:34,995 INFO:     Epoch: 35
2022-12-31 07:37:36,629 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4971765468517939, 'Total loss': 0.4971765468517939} | train loss {'Reaction outcome loss': 0.1481977892595777, 'Total loss': 0.1481977892595777}
2022-12-31 07:37:36,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:36,629 INFO:     Epoch: 36
2022-12-31 07:37:38,262 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5408507118622462, 'Total loss': 0.5408507118622462} | train loss {'Reaction outcome loss': 0.1468457065603363, 'Total loss': 0.1468457065603363}
2022-12-31 07:37:38,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:38,263 INFO:     Epoch: 37
2022-12-31 07:37:39,890 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5029878102242946, 'Total loss': 0.5029878102242946} | train loss {'Reaction outcome loss': 0.1488396044894515, 'Total loss': 0.1488396044894515}
2022-12-31 07:37:39,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:39,890 INFO:     Epoch: 38
2022-12-31 07:37:41,525 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5171941389640172, 'Total loss': 0.5171941389640172} | train loss {'Reaction outcome loss': 0.14547522911727967, 'Total loss': 0.14547522911727967}
2022-12-31 07:37:41,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:41,525 INFO:     Epoch: 39
2022-12-31 07:37:43,142 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5004952510197958, 'Total loss': 0.5004952510197958} | train loss {'Reaction outcome loss': 0.1427613270371507, 'Total loss': 0.1427613270371507}
2022-12-31 07:37:43,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:43,142 INFO:     Epoch: 40
2022-12-31 07:37:44,809 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4852101037899653, 'Total loss': 0.4852101037899653} | train loss {'Reaction outcome loss': 0.1412221604642132, 'Total loss': 0.1412221604642132}
2022-12-31 07:37:44,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:44,810 INFO:     Epoch: 41
2022-12-31 07:37:46,436 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5200049012899399, 'Total loss': 0.5200049012899399} | train loss {'Reaction outcome loss': 0.13834359658552528, 'Total loss': 0.13834359658552528}
2022-12-31 07:37:46,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:46,436 INFO:     Epoch: 42
2022-12-31 07:37:48,053 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5027625372012456, 'Total loss': 0.5027625372012456} | train loss {'Reaction outcome loss': 0.1343930654062987, 'Total loss': 0.1343930654062987}
2022-12-31 07:37:48,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:48,054 INFO:     Epoch: 43
2022-12-31 07:37:49,660 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5135327696800231, 'Total loss': 0.5135327696800231} | train loss {'Reaction outcome loss': 0.13874591822443455, 'Total loss': 0.13874591822443455}
2022-12-31 07:37:49,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:49,660 INFO:     Epoch: 44
2022-12-31 07:37:51,302 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5291917741298675, 'Total loss': 0.5291917741298675} | train loss {'Reaction outcome loss': 0.13378709523067792, 'Total loss': 0.13378709523067792}
2022-12-31 07:37:51,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:51,302 INFO:     Epoch: 45
2022-12-31 07:37:52,939 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5250793486833573, 'Total loss': 0.5250793486833573} | train loss {'Reaction outcome loss': 0.1353677181839701, 'Total loss': 0.1353677181839701}
2022-12-31 07:37:52,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:52,939 INFO:     Epoch: 46
2022-12-31 07:37:54,573 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4980193302035332, 'Total loss': 0.4980193302035332} | train loss {'Reaction outcome loss': 0.13304912907135294, 'Total loss': 0.13304912907135294}
2022-12-31 07:37:54,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:54,573 INFO:     Epoch: 47
2022-12-31 07:37:56,208 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5400715549786885, 'Total loss': 0.5400715549786885} | train loss {'Reaction outcome loss': 0.12926576174593898, 'Total loss': 0.12926576174593898}
2022-12-31 07:37:56,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:56,208 INFO:     Epoch: 48
2022-12-31 07:37:57,835 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5429506123065948, 'Total loss': 0.5429506123065948} | train loss {'Reaction outcome loss': 0.1299132542240867, 'Total loss': 0.1299132542240867}
2022-12-31 07:37:57,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:57,836 INFO:     Epoch: 49
2022-12-31 07:37:59,472 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5247988477349281, 'Total loss': 0.5247988477349281} | train loss {'Reaction outcome loss': 0.12924269813412148, 'Total loss': 0.12924269813412148}
2022-12-31 07:37:59,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:37:59,472 INFO:     Epoch: 50
2022-12-31 07:38:01,098 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4995121876398722, 'Total loss': 0.4995121876398722} | train loss {'Reaction outcome loss': 0.12975885909023804, 'Total loss': 0.12975885909023804}
2022-12-31 07:38:01,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:01,098 INFO:     Epoch: 51
2022-12-31 07:38:02,735 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.509750068684419, 'Total loss': 0.509750068684419} | train loss {'Reaction outcome loss': 0.12977180613157765, 'Total loss': 0.12977180613157765}
2022-12-31 07:38:02,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:02,735 INFO:     Epoch: 52
2022-12-31 07:38:04,370 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5164693146944046, 'Total loss': 0.5164693146944046} | train loss {'Reaction outcome loss': 0.12800298904536112, 'Total loss': 0.12800298904536112}
2022-12-31 07:38:04,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:04,371 INFO:     Epoch: 53
2022-12-31 07:38:06,002 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5183236171801885, 'Total loss': 0.5183236171801885} | train loss {'Reaction outcome loss': 0.1310730752491456, 'Total loss': 0.1310730752491456}
2022-12-31 07:38:06,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:06,003 INFO:     Epoch: 54
2022-12-31 07:38:07,210 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.522543928027153, 'Total loss': 0.522543928027153} | train loss {'Reaction outcome loss': 0.12899341014808965, 'Total loss': 0.12899341014808965}
2022-12-31 07:38:07,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:07,210 INFO:     Epoch: 55
2022-12-31 07:38:08,368 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5359630127747853, 'Total loss': 0.5359630127747853} | train loss {'Reaction outcome loss': 0.12445201990883864, 'Total loss': 0.12445201990883864}
2022-12-31 07:38:08,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:08,369 INFO:     Epoch: 56
2022-12-31 07:38:09,483 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5081989765167236, 'Total loss': 0.5081989765167236} | train loss {'Reaction outcome loss': 0.12649417100373372, 'Total loss': 0.12649417100373372}
2022-12-31 07:38:09,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:09,483 INFO:     Epoch: 57
2022-12-31 07:38:10,594 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5290046254793803, 'Total loss': 0.5290046254793803} | train loss {'Reaction outcome loss': 0.12447602157430582, 'Total loss': 0.12447602157430582}
2022-12-31 07:38:10,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:10,595 INFO:     Epoch: 58
2022-12-31 07:38:12,123 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.523314877351125, 'Total loss': 0.523314877351125} | train loss {'Reaction outcome loss': 0.12200992474742638, 'Total loss': 0.12200992474742638}
2022-12-31 07:38:12,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:12,124 INFO:     Epoch: 59
2022-12-31 07:38:13,750 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5483009288708369, 'Total loss': 0.5483009288708369} | train loss {'Reaction outcome loss': 0.1208880268531559, 'Total loss': 0.1208880268531559}
2022-12-31 07:38:13,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:13,750 INFO:     Epoch: 60
2022-12-31 07:38:15,377 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5228800654411316, 'Total loss': 0.5228800654411316} | train loss {'Reaction outcome loss': 0.12441499946329622, 'Total loss': 0.12441499946329622}
2022-12-31 07:38:15,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:15,378 INFO:     Epoch: 61
2022-12-31 07:38:16,998 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5023620580633481, 'Total loss': 0.5023620580633481} | train loss {'Reaction outcome loss': 0.12136596612403647, 'Total loss': 0.12136596612403647}
2022-12-31 07:38:16,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:16,998 INFO:     Epoch: 62
2022-12-31 07:38:18,631 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5265845785538356, 'Total loss': 0.5265845785538356} | train loss {'Reaction outcome loss': 0.12364464422136491, 'Total loss': 0.12364464422136491}
2022-12-31 07:38:18,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:18,631 INFO:     Epoch: 63
2022-12-31 07:38:20,258 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5115489681561788, 'Total loss': 0.5115489681561788} | train loss {'Reaction outcome loss': 0.12101080531039232, 'Total loss': 0.12101080531039232}
2022-12-31 07:38:20,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:20,258 INFO:     Epoch: 64
2022-12-31 07:38:21,877 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5323381046454112, 'Total loss': 0.5323381046454112} | train loss {'Reaction outcome loss': 0.11771036923899977, 'Total loss': 0.11771036923899977}
2022-12-31 07:38:21,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:21,877 INFO:     Epoch: 65
2022-12-31 07:38:23,493 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5382131497065227, 'Total loss': 0.5382131497065227} | train loss {'Reaction outcome loss': 0.120926311427882, 'Total loss': 0.120926311427882}
2022-12-31 07:38:23,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:23,493 INFO:     Epoch: 66
2022-12-31 07:38:25,111 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5164173583189646, 'Total loss': 0.5164173583189646} | train loss {'Reaction outcome loss': 0.12076959577103276, 'Total loss': 0.12076959577103276}
2022-12-31 07:38:25,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:25,112 INFO:     Epoch: 67
2022-12-31 07:38:26,737 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5385869304339092, 'Total loss': 0.5385869304339092} | train loss {'Reaction outcome loss': 0.12417214400293003, 'Total loss': 0.12417214400293003}
2022-12-31 07:38:26,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:26,737 INFO:     Epoch: 68
2022-12-31 07:38:28,408 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5338430821895599, 'Total loss': 0.5338430821895599} | train loss {'Reaction outcome loss': 0.12068438666136364, 'Total loss': 0.12068438666136364}
2022-12-31 07:38:28,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:28,409 INFO:     Epoch: 69
2022-12-31 07:38:30,037 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5219522585471471, 'Total loss': 0.5219522585471471} | train loss {'Reaction outcome loss': 0.1184988277560833, 'Total loss': 0.1184988277560833}
2022-12-31 07:38:30,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:30,037 INFO:     Epoch: 70
2022-12-31 07:38:31,707 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.505469552675883, 'Total loss': 0.505469552675883} | train loss {'Reaction outcome loss': 0.11803461285139895, 'Total loss': 0.11803461285139895}
2022-12-31 07:38:31,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:31,707 INFO:     Epoch: 71
2022-12-31 07:38:33,332 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5379165103038152, 'Total loss': 0.5379165103038152} | train loss {'Reaction outcome loss': 0.11928098607768005, 'Total loss': 0.11928098607768005}
2022-12-31 07:38:33,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:33,332 INFO:     Epoch: 72
2022-12-31 07:38:34,970 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5192168722550075, 'Total loss': 0.5192168722550075} | train loss {'Reaction outcome loss': 0.11672708474096274, 'Total loss': 0.11672708474096274}
2022-12-31 07:38:34,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:34,970 INFO:     Epoch: 73
2022-12-31 07:38:36,641 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5585726976394654, 'Total loss': 0.5585726976394654} | train loss {'Reaction outcome loss': 0.12150645686569035, 'Total loss': 0.12150645686569035}
2022-12-31 07:38:36,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:36,641 INFO:     Epoch: 74
2022-12-31 07:38:38,266 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5342492779095968, 'Total loss': 0.5342492779095968} | train loss {'Reaction outcome loss': 0.11972889834712344, 'Total loss': 0.11972889834712344}
2022-12-31 07:38:38,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:38,266 INFO:     Epoch: 75
2022-12-31 07:38:39,896 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5202765469749768, 'Total loss': 0.5202765469749768} | train loss {'Reaction outcome loss': 0.11792168280257699, 'Total loss': 0.11792168280257699}
2022-12-31 07:38:39,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:39,897 INFO:     Epoch: 76
2022-12-31 07:38:41,532 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5124469955762228, 'Total loss': 0.5124469955762228} | train loss {'Reaction outcome loss': 0.11779322545968722, 'Total loss': 0.11779322545968722}
2022-12-31 07:38:41,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:41,532 INFO:     Epoch: 77
2022-12-31 07:38:43,168 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5225989992419878, 'Total loss': 0.5225989992419878} | train loss {'Reaction outcome loss': 0.1156699709368984, 'Total loss': 0.1156699709368984}
2022-12-31 07:38:43,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:43,169 INFO:     Epoch: 78
2022-12-31 07:38:44,796 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5269097208976745, 'Total loss': 0.5269097208976745} | train loss {'Reaction outcome loss': 0.11288383681266585, 'Total loss': 0.11288383681266585}
2022-12-31 07:38:44,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:44,797 INFO:     Epoch: 79
2022-12-31 07:38:46,439 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5153000672658284, 'Total loss': 0.5153000672658284} | train loss {'Reaction outcome loss': 0.11527819341781552, 'Total loss': 0.11527819341781552}
2022-12-31 07:38:46,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:46,440 INFO:     Epoch: 80
2022-12-31 07:38:48,075 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5048575747137268, 'Total loss': 0.5048575747137268} | train loss {'Reaction outcome loss': 0.11430657792429605, 'Total loss': 0.11430657792429605}
2022-12-31 07:38:48,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:48,075 INFO:     Epoch: 81
2022-12-31 07:38:49,707 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.52691677014033, 'Total loss': 0.52691677014033} | train loss {'Reaction outcome loss': 0.11472386582367902, 'Total loss': 0.11472386582367902}
2022-12-31 07:38:49,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:49,707 INFO:     Epoch: 82
2022-12-31 07:38:51,344 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5037268102169037, 'Total loss': 0.5037268102169037} | train loss {'Reaction outcome loss': 0.11437269471357123, 'Total loss': 0.11437269471357123}
2022-12-31 07:38:51,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:51,345 INFO:     Epoch: 83
2022-12-31 07:38:52,978 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5112000515063604, 'Total loss': 0.5112000515063604} | train loss {'Reaction outcome loss': 0.11872958747791093, 'Total loss': 0.11872958747791093}
2022-12-31 07:38:52,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:52,979 INFO:     Epoch: 84
2022-12-31 07:38:54,649 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5423931797345479, 'Total loss': 0.5423931797345479} | train loss {'Reaction outcome loss': 0.10914742140711323, 'Total loss': 0.10914742140711323}
2022-12-31 07:38:54,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:54,649 INFO:     Epoch: 85
2022-12-31 07:38:56,283 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5267623901367188, 'Total loss': 0.5267623901367188} | train loss {'Reaction outcome loss': 0.10766442282972621, 'Total loss': 0.10766442282972621}
2022-12-31 07:38:56,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:56,283 INFO:     Epoch: 86
2022-12-31 07:38:57,938 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5239038854837418, 'Total loss': 0.5239038854837418} | train loss {'Reaction outcome loss': 0.10904271250409124, 'Total loss': 0.10904271250409124}
2022-12-31 07:38:57,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:57,938 INFO:     Epoch: 87
2022-12-31 07:38:59,557 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5401961704095205, 'Total loss': 0.5401961704095205} | train loss {'Reaction outcome loss': 0.10995028073990226, 'Total loss': 0.10995028073990226}
2022-12-31 07:38:59,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:38:59,557 INFO:     Epoch: 88
2022-12-31 07:39:01,179 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5033177276452382, 'Total loss': 0.5033177276452382} | train loss {'Reaction outcome loss': 0.10935951625787071, 'Total loss': 0.10935951625787071}
2022-12-31 07:39:01,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:01,179 INFO:     Epoch: 89
2022-12-31 07:39:02,810 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5195650458335876, 'Total loss': 0.5195650458335876} | train loss {'Reaction outcome loss': 0.11658691627306306, 'Total loss': 0.11658691627306306}
2022-12-31 07:39:02,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:02,810 INFO:     Epoch: 90
2022-12-31 07:39:04,446 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5092968732118607, 'Total loss': 0.5092968732118607} | train loss {'Reaction outcome loss': 0.11412369411031881, 'Total loss': 0.11412369411031881}
2022-12-31 07:39:04,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:04,446 INFO:     Epoch: 91
2022-12-31 07:39:06,064 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5063362717628479, 'Total loss': 0.5063362717628479} | train loss {'Reaction outcome loss': 0.11136482662894504, 'Total loss': 0.11136482662894504}
2022-12-31 07:39:06,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:06,065 INFO:     Epoch: 92
2022-12-31 07:39:07,692 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5208808273077011, 'Total loss': 0.5208808273077011} | train loss {'Reaction outcome loss': 0.11069506515634485, 'Total loss': 0.11069506515634485}
2022-12-31 07:39:07,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:07,693 INFO:     Epoch: 93
2022-12-31 07:39:09,364 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5314088215430578, 'Total loss': 0.5314088215430578} | train loss {'Reaction outcome loss': 0.10880885312387498, 'Total loss': 0.10880885312387498}
2022-12-31 07:39:09,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:09,365 INFO:     Epoch: 94
2022-12-31 07:39:11,019 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5129983673493067, 'Total loss': 0.5129983673493067} | train loss {'Reaction outcome loss': 0.10876826488577664, 'Total loss': 0.10876826488577664}
2022-12-31 07:39:11,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:11,020 INFO:     Epoch: 95
2022-12-31 07:39:12,652 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5249641537666321, 'Total loss': 0.5249641537666321} | train loss {'Reaction outcome loss': 0.10610082470021792, 'Total loss': 0.10610082470021792}
2022-12-31 07:39:12,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:12,652 INFO:     Epoch: 96
2022-12-31 07:39:14,284 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4995995829502741, 'Total loss': 0.4995995829502741} | train loss {'Reaction outcome loss': 0.10649165925855618, 'Total loss': 0.10649165925855618}
2022-12-31 07:39:14,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:14,284 INFO:     Epoch: 97
2022-12-31 07:39:15,929 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5438097417354584, 'Total loss': 0.5438097417354584} | train loss {'Reaction outcome loss': 0.11296604870774847, 'Total loss': 0.11296604870774847}
2022-12-31 07:39:15,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:15,930 INFO:     Epoch: 98
2022-12-31 07:39:17,548 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5245271354913712, 'Total loss': 0.5245271354913712} | train loss {'Reaction outcome loss': 0.11055460305159932, 'Total loss': 0.11055460305159932}
2022-12-31 07:39:17,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:17,548 INFO:     Epoch: 99
2022-12-31 07:39:19,169 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5192294776439667, 'Total loss': 0.5192294776439667} | train loss {'Reaction outcome loss': 0.11009307627461931, 'Total loss': 0.11009307627461931}
2022-12-31 07:39:19,169 INFO:     Best model found after epoch 6 of 100.
2022-12-31 07:39:19,169 INFO:   Done with stage: TRAINING
2022-12-31 07:39:19,169 INFO:   Starting stage: EVALUATION
2022-12-31 07:39:19,294 INFO:   Done with stage: EVALUATION
2022-12-31 07:39:19,294 INFO:   Leaving out SEQ value Fold_9
2022-12-31 07:39:19,307 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 07:39:19,307 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:39:19,950 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:39:19,950 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:39:20,018 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:39:20,018 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:39:20,018 INFO:     No hyperparam tuning for this model
2022-12-31 07:39:20,018 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:39:20,018 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:39:20,019 INFO:     None feature selector for col prot
2022-12-31 07:39:20,019 INFO:     None feature selector for col prot
2022-12-31 07:39:20,019 INFO:     None feature selector for col prot
2022-12-31 07:39:20,020 INFO:     None feature selector for col chem
2022-12-31 07:39:20,020 INFO:     None feature selector for col chem
2022-12-31 07:39:20,020 INFO:     None feature selector for col chem
2022-12-31 07:39:20,020 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:39:20,020 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:39:20,022 INFO:     Number of params in model 224011
2022-12-31 07:39:20,025 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:39:20,025 INFO:   Starting stage: TRAINING
2022-12-31 07:39:20,069 INFO:     Val loss before train {'Reaction outcome loss': 0.9280628005663554, 'Total loss': 0.9280628005663554}
2022-12-31 07:39:20,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:20,070 INFO:     Epoch: 0
2022-12-31 07:39:21,686 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5212023337682088, 'Total loss': 0.5212023337682088} | train loss {'Reaction outcome loss': 0.7894786225114058, 'Total loss': 0.7894786225114058}
2022-12-31 07:39:21,686 INFO:     Found new best model at epoch 0
2022-12-31 07:39:21,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:21,687 INFO:     Epoch: 1
2022-12-31 07:39:23,304 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4558142125606537, 'Total loss': 0.4558142125606537} | train loss {'Reaction outcome loss': 0.5110280116757762, 'Total loss': 0.5110280116757762}
2022-12-31 07:39:23,304 INFO:     Found new best model at epoch 1
2022-12-31 07:39:23,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:23,306 INFO:     Epoch: 2
2022-12-31 07:39:24,934 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4382258733113607, 'Total loss': 0.4382258733113607} | train loss {'Reaction outcome loss': 0.4380379861442621, 'Total loss': 0.4380379861442621}
2022-12-31 07:39:24,934 INFO:     Found new best model at epoch 2
2022-12-31 07:39:24,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:24,935 INFO:     Epoch: 3
2022-12-31 07:39:26,574 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41790200571219127, 'Total loss': 0.41790200571219127} | train loss {'Reaction outcome loss': 0.40295616817065527, 'Total loss': 0.40295616817065527}
2022-12-31 07:39:26,574 INFO:     Found new best model at epoch 3
2022-12-31 07:39:26,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:26,575 INFO:     Epoch: 4
2022-12-31 07:39:28,206 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40635805825392407, 'Total loss': 0.40635805825392407} | train loss {'Reaction outcome loss': 0.3743652574960075, 'Total loss': 0.3743652574960075}
2022-12-31 07:39:28,206 INFO:     Found new best model at epoch 4
2022-12-31 07:39:28,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:28,207 INFO:     Epoch: 5
2022-12-31 07:39:29,832 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3919370124737422, 'Total loss': 0.3919370124737422} | train loss {'Reaction outcome loss': 0.3520963806053792, 'Total loss': 0.3520963806053792}
2022-12-31 07:39:29,832 INFO:     Found new best model at epoch 5
2022-12-31 07:39:29,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:29,833 INFO:     Epoch: 6
2022-12-31 07:39:31,471 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39767857690652214, 'Total loss': 0.39767857690652214} | train loss {'Reaction outcome loss': 0.33271517343684653, 'Total loss': 0.33271517343684653}
2022-12-31 07:39:31,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:31,471 INFO:     Epoch: 7
2022-12-31 07:39:33,128 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42449062267939247, 'Total loss': 0.42449062267939247} | train loss {'Reaction outcome loss': 0.31292243159312205, 'Total loss': 0.31292243159312205}
2022-12-31 07:39:33,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:33,128 INFO:     Epoch: 8
2022-12-31 07:39:34,752 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4110903412103653, 'Total loss': 0.4110903412103653} | train loss {'Reaction outcome loss': 0.29921640069745076, 'Total loss': 0.29921640069745076}
2022-12-31 07:39:34,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:34,752 INFO:     Epoch: 9
2022-12-31 07:39:36,375 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39037862519423167, 'Total loss': 0.39037862519423167} | train loss {'Reaction outcome loss': 0.28480892028619237, 'Total loss': 0.28480892028619237}
2022-12-31 07:39:36,376 INFO:     Found new best model at epoch 9
2022-12-31 07:39:36,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:36,377 INFO:     Epoch: 10
2022-12-31 07:39:38,003 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3933867424726486, 'Total loss': 0.3933867424726486} | train loss {'Reaction outcome loss': 0.27119419269183054, 'Total loss': 0.27119419269183054}
2022-12-31 07:39:38,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:38,003 INFO:     Epoch: 11
2022-12-31 07:39:39,621 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3817988564570745, 'Total loss': 0.3817988564570745} | train loss {'Reaction outcome loss': 0.25870485716778446, 'Total loss': 0.25870485716778446}
2022-12-31 07:39:39,621 INFO:     Found new best model at epoch 11
2022-12-31 07:39:39,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:39,622 INFO:     Epoch: 12
2022-12-31 07:39:41,246 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40198821226755777, 'Total loss': 0.40198821226755777} | train loss {'Reaction outcome loss': 0.24883330606986576, 'Total loss': 0.24883330606986576}
2022-12-31 07:39:41,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:41,246 INFO:     Epoch: 13
2022-12-31 07:39:42,868 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3878134508927663, 'Total loss': 0.3878134508927663} | train loss {'Reaction outcome loss': 0.24031205787340226, 'Total loss': 0.24031205787340226}
2022-12-31 07:39:42,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:42,869 INFO:     Epoch: 14
2022-12-31 07:39:44,492 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3887095659971237, 'Total loss': 0.3887095659971237} | train loss {'Reaction outcome loss': 0.23521487963543902, 'Total loss': 0.23521487963543902}
2022-12-31 07:39:44,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:44,492 INFO:     Epoch: 15
2022-12-31 07:39:46,114 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3961152960856756, 'Total loss': 0.3961152960856756} | train loss {'Reaction outcome loss': 0.22551837802901595, 'Total loss': 0.22551837802901595}
2022-12-31 07:39:46,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:46,114 INFO:     Epoch: 16
2022-12-31 07:39:47,758 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38752240836620333, 'Total loss': 0.38752240836620333} | train loss {'Reaction outcome loss': 0.2151196447776005, 'Total loss': 0.2151196447776005}
2022-12-31 07:39:47,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:47,758 INFO:     Epoch: 17
2022-12-31 07:39:49,382 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38742143561442693, 'Total loss': 0.38742143561442693} | train loss {'Reaction outcome loss': 0.2110653550898663, 'Total loss': 0.2110653550898663}
2022-12-31 07:39:49,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:49,382 INFO:     Epoch: 18
2022-12-31 07:39:51,021 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3706228961547216, 'Total loss': 0.3706228961547216} | train loss {'Reaction outcome loss': 0.2041843437895663, 'Total loss': 0.2041843437895663}
2022-12-31 07:39:51,022 INFO:     Found new best model at epoch 18
2022-12-31 07:39:51,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:51,023 INFO:     Epoch: 19
2022-12-31 07:39:52,653 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38674486974875133, 'Total loss': 0.38674486974875133} | train loss {'Reaction outcome loss': 0.20246422266594338, 'Total loss': 0.20246422266594338}
2022-12-31 07:39:52,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:52,653 INFO:     Epoch: 20
2022-12-31 07:39:54,284 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4287147969007492, 'Total loss': 0.4287147969007492} | train loss {'Reaction outcome loss': 0.19489380506132914, 'Total loss': 0.19489380506132914}
2022-12-31 07:39:54,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:54,284 INFO:     Epoch: 21
2022-12-31 07:39:55,904 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3914739618698756, 'Total loss': 0.3914739618698756} | train loss {'Reaction outcome loss': 0.19383925247923992, 'Total loss': 0.19383925247923992}
2022-12-31 07:39:55,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:55,904 INFO:     Epoch: 22
2022-12-31 07:39:57,576 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3846321403980255, 'Total loss': 0.3846321403980255} | train loss {'Reaction outcome loss': 0.1862156130743317, 'Total loss': 0.1862156130743317}
2022-12-31 07:39:57,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:57,577 INFO:     Epoch: 23
2022-12-31 07:39:59,198 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39340283075968424, 'Total loss': 0.39340283075968424} | train loss {'Reaction outcome loss': 0.1859193109715566, 'Total loss': 0.1859193109715566}
2022-12-31 07:39:59,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:39:59,198 INFO:     Epoch: 24
2022-12-31 07:40:00,817 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3828585570057233, 'Total loss': 0.3828585570057233} | train loss {'Reaction outcome loss': 0.17961355066767454, 'Total loss': 0.17961355066767454}
2022-12-31 07:40:00,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:00,817 INFO:     Epoch: 25
2022-12-31 07:40:02,463 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4035226265589396, 'Total loss': 0.4035226265589396} | train loss {'Reaction outcome loss': 0.1787515145824005, 'Total loss': 0.1787515145824005}
2022-12-31 07:40:02,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:02,464 INFO:     Epoch: 26
2022-12-31 07:40:04,086 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3790926719705264, 'Total loss': 0.3790926719705264} | train loss {'Reaction outcome loss': 0.17919348897109824, 'Total loss': 0.17919348897109824}
2022-12-31 07:40:04,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:04,086 INFO:     Epoch: 27
2022-12-31 07:40:05,711 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3805699999133746, 'Total loss': 0.3805699999133746} | train loss {'Reaction outcome loss': 0.17333640068742556, 'Total loss': 0.17333640068742556}
2022-12-31 07:40:05,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:05,711 INFO:     Epoch: 28
2022-12-31 07:40:07,335 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40355789810419085, 'Total loss': 0.40355789810419085} | train loss {'Reaction outcome loss': 0.17367894518010937, 'Total loss': 0.17367894518010937}
2022-12-31 07:40:07,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:07,335 INFO:     Epoch: 29
2022-12-31 07:40:08,952 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41313590506712594, 'Total loss': 0.41313590506712594} | train loss {'Reaction outcome loss': 0.1702846029894393, 'Total loss': 0.1702846029894393}
2022-12-31 07:40:08,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:08,953 INFO:     Epoch: 30
2022-12-31 07:40:10,626 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3887593924999237, 'Total loss': 0.3887593924999237} | train loss {'Reaction outcome loss': 0.16901007275490446, 'Total loss': 0.16901007275490446}
2022-12-31 07:40:10,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:10,627 INFO:     Epoch: 31
2022-12-31 07:40:12,248 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40787499845027925, 'Total loss': 0.40787499845027925} | train loss {'Reaction outcome loss': 0.1621599492586692, 'Total loss': 0.1621599492586692}
2022-12-31 07:40:12,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:12,248 INFO:     Epoch: 32
2022-12-31 07:40:13,871 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3769432226816813, 'Total loss': 0.3769432226816813} | train loss {'Reaction outcome loss': 0.16037566512016183, 'Total loss': 0.16037566512016183}
2022-12-31 07:40:13,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:13,871 INFO:     Epoch: 33
2022-12-31 07:40:15,493 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38273323674996695, 'Total loss': 0.38273323674996695} | train loss {'Reaction outcome loss': 0.15904012490198394, 'Total loss': 0.15904012490198394}
2022-12-31 07:40:15,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:15,493 INFO:     Epoch: 34
2022-12-31 07:40:17,131 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39486495703458785, 'Total loss': 0.39486495703458785} | train loss {'Reaction outcome loss': 0.16086791669075723, 'Total loss': 0.16086791669075723}
2022-12-31 07:40:17,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:17,132 INFO:     Epoch: 35
2022-12-31 07:40:18,773 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3760069578886032, 'Total loss': 0.3760069578886032} | train loss {'Reaction outcome loss': 0.15596953978835998, 'Total loss': 0.15596953978835998}
2022-12-31 07:40:18,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:18,774 INFO:     Epoch: 36
2022-12-31 07:40:20,444 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38525448044141136, 'Total loss': 0.38525448044141136} | train loss {'Reaction outcome loss': 0.1575720860296692, 'Total loss': 0.1575720860296692}
2022-12-31 07:40:20,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:20,444 INFO:     Epoch: 37
2022-12-31 07:40:22,115 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3899169027805328, 'Total loss': 0.3899169027805328} | train loss {'Reaction outcome loss': 0.1548820982505618, 'Total loss': 0.1548820982505618}
2022-12-31 07:40:22,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:22,116 INFO:     Epoch: 38
2022-12-31 07:40:23,743 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4119520177443822, 'Total loss': 0.4119520177443822} | train loss {'Reaction outcome loss': 0.1500585350756019, 'Total loss': 0.1500585350756019}
2022-12-31 07:40:23,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:23,743 INFO:     Epoch: 39
2022-12-31 07:40:25,413 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40194699813922247, 'Total loss': 0.40194699813922247} | train loss {'Reaction outcome loss': 0.15435589868440847, 'Total loss': 0.15435589868440847}
2022-12-31 07:40:25,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:25,413 INFO:     Epoch: 40
2022-12-31 07:40:27,035 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38365567525227867, 'Total loss': 0.38365567525227867} | train loss {'Reaction outcome loss': 0.15577862789645952, 'Total loss': 0.15577862789645952}
2022-12-31 07:40:27,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:27,036 INFO:     Epoch: 41
2022-12-31 07:40:28,699 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38714772164821626, 'Total loss': 0.38714772164821626} | train loss {'Reaction outcome loss': 0.14969065439776394, 'Total loss': 0.14969065439776394}
2022-12-31 07:40:28,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:28,700 INFO:     Epoch: 42
2022-12-31 07:40:30,320 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41222552011410396, 'Total loss': 0.41222552011410396} | train loss {'Reaction outcome loss': 0.14721449287372915, 'Total loss': 0.14721449287372915}
2022-12-31 07:40:30,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:30,320 INFO:     Epoch: 43
2022-12-31 07:40:31,946 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39482077956199646, 'Total loss': 0.39482077956199646} | train loss {'Reaction outcome loss': 0.14772387888006838, 'Total loss': 0.14772387888006838}
2022-12-31 07:40:31,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:31,946 INFO:     Epoch: 44
2022-12-31 07:40:33,579 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40076707899570463, 'Total loss': 0.40076707899570463} | train loss {'Reaction outcome loss': 0.14421964477788024, 'Total loss': 0.14421964477788024}
2022-12-31 07:40:33,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:33,579 INFO:     Epoch: 45
2022-12-31 07:40:35,216 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3971595486005147, 'Total loss': 0.3971595486005147} | train loss {'Reaction outcome loss': 0.14289669667300012, 'Total loss': 0.14289669667300012}
2022-12-31 07:40:35,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:35,216 INFO:     Epoch: 46
2022-12-31 07:40:36,843 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3839392254749934, 'Total loss': 0.3839392254749934} | train loss {'Reaction outcome loss': 0.14353072826854804, 'Total loss': 0.14353072826854804}
2022-12-31 07:40:36,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:36,843 INFO:     Epoch: 47
2022-12-31 07:40:38,478 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42042619610826176, 'Total loss': 0.42042619610826176} | train loss {'Reaction outcome loss': 0.13954528286508436, 'Total loss': 0.13954528286508436}
2022-12-31 07:40:38,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:38,479 INFO:     Epoch: 48
2022-12-31 07:40:40,115 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4159037490685781, 'Total loss': 0.4159037490685781} | train loss {'Reaction outcome loss': 0.14332833196900596, 'Total loss': 0.14332833196900596}
2022-12-31 07:40:40,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:40,116 INFO:     Epoch: 49
2022-12-31 07:40:41,743 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3916529268026352, 'Total loss': 0.3916529268026352} | train loss {'Reaction outcome loss': 0.1378454838775179, 'Total loss': 0.1378454838775179}
2022-12-31 07:40:41,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:41,744 INFO:     Epoch: 50
2022-12-31 07:40:43,382 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3936447868744532, 'Total loss': 0.3936447868744532} | train loss {'Reaction outcome loss': 0.13745469209907865, 'Total loss': 0.13745469209907865}
2022-12-31 07:40:43,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:43,382 INFO:     Epoch: 51
2022-12-31 07:40:45,021 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4114015221595764, 'Total loss': 0.4114015221595764} | train loss {'Reaction outcome loss': 0.1377690680012349, 'Total loss': 0.1377690680012349}
2022-12-31 07:40:45,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:45,021 INFO:     Epoch: 52
2022-12-31 07:40:46,675 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40080426409840586, 'Total loss': 0.40080426409840586} | train loss {'Reaction outcome loss': 0.13638715733461323, 'Total loss': 0.13638715733461323}
2022-12-31 07:40:46,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:46,675 INFO:     Epoch: 53
2022-12-31 07:40:48,299 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37235730811953544, 'Total loss': 0.37235730811953544} | train loss {'Reaction outcome loss': 0.13683478340644403, 'Total loss': 0.13683478340644403}
2022-12-31 07:40:48,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:48,299 INFO:     Epoch: 54
2022-12-31 07:40:49,969 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4063196301460266, 'Total loss': 0.4063196301460266} | train loss {'Reaction outcome loss': 0.13490023862214134, 'Total loss': 0.13490023862214134}
2022-12-31 07:40:49,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:49,969 INFO:     Epoch: 55
2022-12-31 07:40:51,604 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3865380803743998, 'Total loss': 0.3865380803743998} | train loss {'Reaction outcome loss': 0.13420071790922797, 'Total loss': 0.13420071790922797}
2022-12-31 07:40:51,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:51,604 INFO:     Epoch: 56
2022-12-31 07:40:53,276 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4077181895573934, 'Total loss': 0.4077181895573934} | train loss {'Reaction outcome loss': 0.13066476736459814, 'Total loss': 0.13066476736459814}
2022-12-31 07:40:53,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:53,277 INFO:     Epoch: 57
2022-12-31 07:40:54,900 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3678182020783424, 'Total loss': 0.3678182020783424} | train loss {'Reaction outcome loss': 0.1309662420985151, 'Total loss': 0.1309662420985151}
2022-12-31 07:40:54,900 INFO:     Found new best model at epoch 57
2022-12-31 07:40:54,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:54,901 INFO:     Epoch: 58
2022-12-31 07:40:56,524 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39207599659760795, 'Total loss': 0.39207599659760795} | train loss {'Reaction outcome loss': 0.13686492551615737, 'Total loss': 0.13686492551615737}
2022-12-31 07:40:56,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:56,525 INFO:     Epoch: 59
2022-12-31 07:40:58,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37195469612876575, 'Total loss': 0.37195469612876575} | train loss {'Reaction outcome loss': 0.13331066894375246, 'Total loss': 0.13331066894375246}
2022-12-31 07:40:58,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:58,194 INFO:     Epoch: 60
2022-12-31 07:40:59,856 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3949637432893117, 'Total loss': 0.3949637432893117} | train loss {'Reaction outcome loss': 0.13250231580633925, 'Total loss': 0.13250231580633925}
2022-12-31 07:40:59,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:40:59,856 INFO:     Epoch: 61
2022-12-31 07:41:01,477 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4103502333164215, 'Total loss': 0.4103502333164215} | train loss {'Reaction outcome loss': 0.12889840937007743, 'Total loss': 0.12889840937007743}
2022-12-31 07:41:01,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:01,478 INFO:     Epoch: 62
2022-12-31 07:41:03,147 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4201239436864853, 'Total loss': 0.4201239436864853} | train loss {'Reaction outcome loss': 0.13106851535092784, 'Total loss': 0.13106851535092784}
2022-12-31 07:41:03,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:03,147 INFO:     Epoch: 63
2022-12-31 07:41:04,768 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39122911828259627, 'Total loss': 0.39122911828259627} | train loss {'Reaction outcome loss': 0.12994642286235297, 'Total loss': 0.12994642286235297}
2022-12-31 07:41:04,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:04,768 INFO:     Epoch: 64
2022-12-31 07:41:06,386 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4117183725039164, 'Total loss': 0.4117183725039164} | train loss {'Reaction outcome loss': 0.1251230524678039, 'Total loss': 0.1251230524678039}
2022-12-31 07:41:06,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:06,386 INFO:     Epoch: 65
2022-12-31 07:41:08,007 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.383767402668794, 'Total loss': 0.383767402668794} | train loss {'Reaction outcome loss': 0.12557931622954266, 'Total loss': 0.12557931622954266}
2022-12-31 07:41:08,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:08,007 INFO:     Epoch: 66
2022-12-31 07:41:09,654 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3972361157337824, 'Total loss': 0.3972361157337824} | train loss {'Reaction outcome loss': 0.12327393067039093, 'Total loss': 0.12327393067039093}
2022-12-31 07:41:09,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:09,654 INFO:     Epoch: 67
2022-12-31 07:41:11,274 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3933858186006546, 'Total loss': 0.3933858186006546} | train loss {'Reaction outcome loss': 0.1260793493684072, 'Total loss': 0.1260793493684072}
2022-12-31 07:41:11,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:11,274 INFO:     Epoch: 68
2022-12-31 07:41:12,889 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4228729243079821, 'Total loss': 0.4228729243079821} | train loss {'Reaction outcome loss': 0.12690749641386825, 'Total loss': 0.12690749641386825}
2022-12-31 07:41:12,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:12,890 INFO:     Epoch: 69
2022-12-31 07:41:14,510 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41739834323525427, 'Total loss': 0.41739834323525427} | train loss {'Reaction outcome loss': 0.1243787494383833, 'Total loss': 0.1243787494383833}
2022-12-31 07:41:14,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:14,510 INFO:     Epoch: 70
2022-12-31 07:41:16,177 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3798347312491387, 'Total loss': 0.3798347312491387} | train loss {'Reaction outcome loss': 0.12474282797163735, 'Total loss': 0.12474282797163735}
2022-12-31 07:41:16,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:16,178 INFO:     Epoch: 71
2022-12-31 07:41:17,847 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3699944819013278, 'Total loss': 0.3699944819013278} | train loss {'Reaction outcome loss': 0.12315253954252987, 'Total loss': 0.12315253954252987}
2022-12-31 07:41:17,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:17,847 INFO:     Epoch: 72
2022-12-31 07:41:19,464 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3797024466097355, 'Total loss': 0.3797024466097355} | train loss {'Reaction outcome loss': 0.12217405836000393, 'Total loss': 0.12217405836000393}
2022-12-31 07:41:19,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:19,464 INFO:     Epoch: 73
2022-12-31 07:41:21,134 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39822550217310587, 'Total loss': 0.39822550217310587} | train loss {'Reaction outcome loss': 0.11868122015450996, 'Total loss': 0.11868122015450996}
2022-12-31 07:41:21,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:21,135 INFO:     Epoch: 74
2022-12-31 07:41:22,761 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3477049912015597, 'Total loss': 0.3477049912015597} | train loss {'Reaction outcome loss': 0.12452924039991511, 'Total loss': 0.12452924039991511}
2022-12-31 07:41:22,761 INFO:     Found new best model at epoch 74
2022-12-31 07:41:22,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:22,762 INFO:     Epoch: 75
2022-12-31 07:41:24,382 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3772311935822169, 'Total loss': 0.3772311935822169} | train loss {'Reaction outcome loss': 0.12162327338665697, 'Total loss': 0.12162327338665697}
2022-12-31 07:41:24,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:24,382 INFO:     Epoch: 76
2022-12-31 07:41:26,054 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37949804663658143, 'Total loss': 0.37949804663658143} | train loss {'Reaction outcome loss': 0.12316870409911262, 'Total loss': 0.12316870409911262}
2022-12-31 07:41:26,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:26,055 INFO:     Epoch: 77
2022-12-31 07:41:27,674 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38554272552331287, 'Total loss': 0.38554272552331287} | train loss {'Reaction outcome loss': 0.12304430621228978, 'Total loss': 0.12304430621228978}
2022-12-31 07:41:27,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:27,675 INFO:     Epoch: 78
2022-12-31 07:41:29,345 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39102322508891424, 'Total loss': 0.39102322508891424} | train loss {'Reaction outcome loss': 0.12107921528229859, 'Total loss': 0.12107921528229859}
2022-12-31 07:41:29,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:29,346 INFO:     Epoch: 79
2022-12-31 07:41:30,970 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3968218853076299, 'Total loss': 0.3968218853076299} | train loss {'Reaction outcome loss': 0.11978338393155781, 'Total loss': 0.11978338393155781}
2022-12-31 07:41:30,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:30,970 INFO:     Epoch: 80
2022-12-31 07:41:32,601 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38025246063868207, 'Total loss': 0.38025246063868207} | train loss {'Reaction outcome loss': 0.117584468734649, 'Total loss': 0.117584468734649}
2022-12-31 07:41:32,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:32,601 INFO:     Epoch: 81
2022-12-31 07:41:34,228 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37436931232611337, 'Total loss': 0.37436931232611337} | train loss {'Reaction outcome loss': 0.11602278434526889, 'Total loss': 0.11602278434526889}
2022-12-31 07:41:34,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:34,228 INFO:     Epoch: 82
2022-12-31 07:41:35,855 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39749776721000674, 'Total loss': 0.39749776721000674} | train loss {'Reaction outcome loss': 0.11706022216874555, 'Total loss': 0.11706022216874555}
2022-12-31 07:41:35,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:35,856 INFO:     Epoch: 83
2022-12-31 07:41:37,470 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4172783255577087, 'Total loss': 0.4172783255577087} | train loss {'Reaction outcome loss': 0.12165080849417495, 'Total loss': 0.12165080849417495}
2022-12-31 07:41:37,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:37,470 INFO:     Epoch: 84
2022-12-31 07:41:39,141 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39004690448443097, 'Total loss': 0.39004690448443097} | train loss {'Reaction outcome loss': 0.12169296688833929, 'Total loss': 0.12169296688833929}
2022-12-31 07:41:39,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:39,141 INFO:     Epoch: 85
2022-12-31 07:41:40,770 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36357445220152534, 'Total loss': 0.36357445220152534} | train loss {'Reaction outcome loss': 0.12075557042626052, 'Total loss': 0.12075557042626052}
2022-12-31 07:41:40,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:40,770 INFO:     Epoch: 86
2022-12-31 07:41:42,440 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41185373067855835, 'Total loss': 0.41185373067855835} | train loss {'Reaction outcome loss': 0.11734354169030643, 'Total loss': 0.11734354169030643}
2022-12-31 07:41:42,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:42,440 INFO:     Epoch: 87
2022-12-31 07:41:44,110 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3842134416103363, 'Total loss': 0.3842134416103363} | train loss {'Reaction outcome loss': 0.11415323719133486, 'Total loss': 0.11415323719133486}
2022-12-31 07:41:44,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:44,110 INFO:     Epoch: 88
2022-12-31 07:41:45,761 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.374753271540006, 'Total loss': 0.374753271540006} | train loss {'Reaction outcome loss': 0.11381452254840048, 'Total loss': 0.11381452254840048}
2022-12-31 07:41:45,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:45,762 INFO:     Epoch: 89
2022-12-31 07:41:47,434 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.36876616527636846, 'Total loss': 0.36876616527636846} | train loss {'Reaction outcome loss': 0.11959525688537917, 'Total loss': 0.11959525688537917}
2022-12-31 07:41:47,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:47,434 INFO:     Epoch: 90
2022-12-31 07:41:49,057 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4021084745724996, 'Total loss': 0.4021084745724996} | train loss {'Reaction outcome loss': 0.1214248317374515, 'Total loss': 0.1214248317374515}
2022-12-31 07:41:49,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:49,058 INFO:     Epoch: 91
2022-12-31 07:41:50,671 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3962986653049787, 'Total loss': 0.3962986653049787} | train loss {'Reaction outcome loss': 0.11809972709629833, 'Total loss': 0.11809972709629833}
2022-12-31 07:41:50,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:50,671 INFO:     Epoch: 92
2022-12-31 07:41:52,291 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40869463284810387, 'Total loss': 0.40869463284810387} | train loss {'Reaction outcome loss': 0.11708470473287876, 'Total loss': 0.11708470473287876}
2022-12-31 07:41:52,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:52,291 INFO:     Epoch: 93
2022-12-31 07:41:53,911 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38827575544516246, 'Total loss': 0.38827575544516246} | train loss {'Reaction outcome loss': 0.11510914200681534, 'Total loss': 0.11510914200681534}
2022-12-31 07:41:53,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:53,912 INFO:     Epoch: 94
2022-12-31 07:41:55,536 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4029291917880376, 'Total loss': 0.4029291917880376} | train loss {'Reaction outcome loss': 0.11139491077979845, 'Total loss': 0.11139491077979845}
2022-12-31 07:41:55,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:55,536 INFO:     Epoch: 95
2022-12-31 07:41:57,207 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3765472153822581, 'Total loss': 0.3765472153822581} | train loss {'Reaction outcome loss': 0.11130577165529212, 'Total loss': 0.11130577165529212}
2022-12-31 07:41:57,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:57,207 INFO:     Epoch: 96
2022-12-31 07:41:58,822 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4321166565020879, 'Total loss': 0.4321166565020879} | train loss {'Reaction outcome loss': 0.11632673467580054, 'Total loss': 0.11632673467580054}
2022-12-31 07:41:58,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:41:58,822 INFO:     Epoch: 97
2022-12-31 07:42:00,447 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39581165512402855, 'Total loss': 0.39581165512402855} | train loss {'Reaction outcome loss': 0.1193765038607595, 'Total loss': 0.1193765038607595}
2022-12-31 07:42:00,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:00,447 INFO:     Epoch: 98
2022-12-31 07:42:02,071 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3884638875722885, 'Total loss': 0.3884638875722885} | train loss {'Reaction outcome loss': 0.11805289767561514, 'Total loss': 0.11805289767561514}
2022-12-31 07:42:02,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:02,071 INFO:     Epoch: 99
2022-12-31 07:42:03,734 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36951453536748885, 'Total loss': 0.36951453536748885} | train loss {'Reaction outcome loss': 0.11342128250741194, 'Total loss': 0.11342128250741194}
2022-12-31 07:42:03,735 INFO:     Best model found after epoch 75 of 100.
2022-12-31 07:42:03,735 INFO:   Done with stage: TRAINING
2022-12-31 07:42:03,735 INFO:   Starting stage: EVALUATION
2022-12-31 07:42:03,861 INFO:   Done with stage: EVALUATION
2022-12-31 07:42:03,869 INFO:   Leaving out SEQ value Fold_0
2022-12-31 07:42:03,882 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 07:42:03,882 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:42:04,527 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:42:04,527 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:42:04,594 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:42:04,594 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:42:04,594 INFO:     No hyperparam tuning for this model
2022-12-31 07:42:04,594 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:42:04,594 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:42:04,595 INFO:     None feature selector for col prot
2022-12-31 07:42:04,595 INFO:     None feature selector for col prot
2022-12-31 07:42:04,595 INFO:     None feature selector for col prot
2022-12-31 07:42:04,596 INFO:     None feature selector for col chem
2022-12-31 07:42:04,596 INFO:     None feature selector for col chem
2022-12-31 07:42:04,596 INFO:     None feature selector for col chem
2022-12-31 07:42:04,596 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:42:04,596 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:42:04,598 INFO:     Number of params in model 224011
2022-12-31 07:42:04,601 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:42:04,601 INFO:   Starting stage: TRAINING
2022-12-31 07:42:04,646 INFO:     Val loss before train {'Reaction outcome loss': 0.9950869639714559, 'Total loss': 0.9950869639714559}
2022-12-31 07:42:04,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:04,647 INFO:     Epoch: 0
2022-12-31 07:42:06,256 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5696223100026448, 'Total loss': 0.5696223100026448} | train loss {'Reaction outcome loss': 0.7663561633251009, 'Total loss': 0.7663561633251009}
2022-12-31 07:42:06,256 INFO:     Found new best model at epoch 0
2022-12-31 07:42:06,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:06,257 INFO:     Epoch: 1
2022-12-31 07:42:07,880 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4963571190834045, 'Total loss': 0.4963571190834045} | train loss {'Reaction outcome loss': 0.501662010204618, 'Total loss': 0.501662010204618}
2022-12-31 07:42:07,881 INFO:     Found new best model at epoch 1
2022-12-31 07:42:07,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:07,882 INFO:     Epoch: 2
2022-12-31 07:42:09,500 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.453345317641894, 'Total loss': 0.453345317641894} | train loss {'Reaction outcome loss': 0.4360253634135218, 'Total loss': 0.4360253634135218}
2022-12-31 07:42:09,500 INFO:     Found new best model at epoch 2
2022-12-31 07:42:09,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:09,501 INFO:     Epoch: 3
2022-12-31 07:42:11,123 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4319775273402532, 'Total loss': 0.4319775273402532} | train loss {'Reaction outcome loss': 0.39691844609749577, 'Total loss': 0.39691844609749577}
2022-12-31 07:42:11,123 INFO:     Found new best model at epoch 3
2022-12-31 07:42:11,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:11,124 INFO:     Epoch: 4
2022-12-31 07:42:12,734 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4321081876754761, 'Total loss': 0.4321081876754761} | train loss {'Reaction outcome loss': 0.3659306902465594, 'Total loss': 0.3659306902465594}
2022-12-31 07:42:12,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:12,735 INFO:     Epoch: 5
2022-12-31 07:42:14,359 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40648353099823, 'Total loss': 0.40648353099823} | train loss {'Reaction outcome loss': 0.34397301344323333, 'Total loss': 0.34397301344323333}
2022-12-31 07:42:14,359 INFO:     Found new best model at epoch 5
2022-12-31 07:42:14,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:14,360 INFO:     Epoch: 6
2022-12-31 07:42:15,982 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37961699763933815, 'Total loss': 0.37961699763933815} | train loss {'Reaction outcome loss': 0.32616036181358526, 'Total loss': 0.32616036181358526}
2022-12-31 07:42:15,982 INFO:     Found new best model at epoch 6
2022-12-31 07:42:15,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:15,983 INFO:     Epoch: 7
2022-12-31 07:42:17,614 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40507190823554995, 'Total loss': 0.40507190823554995} | train loss {'Reaction outcome loss': 0.3059916993752666, 'Total loss': 0.3059916993752666}
2022-12-31 07:42:17,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:17,614 INFO:     Epoch: 8
2022-12-31 07:42:19,239 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3988744874795278, 'Total loss': 0.3988744874795278} | train loss {'Reaction outcome loss': 0.29269002837530017, 'Total loss': 0.29269002837530017}
2022-12-31 07:42:19,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:19,239 INFO:     Epoch: 9
2022-12-31 07:42:20,860 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39363807837168374, 'Total loss': 0.39363807837168374} | train loss {'Reaction outcome loss': 0.27763454871673654, 'Total loss': 0.27763454871673654}
2022-12-31 07:42:20,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:20,860 INFO:     Epoch: 10
2022-12-31 07:42:22,474 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3735658248265584, 'Total loss': 0.3735658248265584} | train loss {'Reaction outcome loss': 0.2666570328883011, 'Total loss': 0.2666570328883011}
2022-12-31 07:42:22,475 INFO:     Found new best model at epoch 10
2022-12-31 07:42:22,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:22,476 INFO:     Epoch: 11
2022-12-31 07:42:24,100 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39182326992352806, 'Total loss': 0.39182326992352806} | train loss {'Reaction outcome loss': 0.2551345769315958, 'Total loss': 0.2551345769315958}
2022-12-31 07:42:24,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:24,100 INFO:     Epoch: 12
2022-12-31 07:42:25,720 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4214583287636439, 'Total loss': 0.4214583287636439} | train loss {'Reaction outcome loss': 0.24600213899338333, 'Total loss': 0.24600213899338333}
2022-12-31 07:42:25,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:25,720 INFO:     Epoch: 13
2022-12-31 07:42:27,329 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40444974799950917, 'Total loss': 0.40444974799950917} | train loss {'Reaction outcome loss': 0.23674031960213707, 'Total loss': 0.23674031960213707}
2022-12-31 07:42:27,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:27,330 INFO:     Epoch: 14
2022-12-31 07:42:28,945 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3872034172217051, 'Total loss': 0.3872034172217051} | train loss {'Reaction outcome loss': 0.2320940759794338, 'Total loss': 0.2320940759794338}
2022-12-31 07:42:28,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:28,945 INFO:     Epoch: 15
2022-12-31 07:42:30,594 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3683286984761556, 'Total loss': 0.3683286984761556} | train loss {'Reaction outcome loss': 0.22123133596100839, 'Total loss': 0.22123133596100839}
2022-12-31 07:42:30,594 INFO:     Found new best model at epoch 15
2022-12-31 07:42:30,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:30,595 INFO:     Epoch: 16
2022-12-31 07:42:32,204 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3901073202490807, 'Total loss': 0.3901073202490807} | train loss {'Reaction outcome loss': 0.21527629337497872, 'Total loss': 0.21527629337497872}
2022-12-31 07:42:32,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:32,204 INFO:     Epoch: 17
2022-12-31 07:42:33,856 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39415025065342585, 'Total loss': 0.39415025065342585} | train loss {'Reaction outcome loss': 0.21014106106420938, 'Total loss': 0.21014106106420938}
2022-12-31 07:42:33,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:33,856 INFO:     Epoch: 18
2022-12-31 07:42:35,493 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40193528135617573, 'Total loss': 0.40193528135617573} | train loss {'Reaction outcome loss': 0.19786929657315686, 'Total loss': 0.19786929657315686}
2022-12-31 07:42:35,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:35,493 INFO:     Epoch: 19
2022-12-31 07:42:37,091 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3800628145535787, 'Total loss': 0.3800628145535787} | train loss {'Reaction outcome loss': 0.19668559018644866, 'Total loss': 0.19668559018644866}
2022-12-31 07:42:37,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:37,091 INFO:     Epoch: 20
2022-12-31 07:42:38,740 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3889551063378652, 'Total loss': 0.3889551063378652} | train loss {'Reaction outcome loss': 0.19039101237907027, 'Total loss': 0.19039101237907027}
2022-12-31 07:42:38,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:38,741 INFO:     Epoch: 21
2022-12-31 07:42:40,337 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3974516957998276, 'Total loss': 0.3974516957998276} | train loss {'Reaction outcome loss': 0.18824102210873453, 'Total loss': 0.18824102210873453}
2022-12-31 07:42:40,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:40,338 INFO:     Epoch: 22
2022-12-31 07:42:41,947 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4090110023816427, 'Total loss': 0.4090110023816427} | train loss {'Reaction outcome loss': 0.18225129956828198, 'Total loss': 0.18225129956828198}
2022-12-31 07:42:41,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:41,947 INFO:     Epoch: 23
2022-12-31 07:42:43,592 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40224708219369254, 'Total loss': 0.40224708219369254} | train loss {'Reaction outcome loss': 0.18176161535220206, 'Total loss': 0.18176161535220206}
2022-12-31 07:42:43,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:43,592 INFO:     Epoch: 24
2022-12-31 07:42:45,232 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.423556383450826, 'Total loss': 0.423556383450826} | train loss {'Reaction outcome loss': 0.1763062525581378, 'Total loss': 0.1763062525581378}
2022-12-31 07:42:45,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:45,233 INFO:     Epoch: 25
2022-12-31 07:42:46,837 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41205116411050163, 'Total loss': 0.41205116411050163} | train loss {'Reaction outcome loss': 0.17083040542601452, 'Total loss': 0.17083040542601452}
2022-12-31 07:42:46,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:46,838 INFO:     Epoch: 26
2022-12-31 07:42:48,442 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40943423261245093, 'Total loss': 0.40943423261245093} | train loss {'Reaction outcome loss': 0.16896924722844558, 'Total loss': 0.16896924722844558}
2022-12-31 07:42:48,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:48,443 INFO:     Epoch: 27
2022-12-31 07:42:50,054 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4039404273033142, 'Total loss': 0.4039404273033142} | train loss {'Reaction outcome loss': 0.16644973345916636, 'Total loss': 0.16644973345916636}
2022-12-31 07:42:50,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:50,054 INFO:     Epoch: 28
2022-12-31 07:42:51,703 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4050598671038946, 'Total loss': 0.4050598671038946} | train loss {'Reaction outcome loss': 0.1587829566186797, 'Total loss': 0.1587829566186797}
2022-12-31 07:42:51,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:51,704 INFO:     Epoch: 29
2022-12-31 07:42:53,333 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44345077872276306, 'Total loss': 0.44345077872276306} | train loss {'Reaction outcome loss': 0.1614193071264529, 'Total loss': 0.1614193071264529}
2022-12-31 07:42:53,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:53,334 INFO:     Epoch: 30
2022-12-31 07:42:54,950 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41701329747835797, 'Total loss': 0.41701329747835797} | train loss {'Reaction outcome loss': 0.15813679284123827, 'Total loss': 0.15813679284123827}
2022-12-31 07:42:54,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:54,951 INFO:     Epoch: 31
2022-12-31 07:42:56,600 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42011564622322717, 'Total loss': 0.42011564622322717} | train loss {'Reaction outcome loss': 0.15644837023663152, 'Total loss': 0.15644837023663152}
2022-12-31 07:42:56,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:56,600 INFO:     Epoch: 32
2022-12-31 07:42:58,208 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.444911985596021, 'Total loss': 0.444911985596021} | train loss {'Reaction outcome loss': 0.15282973004708977, 'Total loss': 0.15282973004708977}
2022-12-31 07:42:58,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:58,208 INFO:     Epoch: 33
2022-12-31 07:42:59,816 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4585292716821035, 'Total loss': 0.4585292716821035} | train loss {'Reaction outcome loss': 0.1494711137047024, 'Total loss': 0.1494711137047024}
2022-12-31 07:42:59,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:42:59,817 INFO:     Epoch: 34
2022-12-31 07:43:01,423 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4164020508527756, 'Total loss': 0.4164020508527756} | train loss {'Reaction outcome loss': 0.14800993624707534, 'Total loss': 0.14800993624707534}
2022-12-31 07:43:01,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:01,423 INFO:     Epoch: 35
2022-12-31 07:43:03,030 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.459862278898557, 'Total loss': 0.459862278898557} | train loss {'Reaction outcome loss': 0.1495855495530813, 'Total loss': 0.1495855495530813}
2022-12-31 07:43:03,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:03,031 INFO:     Epoch: 36
2022-12-31 07:43:04,645 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4222831924756368, 'Total loss': 0.4222831924756368} | train loss {'Reaction outcome loss': 0.14439434403414247, 'Total loss': 0.14439434403414247}
2022-12-31 07:43:04,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:04,645 INFO:     Epoch: 37
2022-12-31 07:43:06,260 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4448568771282832, 'Total loss': 0.4448568771282832} | train loss {'Reaction outcome loss': 0.14450143219862324, 'Total loss': 0.14450143219862324}
2022-12-31 07:43:06,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:06,260 INFO:     Epoch: 38
2022-12-31 07:43:07,877 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45163948138554894, 'Total loss': 0.45163948138554894} | train loss {'Reaction outcome loss': 0.14416617021494865, 'Total loss': 0.14416617021494865}
2022-12-31 07:43:07,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:07,878 INFO:     Epoch: 39
2022-12-31 07:43:09,486 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43751135369141897, 'Total loss': 0.43751135369141897} | train loss {'Reaction outcome loss': 0.14160861699658372, 'Total loss': 0.14160861699658372}
2022-12-31 07:43:09,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:09,486 INFO:     Epoch: 40
2022-12-31 07:43:11,089 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42777071048816045, 'Total loss': 0.42777071048816045} | train loss {'Reaction outcome loss': 0.14142437078344233, 'Total loss': 0.14142437078344233}
2022-12-31 07:43:11,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:11,090 INFO:     Epoch: 41
2022-12-31 07:43:12,696 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41425628736615183, 'Total loss': 0.41425628736615183} | train loss {'Reaction outcome loss': 0.14113712626387004, 'Total loss': 0.14113712626387004}
2022-12-31 07:43:12,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:12,696 INFO:     Epoch: 42
2022-12-31 07:43:14,306 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4347543666760127, 'Total loss': 0.4347543666760127} | train loss {'Reaction outcome loss': 0.13609778284550691, 'Total loss': 0.13609778284550691}
2022-12-31 07:43:14,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:14,306 INFO:     Epoch: 43
2022-12-31 07:43:15,915 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4429170956214269, 'Total loss': 0.4429170956214269} | train loss {'Reaction outcome loss': 0.1395383926523156, 'Total loss': 0.1395383926523156}
2022-12-31 07:43:15,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:15,915 INFO:     Epoch: 44
2022-12-31 07:43:17,549 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44298554460207623, 'Total loss': 0.44298554460207623} | train loss {'Reaction outcome loss': 0.13418115525893923, 'Total loss': 0.13418115525893923}
2022-12-31 07:43:17,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:17,550 INFO:     Epoch: 45
2022-12-31 07:43:19,162 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4919265270233154, 'Total loss': 0.4919265270233154} | train loss {'Reaction outcome loss': 0.13442932067262212, 'Total loss': 0.13442932067262212}
2022-12-31 07:43:19,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:19,162 INFO:     Epoch: 46
2022-12-31 07:43:20,782 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4356503208478292, 'Total loss': 0.4356503208478292} | train loss {'Reaction outcome loss': 0.13520543906246277, 'Total loss': 0.13520543906246277}
2022-12-31 07:43:20,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:20,782 INFO:     Epoch: 47
2022-12-31 07:43:22,391 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43017910172541934, 'Total loss': 0.43017910172541934} | train loss {'Reaction outcome loss': 0.13352297461102206, 'Total loss': 0.13352297461102206}
2022-12-31 07:43:22,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:22,391 INFO:     Epoch: 48
2022-12-31 07:43:24,042 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4494225064913432, 'Total loss': 0.4494225064913432} | train loss {'Reaction outcome loss': 0.13104535523890415, 'Total loss': 0.13104535523890415}
2022-12-31 07:43:24,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:24,042 INFO:     Epoch: 49
2022-12-31 07:43:25,645 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4281153976917267, 'Total loss': 0.4281153976917267} | train loss {'Reaction outcome loss': 0.12916918769376828, 'Total loss': 0.12916918769376828}
2022-12-31 07:43:25,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:25,646 INFO:     Epoch: 50
2022-12-31 07:43:27,259 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4384380658467611, 'Total loss': 0.4384380658467611} | train loss {'Reaction outcome loss': 0.13063775420861903, 'Total loss': 0.13063775420861903}
2022-12-31 07:43:27,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:27,259 INFO:     Epoch: 51
2022-12-31 07:43:28,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43280080358187356, 'Total loss': 0.43280080358187356} | train loss {'Reaction outcome loss': 0.12560368570954586, 'Total loss': 0.12560368570954586}
2022-12-31 07:43:28,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:28,913 INFO:     Epoch: 52
2022-12-31 07:43:30,537 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49002140363057456, 'Total loss': 0.49002140363057456} | train loss {'Reaction outcome loss': 0.12621852504021494, 'Total loss': 0.12621852504021494}
2022-12-31 07:43:30,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:30,538 INFO:     Epoch: 53
2022-12-31 07:43:32,160 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43567507664362587, 'Total loss': 0.43567507664362587} | train loss {'Reaction outcome loss': 0.12455922712055273, 'Total loss': 0.12455922712055273}
2022-12-31 07:43:32,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:32,161 INFO:     Epoch: 54
2022-12-31 07:43:33,813 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4327638934055964, 'Total loss': 0.4327638934055964} | train loss {'Reaction outcome loss': 0.1255728298335941, 'Total loss': 0.1255728298335941}
2022-12-31 07:43:33,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:33,813 INFO:     Epoch: 55
2022-12-31 07:43:35,451 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4469707548618317, 'Total loss': 0.4469707548618317} | train loss {'Reaction outcome loss': 0.12208724466329236, 'Total loss': 0.12208724466329236}
2022-12-31 07:43:35,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:35,451 INFO:     Epoch: 56
2022-12-31 07:43:37,063 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4485280136267344, 'Total loss': 0.4485280136267344} | train loss {'Reaction outcome loss': 0.1253844823520019, 'Total loss': 0.1253844823520019}
2022-12-31 07:43:37,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:37,063 INFO:     Epoch: 57
2022-12-31 07:43:38,703 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4581734339396159, 'Total loss': 0.4581734339396159} | train loss {'Reaction outcome loss': 0.1228940394999337, 'Total loss': 0.1228940394999337}
2022-12-31 07:43:38,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:38,703 INFO:     Epoch: 58
2022-12-31 07:43:40,321 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43247210582097373, 'Total loss': 0.43247210582097373} | train loss {'Reaction outcome loss': 0.12398769869978954, 'Total loss': 0.12398769869978954}
2022-12-31 07:43:40,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:40,321 INFO:     Epoch: 59
2022-12-31 07:43:41,931 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49116730118791263, 'Total loss': 0.49116730118791263} | train loss {'Reaction outcome loss': 0.11948558303228424, 'Total loss': 0.11948558303228424}
2022-12-31 07:43:41,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:41,933 INFO:     Epoch: 60
2022-12-31 07:43:43,545 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46659700671831766, 'Total loss': 0.46659700671831766} | train loss {'Reaction outcome loss': 0.12599121622934964, 'Total loss': 0.12599121622934964}
2022-12-31 07:43:43,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:43,545 INFO:     Epoch: 61
2022-12-31 07:43:45,151 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45310980677604673, 'Total loss': 0.45310980677604673} | train loss {'Reaction outcome loss': 0.12029301117677378, 'Total loss': 0.12029301117677378}
2022-12-31 07:43:45,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:45,151 INFO:     Epoch: 62
2022-12-31 07:43:46,803 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4335762361685435, 'Total loss': 0.4335762361685435} | train loss {'Reaction outcome loss': 0.12164822922353327, 'Total loss': 0.12164822922353327}
2022-12-31 07:43:46,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:46,803 INFO:     Epoch: 63
2022-12-31 07:43:48,442 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4262749542792638, 'Total loss': 0.4262749542792638} | train loss {'Reaction outcome loss': 0.12055049380151568, 'Total loss': 0.12055049380151568}
2022-12-31 07:43:48,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:48,443 INFO:     Epoch: 64
2022-12-31 07:43:50,048 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41395699282487236, 'Total loss': 0.41395699282487236} | train loss {'Reaction outcome loss': 0.11607531712213735, 'Total loss': 0.11607531712213735}
2022-12-31 07:43:50,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:50,048 INFO:     Epoch: 65
2022-12-31 07:43:51,699 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4192248503367106, 'Total loss': 0.4192248503367106} | train loss {'Reaction outcome loss': 0.11535714402026667, 'Total loss': 0.11535714402026667}
2022-12-31 07:43:51,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:51,699 INFO:     Epoch: 66
2022-12-31 07:43:53,300 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46635928750038147, 'Total loss': 0.46635928750038147} | train loss {'Reaction outcome loss': 0.11469558376927663, 'Total loss': 0.11469558376927663}
2022-12-31 07:43:53,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:53,300 INFO:     Epoch: 67
2022-12-31 07:43:54,915 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4292240599791209, 'Total loss': 0.4292240599791209} | train loss {'Reaction outcome loss': 0.11824810566859877, 'Total loss': 0.11824810566859877}
2022-12-31 07:43:54,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:54,916 INFO:     Epoch: 68
2022-12-31 07:43:56,526 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4616138925155004, 'Total loss': 0.4616138925155004} | train loss {'Reaction outcome loss': 0.11765171918698525, 'Total loss': 0.11765171918698525}
2022-12-31 07:43:56,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:56,527 INFO:     Epoch: 69
2022-12-31 07:43:58,127 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4190853235622247, 'Total loss': 0.4190853235622247} | train loss {'Reaction outcome loss': 0.1186225124716378, 'Total loss': 0.1186225124716378}
2022-12-31 07:43:58,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:58,127 INFO:     Epoch: 70
2022-12-31 07:43:59,778 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4442716007431348, 'Total loss': 0.4442716007431348} | train loss {'Reaction outcome loss': 0.12178555079633846, 'Total loss': 0.12178555079633846}
2022-12-31 07:43:59,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:43:59,778 INFO:     Epoch: 71
2022-12-31 07:44:01,383 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5013479600350063, 'Total loss': 0.5013479600350063} | train loss {'Reaction outcome loss': 0.11944358311185654, 'Total loss': 0.11944358311185654}
2022-12-31 07:44:01,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:01,384 INFO:     Epoch: 72
2022-12-31 07:44:03,004 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.478209842244784, 'Total loss': 0.478209842244784} | train loss {'Reaction outcome loss': 0.11784023508245982, 'Total loss': 0.11784023508245982}
2022-12-31 07:44:03,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:03,005 INFO:     Epoch: 73
2022-12-31 07:44:04,611 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44625871777534487, 'Total loss': 0.44625871777534487} | train loss {'Reaction outcome loss': 0.11659763283334183, 'Total loss': 0.11659763283334183}
2022-12-31 07:44:04,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:04,611 INFO:     Epoch: 74
2022-12-31 07:44:06,212 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4404640128215154, 'Total loss': 0.4404640128215154} | train loss {'Reaction outcome loss': 0.1101214659585529, 'Total loss': 0.1101214659585529}
2022-12-31 07:44:06,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:06,212 INFO:     Epoch: 75
2022-12-31 07:44:07,815 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4007914513349533, 'Total loss': 0.4007914513349533} | train loss {'Reaction outcome loss': 0.10868890999551237, 'Total loss': 0.10868890999551237}
2022-12-31 07:44:07,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:07,816 INFO:     Epoch: 76
2022-12-31 07:44:09,467 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45777636269728345, 'Total loss': 0.45777636269728345} | train loss {'Reaction outcome loss': 0.10987567504864512, 'Total loss': 0.10987567504864512}
2022-12-31 07:44:09,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:09,467 INFO:     Epoch: 77
2022-12-31 07:44:11,074 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4635985970497131, 'Total loss': 0.4635985970497131} | train loss {'Reaction outcome loss': 0.10882369891560235, 'Total loss': 0.10882369891560235}
2022-12-31 07:44:11,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:11,074 INFO:     Epoch: 78
2022-12-31 07:44:12,681 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4476081262032191, 'Total loss': 0.4476081262032191} | train loss {'Reaction outcome loss': 0.11608263083570466, 'Total loss': 0.11608263083570466}
2022-12-31 07:44:12,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:12,682 INFO:     Epoch: 79
2022-12-31 07:44:14,296 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48309021691481274, 'Total loss': 0.48309021691481274} | train loss {'Reaction outcome loss': 0.11344911826750685, 'Total loss': 0.11344911826750685}
2022-12-31 07:44:14,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:14,296 INFO:     Epoch: 80
2022-12-31 07:44:15,895 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4636965371668339, 'Total loss': 0.4636965371668339} | train loss {'Reaction outcome loss': 0.11114565466775349, 'Total loss': 0.11114565466775349}
2022-12-31 07:44:15,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:15,896 INFO:     Epoch: 81
2022-12-31 07:44:17,499 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4360603799422582, 'Total loss': 0.4360603799422582} | train loss {'Reaction outcome loss': 0.11664052919423493, 'Total loss': 0.11664052919423493}
2022-12-31 07:44:17,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:17,500 INFO:     Epoch: 82
2022-12-31 07:44:19,104 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45529905160268147, 'Total loss': 0.45529905160268147} | train loss {'Reaction outcome loss': 0.10965307517636595, 'Total loss': 0.10965307517636595}
2022-12-31 07:44:19,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:19,105 INFO:     Epoch: 83
2022-12-31 07:44:20,713 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42591632852951683, 'Total loss': 0.42591632852951683} | train loss {'Reaction outcome loss': 0.11359646920298301, 'Total loss': 0.11359646920298301}
2022-12-31 07:44:20,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:20,713 INFO:     Epoch: 84
2022-12-31 07:44:22,327 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.432870594280151, 'Total loss': 0.432870594280151} | train loss {'Reaction outcome loss': 0.11160430679247327, 'Total loss': 0.11160430679247327}
2022-12-31 07:44:22,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:22,328 INFO:     Epoch: 85
2022-12-31 07:44:23,965 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4354065239429474, 'Total loss': 0.4354065239429474} | train loss {'Reaction outcome loss': 0.10477834249707278, 'Total loss': 0.10477834249707278}
2022-12-31 07:44:23,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:23,965 INFO:     Epoch: 86
2022-12-31 07:44:25,568 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43288299441337585, 'Total loss': 0.43288299441337585} | train loss {'Reaction outcome loss': 0.10898000225220827, 'Total loss': 0.10898000225220827}
2022-12-31 07:44:25,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:25,569 INFO:     Epoch: 87
2022-12-31 07:44:27,171 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4487664997577667, 'Total loss': 0.4487664997577667} | train loss {'Reaction outcome loss': 0.10179075895873219, 'Total loss': 0.10179075895873219}
2022-12-31 07:44:27,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:27,171 INFO:     Epoch: 88
2022-12-31 07:44:28,772 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43694575627644855, 'Total loss': 0.43694575627644855} | train loss {'Reaction outcome loss': 0.10847176646687988, 'Total loss': 0.10847176646687988}
2022-12-31 07:44:28,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:28,772 INFO:     Epoch: 89
2022-12-31 07:44:30,385 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42103425959746044, 'Total loss': 0.42103425959746044} | train loss {'Reaction outcome loss': 0.10952283826190978, 'Total loss': 0.10952283826190978}
2022-12-31 07:44:30,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:30,386 INFO:     Epoch: 90
2022-12-31 07:44:32,036 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4353695395092169, 'Total loss': 0.4353695395092169} | train loss {'Reaction outcome loss': 0.11398472834929117, 'Total loss': 0.11398472834929117}
2022-12-31 07:44:32,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:32,036 INFO:     Epoch: 91
2022-12-31 07:44:33,635 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43986424009005226, 'Total loss': 0.43986424009005226} | train loss {'Reaction outcome loss': 0.11048087509167143, 'Total loss': 0.11048087509167143}
2022-12-31 07:44:33,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:33,635 INFO:     Epoch: 92
2022-12-31 07:44:35,241 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4327319284280141, 'Total loss': 0.4327319284280141} | train loss {'Reaction outcome loss': 0.10808086868147808, 'Total loss': 0.10808086868147808}
2022-12-31 07:44:35,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:35,242 INFO:     Epoch: 93
2022-12-31 07:44:36,848 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44197270075480144, 'Total loss': 0.44197270075480144} | train loss {'Reaction outcome loss': 0.10617332357019323, 'Total loss': 0.10617332357019323}
2022-12-31 07:44:36,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:36,848 INFO:     Epoch: 94
2022-12-31 07:44:38,490 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.426994530359904, 'Total loss': 0.426994530359904} | train loss {'Reaction outcome loss': 0.10541153371242304, 'Total loss': 0.10541153371242304}
2022-12-31 07:44:38,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:38,490 INFO:     Epoch: 95
2022-12-31 07:44:40,137 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45208751360575355, 'Total loss': 0.45208751360575355} | train loss {'Reaction outcome loss': 0.10412975308233804, 'Total loss': 0.10412975308233804}
2022-12-31 07:44:40,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:40,138 INFO:     Epoch: 96
2022-12-31 07:44:41,743 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4384504238764445, 'Total loss': 0.4384504238764445} | train loss {'Reaction outcome loss': 0.10434570425720274, 'Total loss': 0.10434570425720274}
2022-12-31 07:44:41,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:41,744 INFO:     Epoch: 97
2022-12-31 07:44:43,346 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43085233072439827, 'Total loss': 0.43085233072439827} | train loss {'Reaction outcome loss': 0.10533601541095923, 'Total loss': 0.10533601541095923}
2022-12-31 07:44:43,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:43,346 INFO:     Epoch: 98
2022-12-31 07:44:44,954 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4355675244703889, 'Total loss': 0.4355675244703889} | train loss {'Reaction outcome loss': 0.10693245524554139, 'Total loss': 0.10693245524554139}
2022-12-31 07:44:44,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:44,954 INFO:     Epoch: 99
2022-12-31 07:44:46,561 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4563654879728953, 'Total loss': 0.4563654879728953} | train loss {'Reaction outcome loss': 0.10344012093689484, 'Total loss': 0.10344012093689484}
2022-12-31 07:44:46,561 INFO:     Best model found after epoch 16 of 100.
2022-12-31 07:44:46,561 INFO:   Done with stage: TRAINING
2022-12-31 07:44:46,561 INFO:   Starting stage: EVALUATION
2022-12-31 07:44:46,699 INFO:   Done with stage: EVALUATION
2022-12-31 07:44:46,699 INFO:   Leaving out SEQ value Fold_1
2022-12-31 07:44:46,712 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 07:44:46,712 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:44:47,368 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:44:47,368 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:44:47,436 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:44:47,436 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:44:47,436 INFO:     No hyperparam tuning for this model
2022-12-31 07:44:47,436 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:44:47,436 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:44:47,437 INFO:     None feature selector for col prot
2022-12-31 07:44:47,437 INFO:     None feature selector for col prot
2022-12-31 07:44:47,437 INFO:     None feature selector for col prot
2022-12-31 07:44:47,438 INFO:     None feature selector for col chem
2022-12-31 07:44:47,438 INFO:     None feature selector for col chem
2022-12-31 07:44:47,438 INFO:     None feature selector for col chem
2022-12-31 07:44:47,438 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:44:47,438 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:44:47,440 INFO:     Number of params in model 224011
2022-12-31 07:44:47,443 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:44:47,443 INFO:   Starting stage: TRAINING
2022-12-31 07:44:47,491 INFO:     Val loss before train {'Reaction outcome loss': 0.9961176037788391, 'Total loss': 0.9961176037788391}
2022-12-31 07:44:47,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:47,491 INFO:     Epoch: 0
2022-12-31 07:44:49,102 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5816270271937053, 'Total loss': 0.5816270271937053} | train loss {'Reaction outcome loss': 0.7810645840898918, 'Total loss': 0.7810645840898918}
2022-12-31 07:44:49,104 INFO:     Found new best model at epoch 0
2022-12-31 07:44:49,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:49,105 INFO:     Epoch: 1
2022-12-31 07:44:50,750 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5045066336790721, 'Total loss': 0.5045066336790721} | train loss {'Reaction outcome loss': 0.5134690835745666, 'Total loss': 0.5134690835745666}
2022-12-31 07:44:50,750 INFO:     Found new best model at epoch 1
2022-12-31 07:44:50,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:50,751 INFO:     Epoch: 2
2022-12-31 07:44:52,362 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4845969061056773, 'Total loss': 0.4845969061056773} | train loss {'Reaction outcome loss': 0.4466561108936358, 'Total loss': 0.4466561108936358}
2022-12-31 07:44:52,363 INFO:     Found new best model at epoch 2
2022-12-31 07:44:52,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:52,364 INFO:     Epoch: 3
2022-12-31 07:44:53,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46135473251342773, 'Total loss': 0.46135473251342773} | train loss {'Reaction outcome loss': 0.4109002133681826, 'Total loss': 0.4109002133681826}
2022-12-31 07:44:53,975 INFO:     Found new best model at epoch 3
2022-12-31 07:44:53,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:53,976 INFO:     Epoch: 4
2022-12-31 07:44:55,588 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4393838663895925, 'Total loss': 0.4393838663895925} | train loss {'Reaction outcome loss': 0.3808621467519416, 'Total loss': 0.3808621467519416}
2022-12-31 07:44:55,588 INFO:     Found new best model at epoch 4
2022-12-31 07:44:55,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:55,590 INFO:     Epoch: 5
2022-12-31 07:44:57,192 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4436193108558655, 'Total loss': 0.4436193108558655} | train loss {'Reaction outcome loss': 0.35652318545175293, 'Total loss': 0.35652318545175293}
2022-12-31 07:44:57,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:57,193 INFO:     Epoch: 6
2022-12-31 07:44:58,806 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4629283587137858, 'Total loss': 0.4629283587137858} | train loss {'Reaction outcome loss': 0.33750465724372514, 'Total loss': 0.33750465724372514}
2022-12-31 07:44:58,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:44:58,807 INFO:     Epoch: 7
2022-12-31 07:45:00,413 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4426002343495687, 'Total loss': 0.4426002343495687} | train loss {'Reaction outcome loss': 0.31747926494283396, 'Total loss': 0.31747926494283396}
2022-12-31 07:45:00,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:00,413 INFO:     Epoch: 8
2022-12-31 07:45:02,028 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44929121136665345, 'Total loss': 0.44929121136665345} | train loss {'Reaction outcome loss': 0.30360826035540034, 'Total loss': 0.30360826035540034}
2022-12-31 07:45:02,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:02,028 INFO:     Epoch: 9
2022-12-31 07:45:03,643 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43294916649659476, 'Total loss': 0.43294916649659476} | train loss {'Reaction outcome loss': 0.2904803562012032, 'Total loss': 0.2904803562012032}
2022-12-31 07:45:03,643 INFO:     Found new best model at epoch 9
2022-12-31 07:45:03,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:03,644 INFO:     Epoch: 10
2022-12-31 07:45:05,259 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.424576398730278, 'Total loss': 0.424576398730278} | train loss {'Reaction outcome loss': 0.2807799931615591, 'Total loss': 0.2807799931615591}
2022-12-31 07:45:05,259 INFO:     Found new best model at epoch 10
2022-12-31 07:45:05,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:05,260 INFO:     Epoch: 11
2022-12-31 07:45:06,862 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44934933284918466, 'Total loss': 0.44934933284918466} | train loss {'Reaction outcome loss': 0.27120644794980975, 'Total loss': 0.27120644794980975}
2022-12-31 07:45:06,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:06,862 INFO:     Epoch: 12
2022-12-31 07:45:08,478 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4301978548367818, 'Total loss': 0.4301978548367818} | train loss {'Reaction outcome loss': 0.2623862619001935, 'Total loss': 0.2623862619001935}
2022-12-31 07:45:08,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:08,478 INFO:     Epoch: 13
2022-12-31 07:45:10,089 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41609402000904083, 'Total loss': 0.41609402000904083} | train loss {'Reaction outcome loss': 0.24922685100812547, 'Total loss': 0.24922685100812547}
2022-12-31 07:45:10,089 INFO:     Found new best model at epoch 13
2022-12-31 07:45:10,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:10,090 INFO:     Epoch: 14
2022-12-31 07:45:11,703 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4433840860923131, 'Total loss': 0.4433840860923131} | train loss {'Reaction outcome loss': 0.2430818388578448, 'Total loss': 0.2430818388578448}
2022-12-31 07:45:11,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:11,703 INFO:     Epoch: 15
2022-12-31 07:45:13,315 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46972543398539224, 'Total loss': 0.46972543398539224} | train loss {'Reaction outcome loss': 0.2353739346765036, 'Total loss': 0.2353739346765036}
2022-12-31 07:45:13,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:13,315 INFO:     Epoch: 16
2022-12-31 07:45:14,918 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45512742896874747, 'Total loss': 0.45512742896874747} | train loss {'Reaction outcome loss': 0.22592425826991344, 'Total loss': 0.22592425826991344}
2022-12-31 07:45:14,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:14,918 INFO:     Epoch: 17
2022-12-31 07:45:16,529 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4290405829747518, 'Total loss': 0.4290405829747518} | train loss {'Reaction outcome loss': 0.22244015990001878, 'Total loss': 0.22244015990001878}
2022-12-31 07:45:16,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:16,529 INFO:     Epoch: 18
2022-12-31 07:45:18,132 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42460709661245344, 'Total loss': 0.42460709661245344} | train loss {'Reaction outcome loss': 0.2149766376445981, 'Total loss': 0.2149766376445981}
2022-12-31 07:45:18,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:18,133 INFO:     Epoch: 19
2022-12-31 07:45:19,734 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45719531377156575, 'Total loss': 0.45719531377156575} | train loss {'Reaction outcome loss': 0.2083839881777709, 'Total loss': 0.2083839881777709}
2022-12-31 07:45:19,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:19,736 INFO:     Epoch: 20
2022-12-31 07:45:21,338 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4505902349948883, 'Total loss': 0.4505902349948883} | train loss {'Reaction outcome loss': 0.208638511380575, 'Total loss': 0.208638511380575}
2022-12-31 07:45:21,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:21,339 INFO:     Epoch: 21
2022-12-31 07:45:22,939 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45346079766750336, 'Total loss': 0.45346079766750336} | train loss {'Reaction outcome loss': 0.20047915974346392, 'Total loss': 0.20047915974346392}
2022-12-31 07:45:22,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:22,940 INFO:     Epoch: 22
2022-12-31 07:45:24,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44740652044614154, 'Total loss': 0.44740652044614154} | train loss {'Reaction outcome loss': 0.19529855260149623, 'Total loss': 0.19529855260149623}
2022-12-31 07:45:24,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:24,542 INFO:     Epoch: 23
2022-12-31 07:45:26,144 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46263085504372914, 'Total loss': 0.46263085504372914} | train loss {'Reaction outcome loss': 0.19009655333348435, 'Total loss': 0.19009655333348435}
2022-12-31 07:45:26,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:26,144 INFO:     Epoch: 24
2022-12-31 07:45:27,742 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4537744144598643, 'Total loss': 0.4537744144598643} | train loss {'Reaction outcome loss': 0.1878805007975902, 'Total loss': 0.1878805007975902}
2022-12-31 07:45:27,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:27,742 INFO:     Epoch: 25
2022-12-31 07:45:29,353 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.462453896800677, 'Total loss': 0.462453896800677} | train loss {'Reaction outcome loss': 0.1830922802026472, 'Total loss': 0.1830922802026472}
2022-12-31 07:45:29,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:29,353 INFO:     Epoch: 26
2022-12-31 07:45:30,965 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44793893496195475, 'Total loss': 0.44793893496195475} | train loss {'Reaction outcome loss': 0.1817756457403846, 'Total loss': 0.1817756457403846}
2022-12-31 07:45:30,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:30,965 INFO:     Epoch: 27
2022-12-31 07:45:32,573 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46781929234663644, 'Total loss': 0.46781929234663644} | train loss {'Reaction outcome loss': 0.1789993960818235, 'Total loss': 0.1789993960818235}
2022-12-31 07:45:32,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:32,573 INFO:     Epoch: 28
2022-12-31 07:45:34,215 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4473928143580755, 'Total loss': 0.4473928143580755} | train loss {'Reaction outcome loss': 0.1746572220432878, 'Total loss': 0.1746572220432878}
2022-12-31 07:45:34,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:34,215 INFO:     Epoch: 29
2022-12-31 07:45:35,819 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45239519874254863, 'Total loss': 0.45239519874254863} | train loss {'Reaction outcome loss': 0.1710351349813116, 'Total loss': 0.1710351349813116}
2022-12-31 07:45:35,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:35,819 INFO:     Epoch: 30
2022-12-31 07:45:37,424 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42618745764096577, 'Total loss': 0.42618745764096577} | train loss {'Reaction outcome loss': 0.16958229104396852, 'Total loss': 0.16958229104396852}
2022-12-31 07:45:37,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:37,424 INFO:     Epoch: 31
2022-12-31 07:45:39,070 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44818347493807476, 'Total loss': 0.44818347493807476} | train loss {'Reaction outcome loss': 0.16943500287504526, 'Total loss': 0.16943500287504526}
2022-12-31 07:45:39,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:39,070 INFO:     Epoch: 32
2022-12-31 07:45:40,672 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46356552342573804, 'Total loss': 0.46356552342573804} | train loss {'Reaction outcome loss': 0.16626623263378648, 'Total loss': 0.16626623263378648}
2022-12-31 07:45:40,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:40,672 INFO:     Epoch: 33
2022-12-31 07:45:42,277 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4622349093357722, 'Total loss': 0.4622349093357722} | train loss {'Reaction outcome loss': 0.15909835601388647, 'Total loss': 0.15909835601388647}
2022-12-31 07:45:42,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:42,277 INFO:     Epoch: 34
2022-12-31 07:45:43,880 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47715326845645906, 'Total loss': 0.47715326845645906} | train loss {'Reaction outcome loss': 0.16065032832514847, 'Total loss': 0.16065032832514847}
2022-12-31 07:45:43,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:43,881 INFO:     Epoch: 35
2022-12-31 07:45:45,477 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4771115134159724, 'Total loss': 0.4771115134159724} | train loss {'Reaction outcome loss': 0.1595233108671586, 'Total loss': 0.1595233108671586}
2022-12-31 07:45:45,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:45,478 INFO:     Epoch: 36
2022-12-31 07:45:47,127 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4444604198137919, 'Total loss': 0.4444604198137919} | train loss {'Reaction outcome loss': 0.15514621545091598, 'Total loss': 0.15514621545091598}
2022-12-31 07:45:47,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:47,127 INFO:     Epoch: 37
2022-12-31 07:45:48,776 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45196225345134733, 'Total loss': 0.45196225345134733} | train loss {'Reaction outcome loss': 0.15166884993141802, 'Total loss': 0.15166884993141802}
2022-12-31 07:45:48,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:48,776 INFO:     Epoch: 38
2022-12-31 07:45:50,379 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45477128426233926, 'Total loss': 0.45477128426233926} | train loss {'Reaction outcome loss': 0.15298723515775733, 'Total loss': 0.15298723515775733}
2022-12-31 07:45:50,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:50,379 INFO:     Epoch: 39
2022-12-31 07:45:52,004 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4764638284842173, 'Total loss': 0.4764638284842173} | train loss {'Reaction outcome loss': 0.14746282276881, 'Total loss': 0.14746282276881}
2022-12-31 07:45:52,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:52,005 INFO:     Epoch: 40
2022-12-31 07:45:53,616 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4423130830128988, 'Total loss': 0.4423130830128988} | train loss {'Reaction outcome loss': 0.1504388423806505, 'Total loss': 0.1504388423806505}
2022-12-31 07:45:53,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:53,616 INFO:     Epoch: 41
2022-12-31 07:45:55,221 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4298825899759928, 'Total loss': 0.4298825899759928} | train loss {'Reaction outcome loss': 0.141741273210921, 'Total loss': 0.141741273210921}
2022-12-31 07:45:55,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:55,223 INFO:     Epoch: 42
2022-12-31 07:45:56,829 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5098587413628896, 'Total loss': 0.5098587413628896} | train loss {'Reaction outcome loss': 0.14771457100762939, 'Total loss': 0.14771457100762939}
2022-12-31 07:45:56,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:56,829 INFO:     Epoch: 43
2022-12-31 07:45:58,478 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49899482329686484, 'Total loss': 0.49899482329686484} | train loss {'Reaction outcome loss': 0.14440673023775003, 'Total loss': 0.14440673023775003}
2022-12-31 07:45:58,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:45:58,478 INFO:     Epoch: 44
2022-12-31 07:46:00,074 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46756041248639424, 'Total loss': 0.46756041248639424} | train loss {'Reaction outcome loss': 0.14194455940657072, 'Total loss': 0.14194455940657072}
2022-12-31 07:46:00,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:00,074 INFO:     Epoch: 45
2022-12-31 07:46:01,686 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4940459529558818, 'Total loss': 0.4940459529558818} | train loss {'Reaction outcome loss': 0.1415980989657288, 'Total loss': 0.1415980989657288}
2022-12-31 07:46:01,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:01,687 INFO:     Epoch: 46
2022-12-31 07:46:03,290 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4807668964068095, 'Total loss': 0.4807668964068095} | train loss {'Reaction outcome loss': 0.1404173756528129, 'Total loss': 0.1404173756528129}
2022-12-31 07:46:03,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:03,290 INFO:     Epoch: 47
2022-12-31 07:46:04,895 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4753546794255575, 'Total loss': 0.4753546794255575} | train loss {'Reaction outcome loss': 0.1390692991931943, 'Total loss': 0.1390692991931943}
2022-12-31 07:46:04,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:04,895 INFO:     Epoch: 48
2022-12-31 07:46:06,500 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4672673677404722, 'Total loss': 0.4672673677404722} | train loss {'Reaction outcome loss': 0.13939949826942416, 'Total loss': 0.13939949826942416}
2022-12-31 07:46:06,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:06,501 INFO:     Epoch: 49
2022-12-31 07:46:08,149 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4762045443058014, 'Total loss': 0.4762045443058014} | train loss {'Reaction outcome loss': 0.131001878550181, 'Total loss': 0.131001878550181}
2022-12-31 07:46:08,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:08,149 INFO:     Epoch: 50
2022-12-31 07:46:09,756 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46991578141848245, 'Total loss': 0.46991578141848245} | train loss {'Reaction outcome loss': 0.13365063830244825, 'Total loss': 0.13365063830244825}
2022-12-31 07:46:09,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:09,756 INFO:     Epoch: 51
2022-12-31 07:46:11,352 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4874319225549698, 'Total loss': 0.4874319225549698} | train loss {'Reaction outcome loss': 0.13247330747816685, 'Total loss': 0.13247330747816685}
2022-12-31 07:46:11,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:11,352 INFO:     Epoch: 52
2022-12-31 07:46:12,950 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.512252750992775, 'Total loss': 0.512252750992775} | train loss {'Reaction outcome loss': 0.12971479677506825, 'Total loss': 0.12971479677506825}
2022-12-31 07:46:12,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:12,950 INFO:     Epoch: 53
2022-12-31 07:46:14,554 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4957776367664337, 'Total loss': 0.4957776367664337} | train loss {'Reaction outcome loss': 0.12874769005604958, 'Total loss': 0.12874769005604958}
2022-12-31 07:46:14,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:14,555 INFO:     Epoch: 54
2022-12-31 07:46:16,156 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46543985828757284, 'Total loss': 0.46543985828757284} | train loss {'Reaction outcome loss': 0.12529288043342804, 'Total loss': 0.12529288043342804}
2022-12-31 07:46:16,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:16,157 INFO:     Epoch: 55
2022-12-31 07:46:17,806 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44837574362754823, 'Total loss': 0.44837574362754823} | train loss {'Reaction outcome loss': 0.12904905910896014, 'Total loss': 0.12904905910896014}
2022-12-31 07:46:17,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:17,806 INFO:     Epoch: 56
2022-12-31 07:46:19,438 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4810539086659749, 'Total loss': 0.4810539086659749} | train loss {'Reaction outcome loss': 0.12549863605467726, 'Total loss': 0.12549863605467726}
2022-12-31 07:46:19,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:19,439 INFO:     Epoch: 57
2022-12-31 07:46:21,043 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49409931898117065, 'Total loss': 0.49409931898117065} | train loss {'Reaction outcome loss': 0.12526153873339513, 'Total loss': 0.12526153873339513}
2022-12-31 07:46:21,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:21,043 INFO:     Epoch: 58
2022-12-31 07:46:22,672 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4956701169411341, 'Total loss': 0.4956701169411341} | train loss {'Reaction outcome loss': 0.1308651347916546, 'Total loss': 0.1308651347916546}
2022-12-31 07:46:22,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:22,672 INFO:     Epoch: 59
2022-12-31 07:46:24,321 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5097204387187958, 'Total loss': 0.5097204387187958} | train loss {'Reaction outcome loss': 0.1254307523362991, 'Total loss': 0.1254307523362991}
2022-12-31 07:46:24,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:24,322 INFO:     Epoch: 60
2022-12-31 07:46:25,971 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4938389241695404, 'Total loss': 0.4938389241695404} | train loss {'Reaction outcome loss': 0.12457280585127645, 'Total loss': 0.12457280585127645}
2022-12-31 07:46:25,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:25,971 INFO:     Epoch: 61
2022-12-31 07:46:27,608 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4663384844859441, 'Total loss': 0.4663384844859441} | train loss {'Reaction outcome loss': 0.12306652925432707, 'Total loss': 0.12306652925432707}
2022-12-31 07:46:27,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:27,608 INFO:     Epoch: 62
2022-12-31 07:46:29,257 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5113435516754786, 'Total loss': 0.5113435516754786} | train loss {'Reaction outcome loss': 0.12069560468271646, 'Total loss': 0.12069560468271646}
2022-12-31 07:46:29,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:29,257 INFO:     Epoch: 63
2022-12-31 07:46:30,895 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4730573376019796, 'Total loss': 0.4730573376019796} | train loss {'Reaction outcome loss': 0.1216211173663011, 'Total loss': 0.1216211173663011}
2022-12-31 07:46:30,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:30,896 INFO:     Epoch: 64
2022-12-31 07:46:32,509 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4902544031540553, 'Total loss': 0.4902544031540553} | train loss {'Reaction outcome loss': 0.12337461876832492, 'Total loss': 0.12337461876832492}
2022-12-31 07:46:32,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:32,509 INFO:     Epoch: 65
2022-12-31 07:46:34,120 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46459822754065194, 'Total loss': 0.46459822754065194} | train loss {'Reaction outcome loss': 0.12283899260508101, 'Total loss': 0.12283899260508101}
2022-12-31 07:46:34,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:34,120 INFO:     Epoch: 66
2022-12-31 07:46:35,731 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4714797476927439, 'Total loss': 0.4714797476927439} | train loss {'Reaction outcome loss': 0.12246173810057451, 'Total loss': 0.12246173810057451}
2022-12-31 07:46:35,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:35,731 INFO:     Epoch: 67
2022-12-31 07:46:37,333 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4865906755129496, 'Total loss': 0.4865906755129496} | train loss {'Reaction outcome loss': 0.12124063206979338, 'Total loss': 0.12124063206979338}
2022-12-31 07:46:37,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:37,333 INFO:     Epoch: 68
2022-12-31 07:46:38,945 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48141034245491027, 'Total loss': 0.48141034245491027} | train loss {'Reaction outcome loss': 0.11968589609787955, 'Total loss': 0.11968589609787955}
2022-12-31 07:46:38,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:38,945 INFO:     Epoch: 69
2022-12-31 07:46:40,561 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4866642047961553, 'Total loss': 0.4866642047961553} | train loss {'Reaction outcome loss': 0.11931666037251316, 'Total loss': 0.11931666037251316}
2022-12-31 07:46:40,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:40,561 INFO:     Epoch: 70
2022-12-31 07:46:42,165 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47220541834831237, 'Total loss': 0.47220541834831237} | train loss {'Reaction outcome loss': 0.11939561367884659, 'Total loss': 0.11939561367884659}
2022-12-31 07:46:42,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:42,165 INFO:     Epoch: 71
2022-12-31 07:46:43,771 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48868103623390197, 'Total loss': 0.48868103623390197} | train loss {'Reaction outcome loss': 0.11681229768008211, 'Total loss': 0.11681229768008211}
2022-12-31 07:46:43,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:43,771 INFO:     Epoch: 72
2022-12-31 07:46:45,376 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46436547140280404, 'Total loss': 0.46436547140280404} | train loss {'Reaction outcome loss': 0.11494522955928026, 'Total loss': 0.11494522955928026}
2022-12-31 07:46:45,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:45,377 INFO:     Epoch: 73
2022-12-31 07:46:47,010 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4898956557114919, 'Total loss': 0.4898956557114919} | train loss {'Reaction outcome loss': 0.11680706595682477, 'Total loss': 0.11680706595682477}
2022-12-31 07:46:47,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:47,011 INFO:     Epoch: 74
2022-12-31 07:46:48,610 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49517656763394674, 'Total loss': 0.49517656763394674} | train loss {'Reaction outcome loss': 0.11895541295946242, 'Total loss': 0.11895541295946242}
2022-12-31 07:46:48,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:48,610 INFO:     Epoch: 75
2022-12-31 07:46:50,206 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49295519987742104, 'Total loss': 0.49295519987742104} | train loss {'Reaction outcome loss': 0.11863685884839263, 'Total loss': 0.11863685884839263}
2022-12-31 07:46:50,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:50,207 INFO:     Epoch: 76
2022-12-31 07:46:51,808 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.515985502799352, 'Total loss': 0.515985502799352} | train loss {'Reaction outcome loss': 0.11771997449797218, 'Total loss': 0.11771997449797218}
2022-12-31 07:46:51,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:51,809 INFO:     Epoch: 77
2022-12-31 07:46:53,411 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49032034873962405, 'Total loss': 0.49032034873962405} | train loss {'Reaction outcome loss': 0.11939679630046343, 'Total loss': 0.11939679630046343}
2022-12-31 07:46:53,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:53,411 INFO:     Epoch: 78
2022-12-31 07:46:55,047 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46704626455903053, 'Total loss': 0.46704626455903053} | train loss {'Reaction outcome loss': 0.11529021640223226, 'Total loss': 0.11529021640223226}
2022-12-31 07:46:55,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:55,048 INFO:     Epoch: 79
2022-12-31 07:46:56,651 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48593507955471676, 'Total loss': 0.48593507955471676} | train loss {'Reaction outcome loss': 0.11688100379368249, 'Total loss': 0.11688100379368249}
2022-12-31 07:46:56,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:56,651 INFO:     Epoch: 80
2022-12-31 07:46:58,252 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5221429646015168, 'Total loss': 0.5221429646015168} | train loss {'Reaction outcome loss': 0.11132599878376417, 'Total loss': 0.11132599878376417}
2022-12-31 07:46:58,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:58,252 INFO:     Epoch: 81
2022-12-31 07:46:59,877 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5260531524817149, 'Total loss': 0.5260531524817149} | train loss {'Reaction outcome loss': 0.11069270339964406, 'Total loss': 0.11069270339964406}
2022-12-31 07:46:59,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:46:59,877 INFO:     Epoch: 82
2022-12-31 07:47:01,493 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47456349730491637, 'Total loss': 0.47456349730491637} | train loss {'Reaction outcome loss': 0.11214998349832901, 'Total loss': 0.11214998349832901}
2022-12-31 07:47:01,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:01,494 INFO:     Epoch: 83
2022-12-31 07:47:03,091 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49983241260051725, 'Total loss': 0.49983241260051725} | train loss {'Reaction outcome loss': 0.11083045290837432, 'Total loss': 0.11083045290837432}
2022-12-31 07:47:03,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:03,091 INFO:     Epoch: 84
2022-12-31 07:47:04,731 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4796175758043925, 'Total loss': 0.4796175758043925} | train loss {'Reaction outcome loss': 0.1133216424593634, 'Total loss': 0.1133216424593634}
2022-12-31 07:47:04,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:04,731 INFO:     Epoch: 85
2022-12-31 07:47:06,380 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4871130327383677, 'Total loss': 0.4871130327383677} | train loss {'Reaction outcome loss': 0.11694920731514664, 'Total loss': 0.11694920731514664}
2022-12-31 07:47:06,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:06,381 INFO:     Epoch: 86
2022-12-31 07:47:08,000 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5081539064645767, 'Total loss': 0.5081539064645767} | train loss {'Reaction outcome loss': 0.11376536750051118, 'Total loss': 0.11376536750051118}
2022-12-31 07:47:08,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:08,001 INFO:     Epoch: 87
2022-12-31 07:47:09,605 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5043696224689483, 'Total loss': 0.5043696224689483} | train loss {'Reaction outcome loss': 0.11870452869737888, 'Total loss': 0.11870452869737888}
2022-12-31 07:47:09,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:09,605 INFO:     Epoch: 88
2022-12-31 07:47:11,211 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4958735823631287, 'Total loss': 0.4958735823631287} | train loss {'Reaction outcome loss': 0.11425745326950874, 'Total loss': 0.11425745326950874}
2022-12-31 07:47:11,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:11,211 INFO:     Epoch: 89
2022-12-31 07:47:12,817 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49566173553466797, 'Total loss': 0.49566173553466797} | train loss {'Reaction outcome loss': 0.11546185449357178, 'Total loss': 0.11546185449357178}
2022-12-31 07:47:12,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:12,818 INFO:     Epoch: 90
2022-12-31 07:47:14,432 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4814345002174377, 'Total loss': 0.4814345002174377} | train loss {'Reaction outcome loss': 0.11003259977454959, 'Total loss': 0.11003259977454959}
2022-12-31 07:47:14,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:14,433 INFO:     Epoch: 91
2022-12-31 07:47:16,044 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49994808435440063, 'Total loss': 0.49994808435440063} | train loss {'Reaction outcome loss': 0.10924009196834136, 'Total loss': 0.10924009196834136}
2022-12-31 07:47:16,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:16,044 INFO:     Epoch: 92
2022-12-31 07:47:17,648 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4986728608608246, 'Total loss': 0.4986728608608246} | train loss {'Reaction outcome loss': 0.11129344244620144, 'Total loss': 0.11129344244620144}
2022-12-31 07:47:17,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:17,648 INFO:     Epoch: 93
2022-12-31 07:47:19,261 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49964346885681155, 'Total loss': 0.49964346885681155} | train loss {'Reaction outcome loss': 0.1082272439545877, 'Total loss': 0.1082272439545877}
2022-12-31 07:47:19,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:19,261 INFO:     Epoch: 94
2022-12-31 07:47:20,874 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47216346065203346, 'Total loss': 0.47216346065203346} | train loss {'Reaction outcome loss': 0.10587913475685963, 'Total loss': 0.10587913475685963}
2022-12-31 07:47:20,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:20,875 INFO:     Epoch: 95
2022-12-31 07:47:22,491 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49795694599548973, 'Total loss': 0.49795694599548973} | train loss {'Reaction outcome loss': 0.10910485975315155, 'Total loss': 0.10910485975315155}
2022-12-31 07:47:22,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:22,492 INFO:     Epoch: 96
2022-12-31 07:47:24,096 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4872743854920069, 'Total loss': 0.4872743854920069} | train loss {'Reaction outcome loss': 0.11594776752792353, 'Total loss': 0.11594776752792353}
2022-12-31 07:47:24,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:24,097 INFO:     Epoch: 97
2022-12-31 07:47:25,724 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4825951596101125, 'Total loss': 0.4825951596101125} | train loss {'Reaction outcome loss': 0.11756663311809899, 'Total loss': 0.11756663311809899}
2022-12-31 07:47:25,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:25,724 INFO:     Epoch: 98
2022-12-31 07:47:27,343 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5208275119463602, 'Total loss': 0.5208275119463602} | train loss {'Reaction outcome loss': 0.11386235775154112, 'Total loss': 0.11386235775154112}
2022-12-31 07:47:27,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:27,343 INFO:     Epoch: 99
2022-12-31 07:47:28,962 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48149941364924115, 'Total loss': 0.48149941364924115} | train loss {'Reaction outcome loss': 0.1071760068498008, 'Total loss': 0.1071760068498008}
2022-12-31 07:47:28,962 INFO:     Best model found after epoch 14 of 100.
2022-12-31 07:47:28,962 INFO:   Done with stage: TRAINING
2022-12-31 07:47:28,962 INFO:   Starting stage: EVALUATION
2022-12-31 07:47:29,101 INFO:   Done with stage: EVALUATION
2022-12-31 07:47:29,101 INFO:   Leaving out SEQ value Fold_2
2022-12-31 07:47:29,113 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 07:47:29,113 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:47:29,751 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:47:29,751 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:47:29,818 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:47:29,819 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:47:29,819 INFO:     No hyperparam tuning for this model
2022-12-31 07:47:29,819 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:47:29,819 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:47:29,819 INFO:     None feature selector for col prot
2022-12-31 07:47:29,820 INFO:     None feature selector for col prot
2022-12-31 07:47:29,820 INFO:     None feature selector for col prot
2022-12-31 07:47:29,820 INFO:     None feature selector for col chem
2022-12-31 07:47:29,820 INFO:     None feature selector for col chem
2022-12-31 07:47:29,820 INFO:     None feature selector for col chem
2022-12-31 07:47:29,820 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:47:29,821 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:47:29,822 INFO:     Number of params in model 224011
2022-12-31 07:47:29,826 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:47:29,826 INFO:   Starting stage: TRAINING
2022-12-31 07:47:29,871 INFO:     Val loss before train {'Reaction outcome loss': 0.8117591579755147, 'Total loss': 0.8117591579755147}
2022-12-31 07:47:29,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:29,872 INFO:     Epoch: 0
2022-12-31 07:47:31,470 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5194215297698974, 'Total loss': 0.5194215297698974} | train loss {'Reaction outcome loss': 0.7918472960864231, 'Total loss': 0.7918472960864231}
2022-12-31 07:47:31,470 INFO:     Found new best model at epoch 0
2022-12-31 07:47:31,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:31,471 INFO:     Epoch: 1
2022-12-31 07:47:33,080 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4710712472597758, 'Total loss': 0.4710712472597758} | train loss {'Reaction outcome loss': 0.5132569286958638, 'Total loss': 0.5132569286958638}
2022-12-31 07:47:33,081 INFO:     Found new best model at epoch 1
2022-12-31 07:47:33,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:33,082 INFO:     Epoch: 2
2022-12-31 07:47:34,684 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45450327495733894, 'Total loss': 0.45450327495733894} | train loss {'Reaction outcome loss': 0.44233483103387083, 'Total loss': 0.44233483103387083}
2022-12-31 07:47:34,684 INFO:     Found new best model at epoch 2
2022-12-31 07:47:34,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:34,685 INFO:     Epoch: 3
2022-12-31 07:47:36,284 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4492581437031428, 'Total loss': 0.4492581437031428} | train loss {'Reaction outcome loss': 0.4037991016011535, 'Total loss': 0.4037991016011535}
2022-12-31 07:47:36,284 INFO:     Found new best model at epoch 3
2022-12-31 07:47:36,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:36,285 INFO:     Epoch: 4
2022-12-31 07:47:37,884 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4590488647421201, 'Total loss': 0.4590488647421201} | train loss {'Reaction outcome loss': 0.37562930480246143, 'Total loss': 0.37562930480246143}
2022-12-31 07:47:37,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:37,884 INFO:     Epoch: 5
2022-12-31 07:47:39,526 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44374586939811705, 'Total loss': 0.44374586939811705} | train loss {'Reaction outcome loss': 0.3511298553124343, 'Total loss': 0.3511298553124343}
2022-12-31 07:47:39,527 INFO:     Found new best model at epoch 5
2022-12-31 07:47:39,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:39,528 INFO:     Epoch: 6
2022-12-31 07:47:41,148 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42605829735596973, 'Total loss': 0.42605829735596973} | train loss {'Reaction outcome loss': 0.3284800354623314, 'Total loss': 0.3284800354623314}
2022-12-31 07:47:41,148 INFO:     Found new best model at epoch 6
2022-12-31 07:47:41,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:41,149 INFO:     Epoch: 7
2022-12-31 07:47:42,745 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43385566473007203, 'Total loss': 0.43385566473007203} | train loss {'Reaction outcome loss': 0.31465587726770305, 'Total loss': 0.31465587726770305}
2022-12-31 07:47:42,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:42,745 INFO:     Epoch: 8
2022-12-31 07:47:44,342 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4313656181097031, 'Total loss': 0.4313656181097031} | train loss {'Reaction outcome loss': 0.2945801821220052, 'Total loss': 0.2945801821220052}
2022-12-31 07:47:44,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:44,342 INFO:     Epoch: 9
2022-12-31 07:47:45,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49295672674973806, 'Total loss': 0.49295672674973806} | train loss {'Reaction outcome loss': 0.27808156627274694, 'Total loss': 0.27808156627274694}
2022-12-31 07:47:45,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:45,985 INFO:     Epoch: 10
2022-12-31 07:47:47,582 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47712789128224053, 'Total loss': 0.47712789128224053} | train loss {'Reaction outcome loss': 0.27027977795609626, 'Total loss': 0.27027977795609626}
2022-12-31 07:47:47,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:47,582 INFO:     Epoch: 11
2022-12-31 07:47:49,178 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4713050345579783, 'Total loss': 0.4713050345579783} | train loss {'Reaction outcome loss': 0.256361638315213, 'Total loss': 0.256361638315213}
2022-12-31 07:47:49,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:49,179 INFO:     Epoch: 12
2022-12-31 07:47:50,773 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4691522816816966, 'Total loss': 0.4691522816816966} | train loss {'Reaction outcome loss': 0.24520312558054488, 'Total loss': 0.24520312558054488}
2022-12-31 07:47:50,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:50,773 INFO:     Epoch: 13
2022-12-31 07:47:52,369 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4479988525311152, 'Total loss': 0.4479988525311152} | train loss {'Reaction outcome loss': 0.2367801138714993, 'Total loss': 0.2367801138714993}
2022-12-31 07:47:52,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:52,370 INFO:     Epoch: 14
2022-12-31 07:47:53,973 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4433517922957738, 'Total loss': 0.4433517922957738} | train loss {'Reaction outcome loss': 0.22949675884056878, 'Total loss': 0.22949675884056878}
2022-12-31 07:47:53,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:53,973 INFO:     Epoch: 15
2022-12-31 07:47:55,582 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47422737379868823, 'Total loss': 0.47422737379868823} | train loss {'Reaction outcome loss': 0.21955738497399913, 'Total loss': 0.21955738497399913}
2022-12-31 07:47:55,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:55,583 INFO:     Epoch: 16
2022-12-31 07:47:57,190 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47408885359764097, 'Total loss': 0.47408885359764097} | train loss {'Reaction outcome loss': 0.2158779422837845, 'Total loss': 0.2158779422837845}
2022-12-31 07:47:57,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:57,190 INFO:     Epoch: 17
2022-12-31 07:47:58,803 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4437108784914017, 'Total loss': 0.4437108784914017} | train loss {'Reaction outcome loss': 0.20577799283213669, 'Total loss': 0.20577799283213669}
2022-12-31 07:47:58,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:47:58,803 INFO:     Epoch: 18
2022-12-31 07:48:00,446 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46250894765059153, 'Total loss': 0.46250894765059153} | train loss {'Reaction outcome loss': 0.2009855308987869, 'Total loss': 0.2009855308987869}
2022-12-31 07:48:00,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:00,446 INFO:     Epoch: 19
2022-12-31 07:48:02,066 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43879745304584505, 'Total loss': 0.43879745304584505} | train loss {'Reaction outcome loss': 0.19687290327289167, 'Total loss': 0.19687290327289167}
2022-12-31 07:48:02,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:02,067 INFO:     Epoch: 20
2022-12-31 07:48:03,674 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44533643623193103, 'Total loss': 0.44533643623193103} | train loss {'Reaction outcome loss': 0.19467925598960875, 'Total loss': 0.19467925598960875}
2022-12-31 07:48:03,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:03,676 INFO:     Epoch: 21
2022-12-31 07:48:05,281 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4675037105878194, 'Total loss': 0.4675037105878194} | train loss {'Reaction outcome loss': 0.18442097662746798, 'Total loss': 0.18442097662746798}
2022-12-31 07:48:05,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:05,282 INFO:     Epoch: 22
2022-12-31 07:48:06,891 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4828276147445043, 'Total loss': 0.4828276147445043} | train loss {'Reaction outcome loss': 0.18266610367285027, 'Total loss': 0.18266610367285027}
2022-12-31 07:48:06,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:06,891 INFO:     Epoch: 23
2022-12-31 07:48:08,491 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4295799289519588, 'Total loss': 0.4295799289519588} | train loss {'Reaction outcome loss': 0.1802779788512996, 'Total loss': 0.1802779788512996}
2022-12-31 07:48:08,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:08,491 INFO:     Epoch: 24
2022-12-31 07:48:10,098 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47771536906560264, 'Total loss': 0.47771536906560264} | train loss {'Reaction outcome loss': 0.17480083489654102, 'Total loss': 0.17480083489654102}
2022-12-31 07:48:10,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:10,099 INFO:     Epoch: 25
2022-12-31 07:48:11,704 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4439862656407058, 'Total loss': 0.4439862656407058} | train loss {'Reaction outcome loss': 0.17173528842518837, 'Total loss': 0.17173528842518837}
2022-12-31 07:48:11,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:11,704 INFO:     Epoch: 26
2022-12-31 07:48:13,347 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4444062118728956, 'Total loss': 0.4444062118728956} | train loss {'Reaction outcome loss': 0.17026396274512068, 'Total loss': 0.17026396274512068}
2022-12-31 07:48:13,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:13,347 INFO:     Epoch: 27
2022-12-31 07:48:14,991 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49288984735806785, 'Total loss': 0.49288984735806785} | train loss {'Reaction outcome loss': 0.1655914452841212, 'Total loss': 0.1655914452841212}
2022-12-31 07:48:14,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:14,991 INFO:     Epoch: 28
2022-12-31 07:48:16,600 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.455703761219047, 'Total loss': 0.455703761219047} | train loss {'Reaction outcome loss': 0.16220378054940437, 'Total loss': 0.16220378054940437}
2022-12-31 07:48:16,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:16,600 INFO:     Epoch: 29
2022-12-31 07:48:17,714 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46051284273465476, 'Total loss': 0.46051284273465476} | train loss {'Reaction outcome loss': 0.16089095289208294, 'Total loss': 0.16089095289208294}
2022-12-31 07:48:17,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:17,715 INFO:     Epoch: 30
2022-12-31 07:48:18,834 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4806132197380066, 'Total loss': 0.4806132197380066} | train loss {'Reaction outcome loss': 0.15730378271895887, 'Total loss': 0.15730378271895887}
2022-12-31 07:48:18,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:18,834 INFO:     Epoch: 31
2022-12-31 07:48:19,944 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5135081072648366, 'Total loss': 0.5135081072648366} | train loss {'Reaction outcome loss': 0.1564151881699324, 'Total loss': 0.1564151881699324}
2022-12-31 07:48:19,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:19,944 INFO:     Epoch: 32
2022-12-31 07:48:21,060 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46234381993611656, 'Total loss': 0.46234381993611656} | train loss {'Reaction outcome loss': 0.15069389392386426, 'Total loss': 0.15069389392386426}
2022-12-31 07:48:21,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:21,060 INFO:     Epoch: 33
2022-12-31 07:48:22,660 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4536098559697469, 'Total loss': 0.4536098559697469} | train loss {'Reaction outcome loss': 0.1523512039715663, 'Total loss': 0.1523512039715663}
2022-12-31 07:48:22,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:22,660 INFO:     Epoch: 34
2022-12-31 07:48:24,259 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4709626566618681, 'Total loss': 0.4709626566618681} | train loss {'Reaction outcome loss': 0.1533300348356257, 'Total loss': 0.1533300348356257}
2022-12-31 07:48:24,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:24,259 INFO:     Epoch: 35
2022-12-31 07:48:25,900 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5105577826499939, 'Total loss': 0.5105577826499939} | train loss {'Reaction outcome loss': 0.146802431409121, 'Total loss': 0.146802431409121}
2022-12-31 07:48:25,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:25,900 INFO:     Epoch: 36
2022-12-31 07:48:27,510 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5076000531514485, 'Total loss': 0.5076000531514485} | train loss {'Reaction outcome loss': 0.14840207180015116, 'Total loss': 0.14840207180015116}
2022-12-31 07:48:27,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:27,510 INFO:     Epoch: 37
2022-12-31 07:48:29,107 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4654088219006856, 'Total loss': 0.4654088219006856} | train loss {'Reaction outcome loss': 0.14428747934715708, 'Total loss': 0.14428747934715708}
2022-12-31 07:48:29,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:29,108 INFO:     Epoch: 38
2022-12-31 07:48:30,710 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4823661749561628, 'Total loss': 0.4823661749561628} | train loss {'Reaction outcome loss': 0.1413229110483558, 'Total loss': 0.1413229110483558}
2022-12-31 07:48:30,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:30,711 INFO:     Epoch: 39
2022-12-31 07:48:32,304 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4744330224270622, 'Total loss': 0.4744330224270622} | train loss {'Reaction outcome loss': 0.14282821220151343, 'Total loss': 0.14282821220151343}
2022-12-31 07:48:32,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:32,305 INFO:     Epoch: 40
2022-12-31 07:48:33,901 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49467004934946696, 'Total loss': 0.49467004934946696} | train loss {'Reaction outcome loss': 0.13851625117517652, 'Total loss': 0.13851625117517652}
2022-12-31 07:48:33,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:33,902 INFO:     Epoch: 41
2022-12-31 07:48:35,498 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5118142823378246, 'Total loss': 0.5118142823378246} | train loss {'Reaction outcome loss': 0.13965483245545582, 'Total loss': 0.13965483245545582}
2022-12-31 07:48:35,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:35,498 INFO:     Epoch: 42
2022-12-31 07:48:37,128 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5344243069489797, 'Total loss': 0.5344243069489797} | train loss {'Reaction outcome loss': 0.13375469565053807, 'Total loss': 0.13375469565053807}
2022-12-31 07:48:37,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:37,128 INFO:     Epoch: 43
2022-12-31 07:48:38,735 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5370311339696249, 'Total loss': 0.5370311339696249} | train loss {'Reaction outcome loss': 0.13509915020502763, 'Total loss': 0.13509915020502763}
2022-12-31 07:48:38,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:38,737 INFO:     Epoch: 44
2022-12-31 07:48:40,340 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5091399699449539, 'Total loss': 0.5091399699449539} | train loss {'Reaction outcome loss': 0.13351389231678823, 'Total loss': 0.13351389231678823}
2022-12-31 07:48:40,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:40,340 INFO:     Epoch: 45
2022-12-31 07:48:41,983 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46650808354218803, 'Total loss': 0.46650808354218803} | train loss {'Reaction outcome loss': 0.13181864769255994, 'Total loss': 0.13181864769255994}
2022-12-31 07:48:41,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:41,983 INFO:     Epoch: 46
2022-12-31 07:48:43,625 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4524411499500275, 'Total loss': 0.4524411499500275} | train loss {'Reaction outcome loss': 0.13004220534975713, 'Total loss': 0.13004220534975713}
2022-12-31 07:48:43,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:43,626 INFO:     Epoch: 47
2022-12-31 07:48:45,255 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4860860049724579, 'Total loss': 0.4860860049724579} | train loss {'Reaction outcome loss': 0.12744333284937745, 'Total loss': 0.12744333284937745}
2022-12-31 07:48:45,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:45,256 INFO:     Epoch: 48
2022-12-31 07:48:46,893 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4726089949409167, 'Total loss': 0.4726089949409167} | train loss {'Reaction outcome loss': 0.13027269733070154, 'Total loss': 0.13027269733070154}
2022-12-31 07:48:46,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:46,893 INFO:     Epoch: 49
2022-12-31 07:48:48,490 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46827732523282367, 'Total loss': 0.46827732523282367} | train loss {'Reaction outcome loss': 0.12890073081867381, 'Total loss': 0.12890073081867381}
2022-12-31 07:48:48,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:48,490 INFO:     Epoch: 50
2022-12-31 07:48:50,126 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46057242155075073, 'Total loss': 0.46057242155075073} | train loss {'Reaction outcome loss': 0.1268960031230453, 'Total loss': 0.1268960031230453}
2022-12-31 07:48:50,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:50,127 INFO:     Epoch: 51
2022-12-31 07:48:51,724 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4777026305596034, 'Total loss': 0.4777026305596034} | train loss {'Reaction outcome loss': 0.12413352079205078, 'Total loss': 0.12413352079205078}
2022-12-31 07:48:51,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:51,724 INFO:     Epoch: 52
2022-12-31 07:48:53,367 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4930521830295523, 'Total loss': 0.4930521830295523} | train loss {'Reaction outcome loss': 0.12466342169655002, 'Total loss': 0.12466342169655002}
2022-12-31 07:48:53,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:53,367 INFO:     Epoch: 53
2022-12-31 07:48:55,004 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4550914015620947, 'Total loss': 0.4550914015620947} | train loss {'Reaction outcome loss': 0.12604920690428917, 'Total loss': 0.12604920690428917}
2022-12-31 07:48:55,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:55,005 INFO:     Epoch: 54
2022-12-31 07:48:56,643 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.502349054813385, 'Total loss': 0.502349054813385} | train loss {'Reaction outcome loss': 0.12295167624094137, 'Total loss': 0.12295167624094137}
2022-12-31 07:48:56,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:56,643 INFO:     Epoch: 55
2022-12-31 07:48:58,246 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4829477590663979, 'Total loss': 0.4829477590663979} | train loss {'Reaction outcome loss': 0.12236488867600555, 'Total loss': 0.12236488867600555}
2022-12-31 07:48:58,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:58,247 INFO:     Epoch: 56
2022-12-31 07:48:59,859 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5195526818434397, 'Total loss': 0.5195526818434397} | train loss {'Reaction outcome loss': 0.12439391623172677, 'Total loss': 0.12439391623172677}
2022-12-31 07:48:59,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:48:59,859 INFO:     Epoch: 57
2022-12-31 07:49:01,468 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4573483370632554, 'Total loss': 0.4573483370632554} | train loss {'Reaction outcome loss': 0.12293382008191567, 'Total loss': 0.12293382008191567}
2022-12-31 07:49:01,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:01,468 INFO:     Epoch: 58
2022-12-31 07:49:03,072 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4825665667653084, 'Total loss': 0.4825665667653084} | train loss {'Reaction outcome loss': 0.1205498160037038, 'Total loss': 0.1205498160037038}
2022-12-31 07:49:03,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:03,072 INFO:     Epoch: 59
2022-12-31 07:49:04,680 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5319176425536474, 'Total loss': 0.5319176425536474} | train loss {'Reaction outcome loss': 0.12168598234493136, 'Total loss': 0.12168598234493136}
2022-12-31 07:49:04,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:04,680 INFO:     Epoch: 60
2022-12-31 07:49:06,292 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4673793653647105, 'Total loss': 0.4673793653647105} | train loss {'Reaction outcome loss': 0.12389843814900561, 'Total loss': 0.12389843814900561}
2022-12-31 07:49:06,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:06,293 INFO:     Epoch: 61
2022-12-31 07:49:07,917 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4831962749361992, 'Total loss': 0.4831962749361992} | train loss {'Reaction outcome loss': 0.12109412595240789, 'Total loss': 0.12109412595240789}
2022-12-31 07:49:07,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:07,917 INFO:     Epoch: 62
2022-12-31 07:49:09,563 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4681698143482208, 'Total loss': 0.4681698143482208} | train loss {'Reaction outcome loss': 0.1213038603454528, 'Total loss': 0.1213038603454528}
2022-12-31 07:49:09,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:09,564 INFO:     Epoch: 63
2022-12-31 07:49:11,160 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4880763192971547, 'Total loss': 0.4880763192971547} | train loss {'Reaction outcome loss': 0.1258916421588715, 'Total loss': 0.1258916421588715}
2022-12-31 07:49:11,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:11,160 INFO:     Epoch: 64
2022-12-31 07:49:12,790 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5362722893555959, 'Total loss': 0.5362722893555959} | train loss {'Reaction outcome loss': 0.11630873997770795, 'Total loss': 0.11630873997770795}
2022-12-31 07:49:12,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:12,791 INFO:     Epoch: 65
2022-12-31 07:49:14,389 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48791019022464754, 'Total loss': 0.48791019022464754} | train loss {'Reaction outcome loss': 0.11537143813732725, 'Total loss': 0.11537143813732725}
2022-12-31 07:49:14,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:14,389 INFO:     Epoch: 66
2022-12-31 07:49:15,992 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46305621943126124, 'Total loss': 0.46305621943126124} | train loss {'Reaction outcome loss': 0.11814838297658296, 'Total loss': 0.11814838297658296}
2022-12-31 07:49:15,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:15,993 INFO:     Epoch: 67
2022-12-31 07:49:17,634 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4613337288300196, 'Total loss': 0.4613337288300196} | train loss {'Reaction outcome loss': 0.11244689728706501, 'Total loss': 0.11244689728706501}
2022-12-31 07:49:17,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:17,635 INFO:     Epoch: 68
2022-12-31 07:49:19,268 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5485537906487783, 'Total loss': 0.5485537906487783} | train loss {'Reaction outcome loss': 0.12139976835185355, 'Total loss': 0.12139976835185355}
2022-12-31 07:49:19,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:19,268 INFO:     Epoch: 69
2022-12-31 07:49:20,868 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5082645614941915, 'Total loss': 0.5082645614941915} | train loss {'Reaction outcome loss': 0.11903083809368285, 'Total loss': 0.11903083809368285}
2022-12-31 07:49:20,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:20,869 INFO:     Epoch: 70
2022-12-31 07:49:22,486 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5060988654692967, 'Total loss': 0.5060988654692967} | train loss {'Reaction outcome loss': 0.11518861353056226, 'Total loss': 0.11518861353056226}
2022-12-31 07:49:22,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:22,486 INFO:     Epoch: 71
2022-12-31 07:49:24,087 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5147998591264089, 'Total loss': 0.5147998591264089} | train loss {'Reaction outcome loss': 0.11399270526402981, 'Total loss': 0.11399270526402981}
2022-12-31 07:49:24,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:24,087 INFO:     Epoch: 72
2022-12-31 07:49:25,711 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4846335709095001, 'Total loss': 0.4846335709095001} | train loss {'Reaction outcome loss': 0.11652669861517001, 'Total loss': 0.11652669861517001}
2022-12-31 07:49:25,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:25,711 INFO:     Epoch: 73
2022-12-31 07:49:27,321 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5012239674727123, 'Total loss': 0.5012239674727123} | train loss {'Reaction outcome loss': 0.11270028674521317, 'Total loss': 0.11270028674521317}
2022-12-31 07:49:27,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:27,322 INFO:     Epoch: 74
2022-12-31 07:49:28,933 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5142059048016866, 'Total loss': 0.5142059048016866} | train loss {'Reaction outcome loss': 0.11422625556673459, 'Total loss': 0.11422625556673459}
2022-12-31 07:49:28,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:28,934 INFO:     Epoch: 75
2022-12-31 07:49:30,544 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.486417547861735, 'Total loss': 0.486417547861735} | train loss {'Reaction outcome loss': 0.11370039538517868, 'Total loss': 0.11370039538517868}
2022-12-31 07:49:30,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:30,544 INFO:     Epoch: 76
2022-12-31 07:49:32,154 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4804122060537338, 'Total loss': 0.4804122060537338} | train loss {'Reaction outcome loss': 0.11835988182676854, 'Total loss': 0.11835988182676854}
2022-12-31 07:49:32,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:32,154 INFO:     Epoch: 77
2022-12-31 07:49:33,766 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5055307015776634, 'Total loss': 0.5055307015776634} | train loss {'Reaction outcome loss': 0.11082000478517073, 'Total loss': 0.11082000478517073}
2022-12-31 07:49:33,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:33,766 INFO:     Epoch: 78
2022-12-31 07:49:35,395 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4721327449195087, 'Total loss': 0.4721327449195087} | train loss {'Reaction outcome loss': 0.11245097982741538, 'Total loss': 0.11245097982741538}
2022-12-31 07:49:35,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:35,395 INFO:     Epoch: 79
2022-12-31 07:49:37,041 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46848336793482304, 'Total loss': 0.46848336793482304} | train loss {'Reaction outcome loss': 0.11441868785922261, 'Total loss': 0.11441868785922261}
2022-12-31 07:49:37,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:37,041 INFO:     Epoch: 80
2022-12-31 07:49:38,686 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49442529678344727, 'Total loss': 0.49442529678344727} | train loss {'Reaction outcome loss': 0.11386376390474143, 'Total loss': 0.11386376390474143}
2022-12-31 07:49:38,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:38,686 INFO:     Epoch: 81
2022-12-31 07:49:40,313 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5119787395000458, 'Total loss': 0.5119787395000458} | train loss {'Reaction outcome loss': 0.11114954942903028, 'Total loss': 0.11114954942903028}
2022-12-31 07:49:40,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:40,315 INFO:     Epoch: 82
2022-12-31 07:49:41,925 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5264856408039729, 'Total loss': 0.5264856408039729} | train loss {'Reaction outcome loss': 0.1161521521572624, 'Total loss': 0.1161521521572624}
2022-12-31 07:49:41,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:41,925 INFO:     Epoch: 83
2022-12-31 07:49:43,527 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4581788142522176, 'Total loss': 0.4581788142522176} | train loss {'Reaction outcome loss': 0.11051199906812674, 'Total loss': 0.11051199906812674}
2022-12-31 07:49:43,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:43,527 INFO:     Epoch: 84
2022-12-31 07:49:45,176 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5058771997690201, 'Total loss': 0.5058771997690201} | train loss {'Reaction outcome loss': 0.10849615129396566, 'Total loss': 0.10849615129396566}
2022-12-31 07:49:45,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:45,176 INFO:     Epoch: 85
2022-12-31 07:49:46,811 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49121382981538775, 'Total loss': 0.49121382981538775} | train loss {'Reaction outcome loss': 0.10835919241444805, 'Total loss': 0.10835919241444805}
2022-12-31 07:49:46,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:46,812 INFO:     Epoch: 86
2022-12-31 07:49:48,407 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4731249511241913, 'Total loss': 0.4731249511241913} | train loss {'Reaction outcome loss': 0.10586384468969476, 'Total loss': 0.10586384468969476}
2022-12-31 07:49:48,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:48,407 INFO:     Epoch: 87
2022-12-31 07:49:50,015 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49189239740371704, 'Total loss': 0.49189239740371704} | train loss {'Reaction outcome loss': 0.10915322481243506, 'Total loss': 0.10915322481243506}
2022-12-31 07:49:50,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:50,015 INFO:     Epoch: 88
2022-12-31 07:49:51,663 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5796570772926013, 'Total loss': 0.5796570772926013} | train loss {'Reaction outcome loss': 0.11291066429240036, 'Total loss': 0.11291066429240036}
2022-12-31 07:49:51,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:51,663 INFO:     Epoch: 89
2022-12-31 07:49:53,284 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48811149696509043, 'Total loss': 0.48811149696509043} | train loss {'Reaction outcome loss': 0.11075750587511494, 'Total loss': 0.11075750587511494}
2022-12-31 07:49:53,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:53,285 INFO:     Epoch: 90
2022-12-31 07:49:54,894 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5137437711159388, 'Total loss': 0.5137437711159388} | train loss {'Reaction outcome loss': 0.10937681606025759, 'Total loss': 0.10937681606025759}
2022-12-31 07:49:54,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:54,895 INFO:     Epoch: 91
2022-12-31 07:49:56,505 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5078457611302535, 'Total loss': 0.5078457611302535} | train loss {'Reaction outcome loss': 0.11025536891188978, 'Total loss': 0.11025536891188978}
2022-12-31 07:49:56,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:56,505 INFO:     Epoch: 92
2022-12-31 07:49:58,113 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45949441876922115, 'Total loss': 0.45949441876922115} | train loss {'Reaction outcome loss': 0.11251037471821948, 'Total loss': 0.11251037471821948}
2022-12-31 07:49:58,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:58,113 INFO:     Epoch: 93
2022-12-31 07:49:59,748 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5070129911104838, 'Total loss': 0.5070129911104838} | train loss {'Reaction outcome loss': 0.10863653488624363, 'Total loss': 0.10863653488624363}
2022-12-31 07:49:59,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:49:59,749 INFO:     Epoch: 94
2022-12-31 07:50:01,345 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4865074157714844, 'Total loss': 0.4865074157714844} | train loss {'Reaction outcome loss': 0.10784328605462848, 'Total loss': 0.10784328605462848}
2022-12-31 07:50:01,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:01,345 INFO:     Epoch: 95
2022-12-31 07:50:02,957 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5102599124113719, 'Total loss': 0.5102599124113719} | train loss {'Reaction outcome loss': 0.10822974008187351, 'Total loss': 0.10822974008187351}
2022-12-31 07:50:02,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:02,957 INFO:     Epoch: 96
2022-12-31 07:50:04,572 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.511200982828935, 'Total loss': 0.511200982828935} | train loss {'Reaction outcome loss': 0.10246843085266076, 'Total loss': 0.10246843085266076}
2022-12-31 07:50:04,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:04,573 INFO:     Epoch: 97
2022-12-31 07:50:06,182 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49187504847844443, 'Total loss': 0.49187504847844443} | train loss {'Reaction outcome loss': 0.10460655768563965, 'Total loss': 0.10460655768563965}
2022-12-31 07:50:06,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:06,182 INFO:     Epoch: 98
2022-12-31 07:50:07,826 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4881552537282308, 'Total loss': 0.4881552537282308} | train loss {'Reaction outcome loss': 0.10193358226201664, 'Total loss': 0.10193358226201664}
2022-12-31 07:50:07,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:07,826 INFO:     Epoch: 99
2022-12-31 07:50:09,475 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4809816290934881, 'Total loss': 0.4809816290934881} | train loss {'Reaction outcome loss': 0.10416870412157486, 'Total loss': 0.10416870412157486}
2022-12-31 07:50:09,475 INFO:     Best model found after epoch 7 of 100.
2022-12-31 07:50:09,475 INFO:   Done with stage: TRAINING
2022-12-31 07:50:09,475 INFO:   Starting stage: EVALUATION
2022-12-31 07:50:09,619 INFO:   Done with stage: EVALUATION
2022-12-31 07:50:09,619 INFO:   Leaving out SEQ value Fold_3
2022-12-31 07:50:09,632 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 07:50:09,632 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:50:10,266 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:50:10,266 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:50:10,333 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:50:10,333 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:50:10,334 INFO:     No hyperparam tuning for this model
2022-12-31 07:50:10,334 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:50:10,334 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:50:10,334 INFO:     None feature selector for col prot
2022-12-31 07:50:10,335 INFO:     None feature selector for col prot
2022-12-31 07:50:10,335 INFO:     None feature selector for col prot
2022-12-31 07:50:10,335 INFO:     None feature selector for col chem
2022-12-31 07:50:10,335 INFO:     None feature selector for col chem
2022-12-31 07:50:10,335 INFO:     None feature selector for col chem
2022-12-31 07:50:10,335 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:50:10,335 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:50:10,337 INFO:     Number of params in model 224011
2022-12-31 07:50:10,340 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:50:10,341 INFO:   Starting stage: TRAINING
2022-12-31 07:50:10,385 INFO:     Val loss before train {'Reaction outcome loss': 1.1131832679112752, 'Total loss': 1.1131832679112752}
2022-12-31 07:50:10,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:10,385 INFO:     Epoch: 0
2022-12-31 07:50:11,984 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5729657093683879, 'Total loss': 0.5729657093683879} | train loss {'Reaction outcome loss': 0.7732615508548506, 'Total loss': 0.7732615508548506}
2022-12-31 07:50:11,985 INFO:     Found new best model at epoch 0
2022-12-31 07:50:11,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:11,986 INFO:     Epoch: 1
2022-12-31 07:50:13,580 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4608795483907064, 'Total loss': 0.4608795483907064} | train loss {'Reaction outcome loss': 0.49549207244163906, 'Total loss': 0.49549207244163906}
2022-12-31 07:50:13,580 INFO:     Found new best model at epoch 1
2022-12-31 07:50:13,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:13,581 INFO:     Epoch: 2
2022-12-31 07:50:15,176 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.43990477323532107, 'Total loss': 0.43990477323532107} | train loss {'Reaction outcome loss': 0.4239264625114399, 'Total loss': 0.4239264625114399}
2022-12-31 07:50:15,176 INFO:     Found new best model at epoch 2
2022-12-31 07:50:15,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:15,177 INFO:     Epoch: 3
2022-12-31 07:50:16,769 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3820036229987939, 'Total loss': 0.3820036229987939} | train loss {'Reaction outcome loss': 0.38871490747937354, 'Total loss': 0.38871490747937354}
2022-12-31 07:50:16,769 INFO:     Found new best model at epoch 3
2022-12-31 07:50:16,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:16,770 INFO:     Epoch: 4
2022-12-31 07:50:18,365 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4107189734776815, 'Total loss': 0.4107189734776815} | train loss {'Reaction outcome loss': 0.3581444054241582, 'Total loss': 0.3581444054241582}
2022-12-31 07:50:18,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:18,366 INFO:     Epoch: 5
2022-12-31 07:50:19,959 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3697609384854635, 'Total loss': 0.3697609384854635} | train loss {'Reaction outcome loss': 0.33597154823906256, 'Total loss': 0.33597154823906256}
2022-12-31 07:50:19,959 INFO:     Found new best model at epoch 5
2022-12-31 07:50:19,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:19,960 INFO:     Epoch: 6
2022-12-31 07:50:21,578 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3597551623980204, 'Total loss': 0.3597551623980204} | train loss {'Reaction outcome loss': 0.319690778251096, 'Total loss': 0.319690778251096}
2022-12-31 07:50:21,578 INFO:     Found new best model at epoch 6
2022-12-31 07:50:21,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:21,579 INFO:     Epoch: 7
2022-12-31 07:50:23,195 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39513526459534964, 'Total loss': 0.39513526459534964} | train loss {'Reaction outcome loss': 0.30263442314151445, 'Total loss': 0.30263442314151445}
2022-12-31 07:50:23,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:23,195 INFO:     Epoch: 8
2022-12-31 07:50:24,815 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41485301752885184, 'Total loss': 0.41485301752885184} | train loss {'Reaction outcome loss': 0.2909626069959703, 'Total loss': 0.2909626069959703}
2022-12-31 07:50:24,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:24,815 INFO:     Epoch: 9
2022-12-31 07:50:26,427 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39160782396793364, 'Total loss': 0.39160782396793364} | train loss {'Reaction outcome loss': 0.2739287657670049, 'Total loss': 0.2739287657670049}
2022-12-31 07:50:26,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:26,428 INFO:     Epoch: 10
2022-12-31 07:50:28,068 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3871376782655716, 'Total loss': 0.3871376782655716} | train loss {'Reaction outcome loss': 0.262374195205423, 'Total loss': 0.262374195205423}
2022-12-31 07:50:28,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:28,069 INFO:     Epoch: 11
2022-12-31 07:50:29,705 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39088665743668877, 'Total loss': 0.39088665743668877} | train loss {'Reaction outcome loss': 0.24895718629598182, 'Total loss': 0.24895718629598182}
2022-12-31 07:50:29,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:29,705 INFO:     Epoch: 12
2022-12-31 07:50:31,302 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4068717916806539, 'Total loss': 0.4068717916806539} | train loss {'Reaction outcome loss': 0.24287586611432907, 'Total loss': 0.24287586611432907}
2022-12-31 07:50:31,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:31,302 INFO:     Epoch: 13
2022-12-31 07:50:32,894 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3839252064625422, 'Total loss': 0.3839252064625422} | train loss {'Reaction outcome loss': 0.22954463245067405, 'Total loss': 0.22954463245067405}
2022-12-31 07:50:32,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:32,895 INFO:     Epoch: 14
2022-12-31 07:50:34,485 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.36694044768810274, 'Total loss': 0.36694044768810274} | train loss {'Reaction outcome loss': 0.22091316749024523, 'Total loss': 0.22091316749024523}
2022-12-31 07:50:34,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:34,485 INFO:     Epoch: 15
2022-12-31 07:50:36,080 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37990261365969974, 'Total loss': 0.37990261365969974} | train loss {'Reaction outcome loss': 0.21358445925371988, 'Total loss': 0.21358445925371988}
2022-12-31 07:50:36,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:36,081 INFO:     Epoch: 16
2022-12-31 07:50:37,674 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3818012068669001, 'Total loss': 0.3818012068669001} | train loss {'Reaction outcome loss': 0.20793098969309975, 'Total loss': 0.20793098969309975}
2022-12-31 07:50:37,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:37,674 INFO:     Epoch: 17
2022-12-31 07:50:39,310 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.385332194964091, 'Total loss': 0.385332194964091} | train loss {'Reaction outcome loss': 0.20577022601123696, 'Total loss': 0.20577022601123696}
2022-12-31 07:50:39,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:39,310 INFO:     Epoch: 18
2022-12-31 07:50:40,907 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3749883837997913, 'Total loss': 0.3749883837997913} | train loss {'Reaction outcome loss': 0.19810642230396086, 'Total loss': 0.19810642230396086}
2022-12-31 07:50:40,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:40,907 INFO:     Epoch: 19
2022-12-31 07:50:42,556 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38588179734845957, 'Total loss': 0.38588179734845957} | train loss {'Reaction outcome loss': 0.19197408450364847, 'Total loss': 0.19197408450364847}
2022-12-31 07:50:42,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:42,557 INFO:     Epoch: 20
2022-12-31 07:50:44,155 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36438088367382687, 'Total loss': 0.36438088367382687} | train loss {'Reaction outcome loss': 0.18503073018450195, 'Total loss': 0.18503073018450195}
2022-12-31 07:50:44,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:44,155 INFO:     Epoch: 21
2022-12-31 07:50:45,764 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3874472806851069, 'Total loss': 0.3874472806851069} | train loss {'Reaction outcome loss': 0.17876492646751385, 'Total loss': 0.17876492646751385}
2022-12-31 07:50:45,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:45,765 INFO:     Epoch: 22
2022-12-31 07:50:47,373 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47270881831645967, 'Total loss': 0.47270881831645967} | train loss {'Reaction outcome loss': 0.1772951013016286, 'Total loss': 0.1772951013016286}
2022-12-31 07:50:47,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:47,373 INFO:     Epoch: 23
2022-12-31 07:50:48,967 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3867886881033579, 'Total loss': 0.3867886881033579} | train loss {'Reaction outcome loss': 0.17182388322789482, 'Total loss': 0.17182388322789482}
2022-12-31 07:50:48,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:48,968 INFO:     Epoch: 24
2022-12-31 07:50:50,564 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40189619561036427, 'Total loss': 0.40189619561036427} | train loss {'Reaction outcome loss': 0.16894580508435603, 'Total loss': 0.16894580508435603}
2022-12-31 07:50:50,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:50,564 INFO:     Epoch: 25
2022-12-31 07:50:52,210 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4020966075360775, 'Total loss': 0.4020966075360775} | train loss {'Reaction outcome loss': 0.16555519085445683, 'Total loss': 0.16555519085445683}
2022-12-31 07:50:52,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:52,210 INFO:     Epoch: 26
2022-12-31 07:50:53,840 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44007544914881386, 'Total loss': 0.44007544914881386} | train loss {'Reaction outcome loss': 0.1649107728110824, 'Total loss': 0.1649107728110824}
2022-12-31 07:50:53,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:53,841 INFO:     Epoch: 27
2022-12-31 07:50:55,485 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4074489951133728, 'Total loss': 0.4074489951133728} | train loss {'Reaction outcome loss': 0.1604687640675422, 'Total loss': 0.1604687640675422}
2022-12-31 07:50:55,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:55,486 INFO:     Epoch: 28
2022-12-31 07:50:57,084 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42857579489549, 'Total loss': 0.42857579489549} | train loss {'Reaction outcome loss': 0.15536442018479055, 'Total loss': 0.15536442018479055}
2022-12-31 07:50:57,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:57,085 INFO:     Epoch: 29
2022-12-31 07:50:58,687 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40812619725863136, 'Total loss': 0.40812619725863136} | train loss {'Reaction outcome loss': 0.15606961055784982, 'Total loss': 0.15606961055784982}
2022-12-31 07:50:58,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:50:58,687 INFO:     Epoch: 30
2022-12-31 07:51:00,328 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4270257959763209, 'Total loss': 0.4270257959763209} | train loss {'Reaction outcome loss': 0.15172598927176043, 'Total loss': 0.15172598927176043}
2022-12-31 07:51:00,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:00,328 INFO:     Epoch: 31
2022-12-31 07:51:01,953 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46278034845987953, 'Total loss': 0.46278034845987953} | train loss {'Reaction outcome loss': 0.15268251941549582, 'Total loss': 0.15268251941549582}
2022-12-31 07:51:01,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:01,954 INFO:     Epoch: 32
2022-12-31 07:51:03,548 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.449879535039266, 'Total loss': 0.449879535039266} | train loss {'Reaction outcome loss': 0.14901480089272662, 'Total loss': 0.14901480089272662}
2022-12-31 07:51:03,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:03,548 INFO:     Epoch: 33
2022-12-31 07:51:05,187 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4414269169171651, 'Total loss': 0.4414269169171651} | train loss {'Reaction outcome loss': 0.14822219566001996, 'Total loss': 0.14822219566001996}
2022-12-31 07:51:05,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:05,187 INFO:     Epoch: 34
2022-12-31 07:51:06,786 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4303595632314682, 'Total loss': 0.4303595632314682} | train loss {'Reaction outcome loss': 0.14600949232968, 'Total loss': 0.14600949232968}
2022-12-31 07:51:06,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:06,786 INFO:     Epoch: 35
2022-12-31 07:51:08,431 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4570428808530172, 'Total loss': 0.4570428808530172} | train loss {'Reaction outcome loss': 0.1415649290698079, 'Total loss': 0.1415649290698079}
2022-12-31 07:51:08,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:08,431 INFO:     Epoch: 36
2022-12-31 07:51:10,073 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41573281784852345, 'Total loss': 0.41573281784852345} | train loss {'Reaction outcome loss': 0.14481537040978015, 'Total loss': 0.14481537040978015}
2022-12-31 07:51:10,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:10,073 INFO:     Epoch: 37
2022-12-31 07:51:11,689 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4352118243773778, 'Total loss': 0.4352118243773778} | train loss {'Reaction outcome loss': 0.13779817567626526, 'Total loss': 0.13779817567626526}
2022-12-31 07:51:11,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:11,689 INFO:     Epoch: 38
2022-12-31 07:51:13,332 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3782840063640227, 'Total loss': 0.3782840063640227} | train loss {'Reaction outcome loss': 0.13622728673802628, 'Total loss': 0.13622728673802628}
2022-12-31 07:51:13,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:13,332 INFO:     Epoch: 39
2022-12-31 07:51:14,956 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4292602002620697, 'Total loss': 0.4292602002620697} | train loss {'Reaction outcome loss': 0.1353546093105451, 'Total loss': 0.1353546093105451}
2022-12-31 07:51:14,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:14,956 INFO:     Epoch: 40
2022-12-31 07:51:16,599 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45603849391142526, 'Total loss': 0.45603849391142526} | train loss {'Reaction outcome loss': 0.13531037097653517, 'Total loss': 0.13531037097653517}
2022-12-31 07:51:16,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:16,599 INFO:     Epoch: 41
2022-12-31 07:51:18,242 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41329122881094615, 'Total loss': 0.41329122881094615} | train loss {'Reaction outcome loss': 0.1344351391470053, 'Total loss': 0.1344351391470053}
2022-12-31 07:51:18,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:18,243 INFO:     Epoch: 42
2022-12-31 07:51:19,849 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37609757830699286, 'Total loss': 0.37609757830699286} | train loss {'Reaction outcome loss': 0.1324174283481725, 'Total loss': 0.1324174283481725}
2022-12-31 07:51:19,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:19,849 INFO:     Epoch: 43
2022-12-31 07:51:21,484 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39615174929300945, 'Total loss': 0.39615174929300945} | train loss {'Reaction outcome loss': 0.13169426773845358, 'Total loss': 0.13169426773845358}
2022-12-31 07:51:21,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:21,485 INFO:     Epoch: 44
2022-12-31 07:51:23,130 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4028384655714035, 'Total loss': 0.4028384655714035} | train loss {'Reaction outcome loss': 0.12706952142587183, 'Total loss': 0.12706952142587183}
2022-12-31 07:51:23,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:23,130 INFO:     Epoch: 45
2022-12-31 07:51:24,738 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41629384458065033, 'Total loss': 0.41629384458065033} | train loss {'Reaction outcome loss': 0.12569410559949856, 'Total loss': 0.12569410559949856}
2022-12-31 07:51:24,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:24,738 INFO:     Epoch: 46
2022-12-31 07:51:26,345 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39291314718623954, 'Total loss': 0.39291314718623954} | train loss {'Reaction outcome loss': 0.12684405759751333, 'Total loss': 0.12684405759751333}
2022-12-31 07:51:26,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:26,345 INFO:     Epoch: 47
2022-12-31 07:51:27,988 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3971399004260699, 'Total loss': 0.3971399004260699} | train loss {'Reaction outcome loss': 0.13007427237573124, 'Total loss': 0.13007427237573124}
2022-12-31 07:51:27,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:27,988 INFO:     Epoch: 48
2022-12-31 07:51:29,616 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40518636306126915, 'Total loss': 0.40518636306126915} | train loss {'Reaction outcome loss': 0.12366710057577644, 'Total loss': 0.12366710057577644}
2022-12-31 07:51:29,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:29,616 INFO:     Epoch: 49
2022-12-31 07:51:31,260 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4451915641625722, 'Total loss': 0.4451915641625722} | train loss {'Reaction outcome loss': 0.12048863545708331, 'Total loss': 0.12048863545708331}
2022-12-31 07:51:31,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:31,260 INFO:     Epoch: 50
2022-12-31 07:51:32,864 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45301674405733744, 'Total loss': 0.45301674405733744} | train loss {'Reaction outcome loss': 0.12445554825316965, 'Total loss': 0.12445554825316965}
2022-12-31 07:51:32,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:32,864 INFO:     Epoch: 51
2022-12-31 07:51:34,502 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41001010735829674, 'Total loss': 0.41001010735829674} | train loss {'Reaction outcome loss': 0.12426673107261978, 'Total loss': 0.12426673107261978}
2022-12-31 07:51:34,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:34,503 INFO:     Epoch: 52
2022-12-31 07:51:36,147 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42397487560908, 'Total loss': 0.42397487560908} | train loss {'Reaction outcome loss': 0.12204969272310863, 'Total loss': 0.12204969272310863}
2022-12-31 07:51:36,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:36,147 INFO:     Epoch: 53
2022-12-31 07:51:37,791 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4196281852821509, 'Total loss': 0.4196281852821509} | train loss {'Reaction outcome loss': 0.11879321783883395, 'Total loss': 0.11879321783883395}
2022-12-31 07:51:37,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:37,792 INFO:     Epoch: 54
2022-12-31 07:51:39,397 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4000010182460149, 'Total loss': 0.4000010182460149} | train loss {'Reaction outcome loss': 0.12109950316844734, 'Total loss': 0.12109950316844734}
2022-12-31 07:51:39,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:39,397 INFO:     Epoch: 55
2022-12-31 07:51:41,042 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44171260595321654, 'Total loss': 0.44171260595321654} | train loss {'Reaction outcome loss': 0.11934060094393653, 'Total loss': 0.11934060094393653}
2022-12-31 07:51:41,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:41,043 INFO:     Epoch: 56
2022-12-31 07:51:42,640 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.430258912841479, 'Total loss': 0.430258912841479} | train loss {'Reaction outcome loss': 0.11740721101043644, 'Total loss': 0.11740721101043644}
2022-12-31 07:51:42,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:42,640 INFO:     Epoch: 57
2022-12-31 07:51:44,284 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4237031896909078, 'Total loss': 0.4237031896909078} | train loss {'Reaction outcome loss': 0.11542221716001302, 'Total loss': 0.11542221716001302}
2022-12-31 07:51:44,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:44,284 INFO:     Epoch: 58
2022-12-31 07:51:45,928 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42551970581213633, 'Total loss': 0.42551970581213633} | train loss {'Reaction outcome loss': 0.1204552942197838, 'Total loss': 0.1204552942197838}
2022-12-31 07:51:45,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:45,928 INFO:     Epoch: 59
2022-12-31 07:51:47,571 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4257045452793439, 'Total loss': 0.4257045452793439} | train loss {'Reaction outcome loss': 0.1195641881530429, 'Total loss': 0.1195641881530429}
2022-12-31 07:51:47,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:47,571 INFO:     Epoch: 60
2022-12-31 07:51:49,159 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43575362861156464, 'Total loss': 0.43575362861156464} | train loss {'Reaction outcome loss': 0.11818737562254562, 'Total loss': 0.11818737562254562}
2022-12-31 07:51:49,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:49,159 INFO:     Epoch: 61
2022-12-31 07:51:50,804 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46224878827730814, 'Total loss': 0.46224878827730814} | train loss {'Reaction outcome loss': 0.11283790832385421, 'Total loss': 0.11283790832385421}
2022-12-31 07:51:50,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:50,804 INFO:     Epoch: 62
2022-12-31 07:51:52,404 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4253928398092588, 'Total loss': 0.4253928398092588} | train loss {'Reaction outcome loss': 0.11335036925964685, 'Total loss': 0.11335036925964685}
2022-12-31 07:51:52,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:52,404 INFO:     Epoch: 63
2022-12-31 07:51:54,049 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4006863832473755, 'Total loss': 0.4006863832473755} | train loss {'Reaction outcome loss': 0.11464688804208714, 'Total loss': 0.11464688804208714}
2022-12-31 07:51:54,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:54,050 INFO:     Epoch: 64
2022-12-31 07:51:55,642 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4316161854813496, 'Total loss': 0.4316161854813496} | train loss {'Reaction outcome loss': 0.1138055179994758, 'Total loss': 0.1138055179994758}
2022-12-31 07:51:55,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:55,642 INFO:     Epoch: 65
2022-12-31 07:51:57,276 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4293551007906596, 'Total loss': 0.4293551007906596} | train loss {'Reaction outcome loss': 0.11107018696580888, 'Total loss': 0.11107018696580888}
2022-12-31 07:51:57,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:57,276 INFO:     Epoch: 66
2022-12-31 07:51:58,920 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4399106095234553, 'Total loss': 0.4399106095234553} | train loss {'Reaction outcome loss': 0.11029325933246822, 'Total loss': 0.11029325933246822}
2022-12-31 07:51:58,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:51:58,920 INFO:     Epoch: 67
2022-12-31 07:52:00,516 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40643792355743547, 'Total loss': 0.40643792355743547} | train loss {'Reaction outcome loss': 0.11818618827496037, 'Total loss': 0.11818618827496037}
2022-12-31 07:52:00,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:00,518 INFO:     Epoch: 68
2022-12-31 07:52:02,119 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43779269357522327, 'Total loss': 0.43779269357522327} | train loss {'Reaction outcome loss': 0.1187439468312299, 'Total loss': 0.1187439468312299}
2022-12-31 07:52:02,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:02,119 INFO:     Epoch: 69
2022-12-31 07:52:03,764 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4454671412706375, 'Total loss': 0.4454671412706375} | train loss {'Reaction outcome loss': 0.11377637641975186, 'Total loss': 0.11377637641975186}
2022-12-31 07:52:03,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:03,764 INFO:     Epoch: 70
2022-12-31 07:52:05,408 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44855597416559856, 'Total loss': 0.44855597416559856} | train loss {'Reaction outcome loss': 0.10587595523149117, 'Total loss': 0.10587595523149117}
2022-12-31 07:52:05,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:05,408 INFO:     Epoch: 71
2022-12-31 07:52:07,012 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4295249586304029, 'Total loss': 0.4295249586304029} | train loss {'Reaction outcome loss': 0.10575520675015318, 'Total loss': 0.10575520675015318}
2022-12-31 07:52:07,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:07,012 INFO:     Epoch: 72
2022-12-31 07:52:08,658 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45446215172608695, 'Total loss': 0.45446215172608695} | train loss {'Reaction outcome loss': 0.110877705169944, 'Total loss': 0.110877705169944}
2022-12-31 07:52:08,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:08,658 INFO:     Epoch: 73
2022-12-31 07:52:10,277 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41843634843826294, 'Total loss': 0.41843634843826294} | train loss {'Reaction outcome loss': 0.1077155097792413, 'Total loss': 0.1077155097792413}
2022-12-31 07:52:10,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:10,277 INFO:     Epoch: 74
2022-12-31 07:52:11,923 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4316121399402618, 'Total loss': 0.4316121399402618} | train loss {'Reaction outcome loss': 0.10748492572422484, 'Total loss': 0.10748492572422484}
2022-12-31 07:52:11,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:11,923 INFO:     Epoch: 75
2022-12-31 07:52:13,569 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41563946306705474, 'Total loss': 0.41563946306705474} | train loss {'Reaction outcome loss': 0.10681551106993942, 'Total loss': 0.10681551106993942}
2022-12-31 07:52:13,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:13,570 INFO:     Epoch: 76
2022-12-31 07:52:15,172 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.422154370850573, 'Total loss': 0.422154370850573} | train loss {'Reaction outcome loss': 0.10765936596987721, 'Total loss': 0.10765936596987721}
2022-12-31 07:52:15,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:15,173 INFO:     Epoch: 77
2022-12-31 07:52:16,780 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43248310722410677, 'Total loss': 0.43248310722410677} | train loss {'Reaction outcome loss': 0.11116268115302363, 'Total loss': 0.11116268115302363}
2022-12-31 07:52:16,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:16,780 INFO:     Epoch: 78
2022-12-31 07:52:18,388 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4119911541541417, 'Total loss': 0.4119911541541417} | train loss {'Reaction outcome loss': 0.1116731035448065, 'Total loss': 0.1116731035448065}
2022-12-31 07:52:18,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:18,388 INFO:     Epoch: 79
2022-12-31 07:52:19,994 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4254200958957275, 'Total loss': 0.4254200958957275} | train loss {'Reaction outcome loss': 0.10780393876154112, 'Total loss': 0.10780393876154112}
2022-12-31 07:52:19,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:19,994 INFO:     Epoch: 80
2022-12-31 07:52:21,611 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4229732915759087, 'Total loss': 0.4229732915759087} | train loss {'Reaction outcome loss': 0.10791170299684308, 'Total loss': 0.10791170299684308}
2022-12-31 07:52:21,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:21,611 INFO:     Epoch: 81
2022-12-31 07:52:23,225 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42476849754651386, 'Total loss': 0.42476849754651386} | train loss {'Reaction outcome loss': 0.11401671824819876, 'Total loss': 0.11401671824819876}
2022-12-31 07:52:23,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:23,225 INFO:     Epoch: 82
2022-12-31 07:52:24,822 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44339205423990885, 'Total loss': 0.44339205423990885} | train loss {'Reaction outcome loss': 0.10576272627676499, 'Total loss': 0.10576272627676499}
2022-12-31 07:52:24,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:24,822 INFO:     Epoch: 83
2022-12-31 07:52:26,466 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4114320238431295, 'Total loss': 0.4114320238431295} | train loss {'Reaction outcome loss': 0.10531859344848851, 'Total loss': 0.10531859344848851}
2022-12-31 07:52:26,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:26,467 INFO:     Epoch: 84
2022-12-31 07:52:28,055 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4624144583940506, 'Total loss': 0.4624144583940506} | train loss {'Reaction outcome loss': 0.1092357957618816, 'Total loss': 0.1092357957618816}
2022-12-31 07:52:28,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:28,055 INFO:     Epoch: 85
2022-12-31 07:52:29,668 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44794435997804005, 'Total loss': 0.44794435997804005} | train loss {'Reaction outcome loss': 0.10582380746013652, 'Total loss': 0.10582380746013652}
2022-12-31 07:52:29,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:29,669 INFO:     Epoch: 86
2022-12-31 07:52:31,282 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4354322498043378, 'Total loss': 0.4354322498043378} | train loss {'Reaction outcome loss': 0.10408302621605496, 'Total loss': 0.10408302621605496}
2022-12-31 07:52:31,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:31,283 INFO:     Epoch: 87
2022-12-31 07:52:32,896 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4378830740849177, 'Total loss': 0.4378830740849177} | train loss {'Reaction outcome loss': 0.10449738284204524, 'Total loss': 0.10449738284204524}
2022-12-31 07:52:32,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:32,896 INFO:     Epoch: 88
2022-12-31 07:52:34,503 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4575443059206009, 'Total loss': 0.4575443059206009} | train loss {'Reaction outcome loss': 0.10674022570603797, 'Total loss': 0.10674022570603797}
2022-12-31 07:52:34,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:34,503 INFO:     Epoch: 89
2022-12-31 07:52:36,119 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4399905619521936, 'Total loss': 0.4399905619521936} | train loss {'Reaction outcome loss': 0.10483890104588571, 'Total loss': 0.10483890104588571}
2022-12-31 07:52:36,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:36,119 INFO:     Epoch: 90
2022-12-31 07:52:37,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45546461244424186, 'Total loss': 0.45546461244424186} | train loss {'Reaction outcome loss': 0.11157853751709419, 'Total loss': 0.11157853751709419}
2022-12-31 07:52:37,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:37,724 INFO:     Epoch: 91
2022-12-31 07:52:39,338 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4505681802829107, 'Total loss': 0.4505681802829107} | train loss {'Reaction outcome loss': 0.102279908367477, 'Total loss': 0.102279908367477}
2022-12-31 07:52:39,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:39,338 INFO:     Epoch: 92
2022-12-31 07:52:40,950 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46724480340878166, 'Total loss': 0.46724480340878166} | train loss {'Reaction outcome loss': 0.10362177258681492, 'Total loss': 0.10362177258681492}
2022-12-31 07:52:40,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:40,950 INFO:     Epoch: 93
2022-12-31 07:52:42,555 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44567902584870656, 'Total loss': 0.44567902584870656} | train loss {'Reaction outcome loss': 0.10241521694680382, 'Total loss': 0.10241521694680382}
2022-12-31 07:52:42,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:42,555 INFO:     Epoch: 94
2022-12-31 07:52:44,200 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4342885285615921, 'Total loss': 0.4342885285615921} | train loss {'Reaction outcome loss': 0.10322816205388378, 'Total loss': 0.10322816205388378}
2022-12-31 07:52:44,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:44,201 INFO:     Epoch: 95
2022-12-31 07:52:45,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4430183991789818, 'Total loss': 0.4430183991789818} | train loss {'Reaction outcome loss': 0.10713290620932948, 'Total loss': 0.10713290620932948}
2022-12-31 07:52:45,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:45,800 INFO:     Epoch: 96
2022-12-31 07:52:47,399 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4676263749599457, 'Total loss': 0.4676263749599457} | train loss {'Reaction outcome loss': 0.10302829614929146, 'Total loss': 0.10302829614929146}
2022-12-31 07:52:47,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:47,399 INFO:     Epoch: 97
2022-12-31 07:52:49,044 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5022678782542547, 'Total loss': 0.5022678782542547} | train loss {'Reaction outcome loss': 0.1031857665906227, 'Total loss': 0.1031857665906227}
2022-12-31 07:52:49,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:49,045 INFO:     Epoch: 98
2022-12-31 07:52:50,639 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44804984927177427, 'Total loss': 0.44804984927177427} | train loss {'Reaction outcome loss': 0.10759904651455718, 'Total loss': 0.10759904651455718}
2022-12-31 07:52:50,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:50,640 INFO:     Epoch: 99
2022-12-31 07:52:52,248 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44303256769975025, 'Total loss': 0.44303256769975025} | train loss {'Reaction outcome loss': 0.11152869781509943, 'Total loss': 0.11152869781509943}
2022-12-31 07:52:52,248 INFO:     Best model found after epoch 7 of 100.
2022-12-31 07:52:52,249 INFO:   Done with stage: TRAINING
2022-12-31 07:52:52,249 INFO:   Starting stage: EVALUATION
2022-12-31 07:52:52,393 INFO:   Done with stage: EVALUATION
2022-12-31 07:52:52,393 INFO:   Leaving out SEQ value Fold_4
2022-12-31 07:52:52,406 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:52:52,406 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:52:53,050 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:52:53,050 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:52:53,117 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:52:53,117 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:52:53,117 INFO:     No hyperparam tuning for this model
2022-12-31 07:52:53,117 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:52:53,117 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:52:53,118 INFO:     None feature selector for col prot
2022-12-31 07:52:53,118 INFO:     None feature selector for col prot
2022-12-31 07:52:53,118 INFO:     None feature selector for col prot
2022-12-31 07:52:53,119 INFO:     None feature selector for col chem
2022-12-31 07:52:53,119 INFO:     None feature selector for col chem
2022-12-31 07:52:53,119 INFO:     None feature selector for col chem
2022-12-31 07:52:53,119 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:52:53,119 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:52:53,121 INFO:     Number of params in model 224011
2022-12-31 07:52:53,124 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:52:53,124 INFO:   Starting stage: TRAINING
2022-12-31 07:52:53,169 INFO:     Val loss before train {'Reaction outcome loss': 0.9853053609530131, 'Total loss': 0.9853053609530131}
2022-12-31 07:52:53,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:53,169 INFO:     Epoch: 0
2022-12-31 07:52:54,781 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6323265095551809, 'Total loss': 0.6323265095551809} | train loss {'Reaction outcome loss': 0.7900504664084624, 'Total loss': 0.7900504664084624}
2022-12-31 07:52:54,781 INFO:     Found new best model at epoch 0
2022-12-31 07:52:54,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:54,782 INFO:     Epoch: 1
2022-12-31 07:52:56,392 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5661266307036082, 'Total loss': 0.5661266307036082} | train loss {'Reaction outcome loss': 0.5107430357952515, 'Total loss': 0.5107430357952515}
2022-12-31 07:52:56,393 INFO:     Found new best model at epoch 1
2022-12-31 07:52:56,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:56,394 INFO:     Epoch: 2
2022-12-31 07:52:58,009 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5046839118003845, 'Total loss': 0.5046839118003845} | train loss {'Reaction outcome loss': 0.4419624040686134, 'Total loss': 0.4419624040686134}
2022-12-31 07:52:58,009 INFO:     Found new best model at epoch 2
2022-12-31 07:52:58,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:58,010 INFO:     Epoch: 3
2022-12-31 07:52:59,625 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.510134094953537, 'Total loss': 0.510134094953537} | train loss {'Reaction outcome loss': 0.40329879525023093, 'Total loss': 0.40329879525023093}
2022-12-31 07:52:59,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:52:59,627 INFO:     Epoch: 4
2022-12-31 07:53:01,244 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48048825562000275, 'Total loss': 0.48048825562000275} | train loss {'Reaction outcome loss': 0.37424445065561734, 'Total loss': 0.37424445065561734}
2022-12-31 07:53:01,245 INFO:     Found new best model at epoch 4
2022-12-31 07:53:01,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:01,246 INFO:     Epoch: 5
2022-12-31 07:53:02,862 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48985415101051333, 'Total loss': 0.48985415101051333} | train loss {'Reaction outcome loss': 0.34687894613792497, 'Total loss': 0.34687894613792497}
2022-12-31 07:53:02,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:02,862 INFO:     Epoch: 6
2022-12-31 07:53:04,497 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5243235409259797, 'Total loss': 0.5243235409259797} | train loss {'Reaction outcome loss': 0.3263530014285251, 'Total loss': 0.3263530014285251}
2022-12-31 07:53:04,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:04,497 INFO:     Epoch: 7
2022-12-31 07:53:06,152 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4797593981027603, 'Total loss': 0.4797593981027603} | train loss {'Reaction outcome loss': 0.31007565513752616, 'Total loss': 0.31007565513752616}
2022-12-31 07:53:06,153 INFO:     Found new best model at epoch 7
2022-12-31 07:53:06,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:06,154 INFO:     Epoch: 8
2022-12-31 07:53:07,781 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5414744516213735, 'Total loss': 0.5414744516213735} | train loss {'Reaction outcome loss': 0.2933378506454376, 'Total loss': 0.2933378506454376}
2022-12-31 07:53:07,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:07,781 INFO:     Epoch: 9
2022-12-31 07:53:09,397 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5013077974319458, 'Total loss': 0.5013077974319458} | train loss {'Reaction outcome loss': 0.2823610617711708, 'Total loss': 0.2823610617711708}
2022-12-31 07:53:09,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:09,397 INFO:     Epoch: 10
2022-12-31 07:53:11,025 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4999977643291155, 'Total loss': 0.4999977643291155} | train loss {'Reaction outcome loss': 0.26856654945868946, 'Total loss': 0.26856654945868946}
2022-12-31 07:53:11,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:11,026 INFO:     Epoch: 11
2022-12-31 07:53:12,647 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5116579393545787, 'Total loss': 0.5116579393545787} | train loss {'Reaction outcome loss': 0.2567178130350616, 'Total loss': 0.2567178130350616}
2022-12-31 07:53:12,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:12,647 INFO:     Epoch: 12
2022-12-31 07:53:14,271 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.511389481027921, 'Total loss': 0.511389481027921} | train loss {'Reaction outcome loss': 0.24465060664553437, 'Total loss': 0.24465060664553437}
2022-12-31 07:53:14,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:14,271 INFO:     Epoch: 13
2022-12-31 07:53:15,890 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5243381351232529, 'Total loss': 0.5243381351232529} | train loss {'Reaction outcome loss': 0.24012088030645248, 'Total loss': 0.24012088030645248}
2022-12-31 07:53:15,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:15,890 INFO:     Epoch: 14
2022-12-31 07:53:17,516 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5166280388832092, 'Total loss': 0.5166280388832092} | train loss {'Reaction outcome loss': 0.22916521390468098, 'Total loss': 0.22916521390468098}
2022-12-31 07:53:17,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:17,516 INFO:     Epoch: 15
2022-12-31 07:53:18,883 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.512053640683492, 'Total loss': 0.512053640683492} | train loss {'Reaction outcome loss': 0.22209590904927556, 'Total loss': 0.22209590904927556}
2022-12-31 07:53:18,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:18,884 INFO:     Epoch: 16
2022-12-31 07:53:19,988 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.525882214307785, 'Total loss': 0.525882214307785} | train loss {'Reaction outcome loss': 0.2120867115515031, 'Total loss': 0.2120867115515031}
2022-12-31 07:53:19,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:19,989 INFO:     Epoch: 17
2022-12-31 07:53:21,133 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5726743419965108, 'Total loss': 0.5726743419965108} | train loss {'Reaction outcome loss': 0.2077949499124889, 'Total loss': 0.2077949499124889}
2022-12-31 07:53:21,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:21,133 INFO:     Epoch: 18
2022-12-31 07:53:22,235 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5360846022764841, 'Total loss': 0.5360846022764841} | train loss {'Reaction outcome loss': 0.20422000333011334, 'Total loss': 0.20422000333011334}
2022-12-31 07:53:22,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:22,235 INFO:     Epoch: 19
2022-12-31 07:53:23,582 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5143245875835418, 'Total loss': 0.5143245875835418} | train loss {'Reaction outcome loss': 0.19700021941790127, 'Total loss': 0.19700021941790127}
2022-12-31 07:53:23,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:23,582 INFO:     Epoch: 20
2022-12-31 07:53:25,206 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5546764453252157, 'Total loss': 0.5546764453252157} | train loss {'Reaction outcome loss': 0.1901850701795648, 'Total loss': 0.1901850701795648}
2022-12-31 07:53:25,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:25,206 INFO:     Epoch: 21
2022-12-31 07:53:26,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5705016732215882, 'Total loss': 0.5705016732215882} | train loss {'Reaction outcome loss': 0.18692466082807252, 'Total loss': 0.18692466082807252}
2022-12-31 07:53:26,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:26,881 INFO:     Epoch: 22
2022-12-31 07:53:28,505 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5441158930460612, 'Total loss': 0.5441158930460612} | train loss {'Reaction outcome loss': 0.18140955549070908, 'Total loss': 0.18140955549070908}
2022-12-31 07:53:28,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:28,505 INFO:     Epoch: 23
2022-12-31 07:53:30,135 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5398475428422292, 'Total loss': 0.5398475428422292} | train loss {'Reaction outcome loss': 0.17382652526620126, 'Total loss': 0.17382652526620126}
2022-12-31 07:53:30,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:30,136 INFO:     Epoch: 24
2022-12-31 07:53:31,761 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5471172064542771, 'Total loss': 0.5471172064542771} | train loss {'Reaction outcome loss': 0.17366105954947736, 'Total loss': 0.17366105954947736}
2022-12-31 07:53:31,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:31,761 INFO:     Epoch: 25
2022-12-31 07:53:33,420 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5390838901201884, 'Total loss': 0.5390838901201884} | train loss {'Reaction outcome loss': 0.16882645276010685, 'Total loss': 0.16882645276010685}
2022-12-31 07:53:33,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:33,420 INFO:     Epoch: 26
2022-12-31 07:53:35,083 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5440111696720124, 'Total loss': 0.5440111696720124} | train loss {'Reaction outcome loss': 0.16901963897154032, 'Total loss': 0.16901963897154032}
2022-12-31 07:53:35,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:35,083 INFO:     Epoch: 27
2022-12-31 07:53:36,706 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5523940126101176, 'Total loss': 0.5523940126101176} | train loss {'Reaction outcome loss': 0.16294715806092744, 'Total loss': 0.16294715806092744}
2022-12-31 07:53:36,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:36,707 INFO:     Epoch: 28
2022-12-31 07:53:38,323 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5833499928315481, 'Total loss': 0.5833499928315481} | train loss {'Reaction outcome loss': 0.15865219802367062, 'Total loss': 0.15865219802367062}
2022-12-31 07:53:38,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:38,323 INFO:     Epoch: 29
2022-12-31 07:53:39,941 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5983791907628377, 'Total loss': 0.5983791907628377} | train loss {'Reaction outcome loss': 0.15946963145330117, 'Total loss': 0.15946963145330117}
2022-12-31 07:53:39,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:39,941 INFO:     Epoch: 30
2022-12-31 07:53:41,554 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5814731597900391, 'Total loss': 0.5814731597900391} | train loss {'Reaction outcome loss': 0.16114926818514452, 'Total loss': 0.16114926818514452}
2022-12-31 07:53:41,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:41,554 INFO:     Epoch: 31
2022-12-31 07:53:43,181 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5315251568953197, 'Total loss': 0.5315251568953197} | train loss {'Reaction outcome loss': 0.15172863020764096, 'Total loss': 0.15172863020764096}
2022-12-31 07:53:43,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:43,182 INFO:     Epoch: 32
2022-12-31 07:53:44,810 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5718527416388194, 'Total loss': 0.5718527416388194} | train loss {'Reaction outcome loss': 0.15700368991278135, 'Total loss': 0.15700368991278135}
2022-12-31 07:53:44,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:44,810 INFO:     Epoch: 33
2022-12-31 07:53:46,435 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.6085910876592, 'Total loss': 0.6085910876592} | train loss {'Reaction outcome loss': 0.1465423029385156, 'Total loss': 0.1465423029385156}
2022-12-31 07:53:46,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:46,435 INFO:     Epoch: 34
2022-12-31 07:53:48,050 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5539291958014171, 'Total loss': 0.5539291958014171} | train loss {'Reaction outcome loss': 0.14720189289600702, 'Total loss': 0.14720189289600702}
2022-12-31 07:53:48,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:48,051 INFO:     Epoch: 35
2022-12-31 07:53:49,675 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5741891066233317, 'Total loss': 0.5741891066233317} | train loss {'Reaction outcome loss': 0.14303153507348, 'Total loss': 0.14303153507348}
2022-12-31 07:53:49,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:49,676 INFO:     Epoch: 36
2022-12-31 07:53:51,284 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5611752112706502, 'Total loss': 0.5611752112706502} | train loss {'Reaction outcome loss': 0.13809955047875427, 'Total loss': 0.13809955047875427}
2022-12-31 07:53:51,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:51,284 INFO:     Epoch: 37
2022-12-31 07:53:52,896 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5641240219275157, 'Total loss': 0.5641240219275157} | train loss {'Reaction outcome loss': 0.1431006021844898, 'Total loss': 0.1431006021844898}
2022-12-31 07:53:52,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:52,896 INFO:     Epoch: 38
2022-12-31 07:53:54,507 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5527750054995219, 'Total loss': 0.5527750054995219} | train loss {'Reaction outcome loss': 0.1408288331427236, 'Total loss': 0.1408288331427236}
2022-12-31 07:53:54,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:54,508 INFO:     Epoch: 39
2022-12-31 07:53:56,170 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5791793743769328, 'Total loss': 0.5791793743769328} | train loss {'Reaction outcome loss': 0.13500665933437025, 'Total loss': 0.13500665933437025}
2022-12-31 07:53:56,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:56,171 INFO:     Epoch: 40
2022-12-31 07:53:57,783 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5819470922152201, 'Total loss': 0.5819470922152201} | train loss {'Reaction outcome loss': 0.13619836437030006, 'Total loss': 0.13619836437030006}
2022-12-31 07:53:57,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:57,784 INFO:     Epoch: 41
2022-12-31 07:53:59,423 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5821600874265035, 'Total loss': 0.5821600874265035} | train loss {'Reaction outcome loss': 0.1341923217245283, 'Total loss': 0.1341923217245283}
2022-12-31 07:53:59,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:53:59,423 INFO:     Epoch: 42
2022-12-31 07:54:01,030 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5618160714705785, 'Total loss': 0.5618160714705785} | train loss {'Reaction outcome loss': 0.13224521903928532, 'Total loss': 0.13224521903928532}
2022-12-31 07:54:01,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:01,031 INFO:     Epoch: 43
2022-12-31 07:54:02,649 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.593442565202713, 'Total loss': 0.593442565202713} | train loss {'Reaction outcome loss': 0.1313203217451582, 'Total loss': 0.1313203217451582}
2022-12-31 07:54:02,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:02,649 INFO:     Epoch: 44
2022-12-31 07:54:04,275 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5582111865282059, 'Total loss': 0.5582111865282059} | train loss {'Reaction outcome loss': 0.12772231716561414, 'Total loss': 0.12772231716561414}
2022-12-31 07:54:04,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:04,275 INFO:     Epoch: 45
2022-12-31 07:54:05,909 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5986393163601558, 'Total loss': 0.5986393163601558} | train loss {'Reaction outcome loss': 0.12780271827300632, 'Total loss': 0.12780271827300632}
2022-12-31 07:54:05,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:05,909 INFO:     Epoch: 46
2022-12-31 07:54:07,541 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5915904512008031, 'Total loss': 0.5915904512008031} | train loss {'Reaction outcome loss': 0.12872002711199035, 'Total loss': 0.12872002711199035}
2022-12-31 07:54:07,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:07,542 INFO:     Epoch: 47
2022-12-31 07:54:09,160 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5704889436562856, 'Total loss': 0.5704889436562856} | train loss {'Reaction outcome loss': 0.13542932266558427, 'Total loss': 0.13542932266558427}
2022-12-31 07:54:09,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:09,160 INFO:     Epoch: 48
2022-12-31 07:54:10,805 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5857565383116404, 'Total loss': 0.5857565383116404} | train loss {'Reaction outcome loss': 0.1846416916401274, 'Total loss': 0.1846416916401274}
2022-12-31 07:54:10,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:10,806 INFO:     Epoch: 49
2022-12-31 07:54:12,487 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5866506040096283, 'Total loss': 0.5866506040096283} | train loss {'Reaction outcome loss': 0.13877306512280274, 'Total loss': 0.13877306512280274}
2022-12-31 07:54:12,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:12,488 INFO:     Epoch: 50
2022-12-31 07:54:14,104 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5697963610291481, 'Total loss': 0.5697963610291481} | train loss {'Reaction outcome loss': 0.12678757917129205, 'Total loss': 0.12678757917129205}
2022-12-31 07:54:14,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:14,104 INFO:     Epoch: 51
2022-12-31 07:54:15,752 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5701766431331634, 'Total loss': 0.5701766431331634} | train loss {'Reaction outcome loss': 0.125035505367281, 'Total loss': 0.125035505367281}
2022-12-31 07:54:15,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:15,753 INFO:     Epoch: 52
2022-12-31 07:54:17,415 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5791772047678629, 'Total loss': 0.5791772047678629} | train loss {'Reaction outcome loss': 0.12298530482761291, 'Total loss': 0.12298530482761291}
2022-12-31 07:54:17,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:17,415 INFO:     Epoch: 53
2022-12-31 07:54:19,063 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5653649926185608, 'Total loss': 0.5653649926185608} | train loss {'Reaction outcome loss': 0.11986193050794047, 'Total loss': 0.11986193050794047}
2022-12-31 07:54:19,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:19,064 INFO:     Epoch: 54
2022-12-31 07:54:20,681 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.599625825881958, 'Total loss': 0.599625825881958} | train loss {'Reaction outcome loss': 0.11620580776373216, 'Total loss': 0.11620580776373216}
2022-12-31 07:54:20,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:20,682 INFO:     Epoch: 55
2022-12-31 07:54:22,300 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5812942057847976, 'Total loss': 0.5812942057847976} | train loss {'Reaction outcome loss': 0.11590944185558909, 'Total loss': 0.11590944185558909}
2022-12-31 07:54:22,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:22,300 INFO:     Epoch: 56
2022-12-31 07:54:23,950 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.6023666600386302, 'Total loss': 0.6023666600386302} | train loss {'Reaction outcome loss': 0.11536401969066862, 'Total loss': 0.11536401969066862}
2022-12-31 07:54:23,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:23,950 INFO:     Epoch: 57
2022-12-31 07:54:25,612 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5731437663237254, 'Total loss': 0.5731437663237254} | train loss {'Reaction outcome loss': 0.11492954444754329, 'Total loss': 0.11492954444754329}
2022-12-31 07:54:25,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:25,612 INFO:     Epoch: 58
2022-12-31 07:54:27,251 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5953285137812296, 'Total loss': 0.5953285137812296} | train loss {'Reaction outcome loss': 0.1177222194842677, 'Total loss': 0.1177222194842677}
2022-12-31 07:54:27,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:27,251 INFO:     Epoch: 59
2022-12-31 07:54:28,913 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5946191291014353, 'Total loss': 0.5946191291014353} | train loss {'Reaction outcome loss': 0.12059800576436987, 'Total loss': 0.12059800576436987}
2022-12-31 07:54:28,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:28,913 INFO:     Epoch: 60
2022-12-31 07:54:30,526 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5847004075845083, 'Total loss': 0.5847004075845083} | train loss {'Reaction outcome loss': 0.11990355369904875, 'Total loss': 0.11990355369904875}
2022-12-31 07:54:30,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:30,527 INFO:     Epoch: 61
2022-12-31 07:54:32,141 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5783818274736404, 'Total loss': 0.5783818274736404} | train loss {'Reaction outcome loss': 0.13285044817409167, 'Total loss': 0.13285044817409167}
2022-12-31 07:54:32,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:32,142 INFO:     Epoch: 62
2022-12-31 07:54:33,759 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5853878319263458, 'Total loss': 0.5853878319263458} | train loss {'Reaction outcome loss': 0.12198854159172354, 'Total loss': 0.12198854159172354}
2022-12-31 07:54:33,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:33,759 INFO:     Epoch: 63
2022-12-31 07:54:35,420 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5829637308915456, 'Total loss': 0.5829637308915456} | train loss {'Reaction outcome loss': 0.1284033496428848, 'Total loss': 0.1284033496428848}
2022-12-31 07:54:35,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:35,421 INFO:     Epoch: 64
2022-12-31 07:54:37,028 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5988397677739461, 'Total loss': 0.5988397677739461} | train loss {'Reaction outcome loss': 0.11849461045737068, 'Total loss': 0.11849461045737068}
2022-12-31 07:54:37,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:37,029 INFO:     Epoch: 65
2022-12-31 07:54:38,643 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5920564969380696, 'Total loss': 0.5920564969380696} | train loss {'Reaction outcome loss': 0.11200479902259573, 'Total loss': 0.11200479902259573}
2022-12-31 07:54:38,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:38,643 INFO:     Epoch: 66
2022-12-31 07:54:40,305 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5679692963759104, 'Total loss': 0.5679692963759104} | train loss {'Reaction outcome loss': 0.10803181152099885, 'Total loss': 0.10803181152099885}
2022-12-31 07:54:40,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:40,305 INFO:     Epoch: 67
2022-12-31 07:54:41,966 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5502904733022054, 'Total loss': 0.5502904733022054} | train loss {'Reaction outcome loss': 0.10817479283803655, 'Total loss': 0.10817479283803655}
2022-12-31 07:54:41,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:41,967 INFO:     Epoch: 68
2022-12-31 07:54:43,585 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5704184591770172, 'Total loss': 0.5704184591770172} | train loss {'Reaction outcome loss': 0.10903984215363617, 'Total loss': 0.10903984215363617}
2022-12-31 07:54:43,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:43,585 INFO:     Epoch: 69
2022-12-31 07:54:45,237 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5839236398537954, 'Total loss': 0.5839236398537954} | train loss {'Reaction outcome loss': 0.11237983321399847, 'Total loss': 0.11237983321399847}
2022-12-31 07:54:45,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:45,237 INFO:     Epoch: 70
2022-12-31 07:54:46,867 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5672450423240661, 'Total loss': 0.5672450423240661} | train loss {'Reaction outcome loss': 0.11133387113712134, 'Total loss': 0.11133387113712134}
2022-12-31 07:54:46,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:46,867 INFO:     Epoch: 71
2022-12-31 07:54:48,490 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.569266164302826, 'Total loss': 0.569266164302826} | train loss {'Reaction outcome loss': 0.11432284164576507, 'Total loss': 0.11432284164576507}
2022-12-31 07:54:48,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:48,491 INFO:     Epoch: 72
2022-12-31 07:54:50,111 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5960194071133932, 'Total loss': 0.5960194071133932} | train loss {'Reaction outcome loss': 0.11102718827264059, 'Total loss': 0.11102718827264059}
2022-12-31 07:54:50,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:50,111 INFO:     Epoch: 73
2022-12-31 07:54:51,778 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.6152693013350169, 'Total loss': 0.6152693013350169} | train loss {'Reaction outcome loss': 0.1130707878366883, 'Total loss': 0.1130707878366883}
2022-12-31 07:54:51,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:51,778 INFO:     Epoch: 74
2022-12-31 07:54:53,391 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5779447754224142, 'Total loss': 0.5779447754224142} | train loss {'Reaction outcome loss': 0.11285246706427353, 'Total loss': 0.11285246706427353}
2022-12-31 07:54:53,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:53,392 INFO:     Epoch: 75
2022-12-31 07:54:55,005 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6061494767665863, 'Total loss': 0.6061494767665863} | train loss {'Reaction outcome loss': 0.11079217020327949, 'Total loss': 0.11079217020327949}
2022-12-31 07:54:55,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:55,006 INFO:     Epoch: 76
2022-12-31 07:54:56,630 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5740410049756368, 'Total loss': 0.5740410049756368} | train loss {'Reaction outcome loss': 0.1091838508432704, 'Total loss': 0.1091838508432704}
2022-12-31 07:54:56,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:56,630 INFO:     Epoch: 77
2022-12-31 07:54:58,255 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5964254766702652, 'Total loss': 0.5964254766702652} | train loss {'Reaction outcome loss': 0.10450747155848966, 'Total loss': 0.10450747155848966}
2022-12-31 07:54:58,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:58,256 INFO:     Epoch: 78
2022-12-31 07:54:59,884 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5968013286590577, 'Total loss': 0.5968013286590577} | train loss {'Reaction outcome loss': 0.10610108246177716, 'Total loss': 0.10610108246177716}
2022-12-31 07:54:59,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:54:59,884 INFO:     Epoch: 79
2022-12-31 07:55:01,508 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5831534852584203, 'Total loss': 0.5831534852584203} | train loss {'Reaction outcome loss': 0.1063562317260379, 'Total loss': 0.1063562317260379}
2022-12-31 07:55:01,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:01,508 INFO:     Epoch: 80
2022-12-31 07:55:03,134 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5816249291102091, 'Total loss': 0.5816249291102091} | train loss {'Reaction outcome loss': 0.11092486687994756, 'Total loss': 0.11092486687994756}
2022-12-31 07:55:03,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:03,134 INFO:     Epoch: 81
2022-12-31 07:55:04,782 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6018708944320679, 'Total loss': 0.6018708944320679} | train loss {'Reaction outcome loss': 0.10527954755367397, 'Total loss': 0.10527954755367397}
2022-12-31 07:55:04,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:04,783 INFO:     Epoch: 82
2022-12-31 07:55:06,445 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5790652881066004, 'Total loss': 0.5790652881066004} | train loss {'Reaction outcome loss': 0.10327644057996213, 'Total loss': 0.10327644057996213}
2022-12-31 07:55:06,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:06,446 INFO:     Epoch: 83
2022-12-31 07:55:08,108 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5565067162116368, 'Total loss': 0.5565067162116368} | train loss {'Reaction outcome loss': 0.10951396358754921, 'Total loss': 0.10951396358754921}
2022-12-31 07:55:08,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:08,108 INFO:     Epoch: 84
2022-12-31 07:55:09,723 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5612338135639826, 'Total loss': 0.5612338135639826} | train loss {'Reaction outcome loss': 0.10867270711133788, 'Total loss': 0.10867270711133788}
2022-12-31 07:55:09,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:09,723 INFO:     Epoch: 85
2022-12-31 07:55:11,385 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5800778170426687, 'Total loss': 0.5800778170426687} | train loss {'Reaction outcome loss': 0.10682057012614889, 'Total loss': 0.10682057012614889}
2022-12-31 07:55:11,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:11,386 INFO:     Epoch: 86
2022-12-31 07:55:13,011 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6282909055550893, 'Total loss': 0.6282909055550893} | train loss {'Reaction outcome loss': 0.10507968225157009, 'Total loss': 0.10507968225157009}
2022-12-31 07:55:13,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:13,011 INFO:     Epoch: 87
2022-12-31 07:55:14,673 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5826299766699473, 'Total loss': 0.5826299766699473} | train loss {'Reaction outcome loss': 0.10333978960883594, 'Total loss': 0.10333978960883594}
2022-12-31 07:55:14,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:14,674 INFO:     Epoch: 88
2022-12-31 07:55:16,290 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.583331722021103, 'Total loss': 0.583331722021103} | train loss {'Reaction outcome loss': 0.10441761132086286, 'Total loss': 0.10441761132086286}
2022-12-31 07:55:16,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:16,291 INFO:     Epoch: 89
2022-12-31 07:55:17,907 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5855811913808187, 'Total loss': 0.5855811913808187} | train loss {'Reaction outcome loss': 0.10173682412214871, 'Total loss': 0.10173682412214871}
2022-12-31 07:55:17,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:17,907 INFO:     Epoch: 90
2022-12-31 07:55:19,534 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5850329210360845, 'Total loss': 0.5850329210360845} | train loss {'Reaction outcome loss': 0.09998925916485293, 'Total loss': 0.09998925916485293}
2022-12-31 07:55:19,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:19,534 INFO:     Epoch: 91
2022-12-31 07:55:21,196 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6073871999979019, 'Total loss': 0.6073871999979019} | train loss {'Reaction outcome loss': 0.10265978616371285, 'Total loss': 0.10265978616371285}
2022-12-31 07:55:21,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:21,196 INFO:     Epoch: 92
2022-12-31 07:55:22,843 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5850719213485718, 'Total loss': 0.5850719213485718} | train loss {'Reaction outcome loss': 0.10490092899029453, 'Total loss': 0.10490092899029453}
2022-12-31 07:55:22,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:22,844 INFO:     Epoch: 93
2022-12-31 07:55:24,505 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5531824290752411, 'Total loss': 0.5531824290752411} | train loss {'Reaction outcome loss': 0.10339044884017641, 'Total loss': 0.10339044884017641}
2022-12-31 07:55:24,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:24,507 INFO:     Epoch: 94
2022-12-31 07:55:26,124 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5809945464134216, 'Total loss': 0.5809945464134216} | train loss {'Reaction outcome loss': 0.10234202765201664, 'Total loss': 0.10234202765201664}
2022-12-31 07:55:26,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:26,125 INFO:     Epoch: 95
2022-12-31 07:55:27,785 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5827063461144765, 'Total loss': 0.5827063461144765} | train loss {'Reaction outcome loss': 0.10317255105495123, 'Total loss': 0.10317255105495123}
2022-12-31 07:55:27,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:27,786 INFO:     Epoch: 96
2022-12-31 07:55:29,392 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.602546684940656, 'Total loss': 0.602546684940656} | train loss {'Reaction outcome loss': 0.10431385089886254, 'Total loss': 0.10431385089886254}
2022-12-31 07:55:29,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:29,392 INFO:     Epoch: 97
2022-12-31 07:55:31,040 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6055425584316254, 'Total loss': 0.6055425584316254} | train loss {'Reaction outcome loss': 0.10320651735357546, 'Total loss': 0.10320651735357546}
2022-12-31 07:55:31,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:31,041 INFO:     Epoch: 98
2022-12-31 07:55:32,656 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.601167631149292, 'Total loss': 0.601167631149292} | train loss {'Reaction outcome loss': 0.10705975337085598, 'Total loss': 0.10705975337085598}
2022-12-31 07:55:32,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:32,657 INFO:     Epoch: 99
2022-12-31 07:55:34,318 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6067263344923656, 'Total loss': 0.6067263344923656} | train loss {'Reaction outcome loss': 0.09847011328362724, 'Total loss': 0.09847011328362724}
2022-12-31 07:55:34,318 INFO:     Best model found after epoch 8 of 100.
2022-12-31 07:55:34,318 INFO:   Done with stage: TRAINING
2022-12-31 07:55:34,318 INFO:   Starting stage: EVALUATION
2022-12-31 07:55:34,449 INFO:   Done with stage: EVALUATION
2022-12-31 07:55:34,449 INFO:   Leaving out SEQ value Fold_5
2022-12-31 07:55:34,462 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 07:55:34,462 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:55:35,103 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:55:35,103 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:55:35,170 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:55:35,170 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:55:35,170 INFO:     No hyperparam tuning for this model
2022-12-31 07:55:35,170 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:55:35,170 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:55:35,171 INFO:     None feature selector for col prot
2022-12-31 07:55:35,171 INFO:     None feature selector for col prot
2022-12-31 07:55:35,171 INFO:     None feature selector for col prot
2022-12-31 07:55:35,172 INFO:     None feature selector for col chem
2022-12-31 07:55:35,172 INFO:     None feature selector for col chem
2022-12-31 07:55:35,172 INFO:     None feature selector for col chem
2022-12-31 07:55:35,172 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:55:35,172 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:55:35,174 INFO:     Number of params in model 224011
2022-12-31 07:55:35,177 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:55:35,177 INFO:   Starting stage: TRAINING
2022-12-31 07:55:35,222 INFO:     Val loss before train {'Reaction outcome loss': 0.9822705785433451, 'Total loss': 0.9822705785433451}
2022-12-31 07:55:35,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:35,222 INFO:     Epoch: 0
2022-12-31 07:55:36,837 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5410278379917145, 'Total loss': 0.5410278379917145} | train loss {'Reaction outcome loss': 0.7971275660236352, 'Total loss': 0.7971275660236352}
2022-12-31 07:55:36,837 INFO:     Found new best model at epoch 0
2022-12-31 07:55:36,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:36,839 INFO:     Epoch: 1
2022-12-31 07:55:38,461 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4390341877937317, 'Total loss': 0.4390341877937317} | train loss {'Reaction outcome loss': 0.5161832414408876, 'Total loss': 0.5161832414408876}
2022-12-31 07:55:38,461 INFO:     Found new best model at epoch 1
2022-12-31 07:55:38,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:38,462 INFO:     Epoch: 2
2022-12-31 07:55:40,089 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41957632700602215, 'Total loss': 0.41957632700602215} | train loss {'Reaction outcome loss': 0.44386357555207645, 'Total loss': 0.44386357555207645}
2022-12-31 07:55:40,089 INFO:     Found new best model at epoch 2
2022-12-31 07:55:40,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:40,090 INFO:     Epoch: 3
2022-12-31 07:55:41,718 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.37816773454348246, 'Total loss': 0.37816773454348246} | train loss {'Reaction outcome loss': 0.40108558044480364, 'Total loss': 0.40108558044480364}
2022-12-31 07:55:41,718 INFO:     Found new best model at epoch 3
2022-12-31 07:55:41,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:41,719 INFO:     Epoch: 4
2022-12-31 07:55:43,344 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4083472490310669, 'Total loss': 0.4083472490310669} | train loss {'Reaction outcome loss': 0.37205954105761985, 'Total loss': 0.37205954105761985}
2022-12-31 07:55:43,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:43,345 INFO:     Epoch: 5
2022-12-31 07:55:44,970 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3863285760084788, 'Total loss': 0.3863285760084788} | train loss {'Reaction outcome loss': 0.3456109848794649, 'Total loss': 0.3456109848794649}
2022-12-31 07:55:44,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:44,970 INFO:     Epoch: 6
2022-12-31 07:55:46,605 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3911167641480764, 'Total loss': 0.3911167641480764} | train loss {'Reaction outcome loss': 0.3283368888904975, 'Total loss': 0.3283368888904975}
2022-12-31 07:55:46,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:46,605 INFO:     Epoch: 7
2022-12-31 07:55:48,269 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4109830766916275, 'Total loss': 0.4109830766916275} | train loss {'Reaction outcome loss': 0.31342907074460946, 'Total loss': 0.31342907074460946}
2022-12-31 07:55:48,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:48,269 INFO:     Epoch: 8
2022-12-31 07:55:49,882 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3869156708319982, 'Total loss': 0.3869156708319982} | train loss {'Reaction outcome loss': 0.308609099275824, 'Total loss': 0.308609099275824}
2022-12-31 07:55:49,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:49,882 INFO:     Epoch: 9
2022-12-31 07:55:51,497 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41040917138258615, 'Total loss': 0.41040917138258615} | train loss {'Reaction outcome loss': 0.29557350385521597, 'Total loss': 0.29557350385521597}
2022-12-31 07:55:51,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:51,498 INFO:     Epoch: 10
2022-12-31 07:55:53,162 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38175611197948456, 'Total loss': 0.38175611197948456} | train loss {'Reaction outcome loss': 0.27173820443019486, 'Total loss': 0.27173820443019486}
2022-12-31 07:55:53,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:53,162 INFO:     Epoch: 11
2022-12-31 07:55:54,777 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3898867070674896, 'Total loss': 0.3898867070674896} | train loss {'Reaction outcome loss': 0.264006612685752, 'Total loss': 0.264006612685752}
2022-12-31 07:55:54,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:54,777 INFO:     Epoch: 12
2022-12-31 07:55:56,395 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39225515524546306, 'Total loss': 0.39225515524546306} | train loss {'Reaction outcome loss': 0.2478995919767497, 'Total loss': 0.2478995919767497}
2022-12-31 07:55:56,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:56,396 INFO:     Epoch: 13
2022-12-31 07:55:58,006 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4432663838068644, 'Total loss': 0.4432663838068644} | train loss {'Reaction outcome loss': 0.24483550041644037, 'Total loss': 0.24483550041644037}
2022-12-31 07:55:58,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:58,007 INFO:     Epoch: 14
2022-12-31 07:55:59,671 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40345293978850044, 'Total loss': 0.40345293978850044} | train loss {'Reaction outcome loss': 0.2540806966320868, 'Total loss': 0.2540806966320868}
2022-12-31 07:55:59,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:55:59,672 INFO:     Epoch: 15
2022-12-31 07:56:01,287 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4106137275695801, 'Total loss': 0.4106137275695801} | train loss {'Reaction outcome loss': 0.2295638769448514, 'Total loss': 0.2295638769448514}
2022-12-31 07:56:01,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:01,287 INFO:     Epoch: 16
2022-12-31 07:56:02,901 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4248861496647199, 'Total loss': 0.4248861496647199} | train loss {'Reaction outcome loss': 0.2218525791126856, 'Total loss': 0.2218525791126856}
2022-12-31 07:56:02,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:02,901 INFO:     Epoch: 17
2022-12-31 07:56:04,518 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39326934814453124, 'Total loss': 0.39326934814453124} | train loss {'Reaction outcome loss': 0.2187650600394261, 'Total loss': 0.2187650600394261}
2022-12-31 07:56:04,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:04,518 INFO:     Epoch: 18
2022-12-31 07:56:06,135 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.402600371837616, 'Total loss': 0.402600371837616} | train loss {'Reaction outcome loss': 0.22027750976005758, 'Total loss': 0.22027750976005758}
2022-12-31 07:56:06,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:06,136 INFO:     Epoch: 19
2022-12-31 07:56:07,771 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43164063096046446, 'Total loss': 0.43164063096046446} | train loss {'Reaction outcome loss': 0.21083248726537693, 'Total loss': 0.21083248726537693}
2022-12-31 07:56:07,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:07,771 INFO:     Epoch: 20
2022-12-31 07:56:09,386 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4375026871760686, 'Total loss': 0.4375026871760686} | train loss {'Reaction outcome loss': 0.19987175538351395, 'Total loss': 0.19987175538351395}
2022-12-31 07:56:09,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:09,387 INFO:     Epoch: 21
2022-12-31 07:56:11,004 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44006464928388594, 'Total loss': 0.44006464928388594} | train loss {'Reaction outcome loss': 0.18977160227107073, 'Total loss': 0.18977160227107073}
2022-12-31 07:56:11,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:11,005 INFO:     Epoch: 22
2022-12-31 07:56:12,628 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4507208029429118, 'Total loss': 0.4507208029429118} | train loss {'Reaction outcome loss': 0.1876633762876703, 'Total loss': 0.1876633762876703}
2022-12-31 07:56:12,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:12,628 INFO:     Epoch: 23
2022-12-31 07:56:14,238 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4342011531194051, 'Total loss': 0.4342011531194051} | train loss {'Reaction outcome loss': 0.18494478596712594, 'Total loss': 0.18494478596712594}
2022-12-31 07:56:14,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:14,238 INFO:     Epoch: 24
2022-12-31 07:56:15,851 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38649673263231915, 'Total loss': 0.38649673263231915} | train loss {'Reaction outcome loss': 0.18029673669883303, 'Total loss': 0.18029673669883303}
2022-12-31 07:56:15,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:15,851 INFO:     Epoch: 25
2022-12-31 07:56:17,476 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42100520730018615, 'Total loss': 0.42100520730018615} | train loss {'Reaction outcome loss': 0.17336780347897782, 'Total loss': 0.17336780347897782}
2022-12-31 07:56:17,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:17,476 INFO:     Epoch: 26
2022-12-31 07:56:19,138 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39635641177495323, 'Total loss': 0.39635641177495323} | train loss {'Reaction outcome loss': 0.17513958456507628, 'Total loss': 0.17513958456507628}
2022-12-31 07:56:19,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:19,139 INFO:     Epoch: 27
2022-12-31 07:56:20,759 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4280330310265223, 'Total loss': 0.4280330310265223} | train loss {'Reaction outcome loss': 0.16769553308604637, 'Total loss': 0.16769553308604637}
2022-12-31 07:56:20,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:20,759 INFO:     Epoch: 28
2022-12-31 07:56:22,403 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4567740539709727, 'Total loss': 0.4567740539709727} | train loss {'Reaction outcome loss': 0.16821621779514395, 'Total loss': 0.16821621779514395}
2022-12-31 07:56:22,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:22,404 INFO:     Epoch: 29
2022-12-31 07:56:24,065 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46205325052142143, 'Total loss': 0.46205325052142143} | train loss {'Reaction outcome loss': 0.16684832180971684, 'Total loss': 0.16684832180971684}
2022-12-31 07:56:24,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:24,065 INFO:     Epoch: 30
2022-12-31 07:56:25,692 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4156411280234655, 'Total loss': 0.4156411280234655} | train loss {'Reaction outcome loss': 0.20113737139879537, 'Total loss': 0.20113737139879537}
2022-12-31 07:56:25,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:25,692 INFO:     Epoch: 31
2022-12-31 07:56:27,353 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4463681196173032, 'Total loss': 0.4463681196173032} | train loss {'Reaction outcome loss': 0.15921307296451667, 'Total loss': 0.15921307296451667}
2022-12-31 07:56:27,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:27,353 INFO:     Epoch: 32
2022-12-31 07:56:29,014 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45635599493980405, 'Total loss': 0.45635599493980405} | train loss {'Reaction outcome loss': 0.15666603598325257, 'Total loss': 0.15666603598325257}
2022-12-31 07:56:29,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:29,014 INFO:     Epoch: 33
2022-12-31 07:56:30,652 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46392948627471925, 'Total loss': 0.46392948627471925} | train loss {'Reaction outcome loss': 0.15472951326671097, 'Total loss': 0.15472951326671097}
2022-12-31 07:56:30,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:30,654 INFO:     Epoch: 34
2022-12-31 07:56:32,269 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47364769677321117, 'Total loss': 0.47364769677321117} | train loss {'Reaction outcome loss': 0.15087752573416094, 'Total loss': 0.15087752573416094}
2022-12-31 07:56:32,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:32,270 INFO:     Epoch: 35
2022-12-31 07:56:33,883 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49733892182509104, 'Total loss': 0.49733892182509104} | train loss {'Reaction outcome loss': 0.14892865558478818, 'Total loss': 0.14892865558478818}
2022-12-31 07:56:33,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:33,883 INFO:     Epoch: 36
2022-12-31 07:56:35,492 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46380415558815, 'Total loss': 0.46380415558815} | train loss {'Reaction outcome loss': 0.1552110601562848, 'Total loss': 0.1552110601562848}
2022-12-31 07:56:35,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:35,493 INFO:     Epoch: 37
2022-12-31 07:56:37,107 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46142677863438925, 'Total loss': 0.46142677863438925} | train loss {'Reaction outcome loss': 0.14460064750373008, 'Total loss': 0.14460064750373008}
2022-12-31 07:56:37,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:37,108 INFO:     Epoch: 38
2022-12-31 07:56:38,716 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4568378269672394, 'Total loss': 0.4568378269672394} | train loss {'Reaction outcome loss': 0.14274071674436276, 'Total loss': 0.14274071674436276}
2022-12-31 07:56:38,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:38,716 INFO:     Epoch: 39
2022-12-31 07:56:40,329 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4624783267577489, 'Total loss': 0.4624783267577489} | train loss {'Reaction outcome loss': 0.15356478836063459, 'Total loss': 0.15356478836063459}
2022-12-31 07:56:40,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:40,330 INFO:     Epoch: 40
2022-12-31 07:56:41,984 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44712017277876537, 'Total loss': 0.44712017277876537} | train loss {'Reaction outcome loss': 0.17783998121007427, 'Total loss': 0.17783998121007427}
2022-12-31 07:56:41,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:41,984 INFO:     Epoch: 41
2022-12-31 07:56:43,606 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4573459029197693, 'Total loss': 0.4573459029197693} | train loss {'Reaction outcome loss': 0.1421484737245761, 'Total loss': 0.1421484737245761}
2022-12-31 07:56:43,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:43,606 INFO:     Epoch: 42
2022-12-31 07:56:45,224 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4672577957312266, 'Total loss': 0.4672577957312266} | train loss {'Reaction outcome loss': 0.13572960731782613, 'Total loss': 0.13572960731782613}
2022-12-31 07:56:45,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:45,224 INFO:     Epoch: 43
2022-12-31 07:56:46,841 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45727308293183644, 'Total loss': 0.45727308293183644} | train loss {'Reaction outcome loss': 0.13398140576250822, 'Total loss': 0.13398140576250822}
2022-12-31 07:56:46,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:46,841 INFO:     Epoch: 44
2022-12-31 07:56:48,456 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4175058672825495, 'Total loss': 0.4175058672825495} | train loss {'Reaction outcome loss': 0.13381699447625026, 'Total loss': 0.13381699447625026}
2022-12-31 07:56:48,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:48,456 INFO:     Epoch: 45
2022-12-31 07:56:50,070 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46141578753789264, 'Total loss': 0.46141578753789264} | train loss {'Reaction outcome loss': 0.1341028541480056, 'Total loss': 0.1341028541480056}
2022-12-31 07:56:50,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:50,070 INFO:     Epoch: 46
2022-12-31 07:56:51,692 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4583289444446564, 'Total loss': 0.4583289444446564} | train loss {'Reaction outcome loss': 0.12957203584443525, 'Total loss': 0.12957203584443525}
2022-12-31 07:56:51,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:51,693 INFO:     Epoch: 47
2022-12-31 07:56:53,312 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4301569809516271, 'Total loss': 0.4301569809516271} | train loss {'Reaction outcome loss': 0.13014468441690333, 'Total loss': 0.13014468441690333}
2022-12-31 07:56:53,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:53,313 INFO:     Epoch: 48
2022-12-31 07:56:54,937 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4740893080830574, 'Total loss': 0.4740893080830574} | train loss {'Reaction outcome loss': 0.12717111772824707, 'Total loss': 0.12717111772824707}
2022-12-31 07:56:54,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:54,937 INFO:     Epoch: 49
2022-12-31 07:56:56,562 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4381200791026155, 'Total loss': 0.4381200791026155} | train loss {'Reaction outcome loss': 0.12687645002902634, 'Total loss': 0.12687645002902634}
2022-12-31 07:56:56,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:56,563 INFO:     Epoch: 50
2022-12-31 07:56:58,187 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46129739383856455, 'Total loss': 0.46129739383856455} | train loss {'Reaction outcome loss': 0.12670683285189352, 'Total loss': 0.12670683285189352}
2022-12-31 07:56:58,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:58,187 INFO:     Epoch: 51
2022-12-31 07:56:59,807 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45875353713830314, 'Total loss': 0.45875353713830314} | train loss {'Reaction outcome loss': 0.12593896287902337, 'Total loss': 0.12593896287902337}
2022-12-31 07:56:59,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:56:59,807 INFO:     Epoch: 52
2022-12-31 07:57:01,426 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4820678919553757, 'Total loss': 0.4820678919553757} | train loss {'Reaction outcome loss': 0.12699383028102337, 'Total loss': 0.12699383028102337}
2022-12-31 07:57:01,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:01,426 INFO:     Epoch: 53
2022-12-31 07:57:03,102 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46378579139709475, 'Total loss': 0.46378579139709475} | train loss {'Reaction outcome loss': 0.12619341693726197, 'Total loss': 0.12619341693726197}
2022-12-31 07:57:03,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:03,103 INFO:     Epoch: 54
2022-12-31 07:57:04,724 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4494936992724737, 'Total loss': 0.4494936992724737} | train loss {'Reaction outcome loss': 0.12293886621583901, 'Total loss': 0.12293886621583901}
2022-12-31 07:57:04,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:04,725 INFO:     Epoch: 55
2022-12-31 07:57:06,346 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4542765627304713, 'Total loss': 0.4542765627304713} | train loss {'Reaction outcome loss': 0.11901124707335417, 'Total loss': 0.11901124707335417}
2022-12-31 07:57:06,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:06,347 INFO:     Epoch: 56
2022-12-31 07:57:07,963 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47214633723100025, 'Total loss': 0.47214633723100025} | train loss {'Reaction outcome loss': 0.12000001078168693, 'Total loss': 0.12000001078168693}
2022-12-31 07:57:07,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:07,963 INFO:     Epoch: 57
2022-12-31 07:57:09,627 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4781380444765091, 'Total loss': 0.4781380444765091} | train loss {'Reaction outcome loss': 0.12292408604717701, 'Total loss': 0.12292408604717701}
2022-12-31 07:57:09,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:09,628 INFO:     Epoch: 58
2022-12-31 07:57:11,250 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4876294001936913, 'Total loss': 0.4876294001936913} | train loss {'Reaction outcome loss': 0.12492357366642429, 'Total loss': 0.12492357366642429}
2022-12-31 07:57:11,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:11,250 INFO:     Epoch: 59
2022-12-31 07:57:12,915 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43511865188678106, 'Total loss': 0.43511865188678106} | train loss {'Reaction outcome loss': 0.12473428256677269, 'Total loss': 0.12473428256677269}
2022-12-31 07:57:12,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:12,915 INFO:     Epoch: 60
2022-12-31 07:57:14,533 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45340113043785096, 'Total loss': 0.45340113043785096} | train loss {'Reaction outcome loss': 0.12271365700829504, 'Total loss': 0.12271365700829504}
2022-12-31 07:57:14,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:14,533 INFO:     Epoch: 61
2022-12-31 07:57:16,197 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49488705694675444, 'Total loss': 0.49488705694675444} | train loss {'Reaction outcome loss': 0.123867251884118, 'Total loss': 0.123867251884118}
2022-12-31 07:57:16,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:16,197 INFO:     Epoch: 62
2022-12-31 07:57:17,813 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45474684753765665, 'Total loss': 0.45474684753765665} | train loss {'Reaction outcome loss': 0.1190113381571404, 'Total loss': 0.1190113381571404}
2022-12-31 07:57:17,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:17,813 INFO:     Epoch: 63
2022-12-31 07:57:19,478 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4629498859246572, 'Total loss': 0.4629498859246572} | train loss {'Reaction outcome loss': 0.11596600666382363, 'Total loss': 0.11596600666382363}
2022-12-31 07:57:19,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:19,478 INFO:     Epoch: 64
2022-12-31 07:57:21,103 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4451702197392782, 'Total loss': 0.4451702197392782} | train loss {'Reaction outcome loss': 0.11942424831363167, 'Total loss': 0.11942424831363167}
2022-12-31 07:57:21,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:21,104 INFO:     Epoch: 65
2022-12-31 07:57:22,769 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44375518163045247, 'Total loss': 0.44375518163045247} | train loss {'Reaction outcome loss': 0.11881218089695102, 'Total loss': 0.11881218089695102}
2022-12-31 07:57:22,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:22,769 INFO:     Epoch: 66
2022-12-31 07:57:24,433 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4782738884290059, 'Total loss': 0.4782738884290059} | train loss {'Reaction outcome loss': 0.1258506293108993, 'Total loss': 0.1258506293108993}
2022-12-31 07:57:24,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:24,434 INFO:     Epoch: 67
2022-12-31 07:57:26,093 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46070443093776703, 'Total loss': 0.46070443093776703} | train loss {'Reaction outcome loss': 0.1220507473841755, 'Total loss': 0.1220507473841755}
2022-12-31 07:57:26,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:26,094 INFO:     Epoch: 68
2022-12-31 07:57:27,718 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44517986526091896, 'Total loss': 0.44517986526091896} | train loss {'Reaction outcome loss': 0.11366110631986859, 'Total loss': 0.11366110631986859}
2022-12-31 07:57:27,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:27,718 INFO:     Epoch: 69
2022-12-31 07:57:29,369 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4775065024693807, 'Total loss': 0.4775065024693807} | train loss {'Reaction outcome loss': 0.11232681936192987, 'Total loss': 0.11232681936192987}
2022-12-31 07:57:29,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:29,369 INFO:     Epoch: 70
2022-12-31 07:57:30,995 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4475420186916987, 'Total loss': 0.4475420186916987} | train loss {'Reaction outcome loss': 0.11335744046896318, 'Total loss': 0.11335744046896318}
2022-12-31 07:57:30,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:30,995 INFO:     Epoch: 71
2022-12-31 07:57:32,660 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4525250705579917, 'Total loss': 0.4525250705579917} | train loss {'Reaction outcome loss': 0.11258644086829799, 'Total loss': 0.11258644086829799}
2022-12-31 07:57:32,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:32,661 INFO:     Epoch: 72
2022-12-31 07:57:34,285 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4610625629623731, 'Total loss': 0.4610625629623731} | train loss {'Reaction outcome loss': 0.11490225185000294, 'Total loss': 0.11490225185000294}
2022-12-31 07:57:34,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:34,285 INFO:     Epoch: 73
2022-12-31 07:57:35,922 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4882669987777869, 'Total loss': 0.4882669987777869} | train loss {'Reaction outcome loss': 0.11871470166089779, 'Total loss': 0.11871470166089779}
2022-12-31 07:57:35,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:35,923 INFO:     Epoch: 74
2022-12-31 07:57:37,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4900734007358551, 'Total loss': 0.4900734007358551} | train loss {'Reaction outcome loss': 0.12090311447441902, 'Total loss': 0.12090311447441902}
2022-12-31 07:57:37,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:37,587 INFO:     Epoch: 75
2022-12-31 07:57:39,223 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4559196134408315, 'Total loss': 0.4559196134408315} | train loss {'Reaction outcome loss': 0.11481136958679164, 'Total loss': 0.11481136958679164}
2022-12-31 07:57:39,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:39,224 INFO:     Epoch: 76
2022-12-31 07:57:40,854 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4712511042753855, 'Total loss': 0.4712511042753855} | train loss {'Reaction outcome loss': 0.10817396631113219, 'Total loss': 0.10817396631113219}
2022-12-31 07:57:40,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:40,854 INFO:     Epoch: 77
2022-12-31 07:57:42,482 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48974941770235697, 'Total loss': 0.48974941770235697} | train loss {'Reaction outcome loss': 0.11141877793182874, 'Total loss': 0.11141877793182874}
2022-12-31 07:57:42,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:42,483 INFO:     Epoch: 78
2022-12-31 07:57:44,112 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46900156935056053, 'Total loss': 0.46900156935056053} | train loss {'Reaction outcome loss': 0.10962206632678356, 'Total loss': 0.10962206632678356}
2022-12-31 07:57:44,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:44,113 INFO:     Epoch: 79
2022-12-31 07:57:45,735 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45215869694948196, 'Total loss': 0.45215869694948196} | train loss {'Reaction outcome loss': 0.11183247567149576, 'Total loss': 0.11183247567149576}
2022-12-31 07:57:45,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:45,735 INFO:     Epoch: 80
2022-12-31 07:57:47,377 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46848013401031496, 'Total loss': 0.46848013401031496} | train loss {'Reaction outcome loss': 0.1149369608326157, 'Total loss': 0.1149369608326157}
2022-12-31 07:57:47,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:47,377 INFO:     Epoch: 81
2022-12-31 07:57:48,998 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4816897143920263, 'Total loss': 0.4816897143920263} | train loss {'Reaction outcome loss': 0.11180121045797115, 'Total loss': 0.11180121045797115}
2022-12-31 07:57:48,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:48,999 INFO:     Epoch: 82
2022-12-31 07:57:50,619 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4846441725889842, 'Total loss': 0.4846441725889842} | train loss {'Reaction outcome loss': 0.10846597982226344, 'Total loss': 0.10846597982226344}
2022-12-31 07:57:50,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:50,620 INFO:     Epoch: 83
2022-12-31 07:57:52,239 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4797385136286418, 'Total loss': 0.4797385136286418} | train loss {'Reaction outcome loss': 0.10879325805971335, 'Total loss': 0.10879325805971335}
2022-12-31 07:57:52,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:52,239 INFO:     Epoch: 84
2022-12-31 07:57:53,885 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4439423218369484, 'Total loss': 0.4439423218369484} | train loss {'Reaction outcome loss': 0.10679619535959858, 'Total loss': 0.10679619535959858}
2022-12-31 07:57:53,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:53,885 INFO:     Epoch: 85
2022-12-31 07:57:55,514 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46096614599227903, 'Total loss': 0.46096614599227903} | train loss {'Reaction outcome loss': 0.10736486543875957, 'Total loss': 0.10736486543875957}
2022-12-31 07:57:55,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:55,514 INFO:     Epoch: 86
2022-12-31 07:57:57,133 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4831462641557058, 'Total loss': 0.4831462641557058} | train loss {'Reaction outcome loss': 0.11587222074339862, 'Total loss': 0.11587222074339862}
2022-12-31 07:57:57,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:57,133 INFO:     Epoch: 87
2022-12-31 07:57:58,761 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4558871919910113, 'Total loss': 0.4558871919910113} | train loss {'Reaction outcome loss': 0.11324649177433879, 'Total loss': 0.11324649177433879}
2022-12-31 07:57:58,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:57:58,761 INFO:     Epoch: 88
2022-12-31 07:58:00,388 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5003010402123134, 'Total loss': 0.5003010402123134} | train loss {'Reaction outcome loss': 0.11031360603764356, 'Total loss': 0.11031360603764356}
2022-12-31 07:58:00,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:00,389 INFO:     Epoch: 89
2022-12-31 07:58:02,016 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47080562114715574, 'Total loss': 0.47080562114715574} | train loss {'Reaction outcome loss': 0.1073705777168958, 'Total loss': 0.1073705777168958}
2022-12-31 07:58:02,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:02,017 INFO:     Epoch: 90
2022-12-31 07:58:03,631 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45383797635634743, 'Total loss': 0.45383797635634743} | train loss {'Reaction outcome loss': 0.10803034916297082, 'Total loss': 0.10803034916297082}
2022-12-31 07:58:03,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:03,631 INFO:     Epoch: 91
2022-12-31 07:58:05,247 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4642118791739146, 'Total loss': 0.4642118791739146} | train loss {'Reaction outcome loss': 0.10964071355841082, 'Total loss': 0.10964071355841082}
2022-12-31 07:58:05,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:05,248 INFO:     Epoch: 92
2022-12-31 07:58:06,855 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49441060349345206, 'Total loss': 0.49441060349345206} | train loss {'Reaction outcome loss': 0.10961915153856736, 'Total loss': 0.10961915153856736}
2022-12-31 07:58:06,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:06,855 INFO:     Epoch: 93
2022-12-31 07:58:08,470 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4807760914166768, 'Total loss': 0.4807760914166768} | train loss {'Reaction outcome loss': 0.10864333657166529, 'Total loss': 0.10864333657166529}
2022-12-31 07:58:08,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:08,470 INFO:     Epoch: 94
2022-12-31 07:58:10,083 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48800138135751087, 'Total loss': 0.48800138135751087} | train loss {'Reaction outcome loss': 0.1088868211878909, 'Total loss': 0.1088868211878909}
2022-12-31 07:58:10,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:10,083 INFO:     Epoch: 95
2022-12-31 07:58:11,694 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4702392687400182, 'Total loss': 0.4702392687400182} | train loss {'Reaction outcome loss': 0.11044706498691137, 'Total loss': 0.11044706498691137}
2022-12-31 07:58:11,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:11,694 INFO:     Epoch: 96
2022-12-31 07:58:13,309 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45728710691134133, 'Total loss': 0.45728710691134133} | train loss {'Reaction outcome loss': 0.10492085540275256, 'Total loss': 0.10492085540275256}
2022-12-31 07:58:13,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:13,310 INFO:     Epoch: 97
2022-12-31 07:58:14,927 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4728712310393651, 'Total loss': 0.4728712310393651} | train loss {'Reaction outcome loss': 0.1050697703030037, 'Total loss': 0.1050697703030037}
2022-12-31 07:58:14,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:14,927 INFO:     Epoch: 98
2022-12-31 07:58:16,557 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46205562154452007, 'Total loss': 0.46205562154452007} | train loss {'Reaction outcome loss': 0.10591190089252304, 'Total loss': 0.10591190089252304}
2022-12-31 07:58:16,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:16,557 INFO:     Epoch: 99
2022-12-31 07:58:18,190 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4957065294186274, 'Total loss': 0.4957065294186274} | train loss {'Reaction outcome loss': 0.12318392357606765, 'Total loss': 0.12318392357606765}
2022-12-31 07:58:18,191 INFO:     Best model found after epoch 4 of 100.
2022-12-31 07:58:18,191 INFO:   Done with stage: TRAINING
2022-12-31 07:58:18,191 INFO:   Starting stage: EVALUATION
2022-12-31 07:58:18,324 INFO:   Done with stage: EVALUATION
2022-12-31 07:58:18,324 INFO:   Leaving out SEQ value Fold_6
2022-12-31 07:58:18,337 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 07:58:18,337 INFO:   Starting stage: FEATURE SCALING
2022-12-31 07:58:18,982 INFO:   Done with stage: FEATURE SCALING
2022-12-31 07:58:18,982 INFO:   Starting stage: SCALING TARGETS
2022-12-31 07:58:19,049 INFO:   Done with stage: SCALING TARGETS
2022-12-31 07:58:19,049 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:58:19,049 INFO:     No hyperparam tuning for this model
2022-12-31 07:58:19,049 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 07:58:19,049 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 07:58:19,050 INFO:     None feature selector for col prot
2022-12-31 07:58:19,050 INFO:     None feature selector for col prot
2022-12-31 07:58:19,050 INFO:     None feature selector for col prot
2022-12-31 07:58:19,051 INFO:     None feature selector for col chem
2022-12-31 07:58:19,051 INFO:     None feature selector for col chem
2022-12-31 07:58:19,051 INFO:     None feature selector for col chem
2022-12-31 07:58:19,051 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 07:58:19,051 INFO:   Starting stage: BUILD MODEL
2022-12-31 07:58:19,053 INFO:     Number of params in model 224011
2022-12-31 07:58:19,056 INFO:   Done with stage: BUILD MODEL
2022-12-31 07:58:19,056 INFO:   Starting stage: TRAINING
2022-12-31 07:58:19,103 INFO:     Val loss before train {'Reaction outcome loss': 1.0054251670837402, 'Total loss': 1.0054251670837402}
2022-12-31 07:58:19,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:19,103 INFO:     Epoch: 0
2022-12-31 07:58:20,730 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6131439328193664, 'Total loss': 0.6131439328193664} | train loss {'Reaction outcome loss': 0.7843741777786709, 'Total loss': 0.7843741777786709}
2022-12-31 07:58:20,730 INFO:     Found new best model at epoch 0
2022-12-31 07:58:20,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:20,731 INFO:     Epoch: 1
2022-12-31 07:58:22,365 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5215745866298676, 'Total loss': 0.5215745866298676} | train loss {'Reaction outcome loss': 0.5104132224721599, 'Total loss': 0.5104132224721599}
2022-12-31 07:58:22,366 INFO:     Found new best model at epoch 1
2022-12-31 07:58:22,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:22,367 INFO:     Epoch: 2
2022-12-31 07:58:23,991 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4986009260018667, 'Total loss': 0.4986009260018667} | train loss {'Reaction outcome loss': 0.445223502895462, 'Total loss': 0.445223502895462}
2022-12-31 07:58:23,991 INFO:     Found new best model at epoch 2
2022-12-31 07:58:23,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:23,992 INFO:     Epoch: 3
2022-12-31 07:58:25,629 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4749390641848246, 'Total loss': 0.4749390641848246} | train loss {'Reaction outcome loss': 0.4088134803819312, 'Total loss': 0.4088134803819312}
2022-12-31 07:58:25,629 INFO:     Found new best model at epoch 3
2022-12-31 07:58:25,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:25,631 INFO:     Epoch: 4
2022-12-31 07:58:27,267 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4619743416706721, 'Total loss': 0.4619743416706721} | train loss {'Reaction outcome loss': 0.3836103651928127, 'Total loss': 0.3836103651928127}
2022-12-31 07:58:27,267 INFO:     Found new best model at epoch 4
2022-12-31 07:58:27,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:27,268 INFO:     Epoch: 5
2022-12-31 07:58:28,901 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4820174733797709, 'Total loss': 0.4820174733797709} | train loss {'Reaction outcome loss': 0.35806479657384893, 'Total loss': 0.35806479657384893}
2022-12-31 07:58:28,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:28,902 INFO:     Epoch: 6
2022-12-31 07:58:30,528 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4486266354719798, 'Total loss': 0.4486266354719798} | train loss {'Reaction outcome loss': 0.34122863005752596, 'Total loss': 0.34122863005752596}
2022-12-31 07:58:30,528 INFO:     Found new best model at epoch 6
2022-12-31 07:58:30,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:30,529 INFO:     Epoch: 7
2022-12-31 07:58:32,167 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4425336296359698, 'Total loss': 0.4425336296359698} | train loss {'Reaction outcome loss': 0.32321851307842275, 'Total loss': 0.32321851307842275}
2022-12-31 07:58:32,167 INFO:     Found new best model at epoch 7
2022-12-31 07:58:32,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:32,168 INFO:     Epoch: 8
2022-12-31 07:58:33,794 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4372950911521912, 'Total loss': 0.4372950911521912} | train loss {'Reaction outcome loss': 0.3112315338790847, 'Total loss': 0.3112315338790847}
2022-12-31 07:58:33,794 INFO:     Found new best model at epoch 8
2022-12-31 07:58:33,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:33,795 INFO:     Epoch: 9
2022-12-31 07:58:35,432 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42398970772822697, 'Total loss': 0.42398970772822697} | train loss {'Reaction outcome loss': 0.29611108140071807, 'Total loss': 0.29611108140071807}
2022-12-31 07:58:35,432 INFO:     Found new best model at epoch 9
2022-12-31 07:58:35,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:35,433 INFO:     Epoch: 10
2022-12-31 07:58:37,068 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44035123387972513, 'Total loss': 0.44035123387972513} | train loss {'Reaction outcome loss': 0.2862523446390775, 'Total loss': 0.2862523446390775}
2022-12-31 07:58:37,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:37,068 INFO:     Epoch: 11
2022-12-31 07:58:38,703 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42101510961850486, 'Total loss': 0.42101510961850486} | train loss {'Reaction outcome loss': 0.2772634321359736, 'Total loss': 0.2772634321359736}
2022-12-31 07:58:38,704 INFO:     Found new best model at epoch 11
2022-12-31 07:58:38,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:38,705 INFO:     Epoch: 12
2022-12-31 07:58:40,330 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43636175195376076, 'Total loss': 0.43636175195376076} | train loss {'Reaction outcome loss': 0.26787526031371056, 'Total loss': 0.26787526031371056}
2022-12-31 07:58:40,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:40,330 INFO:     Epoch: 13
2022-12-31 07:58:41,956 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42889689008394877, 'Total loss': 0.42889689008394877} | train loss {'Reaction outcome loss': 0.25697561051521706, 'Total loss': 0.25697561051521706}
2022-12-31 07:58:41,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:41,957 INFO:     Epoch: 14
2022-12-31 07:58:43,592 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46489758988221486, 'Total loss': 0.46489758988221486} | train loss {'Reaction outcome loss': 0.24779013713774697, 'Total loss': 0.24779013713774697}
2022-12-31 07:58:43,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:43,593 INFO:     Epoch: 15
2022-12-31 07:58:45,228 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45727335413297016, 'Total loss': 0.45727335413297016} | train loss {'Reaction outcome loss': 0.24302469072224647, 'Total loss': 0.24302469072224647}
2022-12-31 07:58:45,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:45,228 INFO:     Epoch: 16
2022-12-31 07:58:46,880 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43525538543860115, 'Total loss': 0.43525538543860115} | train loss {'Reaction outcome loss': 0.23392827702612223, 'Total loss': 0.23392827702612223}
2022-12-31 07:58:46,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:46,880 INFO:     Epoch: 17
2022-12-31 07:58:48,523 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44380922317504884, 'Total loss': 0.44380922317504884} | train loss {'Reaction outcome loss': 0.2277563110612575, 'Total loss': 0.2277563110612575}
2022-12-31 07:58:48,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:48,523 INFO:     Epoch: 18
2022-12-31 07:58:50,154 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45247436662515006, 'Total loss': 0.45247436662515006} | train loss {'Reaction outcome loss': 0.22388354307612143, 'Total loss': 0.22388354307612143}
2022-12-31 07:58:50,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:50,154 INFO:     Epoch: 19
2022-12-31 07:58:51,767 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.443144561847051, 'Total loss': 0.443144561847051} | train loss {'Reaction outcome loss': 0.21152038317819258, 'Total loss': 0.21152038317819258}
2022-12-31 07:58:51,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:51,768 INFO:     Epoch: 20
2022-12-31 07:58:53,388 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4208103130261103, 'Total loss': 0.4208103130261103} | train loss {'Reaction outcome loss': 0.2089353642940844, 'Total loss': 0.2089353642940844}
2022-12-31 07:58:53,389 INFO:     Found new best model at epoch 20
2022-12-31 07:58:53,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:53,390 INFO:     Epoch: 21
2022-12-31 07:58:55,062 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4475885252157847, 'Total loss': 0.4475885252157847} | train loss {'Reaction outcome loss': 0.2031592614478045, 'Total loss': 0.2031592614478045}
2022-12-31 07:58:55,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:55,062 INFO:     Epoch: 22
2022-12-31 07:58:56,688 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45101315279801685, 'Total loss': 0.45101315279801685} | train loss {'Reaction outcome loss': 0.19649582532392512, 'Total loss': 0.19649582532392512}
2022-12-31 07:58:56,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:56,688 INFO:     Epoch: 23
2022-12-31 07:58:58,315 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.426773801445961, 'Total loss': 0.426773801445961} | train loss {'Reaction outcome loss': 0.1914935745231619, 'Total loss': 0.1914935745231619}
2022-12-31 07:58:58,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:58,316 INFO:     Epoch: 24
2022-12-31 07:58:59,971 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44571279883384707, 'Total loss': 0.44571279883384707} | train loss {'Reaction outcome loss': 0.19210988900452744, 'Total loss': 0.19210988900452744}
2022-12-31 07:58:59,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:58:59,972 INFO:     Epoch: 25
2022-12-31 07:59:01,597 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4528829495112101, 'Total loss': 0.4528829495112101} | train loss {'Reaction outcome loss': 0.18660241138149686, 'Total loss': 0.18660241138149686}
2022-12-31 07:59:01,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:01,597 INFO:     Epoch: 26
2022-12-31 07:59:03,269 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43629434108734133, 'Total loss': 0.43629434108734133} | train loss {'Reaction outcome loss': 0.1846798784956874, 'Total loss': 0.1846798784956874}
2022-12-31 07:59:03,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:03,269 INFO:     Epoch: 27
2022-12-31 07:59:04,898 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4449067533016205, 'Total loss': 0.4449067533016205} | train loss {'Reaction outcome loss': 0.17730770217059752, 'Total loss': 0.17730770217059752}
2022-12-31 07:59:04,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:04,898 INFO:     Epoch: 28
2022-12-31 07:59:06,553 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4775845408439636, 'Total loss': 0.4775845408439636} | train loss {'Reaction outcome loss': 0.17630141931132073, 'Total loss': 0.17630141931132073}
2022-12-31 07:59:06,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:06,553 INFO:     Epoch: 29
2022-12-31 07:59:08,187 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4420076568921407, 'Total loss': 0.4420076568921407} | train loss {'Reaction outcome loss': 0.17320935341734642, 'Total loss': 0.17320935341734642}
2022-12-31 07:59:08,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:08,188 INFO:     Epoch: 30
2022-12-31 07:59:09,815 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47417832215627037, 'Total loss': 0.47417832215627037} | train loss {'Reaction outcome loss': 0.16988261355026643, 'Total loss': 0.16988261355026643}
2022-12-31 07:59:09,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:09,816 INFO:     Epoch: 31
2022-12-31 07:59:11,449 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45677752246459324, 'Total loss': 0.45677752246459324} | train loss {'Reaction outcome loss': 0.1665554842995715, 'Total loss': 0.1665554842995715}
2022-12-31 07:59:11,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:11,449 INFO:     Epoch: 32
2022-12-31 07:59:13,119 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45106881360212964, 'Total loss': 0.45106881360212964} | train loss {'Reaction outcome loss': 0.16232394296608676, 'Total loss': 0.16232394296608676}
2022-12-31 07:59:13,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:13,120 INFO:     Epoch: 33
2022-12-31 07:59:14,743 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4672530551751455, 'Total loss': 0.4672530551751455} | train loss {'Reaction outcome loss': 0.16388819481007458, 'Total loss': 0.16388819481007458}
2022-12-31 07:59:14,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:14,743 INFO:     Epoch: 34
2022-12-31 07:59:16,396 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44633821249008176, 'Total loss': 0.44633821249008176} | train loss {'Reaction outcome loss': 0.1631250954249921, 'Total loss': 0.1631250954249921}
2022-12-31 07:59:16,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:16,397 INFO:     Epoch: 35
2022-12-31 07:59:18,056 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4398040443658829, 'Total loss': 0.4398040443658829} | train loss {'Reaction outcome loss': 0.161501022072556, 'Total loss': 0.161501022072556}
2022-12-31 07:59:18,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:18,056 INFO:     Epoch: 36
2022-12-31 07:59:19,684 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45992162426312766, 'Total loss': 0.45992162426312766} | train loss {'Reaction outcome loss': 0.15773132141168475, 'Total loss': 0.15773132141168475}
2022-12-31 07:59:19,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:19,684 INFO:     Epoch: 37
2022-12-31 07:59:21,352 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4355816384156545, 'Total loss': 0.4355816384156545} | train loss {'Reaction outcome loss': 0.1527815229269518, 'Total loss': 0.1527815229269518}
2022-12-31 07:59:21,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:21,352 INFO:     Epoch: 38
2022-12-31 07:59:22,981 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4410142739613851, 'Total loss': 0.4410142739613851} | train loss {'Reaction outcome loss': 0.15233079337477953, 'Total loss': 0.15233079337477953}
2022-12-31 07:59:22,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:22,981 INFO:     Epoch: 39
2022-12-31 07:59:24,642 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45816101829210915, 'Total loss': 0.45816101829210915} | train loss {'Reaction outcome loss': 0.151957316596451, 'Total loss': 0.151957316596451}
2022-12-31 07:59:24,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:24,643 INFO:     Epoch: 40
2022-12-31 07:59:26,279 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45844167868296304, 'Total loss': 0.45844167868296304} | train loss {'Reaction outcome loss': 0.15041788334921272, 'Total loss': 0.15041788334921272}
2022-12-31 07:59:26,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:26,279 INFO:     Epoch: 41
2022-12-31 07:59:27,946 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45651015639305115, 'Total loss': 0.45651015639305115} | train loss {'Reaction outcome loss': 0.1488734019805916, 'Total loss': 0.1488734019805916}
2022-12-31 07:59:27,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:27,947 INFO:     Epoch: 42
2022-12-31 07:59:29,570 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47004418770472206, 'Total loss': 0.47004418770472206} | train loss {'Reaction outcome loss': 0.15027701533618062, 'Total loss': 0.15027701533618062}
2022-12-31 07:59:29,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:29,571 INFO:     Epoch: 43
2022-12-31 07:59:31,193 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46353161210815114, 'Total loss': 0.46353161210815114} | train loss {'Reaction outcome loss': 0.1476366209565571, 'Total loss': 0.1476366209565571}
2022-12-31 07:59:31,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:31,194 INFO:     Epoch: 44
2022-12-31 07:59:32,818 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46895815134048463, 'Total loss': 0.46895815134048463} | train loss {'Reaction outcome loss': 0.14786001197348217, 'Total loss': 0.14786001197348217}
2022-12-31 07:59:32,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:32,818 INFO:     Epoch: 45
2022-12-31 07:59:34,443 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45639819304148355, 'Total loss': 0.45639819304148355} | train loss {'Reaction outcome loss': 0.14126784925681912, 'Total loss': 0.14126784925681912}
2022-12-31 07:59:34,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:34,443 INFO:     Epoch: 46
2022-12-31 07:59:36,113 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4574045737584432, 'Total loss': 0.4574045737584432} | train loss {'Reaction outcome loss': 0.14207199975068174, 'Total loss': 0.14207199975068174}
2022-12-31 07:59:36,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:36,113 INFO:     Epoch: 47
2022-12-31 07:59:37,725 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42824642608563107, 'Total loss': 0.42824642608563107} | train loss {'Reaction outcome loss': 0.14388921420806045, 'Total loss': 0.14388921420806045}
2022-12-31 07:59:37,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:37,725 INFO:     Epoch: 48
2022-12-31 07:59:39,393 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4600495919585228, 'Total loss': 0.4600495919585228} | train loss {'Reaction outcome loss': 0.14031934466159193, 'Total loss': 0.14031934466159193}
2022-12-31 07:59:39,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:39,393 INFO:     Epoch: 49
2022-12-31 07:59:41,061 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45559542775154116, 'Total loss': 0.45559542775154116} | train loss {'Reaction outcome loss': 0.13850678833847066, 'Total loss': 0.13850678833847066}
2022-12-31 07:59:41,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:41,061 INFO:     Epoch: 50
2022-12-31 07:59:42,729 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4451134373744329, 'Total loss': 0.4451134373744329} | train loss {'Reaction outcome loss': 0.13608014807844743, 'Total loss': 0.13608014807844743}
2022-12-31 07:59:42,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:42,729 INFO:     Epoch: 51
2022-12-31 07:59:44,349 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4547583520412445, 'Total loss': 0.4547583520412445} | train loss {'Reaction outcome loss': 0.13626285514790928, 'Total loss': 0.13626285514790928}
2022-12-31 07:59:44,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:44,350 INFO:     Epoch: 52
2022-12-31 07:59:45,965 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4732050021489461, 'Total loss': 0.4732050021489461} | train loss {'Reaction outcome loss': 0.13392350326009794, 'Total loss': 0.13392350326009794}
2022-12-31 07:59:45,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:45,966 INFO:     Epoch: 53
2022-12-31 07:59:47,633 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44175365765889485, 'Total loss': 0.44175365765889485} | train loss {'Reaction outcome loss': 0.13166174139081088, 'Total loss': 0.13166174139081088}
2022-12-31 07:59:47,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:47,634 INFO:     Epoch: 54
2022-12-31 07:59:49,302 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45235971609751385, 'Total loss': 0.45235971609751385} | train loss {'Reaction outcome loss': 0.13706199867509655, 'Total loss': 0.13706199867509655}
2022-12-31 07:59:49,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:49,302 INFO:     Epoch: 55
2022-12-31 07:59:50,970 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4551740696032842, 'Total loss': 0.4551740696032842} | train loss {'Reaction outcome loss': 0.1338238176933426, 'Total loss': 0.1338238176933426}
2022-12-31 07:59:50,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:50,970 INFO:     Epoch: 56
2022-12-31 07:59:52,583 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.471324160695076, 'Total loss': 0.471324160695076} | train loss {'Reaction outcome loss': 0.13289242165855766, 'Total loss': 0.13289242165855766}
2022-12-31 07:59:52,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:52,584 INFO:     Epoch: 57
2022-12-31 07:59:54,212 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4840312242507935, 'Total loss': 0.4840312242507935} | train loss {'Reaction outcome loss': 0.130392395887887, 'Total loss': 0.130392395887887}
2022-12-31 07:59:54,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:54,212 INFO:     Epoch: 58
2022-12-31 07:59:55,858 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4731264268358549, 'Total loss': 0.4731264268358549} | train loss {'Reaction outcome loss': 0.12813126284037363, 'Total loss': 0.12813126284037363}
2022-12-31 07:59:55,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:55,858 INFO:     Epoch: 59
2022-12-31 07:59:57,526 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45730583667755126, 'Total loss': 0.45730583667755126} | train loss {'Reaction outcome loss': 0.12980328310139827, 'Total loss': 0.12980328310139827}
2022-12-31 07:59:57,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:57,527 INFO:     Epoch: 60
2022-12-31 07:59:59,148 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46212038993835447, 'Total loss': 0.46212038993835447} | train loss {'Reaction outcome loss': 0.1276634775777936, 'Total loss': 0.1276634775777936}
2022-12-31 07:59:59,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 07:59:59,148 INFO:     Epoch: 61
2022-12-31 08:00:00,818 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46073924700419105, 'Total loss': 0.46073924700419105} | train loss {'Reaction outcome loss': 0.1267155286190285, 'Total loss': 0.1267155286190285}
2022-12-31 08:00:00,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:00,819 INFO:     Epoch: 62
2022-12-31 08:00:02,435 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4452299579977989, 'Total loss': 0.4452299579977989} | train loss {'Reaction outcome loss': 0.13088286425481258, 'Total loss': 0.13088286425481258}
2022-12-31 08:00:02,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:02,435 INFO:     Epoch: 63
2022-12-31 08:00:04,079 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44775950312614443, 'Total loss': 0.44775950312614443} | train loss {'Reaction outcome loss': 0.1289364542217004, 'Total loss': 0.1289364542217004}
2022-12-31 08:00:04,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:04,079 INFO:     Epoch: 64
2022-12-31 08:00:05,707 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.464745565255483, 'Total loss': 0.464745565255483} | train loss {'Reaction outcome loss': 0.1275740626809399, 'Total loss': 0.1275740626809399}
2022-12-31 08:00:05,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:05,708 INFO:     Epoch: 65
2022-12-31 08:00:07,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47012884020805357, 'Total loss': 0.47012884020805357} | train loss {'Reaction outcome loss': 0.1271340748604508, 'Total loss': 0.1271340748604508}
2022-12-31 08:00:07,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:07,337 INFO:     Epoch: 66
2022-12-31 08:00:08,966 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4641567056377729, 'Total loss': 0.4641567056377729} | train loss {'Reaction outcome loss': 0.12775239810710673, 'Total loss': 0.12775239810710673}
2022-12-31 08:00:08,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:08,966 INFO:     Epoch: 67
2022-12-31 08:00:10,586 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.464016525944074, 'Total loss': 0.464016525944074} | train loss {'Reaction outcome loss': 0.12618119147562487, 'Total loss': 0.12618119147562487}
2022-12-31 08:00:10,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:10,587 INFO:     Epoch: 68
2022-12-31 08:00:12,216 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44510492781798044, 'Total loss': 0.44510492781798044} | train loss {'Reaction outcome loss': 0.1254824026721439, 'Total loss': 0.1254824026721439}
2022-12-31 08:00:12,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:12,216 INFO:     Epoch: 69
2022-12-31 08:00:13,834 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44705881277720133, 'Total loss': 0.44705881277720133} | train loss {'Reaction outcome loss': 0.12179635442282319, 'Total loss': 0.12179635442282319}
2022-12-31 08:00:13,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:13,835 INFO:     Epoch: 70
2022-12-31 08:00:15,461 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4505874991416931, 'Total loss': 0.4505874991416931} | train loss {'Reaction outcome loss': 0.12491918118529372, 'Total loss': 0.12491918118529372}
2022-12-31 08:00:15,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:15,461 INFO:     Epoch: 71
2022-12-31 08:00:17,088 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4524293343226115, 'Total loss': 0.4524293343226115} | train loss {'Reaction outcome loss': 0.11896169612550644, 'Total loss': 0.11896169612550644}
2022-12-31 08:00:17,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:17,088 INFO:     Epoch: 72
2022-12-31 08:00:18,715 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4509931405385335, 'Total loss': 0.4509931405385335} | train loss {'Reaction outcome loss': 0.12147972207190301, 'Total loss': 0.12147972207190301}
2022-12-31 08:00:18,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:18,715 INFO:     Epoch: 73
2022-12-31 08:00:20,334 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46168231467405957, 'Total loss': 0.46168231467405957} | train loss {'Reaction outcome loss': 0.12358713586602885, 'Total loss': 0.12358713586602885}
2022-12-31 08:00:20,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:20,335 INFO:     Epoch: 74
2022-12-31 08:00:21,957 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4629189838965734, 'Total loss': 0.4629189838965734} | train loss {'Reaction outcome loss': 0.12179406127297329, 'Total loss': 0.12179406127297329}
2022-12-31 08:00:21,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:21,957 INFO:     Epoch: 75
2022-12-31 08:00:23,587 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4667244146267573, 'Total loss': 0.4667244146267573} | train loss {'Reaction outcome loss': 0.12739748298442696, 'Total loss': 0.12739748298442696}
2022-12-31 08:00:23,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:23,587 INFO:     Epoch: 76
2022-12-31 08:00:25,254 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46550740698973336, 'Total loss': 0.46550740698973336} | train loss {'Reaction outcome loss': 0.12423572447890624, 'Total loss': 0.12423572447890624}
2022-12-31 08:00:25,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:25,254 INFO:     Epoch: 77
2022-12-31 08:00:26,879 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4654265582561493, 'Total loss': 0.4654265582561493} | train loss {'Reaction outcome loss': 0.12273687909488375, 'Total loss': 0.12273687909488375}
2022-12-31 08:00:26,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:26,879 INFO:     Epoch: 78
2022-12-31 08:00:28,540 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4867895692586899, 'Total loss': 0.4867895692586899} | train loss {'Reaction outcome loss': 0.11762672396282588, 'Total loss': 0.11762672396282588}
2022-12-31 08:00:28,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:28,540 INFO:     Epoch: 79
2022-12-31 08:00:30,165 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4686683793862661, 'Total loss': 0.4686683793862661} | train loss {'Reaction outcome loss': 0.11663791699173595, 'Total loss': 0.11663791699173595}
2022-12-31 08:00:30,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:30,165 INFO:     Epoch: 80
2022-12-31 08:00:31,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4659323533376058, 'Total loss': 0.4659323533376058} | train loss {'Reaction outcome loss': 0.12205211082574262, 'Total loss': 0.12205211082574262}
2022-12-31 08:00:31,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:31,811 INFO:     Epoch: 81
2022-12-31 08:00:33,432 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4630558490753174, 'Total loss': 0.4630558490753174} | train loss {'Reaction outcome loss': 0.11654373263395543, 'Total loss': 0.11654373263395543}
2022-12-31 08:00:33,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:33,432 INFO:     Epoch: 82
2022-12-31 08:00:35,052 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4712523659070333, 'Total loss': 0.4712523659070333} | train loss {'Reaction outcome loss': 0.1247915769128687, 'Total loss': 0.1247915769128687}
2022-12-31 08:00:35,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:35,053 INFO:     Epoch: 83
2022-12-31 08:00:36,720 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44656713406244913, 'Total loss': 0.44656713406244913} | train loss {'Reaction outcome loss': 0.11987947951834178, 'Total loss': 0.11987947951834178}
2022-12-31 08:00:36,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:36,721 INFO:     Epoch: 84
2022-12-31 08:00:38,333 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45058547854423525, 'Total loss': 0.45058547854423525} | train loss {'Reaction outcome loss': 0.11592276981234927, 'Total loss': 0.11592276981234927}
2022-12-31 08:00:38,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:38,334 INFO:     Epoch: 85
2022-12-31 08:00:40,001 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4588983476161957, 'Total loss': 0.4588983476161957} | train loss {'Reaction outcome loss': 0.11568112746351786, 'Total loss': 0.11568112746351786}
2022-12-31 08:00:40,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:40,001 INFO:     Epoch: 86
2022-12-31 08:00:41,621 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46485232810179394, 'Total loss': 0.46485232810179394} | train loss {'Reaction outcome loss': 0.1160437353409235, 'Total loss': 0.1160437353409235}
2022-12-31 08:00:41,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:41,621 INFO:     Epoch: 87
2022-12-31 08:00:43,251 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4499336898326874, 'Total loss': 0.4499336898326874} | train loss {'Reaction outcome loss': 0.11763668061395441, 'Total loss': 0.11763668061395441}
2022-12-31 08:00:43,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:43,252 INFO:     Epoch: 88
2022-12-31 08:00:44,880 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45957125822703043, 'Total loss': 0.45957125822703043} | train loss {'Reaction outcome loss': 0.12068801536813163, 'Total loss': 0.12068801536813163}
2022-12-31 08:00:44,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:44,880 INFO:     Epoch: 89
2022-12-31 08:00:46,509 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46724345088005065, 'Total loss': 0.46724345088005065} | train loss {'Reaction outcome loss': 0.11629348369113536, 'Total loss': 0.11629348369113536}
2022-12-31 08:00:46,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:46,510 INFO:     Epoch: 90
2022-12-31 08:00:48,163 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45224248319864274, 'Total loss': 0.45224248319864274} | train loss {'Reaction outcome loss': 0.11455068259419275, 'Total loss': 0.11455068259419275}
2022-12-31 08:00:48,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:48,163 INFO:     Epoch: 91
2022-12-31 08:00:49,775 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45003887116909025, 'Total loss': 0.45003887116909025} | train loss {'Reaction outcome loss': 0.11675856323384878, 'Total loss': 0.11675856323384878}
2022-12-31 08:00:49,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:49,776 INFO:     Epoch: 92
2022-12-31 08:00:51,395 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46674405336380004, 'Total loss': 0.46674405336380004} | train loss {'Reaction outcome loss': 0.12089071785173772, 'Total loss': 0.12089071785173772}
2022-12-31 08:00:51,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:51,395 INFO:     Epoch: 93
2022-12-31 08:00:53,015 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.456743186712265, 'Total loss': 0.456743186712265} | train loss {'Reaction outcome loss': 0.12475194885237445, 'Total loss': 0.12475194885237445}
2022-12-31 08:00:53,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:53,015 INFO:     Epoch: 94
2022-12-31 08:00:54,636 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45371577935293317, 'Total loss': 0.45371577935293317} | train loss {'Reaction outcome loss': 0.11732678860425949, 'Total loss': 0.11732678860425949}
2022-12-31 08:00:54,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:54,637 INFO:     Epoch: 95
2022-12-31 08:00:56,282 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49617700378100077, 'Total loss': 0.49617700378100077} | train loss {'Reaction outcome loss': 0.11845838653330526, 'Total loss': 0.11845838653330526}
2022-12-31 08:00:56,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:56,283 INFO:     Epoch: 96
2022-12-31 08:00:57,907 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.459797228872776, 'Total loss': 0.459797228872776} | train loss {'Reaction outcome loss': 0.11467880549561568, 'Total loss': 0.11467880549561568}
2022-12-31 08:00:57,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:57,907 INFO:     Epoch: 97
2022-12-31 08:00:59,526 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49392377336819965, 'Total loss': 0.49392377336819965} | train loss {'Reaction outcome loss': 0.11686373617758954, 'Total loss': 0.11686373617758954}
2022-12-31 08:00:59,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:00:59,526 INFO:     Epoch: 98
2022-12-31 08:01:01,154 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47531623442967735, 'Total loss': 0.47531623442967735} | train loss {'Reaction outcome loss': 0.11798083032767158, 'Total loss': 0.11798083032767158}
2022-12-31 08:01:01,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:01,154 INFO:     Epoch: 99
2022-12-31 08:01:02,783 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4696788897116979, 'Total loss': 0.4696788897116979} | train loss {'Reaction outcome loss': 0.11186961433598065, 'Total loss': 0.11186961433598065}
2022-12-31 08:01:02,784 INFO:     Best model found after epoch 21 of 100.
2022-12-31 08:01:02,784 INFO:   Done with stage: TRAINING
2022-12-31 08:01:02,784 INFO:   Starting stage: EVALUATION
2022-12-31 08:01:02,911 INFO:   Done with stage: EVALUATION
2022-12-31 08:01:02,911 INFO:   Leaving out SEQ value Fold_7
2022-12-31 08:01:02,923 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:01:02,924 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:01:03,569 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:01:03,569 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:01:03,638 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:01:03,638 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:01:03,638 INFO:     No hyperparam tuning for this model
2022-12-31 08:01:03,638 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:01:03,638 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:01:03,639 INFO:     None feature selector for col prot
2022-12-31 08:01:03,639 INFO:     None feature selector for col prot
2022-12-31 08:01:03,639 INFO:     None feature selector for col prot
2022-12-31 08:01:03,640 INFO:     None feature selector for col chem
2022-12-31 08:01:03,640 INFO:     None feature selector for col chem
2022-12-31 08:01:03,640 INFO:     None feature selector for col chem
2022-12-31 08:01:03,640 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:01:03,640 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:01:03,642 INFO:     Number of params in model 224011
2022-12-31 08:01:03,645 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:01:03,645 INFO:   Starting stage: TRAINING
2022-12-31 08:01:03,689 INFO:     Val loss before train {'Reaction outcome loss': 1.0255876501401266, 'Total loss': 1.0255876501401266}
2022-12-31 08:01:03,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:03,690 INFO:     Epoch: 0
2022-12-31 08:01:05,324 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6298470536867777, 'Total loss': 0.6298470536867777} | train loss {'Reaction outcome loss': 0.7834554186581705, 'Total loss': 0.7834554186581705}
2022-12-31 08:01:05,324 INFO:     Found new best model at epoch 0
2022-12-31 08:01:05,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:05,325 INFO:     Epoch: 1
2022-12-31 08:01:06,956 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5610374947388966, 'Total loss': 0.5610374947388966} | train loss {'Reaction outcome loss': 0.5149605561464702, 'Total loss': 0.5149605561464702}
2022-12-31 08:01:06,957 INFO:     Found new best model at epoch 1
2022-12-31 08:01:06,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:06,958 INFO:     Epoch: 2
2022-12-31 08:01:08,605 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5224565287431081, 'Total loss': 0.5224565287431081} | train loss {'Reaction outcome loss': 0.44848622871219895, 'Total loss': 0.44848622871219895}
2022-12-31 08:01:08,605 INFO:     Found new best model at epoch 2
2022-12-31 08:01:08,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:08,606 INFO:     Epoch: 3
2022-12-31 08:01:10,245 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5023923516273499, 'Total loss': 0.5023923516273499} | train loss {'Reaction outcome loss': 0.4034961805231735, 'Total loss': 0.4034961805231735}
2022-12-31 08:01:10,245 INFO:     Found new best model at epoch 3
2022-12-31 08:01:10,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:10,246 INFO:     Epoch: 4
2022-12-31 08:01:11,868 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49080219070116676, 'Total loss': 0.49080219070116676} | train loss {'Reaction outcome loss': 0.3747019772871737, 'Total loss': 0.3747019772871737}
2022-12-31 08:01:11,869 INFO:     Found new best model at epoch 4
2022-12-31 08:01:11,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:11,870 INFO:     Epoch: 5
2022-12-31 08:01:13,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5183253576358159, 'Total loss': 0.5183253576358159} | train loss {'Reaction outcome loss': 0.34742089995731085, 'Total loss': 0.34742089995731085}
2022-12-31 08:01:13,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:13,539 INFO:     Epoch: 6
2022-12-31 08:01:15,159 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48697295288244885, 'Total loss': 0.48697295288244885} | train loss {'Reaction outcome loss': 0.33076978872936985, 'Total loss': 0.33076978872936985}
2022-12-31 08:01:15,159 INFO:     Found new best model at epoch 6
2022-12-31 08:01:15,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:15,160 INFO:     Epoch: 7
2022-12-31 08:01:16,773 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5025073409080505, 'Total loss': 0.5025073409080505} | train loss {'Reaction outcome loss': 0.3130441085848998, 'Total loss': 0.3130441085848998}
2022-12-31 08:01:16,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:16,773 INFO:     Epoch: 8
2022-12-31 08:01:18,391 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46390868425369264, 'Total loss': 0.46390868425369264} | train loss {'Reaction outcome loss': 0.29722943923533607, 'Total loss': 0.29722943923533607}
2022-12-31 08:01:18,392 INFO:     Found new best model at epoch 8
2022-12-31 08:01:18,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:18,393 INFO:     Epoch: 9
2022-12-31 08:01:20,008 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48597266177336373, 'Total loss': 0.48597266177336373} | train loss {'Reaction outcome loss': 0.2819279034753138, 'Total loss': 0.2819279034753138}
2022-12-31 08:01:20,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:20,009 INFO:     Epoch: 10
2022-12-31 08:01:21,676 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48204732437928516, 'Total loss': 0.48204732437928516} | train loss {'Reaction outcome loss': 0.267888524108953, 'Total loss': 0.267888524108953}
2022-12-31 08:01:21,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:21,677 INFO:     Epoch: 11
2022-12-31 08:01:23,297 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4783409059047699, 'Total loss': 0.4783409059047699} | train loss {'Reaction outcome loss': 0.2540644393756394, 'Total loss': 0.2540644393756394}
2022-12-31 08:01:23,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:23,297 INFO:     Epoch: 12
2022-12-31 08:01:24,916 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4949876477320989, 'Total loss': 0.4949876477320989} | train loss {'Reaction outcome loss': 0.24451696590288452, 'Total loss': 0.24451696590288452}
2022-12-31 08:01:24,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:24,916 INFO:     Epoch: 13
2022-12-31 08:01:26,562 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4682468871275584, 'Total loss': 0.4682468871275584} | train loss {'Reaction outcome loss': 0.23635232740414702, 'Total loss': 0.23635232740414702}
2022-12-31 08:01:26,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:26,562 INFO:     Epoch: 14
2022-12-31 08:01:28,229 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4744637678066889, 'Total loss': 0.4744637678066889} | train loss {'Reaction outcome loss': 0.22872767753441842, 'Total loss': 0.22872767753441842}
2022-12-31 08:01:28,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:28,230 INFO:     Epoch: 15
2022-12-31 08:01:29,898 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4831764797369639, 'Total loss': 0.4831764797369639} | train loss {'Reaction outcome loss': 0.22376020832343652, 'Total loss': 0.22376020832343652}
2022-12-31 08:01:29,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:29,898 INFO:     Epoch: 16
2022-12-31 08:01:31,566 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49683652222156527, 'Total loss': 0.49683652222156527} | train loss {'Reaction outcome loss': 0.2192282305445374, 'Total loss': 0.2192282305445374}
2022-12-31 08:01:31,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:31,567 INFO:     Epoch: 17
2022-12-31 08:01:33,181 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4646999667088191, 'Total loss': 0.4646999667088191} | train loss {'Reaction outcome loss': 0.2099496184273317, 'Total loss': 0.2099496184273317}
2022-12-31 08:01:33,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:33,181 INFO:     Epoch: 18
2022-12-31 08:01:34,834 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47542661825815835, 'Total loss': 0.47542661825815835} | train loss {'Reaction outcome loss': 0.20350268021871468, 'Total loss': 0.20350268021871468}
2022-12-31 08:01:34,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:34,834 INFO:     Epoch: 19
2022-12-31 08:01:36,475 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4768548349539439, 'Total loss': 0.4768548349539439} | train loss {'Reaction outcome loss': 0.1976814639018277, 'Total loss': 0.1976814639018277}
2022-12-31 08:01:36,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:36,475 INFO:     Epoch: 20
2022-12-31 08:01:38,094 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46809206418693067, 'Total loss': 0.46809206418693067} | train loss {'Reaction outcome loss': 0.1959765491408669, 'Total loss': 0.1959765491408669}
2022-12-31 08:01:38,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:38,094 INFO:     Epoch: 21
2022-12-31 08:01:39,716 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48171034653981526, 'Total loss': 0.48171034653981526} | train loss {'Reaction outcome loss': 0.19166061719240696, 'Total loss': 0.19166061719240696}
2022-12-31 08:01:39,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:39,716 INFO:     Epoch: 22
2022-12-31 08:01:41,339 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4825320859750112, 'Total loss': 0.4825320859750112} | train loss {'Reaction outcome loss': 0.1841728283690847, 'Total loss': 0.1841728283690847}
2022-12-31 08:01:41,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:41,340 INFO:     Epoch: 23
2022-12-31 08:01:42,974 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5046174426873525, 'Total loss': 0.5046174426873525} | train loss {'Reaction outcome loss': 0.17968413342019066, 'Total loss': 0.17968413342019066}
2022-12-31 08:01:42,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:42,975 INFO:     Epoch: 24
2022-12-31 08:01:44,595 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4873600592215856, 'Total loss': 0.4873600592215856} | train loss {'Reaction outcome loss': 0.1785699516662568, 'Total loss': 0.1785699516662568}
2022-12-31 08:01:44,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:44,595 INFO:     Epoch: 25
2022-12-31 08:01:46,213 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5424763103326161, 'Total loss': 0.5424763103326161} | train loss {'Reaction outcome loss': 0.1774829285452983, 'Total loss': 0.1774829285452983}
2022-12-31 08:01:46,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:46,213 INFO:     Epoch: 26
2022-12-31 08:01:47,830 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5001347283522288, 'Total loss': 0.5001347283522288} | train loss {'Reaction outcome loss': 0.1748729057825214, 'Total loss': 0.1748729057825214}
2022-12-31 08:01:47,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:47,830 INFO:     Epoch: 27
2022-12-31 08:01:49,497 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48988027771313986, 'Total loss': 0.48988027771313986} | train loss {'Reaction outcome loss': 0.1760215023633375, 'Total loss': 0.1760215023633375}
2022-12-31 08:01:49,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:49,498 INFO:     Epoch: 28
2022-12-31 08:01:51,126 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5130653748909633, 'Total loss': 0.5130653748909633} | train loss {'Reaction outcome loss': 0.16719913779209883, 'Total loss': 0.16719913779209883}
2022-12-31 08:01:51,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:51,126 INFO:     Epoch: 29
2022-12-31 08:01:52,789 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4870668550332387, 'Total loss': 0.4870668550332387} | train loss {'Reaction outcome loss': 0.16693468730802571, 'Total loss': 0.16693468730802571}
2022-12-31 08:01:52,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:52,789 INFO:     Epoch: 30
2022-12-31 08:01:54,447 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4958451479673386, 'Total loss': 0.4958451479673386} | train loss {'Reaction outcome loss': 0.16956872302393297, 'Total loss': 0.16956872302393297}
2022-12-31 08:01:54,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:54,447 INFO:     Epoch: 31
2022-12-31 08:01:56,115 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4907013734181722, 'Total loss': 0.4907013734181722} | train loss {'Reaction outcome loss': 0.15968184734254215, 'Total loss': 0.15968184734254215}
2022-12-31 08:01:56,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:56,115 INFO:     Epoch: 32
2022-12-31 08:01:57,729 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5204664458831151, 'Total loss': 0.5204664458831151} | train loss {'Reaction outcome loss': 0.16116049657121892, 'Total loss': 0.16116049657121892}
2022-12-31 08:01:57,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:57,729 INFO:     Epoch: 33
2022-12-31 08:01:59,396 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48718573252360026, 'Total loss': 0.48718573252360026} | train loss {'Reaction outcome loss': 0.1587040818528363, 'Total loss': 0.1587040818528363}
2022-12-31 08:01:59,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:01:59,396 INFO:     Epoch: 34
2022-12-31 08:02:01,019 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5364254315694174, 'Total loss': 0.5364254315694174} | train loss {'Reaction outcome loss': 0.15632107937943848, 'Total loss': 0.15632107937943848}
2022-12-31 08:02:01,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:01,019 INFO:     Epoch: 35
2022-12-31 08:02:02,643 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5293007691701254, 'Total loss': 0.5293007691701254} | train loss {'Reaction outcome loss': 0.1569552663680072, 'Total loss': 0.1569552663680072}
2022-12-31 08:02:02,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:02,644 INFO:     Epoch: 36
2022-12-31 08:02:04,276 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4849645604689916, 'Total loss': 0.4849645604689916} | train loss {'Reaction outcome loss': 0.15319619055111164, 'Total loss': 0.15319619055111164}
2022-12-31 08:02:04,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:04,276 INFO:     Epoch: 37
2022-12-31 08:02:05,911 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5093114227056503, 'Total loss': 0.5093114227056503} | train loss {'Reaction outcome loss': 0.15280849515504139, 'Total loss': 0.15280849515504139}
2022-12-31 08:02:05,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:05,912 INFO:     Epoch: 38
2022-12-31 08:02:07,548 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5049985349178314, 'Total loss': 0.5049985349178314} | train loss {'Reaction outcome loss': 0.15155485792031734, 'Total loss': 0.15155485792031734}
2022-12-31 08:02:07,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:07,548 INFO:     Epoch: 39
2022-12-31 08:02:09,173 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5046336889266968, 'Total loss': 0.5046336889266968} | train loss {'Reaction outcome loss': 0.14793858531734735, 'Total loss': 0.14793858531734735}
2022-12-31 08:02:09,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:09,174 INFO:     Epoch: 40
2022-12-31 08:02:10,807 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5302406410376231, 'Total loss': 0.5302406410376231} | train loss {'Reaction outcome loss': 0.14530455747565477, 'Total loss': 0.14530455747565477}
2022-12-31 08:02:10,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:10,807 INFO:     Epoch: 41
2022-12-31 08:02:12,429 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5150648852189382, 'Total loss': 0.5150648852189382} | train loss {'Reaction outcome loss': 0.14491389231379767, 'Total loss': 0.14491389231379767}
2022-12-31 08:02:12,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:12,430 INFO:     Epoch: 42
2022-12-31 08:02:14,062 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5211137428879737, 'Total loss': 0.5211137428879737} | train loss {'Reaction outcome loss': 0.14392132959950593, 'Total loss': 0.14392132959950593}
2022-12-31 08:02:14,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:14,062 INFO:     Epoch: 43
2022-12-31 08:02:15,694 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5059694071610769, 'Total loss': 0.5059694071610769} | train loss {'Reaction outcome loss': 0.14411519434208905, 'Total loss': 0.14411519434208905}
2022-12-31 08:02:15,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:15,695 INFO:     Epoch: 44
2022-12-31 08:02:17,326 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5189243018627167, 'Total loss': 0.5189243018627167} | train loss {'Reaction outcome loss': 0.14350189745009267, 'Total loss': 0.14350189745009267}
2022-12-31 08:02:17,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:17,326 INFO:     Epoch: 45
2022-12-31 08:02:18,950 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5543370445569357, 'Total loss': 0.5543370445569357} | train loss {'Reaction outcome loss': 0.14171140984924585, 'Total loss': 0.14171140984924585}
2022-12-31 08:02:18,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:18,951 INFO:     Epoch: 46
2022-12-31 08:02:20,587 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.514071915547053, 'Total loss': 0.514071915547053} | train loss {'Reaction outcome loss': 0.14749639531570596, 'Total loss': 0.14749639531570596}
2022-12-31 08:02:20,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:20,587 INFO:     Epoch: 47
2022-12-31 08:02:22,257 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4962980995575587, 'Total loss': 0.4962980995575587} | train loss {'Reaction outcome loss': 0.13931947755240684, 'Total loss': 0.13931947755240684}
2022-12-31 08:02:22,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:22,257 INFO:     Epoch: 48
2022-12-31 08:02:23,874 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5425052225589753, 'Total loss': 0.5425052225589753} | train loss {'Reaction outcome loss': 0.13268722413235515, 'Total loss': 0.13268722413235515}
2022-12-31 08:02:23,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:23,874 INFO:     Epoch: 49
2022-12-31 08:02:25,491 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.512456535299619, 'Total loss': 0.512456535299619} | train loss {'Reaction outcome loss': 0.13569024511502, 'Total loss': 0.13569024511502}
2022-12-31 08:02:25,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:25,492 INFO:     Epoch: 50
2022-12-31 08:02:27,101 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5267846246560415, 'Total loss': 0.5267846246560415} | train loss {'Reaction outcome loss': 0.13476647613637338, 'Total loss': 0.13476647613637338}
2022-12-31 08:02:27,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:27,101 INFO:     Epoch: 51
2022-12-31 08:02:28,768 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5187418242295583, 'Total loss': 0.5187418242295583} | train loss {'Reaction outcome loss': 0.13587834551049538, 'Total loss': 0.13587834551049538}
2022-12-31 08:02:28,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:28,768 INFO:     Epoch: 52
2022-12-31 08:02:30,388 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5180491497119267, 'Total loss': 0.5180491497119267} | train loss {'Reaction outcome loss': 0.13096709226658199, 'Total loss': 0.13096709226658199}
2022-12-31 08:02:30,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:30,388 INFO:     Epoch: 53
2022-12-31 08:02:32,061 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5027594923973083, 'Total loss': 0.5027594923973083} | train loss {'Reaction outcome loss': 0.13066836875201024, 'Total loss': 0.13066836875201024}
2022-12-31 08:02:32,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:32,062 INFO:     Epoch: 54
2022-12-31 08:02:33,732 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5213766992092133, 'Total loss': 0.5213766992092133} | train loss {'Reaction outcome loss': 0.13031496970648693, 'Total loss': 0.13031496970648693}
2022-12-31 08:02:33,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:33,733 INFO:     Epoch: 55
2022-12-31 08:02:35,401 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5169057716925939, 'Total loss': 0.5169057716925939} | train loss {'Reaction outcome loss': 0.13009031168067497, 'Total loss': 0.13009031168067497}
2022-12-31 08:02:35,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:35,401 INFO:     Epoch: 56
2022-12-31 08:02:37,050 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49394544859727224, 'Total loss': 0.49394544859727224} | train loss {'Reaction outcome loss': 0.1281903589527637, 'Total loss': 0.1281903589527637}
2022-12-31 08:02:37,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:37,050 INFO:     Epoch: 57
2022-12-31 08:02:38,705 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5266054312388102, 'Total loss': 0.5266054312388102} | train loss {'Reaction outcome loss': 0.13094557862432962, 'Total loss': 0.13094557862432962}
2022-12-31 08:02:38,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:38,706 INFO:     Epoch: 58
2022-12-31 08:02:40,340 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5243896106878917, 'Total loss': 0.5243896106878917} | train loss {'Reaction outcome loss': 0.13367319436716957, 'Total loss': 0.13367319436716957}
2022-12-31 08:02:40,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:40,340 INFO:     Epoch: 59
2022-12-31 08:02:41,973 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5282336433728536, 'Total loss': 0.5282336433728536} | train loss {'Reaction outcome loss': 0.12864379443073584, 'Total loss': 0.12864379443073584}
2022-12-31 08:02:41,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:41,974 INFO:     Epoch: 60
2022-12-31 08:02:43,607 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.522231159110864, 'Total loss': 0.522231159110864} | train loss {'Reaction outcome loss': 0.12581286596517594, 'Total loss': 0.12581286596517594}
2022-12-31 08:02:43,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:43,607 INFO:     Epoch: 61
2022-12-31 08:02:45,234 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5477782309055328, 'Total loss': 0.5477782309055328} | train loss {'Reaction outcome loss': 0.1234867051916217, 'Total loss': 0.1234867051916217}
2022-12-31 08:02:45,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:45,234 INFO:     Epoch: 62
2022-12-31 08:02:46,879 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5121128757794698, 'Total loss': 0.5121128757794698} | train loss {'Reaction outcome loss': 0.12745049987694362, 'Total loss': 0.12745049987694362}
2022-12-31 08:02:46,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:46,879 INFO:     Epoch: 63
2022-12-31 08:02:48,520 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5056051333745321, 'Total loss': 0.5056051333745321} | train loss {'Reaction outcome loss': 0.1209141871646477, 'Total loss': 0.1209141871646477}
2022-12-31 08:02:48,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:48,521 INFO:     Epoch: 64
2022-12-31 08:02:50,155 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5306227952241898, 'Total loss': 0.5306227952241898} | train loss {'Reaction outcome loss': 0.12592298084271514, 'Total loss': 0.12592298084271514}
2022-12-31 08:02:50,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:50,155 INFO:     Epoch: 65
2022-12-31 08:02:51,789 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5510274211565653, 'Total loss': 0.5510274211565653} | train loss {'Reaction outcome loss': 0.12606278920902564, 'Total loss': 0.12606278920902564}
2022-12-31 08:02:51,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:51,790 INFO:     Epoch: 66
2022-12-31 08:02:53,424 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.522987425327301, 'Total loss': 0.522987425327301} | train loss {'Reaction outcome loss': 0.12530587715456523, 'Total loss': 0.12530587715456523}
2022-12-31 08:02:53,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:53,424 INFO:     Epoch: 67
2022-12-31 08:02:55,051 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49673233131567635, 'Total loss': 0.49673233131567635} | train loss {'Reaction outcome loss': 0.12130204332313275, 'Total loss': 0.12130204332313275}
2022-12-31 08:02:55,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:55,052 INFO:     Epoch: 68
2022-12-31 08:02:56,672 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5288519372542699, 'Total loss': 0.5288519372542699} | train loss {'Reaction outcome loss': 0.12437778606923425, 'Total loss': 0.12437778606923425}
2022-12-31 08:02:56,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:56,672 INFO:     Epoch: 69
2022-12-31 08:02:58,295 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5437172472476959, 'Total loss': 0.5437172472476959} | train loss {'Reaction outcome loss': 0.118496102265785, 'Total loss': 0.118496102265785}
2022-12-31 08:02:58,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:58,296 INFO:     Epoch: 70
2022-12-31 08:02:59,923 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5069249644875526, 'Total loss': 0.5069249644875526} | train loss {'Reaction outcome loss': 0.12013924626519211, 'Total loss': 0.12013924626519211}
2022-12-31 08:02:59,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:02:59,923 INFO:     Epoch: 71
2022-12-31 08:03:01,549 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5198994656403859, 'Total loss': 0.5198994656403859} | train loss {'Reaction outcome loss': 0.12414502482256089, 'Total loss': 0.12414502482256089}
2022-12-31 08:03:01,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:01,550 INFO:     Epoch: 72
2022-12-31 08:03:03,175 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5466019908587137, 'Total loss': 0.5466019908587137} | train loss {'Reaction outcome loss': 0.12377013844212631, 'Total loss': 0.12377013844212631}
2022-12-31 08:03:03,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:03,175 INFO:     Epoch: 73
2022-12-31 08:03:04,793 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5502408941586813, 'Total loss': 0.5502408941586813} | train loss {'Reaction outcome loss': 0.11933996096179428, 'Total loss': 0.11933996096179428}
2022-12-31 08:03:04,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:04,793 INFO:     Epoch: 74
2022-12-31 08:03:06,402 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5199129164218903, 'Total loss': 0.5199129164218903} | train loss {'Reaction outcome loss': 0.11544751207468634, 'Total loss': 0.11544751207468634}
2022-12-31 08:03:06,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:06,403 INFO:     Epoch: 75
2022-12-31 08:03:08,019 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5010117550690969, 'Total loss': 0.5010117550690969} | train loss {'Reaction outcome loss': 0.11753763659060378, 'Total loss': 0.11753763659060378}
2022-12-31 08:03:08,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:08,019 INFO:     Epoch: 76
2022-12-31 08:03:09,633 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5387246668338775, 'Total loss': 0.5387246668338775} | train loss {'Reaction outcome loss': 0.12096432750432715, 'Total loss': 0.12096432750432715}
2022-12-31 08:03:09,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:09,634 INFO:     Epoch: 77
2022-12-31 08:03:11,249 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5320329253872236, 'Total loss': 0.5320329253872236} | train loss {'Reaction outcome loss': 0.12380127324167949, 'Total loss': 0.12380127324167949}
2022-12-31 08:03:11,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:11,250 INFO:     Epoch: 78
2022-12-31 08:03:12,868 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5020816047986348, 'Total loss': 0.5020816047986348} | train loss {'Reaction outcome loss': 0.12151559970395417, 'Total loss': 0.12151559970395417}
2022-12-31 08:03:12,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:12,869 INFO:     Epoch: 79
2022-12-31 08:03:14,482 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5161036809285482, 'Total loss': 0.5161036809285482} | train loss {'Reaction outcome loss': 0.11580652455775746, 'Total loss': 0.11580652455775746}
2022-12-31 08:03:14,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:14,483 INFO:     Epoch: 80
2022-12-31 08:03:16,093 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.489298614859581, 'Total loss': 0.489298614859581} | train loss {'Reaction outcome loss': 0.11655333982646089, 'Total loss': 0.11655333982646089}
2022-12-31 08:03:16,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:16,093 INFO:     Epoch: 81
2022-12-31 08:03:17,717 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5008314833045006, 'Total loss': 0.5008314833045006} | train loss {'Reaction outcome loss': 0.11373163397602118, 'Total loss': 0.11373163397602118}
2022-12-31 08:03:17,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:17,717 INFO:     Epoch: 82
2022-12-31 08:03:19,345 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5666036148866017, 'Total loss': 0.5666036148866017} | train loss {'Reaction outcome loss': 0.11975518031052519, 'Total loss': 0.11975518031052519}
2022-12-31 08:03:19,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:19,345 INFO:     Epoch: 83
2022-12-31 08:03:20,970 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5182347993055979, 'Total loss': 0.5182347993055979} | train loss {'Reaction outcome loss': 0.11858990596731728, 'Total loss': 0.11858990596731728}
2022-12-31 08:03:20,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:20,971 INFO:     Epoch: 84
2022-12-31 08:03:22,599 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5148595809936524, 'Total loss': 0.5148595809936524} | train loss {'Reaction outcome loss': 0.1139921296689666, 'Total loss': 0.1139921296689666}
2022-12-31 08:03:22,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:22,599 INFO:     Epoch: 85
2022-12-31 08:03:24,251 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5283380458752315, 'Total loss': 0.5283380458752315} | train loss {'Reaction outcome loss': 0.11487460890885724, 'Total loss': 0.11487460890885724}
2022-12-31 08:03:24,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:24,251 INFO:     Epoch: 86
2022-12-31 08:03:25,877 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5450286080439886, 'Total loss': 0.5450286080439886} | train loss {'Reaction outcome loss': 0.11490682266410507, 'Total loss': 0.11490682266410507}
2022-12-31 08:03:25,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:25,878 INFO:     Epoch: 87
2022-12-31 08:03:27,503 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5142138183116913, 'Total loss': 0.5142138183116913} | train loss {'Reaction outcome loss': 0.11499072784483971, 'Total loss': 0.11499072784483971}
2022-12-31 08:03:27,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:27,503 INFO:     Epoch: 88
2022-12-31 08:03:29,130 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5223270356655121, 'Total loss': 0.5223270356655121} | train loss {'Reaction outcome loss': 0.11757418362336361, 'Total loss': 0.11757418362336361}
2022-12-31 08:03:29,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:29,131 INFO:     Epoch: 89
2022-12-31 08:03:30,696 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5421798348426818, 'Total loss': 0.5421798348426818} | train loss {'Reaction outcome loss': 0.11916605461832634, 'Total loss': 0.11916605461832634}
2022-12-31 08:03:30,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:30,697 INFO:     Epoch: 90
2022-12-31 08:03:31,822 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5132423231999079, 'Total loss': 0.5132423231999079} | train loss {'Reaction outcome loss': 0.11480578668886252, 'Total loss': 0.11480578668886252}
2022-12-31 08:03:31,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:31,822 INFO:     Epoch: 91
2022-12-31 08:03:33,149 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5041613628466924, 'Total loss': 0.5041613628466924} | train loss {'Reaction outcome loss': 0.10927183341759422, 'Total loss': 0.10927183341759422}
2022-12-31 08:03:33,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:33,150 INFO:     Epoch: 92
2022-12-31 08:03:34,566 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5087723672389984, 'Total loss': 0.5087723672389984} | train loss {'Reaction outcome loss': 0.10942617408252096, 'Total loss': 0.10942617408252096}
2022-12-31 08:03:34,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:34,567 INFO:     Epoch: 93
2022-12-31 08:03:36,129 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5208967725435892, 'Total loss': 0.5208967725435892} | train loss {'Reaction outcome loss': 0.1181188026100182, 'Total loss': 0.1181188026100182}
2022-12-31 08:03:36,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:36,129 INFO:     Epoch: 94
2022-12-31 08:03:37,796 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5070410013198853, 'Total loss': 0.5070410013198853} | train loss {'Reaction outcome loss': 0.11468726988807859, 'Total loss': 0.11468726988807859}
2022-12-31 08:03:37,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:37,797 INFO:     Epoch: 95
2022-12-31 08:03:39,419 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5320876091718674, 'Total loss': 0.5320876091718674} | train loss {'Reaction outcome loss': 0.11168696059062001, 'Total loss': 0.11168696059062001}
2022-12-31 08:03:39,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:39,419 INFO:     Epoch: 96
2022-12-31 08:03:41,038 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5548005004723867, 'Total loss': 0.5548005004723867} | train loss {'Reaction outcome loss': 0.11516405075169858, 'Total loss': 0.11516405075169858}
2022-12-31 08:03:41,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:41,038 INFO:     Epoch: 97
2022-12-31 08:03:42,660 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5082074364026388, 'Total loss': 0.5082074364026388} | train loss {'Reaction outcome loss': 0.11366202958123187, 'Total loss': 0.11366202958123187}
2022-12-31 08:03:42,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:42,660 INFO:     Epoch: 98
2022-12-31 08:03:44,284 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5111646533012391, 'Total loss': 0.5111646533012391} | train loss {'Reaction outcome loss': 0.11440663779362875, 'Total loss': 0.11440663779362875}
2022-12-31 08:03:44,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:44,284 INFO:     Epoch: 99
2022-12-31 08:03:45,907 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5342230002085367, 'Total loss': 0.5342230002085367} | train loss {'Reaction outcome loss': 0.11059295444241607, 'Total loss': 0.11059295444241607}
2022-12-31 08:03:45,907 INFO:     Best model found after epoch 9 of 100.
2022-12-31 08:03:45,907 INFO:   Done with stage: TRAINING
2022-12-31 08:03:45,907 INFO:   Starting stage: EVALUATION
2022-12-31 08:03:46,033 INFO:   Done with stage: EVALUATION
2022-12-31 08:03:46,033 INFO:   Leaving out SEQ value Fold_8
2022-12-31 08:03:46,046 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 08:03:46,046 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:03:46,706 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:03:46,706 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:03:46,774 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:03:46,774 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:03:46,774 INFO:     No hyperparam tuning for this model
2022-12-31 08:03:46,774 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:03:46,774 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:03:46,775 INFO:     None feature selector for col prot
2022-12-31 08:03:46,775 INFO:     None feature selector for col prot
2022-12-31 08:03:46,775 INFO:     None feature selector for col prot
2022-12-31 08:03:46,776 INFO:     None feature selector for col chem
2022-12-31 08:03:46,776 INFO:     None feature selector for col chem
2022-12-31 08:03:46,776 INFO:     None feature selector for col chem
2022-12-31 08:03:46,776 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:03:46,776 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:03:46,778 INFO:     Number of params in model 224011
2022-12-31 08:03:46,781 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:03:46,781 INFO:   Starting stage: TRAINING
2022-12-31 08:03:46,826 INFO:     Val loss before train {'Reaction outcome loss': 0.9554327487945556, 'Total loss': 0.9554327487945556}
2022-12-31 08:03:46,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:46,826 INFO:     Epoch: 0
2022-12-31 08:03:48,442 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5445700228214264, 'Total loss': 0.5445700228214264} | train loss {'Reaction outcome loss': 0.7649635885490997, 'Total loss': 0.7649635885490997}
2022-12-31 08:03:48,442 INFO:     Found new best model at epoch 0
2022-12-31 08:03:48,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:48,443 INFO:     Epoch: 1
2022-12-31 08:03:50,083 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49128918449083964, 'Total loss': 0.49128918449083964} | train loss {'Reaction outcome loss': 0.5019364978905524, 'Total loss': 0.5019364978905524}
2022-12-31 08:03:50,084 INFO:     Found new best model at epoch 1
2022-12-31 08:03:50,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:50,085 INFO:     Epoch: 2
2022-12-31 08:03:51,708 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4681150853633881, 'Total loss': 0.4681150853633881} | train loss {'Reaction outcome loss': 0.43581839633153996, 'Total loss': 0.43581839633153996}
2022-12-31 08:03:51,708 INFO:     Found new best model at epoch 2
2022-12-31 08:03:51,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:51,709 INFO:     Epoch: 3
2022-12-31 08:03:53,326 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4538499295711517, 'Total loss': 0.4538499295711517} | train loss {'Reaction outcome loss': 0.4052280695919973, 'Total loss': 0.4052280695919973}
2022-12-31 08:03:53,327 INFO:     Found new best model at epoch 3
2022-12-31 08:03:53,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:53,328 INFO:     Epoch: 4
2022-12-31 08:03:54,940 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4574873755375544, 'Total loss': 0.4574873755375544} | train loss {'Reaction outcome loss': 0.37624971376246086, 'Total loss': 0.37624971376246086}
2022-12-31 08:03:54,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:54,941 INFO:     Epoch: 5
2022-12-31 08:03:56,556 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4678327560424805, 'Total loss': 0.4678327560424805} | train loss {'Reaction outcome loss': 0.372266778425462, 'Total loss': 0.372266778425462}
2022-12-31 08:03:56,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:56,556 INFO:     Epoch: 6
2022-12-31 08:03:58,169 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.463943205277125, 'Total loss': 0.463943205277125} | train loss {'Reaction outcome loss': 0.32952387903587543, 'Total loss': 0.32952387903587543}
2022-12-31 08:03:58,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:58,169 INFO:     Epoch: 7
2022-12-31 08:03:59,779 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4914289092024167, 'Total loss': 0.4914289092024167} | train loss {'Reaction outcome loss': 0.31066312084758596, 'Total loss': 0.31066312084758596}
2022-12-31 08:03:59,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:03:59,779 INFO:     Epoch: 8
2022-12-31 08:04:01,443 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4544810851414998, 'Total loss': 0.4544810851414998} | train loss {'Reaction outcome loss': 0.2929080809749987, 'Total loss': 0.2929080809749987}
2022-12-31 08:04:01,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:01,443 INFO:     Epoch: 9
2022-12-31 08:04:03,066 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4831406990687052, 'Total loss': 0.4831406990687052} | train loss {'Reaction outcome loss': 0.2810491315547657, 'Total loss': 0.2810491315547657}
2022-12-31 08:04:03,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:03,066 INFO:     Epoch: 10
2022-12-31 08:04:04,683 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4871346056461334, 'Total loss': 0.4871346056461334} | train loss {'Reaction outcome loss': 0.26637445300550916, 'Total loss': 0.26637445300550916}
2022-12-31 08:04:04,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:04,683 INFO:     Epoch: 11
2022-12-31 08:04:06,295 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49121961891651156, 'Total loss': 0.49121961891651156} | train loss {'Reaction outcome loss': 0.25229050152657967, 'Total loss': 0.25229050152657967}
2022-12-31 08:04:06,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:06,297 INFO:     Epoch: 12
2022-12-31 08:04:07,909 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4644852777322133, 'Total loss': 0.4644852777322133} | train loss {'Reaction outcome loss': 0.24635309649064488, 'Total loss': 0.24635309649064488}
2022-12-31 08:04:07,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:07,909 INFO:     Epoch: 13
2022-12-31 08:04:09,527 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45664668679237364, 'Total loss': 0.45664668679237364} | train loss {'Reaction outcome loss': 0.23589524277401547, 'Total loss': 0.23589524277401547}
2022-12-31 08:04:09,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:09,528 INFO:     Epoch: 14
2022-12-31 08:04:11,140 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4689417352279027, 'Total loss': 0.4689417352279027} | train loss {'Reaction outcome loss': 0.22499317511160305, 'Total loss': 0.22499317511160305}
2022-12-31 08:04:11,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:11,141 INFO:     Epoch: 15
2022-12-31 08:04:12,807 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4496916194756826, 'Total loss': 0.4496916194756826} | train loss {'Reaction outcome loss': 0.22314471037100084, 'Total loss': 0.22314471037100084}
2022-12-31 08:04:12,808 INFO:     Found new best model at epoch 15
2022-12-31 08:04:12,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:12,809 INFO:     Epoch: 16
2022-12-31 08:04:14,474 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4876882870992025, 'Total loss': 0.4876882870992025} | train loss {'Reaction outcome loss': 0.2110448930677418, 'Total loss': 0.2110448930677418}
2022-12-31 08:04:14,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:14,474 INFO:     Epoch: 17
2022-12-31 08:04:16,139 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46619038581848143, 'Total loss': 0.46619038581848143} | train loss {'Reaction outcome loss': 0.20727231381191075, 'Total loss': 0.20727231381191075}
2022-12-31 08:04:16,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:16,139 INFO:     Epoch: 18
2022-12-31 08:04:17,770 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48758827745914457, 'Total loss': 0.48758827745914457} | train loss {'Reaction outcome loss': 0.19510447001000325, 'Total loss': 0.19510447001000325}
2022-12-31 08:04:17,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:17,771 INFO:     Epoch: 19
2022-12-31 08:04:19,399 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4795862078666687, 'Total loss': 0.4795862078666687} | train loss {'Reaction outcome loss': 0.19227844245218928, 'Total loss': 0.19227844245218928}
2022-12-31 08:04:19,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:19,400 INFO:     Epoch: 20
2022-12-31 08:04:21,022 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4381664882103602, 'Total loss': 0.4381664882103602} | train loss {'Reaction outcome loss': 0.18889574779018733, 'Total loss': 0.18889574779018733}
2022-12-31 08:04:21,022 INFO:     Found new best model at epoch 20
2022-12-31 08:04:21,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:21,023 INFO:     Epoch: 21
2022-12-31 08:04:22,647 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4585470825433731, 'Total loss': 0.4585470825433731} | train loss {'Reaction outcome loss': 0.18055092320170277, 'Total loss': 0.18055092320170277}
2022-12-31 08:04:22,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:22,647 INFO:     Epoch: 22
2022-12-31 08:04:24,272 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4575790633757909, 'Total loss': 0.4575790633757909} | train loss {'Reaction outcome loss': 0.1788752413881214, 'Total loss': 0.1788752413881214}
2022-12-31 08:04:24,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:24,273 INFO:     Epoch: 23
2022-12-31 08:04:25,891 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4455287307500839, 'Total loss': 0.4455287307500839} | train loss {'Reaction outcome loss': 0.1789713202216671, 'Total loss': 0.1789713202216671}
2022-12-31 08:04:25,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:25,892 INFO:     Epoch: 24
2022-12-31 08:04:27,510 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5114242374897003, 'Total loss': 0.5114242374897003} | train loss {'Reaction outcome loss': 0.1742277957610381, 'Total loss': 0.1742277957610381}
2022-12-31 08:04:27,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:27,510 INFO:     Epoch: 25
2022-12-31 08:04:29,171 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43821800748507184, 'Total loss': 0.43821800748507184} | train loss {'Reaction outcome loss': 0.1697219162289411, 'Total loss': 0.1697219162289411}
2022-12-31 08:04:29,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:29,172 INFO:     Epoch: 26
2022-12-31 08:04:30,820 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4398167317112287, 'Total loss': 0.4398167317112287} | train loss {'Reaction outcome loss': 0.1636689930379836, 'Total loss': 0.1636689930379836}
2022-12-31 08:04:30,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:30,820 INFO:     Epoch: 27
2022-12-31 08:04:32,483 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4655581076939901, 'Total loss': 0.4655581076939901} | train loss {'Reaction outcome loss': 0.1601281932553452, 'Total loss': 0.1601281932553452}
2022-12-31 08:04:32,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:32,483 INFO:     Epoch: 28
2022-12-31 08:04:34,145 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4498467514912287, 'Total loss': 0.4498467514912287} | train loss {'Reaction outcome loss': 0.1600951867994677, 'Total loss': 0.1600951867994677}
2022-12-31 08:04:34,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:34,145 INFO:     Epoch: 29
2022-12-31 08:04:35,775 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45182320872942605, 'Total loss': 0.45182320872942605} | train loss {'Reaction outcome loss': 0.15889354190983504, 'Total loss': 0.15889354190983504}
2022-12-31 08:04:35,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:35,775 INFO:     Epoch: 30
2022-12-31 08:04:37,388 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4652373790740967, 'Total loss': 0.4652373790740967} | train loss {'Reaction outcome loss': 0.15585755631563833, 'Total loss': 0.15585755631563833}
2022-12-31 08:04:37,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:37,388 INFO:     Epoch: 31
2022-12-31 08:04:39,002 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4373090902964274, 'Total loss': 0.4373090902964274} | train loss {'Reaction outcome loss': 0.15340632066285043, 'Total loss': 0.15340632066285043}
2022-12-31 08:04:39,002 INFO:     Found new best model at epoch 31
2022-12-31 08:04:39,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:39,003 INFO:     Epoch: 32
2022-12-31 08:04:40,627 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4342219352722168, 'Total loss': 0.4342219352722168} | train loss {'Reaction outcome loss': 0.15454869285104392, 'Total loss': 0.15454869285104392}
2022-12-31 08:04:40,627 INFO:     Found new best model at epoch 32
2022-12-31 08:04:40,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:40,628 INFO:     Epoch: 33
2022-12-31 08:04:42,252 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4520512521266937, 'Total loss': 0.4520512521266937} | train loss {'Reaction outcome loss': 0.1510390808697844, 'Total loss': 0.1510390808697844}
2022-12-31 08:04:42,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:42,253 INFO:     Epoch: 34
2022-12-31 08:04:43,876 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4614359815915426, 'Total loss': 0.4614359815915426} | train loss {'Reaction outcome loss': 0.14775662233823558, 'Total loss': 0.14775662233823558}
2022-12-31 08:04:43,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:43,877 INFO:     Epoch: 35
2022-12-31 08:04:45,522 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45727019334832825, 'Total loss': 0.45727019334832825} | train loss {'Reaction outcome loss': 0.147352633490379, 'Total loss': 0.147352633490379}
2022-12-31 08:04:45,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:45,523 INFO:     Epoch: 36
2022-12-31 08:04:47,144 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46413839956124625, 'Total loss': 0.46413839956124625} | train loss {'Reaction outcome loss': 0.14672136347146897, 'Total loss': 0.14672136347146897}
2022-12-31 08:04:47,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:47,144 INFO:     Epoch: 37
2022-12-31 08:04:48,774 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4776626884937286, 'Total loss': 0.4776626884937286} | train loss {'Reaction outcome loss': 0.14304751651597788, 'Total loss': 0.14304751651597788}
2022-12-31 08:04:48,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:48,775 INFO:     Epoch: 38
2022-12-31 08:04:50,401 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.429065332810084, 'Total loss': 0.429065332810084} | train loss {'Reaction outcome loss': 0.14062859647421408, 'Total loss': 0.14062859647421408}
2022-12-31 08:04:50,401 INFO:     Found new best model at epoch 38
2022-12-31 08:04:50,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:50,402 INFO:     Epoch: 39
2022-12-31 08:04:52,024 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45884645481904346, 'Total loss': 0.45884645481904346} | train loss {'Reaction outcome loss': 0.1487635461089667, 'Total loss': 0.1487635461089667}
2022-12-31 08:04:52,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:52,024 INFO:     Epoch: 40
2022-12-31 08:04:53,655 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4369930903116862, 'Total loss': 0.4369930903116862} | train loss {'Reaction outcome loss': 0.13859588954854163, 'Total loss': 0.13859588954854163}
2022-12-31 08:04:53,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:53,656 INFO:     Epoch: 41
2022-12-31 08:04:55,280 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45830244819323224, 'Total loss': 0.45830244819323224} | train loss {'Reaction outcome loss': 0.1365487486532995, 'Total loss': 0.1365487486532995}
2022-12-31 08:04:55,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:55,280 INFO:     Epoch: 42
2022-12-31 08:04:56,929 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47026695013046266, 'Total loss': 0.47026695013046266} | train loss {'Reaction outcome loss': 0.1372486970607154, 'Total loss': 0.1372486970607154}
2022-12-31 08:04:56,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:56,929 INFO:     Epoch: 43
2022-12-31 08:04:58,594 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45309859613577524, 'Total loss': 0.45309859613577524} | train loss {'Reaction outcome loss': 0.13271533693625606, 'Total loss': 0.13271533693625606}
2022-12-31 08:04:58,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:04:58,594 INFO:     Epoch: 44
2022-12-31 08:05:00,211 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4917499959468842, 'Total loss': 0.4917499959468842} | train loss {'Reaction outcome loss': 0.13918882599640367, 'Total loss': 0.13918882599640367}
2022-12-31 08:05:00,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:00,211 INFO:     Epoch: 45
2022-12-31 08:05:01,873 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4633451799551646, 'Total loss': 0.4633451799551646} | train loss {'Reaction outcome loss': 0.14157424507277977, 'Total loss': 0.14157424507277977}
2022-12-31 08:05:01,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:01,874 INFO:     Epoch: 46
2022-12-31 08:05:03,492 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43987398346265155, 'Total loss': 0.43987398346265155} | train loss {'Reaction outcome loss': 0.12836339705677677, 'Total loss': 0.12836339705677677}
2022-12-31 08:05:03,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:03,493 INFO:     Epoch: 47
2022-12-31 08:05:05,155 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4707537869612376, 'Total loss': 0.4707537869612376} | train loss {'Reaction outcome loss': 0.12880207600355262, 'Total loss': 0.12880207600355262}
2022-12-31 08:05:05,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:05,155 INFO:     Epoch: 48
2022-12-31 08:05:06,787 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45006521642208097, 'Total loss': 0.45006521642208097} | train loss {'Reaction outcome loss': 0.12749568323593796, 'Total loss': 0.12749568323593796}
2022-12-31 08:05:06,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:06,788 INFO:     Epoch: 49
2022-12-31 08:05:08,450 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48857721090316775, 'Total loss': 0.48857721090316775} | train loss {'Reaction outcome loss': 0.129733936181119, 'Total loss': 0.129733936181119}
2022-12-31 08:05:08,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:08,450 INFO:     Epoch: 50
2022-12-31 08:05:10,112 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4172563632329305, 'Total loss': 0.4172563632329305} | train loss {'Reaction outcome loss': 0.13028981840635306, 'Total loss': 0.13028981840635306}
2022-12-31 08:05:10,112 INFO:     Found new best model at epoch 50
2022-12-31 08:05:10,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:10,113 INFO:     Epoch: 51
2022-12-31 08:05:11,733 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4519197642803192, 'Total loss': 0.4519197642803192} | train loss {'Reaction outcome loss': 0.12477041256236102, 'Total loss': 0.12477041256236102}
2022-12-31 08:05:11,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:11,733 INFO:     Epoch: 52
2022-12-31 08:05:13,394 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48585874438285825, 'Total loss': 0.48585874438285825} | train loss {'Reaction outcome loss': 0.12814480220523378, 'Total loss': 0.12814480220523378}
2022-12-31 08:05:13,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:13,394 INFO:     Epoch: 53
2022-12-31 08:05:15,055 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48397932449976605, 'Total loss': 0.48397932449976605} | train loss {'Reaction outcome loss': 0.12198429411000689, 'Total loss': 0.12198429411000689}
2022-12-31 08:05:15,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:15,055 INFO:     Epoch: 54
2022-12-31 08:05:16,665 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4329553797841072, 'Total loss': 0.4329553797841072} | train loss {'Reaction outcome loss': 0.12453664411889055, 'Total loss': 0.12453664411889055}
2022-12-31 08:05:16,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:16,665 INFO:     Epoch: 55
2022-12-31 08:05:18,326 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45841961205005644, 'Total loss': 0.45841961205005644} | train loss {'Reaction outcome loss': 0.12435807146138741, 'Total loss': 0.12435807146138741}
2022-12-31 08:05:18,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:18,328 INFO:     Epoch: 56
2022-12-31 08:05:19,944 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4647593587636948, 'Total loss': 0.4647593587636948} | train loss {'Reaction outcome loss': 0.12815667101892977, 'Total loss': 0.12815667101892977}
2022-12-31 08:05:19,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:19,945 INFO:     Epoch: 57
2022-12-31 08:05:21,576 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4987051566441854, 'Total loss': 0.4987051566441854} | train loss {'Reaction outcome loss': 0.1208986110177516, 'Total loss': 0.1208986110177516}
2022-12-31 08:05:21,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:21,576 INFO:     Epoch: 58
2022-12-31 08:05:23,204 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47587315837542216, 'Total loss': 0.47587315837542216} | train loss {'Reaction outcome loss': 0.12382077459588417, 'Total loss': 0.12382077459588417}
2022-12-31 08:05:23,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:23,204 INFO:     Epoch: 59
2022-12-31 08:05:24,820 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45713288088639575, 'Total loss': 0.45713288088639575} | train loss {'Reaction outcome loss': 0.12054992091430324, 'Total loss': 0.12054992091430324}
2022-12-31 08:05:24,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:24,821 INFO:     Epoch: 60
2022-12-31 08:05:26,448 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4661477982997894, 'Total loss': 0.4661477982997894} | train loss {'Reaction outcome loss': 0.119370551786984, 'Total loss': 0.119370551786984}
2022-12-31 08:05:26,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:26,448 INFO:     Epoch: 61
2022-12-31 08:05:28,076 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46123939951260884, 'Total loss': 0.46123939951260884} | train loss {'Reaction outcome loss': 0.12381498135800939, 'Total loss': 0.12381498135800939}
2022-12-31 08:05:28,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:28,076 INFO:     Epoch: 62
2022-12-31 08:05:29,701 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4644342998663584, 'Total loss': 0.4644342998663584} | train loss {'Reaction outcome loss': 0.11791588223981755, 'Total loss': 0.11791588223981755}
2022-12-31 08:05:29,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:29,702 INFO:     Epoch: 63
2022-12-31 08:05:31,321 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4618158201376597, 'Total loss': 0.4618158201376597} | train loss {'Reaction outcome loss': 0.11517893071059303, 'Total loss': 0.11517893071059303}
2022-12-31 08:05:31,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:31,322 INFO:     Epoch: 64
2022-12-31 08:05:32,949 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4765835444132487, 'Total loss': 0.4765835444132487} | train loss {'Reaction outcome loss': 0.11714962349387993, 'Total loss': 0.11714962349387993}
2022-12-31 08:05:32,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:32,950 INFO:     Epoch: 65
2022-12-31 08:05:34,568 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4815474679072698, 'Total loss': 0.4815474679072698} | train loss {'Reaction outcome loss': 0.12039193310347468, 'Total loss': 0.12039193310347468}
2022-12-31 08:05:34,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:34,569 INFO:     Epoch: 66
2022-12-31 08:05:36,187 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4555481692155202, 'Total loss': 0.4555481692155202} | train loss {'Reaction outcome loss': 0.11359281142274309, 'Total loss': 0.11359281142274309}
2022-12-31 08:05:36,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:36,187 INFO:     Epoch: 67
2022-12-31 08:05:37,807 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46153868238131207, 'Total loss': 0.46153868238131207} | train loss {'Reaction outcome loss': 0.1143608709824258, 'Total loss': 0.1143608709824258}
2022-12-31 08:05:37,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:37,808 INFO:     Epoch: 68
2022-12-31 08:05:39,423 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4351062836746375, 'Total loss': 0.4351062836746375} | train loss {'Reaction outcome loss': 0.11404509973679365, 'Total loss': 0.11404509973679365}
2022-12-31 08:05:39,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:39,423 INFO:     Epoch: 69
2022-12-31 08:05:41,050 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48030519982179004, 'Total loss': 0.48030519982179004} | train loss {'Reaction outcome loss': 0.11155754539683677, 'Total loss': 0.11155754539683677}
2022-12-31 08:05:41,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:41,050 INFO:     Epoch: 70
2022-12-31 08:05:42,671 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.439405416448911, 'Total loss': 0.439405416448911} | train loss {'Reaction outcome loss': 0.10933455479270365, 'Total loss': 0.10933455479270365}
2022-12-31 08:05:42,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:42,671 INFO:     Epoch: 71
2022-12-31 08:05:44,300 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4482652465502421, 'Total loss': 0.4482652465502421} | train loss {'Reaction outcome loss': 0.11738808725336983, 'Total loss': 0.11738808725336983}
2022-12-31 08:05:44,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:44,300 INFO:     Epoch: 72
2022-12-31 08:05:45,930 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4678784251213074, 'Total loss': 0.4678784251213074} | train loss {'Reaction outcome loss': 0.11415606076015915, 'Total loss': 0.11415606076015915}
2022-12-31 08:05:45,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:45,930 INFO:     Epoch: 73
2022-12-31 08:05:47,564 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4619470010201136, 'Total loss': 0.4619470010201136} | train loss {'Reaction outcome loss': 0.10928961474775756, 'Total loss': 0.10928961474775756}
2022-12-31 08:05:47,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:47,564 INFO:     Epoch: 74
2022-12-31 08:05:49,187 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5051864127318064, 'Total loss': 0.5051864127318064} | train loss {'Reaction outcome loss': 0.11121742409428091, 'Total loss': 0.11121742409428091}
2022-12-31 08:05:49,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:49,187 INFO:     Epoch: 75
2022-12-31 08:05:50,819 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4653960098822912, 'Total loss': 0.4653960098822912} | train loss {'Reaction outcome loss': 0.10909810228701605, 'Total loss': 0.10909810228701605}
2022-12-31 08:05:50,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:50,819 INFO:     Epoch: 76
2022-12-31 08:05:52,441 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46689214011033375, 'Total loss': 0.46689214011033375} | train loss {'Reaction outcome loss': 0.10716193464031676, 'Total loss': 0.10716193464031676}
2022-12-31 08:05:52,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:52,441 INFO:     Epoch: 77
2022-12-31 08:05:54,073 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46569038530190787, 'Total loss': 0.46569038530190787} | train loss {'Reaction outcome loss': 0.10955865802516464, 'Total loss': 0.10955865802516464}
2022-12-31 08:05:54,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:54,074 INFO:     Epoch: 78
2022-12-31 08:05:55,702 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5051588594913483, 'Total loss': 0.5051588594913483} | train loss {'Reaction outcome loss': 0.11568059603614265, 'Total loss': 0.11568059603614265}
2022-12-31 08:05:55,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:55,702 INFO:     Epoch: 79
2022-12-31 08:05:57,349 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4659978499015172, 'Total loss': 0.4659978499015172} | train loss {'Reaction outcome loss': 0.11057677004280042, 'Total loss': 0.11057677004280042}
2022-12-31 08:05:57,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:57,349 INFO:     Epoch: 80
2022-12-31 08:05:58,981 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45602418382962545, 'Total loss': 0.45602418382962545} | train loss {'Reaction outcome loss': 0.10885153156949315, 'Total loss': 0.10885153156949315}
2022-12-31 08:05:58,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:05:58,982 INFO:     Epoch: 81
2022-12-31 08:06:00,610 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4867100089788437, 'Total loss': 0.4867100089788437} | train loss {'Reaction outcome loss': 0.10748710600845685, 'Total loss': 0.10748710600845685}
2022-12-31 08:06:00,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:00,610 INFO:     Epoch: 82
2022-12-31 08:06:02,233 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48675210972627003, 'Total loss': 0.48675210972627003} | train loss {'Reaction outcome loss': 0.10345127586971511, 'Total loss': 0.10345127586971511}
2022-12-31 08:06:02,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:02,233 INFO:     Epoch: 83
2022-12-31 08:06:03,864 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48651652137438456, 'Total loss': 0.48651652137438456} | train loss {'Reaction outcome loss': 0.10508620283107503, 'Total loss': 0.10508620283107503}
2022-12-31 08:06:03,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:03,864 INFO:     Epoch: 84
2022-12-31 08:06:05,496 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48402998050053914, 'Total loss': 0.48402998050053914} | train loss {'Reaction outcome loss': 0.11157800559079117, 'Total loss': 0.11157800559079117}
2022-12-31 08:06:05,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:05,496 INFO:     Epoch: 85
2022-12-31 08:06:07,135 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.510020183523496, 'Total loss': 0.510020183523496} | train loss {'Reaction outcome loss': 0.11468785334980804, 'Total loss': 0.11468785334980804}
2022-12-31 08:06:07,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:07,136 INFO:     Epoch: 86
2022-12-31 08:06:08,753 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4442956656217575, 'Total loss': 0.4442956656217575} | train loss {'Reaction outcome loss': 0.10609154865370078, 'Total loss': 0.10609154865370078}
2022-12-31 08:06:08,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:08,753 INFO:     Epoch: 87
2022-12-31 08:06:10,389 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4542851517597834, 'Total loss': 0.4542851517597834} | train loss {'Reaction outcome loss': 0.10349984776500303, 'Total loss': 0.10349984776500303}
2022-12-31 08:06:10,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:10,390 INFO:     Epoch: 88
2022-12-31 08:06:12,051 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4768114517132441, 'Total loss': 0.4768114517132441} | train loss {'Reaction outcome loss': 0.1031687980862773, 'Total loss': 0.1031687980862773}
2022-12-31 08:06:12,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:12,051 INFO:     Epoch: 89
2022-12-31 08:06:13,714 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4894945926964283, 'Total loss': 0.4894945926964283} | train loss {'Reaction outcome loss': 0.10933220832168075, 'Total loss': 0.10933220832168075}
2022-12-31 08:06:13,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:13,715 INFO:     Epoch: 90
2022-12-31 08:06:15,325 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4644147674242655, 'Total loss': 0.4644147674242655} | train loss {'Reaction outcome loss': 0.11150854429655263, 'Total loss': 0.11150854429655263}
2022-12-31 08:06:15,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:15,325 INFO:     Epoch: 91
2022-12-31 08:06:16,980 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4989312211672465, 'Total loss': 0.4989312211672465} | train loss {'Reaction outcome loss': 0.11548847338986967, 'Total loss': 0.11548847338986967}
2022-12-31 08:06:16,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:16,980 INFO:     Epoch: 92
2022-12-31 08:06:18,643 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4878071337938309, 'Total loss': 0.4878071337938309} | train loss {'Reaction outcome loss': 0.1066020302722514, 'Total loss': 0.1066020302722514}
2022-12-31 08:06:18,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:18,644 INFO:     Epoch: 93
2022-12-31 08:06:20,252 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46004603803157806, 'Total loss': 0.46004603803157806} | train loss {'Reaction outcome loss': 0.10332269815908281, 'Total loss': 0.10332269815908281}
2022-12-31 08:06:20,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:20,253 INFO:     Epoch: 94
2022-12-31 08:06:21,916 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47127063671747843, 'Total loss': 0.47127063671747843} | train loss {'Reaction outcome loss': 0.10202833161895176, 'Total loss': 0.10202833161895176}
2022-12-31 08:06:21,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:21,916 INFO:     Epoch: 95
2022-12-31 08:06:23,579 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4490528583526611, 'Total loss': 0.4490528583526611} | train loss {'Reaction outcome loss': 0.10556089316420528, 'Total loss': 0.10556089316420528}
2022-12-31 08:06:23,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:23,579 INFO:     Epoch: 96
2022-12-31 08:06:25,219 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4746376643578211, 'Total loss': 0.4746376643578211} | train loss {'Reaction outcome loss': 0.10287509026323054, 'Total loss': 0.10287509026323054}
2022-12-31 08:06:25,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:25,219 INFO:     Epoch: 97
2022-12-31 08:06:26,851 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45189654727776846, 'Total loss': 0.45189654727776846} | train loss {'Reaction outcome loss': 0.1018921842462104, 'Total loss': 0.1018921842462104}
2022-12-31 08:06:26,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:26,852 INFO:     Epoch: 98
2022-12-31 08:06:28,475 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5064456363519033, 'Total loss': 0.5064456363519033} | train loss {'Reaction outcome loss': 0.10129764409098045, 'Total loss': 0.10129764409098045}
2022-12-31 08:06:28,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:28,476 INFO:     Epoch: 99
2022-12-31 08:06:30,104 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4771393472949664, 'Total loss': 0.4771393472949664} | train loss {'Reaction outcome loss': 0.10304687756423306, 'Total loss': 0.10304687756423306}
2022-12-31 08:06:30,106 INFO:     Best model found after epoch 51 of 100.
2022-12-31 08:06:30,106 INFO:   Done with stage: TRAINING
2022-12-31 08:06:30,106 INFO:   Starting stage: EVALUATION
2022-12-31 08:06:30,239 INFO:   Done with stage: EVALUATION
2022-12-31 08:06:30,240 INFO:   Leaving out SEQ value Fold_9
2022-12-31 08:06:30,252 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 08:06:30,252 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:06:30,894 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:06:30,894 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:06:30,961 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:06:30,961 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:06:30,961 INFO:     No hyperparam tuning for this model
2022-12-31 08:06:30,961 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:06:30,961 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:06:30,962 INFO:     None feature selector for col prot
2022-12-31 08:06:30,962 INFO:     None feature selector for col prot
2022-12-31 08:06:30,962 INFO:     None feature selector for col prot
2022-12-31 08:06:30,963 INFO:     None feature selector for col chem
2022-12-31 08:06:30,963 INFO:     None feature selector for col chem
2022-12-31 08:06:30,963 INFO:     None feature selector for col chem
2022-12-31 08:06:30,963 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:06:30,963 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:06:30,965 INFO:     Number of params in model 224011
2022-12-31 08:06:30,968 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:06:30,968 INFO:   Starting stage: TRAINING
2022-12-31 08:06:31,015 INFO:     Val loss before train {'Reaction outcome loss': 0.9951428771018982, 'Total loss': 0.9951428771018982}
2022-12-31 08:06:31,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:31,016 INFO:     Epoch: 0
2022-12-31 08:06:32,674 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5588019649187724, 'Total loss': 0.5588019649187724} | train loss {'Reaction outcome loss': 0.7926141442258613, 'Total loss': 0.7926141442258613}
2022-12-31 08:06:32,674 INFO:     Found new best model at epoch 0
2022-12-31 08:06:32,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:32,675 INFO:     Epoch: 1
2022-12-31 08:06:34,297 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47012790441513064, 'Total loss': 0.47012790441513064} | train loss {'Reaction outcome loss': 0.5314967952946208, 'Total loss': 0.5314967952946208}
2022-12-31 08:06:34,298 INFO:     Found new best model at epoch 1
2022-12-31 08:06:34,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:34,299 INFO:     Epoch: 2
2022-12-31 08:06:35,930 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4136889070272446, 'Total loss': 0.4136889070272446} | train loss {'Reaction outcome loss': 0.4591354202324958, 'Total loss': 0.4591354202324958}
2022-12-31 08:06:35,931 INFO:     Found new best model at epoch 2
2022-12-31 08:06:35,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:35,932 INFO:     Epoch: 3
2022-12-31 08:06:37,553 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.40020702679951986, 'Total loss': 0.40020702679951986} | train loss {'Reaction outcome loss': 0.4200848498368177, 'Total loss': 0.4200848498368177}
2022-12-31 08:06:37,554 INFO:     Found new best model at epoch 3
2022-12-31 08:06:37,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:37,555 INFO:     Epoch: 4
2022-12-31 08:06:39,182 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3858794867992401, 'Total loss': 0.3858794867992401} | train loss {'Reaction outcome loss': 0.39149049453909107, 'Total loss': 0.39149049453909107}
2022-12-31 08:06:39,182 INFO:     Found new best model at epoch 4
2022-12-31 08:06:39,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:39,183 INFO:     Epoch: 5
2022-12-31 08:06:40,828 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3633324866493543, 'Total loss': 0.3633324866493543} | train loss {'Reaction outcome loss': 0.3658151086141436, 'Total loss': 0.3658151086141436}
2022-12-31 08:06:40,828 INFO:     Found new best model at epoch 5
2022-12-31 08:06:40,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:40,829 INFO:     Epoch: 6
2022-12-31 08:06:42,442 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38244051337242124, 'Total loss': 0.38244051337242124} | train loss {'Reaction outcome loss': 0.34407478968923766, 'Total loss': 0.34407478968923766}
2022-12-31 08:06:42,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:42,442 INFO:     Epoch: 7
2022-12-31 08:06:44,090 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3876624842484792, 'Total loss': 0.3876624842484792} | train loss {'Reaction outcome loss': 0.3276731200331478, 'Total loss': 0.3276731200331478}
2022-12-31 08:06:44,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:44,090 INFO:     Epoch: 8
2022-12-31 08:06:45,701 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38040961027145387, 'Total loss': 0.38040961027145387} | train loss {'Reaction outcome loss': 0.3090522585491957, 'Total loss': 0.3090522585491957}
2022-12-31 08:06:45,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:45,702 INFO:     Epoch: 9
2022-12-31 08:06:47,335 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37423137029012044, 'Total loss': 0.37423137029012044} | train loss {'Reaction outcome loss': 0.29861612294832635, 'Total loss': 0.29861612294832635}
2022-12-31 08:06:47,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:47,335 INFO:     Epoch: 10
2022-12-31 08:06:48,968 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3864678591489792, 'Total loss': 0.3864678591489792} | train loss {'Reaction outcome loss': 0.28469113767673465, 'Total loss': 0.28469113767673465}
2022-12-31 08:06:48,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:48,968 INFO:     Epoch: 11
2022-12-31 08:06:50,601 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36879467566808066, 'Total loss': 0.36879467566808066} | train loss {'Reaction outcome loss': 0.27234131915010157, 'Total loss': 0.27234131915010157}
2022-12-31 08:06:50,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:50,602 INFO:     Epoch: 12
2022-12-31 08:06:52,230 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3752931217352549, 'Total loss': 0.3752931217352549} | train loss {'Reaction outcome loss': 0.2665229750716168, 'Total loss': 0.2665229750716168}
2022-12-31 08:06:52,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:52,230 INFO:     Epoch: 13
2022-12-31 08:06:53,852 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3711591879526774, 'Total loss': 0.3711591879526774} | train loss {'Reaction outcome loss': 0.2635534084224871, 'Total loss': 0.2635534084224871}
2022-12-31 08:06:53,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:53,852 INFO:     Epoch: 14
2022-12-31 08:06:55,509 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39774982233842215, 'Total loss': 0.39774982233842215} | train loss {'Reaction outcome loss': 0.24733451207968124, 'Total loss': 0.24733451207968124}
2022-12-31 08:06:55,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:55,509 INFO:     Epoch: 15
2022-12-31 08:06:57,129 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4191540499528249, 'Total loss': 0.4191540499528249} | train loss {'Reaction outcome loss': 0.2416789995884334, 'Total loss': 0.2416789995884334}
2022-12-31 08:06:57,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:57,129 INFO:     Epoch: 16
2022-12-31 08:06:58,756 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35280636698007584, 'Total loss': 0.35280636698007584} | train loss {'Reaction outcome loss': 0.23897926749297135, 'Total loss': 0.23897926749297135}
2022-12-31 08:06:58,756 INFO:     Found new best model at epoch 16
2022-12-31 08:06:58,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:06:58,757 INFO:     Epoch: 17
2022-12-31 08:07:00,379 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3818073054154714, 'Total loss': 0.3818073054154714} | train loss {'Reaction outcome loss': 0.22710385459029805, 'Total loss': 0.22710385459029805}
2022-12-31 08:07:00,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:00,380 INFO:     Epoch: 18
2022-12-31 08:07:02,000 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3741652637720108, 'Total loss': 0.3741652637720108} | train loss {'Reaction outcome loss': 0.22574335606317408, 'Total loss': 0.22574335606317408}
2022-12-31 08:07:02,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:02,000 INFO:     Epoch: 19
2022-12-31 08:07:03,631 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40341624021530154, 'Total loss': 0.40341624021530154} | train loss {'Reaction outcome loss': 0.2175515721268628, 'Total loss': 0.2175515721268628}
2022-12-31 08:07:03,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:03,631 INFO:     Epoch: 20
2022-12-31 08:07:05,263 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36986557046572366, 'Total loss': 0.36986557046572366} | train loss {'Reaction outcome loss': 0.21166503830961342, 'Total loss': 0.21166503830961342}
2022-12-31 08:07:05,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:05,264 INFO:     Epoch: 21
2022-12-31 08:07:06,890 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39933466811974844, 'Total loss': 0.39933466811974844} | train loss {'Reaction outcome loss': 0.21060903089633887, 'Total loss': 0.21060903089633887}
2022-12-31 08:07:06,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:06,890 INFO:     Epoch: 22
2022-12-31 08:07:08,553 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38906680047512054, 'Total loss': 0.38906680047512054} | train loss {'Reaction outcome loss': 0.21558477236365012, 'Total loss': 0.21558477236365012}
2022-12-31 08:07:08,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:08,554 INFO:     Epoch: 23
2022-12-31 08:07:10,204 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.417876190940539, 'Total loss': 0.417876190940539} | train loss {'Reaction outcome loss': 0.2014293783189108, 'Total loss': 0.2014293783189108}
2022-12-31 08:07:10,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:10,204 INFO:     Epoch: 24
2022-12-31 08:07:11,867 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39528058071931205, 'Total loss': 0.39528058071931205} | train loss {'Reaction outcome loss': 0.1945923917953843, 'Total loss': 0.1945923917953843}
2022-12-31 08:07:11,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:11,868 INFO:     Epoch: 25
2022-12-31 08:07:13,489 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3799674098690351, 'Total loss': 0.3799674098690351} | train loss {'Reaction outcome loss': 0.19148982187439484, 'Total loss': 0.19148982187439484}
2022-12-31 08:07:13,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:13,489 INFO:     Epoch: 26
2022-12-31 08:07:15,105 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4041994959115982, 'Total loss': 0.4041994959115982} | train loss {'Reaction outcome loss': 0.18503828692853963, 'Total loss': 0.18503828692853963}
2022-12-31 08:07:15,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:15,106 INFO:     Epoch: 27
2022-12-31 08:07:16,768 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3905939651032289, 'Total loss': 0.3905939651032289} | train loss {'Reaction outcome loss': 0.18861198974453777, 'Total loss': 0.18861198974453777}
2022-12-31 08:07:16,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:16,768 INFO:     Epoch: 28
2022-12-31 08:07:18,430 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3758913983901342, 'Total loss': 0.3758913983901342} | train loss {'Reaction outcome loss': 0.1795258250988453, 'Total loss': 0.1795258250988453}
2022-12-31 08:07:18,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:18,431 INFO:     Epoch: 29
2022-12-31 08:07:20,067 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3994304408629735, 'Total loss': 0.3994304408629735} | train loss {'Reaction outcome loss': 0.18327141247109335, 'Total loss': 0.18327141247109335}
2022-12-31 08:07:20,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:20,067 INFO:     Epoch: 30
2022-12-31 08:07:21,700 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37870135009288786, 'Total loss': 0.37870135009288786} | train loss {'Reaction outcome loss': 0.1797083574819608, 'Total loss': 0.1797083574819608}
2022-12-31 08:07:21,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:21,701 INFO:     Epoch: 31
2022-12-31 08:07:23,326 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3950321763753891, 'Total loss': 0.3950321763753891} | train loss {'Reaction outcome loss': 0.17255413564617955, 'Total loss': 0.17255413564617955}
2022-12-31 08:07:23,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:23,326 INFO:     Epoch: 32
2022-12-31 08:07:24,958 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3970836207270622, 'Total loss': 0.3970836207270622} | train loss {'Reaction outcome loss': 0.17534850383589914, 'Total loss': 0.17534850383589914}
2022-12-31 08:07:24,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:24,959 INFO:     Epoch: 33
2022-12-31 08:07:26,592 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3738004406293233, 'Total loss': 0.3738004406293233} | train loss {'Reaction outcome loss': 0.17023094833627733, 'Total loss': 0.17023094833627733}
2022-12-31 08:07:26,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:26,592 INFO:     Epoch: 34
2022-12-31 08:07:28,221 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3781064917643865, 'Total loss': 0.3781064917643865} | train loss {'Reaction outcome loss': 0.16844492139446537, 'Total loss': 0.16844492139446537}
2022-12-31 08:07:28,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:28,221 INFO:     Epoch: 35
2022-12-31 08:07:29,861 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3865389088789622, 'Total loss': 0.3865389088789622} | train loss {'Reaction outcome loss': 0.16335301605041436, 'Total loss': 0.16335301605041436}
2022-12-31 08:07:29,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:29,861 INFO:     Epoch: 36
2022-12-31 08:07:31,486 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41176999111970264, 'Total loss': 0.41176999111970264} | train loss {'Reaction outcome loss': 0.16030117540546032, 'Total loss': 0.16030117540546032}
2022-12-31 08:07:31,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:31,486 INFO:     Epoch: 37
2022-12-31 08:07:33,108 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3813405841588974, 'Total loss': 0.3813405841588974} | train loss {'Reaction outcome loss': 0.18156622692375726, 'Total loss': 0.18156622692375726}
2022-12-31 08:07:33,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:33,108 INFO:     Epoch: 38
2022-12-31 08:07:34,725 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4236887554327647, 'Total loss': 0.4236887554327647} | train loss {'Reaction outcome loss': 0.16888070177452208, 'Total loss': 0.16888070177452208}
2022-12-31 08:07:34,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:34,725 INFO:     Epoch: 39
2022-12-31 08:07:36,343 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4081157217423121, 'Total loss': 0.4081157217423121} | train loss {'Reaction outcome loss': 0.15969717859354166, 'Total loss': 0.15969717859354166}
2022-12-31 08:07:36,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:36,344 INFO:     Epoch: 40
2022-12-31 08:07:37,956 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4165463368097941, 'Total loss': 0.4165463368097941} | train loss {'Reaction outcome loss': 0.1545586588605226, 'Total loss': 0.1545586588605226}
2022-12-31 08:07:37,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:37,956 INFO:     Epoch: 41
2022-12-31 08:07:39,619 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4540146122376124, 'Total loss': 0.4540146122376124} | train loss {'Reaction outcome loss': 0.15253771194071253, 'Total loss': 0.15253771194071253}
2022-12-31 08:07:39,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:39,619 INFO:     Epoch: 42
2022-12-31 08:07:41,274 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3893478562434514, 'Total loss': 0.3893478562434514} | train loss {'Reaction outcome loss': 0.15231041385479752, 'Total loss': 0.15231041385479752}
2022-12-31 08:07:41,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:41,274 INFO:     Epoch: 43
2022-12-31 08:07:42,934 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40360434353351593, 'Total loss': 0.40360434353351593} | train loss {'Reaction outcome loss': 0.15916565202675975, 'Total loss': 0.15916565202675975}
2022-12-31 08:07:42,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:42,935 INFO:     Epoch: 44
2022-12-31 08:07:44,552 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39701573302348453, 'Total loss': 0.39701573302348453} | train loss {'Reaction outcome loss': 0.17382491978924666, 'Total loss': 0.17382491978924666}
2022-12-31 08:07:44,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:44,552 INFO:     Epoch: 45
2022-12-31 08:07:46,170 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39630696972211205, 'Total loss': 0.39630696972211205} | train loss {'Reaction outcome loss': 0.17375406412875105, 'Total loss': 0.17375406412875105}
2022-12-31 08:07:46,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:46,170 INFO:     Epoch: 46
2022-12-31 08:07:47,797 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4253533611694972, 'Total loss': 0.4253533611694972} | train loss {'Reaction outcome loss': 0.14968569031106713, 'Total loss': 0.14968569031106713}
2022-12-31 08:07:47,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:47,798 INFO:     Epoch: 47
2022-12-31 08:07:49,430 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4385497352729241, 'Total loss': 0.4385497352729241} | train loss {'Reaction outcome loss': 0.14387577175634564, 'Total loss': 0.14387577175634564}
2022-12-31 08:07:49,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:49,430 INFO:     Epoch: 48
2022-12-31 08:07:51,052 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4028054152925809, 'Total loss': 0.4028054152925809} | train loss {'Reaction outcome loss': 0.14306895926595156, 'Total loss': 0.14306895926595156}
2022-12-31 08:07:51,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:51,052 INFO:     Epoch: 49
2022-12-31 08:07:52,683 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4218580524126689, 'Total loss': 0.4218580524126689} | train loss {'Reaction outcome loss': 0.14022279539705673, 'Total loss': 0.14022279539705673}
2022-12-31 08:07:52,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:52,683 INFO:     Epoch: 50
2022-12-31 08:07:54,313 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43231751869122187, 'Total loss': 0.43231751869122187} | train loss {'Reaction outcome loss': 0.14232055587142342, 'Total loss': 0.14232055587142342}
2022-12-31 08:07:54,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:54,314 INFO:     Epoch: 51
2022-12-31 08:07:55,936 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4024782791733742, 'Total loss': 0.4024782791733742} | train loss {'Reaction outcome loss': 0.1421090484309191, 'Total loss': 0.1421090484309191}
2022-12-31 08:07:55,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:55,937 INFO:     Epoch: 52
2022-12-31 08:07:57,566 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4232542912165324, 'Total loss': 0.4232542912165324} | train loss {'Reaction outcome loss': 0.14294769429794424, 'Total loss': 0.14294769429794424}
2022-12-31 08:07:57,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:57,566 INFO:     Epoch: 53
2022-12-31 08:07:59,189 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43703149557113646, 'Total loss': 0.43703149557113646} | train loss {'Reaction outcome loss': 0.13634356914385073, 'Total loss': 0.13634356914385073}
2022-12-31 08:07:59,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:07:59,189 INFO:     Epoch: 54
2022-12-31 08:08:00,807 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4153865943352381, 'Total loss': 0.4153865943352381} | train loss {'Reaction outcome loss': 0.1397734941323427, 'Total loss': 0.1397734941323427}
2022-12-31 08:08:00,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:00,808 INFO:     Epoch: 55
2022-12-31 08:08:02,432 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41951806644598644, 'Total loss': 0.41951806644598644} | train loss {'Reaction outcome loss': 0.1409392959887054, 'Total loss': 0.1409392959887054}
2022-12-31 08:08:02,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:02,432 INFO:     Epoch: 56
2022-12-31 08:08:04,057 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40712939004103343, 'Total loss': 0.40712939004103343} | train loss {'Reaction outcome loss': 0.13968979631486497, 'Total loss': 0.13968979631486497}
2022-12-31 08:08:04,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:04,057 INFO:     Epoch: 57
2022-12-31 08:08:05,694 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4299237410227458, 'Total loss': 0.4299237410227458} | train loss {'Reaction outcome loss': 0.164065417084519, 'Total loss': 0.164065417084519}
2022-12-31 08:08:05,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:05,694 INFO:     Epoch: 58
2022-12-31 08:08:07,358 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39631639172633487, 'Total loss': 0.39631639172633487} | train loss {'Reaction outcome loss': 0.1457014408133282, 'Total loss': 0.1457014408133282}
2022-12-31 08:08:07,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:07,358 INFO:     Epoch: 59
2022-12-31 08:08:08,998 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40903874635696413, 'Total loss': 0.40903874635696413} | train loss {'Reaction outcome loss': 0.13929905903279322, 'Total loss': 0.13929905903279322}
2022-12-31 08:08:08,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:08,998 INFO:     Epoch: 60
2022-12-31 08:08:10,661 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39350227614243827, 'Total loss': 0.39350227614243827} | train loss {'Reaction outcome loss': 0.14066558574238472, 'Total loss': 0.14066558574238472}
2022-12-31 08:08:10,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:10,661 INFO:     Epoch: 61
2022-12-31 08:08:12,277 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4073538392782211, 'Total loss': 0.4073538392782211} | train loss {'Reaction outcome loss': 0.13790523301661556, 'Total loss': 0.13790523301661556}
2022-12-31 08:08:12,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:12,279 INFO:     Epoch: 62
2022-12-31 08:08:13,894 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4139293670654297, 'Total loss': 0.4139293670654297} | train loss {'Reaction outcome loss': 0.13954073460131505, 'Total loss': 0.13954073460131505}
2022-12-31 08:08:13,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:13,895 INFO:     Epoch: 63
2022-12-31 08:08:15,544 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3920104831457138, 'Total loss': 0.3920104831457138} | train loss {'Reaction outcome loss': 0.133366118181426, 'Total loss': 0.133366118181426}
2022-12-31 08:08:15,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:15,544 INFO:     Epoch: 64
2022-12-31 08:08:17,159 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41878390808900195, 'Total loss': 0.41878390808900195} | train loss {'Reaction outcome loss': 0.13082875610384886, 'Total loss': 0.13082875610384886}
2022-12-31 08:08:17,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:17,159 INFO:     Epoch: 65
2022-12-31 08:08:18,777 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4260774334271749, 'Total loss': 0.4260774334271749} | train loss {'Reaction outcome loss': 0.13291256579428143, 'Total loss': 0.13291256579428143}
2022-12-31 08:08:18,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:18,778 INFO:     Epoch: 66
2022-12-31 08:08:20,392 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41338206430276236, 'Total loss': 0.41338206430276236} | train loss {'Reaction outcome loss': 0.12875496471162373, 'Total loss': 0.12875496471162373}
2022-12-31 08:08:20,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:20,393 INFO:     Epoch: 67
2022-12-31 08:08:22,034 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42388154069582623, 'Total loss': 0.42388154069582623} | train loss {'Reaction outcome loss': 0.13008008923950434, 'Total loss': 0.13008008923950434}
2022-12-31 08:08:22,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:22,034 INFO:     Epoch: 68
2022-12-31 08:08:23,647 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39318870604038236, 'Total loss': 0.39318870604038236} | train loss {'Reaction outcome loss': 0.13695616920080467, 'Total loss': 0.13695616920080467}
2022-12-31 08:08:23,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:23,647 INFO:     Epoch: 69
2022-12-31 08:08:25,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43228992422421775, 'Total loss': 0.43228992422421775} | train loss {'Reaction outcome loss': 0.16063741026648684, 'Total loss': 0.16063741026648684}
2022-12-31 08:08:25,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:25,268 INFO:     Epoch: 70
2022-12-31 08:08:26,884 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41802295843760173, 'Total loss': 0.41802295843760173} | train loss {'Reaction outcome loss': 0.14057533243307052, 'Total loss': 0.14057533243307052}
2022-12-31 08:08:26,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:26,884 INFO:     Epoch: 71
2022-12-31 08:08:28,501 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38147858281930286, 'Total loss': 0.38147858281930286} | train loss {'Reaction outcome loss': 0.12914545005912878, 'Total loss': 0.12914545005912878}
2022-12-31 08:08:28,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:28,501 INFO:     Epoch: 72
2022-12-31 08:08:30,184 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3941000930964947, 'Total loss': 0.3941000930964947} | train loss {'Reaction outcome loss': 0.12649925022054484, 'Total loss': 0.12649925022054484}
2022-12-31 08:08:30,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:30,184 INFO:     Epoch: 73
2022-12-31 08:08:31,799 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40178306500116984, 'Total loss': 0.40178306500116984} | train loss {'Reaction outcome loss': 0.12367903121512559, 'Total loss': 0.12367903121512559}
2022-12-31 08:08:31,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:31,800 INFO:     Epoch: 74
2022-12-31 08:08:33,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3988887757062912, 'Total loss': 0.3988887757062912} | train loss {'Reaction outcome loss': 0.12306591526773274, 'Total loss': 0.12306591526773274}
2022-12-31 08:08:33,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:33,099 INFO:     Epoch: 75
2022-12-31 08:08:34,243 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40922054946422576, 'Total loss': 0.40922054946422576} | train loss {'Reaction outcome loss': 0.12786773432890186, 'Total loss': 0.12786773432890186}
2022-12-31 08:08:34,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:34,243 INFO:     Epoch: 76
2022-12-31 08:08:35,504 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39081913928190865, 'Total loss': 0.39081913928190865} | train loss {'Reaction outcome loss': 0.1257830277781351, 'Total loss': 0.1257830277781351}
2022-12-31 08:08:35,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:35,504 INFO:     Epoch: 77
2022-12-31 08:08:36,625 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40144468247890475, 'Total loss': 0.40144468247890475} | train loss {'Reaction outcome loss': 0.1253460801558306, 'Total loss': 0.1253460801558306}
2022-12-31 08:08:36,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:36,625 INFO:     Epoch: 78
2022-12-31 08:08:38,216 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39889142513275144, 'Total loss': 0.39889142513275144} | train loss {'Reaction outcome loss': 0.1254543871397365, 'Total loss': 0.1254543871397365}
2022-12-31 08:08:38,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:38,217 INFO:     Epoch: 79
2022-12-31 08:08:39,880 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3904179165760676, 'Total loss': 0.3904179165760676} | train loss {'Reaction outcome loss': 0.126733259561529, 'Total loss': 0.126733259561529}
2022-12-31 08:08:39,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:39,880 INFO:     Epoch: 80
2022-12-31 08:08:41,543 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4146551867326101, 'Total loss': 0.4146551867326101} | train loss {'Reaction outcome loss': 0.12750998505108999, 'Total loss': 0.12750998505108999}
2022-12-31 08:08:41,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:41,543 INFO:     Epoch: 81
2022-12-31 08:08:43,161 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3918116648991903, 'Total loss': 0.3918116648991903} | train loss {'Reaction outcome loss': 0.12097801468801175, 'Total loss': 0.12097801468801175}
2022-12-31 08:08:43,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:43,161 INFO:     Epoch: 82
2022-12-31 08:08:44,779 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3799043993155162, 'Total loss': 0.3799043993155162} | train loss {'Reaction outcome loss': 0.13833009824241121, 'Total loss': 0.13833009824241121}
2022-12-31 08:08:44,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:44,780 INFO:     Epoch: 83
2022-12-31 08:08:46,401 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3949309860666593, 'Total loss': 0.3949309860666593} | train loss {'Reaction outcome loss': 0.1212469351749939, 'Total loss': 0.1212469351749939}
2022-12-31 08:08:46,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:46,402 INFO:     Epoch: 84
2022-12-31 08:08:48,026 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.406594650944074, 'Total loss': 0.406594650944074} | train loss {'Reaction outcome loss': 0.1258375646735869, 'Total loss': 0.1258375646735869}
2022-12-31 08:08:48,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:48,027 INFO:     Epoch: 85
2022-12-31 08:08:49,650 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4004020690917969, 'Total loss': 0.4004020690917969} | train loss {'Reaction outcome loss': 0.1244347049163269, 'Total loss': 0.1244347049163269}
2022-12-31 08:08:49,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:49,650 INFO:     Epoch: 86
2022-12-31 08:08:51,276 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4117065111796061, 'Total loss': 0.4117065111796061} | train loss {'Reaction outcome loss': 0.1275385890773538, 'Total loss': 0.1275385890773538}
2022-12-31 08:08:51,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:51,276 INFO:     Epoch: 87
2022-12-31 08:08:52,893 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4391071026523908, 'Total loss': 0.4391071026523908} | train loss {'Reaction outcome loss': 0.12243013961267644, 'Total loss': 0.12243013961267644}
2022-12-31 08:08:52,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:52,894 INFO:     Epoch: 88
2022-12-31 08:08:54,517 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3940941743552685, 'Total loss': 0.3940941743552685} | train loss {'Reaction outcome loss': 0.1229120328625077, 'Total loss': 0.1229120328625077}
2022-12-31 08:08:54,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:54,518 INFO:     Epoch: 89
2022-12-31 08:08:56,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4236846054593722, 'Total loss': 0.4236846054593722} | train loss {'Reaction outcome loss': 0.1226123800025443, 'Total loss': 0.1226123800025443}
2022-12-31 08:08:56,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:56,127 INFO:     Epoch: 90
2022-12-31 08:08:57,791 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3713816891113917, 'Total loss': 0.3713816891113917} | train loss {'Reaction outcome loss': 0.12086059134182063, 'Total loss': 0.12086059134182063}
2022-12-31 08:08:57,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:57,791 INFO:     Epoch: 91
2022-12-31 08:08:59,409 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4104484334588051, 'Total loss': 0.4104484334588051} | train loss {'Reaction outcome loss': 0.11997278321001247, 'Total loss': 0.11997278321001247}
2022-12-31 08:08:59,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:08:59,410 INFO:     Epoch: 92
2022-12-31 08:09:01,022 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40008676846822105, 'Total loss': 0.40008676846822105} | train loss {'Reaction outcome loss': 0.11984057940898693, 'Total loss': 0.11984057940898693}
2022-12-31 08:09:01,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:01,022 INFO:     Epoch: 93
2022-12-31 08:09:02,642 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40277093450228374, 'Total loss': 0.40277093450228374} | train loss {'Reaction outcome loss': 0.11932100039321349, 'Total loss': 0.11932100039321349}
2022-12-31 08:09:02,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:02,642 INFO:     Epoch: 94
2022-12-31 08:09:04,256 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4029377311468124, 'Total loss': 0.4029377311468124} | train loss {'Reaction outcome loss': 0.11881490977319355, 'Total loss': 0.11881490977319355}
2022-12-31 08:09:04,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:04,256 INFO:     Epoch: 95
2022-12-31 08:09:05,878 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39630233744780224, 'Total loss': 0.39630233744780224} | train loss {'Reaction outcome loss': 0.12575933951281343, 'Total loss': 0.12575933951281343}
2022-12-31 08:09:05,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:05,878 INFO:     Epoch: 96
2022-12-31 08:09:07,541 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42875123073657356, 'Total loss': 0.42875123073657356} | train loss {'Reaction outcome loss': 0.11707623933962431, 'Total loss': 0.11707623933962431}
2022-12-31 08:09:07,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:07,541 INFO:     Epoch: 97
2022-12-31 08:09:09,162 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4192653253674507, 'Total loss': 0.4192653253674507} | train loss {'Reaction outcome loss': 0.11941332378225616, 'Total loss': 0.11941332378225616}
2022-12-31 08:09:09,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:09,162 INFO:     Epoch: 98
2022-12-31 08:09:10,811 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43184365928173063, 'Total loss': 0.43184365928173063} | train loss {'Reaction outcome loss': 0.11681542466301809, 'Total loss': 0.11681542466301809}
2022-12-31 08:09:10,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:10,812 INFO:     Epoch: 99
2022-12-31 08:09:12,427 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39130156934261323, 'Total loss': 0.39130156934261323} | train loss {'Reaction outcome loss': 0.11641945794563861, 'Total loss': 0.11641945794563861}
2022-12-31 08:09:12,427 INFO:     Best model found after epoch 17 of 100.
2022-12-31 08:09:12,427 INFO:   Done with stage: TRAINING
2022-12-31 08:09:12,427 INFO:   Starting stage: EVALUATION
2022-12-31 08:09:12,559 INFO:   Done with stage: EVALUATION
2022-12-31 08:09:12,568 INFO:   Leaving out SEQ value Fold_0
2022-12-31 08:09:12,581 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 08:09:12,581 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:09:13,232 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:09:13,232 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:09:13,298 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:09:13,299 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:09:13,299 INFO:     No hyperparam tuning for this model
2022-12-31 08:09:13,299 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:09:13,299 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:09:13,299 INFO:     None feature selector for col prot
2022-12-31 08:09:13,300 INFO:     None feature selector for col prot
2022-12-31 08:09:13,300 INFO:     None feature selector for col prot
2022-12-31 08:09:13,300 INFO:     None feature selector for col chem
2022-12-31 08:09:13,300 INFO:     None feature selector for col chem
2022-12-31 08:09:13,300 INFO:     None feature selector for col chem
2022-12-31 08:09:13,300 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:09:13,301 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:09:13,302 INFO:     Number of params in model 224011
2022-12-31 08:09:13,306 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:09:13,306 INFO:   Starting stage: TRAINING
2022-12-31 08:09:13,350 INFO:     Val loss before train {'Reaction outcome loss': 0.9668227076530457, 'Total loss': 0.9668227076530457}
2022-12-31 08:09:13,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:13,350 INFO:     Epoch: 0
2022-12-31 08:09:14,955 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5751870334148407, 'Total loss': 0.5751870334148407} | train loss {'Reaction outcome loss': 0.7887290136439957, 'Total loss': 0.7887290136439957}
2022-12-31 08:09:14,955 INFO:     Found new best model at epoch 0
2022-12-31 08:09:14,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:14,956 INFO:     Epoch: 1
2022-12-31 08:09:16,561 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5217507893840472, 'Total loss': 0.5217507893840472} | train loss {'Reaction outcome loss': 0.5229641684759272, 'Total loss': 0.5229641684759272}
2022-12-31 08:09:16,562 INFO:     Found new best model at epoch 1
2022-12-31 08:09:16,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:16,563 INFO:     Epoch: 2
2022-12-31 08:09:18,165 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48871492346127826, 'Total loss': 0.48871492346127826} | train loss {'Reaction outcome loss': 0.45423585241728454, 'Total loss': 0.45423585241728454}
2022-12-31 08:09:18,165 INFO:     Found new best model at epoch 2
2022-12-31 08:09:18,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:18,166 INFO:     Epoch: 3
2022-12-31 08:09:19,759 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4652490794658661, 'Total loss': 0.4652490794658661} | train loss {'Reaction outcome loss': 0.4133800165387836, 'Total loss': 0.4133800165387836}
2022-12-31 08:09:19,759 INFO:     Found new best model at epoch 3
2022-12-31 08:09:19,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:19,760 INFO:     Epoch: 4
2022-12-31 08:09:21,365 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4960611422856649, 'Total loss': 0.4960611422856649} | train loss {'Reaction outcome loss': 0.38174665675763664, 'Total loss': 0.38174665675763664}
2022-12-31 08:09:21,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:21,366 INFO:     Epoch: 5
2022-12-31 08:09:23,002 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44854798714319866, 'Total loss': 0.44854798714319866} | train loss {'Reaction outcome loss': 0.35626604185052163, 'Total loss': 0.35626604185052163}
2022-12-31 08:09:23,004 INFO:     Found new best model at epoch 5
2022-12-31 08:09:23,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:23,005 INFO:     Epoch: 6
2022-12-31 08:09:24,655 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4363780568043391, 'Total loss': 0.4363780568043391} | train loss {'Reaction outcome loss': 0.3360869605502073, 'Total loss': 0.3360869605502073}
2022-12-31 08:09:24,655 INFO:     Found new best model at epoch 6
2022-12-31 08:09:24,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:24,656 INFO:     Epoch: 7
2022-12-31 08:09:26,260 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42955632209777833, 'Total loss': 0.42955632209777833} | train loss {'Reaction outcome loss': 0.31932508347923083, 'Total loss': 0.31932508347923083}
2022-12-31 08:09:26,260 INFO:     Found new best model at epoch 7
2022-12-31 08:09:26,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:26,261 INFO:     Epoch: 8
2022-12-31 08:09:27,864 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4038236161073049, 'Total loss': 0.4038236161073049} | train loss {'Reaction outcome loss': 0.30539506910382397, 'Total loss': 0.30539506910382397}
2022-12-31 08:09:27,864 INFO:     Found new best model at epoch 8
2022-12-31 08:09:27,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:27,865 INFO:     Epoch: 9
2022-12-31 08:09:29,467 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43504355251789095, 'Total loss': 0.43504355251789095} | train loss {'Reaction outcome loss': 0.2887250369917737, 'Total loss': 0.2887250369917737}
2022-12-31 08:09:29,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:29,468 INFO:     Epoch: 10
2022-12-31 08:09:31,073 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4424935082594554, 'Total loss': 0.4424935082594554} | train loss {'Reaction outcome loss': 0.27813340178316964, 'Total loss': 0.27813340178316964}
2022-12-31 08:09:31,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:31,073 INFO:     Epoch: 11
2022-12-31 08:09:32,676 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43960420191287997, 'Total loss': 0.43960420191287997} | train loss {'Reaction outcome loss': 0.26527525415222575, 'Total loss': 0.26527525415222575}
2022-12-31 08:09:32,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:32,676 INFO:     Epoch: 12
2022-12-31 08:09:34,286 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4308063526948293, 'Total loss': 0.4308063526948293} | train loss {'Reaction outcome loss': 0.25652890220066926, 'Total loss': 0.25652890220066926}
2022-12-31 08:09:34,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:34,286 INFO:     Epoch: 13
2022-12-31 08:09:35,890 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4123361070950826, 'Total loss': 0.4123361070950826} | train loss {'Reaction outcome loss': 0.2480471348457963, 'Total loss': 0.2480471348457963}
2022-12-31 08:09:35,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:35,890 INFO:     Epoch: 14
2022-12-31 08:09:37,490 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4390481879313787, 'Total loss': 0.4390481879313787} | train loss {'Reaction outcome loss': 0.23976046117498492, 'Total loss': 0.23976046117498492}
2022-12-31 08:09:37,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:37,490 INFO:     Epoch: 15
2022-12-31 08:09:39,090 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40699338763952253, 'Total loss': 0.40699338763952253} | train loss {'Reaction outcome loss': 0.23041355783921957, 'Total loss': 0.23041355783921957}
2022-12-31 08:09:39,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:39,090 INFO:     Epoch: 16
2022-12-31 08:09:40,716 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3945042178034782, 'Total loss': 0.3945042178034782} | train loss {'Reaction outcome loss': 0.22274766133649507, 'Total loss': 0.22274766133649507}
2022-12-31 08:09:40,716 INFO:     Found new best model at epoch 16
2022-12-31 08:09:40,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:40,717 INFO:     Epoch: 17
2022-12-31 08:09:42,323 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4217698593934377, 'Total loss': 0.4217698593934377} | train loss {'Reaction outcome loss': 0.2170693511619185, 'Total loss': 0.2170693511619185}
2022-12-31 08:09:42,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:42,324 INFO:     Epoch: 18
2022-12-31 08:09:43,932 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4386846254269282, 'Total loss': 0.4386846254269282} | train loss {'Reaction outcome loss': 0.20779366072022568, 'Total loss': 0.20779366072022568}
2022-12-31 08:09:43,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:43,932 INFO:     Epoch: 19
2022-12-31 08:09:45,584 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4457232048114141, 'Total loss': 0.4457232048114141} | train loss {'Reaction outcome loss': 0.20860654193173794, 'Total loss': 0.20860654193173794}
2022-12-31 08:09:45,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:45,584 INFO:     Epoch: 20
2022-12-31 08:09:47,211 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4224575340747833, 'Total loss': 0.4224575340747833} | train loss {'Reaction outcome loss': 0.1976313797321959, 'Total loss': 0.1976313797321959}
2022-12-31 08:09:47,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:47,211 INFO:     Epoch: 21
2022-12-31 08:09:48,861 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4437881976366043, 'Total loss': 0.4437881976366043} | train loss {'Reaction outcome loss': 0.19189625792885132, 'Total loss': 0.19189625792885132}
2022-12-31 08:09:48,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:48,861 INFO:     Epoch: 22
2022-12-31 08:09:50,470 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40492542969683804, 'Total loss': 0.40492542969683804} | train loss {'Reaction outcome loss': 0.18944238527358448, 'Total loss': 0.18944238527358448}
2022-12-31 08:09:50,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:50,470 INFO:     Epoch: 23
2022-12-31 08:09:52,080 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4170211190978686, 'Total loss': 0.4170211190978686} | train loss {'Reaction outcome loss': 0.18686673046517982, 'Total loss': 0.18686673046517982}
2022-12-31 08:09:52,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:52,080 INFO:     Epoch: 24
2022-12-31 08:09:53,692 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4266721228758494, 'Total loss': 0.4266721228758494} | train loss {'Reaction outcome loss': 0.17954637973576132, 'Total loss': 0.17954637973576132}
2022-12-31 08:09:53,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:53,693 INFO:     Epoch: 25
2022-12-31 08:09:55,305 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44518239597479503, 'Total loss': 0.44518239597479503} | train loss {'Reaction outcome loss': 0.17742203367044673, 'Total loss': 0.17742203367044673}
2022-12-31 08:09:55,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:55,305 INFO:     Epoch: 26
2022-12-31 08:09:56,937 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44273487230141956, 'Total loss': 0.44273487230141956} | train loss {'Reaction outcome loss': 0.17105869947504387, 'Total loss': 0.17105869947504387}
2022-12-31 08:09:56,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:56,937 INFO:     Epoch: 27
2022-12-31 08:09:58,539 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41671635607878366, 'Total loss': 0.41671635607878366} | train loss {'Reaction outcome loss': 0.17137929788675077, 'Total loss': 0.17137929788675077}
2022-12-31 08:09:58,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:09:58,539 INFO:     Epoch: 28
2022-12-31 08:10:00,142 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45219321449597677, 'Total loss': 0.45219321449597677} | train loss {'Reaction outcome loss': 0.16628333013572724, 'Total loss': 0.16628333013572724}
2022-12-31 08:10:00,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:00,143 INFO:     Epoch: 29
2022-12-31 08:10:01,745 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.471521403392156, 'Total loss': 0.471521403392156} | train loss {'Reaction outcome loss': 0.16659507502794918, 'Total loss': 0.16659507502794918}
2022-12-31 08:10:01,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:01,745 INFO:     Epoch: 30
2022-12-31 08:10:03,346 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42448432904978595, 'Total loss': 0.42448432904978595} | train loss {'Reaction outcome loss': 0.16301794303921016, 'Total loss': 0.16301794303921016}
2022-12-31 08:10:03,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:03,346 INFO:     Epoch: 31
2022-12-31 08:10:04,951 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4176191300153732, 'Total loss': 0.4176191300153732} | train loss {'Reaction outcome loss': 0.16020747943081126, 'Total loss': 0.16020747943081126}
2022-12-31 08:10:04,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:04,951 INFO:     Epoch: 32
2022-12-31 08:10:06,558 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43013027707735696, 'Total loss': 0.43013027707735696} | train loss {'Reaction outcome loss': 0.15470276458909477, 'Total loss': 0.15470276458909477}
2022-12-31 08:10:06,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:06,558 INFO:     Epoch: 33
2022-12-31 08:10:08,178 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4128329664468765, 'Total loss': 0.4128329664468765} | train loss {'Reaction outcome loss': 0.15230230912634166, 'Total loss': 0.15230230912634166}
2022-12-31 08:10:08,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:08,178 INFO:     Epoch: 34
2022-12-31 08:10:09,829 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4666867117087046, 'Total loss': 0.4666867117087046} | train loss {'Reaction outcome loss': 0.14934571344833686, 'Total loss': 0.14934571344833686}
2022-12-31 08:10:09,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:09,829 INFO:     Epoch: 35
2022-12-31 08:10:11,434 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4805855085452398, 'Total loss': 0.4805855085452398} | train loss {'Reaction outcome loss': 0.1511410584564518, 'Total loss': 0.1511410584564518}
2022-12-31 08:10:11,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:11,435 INFO:     Epoch: 36
2022-12-31 08:10:13,040 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44198643465836845, 'Total loss': 0.44198643465836845} | train loss {'Reaction outcome loss': 0.14692971122920187, 'Total loss': 0.14692971122920187}
2022-12-31 08:10:13,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:13,041 INFO:     Epoch: 37
2022-12-31 08:10:14,650 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4201516926288605, 'Total loss': 0.4201516926288605} | train loss {'Reaction outcome loss': 0.14684893401597973, 'Total loss': 0.14684893401597973}
2022-12-31 08:10:14,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:14,650 INFO:     Epoch: 38
2022-12-31 08:10:16,256 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45034491320451103, 'Total loss': 0.45034491320451103} | train loss {'Reaction outcome loss': 0.1462250811278983, 'Total loss': 0.1462250811278983}
2022-12-31 08:10:16,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:16,256 INFO:     Epoch: 39
2022-12-31 08:10:17,861 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4349366664886475, 'Total loss': 0.4349366664886475} | train loss {'Reaction outcome loss': 0.1447347877479165, 'Total loss': 0.1447347877479165}
2022-12-31 08:10:17,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:17,861 INFO:     Epoch: 40
2022-12-31 08:10:19,474 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4467974901199341, 'Total loss': 0.4467974901199341} | train loss {'Reaction outcome loss': 0.14333409981727327, 'Total loss': 0.14333409981727327}
2022-12-31 08:10:19,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:19,474 INFO:     Epoch: 41
2022-12-31 08:10:21,085 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43658675750096637, 'Total loss': 0.43658675750096637} | train loss {'Reaction outcome loss': 0.14064268013598383, 'Total loss': 0.14064268013598383}
2022-12-31 08:10:21,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:21,086 INFO:     Epoch: 42
2022-12-31 08:10:22,698 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4211993059143424, 'Total loss': 0.4211993059143424} | train loss {'Reaction outcome loss': 0.13617074884215954, 'Total loss': 0.13617074884215954}
2022-12-31 08:10:22,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:22,698 INFO:     Epoch: 43
2022-12-31 08:10:24,332 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.437478119134903, 'Total loss': 0.437478119134903} | train loss {'Reaction outcome loss': 0.13927781906991815, 'Total loss': 0.13927781906991815}
2022-12-31 08:10:24,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:24,333 INFO:     Epoch: 44
2022-12-31 08:10:25,943 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4314444581667582, 'Total loss': 0.4314444581667582} | train loss {'Reaction outcome loss': 0.1358250092415914, 'Total loss': 0.1358250092415914}
2022-12-31 08:10:25,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:25,943 INFO:     Epoch: 45
2022-12-31 08:10:27,594 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43572627753019333, 'Total loss': 0.43572627753019333} | train loss {'Reaction outcome loss': 0.1335057577791277, 'Total loss': 0.1335057577791277}
2022-12-31 08:10:27,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:27,594 INFO:     Epoch: 46
2022-12-31 08:10:29,198 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4126206045349439, 'Total loss': 0.4126206045349439} | train loss {'Reaction outcome loss': 0.13247810970366436, 'Total loss': 0.13247810970366436}
2022-12-31 08:10:29,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:29,199 INFO:     Epoch: 47
2022-12-31 08:10:30,810 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45272463659445444, 'Total loss': 0.45272463659445444} | train loss {'Reaction outcome loss': 0.13615561813374397, 'Total loss': 0.13615561813374397}
2022-12-31 08:10:30,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:30,811 INFO:     Epoch: 48
2022-12-31 08:10:32,416 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41189548149704935, 'Total loss': 0.41189548149704935} | train loss {'Reaction outcome loss': 0.13101355466026351, 'Total loss': 0.13101355466026351}
2022-12-31 08:10:32,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:32,416 INFO:     Epoch: 49
2022-12-31 08:10:34,067 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4381951073805491, 'Total loss': 0.4381951073805491} | train loss {'Reaction outcome loss': 0.1286418351784933, 'Total loss': 0.1286418351784933}
2022-12-31 08:10:34,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:34,067 INFO:     Epoch: 50
2022-12-31 08:10:35,676 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4236041178305944, 'Total loss': 0.4236041178305944} | train loss {'Reaction outcome loss': 0.12819819518256198, 'Total loss': 0.12819819518256198}
2022-12-31 08:10:35,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:35,676 INFO:     Epoch: 51
2022-12-31 08:10:37,326 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44829370776812233, 'Total loss': 0.44829370776812233} | train loss {'Reaction outcome loss': 0.12851954299963358, 'Total loss': 0.12851954299963358}
2022-12-31 08:10:37,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:37,327 INFO:     Epoch: 52
2022-12-31 08:10:38,978 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4193402846654256, 'Total loss': 0.4193402846654256} | train loss {'Reaction outcome loss': 0.12605047767750754, 'Total loss': 0.12605047767750754}
2022-12-31 08:10:38,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:38,978 INFO:     Epoch: 53
2022-12-31 08:10:40,585 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45338433384895327, 'Total loss': 0.45338433384895327} | train loss {'Reaction outcome loss': 0.12999740839310425, 'Total loss': 0.12999740839310425}
2022-12-31 08:10:40,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:40,585 INFO:     Epoch: 54
2022-12-31 08:10:42,196 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43225896805524827, 'Total loss': 0.43225896805524827} | train loss {'Reaction outcome loss': 0.12493674459622452, 'Total loss': 0.12493674459622452}
2022-12-31 08:10:42,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:42,196 INFO:     Epoch: 55
2022-12-31 08:10:43,838 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4340938319762548, 'Total loss': 0.4340938319762548} | train loss {'Reaction outcome loss': 0.12532784981843437, 'Total loss': 0.12532784981843437}
2022-12-31 08:10:43,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:43,839 INFO:     Epoch: 56
2022-12-31 08:10:45,445 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45977173844973246, 'Total loss': 0.45977173844973246} | train loss {'Reaction outcome loss': 0.12912110859922465, 'Total loss': 0.12912110859922465}
2022-12-31 08:10:45,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:45,446 INFO:     Epoch: 57
2022-12-31 08:10:47,104 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4415035963058472, 'Total loss': 0.4415035963058472} | train loss {'Reaction outcome loss': 0.12585193569683573, 'Total loss': 0.12585193569683573}
2022-12-31 08:10:47,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:47,104 INFO:     Epoch: 58
2022-12-31 08:10:48,754 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4386221945285797, 'Total loss': 0.4386221945285797} | train loss {'Reaction outcome loss': 0.12302546201691875, 'Total loss': 0.12302546201691875}
2022-12-31 08:10:48,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:48,754 INFO:     Epoch: 59
2022-12-31 08:10:50,404 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4609341621398926, 'Total loss': 0.4609341621398926} | train loss {'Reaction outcome loss': 0.1229594086677543, 'Total loss': 0.1229594086677543}
2022-12-31 08:10:50,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:50,405 INFO:     Epoch: 60
2022-12-31 08:10:52,013 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45362189710140227, 'Total loss': 0.45362189710140227} | train loss {'Reaction outcome loss': 0.12025589133565226, 'Total loss': 0.12025589133565226}
2022-12-31 08:10:52,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:52,014 INFO:     Epoch: 61
2022-12-31 08:10:53,624 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47479497293631234, 'Total loss': 0.47479497293631234} | train loss {'Reaction outcome loss': 0.12106645052800512, 'Total loss': 0.12106645052800512}
2022-12-31 08:10:53,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:53,624 INFO:     Epoch: 62
2022-12-31 08:10:55,243 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4697388639052709, 'Total loss': 0.4697388639052709} | train loss {'Reaction outcome loss': 0.12427180342165495, 'Total loss': 0.12427180342165495}
2022-12-31 08:10:55,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:55,243 INFO:     Epoch: 63
2022-12-31 08:10:56,862 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4462698345383008, 'Total loss': 0.4462698345383008} | train loss {'Reaction outcome loss': 0.1245845412244055, 'Total loss': 0.1245845412244055}
2022-12-31 08:10:56,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:56,863 INFO:     Epoch: 64
2022-12-31 08:10:58,483 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43659114837646484, 'Total loss': 0.43659114837646484} | train loss {'Reaction outcome loss': 0.12635620632276864, 'Total loss': 0.12635620632276864}
2022-12-31 08:10:58,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:10:58,484 INFO:     Epoch: 65
2022-12-31 08:11:00,094 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46663119196891784, 'Total loss': 0.46663119196891784} | train loss {'Reaction outcome loss': 0.1176772704653877, 'Total loss': 0.1176772704653877}
2022-12-31 08:11:00,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:00,096 INFO:     Epoch: 66
2022-12-31 08:11:01,712 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45922151108582815, 'Total loss': 0.45922151108582815} | train loss {'Reaction outcome loss': 0.11570768527700191, 'Total loss': 0.11570768527700191}
2022-12-31 08:11:01,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:01,713 INFO:     Epoch: 67
2022-12-31 08:11:03,323 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43017860849698386, 'Total loss': 0.43017860849698386} | train loss {'Reaction outcome loss': 0.11887471982529454, 'Total loss': 0.11887471982529454}
2022-12-31 08:11:03,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:03,324 INFO:     Epoch: 68
2022-12-31 08:11:04,942 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44163289268811545, 'Total loss': 0.44163289268811545} | train loss {'Reaction outcome loss': 0.11748140808840683, 'Total loss': 0.11748140808840683}
2022-12-31 08:11:04,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:04,942 INFO:     Epoch: 69
2022-12-31 08:11:06,558 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4662717709938685, 'Total loss': 0.4662717709938685} | train loss {'Reaction outcome loss': 0.1228384328445243, 'Total loss': 0.1228384328445243}
2022-12-31 08:11:06,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:06,559 INFO:     Epoch: 70
2022-12-31 08:11:08,174 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42145880659421286, 'Total loss': 0.42145880659421286} | train loss {'Reaction outcome loss': 0.11987592427257149, 'Total loss': 0.11987592427257149}
2022-12-31 08:11:08,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:08,174 INFO:     Epoch: 71
2022-12-31 08:11:09,779 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46843395903706553, 'Total loss': 0.46843395903706553} | train loss {'Reaction outcome loss': 0.11923576183498151, 'Total loss': 0.11923576183498151}
2022-12-31 08:11:09,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:09,779 INFO:     Epoch: 72
2022-12-31 08:11:11,388 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4581831013162931, 'Total loss': 0.4581831013162931} | train loss {'Reaction outcome loss': 0.11811090378688961, 'Total loss': 0.11811090378688961}
2022-12-31 08:11:11,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:11,388 INFO:     Epoch: 73
2022-12-31 08:11:13,013 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45309107601642606, 'Total loss': 0.45309107601642606} | train loss {'Reaction outcome loss': 0.12066288217460315, 'Total loss': 0.12066288217460315}
2022-12-31 08:11:13,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:13,014 INFO:     Epoch: 74
2022-12-31 08:11:14,635 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4533008585373561, 'Total loss': 0.4533008585373561} | train loss {'Reaction outcome loss': 0.11938542450003217, 'Total loss': 0.11938542450003217}
2022-12-31 08:11:14,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:14,635 INFO:     Epoch: 75
2022-12-31 08:11:16,247 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4384174019098282, 'Total loss': 0.4384174019098282} | train loss {'Reaction outcome loss': 0.11410629956721308, 'Total loss': 0.11410629956721308}
2022-12-31 08:11:16,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:16,247 INFO:     Epoch: 76
2022-12-31 08:11:17,852 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4469215601682663, 'Total loss': 0.4469215601682663} | train loss {'Reaction outcome loss': 0.1141180980654882, 'Total loss': 0.1141180980654882}
2022-12-31 08:11:17,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:17,852 INFO:     Epoch: 77
2022-12-31 08:11:19,458 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45076559484004974, 'Total loss': 0.45076559484004974} | train loss {'Reaction outcome loss': 0.11619708402911677, 'Total loss': 0.11619708402911677}
2022-12-31 08:11:19,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:19,459 INFO:     Epoch: 78
2022-12-31 08:11:21,072 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4673966477314631, 'Total loss': 0.4673966477314631} | train loss {'Reaction outcome loss': 0.11784964032389604, 'Total loss': 0.11784964032389604}
2022-12-31 08:11:21,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:21,072 INFO:     Epoch: 79
2022-12-31 08:11:22,682 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4408014843861262, 'Total loss': 0.4408014843861262} | train loss {'Reaction outcome loss': 0.11025741571614886, 'Total loss': 0.11025741571614886}
2022-12-31 08:11:22,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:22,683 INFO:     Epoch: 80
2022-12-31 08:11:24,333 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45289852023124694, 'Total loss': 0.45289852023124694} | train loss {'Reaction outcome loss': 0.11148747883356401, 'Total loss': 0.11148747883356401}
2022-12-31 08:11:24,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:24,333 INFO:     Epoch: 81
2022-12-31 08:11:25,983 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4855413178602854, 'Total loss': 0.4855413178602854} | train loss {'Reaction outcome loss': 0.11422973649787044, 'Total loss': 0.11422973649787044}
2022-12-31 08:11:25,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:25,984 INFO:     Epoch: 82
2022-12-31 08:11:27,606 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46784561475118003, 'Total loss': 0.46784561475118003} | train loss {'Reaction outcome loss': 0.11334141233704821, 'Total loss': 0.11334141233704821}
2022-12-31 08:11:27,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:27,607 INFO:     Epoch: 83
2022-12-31 08:11:29,257 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46352414786815643, 'Total loss': 0.46352414786815643} | train loss {'Reaction outcome loss': 0.1142732221344282, 'Total loss': 0.1142732221344282}
2022-12-31 08:11:29,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:29,258 INFO:     Epoch: 84
2022-12-31 08:11:30,894 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4550296703974406, 'Total loss': 0.4550296703974406} | train loss {'Reaction outcome loss': 0.11102504616970346, 'Total loss': 0.11102504616970346}
2022-12-31 08:11:30,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:30,894 INFO:     Epoch: 85
2022-12-31 08:11:32,500 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.462608269850413, 'Total loss': 0.462608269850413} | train loss {'Reaction outcome loss': 0.11273131890640506, 'Total loss': 0.11273131890640506}
2022-12-31 08:11:32,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:32,501 INFO:     Epoch: 86
2022-12-31 08:11:34,108 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45227202971776326, 'Total loss': 0.45227202971776326} | train loss {'Reaction outcome loss': 0.11544546685147568, 'Total loss': 0.11544546685147568}
2022-12-31 08:11:34,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:34,108 INFO:     Epoch: 87
2022-12-31 08:11:35,713 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4441057682037354, 'Total loss': 0.4441057682037354} | train loss {'Reaction outcome loss': 0.1100962887480719, 'Total loss': 0.1100962887480719}
2022-12-31 08:11:35,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:35,713 INFO:     Epoch: 88
2022-12-31 08:11:37,349 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46042123635609944, 'Total loss': 0.46042123635609944} | train loss {'Reaction outcome loss': 0.11042081473232077, 'Total loss': 0.11042081473232077}
2022-12-31 08:11:37,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:37,350 INFO:     Epoch: 89
2022-12-31 08:11:38,959 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42938789129257204, 'Total loss': 0.42938789129257204} | train loss {'Reaction outcome loss': 0.11020032272939265, 'Total loss': 0.11020032272939265}
2022-12-31 08:11:38,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:38,959 INFO:     Epoch: 90
2022-12-31 08:11:40,569 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4585588326056798, 'Total loss': 0.4585588326056798} | train loss {'Reaction outcome loss': 0.11164864047131345, 'Total loss': 0.11164864047131345}
2022-12-31 08:11:40,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:40,569 INFO:     Epoch: 91
2022-12-31 08:11:42,201 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4901084731022517, 'Total loss': 0.4901084731022517} | train loss {'Reaction outcome loss': 0.11416582854117953, 'Total loss': 0.11416582854117953}
2022-12-31 08:11:42,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:42,201 INFO:     Epoch: 92
2022-12-31 08:11:43,852 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45765824913978576, 'Total loss': 0.45765824913978576} | train loss {'Reaction outcome loss': 0.10980881718973065, 'Total loss': 0.10980881718973065}
2022-12-31 08:11:43,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:43,853 INFO:     Epoch: 93
2022-12-31 08:11:45,455 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4104165181517601, 'Total loss': 0.4104165181517601} | train loss {'Reaction outcome loss': 0.10764082608554158, 'Total loss': 0.10764082608554158}
2022-12-31 08:11:45,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:45,455 INFO:     Epoch: 94
2022-12-31 08:11:47,077 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4526562432448069, 'Total loss': 0.4526562432448069} | train loss {'Reaction outcome loss': 0.10996205439403599, 'Total loss': 0.10996205439403599}
2022-12-31 08:11:47,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:47,077 INFO:     Epoch: 95
2022-12-31 08:11:48,676 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4487006594737371, 'Total loss': 0.4487006594737371} | train loss {'Reaction outcome loss': 0.11058808168919798, 'Total loss': 0.11058808168919798}
2022-12-31 08:11:48,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:48,676 INFO:     Epoch: 96
2022-12-31 08:11:50,285 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4533597523967425, 'Total loss': 0.4533597523967425} | train loss {'Reaction outcome loss': 0.10803465471419431, 'Total loss': 0.10803465471419431}
2022-12-31 08:11:50,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:50,285 INFO:     Epoch: 97
2022-12-31 08:11:51,935 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4726796413461367, 'Total loss': 0.4726796413461367} | train loss {'Reaction outcome loss': 0.10687913211235898, 'Total loss': 0.10687913211235898}
2022-12-31 08:11:51,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:51,935 INFO:     Epoch: 98
2022-12-31 08:11:53,540 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4465770224730174, 'Total loss': 0.4465770224730174} | train loss {'Reaction outcome loss': 0.11177068251613391, 'Total loss': 0.11177068251613391}
2022-12-31 08:11:53,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:53,540 INFO:     Epoch: 99
2022-12-31 08:11:55,163 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5197996179262797, 'Total loss': 0.5197996179262797} | train loss {'Reaction outcome loss': 0.1093552767462267, 'Total loss': 0.1093552767462267}
2022-12-31 08:11:55,163 INFO:     Best model found after epoch 17 of 100.
2022-12-31 08:11:55,163 INFO:   Done with stage: TRAINING
2022-12-31 08:11:55,163 INFO:   Starting stage: EVALUATION
2022-12-31 08:11:55,303 INFO:   Done with stage: EVALUATION
2022-12-31 08:11:55,304 INFO:   Leaving out SEQ value Fold_1
2022-12-31 08:11:55,316 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 08:11:55,316 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:11:55,958 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:11:55,959 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:11:56,026 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:11:56,026 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:11:56,026 INFO:     No hyperparam tuning for this model
2022-12-31 08:11:56,026 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:11:56,026 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:11:56,027 INFO:     None feature selector for col prot
2022-12-31 08:11:56,027 INFO:     None feature selector for col prot
2022-12-31 08:11:56,027 INFO:     None feature selector for col prot
2022-12-31 08:11:56,028 INFO:     None feature selector for col chem
2022-12-31 08:11:56,028 INFO:     None feature selector for col chem
2022-12-31 08:11:56,028 INFO:     None feature selector for col chem
2022-12-31 08:11:56,028 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:11:56,028 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:11:56,030 INFO:     Number of params in model 224011
2022-12-31 08:11:56,033 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:11:56,033 INFO:   Starting stage: TRAINING
2022-12-31 08:11:56,079 INFO:     Val loss before train {'Reaction outcome loss': 0.8901663879553477, 'Total loss': 0.8901663879553477}
2022-12-31 08:11:56,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:56,080 INFO:     Epoch: 0
2022-12-31 08:11:57,700 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.430544501543045, 'Total loss': 0.430544501543045} | train loss {'Reaction outcome loss': 0.7792432474129366, 'Total loss': 0.7792432474129366}
2022-12-31 08:11:57,700 INFO:     Found new best model at epoch 0
2022-12-31 08:11:57,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:57,701 INFO:     Epoch: 1
2022-12-31 08:11:59,302 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.38884344696998596, 'Total loss': 0.38884344696998596} | train loss {'Reaction outcome loss': 0.5220109265256714, 'Total loss': 0.5220109265256714}
2022-12-31 08:11:59,302 INFO:     Found new best model at epoch 1
2022-12-31 08:11:59,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:11:59,303 INFO:     Epoch: 2
2022-12-31 08:12:00,904 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.36898492177327474, 'Total loss': 0.36898492177327474} | train loss {'Reaction outcome loss': 0.4573694977895681, 'Total loss': 0.4573694977895681}
2022-12-31 08:12:00,904 INFO:     Found new best model at epoch 2
2022-12-31 08:12:00,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:00,905 INFO:     Epoch: 3
2022-12-31 08:12:02,503 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.36447924971580503, 'Total loss': 0.36447924971580503} | train loss {'Reaction outcome loss': 0.41722795361782605, 'Total loss': 0.41722795361782605}
2022-12-31 08:12:02,503 INFO:     Found new best model at epoch 3
2022-12-31 08:12:02,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:02,504 INFO:     Epoch: 4
2022-12-31 08:12:04,116 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3488382329543432, 'Total loss': 0.3488382329543432} | train loss {'Reaction outcome loss': 0.38890002708841154, 'Total loss': 0.38890002708841154}
2022-12-31 08:12:04,116 INFO:     Found new best model at epoch 4
2022-12-31 08:12:04,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:04,117 INFO:     Epoch: 5
2022-12-31 08:12:05,719 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3537645955880483, 'Total loss': 0.3537645955880483} | train loss {'Reaction outcome loss': 0.36847276243316385, 'Total loss': 0.36847276243316385}
2022-12-31 08:12:05,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:05,719 INFO:     Epoch: 6
2022-12-31 08:12:07,313 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3477318733930588, 'Total loss': 0.3477318733930588} | train loss {'Reaction outcome loss': 0.3469456128039203, 'Total loss': 0.3469456128039203}
2022-12-31 08:12:07,313 INFO:     Found new best model at epoch 6
2022-12-31 08:12:07,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:07,314 INFO:     Epoch: 7
2022-12-31 08:12:08,911 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3676803052425385, 'Total loss': 0.3676803052425385} | train loss {'Reaction outcome loss': 0.3322788109600326, 'Total loss': 0.3322788109600326}
2022-12-31 08:12:08,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:08,911 INFO:     Epoch: 8
2022-12-31 08:12:10,509 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3438144246737162, 'Total loss': 0.3438144246737162} | train loss {'Reaction outcome loss': 0.31444793710341823, 'Total loss': 0.31444793710341823}
2022-12-31 08:12:10,509 INFO:     Found new best model at epoch 8
2022-12-31 08:12:10,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:10,510 INFO:     Epoch: 9
2022-12-31 08:12:12,105 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3228564540545146, 'Total loss': 0.3228564540545146} | train loss {'Reaction outcome loss': 0.29950284968802343, 'Total loss': 0.29950284968802343}
2022-12-31 08:12:12,106 INFO:     Found new best model at epoch 9
2022-12-31 08:12:12,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:12,107 INFO:     Epoch: 10
2022-12-31 08:12:13,737 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.33323935866355897, 'Total loss': 0.33323935866355897} | train loss {'Reaction outcome loss': 0.2899961878473942, 'Total loss': 0.2899961878473942}
2022-12-31 08:12:13,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:13,737 INFO:     Epoch: 11
2022-12-31 08:12:15,356 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3013304854432742, 'Total loss': 0.3013304854432742} | train loss {'Reaction outcome loss': 0.28168924147392804, 'Total loss': 0.28168924147392804}
2022-12-31 08:12:15,356 INFO:     Found new best model at epoch 11
2022-12-31 08:12:15,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:15,357 INFO:     Epoch: 12
2022-12-31 08:12:16,964 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3200287994618217, 'Total loss': 0.3200287994618217} | train loss {'Reaction outcome loss': 0.2674093524833302, 'Total loss': 0.2674093524833302}
2022-12-31 08:12:16,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:16,965 INFO:     Epoch: 13
2022-12-31 08:12:18,569 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.2987987667322159, 'Total loss': 0.2987987667322159} | train loss {'Reaction outcome loss': 0.2574841224694208, 'Total loss': 0.2574841224694208}
2022-12-31 08:12:18,570 INFO:     Found new best model at epoch 13
2022-12-31 08:12:18,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:18,571 INFO:     Epoch: 14
2022-12-31 08:12:20,175 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.2975819839785496, 'Total loss': 0.2975819839785496} | train loss {'Reaction outcome loss': 0.24857658046833325, 'Total loss': 0.24857658046833325}
2022-12-31 08:12:20,175 INFO:     Found new best model at epoch 14
2022-12-31 08:12:20,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:20,176 INFO:     Epoch: 15
2022-12-31 08:12:21,774 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.298134990533193, 'Total loss': 0.298134990533193} | train loss {'Reaction outcome loss': 0.23781327609887054, 'Total loss': 0.23781327609887054}
2022-12-31 08:12:21,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:21,774 INFO:     Epoch: 16
2022-12-31 08:12:23,383 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.31460566222667696, 'Total loss': 0.31460566222667696} | train loss {'Reaction outcome loss': 0.23318719800438856, 'Total loss': 0.23318719800438856}
2022-12-31 08:12:23,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:23,384 INFO:     Epoch: 17
2022-12-31 08:12:25,013 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.2766352792580922, 'Total loss': 0.2766352792580922} | train loss {'Reaction outcome loss': 0.22696754079816978, 'Total loss': 0.22696754079816978}
2022-12-31 08:12:25,013 INFO:     Found new best model at epoch 17
2022-12-31 08:12:25,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:25,014 INFO:     Epoch: 18
2022-12-31 08:12:26,615 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.2926380957166354, 'Total loss': 0.2926380957166354} | train loss {'Reaction outcome loss': 0.2186481891056666, 'Total loss': 0.2186481891056666}
2022-12-31 08:12:26,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:26,615 INFO:     Epoch: 19
2022-12-31 08:12:28,259 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.311201008160909, 'Total loss': 0.311201008160909} | train loss {'Reaction outcome loss': 0.2104889724894867, 'Total loss': 0.2104889724894867}
2022-12-31 08:12:28,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:28,260 INFO:     Epoch: 20
2022-12-31 08:12:29,905 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3182651271422704, 'Total loss': 0.3182651271422704} | train loss {'Reaction outcome loss': 0.2093464115177428, 'Total loss': 0.2093464115177428}
2022-12-31 08:12:29,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:29,905 INFO:     Epoch: 21
2022-12-31 08:12:31,519 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.27096122205257417, 'Total loss': 0.27096122205257417} | train loss {'Reaction outcome loss': 0.20457001242124828, 'Total loss': 0.20457001242124828}
2022-12-31 08:12:31,519 INFO:     Found new best model at epoch 21
2022-12-31 08:12:31,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:31,520 INFO:     Epoch: 22
2022-12-31 08:12:33,126 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.2697651647031307, 'Total loss': 0.2697651647031307} | train loss {'Reaction outcome loss': 0.20069290020063027, 'Total loss': 0.20069290020063027}
2022-12-31 08:12:33,126 INFO:     Found new best model at epoch 22
2022-12-31 08:12:33,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:33,127 INFO:     Epoch: 23
2022-12-31 08:12:34,728 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.2809045379360517, 'Total loss': 0.2809045379360517} | train loss {'Reaction outcome loss': 0.19498813436827162, 'Total loss': 0.19498813436827162}
2022-12-31 08:12:34,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:34,728 INFO:     Epoch: 24
2022-12-31 08:12:36,358 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.2810595492521922, 'Total loss': 0.2810595492521922} | train loss {'Reaction outcome loss': 0.18978504650977068, 'Total loss': 0.18978504650977068}
2022-12-31 08:12:36,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:36,359 INFO:     Epoch: 25
2022-12-31 08:12:37,971 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.29452956865231195, 'Total loss': 0.29452956865231195} | train loss {'Reaction outcome loss': 0.18318307080439158, 'Total loss': 0.18318307080439158}
2022-12-31 08:12:37,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:37,971 INFO:     Epoch: 26
2022-12-31 08:12:39,583 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.2923505416760842, 'Total loss': 0.2923505416760842} | train loss {'Reaction outcome loss': 0.18473993933626584, 'Total loss': 0.18473993933626584}
2022-12-31 08:12:39,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:39,583 INFO:     Epoch: 27
2022-12-31 08:12:41,187 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3042426899075508, 'Total loss': 0.3042426899075508} | train loss {'Reaction outcome loss': 0.17835967302076763, 'Total loss': 0.17835967302076763}
2022-12-31 08:12:41,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:41,188 INFO:     Epoch: 28
2022-12-31 08:12:42,793 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3322082906961441, 'Total loss': 0.3322082906961441} | train loss {'Reaction outcome loss': 0.17423712609560935, 'Total loss': 0.17423712609560935}
2022-12-31 08:12:42,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:42,794 INFO:     Epoch: 29
2022-12-31 08:12:44,406 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3352655331293742, 'Total loss': 0.3352655331293742} | train loss {'Reaction outcome loss': 0.17353554522693704, 'Total loss': 0.17353554522693704}
2022-12-31 08:12:44,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:44,406 INFO:     Epoch: 30
2022-12-31 08:12:46,020 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.331431928028663, 'Total loss': 0.331431928028663} | train loss {'Reaction outcome loss': 0.16963137883263138, 'Total loss': 0.16963137883263138}
2022-12-31 08:12:46,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:46,020 INFO:     Epoch: 31
2022-12-31 08:12:47,632 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.29332891007264456, 'Total loss': 0.29332891007264456} | train loss {'Reaction outcome loss': 0.16611997990258337, 'Total loss': 0.16611997990258337}
2022-12-31 08:12:47,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:47,632 INFO:     Epoch: 32
2022-12-31 08:12:49,239 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.2910389080643654, 'Total loss': 0.2910389080643654} | train loss {'Reaction outcome loss': 0.16676909322321634, 'Total loss': 0.16676909322321634}
2022-12-31 08:12:49,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:49,240 INFO:     Epoch: 33
2022-12-31 08:12:50,856 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.30560281972090403, 'Total loss': 0.30560281972090403} | train loss {'Reaction outcome loss': 0.1625357110107884, 'Total loss': 0.1625357110107884}
2022-12-31 08:12:50,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:50,857 INFO:     Epoch: 34
2022-12-31 08:12:52,447 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.2929832052439451, 'Total loss': 0.2929832052439451} | train loss {'Reaction outcome loss': 0.16303252742622362, 'Total loss': 0.16303252742622362}
2022-12-31 08:12:52,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:52,447 INFO:     Epoch: 35
2022-12-31 08:12:54,043 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.28738128977517285, 'Total loss': 0.28738128977517285} | train loss {'Reaction outcome loss': 0.1584414035702745, 'Total loss': 0.1584414035702745}
2022-12-31 08:12:54,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:54,043 INFO:     Epoch: 36
2022-12-31 08:12:55,687 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3190889522433281, 'Total loss': 0.3190889522433281} | train loss {'Reaction outcome loss': 0.15985980404254335, 'Total loss': 0.15985980404254335}
2022-12-31 08:12:55,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:55,688 INFO:     Epoch: 37
2022-12-31 08:12:57,333 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3019534523288409, 'Total loss': 0.3019534523288409} | train loss {'Reaction outcome loss': 0.15917859898859654, 'Total loss': 0.15917859898859654}
2022-12-31 08:12:57,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:57,333 INFO:     Epoch: 38
2022-12-31 08:12:58,945 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.2965449129541715, 'Total loss': 0.2965449129541715} | train loss {'Reaction outcome loss': 0.15146903544937299, 'Total loss': 0.15146903544937299}
2022-12-31 08:12:58,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:12:58,946 INFO:     Epoch: 39
2022-12-31 08:13:00,536 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.30664875780542694, 'Total loss': 0.30664875780542694} | train loss {'Reaction outcome loss': 0.14638623012052404, 'Total loss': 0.14638623012052404}
2022-12-31 08:13:00,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:00,537 INFO:     Epoch: 40
2022-12-31 08:13:02,131 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3150602872172991, 'Total loss': 0.3150602872172991} | train loss {'Reaction outcome loss': 0.1502014974698479, 'Total loss': 0.1502014974698479}
2022-12-31 08:13:02,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:02,132 INFO:     Epoch: 41
2022-12-31 08:13:03,726 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.29771191626787186, 'Total loss': 0.29771191626787186} | train loss {'Reaction outcome loss': 0.1466812097788157, 'Total loss': 0.1466812097788157}
2022-12-31 08:13:03,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:03,726 INFO:     Epoch: 42
2022-12-31 08:13:05,371 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.34585567538936934, 'Total loss': 0.34585567538936934} | train loss {'Reaction outcome loss': 0.14379316945679677, 'Total loss': 0.14379316945679677}
2022-12-31 08:13:05,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:05,371 INFO:     Epoch: 43
2022-12-31 08:13:06,966 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.2870323707660039, 'Total loss': 0.2870323707660039} | train loss {'Reaction outcome loss': 0.14457375866799332, 'Total loss': 0.14457375866799332}
2022-12-31 08:13:06,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:06,966 INFO:     Epoch: 44
2022-12-31 08:13:08,568 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.2720897078514099, 'Total loss': 0.2720897078514099} | train loss {'Reaction outcome loss': 0.14053451835993172, 'Total loss': 0.14053451835993172}
2022-12-31 08:13:08,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:08,568 INFO:     Epoch: 45
2022-12-31 08:13:10,186 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.310435343409578, 'Total loss': 0.310435343409578} | train loss {'Reaction outcome loss': 0.13955250041791317, 'Total loss': 0.13955250041791317}
2022-12-31 08:13:10,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:10,186 INFO:     Epoch: 46
2022-12-31 08:13:11,786 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.29448940853277844, 'Total loss': 0.29448940853277844} | train loss {'Reaction outcome loss': 0.14009909014023103, 'Total loss': 0.14009909014023103}
2022-12-31 08:13:11,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:11,786 INFO:     Epoch: 47
2022-12-31 08:13:13,431 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.30488292425870894, 'Total loss': 0.30488292425870894} | train loss {'Reaction outcome loss': 0.13780178263102874, 'Total loss': 0.13780178263102874}
2022-12-31 08:13:13,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:13,432 INFO:     Epoch: 48
2022-12-31 08:13:15,033 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3082653363545736, 'Total loss': 0.3082653363545736} | train loss {'Reaction outcome loss': 0.1410669366685817, 'Total loss': 0.1410669366685817}
2022-12-31 08:13:15,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:15,033 INFO:     Epoch: 49
2022-12-31 08:13:16,655 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.29670239190260567, 'Total loss': 0.29670239190260567} | train loss {'Reaction outcome loss': 0.13852392175941022, 'Total loss': 0.13852392175941022}
2022-12-31 08:13:16,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:16,655 INFO:     Epoch: 50
2022-12-31 08:13:18,298 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.27145091419418654, 'Total loss': 0.27145091419418654} | train loss {'Reaction outcome loss': 0.13456276188444197, 'Total loss': 0.13456276188444197}
2022-12-31 08:13:18,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:18,299 INFO:     Epoch: 51
2022-12-31 08:13:19,897 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.32864742577075956, 'Total loss': 0.32864742577075956} | train loss {'Reaction outcome loss': 0.13284168415617592, 'Total loss': 0.13284168415617592}
2022-12-31 08:13:19,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:19,898 INFO:     Epoch: 52
2022-12-31 08:13:21,506 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.27467533672849337, 'Total loss': 0.27467533672849337} | train loss {'Reaction outcome loss': 0.13680116651791246, 'Total loss': 0.13680116651791246}
2022-12-31 08:13:21,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:21,506 INFO:     Epoch: 53
2022-12-31 08:13:23,115 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3262308776378632, 'Total loss': 0.3262308776378632} | train loss {'Reaction outcome loss': 0.13576298664006722, 'Total loss': 0.13576298664006722}
2022-12-31 08:13:23,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:23,115 INFO:     Epoch: 54
2022-12-31 08:13:24,723 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.2860119712849458, 'Total loss': 0.2860119712849458} | train loss {'Reaction outcome loss': 0.13424695235499667, 'Total loss': 0.13424695235499667}
2022-12-31 08:13:24,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:24,723 INFO:     Epoch: 55
2022-12-31 08:13:26,341 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35111755803227424, 'Total loss': 0.35111755803227424} | train loss {'Reaction outcome loss': 0.12982105672011499, 'Total loss': 0.12982105672011499}
2022-12-31 08:13:26,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:26,342 INFO:     Epoch: 56
2022-12-31 08:13:27,967 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3193646817157666, 'Total loss': 0.3193646817157666} | train loss {'Reaction outcome loss': 0.12955636028098044, 'Total loss': 0.12955636028098044}
2022-12-31 08:13:27,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:27,968 INFO:     Epoch: 57
2022-12-31 08:13:29,612 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.2701698824763298, 'Total loss': 0.2701698824763298} | train loss {'Reaction outcome loss': 0.13248350403029405, 'Total loss': 0.13248350403029405}
2022-12-31 08:13:29,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:29,612 INFO:     Epoch: 58
2022-12-31 08:13:31,258 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3037902389963468, 'Total loss': 0.3037902389963468} | train loss {'Reaction outcome loss': 0.13077303456592854, 'Total loss': 0.13077303456592854}
2022-12-31 08:13:31,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:31,258 INFO:     Epoch: 59
2022-12-31 08:13:32,867 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.31916462555527686, 'Total loss': 0.31916462555527686} | train loss {'Reaction outcome loss': 0.1268361723766877, 'Total loss': 0.1268361723766877}
2022-12-31 08:13:32,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:32,868 INFO:     Epoch: 60
2022-12-31 08:13:34,469 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3012019624312719, 'Total loss': 0.3012019624312719} | train loss {'Reaction outcome loss': 0.12421946037874554, 'Total loss': 0.12421946037874554}
2022-12-31 08:13:34,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:34,469 INFO:     Epoch: 61
2022-12-31 08:13:36,068 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.27173497329155605, 'Total loss': 0.27173497329155605} | train loss {'Reaction outcome loss': 0.12138104229404731, 'Total loss': 0.12138104229404731}
2022-12-31 08:13:36,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:36,068 INFO:     Epoch: 62
2022-12-31 08:13:37,663 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.31516008675098417, 'Total loss': 0.31516008675098417} | train loss {'Reaction outcome loss': 0.12480094722700698, 'Total loss': 0.12480094722700698}
2022-12-31 08:13:37,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:37,663 INFO:     Epoch: 63
2022-12-31 08:13:39,274 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.2825507790471117, 'Total loss': 0.2825507790471117} | train loss {'Reaction outcome loss': 0.12848024026937646, 'Total loss': 0.12848024026937646}
2022-12-31 08:13:39,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:39,274 INFO:     Epoch: 64
2022-12-31 08:13:40,886 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.303397632141908, 'Total loss': 0.303397632141908} | train loss {'Reaction outcome loss': 0.126666583405678, 'Total loss': 0.126666583405678}
2022-12-31 08:13:40,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:40,886 INFO:     Epoch: 65
2022-12-31 08:13:42,495 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.29697065651416776, 'Total loss': 0.29697065651416776} | train loss {'Reaction outcome loss': 0.1246688979841605, 'Total loss': 0.1246688979841605}
2022-12-31 08:13:42,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:42,495 INFO:     Epoch: 66
2022-12-31 08:13:44,119 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3039442057410876, 'Total loss': 0.3039442057410876} | train loss {'Reaction outcome loss': 0.13190072349480766, 'Total loss': 0.13190072349480766}
2022-12-31 08:13:44,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:44,120 INFO:     Epoch: 67
2022-12-31 08:13:45,729 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.30918635378281273, 'Total loss': 0.30918635378281273} | train loss {'Reaction outcome loss': 0.12378286478031195, 'Total loss': 0.12378286478031195}
2022-12-31 08:13:45,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:45,729 INFO:     Epoch: 68
2022-12-31 08:13:47,316 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.2985586514075597, 'Total loss': 0.2985586514075597} | train loss {'Reaction outcome loss': 0.1289350310333701, 'Total loss': 0.1289350310333701}
2022-12-31 08:13:47,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:47,317 INFO:     Epoch: 69
2022-12-31 08:13:48,916 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3014058937629064, 'Total loss': 0.3014058937629064} | train loss {'Reaction outcome loss': 0.12112453496663561, 'Total loss': 0.12112453496663561}
2022-12-31 08:13:48,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:48,917 INFO:     Epoch: 70
2022-12-31 08:13:50,564 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.2869356647133827, 'Total loss': 0.2869356647133827} | train loss {'Reaction outcome loss': 0.12253079851048797, 'Total loss': 0.12253079851048797}
2022-12-31 08:13:50,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:50,565 INFO:     Epoch: 71
2022-12-31 08:13:52,166 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3214204773306847, 'Total loss': 0.3214204773306847} | train loss {'Reaction outcome loss': 0.11937336748442015, 'Total loss': 0.11937336748442015}
2022-12-31 08:13:52,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:52,166 INFO:     Epoch: 72
2022-12-31 08:13:53,779 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.29671284059683484, 'Total loss': 0.29671284059683484} | train loss {'Reaction outcome loss': 0.12263004996066729, 'Total loss': 0.12263004996066729}
2022-12-31 08:13:53,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:53,779 INFO:     Epoch: 73
2022-12-31 08:13:55,384 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.27880257467428843, 'Total loss': 0.27880257467428843} | train loss {'Reaction outcome loss': 0.12223704743767055, 'Total loss': 0.12223704743767055}
2022-12-31 08:13:55,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:55,384 INFO:     Epoch: 74
2022-12-31 08:13:56,996 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.316811399658521, 'Total loss': 0.316811399658521} | train loss {'Reaction outcome loss': 0.11609317757694167, 'Total loss': 0.11609317757694167}
2022-12-31 08:13:56,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:56,997 INFO:     Epoch: 75
2022-12-31 08:13:58,611 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3212443381547928, 'Total loss': 0.3212443381547928} | train loss {'Reaction outcome loss': 0.11706104078381271, 'Total loss': 0.11706104078381271}
2022-12-31 08:13:58,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:13:58,611 INFO:     Epoch: 76
2022-12-31 08:14:00,225 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35630967368682226, 'Total loss': 0.35630967368682226} | train loss {'Reaction outcome loss': 0.11954277657456833, 'Total loss': 0.11954277657456833}
2022-12-31 08:14:00,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:00,225 INFO:     Epoch: 77
2022-12-31 08:14:01,834 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.2796295245488485, 'Total loss': 0.2796295245488485} | train loss {'Reaction outcome loss': 0.1203483008854637, 'Total loss': 0.1203483008854637}
2022-12-31 08:14:01,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:01,834 INFO:     Epoch: 78
2022-12-31 08:14:03,429 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.33803528596957527, 'Total loss': 0.33803528596957527} | train loss {'Reaction outcome loss': 0.11692651096989841, 'Total loss': 0.11692651096989841}
2022-12-31 08:14:03,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:03,430 INFO:     Epoch: 79
2022-12-31 08:14:05,034 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3270657648642858, 'Total loss': 0.3270657648642858} | train loss {'Reaction outcome loss': 0.11847965066890905, 'Total loss': 0.11847965066890905}
2022-12-31 08:14:05,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:05,034 INFO:     Epoch: 80
2022-12-31 08:14:06,648 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.29987586438655855, 'Total loss': 0.29987586438655855} | train loss {'Reaction outcome loss': 0.11754278062958776, 'Total loss': 0.11754278062958776}
2022-12-31 08:14:06,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:06,648 INFO:     Epoch: 81
2022-12-31 08:14:08,261 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.29009488262236116, 'Total loss': 0.29009488262236116} | train loss {'Reaction outcome loss': 0.12064732123770147, 'Total loss': 0.12064732123770147}
2022-12-31 08:14:08,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:08,261 INFO:     Epoch: 82
2022-12-31 08:14:09,874 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.31413034979098786, 'Total loss': 0.31413034979098786} | train loss {'Reaction outcome loss': 0.11722420041463014, 'Total loss': 0.11722420041463014}
2022-12-31 08:14:09,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:09,874 INFO:     Epoch: 83
2022-12-31 08:14:11,488 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.302928268785278, 'Total loss': 0.302928268785278} | train loss {'Reaction outcome loss': 0.11910005356696854, 'Total loss': 0.11910005356696854}
2022-12-31 08:14:11,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:11,488 INFO:     Epoch: 84
2022-12-31 08:14:13,137 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.2854942341645559, 'Total loss': 0.2854942341645559} | train loss {'Reaction outcome loss': 0.11951001379604796, 'Total loss': 0.11951001379604796}
2022-12-31 08:14:13,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:13,137 INFO:     Epoch: 85
2022-12-31 08:14:14,776 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3011771226922671, 'Total loss': 0.3011771226922671} | train loss {'Reaction outcome loss': 0.11685079333181374, 'Total loss': 0.11685079333181374}
2022-12-31 08:14:14,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:14,777 INFO:     Epoch: 86
2022-12-31 08:14:16,377 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.32164650137225786, 'Total loss': 0.32164650137225786} | train loss {'Reaction outcome loss': 0.1153207662286776, 'Total loss': 0.1153207662286776}
2022-12-31 08:14:16,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:16,377 INFO:     Epoch: 87
2022-12-31 08:14:18,026 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.2911750381191572, 'Total loss': 0.2911750381191572} | train loss {'Reaction outcome loss': 0.11532032429735302, 'Total loss': 0.11532032429735302}
2022-12-31 08:14:18,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:18,027 INFO:     Epoch: 88
2022-12-31 08:14:19,675 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.30244231472412747, 'Total loss': 0.30244231472412747} | train loss {'Reaction outcome loss': 0.11659880057864246, 'Total loss': 0.11659880057864246}
2022-12-31 08:14:19,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:19,675 INFO:     Epoch: 89
2022-12-31 08:14:21,282 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.32385920484860736, 'Total loss': 0.32385920484860736} | train loss {'Reaction outcome loss': 0.11161025268991133, 'Total loss': 0.11161025268991133}
2022-12-31 08:14:21,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:21,283 INFO:     Epoch: 90
2022-12-31 08:14:22,890 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.2898842898507913, 'Total loss': 0.2898842898507913} | train loss {'Reaction outcome loss': 0.11178710026838799, 'Total loss': 0.11178710026838799}
2022-12-31 08:14:22,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:22,891 INFO:     Epoch: 91
2022-12-31 08:14:24,496 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3233921468257904, 'Total loss': 0.3233921468257904} | train loss {'Reaction outcome loss': 0.1202461208854785, 'Total loss': 0.1202461208854785}
2022-12-31 08:14:24,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:24,496 INFO:     Epoch: 92
2022-12-31 08:14:26,146 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.30335039148728055, 'Total loss': 0.30335039148728055} | train loss {'Reaction outcome loss': 0.12315252963317073, 'Total loss': 0.12315252963317073}
2022-12-31 08:14:26,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:26,146 INFO:     Epoch: 93
2022-12-31 08:14:27,794 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3196477144956589, 'Total loss': 0.3196477144956589} | train loss {'Reaction outcome loss': 0.11804129929203308, 'Total loss': 0.11804129929203308}
2022-12-31 08:14:27,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:27,795 INFO:     Epoch: 94
2022-12-31 08:14:29,432 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3202757486452659, 'Total loss': 0.3202757486452659} | train loss {'Reaction outcome loss': 0.11437286440992639, 'Total loss': 0.11437286440992639}
2022-12-31 08:14:29,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:29,432 INFO:     Epoch: 95
2022-12-31 08:14:31,032 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.344868458310763, 'Total loss': 0.344868458310763} | train loss {'Reaction outcome loss': 0.11217502552859021, 'Total loss': 0.11217502552859021}
2022-12-31 08:14:31,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:31,032 INFO:     Epoch: 96
2022-12-31 08:14:32,635 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3119610110918681, 'Total loss': 0.3119610110918681} | train loss {'Reaction outcome loss': 0.11410801995617266, 'Total loss': 0.11410801995617266}
2022-12-31 08:14:32,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:32,635 INFO:     Epoch: 97
2022-12-31 08:14:34,250 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.2765184797346592, 'Total loss': 0.2765184797346592} | train loss {'Reaction outcome loss': 0.1088492627896969, 'Total loss': 0.1088492627896969}
2022-12-31 08:14:34,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:34,251 INFO:     Epoch: 98
2022-12-31 08:14:35,859 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3065460364023844, 'Total loss': 0.3065460364023844} | train loss {'Reaction outcome loss': 0.11105286613134019, 'Total loss': 0.11105286613134019}
2022-12-31 08:14:35,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:35,860 INFO:     Epoch: 99
2022-12-31 08:14:37,474 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.2999804988503456, 'Total loss': 0.2999804988503456} | train loss {'Reaction outcome loss': 0.11131188694486606, 'Total loss': 0.11131188694486606}
2022-12-31 08:14:37,474 INFO:     Best model found after epoch 23 of 100.
2022-12-31 08:14:37,474 INFO:   Done with stage: TRAINING
2022-12-31 08:14:37,474 INFO:   Starting stage: EVALUATION
2022-12-31 08:14:37,619 INFO:   Done with stage: EVALUATION
2022-12-31 08:14:37,619 INFO:   Leaving out SEQ value Fold_2
2022-12-31 08:14:37,632 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 08:14:37,632 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:14:38,268 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:14:38,268 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:14:38,335 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:14:38,335 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:14:38,335 INFO:     No hyperparam tuning for this model
2022-12-31 08:14:38,335 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:14:38,335 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:14:38,336 INFO:     None feature selector for col prot
2022-12-31 08:14:38,336 INFO:     None feature selector for col prot
2022-12-31 08:14:38,336 INFO:     None feature selector for col prot
2022-12-31 08:14:38,337 INFO:     None feature selector for col chem
2022-12-31 08:14:38,337 INFO:     None feature selector for col chem
2022-12-31 08:14:38,337 INFO:     None feature selector for col chem
2022-12-31 08:14:38,337 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:14:38,337 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:14:38,339 INFO:     Number of params in model 224011
2022-12-31 08:14:38,342 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:14:38,342 INFO:   Starting stage: TRAINING
2022-12-31 08:14:38,387 INFO:     Val loss before train {'Reaction outcome loss': 1.0300012509028116, 'Total loss': 1.0300012509028116}
2022-12-31 08:14:38,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:38,387 INFO:     Epoch: 0
2022-12-31 08:14:40,007 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.563178555170695, 'Total loss': 0.563178555170695} | train loss {'Reaction outcome loss': 0.7899656448636988, 'Total loss': 0.7899656448636988}
2022-12-31 08:14:40,007 INFO:     Found new best model at epoch 0
2022-12-31 08:14:40,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:40,008 INFO:     Epoch: 1
2022-12-31 08:14:41,626 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46976406673590343, 'Total loss': 0.46976406673590343} | train loss {'Reaction outcome loss': 0.5292751739605767, 'Total loss': 0.5292751739605767}
2022-12-31 08:14:41,626 INFO:     Found new best model at epoch 1
2022-12-31 08:14:41,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:41,627 INFO:     Epoch: 2
2022-12-31 08:14:43,220 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4287870610753695, 'Total loss': 0.4287870610753695} | train loss {'Reaction outcome loss': 0.45701144481717, 'Total loss': 0.45701144481717}
2022-12-31 08:14:43,220 INFO:     Found new best model at epoch 2
2022-12-31 08:14:43,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:43,221 INFO:     Epoch: 3
2022-12-31 08:14:44,816 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41818930904070534, 'Total loss': 0.41818930904070534} | train loss {'Reaction outcome loss': 0.4144683706529466, 'Total loss': 0.4144683706529466}
2022-12-31 08:14:44,816 INFO:     Found new best model at epoch 3
2022-12-31 08:14:44,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:44,818 INFO:     Epoch: 4
2022-12-31 08:14:46,412 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4000236670176188, 'Total loss': 0.4000236670176188} | train loss {'Reaction outcome loss': 0.3832931100662344, 'Total loss': 0.3832931100662344}
2022-12-31 08:14:46,412 INFO:     Found new best model at epoch 4
2022-12-31 08:14:46,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:46,413 INFO:     Epoch: 5
2022-12-31 08:14:48,030 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41100061535835264, 'Total loss': 0.41100061535835264} | train loss {'Reaction outcome loss': 0.35626666104881527, 'Total loss': 0.35626666104881527}
2022-12-31 08:14:48,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:48,031 INFO:     Epoch: 6
2022-12-31 08:14:49,624 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4000471929709117, 'Total loss': 0.4000471929709117} | train loss {'Reaction outcome loss': 0.33591652309652625, 'Total loss': 0.33591652309652625}
2022-12-31 08:14:49,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:49,624 INFO:     Epoch: 7
2022-12-31 08:14:51,215 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39549056043227515, 'Total loss': 0.39549056043227515} | train loss {'Reaction outcome loss': 0.31737805759994747, 'Total loss': 0.31737805759994747}
2022-12-31 08:14:51,216 INFO:     Found new best model at epoch 7
2022-12-31 08:14:51,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:51,217 INFO:     Epoch: 8
2022-12-31 08:14:52,814 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40904600024223325, 'Total loss': 0.40904600024223325} | train loss {'Reaction outcome loss': 0.3010332832367218, 'Total loss': 0.3010332832367218}
2022-12-31 08:14:52,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:52,815 INFO:     Epoch: 9
2022-12-31 08:14:54,414 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4268948624531428, 'Total loss': 0.4268948624531428} | train loss {'Reaction outcome loss': 0.2876872778543687, 'Total loss': 0.2876872778543687}
2022-12-31 08:14:54,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:54,414 INFO:     Epoch: 10
2022-12-31 08:14:56,014 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4194459040959676, 'Total loss': 0.4194459040959676} | train loss {'Reaction outcome loss': 0.2723045989568603, 'Total loss': 0.2723045989568603}
2022-12-31 08:14:56,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:56,014 INFO:     Epoch: 11
2022-12-31 08:14:57,602 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3796116679906845, 'Total loss': 0.3796116679906845} | train loss {'Reaction outcome loss': 0.2642971452779216, 'Total loss': 0.2642971452779216}
2022-12-31 08:14:57,602 INFO:     Found new best model at epoch 11
2022-12-31 08:14:57,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:57,603 INFO:     Epoch: 12
2022-12-31 08:14:59,189 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38615276515483854, 'Total loss': 0.38615276515483854} | train loss {'Reaction outcome loss': 0.2499346216501345, 'Total loss': 0.2499346216501345}
2022-12-31 08:14:59,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:14:59,189 INFO:     Epoch: 13
2022-12-31 08:15:00,789 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41881826718648274, 'Total loss': 0.41881826718648274} | train loss {'Reaction outcome loss': 0.24306144801782945, 'Total loss': 0.24306144801782945}
2022-12-31 08:15:00,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:00,790 INFO:     Epoch: 14
2022-12-31 08:15:02,388 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4175481632351875, 'Total loss': 0.4175481632351875} | train loss {'Reaction outcome loss': 0.22970916039389438, 'Total loss': 0.22970916039389438}
2022-12-31 08:15:02,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:02,388 INFO:     Epoch: 15
2022-12-31 08:15:03,987 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38042450944582623, 'Total loss': 0.38042450944582623} | train loss {'Reaction outcome loss': 0.22639513905142947, 'Total loss': 0.22639513905142947}
2022-12-31 08:15:03,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:03,987 INFO:     Epoch: 16
2022-12-31 08:15:05,583 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4073380211989085, 'Total loss': 0.4073380211989085} | train loss {'Reaction outcome loss': 0.21596239588989763, 'Total loss': 0.21596239588989763}
2022-12-31 08:15:05,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:05,583 INFO:     Epoch: 17
2022-12-31 08:15:07,202 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40730443596839905, 'Total loss': 0.40730443596839905} | train loss {'Reaction outcome loss': 0.21300803550357528, 'Total loss': 0.21300803550357528}
2022-12-31 08:15:07,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:07,203 INFO:     Epoch: 18
2022-12-31 08:15:08,822 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4173532714446386, 'Total loss': 0.4173532714446386} | train loss {'Reaction outcome loss': 0.20406059066445406, 'Total loss': 0.20406059066445406}
2022-12-31 08:15:08,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:08,822 INFO:     Epoch: 19
2022-12-31 08:15:10,426 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4241108347972234, 'Total loss': 0.4241108347972234} | train loss {'Reaction outcome loss': 0.2008204486399779, 'Total loss': 0.2008204486399779}
2022-12-31 08:15:10,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:10,427 INFO:     Epoch: 20
2022-12-31 08:15:12,028 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4115583340326945, 'Total loss': 0.4115583340326945} | train loss {'Reaction outcome loss': 0.1966596869717445, 'Total loss': 0.1966596869717445}
2022-12-31 08:15:12,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:12,028 INFO:     Epoch: 21
2022-12-31 08:15:13,630 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4355273485183716, 'Total loss': 0.4355273485183716} | train loss {'Reaction outcome loss': 0.1926043401592552, 'Total loss': 0.1926043401592552}
2022-12-31 08:15:13,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:13,630 INFO:     Epoch: 22
2022-12-31 08:15:15,225 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4170154710610708, 'Total loss': 0.4170154710610708} | train loss {'Reaction outcome loss': 0.17830371679360135, 'Total loss': 0.17830371679360135}
2022-12-31 08:15:15,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:15,225 INFO:     Epoch: 23
2022-12-31 08:15:16,835 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3814525634050369, 'Total loss': 0.3814525634050369} | train loss {'Reaction outcome loss': 0.18049199504578464, 'Total loss': 0.18049199504578464}
2022-12-31 08:15:16,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:16,835 INFO:     Epoch: 24
2022-12-31 08:15:18,413 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4069817324479421, 'Total loss': 0.4069817324479421} | train loss {'Reaction outcome loss': 0.1788158733810116, 'Total loss': 0.1788158733810116}
2022-12-31 08:15:18,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:18,414 INFO:     Epoch: 25
2022-12-31 08:15:20,050 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4133838951587677, 'Total loss': 0.4133838951587677} | train loss {'Reaction outcome loss': 0.17170723171636626, 'Total loss': 0.17170723171636626}
2022-12-31 08:15:20,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:20,051 INFO:     Epoch: 26
2022-12-31 08:15:21,688 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38259629532694817, 'Total loss': 0.38259629532694817} | train loss {'Reaction outcome loss': 0.16804328465291274, 'Total loss': 0.16804328465291274}
2022-12-31 08:15:21,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:21,689 INFO:     Epoch: 27
2022-12-31 08:15:23,277 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3918947771191597, 'Total loss': 0.3918947771191597} | train loss {'Reaction outcome loss': 0.1667869214614599, 'Total loss': 0.1667869214614599}
2022-12-31 08:15:23,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:23,277 INFO:     Epoch: 28
2022-12-31 08:15:24,900 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41011010805765785, 'Total loss': 0.41011010805765785} | train loss {'Reaction outcome loss': 0.1594941011179802, 'Total loss': 0.1594941011179802}
2022-12-31 08:15:24,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:24,900 INFO:     Epoch: 29
2022-12-31 08:15:26,492 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3745984736829996, 'Total loss': 0.3745984736829996} | train loss {'Reaction outcome loss': 0.15999259578400873, 'Total loss': 0.15999259578400873}
2022-12-31 08:15:26,492 INFO:     Found new best model at epoch 29
2022-12-31 08:15:26,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:26,493 INFO:     Epoch: 30
2022-12-31 08:15:28,084 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39668119450410205, 'Total loss': 0.39668119450410205} | train loss {'Reaction outcome loss': 0.15675677906213212, 'Total loss': 0.15675677906213212}
2022-12-31 08:15:28,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:28,084 INFO:     Epoch: 31
2022-12-31 08:15:29,773 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4097367137670517, 'Total loss': 0.4097367137670517} | train loss {'Reaction outcome loss': 0.15293314158091686, 'Total loss': 0.15293314158091686}
2022-12-31 08:15:29,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:29,773 INFO:     Epoch: 32
2022-12-31 08:15:31,375 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41704919586579003, 'Total loss': 0.41704919586579003} | train loss {'Reaction outcome loss': 0.15476284010122732, 'Total loss': 0.15476284010122732}
2022-12-31 08:15:31,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:31,376 INFO:     Epoch: 33
2022-12-31 08:15:32,972 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44461951951185863, 'Total loss': 0.44461951951185863} | train loss {'Reaction outcome loss': 0.15189701696424796, 'Total loss': 0.15189701696424796}
2022-12-31 08:15:32,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:32,972 INFO:     Epoch: 34
2022-12-31 08:15:34,574 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39569347351789474, 'Total loss': 0.39569347351789474} | train loss {'Reaction outcome loss': 0.14514623232000262, 'Total loss': 0.14514623232000262}
2022-12-31 08:15:34,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:34,575 INFO:     Epoch: 35
2022-12-31 08:15:36,179 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4157823383808136, 'Total loss': 0.4157823383808136} | train loss {'Reaction outcome loss': 0.1456472422632069, 'Total loss': 0.1456472422632069}
2022-12-31 08:15:36,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:36,179 INFO:     Epoch: 36
2022-12-31 08:15:37,796 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4382678300142288, 'Total loss': 0.4382678300142288} | train loss {'Reaction outcome loss': 0.14509354271613253, 'Total loss': 0.14509354271613253}
2022-12-31 08:15:37,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:37,796 INFO:     Epoch: 37
2022-12-31 08:15:39,402 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39733493824799854, 'Total loss': 0.39733493824799854} | train loss {'Reaction outcome loss': 0.148908870920154, 'Total loss': 0.148908870920154}
2022-12-31 08:15:39,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:39,402 INFO:     Epoch: 38
2022-12-31 08:15:41,007 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40161790971954664, 'Total loss': 0.40161790971954664} | train loss {'Reaction outcome loss': 0.14034174835460597, 'Total loss': 0.14034174835460597}
2022-12-31 08:15:41,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:41,008 INFO:     Epoch: 39
2022-12-31 08:15:42,611 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41056091835101444, 'Total loss': 0.41056091835101444} | train loss {'Reaction outcome loss': 0.13958537935303367, 'Total loss': 0.13958537935303367}
2022-12-31 08:15:42,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:42,612 INFO:     Epoch: 40
2022-12-31 08:15:44,221 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39756065954764686, 'Total loss': 0.39756065954764686} | train loss {'Reaction outcome loss': 0.13779033139018115, 'Total loss': 0.13779033139018115}
2022-12-31 08:15:44,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:44,221 INFO:     Epoch: 41
2022-12-31 08:15:45,845 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4109323223431905, 'Total loss': 0.4109323223431905} | train loss {'Reaction outcome loss': 0.1375841780211708, 'Total loss': 0.1375841780211708}
2022-12-31 08:15:45,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:45,845 INFO:     Epoch: 42
2022-12-31 08:15:47,480 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4227524161338806, 'Total loss': 0.4227524161338806} | train loss {'Reaction outcome loss': 0.13764160372509288, 'Total loss': 0.13764160372509288}
2022-12-31 08:15:47,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:47,481 INFO:     Epoch: 43
2022-12-31 08:15:49,117 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.427983579536279, 'Total loss': 0.427983579536279} | train loss {'Reaction outcome loss': 0.13252548300197203, 'Total loss': 0.13252548300197203}
2022-12-31 08:15:49,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:49,117 INFO:     Epoch: 44
2022-12-31 08:15:50,751 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4016046044727167, 'Total loss': 0.4016046044727167} | train loss {'Reaction outcome loss': 0.13295967706798736, 'Total loss': 0.13295967706798736}
2022-12-31 08:15:50,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:50,752 INFO:     Epoch: 45
2022-12-31 08:15:52,355 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4272106776634852, 'Total loss': 0.4272106776634852} | train loss {'Reaction outcome loss': 0.13156665230644146, 'Total loss': 0.13156665230644146}
2022-12-31 08:15:52,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:52,356 INFO:     Epoch: 46
2022-12-31 08:15:53,946 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41270326524972917, 'Total loss': 0.41270326524972917} | train loss {'Reaction outcome loss': 0.1332050810200317, 'Total loss': 0.1332050810200317}
2022-12-31 08:15:53,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:53,946 INFO:     Epoch: 47
2022-12-31 08:15:55,534 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4150820513566335, 'Total loss': 0.4150820513566335} | train loss {'Reaction outcome loss': 0.12804146363430852, 'Total loss': 0.12804146363430852}
2022-12-31 08:15:55,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:55,534 INFO:     Epoch: 48
2022-12-31 08:15:57,169 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.388329915702343, 'Total loss': 0.388329915702343} | train loss {'Reaction outcome loss': 0.12602977791880138, 'Total loss': 0.12602977791880138}
2022-12-31 08:15:57,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:57,169 INFO:     Epoch: 49
2022-12-31 08:15:58,758 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39142302762096126, 'Total loss': 0.39142302762096126} | train loss {'Reaction outcome loss': 0.12701589547482584, 'Total loss': 0.12701589547482584}
2022-12-31 08:15:58,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:15:58,759 INFO:     Epoch: 50
2022-12-31 08:16:00,347 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40816852847735086, 'Total loss': 0.40816852847735086} | train loss {'Reaction outcome loss': 0.12851479442315897, 'Total loss': 0.12851479442315897}
2022-12-31 08:16:00,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:00,347 INFO:     Epoch: 51
2022-12-31 08:16:01,954 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3794558247551322, 'Total loss': 0.3794558247551322} | train loss {'Reaction outcome loss': 0.1252354349257129, 'Total loss': 0.1252354349257129}
2022-12-31 08:16:01,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:01,954 INFO:     Epoch: 52
2022-12-31 08:16:03,551 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39819933474063873, 'Total loss': 0.39819933474063873} | train loss {'Reaction outcome loss': 0.12266788688467685, 'Total loss': 0.12266788688467685}
2022-12-31 08:16:03,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:03,551 INFO:     Epoch: 53
2022-12-31 08:16:05,154 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40027100816369054, 'Total loss': 0.40027100816369054} | train loss {'Reaction outcome loss': 0.11980424358636636, 'Total loss': 0.11980424358636636}
2022-12-31 08:16:05,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:05,154 INFO:     Epoch: 54
2022-12-31 08:16:06,757 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3819019720423967, 'Total loss': 0.3819019720423967} | train loss {'Reaction outcome loss': 0.12105595195026746, 'Total loss': 0.12105595195026746}
2022-12-31 08:16:06,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:06,758 INFO:     Epoch: 55
2022-12-31 08:16:08,363 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37196052813281616, 'Total loss': 0.37196052813281616} | train loss {'Reaction outcome loss': 0.1196828869805496, 'Total loss': 0.1196828869805496}
2022-12-31 08:16:08,363 INFO:     Found new best model at epoch 55
2022-12-31 08:16:08,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:08,364 INFO:     Epoch: 56
2022-12-31 08:16:09,957 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42041626075903576, 'Total loss': 0.42041626075903576} | train loss {'Reaction outcome loss': 0.1192101895761061, 'Total loss': 0.1192101895761061}
2022-12-31 08:16:09,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:09,958 INFO:     Epoch: 57
2022-12-31 08:16:11,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44393640756607056, 'Total loss': 0.44393640756607056} | train loss {'Reaction outcome loss': 0.12121973524636476, 'Total loss': 0.12121973524636476}
2022-12-31 08:16:11,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:11,545 INFO:     Epoch: 58
2022-12-31 08:16:13,137 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4896948480357726, 'Total loss': 0.4896948480357726} | train loss {'Reaction outcome loss': 0.11810467850478758, 'Total loss': 0.11810467850478758}
2022-12-31 08:16:13,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:13,137 INFO:     Epoch: 59
2022-12-31 08:16:14,772 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.438620455066363, 'Total loss': 0.438620455066363} | train loss {'Reaction outcome loss': 0.11514146857451633, 'Total loss': 0.11514146857451633}
2022-12-31 08:16:14,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:14,772 INFO:     Epoch: 60
2022-12-31 08:16:16,407 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4551618218421936, 'Total loss': 0.4551618218421936} | train loss {'Reaction outcome loss': 0.12022777933565508, 'Total loss': 0.12022777933565508}
2022-12-31 08:16:16,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:16,407 INFO:     Epoch: 61
2022-12-31 08:16:18,043 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45291271607081096, 'Total loss': 0.45291271607081096} | train loss {'Reaction outcome loss': 0.12031265991186633, 'Total loss': 0.12031265991186633}
2022-12-31 08:16:18,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:18,043 INFO:     Epoch: 62
2022-12-31 08:16:19,628 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44372764031092327, 'Total loss': 0.44372764031092327} | train loss {'Reaction outcome loss': 0.116891477719238, 'Total loss': 0.116891477719238}
2022-12-31 08:16:19,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:19,628 INFO:     Epoch: 63
2022-12-31 08:16:21,252 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4085996337234974, 'Total loss': 0.4085996337234974} | train loss {'Reaction outcome loss': 0.1159403558624599, 'Total loss': 0.1159403558624599}
2022-12-31 08:16:21,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:21,252 INFO:     Epoch: 64
2022-12-31 08:16:22,849 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42149698237578076, 'Total loss': 0.42149698237578076} | train loss {'Reaction outcome loss': 0.11487362387407969, 'Total loss': 0.11487362387407969}
2022-12-31 08:16:22,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:22,850 INFO:     Epoch: 65
2022-12-31 08:16:24,442 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41839070270458856, 'Total loss': 0.41839070270458856} | train loss {'Reaction outcome loss': 0.10766892733629724, 'Total loss': 0.10766892733629724}
2022-12-31 08:16:24,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:24,442 INFO:     Epoch: 66
2022-12-31 08:16:26,074 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4551379164059957, 'Total loss': 0.4551379164059957} | train loss {'Reaction outcome loss': 0.11315738955663854, 'Total loss': 0.11315738955663854}
2022-12-31 08:16:26,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:26,075 INFO:     Epoch: 67
2022-12-31 08:16:27,706 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4441696345806122, 'Total loss': 0.4441696345806122} | train loss {'Reaction outcome loss': 0.1106131817231374, 'Total loss': 0.1106131817231374}
2022-12-31 08:16:27,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:27,706 INFO:     Epoch: 68
2022-12-31 08:16:29,302 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4135775963465373, 'Total loss': 0.4135775963465373} | train loss {'Reaction outcome loss': 0.11133621049171995, 'Total loss': 0.11133621049171995}
2022-12-31 08:16:29,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:29,303 INFO:     Epoch: 69
2022-12-31 08:16:30,901 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3988347116857767, 'Total loss': 0.3988347116857767} | train loss {'Reaction outcome loss': 0.1086967538542207, 'Total loss': 0.1086967538542207}
2022-12-31 08:16:30,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:30,902 INFO:     Epoch: 70
2022-12-31 08:16:32,491 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4540789360801379, 'Total loss': 0.4540789360801379} | train loss {'Reaction outcome loss': 0.11091211241776489, 'Total loss': 0.11091211241776489}
2022-12-31 08:16:32,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:32,492 INFO:     Epoch: 71
2022-12-31 08:16:34,124 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4340601623058319, 'Total loss': 0.4340601623058319} | train loss {'Reaction outcome loss': 0.11262051277962339, 'Total loss': 0.11262051277962339}
2022-12-31 08:16:34,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:34,124 INFO:     Epoch: 72
2022-12-31 08:16:35,757 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44951982200145724, 'Total loss': 0.44951982200145724} | train loss {'Reaction outcome loss': 0.11304289939198162, 'Total loss': 0.11304289939198162}
2022-12-31 08:16:35,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:35,757 INFO:     Epoch: 73
2022-12-31 08:16:37,386 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39229087146619956, 'Total loss': 0.39229087146619956} | train loss {'Reaction outcome loss': 0.1087773044256844, 'Total loss': 0.1087773044256844}
2022-12-31 08:16:37,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:37,386 INFO:     Epoch: 74
2022-12-31 08:16:39,010 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41606265902519224, 'Total loss': 0.41606265902519224} | train loss {'Reaction outcome loss': 0.10924078282475733, 'Total loss': 0.10924078282475733}
2022-12-31 08:16:39,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:39,010 INFO:     Epoch: 75
2022-12-31 08:16:40,587 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3905512347196539, 'Total loss': 0.3905512347196539} | train loss {'Reaction outcome loss': 0.10951434621910437, 'Total loss': 0.10951434621910437}
2022-12-31 08:16:40,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:40,588 INFO:     Epoch: 76
2022-12-31 08:16:42,221 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46316497325897216, 'Total loss': 0.46316497325897216} | train loss {'Reaction outcome loss': 0.10732444279528192, 'Total loss': 0.10732444279528192}
2022-12-31 08:16:42,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:42,222 INFO:     Epoch: 77
2022-12-31 08:16:43,805 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40661266843477883, 'Total loss': 0.40661266843477883} | train loss {'Reaction outcome loss': 0.10617177901150336, 'Total loss': 0.10617177901150336}
2022-12-31 08:16:43,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:43,805 INFO:     Epoch: 78
2022-12-31 08:16:45,438 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41571749467402697, 'Total loss': 0.41571749467402697} | train loss {'Reaction outcome loss': 0.10859571980841705, 'Total loss': 0.10859571980841705}
2022-12-31 08:16:45,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:45,439 INFO:     Epoch: 79
2022-12-31 08:16:47,059 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4492653995752335, 'Total loss': 0.4492653995752335} | train loss {'Reaction outcome loss': 0.11172245863852576, 'Total loss': 0.11172245863852576}
2022-12-31 08:16:47,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:47,059 INFO:     Epoch: 80
2022-12-31 08:16:48,651 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42077162563800813, 'Total loss': 0.42077162563800813} | train loss {'Reaction outcome loss': 0.1080529572308146, 'Total loss': 0.1080529572308146}
2022-12-31 08:16:48,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:48,651 INFO:     Epoch: 81
2022-12-31 08:16:50,242 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4287363360325495, 'Total loss': 0.4287363360325495} | train loss {'Reaction outcome loss': 0.10863676280508375, 'Total loss': 0.10863676280508375}
2022-12-31 08:16:50,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:50,242 INFO:     Epoch: 82
2022-12-31 08:16:51,842 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40883938218466936, 'Total loss': 0.40883938218466936} | train loss {'Reaction outcome loss': 0.10744558060988509, 'Total loss': 0.10744558060988509}
2022-12-31 08:16:51,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:51,842 INFO:     Epoch: 83
2022-12-31 08:16:53,444 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4227221849684914, 'Total loss': 0.4227221849684914} | train loss {'Reaction outcome loss': 0.1073679076851349, 'Total loss': 0.1073679076851349}
2022-12-31 08:16:53,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:53,445 INFO:     Epoch: 84
2022-12-31 08:16:55,045 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44025886310264467, 'Total loss': 0.44025886310264467} | train loss {'Reaction outcome loss': 0.10776986271259804, 'Total loss': 0.10776986271259804}
2022-12-31 08:16:55,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:55,046 INFO:     Epoch: 85
2022-12-31 08:16:56,636 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44301657218796514, 'Total loss': 0.44301657218796514} | train loss {'Reaction outcome loss': 0.10551642125035976, 'Total loss': 0.10551642125035976}
2022-12-31 08:16:56,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:56,636 INFO:     Epoch: 86
2022-12-31 08:16:58,240 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4762842319905758, 'Total loss': 0.4762842319905758} | train loss {'Reaction outcome loss': 0.10360645612863295, 'Total loss': 0.10360645612863295}
2022-12-31 08:16:58,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:58,241 INFO:     Epoch: 87
2022-12-31 08:16:59,873 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4538165554404259, 'Total loss': 0.4538165554404259} | train loss {'Reaction outcome loss': 0.10650500004880845, 'Total loss': 0.10650500004880845}
2022-12-31 08:16:59,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:16:59,874 INFO:     Epoch: 88
2022-12-31 08:17:01,468 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45437955659193296, 'Total loss': 0.45437955659193296} | train loss {'Reaction outcome loss': 0.10533615046634418, 'Total loss': 0.10533615046634418}
2022-12-31 08:17:01,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:01,468 INFO:     Epoch: 89
2022-12-31 08:17:03,101 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4527172287305196, 'Total loss': 0.4527172287305196} | train loss {'Reaction outcome loss': 0.10395131442211293, 'Total loss': 0.10395131442211293}
2022-12-31 08:17:03,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:03,101 INFO:     Epoch: 90
2022-12-31 08:17:04,733 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41989259819189706, 'Total loss': 0.41989259819189706} | train loss {'Reaction outcome loss': 0.10457853280262148, 'Total loss': 0.10457853280262148}
2022-12-31 08:17:04,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:04,733 INFO:     Epoch: 91
2022-12-31 08:17:06,350 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45305118560791013, 'Total loss': 0.45305118560791013} | train loss {'Reaction outcome loss': 0.10854450403669733, 'Total loss': 0.10854450403669733}
2022-12-31 08:17:06,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:06,350 INFO:     Epoch: 92
2022-12-31 08:17:07,952 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46604617436726886, 'Total loss': 0.46604617436726886} | train loss {'Reaction outcome loss': 0.1081604633645268, 'Total loss': 0.1081604633645268}
2022-12-31 08:17:07,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:07,952 INFO:     Epoch: 93
2022-12-31 08:17:09,549 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47550662557284035, 'Total loss': 0.47550662557284035} | train loss {'Reaction outcome loss': 0.1026450634609248, 'Total loss': 0.1026450634609248}
2022-12-31 08:17:09,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:09,549 INFO:     Epoch: 94
2022-12-31 08:17:11,147 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43621150056521096, 'Total loss': 0.43621150056521096} | train loss {'Reaction outcome loss': 0.10351564061339959, 'Total loss': 0.10351564061339959}
2022-12-31 08:17:11,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:11,147 INFO:     Epoch: 95
2022-12-31 08:17:12,745 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43810011545817057, 'Total loss': 0.43810011545817057} | train loss {'Reaction outcome loss': 0.10537132145484697, 'Total loss': 0.10537132145484697}
2022-12-31 08:17:12,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:12,746 INFO:     Epoch: 96
2022-12-31 08:17:14,335 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4945540130138397, 'Total loss': 0.4945540130138397} | train loss {'Reaction outcome loss': 0.10500723153019385, 'Total loss': 0.10500723153019385}
2022-12-31 08:17:14,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:14,336 INFO:     Epoch: 97
2022-12-31 08:17:15,931 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4477594474951426, 'Total loss': 0.4477594474951426} | train loss {'Reaction outcome loss': 0.10127387833403513, 'Total loss': 0.10127387833403513}
2022-12-31 08:17:15,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:15,931 INFO:     Epoch: 98
2022-12-31 08:17:17,530 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46231997311115264, 'Total loss': 0.46231997311115264} | train loss {'Reaction outcome loss': 0.10398362688393747, 'Total loss': 0.10398362688393747}
2022-12-31 08:17:17,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:17,530 INFO:     Epoch: 99
2022-12-31 08:17:19,146 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4253718892733256, 'Total loss': 0.4253718892733256} | train loss {'Reaction outcome loss': 0.10162116187397817, 'Total loss': 0.10162116187397817}
2022-12-31 08:17:19,146 INFO:     Best model found after epoch 56 of 100.
2022-12-31 08:17:19,146 INFO:   Done with stage: TRAINING
2022-12-31 08:17:19,146 INFO:   Starting stage: EVALUATION
2022-12-31 08:17:19,294 INFO:   Done with stage: EVALUATION
2022-12-31 08:17:19,295 INFO:   Leaving out SEQ value Fold_3
2022-12-31 08:17:19,307 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 08:17:19,307 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:17:19,943 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:17:19,943 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:17:20,010 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:17:20,010 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:17:20,010 INFO:     No hyperparam tuning for this model
2022-12-31 08:17:20,010 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:17:20,010 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:17:20,011 INFO:     None feature selector for col prot
2022-12-31 08:17:20,011 INFO:     None feature selector for col prot
2022-12-31 08:17:20,011 INFO:     None feature selector for col prot
2022-12-31 08:17:20,012 INFO:     None feature selector for col chem
2022-12-31 08:17:20,012 INFO:     None feature selector for col chem
2022-12-31 08:17:20,012 INFO:     None feature selector for col chem
2022-12-31 08:17:20,012 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:17:20,012 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:17:20,014 INFO:     Number of params in model 224011
2022-12-31 08:17:20,017 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:17:20,017 INFO:   Starting stage: TRAINING
2022-12-31 08:17:20,062 INFO:     Val loss before train {'Reaction outcome loss': 1.0206037878990173, 'Total loss': 1.0206037878990173}
2022-12-31 08:17:20,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:20,062 INFO:     Epoch: 0
2022-12-31 08:17:21,698 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.555405569076538, 'Total loss': 0.555405569076538} | train loss {'Reaction outcome loss': 0.783546531287423, 'Total loss': 0.783546531287423}
2022-12-31 08:17:21,699 INFO:     Found new best model at epoch 0
2022-12-31 08:17:21,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:21,700 INFO:     Epoch: 1
2022-12-31 08:17:23,302 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47872530420621234, 'Total loss': 0.47872530420621234} | train loss {'Reaction outcome loss': 0.514520735038023, 'Total loss': 0.514520735038023}
2022-12-31 08:17:23,303 INFO:     Found new best model at epoch 1
2022-12-31 08:17:23,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:23,304 INFO:     Epoch: 2
2022-12-31 08:17:24,907 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45272424817085266, 'Total loss': 0.45272424817085266} | train loss {'Reaction outcome loss': 0.4419364896025101, 'Total loss': 0.4419364896025101}
2022-12-31 08:17:24,908 INFO:     Found new best model at epoch 2
2022-12-31 08:17:24,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:24,909 INFO:     Epoch: 3
2022-12-31 08:17:26,558 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4234968503316244, 'Total loss': 0.4234968503316244} | train loss {'Reaction outcome loss': 0.40841375555108933, 'Total loss': 0.40841375555108933}
2022-12-31 08:17:26,558 INFO:     Found new best model at epoch 3
2022-12-31 08:17:26,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:26,559 INFO:     Epoch: 4
2022-12-31 08:17:28,167 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42297107179959614, 'Total loss': 0.42297107179959614} | train loss {'Reaction outcome loss': 0.3787845606868067, 'Total loss': 0.3787845606868067}
2022-12-31 08:17:28,167 INFO:     Found new best model at epoch 4
2022-12-31 08:17:28,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:28,168 INFO:     Epoch: 5
2022-12-31 08:17:29,772 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3941252181927363, 'Total loss': 0.3941252181927363} | train loss {'Reaction outcome loss': 0.3560483898885929, 'Total loss': 0.3560483898885929}
2022-12-31 08:17:29,772 INFO:     Found new best model at epoch 5
2022-12-31 08:17:29,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:29,773 INFO:     Epoch: 6
2022-12-31 08:17:31,379 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42558132906754814, 'Total loss': 0.42558132906754814} | train loss {'Reaction outcome loss': 0.3376063964581185, 'Total loss': 0.3376063964581185}
2022-12-31 08:17:31,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:31,380 INFO:     Epoch: 7
2022-12-31 08:17:33,006 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40452637871106467, 'Total loss': 0.40452637871106467} | train loss {'Reaction outcome loss': 0.32028158310882365, 'Total loss': 0.32028158310882365}
2022-12-31 08:17:33,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:33,006 INFO:     Epoch: 8
2022-12-31 08:17:34,614 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4263238191604614, 'Total loss': 0.4263238191604614} | train loss {'Reaction outcome loss': 0.3024254620795811, 'Total loss': 0.3024254620795811}
2022-12-31 08:17:34,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:34,615 INFO:     Epoch: 9
2022-12-31 08:17:36,266 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3835832983255386, 'Total loss': 0.3835832983255386} | train loss {'Reaction outcome loss': 0.2882500733418839, 'Total loss': 0.2882500733418839}
2022-12-31 08:17:36,266 INFO:     Found new best model at epoch 9
2022-12-31 08:17:36,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:36,267 INFO:     Epoch: 10
2022-12-31 08:17:37,870 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.395016806324323, 'Total loss': 0.395016806324323} | train loss {'Reaction outcome loss': 0.27498156018555164, 'Total loss': 0.27498156018555164}
2022-12-31 08:17:37,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:37,871 INFO:     Epoch: 11
2022-12-31 08:17:39,472 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38285979529221853, 'Total loss': 0.38285979529221853} | train loss {'Reaction outcome loss': 0.2634687289378069, 'Total loss': 0.2634687289378069}
2022-12-31 08:17:39,472 INFO:     Found new best model at epoch 11
2022-12-31 08:17:39,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:39,473 INFO:     Epoch: 12
2022-12-31 08:17:41,074 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3730677197376887, 'Total loss': 0.3730677197376887} | train loss {'Reaction outcome loss': 0.25304659158263326, 'Total loss': 0.25304659158263326}
2022-12-31 08:17:41,074 INFO:     Found new best model at epoch 12
2022-12-31 08:17:41,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:41,075 INFO:     Epoch: 13
2022-12-31 08:17:42,691 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3914243459701538, 'Total loss': 0.3914243459701538} | train loss {'Reaction outcome loss': 0.2426451427358998, 'Total loss': 0.2426451427358998}
2022-12-31 08:17:42,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:42,691 INFO:     Epoch: 14
2022-12-31 08:17:44,297 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41388046741485596, 'Total loss': 0.41388046741485596} | train loss {'Reaction outcome loss': 0.232526258966566, 'Total loss': 0.232526258966566}
2022-12-31 08:17:44,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:44,298 INFO:     Epoch: 15
2022-12-31 08:17:45,914 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3736771156390508, 'Total loss': 0.3736771156390508} | train loss {'Reaction outcome loss': 0.22738155968704798, 'Total loss': 0.22738155968704798}
2022-12-31 08:17:45,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:45,914 INFO:     Epoch: 16
2022-12-31 08:17:47,520 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3903076569239298, 'Total loss': 0.3903076569239298} | train loss {'Reaction outcome loss': 0.21941683888707283, 'Total loss': 0.21941683888707283}
2022-12-31 08:17:47,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:47,521 INFO:     Epoch: 17
2022-12-31 08:17:49,170 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3701244945327441, 'Total loss': 0.3701244945327441} | train loss {'Reaction outcome loss': 0.2139751099281176, 'Total loss': 0.2139751099281176}
2022-12-31 08:17:49,170 INFO:     Found new best model at epoch 17
2022-12-31 08:17:49,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:49,172 INFO:     Epoch: 18
2022-12-31 08:17:50,769 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38650647550821304, 'Total loss': 0.38650647550821304} | train loss {'Reaction outcome loss': 0.20857598224015783, 'Total loss': 0.20857598224015783}
2022-12-31 08:17:50,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:50,769 INFO:     Epoch: 19
2022-12-31 08:17:52,404 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3596483136216799, 'Total loss': 0.3596483136216799} | train loss {'Reaction outcome loss': 0.20354800041506652, 'Total loss': 0.20354800041506652}
2022-12-31 08:17:52,404 INFO:     Found new best model at epoch 19
2022-12-31 08:17:52,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:52,405 INFO:     Epoch: 20
2022-12-31 08:17:54,010 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3854062964518865, 'Total loss': 0.3854062964518865} | train loss {'Reaction outcome loss': 0.19478829588441954, 'Total loss': 0.19478829588441954}
2022-12-31 08:17:54,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:54,011 INFO:     Epoch: 21
2022-12-31 08:17:55,660 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37282771865526837, 'Total loss': 0.37282771865526837} | train loss {'Reaction outcome loss': 0.1900723379744339, 'Total loss': 0.1900723379744339}
2022-12-31 08:17:55,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:55,660 INFO:     Epoch: 22
2022-12-31 08:17:57,263 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3635362058877945, 'Total loss': 0.3635362058877945} | train loss {'Reaction outcome loss': 0.1925211869023849, 'Total loss': 0.1925211869023849}
2022-12-31 08:17:57,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:57,263 INFO:     Epoch: 23
2022-12-31 08:17:58,913 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3976007789373398, 'Total loss': 0.3976007789373398} | train loss {'Reaction outcome loss': 0.18419924819583658, 'Total loss': 0.18419924819583658}
2022-12-31 08:17:58,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:17:58,913 INFO:     Epoch: 24
2022-12-31 08:18:00,519 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38520992547273636, 'Total loss': 0.38520992547273636} | train loss {'Reaction outcome loss': 0.1788324192574207, 'Total loss': 0.1788324192574207}
2022-12-31 08:18:00,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:00,520 INFO:     Epoch: 25
2022-12-31 08:18:02,139 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.36643350770076116, 'Total loss': 0.36643350770076116} | train loss {'Reaction outcome loss': 0.1737376423654602, 'Total loss': 0.1737376423654602}
2022-12-31 08:18:02,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:02,139 INFO:     Epoch: 26
2022-12-31 08:18:03,790 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36755467603604, 'Total loss': 0.36755467603604} | train loss {'Reaction outcome loss': 0.17172198633860497, 'Total loss': 0.17172198633860497}
2022-12-31 08:18:03,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:03,790 INFO:     Epoch: 27
2022-12-31 08:18:05,395 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37413398331652087, 'Total loss': 0.37413398331652087} | train loss {'Reaction outcome loss': 0.16665263532450164, 'Total loss': 0.16665263532450164}
2022-12-31 08:18:05,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:05,395 INFO:     Epoch: 28
2022-12-31 08:18:07,044 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3656600281596184, 'Total loss': 0.3656600281596184} | train loss {'Reaction outcome loss': 0.1668477814251992, 'Total loss': 0.1668477814251992}
2022-12-31 08:18:07,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:07,045 INFO:     Epoch: 29
2022-12-31 08:18:08,699 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39916161199410755, 'Total loss': 0.39916161199410755} | train loss {'Reaction outcome loss': 0.16304201087880418, 'Total loss': 0.16304201087880418}
2022-12-31 08:18:08,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:08,700 INFO:     Epoch: 30
2022-12-31 08:18:10,312 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3371112048625946, 'Total loss': 0.3371112048625946} | train loss {'Reaction outcome loss': 0.1563955996454061, 'Total loss': 0.1563955996454061}
2022-12-31 08:18:10,312 INFO:     Found new best model at epoch 30
2022-12-31 08:18:10,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:10,313 INFO:     Epoch: 31
2022-12-31 08:18:11,917 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41139420370260876, 'Total loss': 0.41139420370260876} | train loss {'Reaction outcome loss': 0.1548597510040731, 'Total loss': 0.1548597510040731}
2022-12-31 08:18:11,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:11,918 INFO:     Epoch: 32
2022-12-31 08:18:13,540 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3946477850278219, 'Total loss': 0.3946477850278219} | train loss {'Reaction outcome loss': 0.15604798994061067, 'Total loss': 0.15604798994061067}
2022-12-31 08:18:13,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:13,540 INFO:     Epoch: 33
2022-12-31 08:18:15,150 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35219302847981454, 'Total loss': 0.35219302847981454} | train loss {'Reaction outcome loss': 0.15116197008462826, 'Total loss': 0.15116197008462826}
2022-12-31 08:18:15,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:15,150 INFO:     Epoch: 34
2022-12-31 08:18:16,760 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3986907944083214, 'Total loss': 0.3986907944083214} | train loss {'Reaction outcome loss': 0.14652158659169057, 'Total loss': 0.14652158659169057}
2022-12-31 08:18:16,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:16,760 INFO:     Epoch: 35
2022-12-31 08:18:18,363 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3783620749910673, 'Total loss': 0.3783620749910673} | train loss {'Reaction outcome loss': 0.14678525590902045, 'Total loss': 0.14678525590902045}
2022-12-31 08:18:18,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:18,364 INFO:     Epoch: 36
2022-12-31 08:18:19,965 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37453484733899434, 'Total loss': 0.37453484733899434} | train loss {'Reaction outcome loss': 0.14353566121881026, 'Total loss': 0.14353566121881026}
2022-12-31 08:18:19,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:19,965 INFO:     Epoch: 37
2022-12-31 08:18:21,579 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3872308313846588, 'Total loss': 0.3872308313846588} | train loss {'Reaction outcome loss': 0.14398053880223502, 'Total loss': 0.14398053880223502}
2022-12-31 08:18:21,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:21,579 INFO:     Epoch: 38
2022-12-31 08:18:23,195 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3850895494222641, 'Total loss': 0.3850895494222641} | train loss {'Reaction outcome loss': 0.14101980274108095, 'Total loss': 0.14101980274108095}
2022-12-31 08:18:23,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:23,196 INFO:     Epoch: 39
2022-12-31 08:18:24,846 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3675076057513555, 'Total loss': 0.3675076057513555} | train loss {'Reaction outcome loss': 0.14231301685727207, 'Total loss': 0.14231301685727207}
2022-12-31 08:18:24,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:24,846 INFO:     Epoch: 40
2022-12-31 08:18:26,496 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3896812359491984, 'Total loss': 0.3896812359491984} | train loss {'Reaction outcome loss': 0.13934798909684332, 'Total loss': 0.13934798909684332}
2022-12-31 08:18:26,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:26,496 INFO:     Epoch: 41
2022-12-31 08:18:28,096 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38519029517968495, 'Total loss': 0.38519029517968495} | train loss {'Reaction outcome loss': 0.13648604850427512, 'Total loss': 0.13648604850427512}
2022-12-31 08:18:28,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:28,097 INFO:     Epoch: 42
2022-12-31 08:18:29,725 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3934734341998895, 'Total loss': 0.3934734341998895} | train loss {'Reaction outcome loss': 0.1319006822228323, 'Total loss': 0.1319006822228323}
2022-12-31 08:18:29,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:29,725 INFO:     Epoch: 43
2022-12-31 08:18:31,376 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3742783049742381, 'Total loss': 0.3742783049742381} | train loss {'Reaction outcome loss': 0.13389827269061474, 'Total loss': 0.13389827269061474}
2022-12-31 08:18:31,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:31,377 INFO:     Epoch: 44
2022-12-31 08:18:32,982 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3500675419035057, 'Total loss': 0.3500675419035057} | train loss {'Reaction outcome loss': 0.1378193227846148, 'Total loss': 0.1378193227846148}
2022-12-31 08:18:32,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:32,982 INFO:     Epoch: 45
2022-12-31 08:18:34,588 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4124931941429774, 'Total loss': 0.4124931941429774} | train loss {'Reaction outcome loss': 0.13196934290556578, 'Total loss': 0.13196934290556578}
2022-12-31 08:18:34,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:34,588 INFO:     Epoch: 46
2022-12-31 08:18:36,219 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38306248287359873, 'Total loss': 0.38306248287359873} | train loss {'Reaction outcome loss': 0.1357701718399342, 'Total loss': 0.1357701718399342}
2022-12-31 08:18:36,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:36,219 INFO:     Epoch: 47
2022-12-31 08:18:37,857 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3795288309144477, 'Total loss': 0.3795288309144477} | train loss {'Reaction outcome loss': 0.12986050738551974, 'Total loss': 0.12986050738551974}
2022-12-31 08:18:37,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:37,858 INFO:     Epoch: 48
2022-12-31 08:18:39,462 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3911653280258179, 'Total loss': 0.3911653280258179} | train loss {'Reaction outcome loss': 0.12940126861255263, 'Total loss': 0.12940126861255263}
2022-12-31 08:18:39,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:39,462 INFO:     Epoch: 49
2022-12-31 08:18:41,113 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4236365536848704, 'Total loss': 0.4236365536848704} | train loss {'Reaction outcome loss': 0.12729419010562182, 'Total loss': 0.12729419010562182}
2022-12-31 08:18:41,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:41,113 INFO:     Epoch: 50
2022-12-31 08:18:42,716 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38802333573500314, 'Total loss': 0.38802333573500314} | train loss {'Reaction outcome loss': 0.1283492217261861, 'Total loss': 0.1283492217261861}
2022-12-31 08:18:42,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:42,716 INFO:     Epoch: 51
2022-12-31 08:18:44,366 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39697795510292055, 'Total loss': 0.39697795510292055} | train loss {'Reaction outcome loss': 0.12445079552580732, 'Total loss': 0.12445079552580732}
2022-12-31 08:18:44,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:44,366 INFO:     Epoch: 52
2022-12-31 08:18:45,691 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38090182840824127, 'Total loss': 0.38090182840824127} | train loss {'Reaction outcome loss': 0.12529555747768142, 'Total loss': 0.12529555747768142}
2022-12-31 08:18:45,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:45,691 INFO:     Epoch: 53
2022-12-31 08:18:46,816 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3952172709318499, 'Total loss': 0.3952172709318499} | train loss {'Reaction outcome loss': 0.12419901371688792, 'Total loss': 0.12419901371688792}
2022-12-31 08:18:46,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:46,817 INFO:     Epoch: 54
2022-12-31 08:18:47,916 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37336441775163015, 'Total loss': 0.37336441775163015} | train loss {'Reaction outcome loss': 0.1233672316196327, 'Total loss': 0.1233672316196327}
2022-12-31 08:18:47,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:47,917 INFO:     Epoch: 55
2022-12-31 08:18:49,016 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41905670464038847, 'Total loss': 0.41905670464038847} | train loss {'Reaction outcome loss': 0.12371048935600658, 'Total loss': 0.12371048935600658}
2022-12-31 08:18:49,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:49,017 INFO:     Epoch: 56
2022-12-31 08:18:50,397 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37747619648774466, 'Total loss': 0.37747619648774466} | train loss {'Reaction outcome loss': 0.12358063432034513, 'Total loss': 0.12358063432034513}
2022-12-31 08:18:50,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:50,397 INFO:     Epoch: 57
2022-12-31 08:18:51,998 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3990183393160502, 'Total loss': 0.3990183393160502} | train loss {'Reaction outcome loss': 0.11907970016553698, 'Total loss': 0.11907970016553698}
2022-12-31 08:18:51,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:51,999 INFO:     Epoch: 58
2022-12-31 08:18:53,599 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3808833782871564, 'Total loss': 0.3808833782871564} | train loss {'Reaction outcome loss': 0.11935379425655153, 'Total loss': 0.11935379425655153}
2022-12-31 08:18:53,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:53,599 INFO:     Epoch: 59
2022-12-31 08:18:55,194 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3730091666181882, 'Total loss': 0.3730091666181882} | train loss {'Reaction outcome loss': 0.12295779564594646, 'Total loss': 0.12295779564594646}
2022-12-31 08:18:55,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:55,194 INFO:     Epoch: 60
2022-12-31 08:18:56,793 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3506222665309906, 'Total loss': 0.3506222665309906} | train loss {'Reaction outcome loss': 0.12262198762682668, 'Total loss': 0.12262198762682668}
2022-12-31 08:18:56,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:56,793 INFO:     Epoch: 61
2022-12-31 08:18:58,406 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39118255575497946, 'Total loss': 0.39118255575497946} | train loss {'Reaction outcome loss': 0.11778452604444847, 'Total loss': 0.11778452604444847}
2022-12-31 08:18:58,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:18:58,406 INFO:     Epoch: 62
2022-12-31 08:19:00,043 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3917578389247259, 'Total loss': 0.3917578389247259} | train loss {'Reaction outcome loss': 0.12088450105575314, 'Total loss': 0.12088450105575314}
2022-12-31 08:19:00,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:00,043 INFO:     Epoch: 63
2022-12-31 08:19:01,691 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39639816284179685, 'Total loss': 0.39639816284179685} | train loss {'Reaction outcome loss': 0.1158783359208355, 'Total loss': 0.1158783359208355}
2022-12-31 08:19:01,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:01,692 INFO:     Epoch: 64
2022-12-31 08:19:03,300 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37870546877384187, 'Total loss': 0.37870546877384187} | train loss {'Reaction outcome loss': 0.11700659196477138, 'Total loss': 0.11700659196477138}
2022-12-31 08:19:03,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:03,300 INFO:     Epoch: 65
2022-12-31 08:19:04,949 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38321049710114796, 'Total loss': 0.38321049710114796} | train loss {'Reaction outcome loss': 0.1178713419421977, 'Total loss': 0.1178713419421977}
2022-12-31 08:19:04,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:04,949 INFO:     Epoch: 66
2022-12-31 08:19:06,598 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3691900936421007, 'Total loss': 0.3691900936421007} | train loss {'Reaction outcome loss': 0.11558414029423147, 'Total loss': 0.11558414029423147}
2022-12-31 08:19:06,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:06,599 INFO:     Epoch: 67
2022-12-31 08:19:08,240 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40360324680805204, 'Total loss': 0.40360324680805204} | train loss {'Reaction outcome loss': 0.11638348938788484, 'Total loss': 0.11638348938788484}
2022-12-31 08:19:08,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:08,241 INFO:     Epoch: 68
2022-12-31 08:19:09,859 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4064395586649577, 'Total loss': 0.4064395586649577} | train loss {'Reaction outcome loss': 0.11883290217387198, 'Total loss': 0.11883290217387198}
2022-12-31 08:19:09,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:09,859 INFO:     Epoch: 69
2022-12-31 08:19:11,471 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41115257640679675, 'Total loss': 0.41115257640679675} | train loss {'Reaction outcome loss': 0.11671552406352041, 'Total loss': 0.11671552406352041}
2022-12-31 08:19:11,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:11,471 INFO:     Epoch: 70
2022-12-31 08:19:13,106 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37485101222991946, 'Total loss': 0.37485101222991946} | train loss {'Reaction outcome loss': 0.11631710844005655, 'Total loss': 0.11631710844005655}
2022-12-31 08:19:13,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:13,107 INFO:     Epoch: 71
2022-12-31 08:19:14,720 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3555723269780477, 'Total loss': 0.3555723269780477} | train loss {'Reaction outcome loss': 0.11071650217708717, 'Total loss': 0.11071650217708717}
2022-12-31 08:19:14,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:14,720 INFO:     Epoch: 72
2022-12-31 08:19:16,330 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.364032456278801, 'Total loss': 0.364032456278801} | train loss {'Reaction outcome loss': 0.11169286729448413, 'Total loss': 0.11169286729448413}
2022-12-31 08:19:16,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:16,330 INFO:     Epoch: 73
2022-12-31 08:19:17,965 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.410495920976003, 'Total loss': 0.410495920976003} | train loss {'Reaction outcome loss': 0.11509829330985455, 'Total loss': 0.11509829330985455}
2022-12-31 08:19:17,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:17,965 INFO:     Epoch: 74
2022-12-31 08:19:19,613 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3950702240069707, 'Total loss': 0.3950702240069707} | train loss {'Reaction outcome loss': 0.1115043810390303, 'Total loss': 0.1115043810390303}
2022-12-31 08:19:19,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:19,614 INFO:     Epoch: 75
2022-12-31 08:19:21,256 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3911469101905823, 'Total loss': 0.3911469101905823} | train loss {'Reaction outcome loss': 0.1154011532674496, 'Total loss': 0.1154011532674496}
2022-12-31 08:19:21,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:21,257 INFO:     Epoch: 76
2022-12-31 08:19:22,844 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37525415370861687, 'Total loss': 0.37525415370861687} | train loss {'Reaction outcome loss': 0.11076123122955217, 'Total loss': 0.11076123122955217}
2022-12-31 08:19:22,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:22,844 INFO:     Epoch: 77
2022-12-31 08:19:24,493 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3828767059991757, 'Total loss': 0.3828767059991757} | train loss {'Reaction outcome loss': 0.1138053062927644, 'Total loss': 0.1138053062927644}
2022-12-31 08:19:24,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:24,494 INFO:     Epoch: 78
2022-12-31 08:19:26,094 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3954920987288157, 'Total loss': 0.3954920987288157} | train loss {'Reaction outcome loss': 0.11286120652391092, 'Total loss': 0.11286120652391092}
2022-12-31 08:19:26,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:26,094 INFO:     Epoch: 79
2022-12-31 08:19:27,697 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3858881692091624, 'Total loss': 0.3858881692091624} | train loss {'Reaction outcome loss': 0.10969834004437048, 'Total loss': 0.10969834004437048}
2022-12-31 08:19:27,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:27,697 INFO:     Epoch: 80
2022-12-31 08:19:29,346 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39429757247368497, 'Total loss': 0.39429757247368497} | train loss {'Reaction outcome loss': 0.10907002283688498, 'Total loss': 0.10907002283688498}
2022-12-31 08:19:29,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:29,347 INFO:     Epoch: 81
2022-12-31 08:19:30,957 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3888124813636144, 'Total loss': 0.3888124813636144} | train loss {'Reaction outcome loss': 0.10992305095853067, 'Total loss': 0.10992305095853067}
2022-12-31 08:19:30,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:30,957 INFO:     Epoch: 82
2022-12-31 08:19:32,582 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4237770090500514, 'Total loss': 0.4237770090500514} | train loss {'Reaction outcome loss': 0.10751331151789394, 'Total loss': 0.10751331151789394}
2022-12-31 08:19:32,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:32,583 INFO:     Epoch: 83
2022-12-31 08:19:34,195 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3944039190808932, 'Total loss': 0.3944039190808932} | train loss {'Reaction outcome loss': 0.10526547496492573, 'Total loss': 0.10526547496492573}
2022-12-31 08:19:34,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:34,195 INFO:     Epoch: 84
2022-12-31 08:19:35,851 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3847061405579249, 'Total loss': 0.3847061405579249} | train loss {'Reaction outcome loss': 0.1050012489954132, 'Total loss': 0.1050012489954132}
2022-12-31 08:19:35,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:35,851 INFO:     Epoch: 85
2022-12-31 08:19:37,465 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39553932547569276, 'Total loss': 0.39553932547569276} | train loss {'Reaction outcome loss': 0.11349966858316513, 'Total loss': 0.11349966858316513}
2022-12-31 08:19:37,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:37,466 INFO:     Epoch: 86
2022-12-31 08:19:39,077 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4569498380025228, 'Total loss': 0.4569498380025228} | train loss {'Reaction outcome loss': 0.10810092903068629, 'Total loss': 0.10810092903068629}
2022-12-31 08:19:39,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:39,078 INFO:     Epoch: 87
2022-12-31 08:19:40,688 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3756676107645035, 'Total loss': 0.3756676107645035} | train loss {'Reaction outcome loss': 0.10716319306461262, 'Total loss': 0.10716319306461262}
2022-12-31 08:19:40,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:40,688 INFO:     Epoch: 88
2022-12-31 08:19:42,299 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40555274685223897, 'Total loss': 0.40555274685223897} | train loss {'Reaction outcome loss': 0.10794969444268512, 'Total loss': 0.10794969444268512}
2022-12-31 08:19:42,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:42,300 INFO:     Epoch: 89
2022-12-31 08:19:43,926 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40212668279806774, 'Total loss': 0.40212668279806774} | train loss {'Reaction outcome loss': 0.11141353434148876, 'Total loss': 0.11141353434148876}
2022-12-31 08:19:43,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:43,926 INFO:     Epoch: 90
2022-12-31 08:19:45,554 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43848475217819216, 'Total loss': 0.43848475217819216} | train loss {'Reaction outcome loss': 0.11308582783778653, 'Total loss': 0.11308582783778653}
2022-12-31 08:19:45,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:45,554 INFO:     Epoch: 91
2022-12-31 08:19:47,216 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4272862603267034, 'Total loss': 0.4272862603267034} | train loss {'Reaction outcome loss': 0.10767302561014293, 'Total loss': 0.10767302561014293}
2022-12-31 08:19:47,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:47,216 INFO:     Epoch: 92
2022-12-31 08:19:48,829 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4241418321927389, 'Total loss': 0.4241418321927389} | train loss {'Reaction outcome loss': 0.10139943806141832, 'Total loss': 0.10139943806141832}
2022-12-31 08:19:48,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:48,829 INFO:     Epoch: 93
2022-12-31 08:19:50,466 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4114119569460551, 'Total loss': 0.4114119569460551} | train loss {'Reaction outcome loss': 0.10253575173407167, 'Total loss': 0.10253575173407167}
2022-12-31 08:19:50,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:50,467 INFO:     Epoch: 94
2022-12-31 08:19:52,081 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3972323536872864, 'Total loss': 0.3972323536872864} | train loss {'Reaction outcome loss': 0.10400689955729393, 'Total loss': 0.10400689955729393}
2022-12-31 08:19:52,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:52,082 INFO:     Epoch: 95
2022-12-31 08:19:53,702 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42660957475503286, 'Total loss': 0.42660957475503286} | train loss {'Reaction outcome loss': 0.10438113772551645, 'Total loss': 0.10438113772551645}
2022-12-31 08:19:53,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:53,702 INFO:     Epoch: 96
2022-12-31 08:19:55,360 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41724319954713185, 'Total loss': 0.41724319954713185} | train loss {'Reaction outcome loss': 0.10188039862312866, 'Total loss': 0.10188039862312866}
2022-12-31 08:19:55,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:55,360 INFO:     Epoch: 97
2022-12-31 08:19:56,984 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4565181424220403, 'Total loss': 0.4565181424220403} | train loss {'Reaction outcome loss': 0.1121184100850696, 'Total loss': 0.1121184100850696}
2022-12-31 08:19:56,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:56,984 INFO:     Epoch: 98
2022-12-31 08:19:58,612 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3881960724790891, 'Total loss': 0.3881960724790891} | train loss {'Reaction outcome loss': 0.10828710232783163, 'Total loss': 0.10828710232783163}
2022-12-31 08:19:58,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:19:58,612 INFO:     Epoch: 99
2022-12-31 08:20:00,229 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41361322104930875, 'Total loss': 0.41361322104930875} | train loss {'Reaction outcome loss': 0.10598729040820397, 'Total loss': 0.10598729040820397}
2022-12-31 08:20:00,229 INFO:     Best model found after epoch 31 of 100.
2022-12-31 08:20:00,230 INFO:   Done with stage: TRAINING
2022-12-31 08:20:00,230 INFO:   Starting stage: EVALUATION
2022-12-31 08:20:00,387 INFO:   Done with stage: EVALUATION
2022-12-31 08:20:00,387 INFO:   Leaving out SEQ value Fold_4
2022-12-31 08:20:00,401 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:20:00,401 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:20:01,109 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:20:01,109 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:20:01,184 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:20:01,184 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:20:01,184 INFO:     No hyperparam tuning for this model
2022-12-31 08:20:01,184 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:20:01,184 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:20:01,185 INFO:     None feature selector for col prot
2022-12-31 08:20:01,185 INFO:     None feature selector for col prot
2022-12-31 08:20:01,185 INFO:     None feature selector for col prot
2022-12-31 08:20:01,186 INFO:     None feature selector for col chem
2022-12-31 08:20:01,186 INFO:     None feature selector for col chem
2022-12-31 08:20:01,186 INFO:     None feature selector for col chem
2022-12-31 08:20:01,187 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:20:01,187 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:20:01,188 INFO:     Number of params in model 224011
2022-12-31 08:20:01,192 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:20:01,192 INFO:   Starting stage: TRAINING
2022-12-31 08:20:01,241 INFO:     Val loss before train {'Reaction outcome loss': 0.9896398464838664, 'Total loss': 0.9896398464838664}
2022-12-31 08:20:01,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:01,242 INFO:     Epoch: 0
2022-12-31 08:20:02,877 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6373703896999359, 'Total loss': 0.6373703896999359} | train loss {'Reaction outcome loss': 0.7862983529963649, 'Total loss': 0.7862983529963649}
2022-12-31 08:20:02,878 INFO:     Found new best model at epoch 0
2022-12-31 08:20:02,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:02,879 INFO:     Epoch: 1
2022-12-31 08:20:04,505 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5420875867207845, 'Total loss': 0.5420875867207845} | train loss {'Reaction outcome loss': 0.5136072862126767, 'Total loss': 0.5136072862126767}
2022-12-31 08:20:04,505 INFO:     Found new best model at epoch 1
2022-12-31 08:20:04,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:04,506 INFO:     Epoch: 2
2022-12-31 08:20:06,217 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5497949699560801, 'Total loss': 0.5497949699560801} | train loss {'Reaction outcome loss': 0.44832105775925224, 'Total loss': 0.44832105775925224}
2022-12-31 08:20:06,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:06,217 INFO:     Epoch: 3
2022-12-31 08:20:07,841 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.50738478799661, 'Total loss': 0.50738478799661} | train loss {'Reaction outcome loss': 0.4038010238256265, 'Total loss': 0.4038010238256265}
2022-12-31 08:20:07,841 INFO:     Found new best model at epoch 3
2022-12-31 08:20:07,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:07,842 INFO:     Epoch: 4
2022-12-31 08:20:09,466 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5416757305463155, 'Total loss': 0.5416757305463155} | train loss {'Reaction outcome loss': 0.3765019047131177, 'Total loss': 0.3765019047131177}
2022-12-31 08:20:09,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:09,467 INFO:     Epoch: 5
2022-12-31 08:20:11,095 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5017984211444855, 'Total loss': 0.5017984211444855} | train loss {'Reaction outcome loss': 0.3558627672305176, 'Total loss': 0.3558627672305176}
2022-12-31 08:20:11,095 INFO:     Found new best model at epoch 5
2022-12-31 08:20:11,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:11,096 INFO:     Epoch: 6
2022-12-31 08:20:12,726 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5051972597837449, 'Total loss': 0.5051972597837449} | train loss {'Reaction outcome loss': 0.33111944762377965, 'Total loss': 0.33111944762377965}
2022-12-31 08:20:12,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:12,726 INFO:     Epoch: 7
2022-12-31 08:20:14,384 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5019863029321034, 'Total loss': 0.5019863029321034} | train loss {'Reaction outcome loss': 0.31520667077724684, 'Total loss': 0.31520667077724684}
2022-12-31 08:20:14,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:14,384 INFO:     Epoch: 8
2022-12-31 08:20:16,040 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5232374250888825, 'Total loss': 0.5232374250888825} | train loss {'Reaction outcome loss': 0.2993738139418058, 'Total loss': 0.2993738139418058}
2022-12-31 08:20:16,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:16,041 INFO:     Epoch: 9
2022-12-31 08:20:17,708 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5121439099311829, 'Total loss': 0.5121439099311829} | train loss {'Reaction outcome loss': 0.2870466893653147, 'Total loss': 0.2870466893653147}
2022-12-31 08:20:17,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:17,708 INFO:     Epoch: 10
2022-12-31 08:20:19,332 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4944559713204702, 'Total loss': 0.4944559713204702} | train loss {'Reaction outcome loss': 0.2710298489954067, 'Total loss': 0.2710298489954067}
2022-12-31 08:20:19,332 INFO:     Found new best model at epoch 10
2022-12-31 08:20:19,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:19,333 INFO:     Epoch: 11
2022-12-31 08:20:20,951 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4819324721892675, 'Total loss': 0.4819324721892675} | train loss {'Reaction outcome loss': 0.2605136472072842, 'Total loss': 0.2605136472072842}
2022-12-31 08:20:20,951 INFO:     Found new best model at epoch 11
2022-12-31 08:20:20,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:20,952 INFO:     Epoch: 12
2022-12-31 08:20:22,578 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5114490548769633, 'Total loss': 0.5114490548769633} | train loss {'Reaction outcome loss': 0.25113825314419363, 'Total loss': 0.25113825314419363}
2022-12-31 08:20:22,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:22,579 INFO:     Epoch: 13
2022-12-31 08:20:24,200 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46587115128835044, 'Total loss': 0.46587115128835044} | train loss {'Reaction outcome loss': 0.2429230911825323, 'Total loss': 0.2429230911825323}
2022-12-31 08:20:24,200 INFO:     Found new best model at epoch 13
2022-12-31 08:20:24,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:24,201 INFO:     Epoch: 14
2022-12-31 08:20:25,827 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4791154573361079, 'Total loss': 0.4791154573361079} | train loss {'Reaction outcome loss': 0.2329072722028739, 'Total loss': 0.2329072722028739}
2022-12-31 08:20:25,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:25,827 INFO:     Epoch: 15
2022-12-31 08:20:27,465 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48606201708316804, 'Total loss': 0.48606201708316804} | train loss {'Reaction outcome loss': 0.22320705647193675, 'Total loss': 0.22320705647193675}
2022-12-31 08:20:27,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:27,466 INFO:     Epoch: 16
2022-12-31 08:20:29,135 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5074303964773814, 'Total loss': 0.5074303964773814} | train loss {'Reaction outcome loss': 0.21755324470867748, 'Total loss': 0.21755324470867748}
2022-12-31 08:20:29,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:29,136 INFO:     Epoch: 17
2022-12-31 08:20:30,767 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5185616453488667, 'Total loss': 0.5185616453488667} | train loss {'Reaction outcome loss': 0.21079268881425745, 'Total loss': 0.21079268881425745}
2022-12-31 08:20:30,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:30,767 INFO:     Epoch: 18
2022-12-31 08:20:32,435 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.523073677221934, 'Total loss': 0.523073677221934} | train loss {'Reaction outcome loss': 0.20081869935758062, 'Total loss': 0.20081869935758062}
2022-12-31 08:20:32,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:32,436 INFO:     Epoch: 19
2022-12-31 08:20:34,057 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5044774621725082, 'Total loss': 0.5044774621725082} | train loss {'Reaction outcome loss': 0.19830885755456312, 'Total loss': 0.19830885755456312}
2022-12-31 08:20:34,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:34,058 INFO:     Epoch: 20
2022-12-31 08:20:35,680 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5094617257515589, 'Total loss': 0.5094617257515589} | train loss {'Reaction outcome loss': 0.1959303215495731, 'Total loss': 0.1959303215495731}
2022-12-31 08:20:35,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:35,681 INFO:     Epoch: 21
2022-12-31 08:20:37,348 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4896708865960439, 'Total loss': 0.4896708865960439} | train loss {'Reaction outcome loss': 0.18968139795270422, 'Total loss': 0.18968139795270422}
2022-12-31 08:20:37,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:37,348 INFO:     Epoch: 22
2022-12-31 08:20:38,973 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4835172931353251, 'Total loss': 0.4835172931353251} | train loss {'Reaction outcome loss': 0.1835238844129368, 'Total loss': 0.1835238844129368}
2022-12-31 08:20:38,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:38,973 INFO:     Epoch: 23
2022-12-31 08:20:40,627 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5289652029673259, 'Total loss': 0.5289652029673259} | train loss {'Reaction outcome loss': 0.17973095099929223, 'Total loss': 0.17973095099929223}
2022-12-31 08:20:40,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:40,628 INFO:     Epoch: 24
2022-12-31 08:20:42,259 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5039879510800044, 'Total loss': 0.5039879510800044} | train loss {'Reaction outcome loss': 0.17544627645210992, 'Total loss': 0.17544627645210992}
2022-12-31 08:20:42,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:42,259 INFO:     Epoch: 25
2022-12-31 08:20:43,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5109094202518463, 'Total loss': 0.5109094202518463} | train loss {'Reaction outcome loss': 0.17501036803967687, 'Total loss': 0.17501036803967687}
2022-12-31 08:20:43,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:43,911 INFO:     Epoch: 26
2022-12-31 08:20:45,536 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49164857268333434, 'Total loss': 0.49164857268333434} | train loss {'Reaction outcome loss': 0.16773487195802939, 'Total loss': 0.16773487195802939}
2022-12-31 08:20:45,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:45,536 INFO:     Epoch: 27
2022-12-31 08:20:47,199 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.520438277721405, 'Total loss': 0.520438277721405} | train loss {'Reaction outcome loss': 0.16872119239198602, 'Total loss': 0.16872119239198602}
2022-12-31 08:20:47,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:47,200 INFO:     Epoch: 28
2022-12-31 08:20:48,825 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5144963880379995, 'Total loss': 0.5144963880379995} | train loss {'Reaction outcome loss': 0.167176084814842, 'Total loss': 0.167176084814842}
2022-12-31 08:20:48,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:48,826 INFO:     Epoch: 29
2022-12-31 08:20:50,443 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5213742593924204, 'Total loss': 0.5213742593924204} | train loss {'Reaction outcome loss': 0.16297483967368354, 'Total loss': 0.16297483967368354}
2022-12-31 08:20:50,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:50,443 INFO:     Epoch: 30
2022-12-31 08:20:52,111 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5408285886049271, 'Total loss': 0.5408285886049271} | train loss {'Reaction outcome loss': 0.1584664313963174, 'Total loss': 0.1584664313963174}
2022-12-31 08:20:52,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:52,111 INFO:     Epoch: 31
2022-12-31 08:20:53,738 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5401935199896495, 'Total loss': 0.5401935199896495} | train loss {'Reaction outcome loss': 0.15944859431888436, 'Total loss': 0.15944859431888436}
2022-12-31 08:20:53,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:53,739 INFO:     Epoch: 32
2022-12-31 08:20:55,360 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.532554500301679, 'Total loss': 0.532554500301679} | train loss {'Reaction outcome loss': 0.15564640596280352, 'Total loss': 0.15564640596280352}
2022-12-31 08:20:55,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:55,360 INFO:     Epoch: 33
2022-12-31 08:20:56,982 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5436595817406972, 'Total loss': 0.5436595817406972} | train loss {'Reaction outcome loss': 0.15455244453321296, 'Total loss': 0.15455244453321296}
2022-12-31 08:20:56,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:56,982 INFO:     Epoch: 34
2022-12-31 08:20:58,595 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5885717590649923, 'Total loss': 0.5885717590649923} | train loss {'Reaction outcome loss': 0.15294145275283913, 'Total loss': 0.15294145275283913}
2022-12-31 08:20:58,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:20:58,595 INFO:     Epoch: 35
2022-12-31 08:21:00,216 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5280724416176478, 'Total loss': 0.5280724416176478} | train loss {'Reaction outcome loss': 0.14907713249890597, 'Total loss': 0.14907713249890597}
2022-12-31 08:21:00,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:00,216 INFO:     Epoch: 36
2022-12-31 08:21:01,863 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5066423654556275, 'Total loss': 0.5066423654556275} | train loss {'Reaction outcome loss': 0.1458569015208161, 'Total loss': 0.1458569015208161}
2022-12-31 08:21:01,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:01,863 INFO:     Epoch: 37
2022-12-31 08:21:03,517 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5064030557870864, 'Total loss': 0.5064030557870864} | train loss {'Reaction outcome loss': 0.14801707082438126, 'Total loss': 0.14801707082438126}
2022-12-31 08:21:03,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:03,517 INFO:     Epoch: 38
2022-12-31 08:21:05,185 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.528614820043246, 'Total loss': 0.528614820043246} | train loss {'Reaction outcome loss': 0.14817235385494756, 'Total loss': 0.14817235385494756}
2022-12-31 08:21:05,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:05,186 INFO:     Epoch: 39
2022-12-31 08:21:06,805 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5518498539924621, 'Total loss': 0.5518498539924621} | train loss {'Reaction outcome loss': 0.14537633845535533, 'Total loss': 0.14537633845535533}
2022-12-31 08:21:06,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:06,805 INFO:     Epoch: 40
2022-12-31 08:21:08,472 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5443636933962505, 'Total loss': 0.5443636933962505} | train loss {'Reaction outcome loss': 0.14375922205565422, 'Total loss': 0.14375922205565422}
2022-12-31 08:21:08,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:08,473 INFO:     Epoch: 41
2022-12-31 08:21:10,098 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5382690439621608, 'Total loss': 0.5382690439621608} | train loss {'Reaction outcome loss': 0.1395543504418933, 'Total loss': 0.1395543504418933}
2022-12-31 08:21:10,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:10,098 INFO:     Epoch: 42
2022-12-31 08:21:11,719 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5308089196681977, 'Total loss': 0.5308089196681977} | train loss {'Reaction outcome loss': 0.1411851862586685, 'Total loss': 0.1411851862586685}
2022-12-31 08:21:11,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:11,720 INFO:     Epoch: 43
2022-12-31 08:21:13,335 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5582842667897542, 'Total loss': 0.5582842667897542} | train loss {'Reaction outcome loss': 0.13800474037735685, 'Total loss': 0.13800474037735685}
2022-12-31 08:21:13,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:13,335 INFO:     Epoch: 44
2022-12-31 08:21:14,948 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5656423509120941, 'Total loss': 0.5656423509120941} | train loss {'Reaction outcome loss': 0.13920682550841668, 'Total loss': 0.13920682550841668}
2022-12-31 08:21:14,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:14,949 INFO:     Epoch: 45
2022-12-31 08:21:16,591 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5360663955410322, 'Total loss': 0.5360663955410322} | train loss {'Reaction outcome loss': 0.13800181759460847, 'Total loss': 0.13800181759460847}
2022-12-31 08:21:16,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:16,592 INFO:     Epoch: 46
2022-12-31 08:21:18,226 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5138937791188558, 'Total loss': 0.5138937791188558} | train loss {'Reaction outcome loss': 0.13598986353812612, 'Total loss': 0.13598986353812612}
2022-12-31 08:21:18,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:18,226 INFO:     Epoch: 47
2022-12-31 08:21:19,849 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5419781217972438, 'Total loss': 0.5419781217972438} | train loss {'Reaction outcome loss': 0.13625552585778844, 'Total loss': 0.13625552585778844}
2022-12-31 08:21:19,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:19,850 INFO:     Epoch: 48
2022-12-31 08:21:21,482 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5357542465130488, 'Total loss': 0.5357542465130488} | train loss {'Reaction outcome loss': 0.13271634660775536, 'Total loss': 0.13271634660775536}
2022-12-31 08:21:21,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:21,483 INFO:     Epoch: 49
2022-12-31 08:21:23,118 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5408145010471344, 'Total loss': 0.5408145010471344} | train loss {'Reaction outcome loss': 0.13080491891150978, 'Total loss': 0.13080491891150978}
2022-12-31 08:21:23,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:23,119 INFO:     Epoch: 50
2022-12-31 08:21:24,744 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5585357904434204, 'Total loss': 0.5585357904434204} | train loss {'Reaction outcome loss': 0.14078089927696363, 'Total loss': 0.14078089927696363}
2022-12-31 08:21:24,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:24,745 INFO:     Epoch: 51
2022-12-31 08:21:26,365 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5080935398737589, 'Total loss': 0.5080935398737589} | train loss {'Reaction outcome loss': 0.1316121000383009, 'Total loss': 0.1316121000383009}
2022-12-31 08:21:26,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:26,366 INFO:     Epoch: 52
2022-12-31 08:21:27,980 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5531288981437683, 'Total loss': 0.5531288981437683} | train loss {'Reaction outcome loss': 0.129835037852466, 'Total loss': 0.129835037852466}
2022-12-31 08:21:27,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:27,980 INFO:     Epoch: 53
2022-12-31 08:21:29,614 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5307562013467153, 'Total loss': 0.5307562013467153} | train loss {'Reaction outcome loss': 0.1287980076877084, 'Total loss': 0.1287980076877084}
2022-12-31 08:21:29,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:29,615 INFO:     Epoch: 54
2022-12-31 08:21:31,231 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5453384757041931, 'Total loss': 0.5453384757041931} | train loss {'Reaction outcome loss': 0.12569272320966374, 'Total loss': 0.12569272320966374}
2022-12-31 08:21:31,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:31,231 INFO:     Epoch: 55
2022-12-31 08:21:32,849 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5445270786682764, 'Total loss': 0.5445270786682764} | train loss {'Reaction outcome loss': 0.1275141498642143, 'Total loss': 0.1275141498642143}
2022-12-31 08:21:32,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:32,849 INFO:     Epoch: 56
2022-12-31 08:21:34,469 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5270189613103866, 'Total loss': 0.5270189613103866} | train loss {'Reaction outcome loss': 0.12929931541548417, 'Total loss': 0.12929931541548417}
2022-12-31 08:21:34,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:34,469 INFO:     Epoch: 57
2022-12-31 08:21:36,139 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5522336562474569, 'Total loss': 0.5522336562474569} | train loss {'Reaction outcome loss': 0.12836356149206363, 'Total loss': 0.12836356149206363}
2022-12-31 08:21:36,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:36,139 INFO:     Epoch: 58
2022-12-31 08:21:37,752 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5429586122433344, 'Total loss': 0.5429586122433344} | train loss {'Reaction outcome loss': 0.12560747725727703, 'Total loss': 0.12560747725727703}
2022-12-31 08:21:37,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:37,753 INFO:     Epoch: 59
2022-12-31 08:21:39,386 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5600951790809632, 'Total loss': 0.5600951790809632} | train loss {'Reaction outcome loss': 0.12816921516997395, 'Total loss': 0.12816921516997395}
2022-12-31 08:21:39,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:39,387 INFO:     Epoch: 60
2022-12-31 08:21:41,019 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5620185236136118, 'Total loss': 0.5620185236136118} | train loss {'Reaction outcome loss': 0.123475232573448, 'Total loss': 0.123475232573448}
2022-12-31 08:21:41,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:41,021 INFO:     Epoch: 61
2022-12-31 08:21:42,648 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5167177309592564, 'Total loss': 0.5167177309592564} | train loss {'Reaction outcome loss': 0.12158361912641123, 'Total loss': 0.12158361912641123}
2022-12-31 08:21:42,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:42,649 INFO:     Epoch: 62
2022-12-31 08:21:44,268 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5534761468569438, 'Total loss': 0.5534761468569438} | train loss {'Reaction outcome loss': 0.11854514589916498, 'Total loss': 0.11854514589916498}
2022-12-31 08:21:44,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:44,268 INFO:     Epoch: 63
2022-12-31 08:21:45,936 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.520023908217748, 'Total loss': 0.520023908217748} | train loss {'Reaction outcome loss': 0.12154336594757943, 'Total loss': 0.12154336594757943}
2022-12-31 08:21:45,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:45,937 INFO:     Epoch: 64
2022-12-31 08:21:47,600 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5373306612173716, 'Total loss': 0.5373306612173716} | train loss {'Reaction outcome loss': 0.12183152619137391, 'Total loss': 0.12183152619137391}
2022-12-31 08:21:47,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:47,600 INFO:     Epoch: 65
2022-12-31 08:21:49,222 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5464940006534259, 'Total loss': 0.5464940006534259} | train loss {'Reaction outcome loss': 0.12320166927281538, 'Total loss': 0.12320166927281538}
2022-12-31 08:21:49,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:49,222 INFO:     Epoch: 66
2022-12-31 08:21:50,891 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5723323881626129, 'Total loss': 0.5723323881626129} | train loss {'Reaction outcome loss': 0.12366632076773779, 'Total loss': 0.12366632076773779}
2022-12-31 08:21:50,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:50,891 INFO:     Epoch: 67
2022-12-31 08:21:52,545 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5275942077239354, 'Total loss': 0.5275942077239354} | train loss {'Reaction outcome loss': 0.12166389143632368, 'Total loss': 0.12166389143632368}
2022-12-31 08:21:52,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:52,545 INFO:     Epoch: 68
2022-12-31 08:21:54,213 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5415412157773971, 'Total loss': 0.5415412157773971} | train loss {'Reaction outcome loss': 0.11753329726285722, 'Total loss': 0.11753329726285722}
2022-12-31 08:21:54,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:54,213 INFO:     Epoch: 69
2022-12-31 08:21:55,881 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5219913442929586, 'Total loss': 0.5219913442929586} | train loss {'Reaction outcome loss': 0.11610338769328615, 'Total loss': 0.11610338769328615}
2022-12-31 08:21:55,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:55,881 INFO:     Epoch: 70
2022-12-31 08:21:57,495 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5548737843831381, 'Total loss': 0.5548737843831381} | train loss {'Reaction outcome loss': 0.11701853836580627, 'Total loss': 0.11701853836580627}
2022-12-31 08:21:57,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:57,495 INFO:     Epoch: 71
2022-12-31 08:21:59,164 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5394111096858978, 'Total loss': 0.5394111096858978} | train loss {'Reaction outcome loss': 0.116339912557376, 'Total loss': 0.116339912557376}
2022-12-31 08:21:59,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:21:59,164 INFO:     Epoch: 72
2022-12-31 08:22:00,833 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5401068737109502, 'Total loss': 0.5401068737109502} | train loss {'Reaction outcome loss': 0.11472766795649533, 'Total loss': 0.11472766795649533}
2022-12-31 08:22:00,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:00,834 INFO:     Epoch: 73
2022-12-31 08:22:02,452 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49207314650217693, 'Total loss': 0.49207314650217693} | train loss {'Reaction outcome loss': 0.11802927864167423, 'Total loss': 0.11802927864167423}
2022-12-31 08:22:02,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:02,453 INFO:     Epoch: 74
2022-12-31 08:22:04,122 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5318475623925527, 'Total loss': 0.5318475623925527} | train loss {'Reaction outcome loss': 0.11686760267084767, 'Total loss': 0.11686760267084767}
2022-12-31 08:22:04,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:04,122 INFO:     Epoch: 75
2022-12-31 08:22:05,735 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.542027066151301, 'Total loss': 0.542027066151301} | train loss {'Reaction outcome loss': 0.11738446772952534, 'Total loss': 0.11738446772952534}
2022-12-31 08:22:05,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:05,735 INFO:     Epoch: 76
2022-12-31 08:22:07,358 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5611968986690045, 'Total loss': 0.5611968986690045} | train loss {'Reaction outcome loss': 0.11467486644325112, 'Total loss': 0.11467486644325112}
2022-12-31 08:22:07,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:07,358 INFO:     Epoch: 77
2022-12-31 08:22:08,982 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5581414898236593, 'Total loss': 0.5581414898236593} | train loss {'Reaction outcome loss': 0.11129665800743477, 'Total loss': 0.11129665800743477}
2022-12-31 08:22:08,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:08,982 INFO:     Epoch: 78
2022-12-31 08:22:10,606 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5511544009049734, 'Total loss': 0.5511544009049734} | train loss {'Reaction outcome loss': 0.1155806585174686, 'Total loss': 0.1155806585174686}
2022-12-31 08:22:10,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:10,607 INFO:     Epoch: 79
2022-12-31 08:22:12,230 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5486178159713745, 'Total loss': 0.5486178159713745} | train loss {'Reaction outcome loss': 0.11665326990741927, 'Total loss': 0.11665326990741927}
2022-12-31 08:22:12,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:12,230 INFO:     Epoch: 80
2022-12-31 08:22:13,898 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5858770278592904, 'Total loss': 0.5858770278592904} | train loss {'Reaction outcome loss': 0.11483258156892626, 'Total loss': 0.11483258156892626}
2022-12-31 08:22:13,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:13,899 INFO:     Epoch: 81
2022-12-31 08:22:15,536 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5228900447487831, 'Total loss': 0.5228900447487831} | train loss {'Reaction outcome loss': 0.11265708462987431, 'Total loss': 0.11265708462987431}
2022-12-31 08:22:15,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:15,536 INFO:     Epoch: 82
2022-12-31 08:22:17,161 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5521633307139079, 'Total loss': 0.5521633307139079} | train loss {'Reaction outcome loss': 0.11238657793749648, 'Total loss': 0.11238657793749648}
2022-12-31 08:22:17,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:17,162 INFO:     Epoch: 83
2022-12-31 08:22:18,786 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5584068536758423, 'Total loss': 0.5584068536758423} | train loss {'Reaction outcome loss': 0.1075986815744251, 'Total loss': 0.1075986815744251}
2022-12-31 08:22:18,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:18,786 INFO:     Epoch: 84
2022-12-31 08:22:20,404 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5747773985068003, 'Total loss': 0.5747773985068003} | train loss {'Reaction outcome loss': 0.10941842149788453, 'Total loss': 0.10941842149788453}
2022-12-31 08:22:20,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:20,404 INFO:     Epoch: 85
2022-12-31 08:22:22,030 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5446997284889221, 'Total loss': 0.5446997284889221} | train loss {'Reaction outcome loss': 0.11199895477608277, 'Total loss': 0.11199895477608277}
2022-12-31 08:22:22,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:22,030 INFO:     Epoch: 86
2022-12-31 08:22:23,643 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.559580976764361, 'Total loss': 0.559580976764361} | train loss {'Reaction outcome loss': 0.11267041932583016, 'Total loss': 0.11267041932583016}
2022-12-31 08:22:23,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:23,644 INFO:     Epoch: 87
2022-12-31 08:22:25,281 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5665333410104115, 'Total loss': 0.5665333410104115} | train loss {'Reaction outcome loss': 0.10989880734308209, 'Total loss': 0.10989880734308209}
2022-12-31 08:22:25,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:25,281 INFO:     Epoch: 88
2022-12-31 08:22:26,910 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5312018473943074, 'Total loss': 0.5312018473943074} | train loss {'Reaction outcome loss': 0.1084837974183638, 'Total loss': 0.1084837974183638}
2022-12-31 08:22:26,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:26,910 INFO:     Epoch: 89
2022-12-31 08:22:28,528 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5228295256694158, 'Total loss': 0.5228295256694158} | train loss {'Reaction outcome loss': 0.11178824127591232, 'Total loss': 0.11178824127591232}
2022-12-31 08:22:28,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:28,529 INFO:     Epoch: 90
2022-12-31 08:22:30,172 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5291705677906672, 'Total loss': 0.5291705677906672} | train loss {'Reaction outcome loss': 0.10822808707052244, 'Total loss': 0.10822808707052244}
2022-12-31 08:22:30,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:30,172 INFO:     Epoch: 91
2022-12-31 08:22:31,804 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5518264750639598, 'Total loss': 0.5518264750639598} | train loss {'Reaction outcome loss': 0.11076428338343997, 'Total loss': 0.11076428338343997}
2022-12-31 08:22:31,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:31,805 INFO:     Epoch: 92
2022-12-31 08:22:33,427 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5557421669363976, 'Total loss': 0.5557421669363976} | train loss {'Reaction outcome loss': 0.10791772532206204, 'Total loss': 0.10791772532206204}
2022-12-31 08:22:33,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:33,428 INFO:     Epoch: 93
2022-12-31 08:22:35,054 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5380100727081298, 'Total loss': 0.5380100727081298} | train loss {'Reaction outcome loss': 0.1108453644284918, 'Total loss': 0.1108453644284918}
2022-12-31 08:22:35,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:35,054 INFO:     Epoch: 94
2022-12-31 08:22:36,684 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5406315485636394, 'Total loss': 0.5406315485636394} | train loss {'Reaction outcome loss': 0.10459322881857976, 'Total loss': 0.10459322881857976}
2022-12-31 08:22:36,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:36,685 INFO:     Epoch: 95
2022-12-31 08:22:38,304 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5561927576859792, 'Total loss': 0.5561927576859792} | train loss {'Reaction outcome loss': 0.10491906544059139, 'Total loss': 0.10491906544059139}
2022-12-31 08:22:38,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:38,304 INFO:     Epoch: 96
2022-12-31 08:22:39,936 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5576779345671335, 'Total loss': 0.5576779345671335} | train loss {'Reaction outcome loss': 0.10683147961085508, 'Total loss': 0.10683147961085508}
2022-12-31 08:22:39,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:39,936 INFO:     Epoch: 97
2022-12-31 08:22:41,572 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.536317765712738, 'Total loss': 0.536317765712738} | train loss {'Reaction outcome loss': 0.10615779152005535, 'Total loss': 0.10615779152005535}
2022-12-31 08:22:41,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:41,572 INFO:     Epoch: 98
2022-12-31 08:22:43,193 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5493982672691345, 'Total loss': 0.5493982672691345} | train loss {'Reaction outcome loss': 0.10654978946671696, 'Total loss': 0.10654978946671696}
2022-12-31 08:22:43,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:43,193 INFO:     Epoch: 99
2022-12-31 08:22:44,820 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5734371244907379, 'Total loss': 0.5734371244907379} | train loss {'Reaction outcome loss': 0.09952921716123148, 'Total loss': 0.09952921716123148}
2022-12-31 08:22:44,820 INFO:     Best model found after epoch 14 of 100.
2022-12-31 08:22:44,820 INFO:   Done with stage: TRAINING
2022-12-31 08:22:44,820 INFO:   Starting stage: EVALUATION
2022-12-31 08:22:44,946 INFO:   Done with stage: EVALUATION
2022-12-31 08:22:44,946 INFO:   Leaving out SEQ value Fold_5
2022-12-31 08:22:44,958 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:22:44,959 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:22:45,615 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:22:45,615 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:22:45,683 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:22:45,683 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:22:45,683 INFO:     No hyperparam tuning for this model
2022-12-31 08:22:45,683 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:22:45,683 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:22:45,684 INFO:     None feature selector for col prot
2022-12-31 08:22:45,684 INFO:     None feature selector for col prot
2022-12-31 08:22:45,684 INFO:     None feature selector for col prot
2022-12-31 08:22:45,685 INFO:     None feature selector for col chem
2022-12-31 08:22:45,685 INFO:     None feature selector for col chem
2022-12-31 08:22:45,685 INFO:     None feature selector for col chem
2022-12-31 08:22:45,685 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:22:45,685 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:22:45,687 INFO:     Number of params in model 224011
2022-12-31 08:22:45,690 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:22:45,690 INFO:   Starting stage: TRAINING
2022-12-31 08:22:45,735 INFO:     Val loss before train {'Reaction outcome loss': 0.8903738896052042, 'Total loss': 0.8903738896052042}
2022-12-31 08:22:45,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:45,735 INFO:     Epoch: 0
2022-12-31 08:22:47,355 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5253012994925181, 'Total loss': 0.5253012994925181} | train loss {'Reaction outcome loss': 0.7760838755416526, 'Total loss': 0.7760838755416526}
2022-12-31 08:22:47,355 INFO:     Found new best model at epoch 0
2022-12-31 08:22:47,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:47,356 INFO:     Epoch: 1
2022-12-31 08:22:48,989 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47692690094312035, 'Total loss': 0.47692690094312035} | train loss {'Reaction outcome loss': 0.501191123566903, 'Total loss': 0.501191123566903}
2022-12-31 08:22:48,989 INFO:     Found new best model at epoch 1
2022-12-31 08:22:48,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:48,990 INFO:     Epoch: 2
2022-12-31 08:22:50,602 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4190354918440183, 'Total loss': 0.4190354918440183} | train loss {'Reaction outcome loss': 0.43468156559157456, 'Total loss': 0.43468156559157456}
2022-12-31 08:22:50,602 INFO:     Found new best model at epoch 2
2022-12-31 08:22:50,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:50,604 INFO:     Epoch: 3
2022-12-31 08:22:52,224 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.400797904531161, 'Total loss': 0.400797904531161} | train loss {'Reaction outcome loss': 0.39482723114615315, 'Total loss': 0.39482723114615315}
2022-12-31 08:22:52,226 INFO:     Found new best model at epoch 3
2022-12-31 08:22:52,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:52,227 INFO:     Epoch: 4
2022-12-31 08:22:53,848 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.393768568833669, 'Total loss': 0.393768568833669} | train loss {'Reaction outcome loss': 0.37116305021710344, 'Total loss': 0.37116305021710344}
2022-12-31 08:22:53,848 INFO:     Found new best model at epoch 4
2022-12-31 08:22:53,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:53,849 INFO:     Epoch: 5
2022-12-31 08:22:55,462 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40546046594778695, 'Total loss': 0.40546046594778695} | train loss {'Reaction outcome loss': 0.3455370279694722, 'Total loss': 0.3455370279694722}
2022-12-31 08:22:55,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:55,462 INFO:     Epoch: 6
2022-12-31 08:22:57,130 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39846122612555823, 'Total loss': 0.39846122612555823} | train loss {'Reaction outcome loss': 0.32902969779036534, 'Total loss': 0.32902969779036534}
2022-12-31 08:22:57,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:57,130 INFO:     Epoch: 7
2022-12-31 08:22:58,798 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3633899956941605, 'Total loss': 0.3633899956941605} | train loss {'Reaction outcome loss': 0.31095573542780824, 'Total loss': 0.31095573542780824}
2022-12-31 08:22:58,798 INFO:     Found new best model at epoch 7
2022-12-31 08:22:58,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:22:58,800 INFO:     Epoch: 8
2022-12-31 08:23:00,435 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4053194453318914, 'Total loss': 0.4053194453318914} | train loss {'Reaction outcome loss': 0.29735649140410475, 'Total loss': 0.29735649140410475}
2022-12-31 08:23:00,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:00,436 INFO:     Epoch: 9
2022-12-31 08:23:02,066 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.36781373421351116, 'Total loss': 0.36781373421351116} | train loss {'Reaction outcome loss': 0.28988387250082587, 'Total loss': 0.28988387250082587}
2022-12-31 08:23:02,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:02,067 INFO:     Epoch: 10
2022-12-31 08:23:03,699 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3922000606854757, 'Total loss': 0.3922000606854757} | train loss {'Reaction outcome loss': 0.2735216220040614, 'Total loss': 0.2735216220040614}
2022-12-31 08:23:03,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:03,699 INFO:     Epoch: 11
2022-12-31 08:23:05,320 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37290095786253613, 'Total loss': 0.37290095786253613} | train loss {'Reaction outcome loss': 0.2602096187078565, 'Total loss': 0.2602096187078565}
2022-12-31 08:23:05,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:05,321 INFO:     Epoch: 12
2022-12-31 08:23:06,952 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39228426416714984, 'Total loss': 0.39228426416714984} | train loss {'Reaction outcome loss': 0.2528480066235315, 'Total loss': 0.2528480066235315}
2022-12-31 08:23:06,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:06,952 INFO:     Epoch: 13
2022-12-31 08:23:08,574 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3589153935511907, 'Total loss': 0.3589153935511907} | train loss {'Reaction outcome loss': 0.24301198931807647, 'Total loss': 0.24301198931807647}
2022-12-31 08:23:08,574 INFO:     Found new best model at epoch 13
2022-12-31 08:23:08,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:08,575 INFO:     Epoch: 14
2022-12-31 08:23:10,242 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.355788624783357, 'Total loss': 0.355788624783357} | train loss {'Reaction outcome loss': 0.2326552762317098, 'Total loss': 0.2326552762317098}
2022-12-31 08:23:10,242 INFO:     Found new best model at epoch 14
2022-12-31 08:23:10,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:10,243 INFO:     Epoch: 15
2022-12-31 08:23:11,863 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.399735826253891, 'Total loss': 0.399735826253891} | train loss {'Reaction outcome loss': 0.22485388453632915, 'Total loss': 0.22485388453632915}
2022-12-31 08:23:11,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:11,864 INFO:     Epoch: 16
2022-12-31 08:23:13,487 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3825423429409663, 'Total loss': 0.3825423429409663} | train loss {'Reaction outcome loss': 0.2206922176660506, 'Total loss': 0.2206922176660506}
2022-12-31 08:23:13,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:13,487 INFO:     Epoch: 17
2022-12-31 08:23:15,123 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39108922282854713, 'Total loss': 0.39108922282854713} | train loss {'Reaction outcome loss': 0.21523101496029418, 'Total loss': 0.21523101496029418}
2022-12-31 08:23:15,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:15,123 INFO:     Epoch: 18
2022-12-31 08:23:16,752 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3929228514432907, 'Total loss': 0.3929228514432907} | train loss {'Reaction outcome loss': 0.2078654104810114, 'Total loss': 0.2078654104810114}
2022-12-31 08:23:16,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:16,752 INFO:     Epoch: 19
2022-12-31 08:23:18,378 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3823844085137049, 'Total loss': 0.3823844085137049} | train loss {'Reaction outcome loss': 0.1993348929587254, 'Total loss': 0.1993348929587254}
2022-12-31 08:23:18,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:18,379 INFO:     Epoch: 20
2022-12-31 08:23:20,009 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38144627610842385, 'Total loss': 0.38144627610842385} | train loss {'Reaction outcome loss': 0.1976955093524086, 'Total loss': 0.1976955093524086}
2022-12-31 08:23:20,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:20,010 INFO:     Epoch: 21
2022-12-31 08:23:21,645 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37681845128536223, 'Total loss': 0.37681845128536223} | train loss {'Reaction outcome loss': 0.19124077880815585, 'Total loss': 0.19124077880815585}
2022-12-31 08:23:21,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:21,645 INFO:     Epoch: 22
2022-12-31 08:23:23,261 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3867126524448395, 'Total loss': 0.3867126524448395} | train loss {'Reaction outcome loss': 0.19010741177892534, 'Total loss': 0.19010741177892534}
2022-12-31 08:23:23,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:23,262 INFO:     Epoch: 23
2022-12-31 08:23:24,885 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43022534052530925, 'Total loss': 0.43022534052530925} | train loss {'Reaction outcome loss': 0.1854654459840877, 'Total loss': 0.1854654459840877}
2022-12-31 08:23:24,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:24,885 INFO:     Epoch: 24
2022-12-31 08:23:26,551 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3741091459989548, 'Total loss': 0.3741091459989548} | train loss {'Reaction outcome loss': 0.1786974611009609, 'Total loss': 0.1786974611009609}
2022-12-31 08:23:26,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:26,552 INFO:     Epoch: 25
2022-12-31 08:23:28,172 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3807217876116435, 'Total loss': 0.3807217876116435} | train loss {'Reaction outcome loss': 0.17291013119802792, 'Total loss': 0.17291013119802792}
2022-12-31 08:23:28,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:28,173 INFO:     Epoch: 26
2022-12-31 08:23:29,839 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36927849253018696, 'Total loss': 0.36927849253018696} | train loss {'Reaction outcome loss': 0.1763511931705238, 'Total loss': 0.1763511931705238}
2022-12-31 08:23:29,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:29,840 INFO:     Epoch: 27
2022-12-31 08:23:31,458 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4153209278980891, 'Total loss': 0.4153209278980891} | train loss {'Reaction outcome loss': 0.1704531267339142, 'Total loss': 0.1704531267339142}
2022-12-31 08:23:31,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:31,459 INFO:     Epoch: 28
2022-12-31 08:23:33,079 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39663697481155397, 'Total loss': 0.39663697481155397} | train loss {'Reaction outcome loss': 0.16587653895335722, 'Total loss': 0.16587653895335722}
2022-12-31 08:23:33,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:33,080 INFO:     Epoch: 29
2022-12-31 08:23:34,709 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3683539889752865, 'Total loss': 0.3683539889752865} | train loss {'Reaction outcome loss': 0.16458917593428804, 'Total loss': 0.16458917593428804}
2022-12-31 08:23:34,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:34,710 INFO:     Epoch: 30
2022-12-31 08:23:36,339 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40064147412776946, 'Total loss': 0.40064147412776946} | train loss {'Reaction outcome loss': 0.1597860096029211, 'Total loss': 0.1597860096029211}
2022-12-31 08:23:36,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:36,339 INFO:     Epoch: 31
2022-12-31 08:23:38,005 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4171430895725886, 'Total loss': 0.4171430895725886} | train loss {'Reaction outcome loss': 0.161411185631199, 'Total loss': 0.161411185631199}
2022-12-31 08:23:38,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:38,006 INFO:     Epoch: 32
2022-12-31 08:23:39,628 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4232644110918045, 'Total loss': 0.4232644110918045} | train loss {'Reaction outcome loss': 0.15482499324699817, 'Total loss': 0.15482499324699817}
2022-12-31 08:23:39,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:39,628 INFO:     Epoch: 33
2022-12-31 08:23:41,269 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3956971620519956, 'Total loss': 0.3956971620519956} | train loss {'Reaction outcome loss': 0.15945122447470034, 'Total loss': 0.15945122447470034}
2022-12-31 08:23:41,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:41,270 INFO:     Epoch: 34
2022-12-31 08:23:42,926 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41179174184799194, 'Total loss': 0.41179174184799194} | train loss {'Reaction outcome loss': 0.15177479252515072, 'Total loss': 0.15177479252515072}
2022-12-31 08:23:42,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:42,927 INFO:     Epoch: 35
2022-12-31 08:23:44,557 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39422692557175953, 'Total loss': 0.39422692557175953} | train loss {'Reaction outcome loss': 0.15012869266087076, 'Total loss': 0.15012869266087076}
2022-12-31 08:23:44,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:44,557 INFO:     Epoch: 36
2022-12-31 08:23:45,816 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40834631621837614, 'Total loss': 0.40834631621837614} | train loss {'Reaction outcome loss': 0.14948825004917404, 'Total loss': 0.14948825004917404}
2022-12-31 08:23:45,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:45,817 INFO:     Epoch: 37
2022-12-31 08:23:46,930 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38625578780968983, 'Total loss': 0.38625578780968983} | train loss {'Reaction outcome loss': 0.14616956838174633, 'Total loss': 0.14616956838174633}
2022-12-31 08:23:46,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:46,930 INFO:     Epoch: 38
2022-12-31 08:23:48,038 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38470898270606996, 'Total loss': 0.38470898270606996} | train loss {'Reaction outcome loss': 0.14779907098503964, 'Total loss': 0.14779907098503964}
2022-12-31 08:23:48,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:48,038 INFO:     Epoch: 39
2022-12-31 08:23:49,250 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41238954414923984, 'Total loss': 0.41238954414923984} | train loss {'Reaction outcome loss': 0.142891045975825, 'Total loss': 0.142891045975825}
2022-12-31 08:23:49,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:49,250 INFO:     Epoch: 40
2022-12-31 08:23:50,764 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41523136546214423, 'Total loss': 0.41523136546214423} | train loss {'Reaction outcome loss': 0.1440930305156413, 'Total loss': 0.1440930305156413}
2022-12-31 08:23:50,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:50,764 INFO:     Epoch: 41
2022-12-31 08:23:52,385 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3742675026257833, 'Total loss': 0.3742675026257833} | train loss {'Reaction outcome loss': 0.1392847129979275, 'Total loss': 0.1392847129979275}
2022-12-31 08:23:52,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:52,385 INFO:     Epoch: 42
2022-12-31 08:23:54,005 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36005870898564657, 'Total loss': 0.36005870898564657} | train loss {'Reaction outcome loss': 0.13944139484390078, 'Total loss': 0.13944139484390078}
2022-12-31 08:23:54,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:54,006 INFO:     Epoch: 43
2022-12-31 08:23:55,612 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4018673817316691, 'Total loss': 0.4018673817316691} | train loss {'Reaction outcome loss': 0.13710410782684057, 'Total loss': 0.13710410782684057}
2022-12-31 08:23:55,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:55,613 INFO:     Epoch: 44
2022-12-31 08:23:57,233 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4080439587434133, 'Total loss': 0.4080439587434133} | train loss {'Reaction outcome loss': 0.13267765275878488, 'Total loss': 0.13267765275878488}
2022-12-31 08:23:57,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:57,234 INFO:     Epoch: 45
2022-12-31 08:23:58,848 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.385367351770401, 'Total loss': 0.385367351770401} | train loss {'Reaction outcome loss': 0.13738086021468313, 'Total loss': 0.13738086021468313}
2022-12-31 08:23:58,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:23:58,849 INFO:     Epoch: 46
2022-12-31 08:24:00,478 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38650789906581245, 'Total loss': 0.38650789906581245} | train loss {'Reaction outcome loss': 0.13490375316792608, 'Total loss': 0.13490375316792608}
2022-12-31 08:24:00,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:00,478 INFO:     Epoch: 47
2022-12-31 08:24:02,108 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3761861860752106, 'Total loss': 0.3761861860752106} | train loss {'Reaction outcome loss': 0.1346795112247636, 'Total loss': 0.1346795112247636}
2022-12-31 08:24:02,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:02,109 INFO:     Epoch: 48
2022-12-31 08:24:03,739 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4324020564556122, 'Total loss': 0.4324020564556122} | train loss {'Reaction outcome loss': 0.13353523682459972, 'Total loss': 0.13353523682459972}
2022-12-31 08:24:03,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:03,740 INFO:     Epoch: 49
2022-12-31 08:24:05,368 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4045282314221064, 'Total loss': 0.4045282314221064} | train loss {'Reaction outcome loss': 0.13138360562078683, 'Total loss': 0.13138360562078683}
2022-12-31 08:24:05,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:05,369 INFO:     Epoch: 50
2022-12-31 08:24:06,992 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4074007193247477, 'Total loss': 0.4074007193247477} | train loss {'Reaction outcome loss': 0.13211412871061465, 'Total loss': 0.13211412871061465}
2022-12-31 08:24:06,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:06,992 INFO:     Epoch: 51
2022-12-31 08:24:08,633 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3881064037481944, 'Total loss': 0.3881064037481944} | train loss {'Reaction outcome loss': 0.12915421436651733, 'Total loss': 0.12915421436651733}
2022-12-31 08:24:08,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:08,633 INFO:     Epoch: 52
2022-12-31 08:24:10,299 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4104385328789552, 'Total loss': 0.4104385328789552} | train loss {'Reaction outcome loss': 0.12700787313124468, 'Total loss': 0.12700787313124468}
2022-12-31 08:24:10,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:10,300 INFO:     Epoch: 53
2022-12-31 08:24:11,967 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4164052421847979, 'Total loss': 0.4164052421847979} | train loss {'Reaction outcome loss': 0.12889882200649713, 'Total loss': 0.12889882200649713}
2022-12-31 08:24:11,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:11,968 INFO:     Epoch: 54
2022-12-31 08:24:13,633 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39245698650678, 'Total loss': 0.39245698650678} | train loss {'Reaction outcome loss': 0.12834855510318646, 'Total loss': 0.12834855510318646}
2022-12-31 08:24:13,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:13,634 INFO:     Epoch: 55
2022-12-31 08:24:15,256 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38640708855042855, 'Total loss': 0.38640708855042855} | train loss {'Reaction outcome loss': 0.12872757141256455, 'Total loss': 0.12872757141256455}
2022-12-31 08:24:15,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:15,256 INFO:     Epoch: 56
2022-12-31 08:24:16,877 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40221740504105885, 'Total loss': 0.40221740504105885} | train loss {'Reaction outcome loss': 0.12648070923015745, 'Total loss': 0.12648070923015745}
2022-12-31 08:24:16,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:16,877 INFO:     Epoch: 57
2022-12-31 08:24:18,535 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42037826428810754, 'Total loss': 0.42037826428810754} | train loss {'Reaction outcome loss': 0.12503295070037837, 'Total loss': 0.12503295070037837}
2022-12-31 08:24:18,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:18,535 INFO:     Epoch: 58
2022-12-31 08:24:20,150 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42202024161815643, 'Total loss': 0.42202024161815643} | train loss {'Reaction outcome loss': 0.11992353324640528, 'Total loss': 0.11992353324640528}
2022-12-31 08:24:20,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:20,151 INFO:     Epoch: 59
2022-12-31 08:24:21,816 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3990287939707438, 'Total loss': 0.3990287939707438} | train loss {'Reaction outcome loss': 0.12561272034952786, 'Total loss': 0.12561272034952786}
2022-12-31 08:24:21,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:21,816 INFO:     Epoch: 60
2022-12-31 08:24:23,433 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4137450377146403, 'Total loss': 0.4137450377146403} | train loss {'Reaction outcome loss': 0.1228414200303491, 'Total loss': 0.1228414200303491}
2022-12-31 08:24:23,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:23,433 INFO:     Epoch: 61
2022-12-31 08:24:25,072 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4002440462509791, 'Total loss': 0.4002440462509791} | train loss {'Reaction outcome loss': 0.12107439815917385, 'Total loss': 0.12107439815917385}
2022-12-31 08:24:25,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:25,073 INFO:     Epoch: 62
2022-12-31 08:24:26,693 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.418811230858167, 'Total loss': 0.418811230858167} | train loss {'Reaction outcome loss': 0.12041236395318908, 'Total loss': 0.12041236395318908}
2022-12-31 08:24:26,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:26,693 INFO:     Epoch: 63
2022-12-31 08:24:28,323 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4274641702572505, 'Total loss': 0.4274641702572505} | train loss {'Reaction outcome loss': 0.1188489867547453, 'Total loss': 0.1188489867547453}
2022-12-31 08:24:28,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:28,323 INFO:     Epoch: 64
2022-12-31 08:24:29,957 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40245806276798246, 'Total loss': 0.40245806276798246} | train loss {'Reaction outcome loss': 0.11754359200173176, 'Total loss': 0.11754359200173176}
2022-12-31 08:24:29,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:29,957 INFO:     Epoch: 65
2022-12-31 08:24:31,589 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4114486197630564, 'Total loss': 0.4114486197630564} | train loss {'Reaction outcome loss': 0.1215169264780297, 'Total loss': 0.1215169264780297}
2022-12-31 08:24:31,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:31,590 INFO:     Epoch: 66
2022-12-31 08:24:33,221 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40136712590853374, 'Total loss': 0.40136712590853374} | train loss {'Reaction outcome loss': 0.11812808202068567, 'Total loss': 0.11812808202068567}
2022-12-31 08:24:33,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:33,221 INFO:     Epoch: 67
2022-12-31 08:24:34,845 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41318562428156536, 'Total loss': 0.41318562428156536} | train loss {'Reaction outcome loss': 0.11841622552673067, 'Total loss': 0.11841622552673067}
2022-12-31 08:24:34,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:34,845 INFO:     Epoch: 68
2022-12-31 08:24:36,458 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37351334393024443, 'Total loss': 0.37351334393024443} | train loss {'Reaction outcome loss': 0.11677402388707933, 'Total loss': 0.11677402388707933}
2022-12-31 08:24:36,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:36,458 INFO:     Epoch: 69
2022-12-31 08:24:38,080 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4134890705347061, 'Total loss': 0.4134890705347061} | train loss {'Reaction outcome loss': 0.11545954507167051, 'Total loss': 0.11545954507167051}
2022-12-31 08:24:38,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:38,080 INFO:     Epoch: 70
2022-12-31 08:24:39,703 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40009809136390684, 'Total loss': 0.40009809136390684} | train loss {'Reaction outcome loss': 0.11572223390698003, 'Total loss': 0.11572223390698003}
2022-12-31 08:24:39,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:39,703 INFO:     Epoch: 71
2022-12-31 08:24:41,368 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4322044630845388, 'Total loss': 0.4322044630845388} | train loss {'Reaction outcome loss': 0.1175451457428171, 'Total loss': 0.1175451457428171}
2022-12-31 08:24:41,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:41,369 INFO:     Epoch: 72
2022-12-31 08:24:43,014 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43285776376724244, 'Total loss': 0.43285776376724244} | train loss {'Reaction outcome loss': 0.11264436473626145, 'Total loss': 0.11264436473626145}
2022-12-31 08:24:43,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:43,014 INFO:     Epoch: 73
2022-12-31 08:24:44,645 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4186427965760231, 'Total loss': 0.4186427965760231} | train loss {'Reaction outcome loss': 0.11644380526879419, 'Total loss': 0.11644380526879419}
2022-12-31 08:24:44,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:44,646 INFO:     Epoch: 74
2022-12-31 08:24:46,274 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3949576576550802, 'Total loss': 0.3949576576550802} | train loss {'Reaction outcome loss': 0.11994884935012659, 'Total loss': 0.11994884935012659}
2022-12-31 08:24:46,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:46,274 INFO:     Epoch: 75
2022-12-31 08:24:47,900 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40992857813835143, 'Total loss': 0.40992857813835143} | train loss {'Reaction outcome loss': 0.1167241190980434, 'Total loss': 0.1167241190980434}
2022-12-31 08:24:47,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:47,900 INFO:     Epoch: 76
2022-12-31 08:24:49,525 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44643733104070027, 'Total loss': 0.44643733104070027} | train loss {'Reaction outcome loss': 0.11351248950383118, 'Total loss': 0.11351248950383118}
2022-12-31 08:24:49,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:49,525 INFO:     Epoch: 77
2022-12-31 08:24:51,151 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41378073394298553, 'Total loss': 0.41378073394298553} | train loss {'Reaction outcome loss': 0.11680902450577446, 'Total loss': 0.11680902450577446}
2022-12-31 08:24:51,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:51,151 INFO:     Epoch: 78
2022-12-31 08:24:52,770 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41768490672111513, 'Total loss': 0.41768490672111513} | train loss {'Reaction outcome loss': 0.1134255434325913, 'Total loss': 0.1134255434325913}
2022-12-31 08:24:52,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:52,770 INFO:     Epoch: 79
2022-12-31 08:24:54,412 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40071894923845924, 'Total loss': 0.40071894923845924} | train loss {'Reaction outcome loss': 0.11299861731034593, 'Total loss': 0.11299861731034593}
2022-12-31 08:24:54,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:54,413 INFO:     Epoch: 80
2022-12-31 08:24:56,034 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4142575373252233, 'Total loss': 0.4142575373252233} | train loss {'Reaction outcome loss': 0.10813280500871691, 'Total loss': 0.10813280500871691}
2022-12-31 08:24:56,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:56,034 INFO:     Epoch: 81
2022-12-31 08:24:57,701 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4015460073947906, 'Total loss': 0.4015460073947906} | train loss {'Reaction outcome loss': 0.10920346466259567, 'Total loss': 0.10920346466259567}
2022-12-31 08:24:57,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:57,701 INFO:     Epoch: 82
2022-12-31 08:24:59,323 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42895743226011596, 'Total loss': 0.42895743226011596} | train loss {'Reaction outcome loss': 0.10942898016584371, 'Total loss': 0.10942898016584371}
2022-12-31 08:24:59,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:24:59,323 INFO:     Epoch: 83
2022-12-31 08:25:00,939 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4535392254590988, 'Total loss': 0.4535392254590988} | train loss {'Reaction outcome loss': 0.11258715717878448, 'Total loss': 0.11258715717878448}
2022-12-31 08:25:00,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:00,940 INFO:     Epoch: 84
2022-12-31 08:25:02,581 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4159408037861188, 'Total loss': 0.4159408037861188} | train loss {'Reaction outcome loss': 0.11767934420270448, 'Total loss': 0.11767934420270448}
2022-12-31 08:25:02,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:02,581 INFO:     Epoch: 85
2022-12-31 08:25:04,200 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4228460391362508, 'Total loss': 0.4228460391362508} | train loss {'Reaction outcome loss': 0.11168869379622061, 'Total loss': 0.11168869379622061}
2022-12-31 08:25:04,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:04,201 INFO:     Epoch: 86
2022-12-31 08:25:05,822 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40648565590381625, 'Total loss': 0.40648565590381625} | train loss {'Reaction outcome loss': 0.114556991570841, 'Total loss': 0.114556991570841}
2022-12-31 08:25:05,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:05,822 INFO:     Epoch: 87
2022-12-31 08:25:07,442 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4200160304705302, 'Total loss': 0.4200160304705302} | train loss {'Reaction outcome loss': 0.11379008047746676, 'Total loss': 0.11379008047746676}
2022-12-31 08:25:07,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:07,443 INFO:     Epoch: 88
2022-12-31 08:25:09,063 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40938823322455087, 'Total loss': 0.40938823322455087} | train loss {'Reaction outcome loss': 0.11124802657423224, 'Total loss': 0.11124802657423224}
2022-12-31 08:25:09,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:09,063 INFO:     Epoch: 89
2022-12-31 08:25:10,688 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4045354271928469, 'Total loss': 0.4045354271928469} | train loss {'Reaction outcome loss': 0.11037816999342279, 'Total loss': 0.11037816999342279}
2022-12-31 08:25:10,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:10,689 INFO:     Epoch: 90
2022-12-31 08:25:12,307 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40419343014558157, 'Total loss': 0.40419343014558157} | train loss {'Reaction outcome loss': 0.10526292338725246, 'Total loss': 0.10526292338725246}
2022-12-31 08:25:12,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:12,307 INFO:     Epoch: 91
2022-12-31 08:25:13,929 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.418413370847702, 'Total loss': 0.418413370847702} | train loss {'Reaction outcome loss': 0.10477064478896989, 'Total loss': 0.10477064478896989}
2022-12-31 08:25:13,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:13,929 INFO:     Epoch: 92
2022-12-31 08:25:15,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40617469102144244, 'Total loss': 0.40617469102144244} | train loss {'Reaction outcome loss': 0.11006865170044616, 'Total loss': 0.11006865170044616}
2022-12-31 08:25:15,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:15,552 INFO:     Epoch: 93
2022-12-31 08:25:17,175 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43498092591762544, 'Total loss': 0.43498092591762544} | train loss {'Reaction outcome loss': 0.11005450017827594, 'Total loss': 0.11005450017827594}
2022-12-31 08:25:17,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:17,176 INFO:     Epoch: 94
2022-12-31 08:25:18,798 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3875141312678655, 'Total loss': 0.3875141312678655} | train loss {'Reaction outcome loss': 0.11285163568953113, 'Total loss': 0.11285163568953113}
2022-12-31 08:25:18,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:18,798 INFO:     Epoch: 95
2022-12-31 08:25:20,455 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4089826410015424, 'Total loss': 0.4089826410015424} | train loss {'Reaction outcome loss': 0.10941017313359393, 'Total loss': 0.10941017313359393}
2022-12-31 08:25:20,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:20,456 INFO:     Epoch: 96
2022-12-31 08:25:22,089 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42719675600528717, 'Total loss': 0.42719675600528717} | train loss {'Reaction outcome loss': 0.10720223145028207, 'Total loss': 0.10720223145028207}
2022-12-31 08:25:22,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:22,089 INFO:     Epoch: 97
2022-12-31 08:25:23,720 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41947898964087166, 'Total loss': 0.41947898964087166} | train loss {'Reaction outcome loss': 0.11034550312368556, 'Total loss': 0.11034550312368556}
2022-12-31 08:25:23,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:23,720 INFO:     Epoch: 98
2022-12-31 08:25:25,352 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42843400488297145, 'Total loss': 0.42843400488297145} | train loss {'Reaction outcome loss': 0.1071707431827117, 'Total loss': 0.1071707431827117}
2022-12-31 08:25:25,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:25,352 INFO:     Epoch: 99
2022-12-31 08:25:26,982 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.379092945655187, 'Total loss': 0.379092945655187} | train loss {'Reaction outcome loss': 0.11105112459120553, 'Total loss': 0.11105112459120553}
2022-12-31 08:25:26,982 INFO:     Best model found after epoch 15 of 100.
2022-12-31 08:25:26,983 INFO:   Done with stage: TRAINING
2022-12-31 08:25:26,983 INFO:   Starting stage: EVALUATION
2022-12-31 08:25:27,110 INFO:   Done with stage: EVALUATION
2022-12-31 08:25:27,110 INFO:   Leaving out SEQ value Fold_6
2022-12-31 08:25:27,123 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:25:27,123 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:25:27,774 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:25:27,774 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:25:27,842 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:25:27,842 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:25:27,842 INFO:     No hyperparam tuning for this model
2022-12-31 08:25:27,842 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:25:27,842 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:25:27,843 INFO:     None feature selector for col prot
2022-12-31 08:25:27,843 INFO:     None feature selector for col prot
2022-12-31 08:25:27,843 INFO:     None feature selector for col prot
2022-12-31 08:25:27,844 INFO:     None feature selector for col chem
2022-12-31 08:25:27,844 INFO:     None feature selector for col chem
2022-12-31 08:25:27,844 INFO:     None feature selector for col chem
2022-12-31 08:25:27,844 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:25:27,844 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:25:27,846 INFO:     Number of params in model 224011
2022-12-31 08:25:27,849 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:25:27,849 INFO:   Starting stage: TRAINING
2022-12-31 08:25:27,893 INFO:     Val loss before train {'Reaction outcome loss': 0.9232988953590393, 'Total loss': 0.9232988953590393}
2022-12-31 08:25:27,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:27,893 INFO:     Epoch: 0
2022-12-31 08:25:29,548 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.48542292912801105, 'Total loss': 0.48542292912801105} | train loss {'Reaction outcome loss': 0.7635935234033674, 'Total loss': 0.7635935234033674}
2022-12-31 08:25:29,548 INFO:     Found new best model at epoch 0
2022-12-31 08:25:29,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:29,549 INFO:     Epoch: 1
2022-12-31 08:25:31,170 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4232799788316091, 'Total loss': 0.4232799788316091} | train loss {'Reaction outcome loss': 0.5075889564916115, 'Total loss': 0.5075889564916115}
2022-12-31 08:25:31,170 INFO:     Found new best model at epoch 1
2022-12-31 08:25:31,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:31,171 INFO:     Epoch: 2
2022-12-31 08:25:32,794 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4128384570280711, 'Total loss': 0.4128384570280711} | train loss {'Reaction outcome loss': 0.4465088317648168, 'Total loss': 0.4465088317648168}
2022-12-31 08:25:32,794 INFO:     Found new best model at epoch 2
2022-12-31 08:25:32,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:32,795 INFO:     Epoch: 3
2022-12-31 08:25:34,414 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3791854351758957, 'Total loss': 0.3791854351758957} | train loss {'Reaction outcome loss': 0.4042842494666792, 'Total loss': 0.4042842494666792}
2022-12-31 08:25:34,414 INFO:     Found new best model at epoch 3
2022-12-31 08:25:34,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:34,415 INFO:     Epoch: 4
2022-12-31 08:25:36,035 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3696440781156222, 'Total loss': 0.3696440781156222} | train loss {'Reaction outcome loss': 0.37796314211313475, 'Total loss': 0.37796314211313475}
2022-12-31 08:25:36,036 INFO:     Found new best model at epoch 4
2022-12-31 08:25:36,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:36,037 INFO:     Epoch: 5
2022-12-31 08:25:37,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3631221373875936, 'Total loss': 0.3631221373875936} | train loss {'Reaction outcome loss': 0.35281146140197556, 'Total loss': 0.35281146140197556}
2022-12-31 08:25:37,673 INFO:     Found new best model at epoch 5
2022-12-31 08:25:37,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:37,674 INFO:     Epoch: 6
2022-12-31 08:25:39,292 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3643929084142049, 'Total loss': 0.3643929084142049} | train loss {'Reaction outcome loss': 0.33264548008730266, 'Total loss': 0.33264548008730266}
2022-12-31 08:25:39,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:39,292 INFO:     Epoch: 7
2022-12-31 08:25:40,923 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.35356500844160715, 'Total loss': 0.35356500844160715} | train loss {'Reaction outcome loss': 0.31419087661302475, 'Total loss': 0.31419087661302475}
2022-12-31 08:25:40,923 INFO:     Found new best model at epoch 7
2022-12-31 08:25:40,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:40,924 INFO:     Epoch: 8
2022-12-31 08:25:42,554 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3448681910832723, 'Total loss': 0.3448681910832723} | train loss {'Reaction outcome loss': 0.2993729790598692, 'Total loss': 0.2993729790598692}
2022-12-31 08:25:42,555 INFO:     Found new best model at epoch 8
2022-12-31 08:25:42,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:42,556 INFO:     Epoch: 9
2022-12-31 08:25:44,183 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.34978274603684745, 'Total loss': 0.34978274603684745} | train loss {'Reaction outcome loss': 0.2873154130330585, 'Total loss': 0.2873154130330585}
2022-12-31 08:25:44,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:44,184 INFO:     Epoch: 10
2022-12-31 08:25:45,808 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.34808604220549266, 'Total loss': 0.34808604220549266} | train loss {'Reaction outcome loss': 0.2747747797774494, 'Total loss': 0.2747747797774494}
2022-12-31 08:25:45,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:45,809 INFO:     Epoch: 11
2022-12-31 08:25:47,429 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3398642152547836, 'Total loss': 0.3398642152547836} | train loss {'Reaction outcome loss': 0.2618269762864827, 'Total loss': 0.2618269762864827}
2022-12-31 08:25:47,429 INFO:     Found new best model at epoch 11
2022-12-31 08:25:47,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:47,430 INFO:     Epoch: 12
2022-12-31 08:25:49,039 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3640346844991048, 'Total loss': 0.3640346844991048} | train loss {'Reaction outcome loss': 0.2545590150818928, 'Total loss': 0.2545590150818928}
2022-12-31 08:25:49,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:49,040 INFO:     Epoch: 13
2022-12-31 08:25:50,654 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3294462223847707, 'Total loss': 0.3294462223847707} | train loss {'Reaction outcome loss': 0.24330105308429859, 'Total loss': 0.24330105308429859}
2022-12-31 08:25:50,654 INFO:     Found new best model at epoch 13
2022-12-31 08:25:50,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:50,655 INFO:     Epoch: 14
2022-12-31 08:25:52,268 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.34682196875413257, 'Total loss': 0.34682196875413257} | train loss {'Reaction outcome loss': 0.23675768335588573, 'Total loss': 0.23675768335588573}
2022-12-31 08:25:52,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:52,268 INFO:     Epoch: 15
2022-12-31 08:25:53,883 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.34532927311956885, 'Total loss': 0.34532927311956885} | train loss {'Reaction outcome loss': 0.22884515547176776, 'Total loss': 0.22884515547176776}
2022-12-31 08:25:53,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:53,883 INFO:     Epoch: 16
2022-12-31 08:25:55,524 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37764228880405426, 'Total loss': 0.37764228880405426} | train loss {'Reaction outcome loss': 0.22466100577856768, 'Total loss': 0.22466100577856768}
2022-12-31 08:25:55,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:55,524 INFO:     Epoch: 17
2022-12-31 08:25:57,144 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3515710214773814, 'Total loss': 0.3515710214773814} | train loss {'Reaction outcome loss': 0.21743140054281654, 'Total loss': 0.21743140054281654}
2022-12-31 08:25:57,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:57,144 INFO:     Epoch: 18
2022-12-31 08:25:58,810 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.33859749088684715, 'Total loss': 0.33859749088684715} | train loss {'Reaction outcome loss': 0.20846148268302855, 'Total loss': 0.20846148268302855}
2022-12-31 08:25:58,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:25:58,810 INFO:     Epoch: 19
2022-12-31 08:26:00,435 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.34189718465010327, 'Total loss': 0.34189718465010327} | train loss {'Reaction outcome loss': 0.20440919509675312, 'Total loss': 0.20440919509675312}
2022-12-31 08:26:00,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:00,435 INFO:     Epoch: 20
2022-12-31 08:26:02,101 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34267595211664836, 'Total loss': 0.34267595211664836} | train loss {'Reaction outcome loss': 0.2043100107151894, 'Total loss': 0.2043100107151894}
2022-12-31 08:26:02,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:02,101 INFO:     Epoch: 21
2022-12-31 08:26:03,767 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3775061070919037, 'Total loss': 0.3775061070919037} | train loss {'Reaction outcome loss': 0.1953913991134412, 'Total loss': 0.1953913991134412}
2022-12-31 08:26:03,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:03,767 INFO:     Epoch: 22
2022-12-31 08:26:05,388 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3669815056025982, 'Total loss': 0.3669815056025982} | train loss {'Reaction outcome loss': 0.19001028820576435, 'Total loss': 0.19001028820576435}
2022-12-31 08:26:05,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:05,389 INFO:     Epoch: 23
2022-12-31 08:26:07,040 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38099701901276906, 'Total loss': 0.38099701901276906} | train loss {'Reaction outcome loss': 0.18857560367979082, 'Total loss': 0.18857560367979082}
2022-12-31 08:26:07,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:07,041 INFO:     Epoch: 24
2022-12-31 08:26:08,669 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35364576677481335, 'Total loss': 0.35364576677481335} | train loss {'Reaction outcome loss': 0.18645341786478617, 'Total loss': 0.18645341786478617}
2022-12-31 08:26:08,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:08,669 INFO:     Epoch: 25
2022-12-31 08:26:10,337 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3648239920536677, 'Total loss': 0.3648239920536677} | train loss {'Reaction outcome loss': 0.18673218923893214, 'Total loss': 0.18673218923893214}
2022-12-31 08:26:10,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:10,337 INFO:     Epoch: 26
2022-12-31 08:26:11,959 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.374520472685496, 'Total loss': 0.374520472685496} | train loss {'Reaction outcome loss': 0.1794556885998064, 'Total loss': 0.1794556885998064}
2022-12-31 08:26:11,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:11,960 INFO:     Epoch: 27
2022-12-31 08:26:13,612 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3581334953506788, 'Total loss': 0.3581334953506788} | train loss {'Reaction outcome loss': 0.1761289584897593, 'Total loss': 0.1761289584897593}
2022-12-31 08:26:13,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:13,613 INFO:     Epoch: 28
2022-12-31 08:26:15,235 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3563874145348867, 'Total loss': 0.3563874145348867} | train loss {'Reaction outcome loss': 0.17612495781712584, 'Total loss': 0.17612495781712584}
2022-12-31 08:26:15,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:15,235 INFO:     Epoch: 29
2022-12-31 08:26:16,902 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3443629691998164, 'Total loss': 0.3443629691998164} | train loss {'Reaction outcome loss': 0.17276192224493742, 'Total loss': 0.17276192224493742}
2022-12-31 08:26:16,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:16,902 INFO:     Epoch: 30
2022-12-31 08:26:18,523 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3624334096908569, 'Total loss': 0.3624334096908569} | train loss {'Reaction outcome loss': 0.16857966312983944, 'Total loss': 0.16857966312983944}
2022-12-31 08:26:18,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:18,524 INFO:     Epoch: 31
2022-12-31 08:26:20,190 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.35952296331524847, 'Total loss': 0.35952296331524847} | train loss {'Reaction outcome loss': 0.17075592346005275, 'Total loss': 0.17075592346005275}
2022-12-31 08:26:20,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:20,190 INFO:     Epoch: 32
2022-12-31 08:26:21,809 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3311240949978431, 'Total loss': 0.3311240949978431} | train loss {'Reaction outcome loss': 0.16588763591063474, 'Total loss': 0.16588763591063474}
2022-12-31 08:26:21,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:21,809 INFO:     Epoch: 33
2022-12-31 08:26:23,437 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34715546170870465, 'Total loss': 0.34715546170870465} | train loss {'Reaction outcome loss': 0.1611933168259177, 'Total loss': 0.1611933168259177}
2022-12-31 08:26:23,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:23,437 INFO:     Epoch: 34
2022-12-31 08:26:25,090 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.33998758097489673, 'Total loss': 0.33998758097489673} | train loss {'Reaction outcome loss': 0.1598634340225413, 'Total loss': 0.1598634340225413}
2022-12-31 08:26:25,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:25,090 INFO:     Epoch: 35
2022-12-31 08:26:26,756 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3575409039855003, 'Total loss': 0.3575409039855003} | train loss {'Reaction outcome loss': 0.1609900027567299, 'Total loss': 0.1609900027567299}
2022-12-31 08:26:26,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:26,757 INFO:     Epoch: 36
2022-12-31 08:26:28,381 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3251592504481475, 'Total loss': 0.3251592504481475} | train loss {'Reaction outcome loss': 0.15551126965519968, 'Total loss': 0.15551126965519968}
2022-12-31 08:26:28,381 INFO:     Found new best model at epoch 36
2022-12-31 08:26:28,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:28,382 INFO:     Epoch: 37
2022-12-31 08:26:30,004 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3464864581823349, 'Total loss': 0.3464864581823349} | train loss {'Reaction outcome loss': 0.15372993730828974, 'Total loss': 0.15372993730828974}
2022-12-31 08:26:30,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:30,004 INFO:     Epoch: 38
2022-12-31 08:26:31,667 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34795649151007335, 'Total loss': 0.34795649151007335} | train loss {'Reaction outcome loss': 0.15445080781456366, 'Total loss': 0.15445080781456366}
2022-12-31 08:26:31,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:31,667 INFO:     Epoch: 39
2022-12-31 08:26:33,315 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35656964083512627, 'Total loss': 0.35656964083512627} | train loss {'Reaction outcome loss': 0.14974145607397443, 'Total loss': 0.14974145607397443}
2022-12-31 08:26:33,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:33,315 INFO:     Epoch: 40
2022-12-31 08:26:34,938 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34441428954402603, 'Total loss': 0.34441428954402603} | train loss {'Reaction outcome loss': 0.15149212128983724, 'Total loss': 0.15149212128983724}
2022-12-31 08:26:34,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:34,938 INFO:     Epoch: 41
2022-12-31 08:26:36,608 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3553076614936193, 'Total loss': 0.3553076614936193} | train loss {'Reaction outcome loss': 0.14992863920917365, 'Total loss': 0.14992863920917365}
2022-12-31 08:26:36,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:36,608 INFO:     Epoch: 42
2022-12-31 08:26:38,230 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3477483794093132, 'Total loss': 0.3477483794093132} | train loss {'Reaction outcome loss': 0.14719723394671824, 'Total loss': 0.14719723394671824}
2022-12-31 08:26:38,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:38,231 INFO:     Epoch: 43
2022-12-31 08:26:39,850 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.358960563937823, 'Total loss': 0.358960563937823} | train loss {'Reaction outcome loss': 0.1454596348873437, 'Total loss': 0.1454596348873437}
2022-12-31 08:26:39,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:39,851 INFO:     Epoch: 44
2022-12-31 08:26:41,472 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3420570075511932, 'Total loss': 0.3420570075511932} | train loss {'Reaction outcome loss': 0.14524038245360155, 'Total loss': 0.14524038245360155}
2022-12-31 08:26:41,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:41,472 INFO:     Epoch: 45
2022-12-31 08:26:43,112 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35937870343526207, 'Total loss': 0.35937870343526207} | train loss {'Reaction outcome loss': 0.1441471395856072, 'Total loss': 0.1441471395856072}
2022-12-31 08:26:43,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:43,113 INFO:     Epoch: 46
2022-12-31 08:26:44,753 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3420878991484642, 'Total loss': 0.3420878991484642} | train loss {'Reaction outcome loss': 0.14320706072455064, 'Total loss': 0.14320706072455064}
2022-12-31 08:26:44,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:44,753 INFO:     Epoch: 47
2022-12-31 08:26:46,399 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35894467631975807, 'Total loss': 0.35894467631975807} | train loss {'Reaction outcome loss': 0.1371205021469225, 'Total loss': 0.1371205021469225}
2022-12-31 08:26:46,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:46,400 INFO:     Epoch: 48
2022-12-31 08:26:48,041 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.34658363958199817, 'Total loss': 0.34658363958199817} | train loss {'Reaction outcome loss': 0.14069543345343818, 'Total loss': 0.14069543345343818}
2022-12-31 08:26:48,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:48,041 INFO:     Epoch: 49
2022-12-31 08:26:49,680 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35512470950682956, 'Total loss': 0.35512470950682956} | train loss {'Reaction outcome loss': 0.13970352788304485, 'Total loss': 0.13970352788304485}
2022-12-31 08:26:49,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:49,680 INFO:     Epoch: 50
2022-12-31 08:26:51,295 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34703478614489236, 'Total loss': 0.34703478614489236} | train loss {'Reaction outcome loss': 0.13724779099098236, 'Total loss': 0.13724779099098236}
2022-12-31 08:26:51,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:51,295 INFO:     Epoch: 51
2022-12-31 08:26:52,908 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3524028204381466, 'Total loss': 0.3524028204381466} | train loss {'Reaction outcome loss': 0.13611859072752916, 'Total loss': 0.13611859072752916}
2022-12-31 08:26:52,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:52,909 INFO:     Epoch: 52
2022-12-31 08:26:54,527 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3458148628473282, 'Total loss': 0.3458148628473282} | train loss {'Reaction outcome loss': 0.14112109404447276, 'Total loss': 0.14112109404447276}
2022-12-31 08:26:54,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:54,527 INFO:     Epoch: 53
2022-12-31 08:26:56,146 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36095072850584986, 'Total loss': 0.36095072850584986} | train loss {'Reaction outcome loss': 0.13990921703997716, 'Total loss': 0.13990921703997716}
2022-12-31 08:26:56,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:56,146 INFO:     Epoch: 54
2022-12-31 08:26:57,817 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37452732523282367, 'Total loss': 0.37452732523282367} | train loss {'Reaction outcome loss': 0.13582183232628456, 'Total loss': 0.13582183232628456}
2022-12-31 08:26:57,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:57,818 INFO:     Epoch: 55
2022-12-31 08:26:59,434 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.32235439121723175, 'Total loss': 0.32235439121723175} | train loss {'Reaction outcome loss': 0.13941303409118247, 'Total loss': 0.13941303409118247}
2022-12-31 08:26:59,434 INFO:     Found new best model at epoch 55
2022-12-31 08:26:59,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:26:59,435 INFO:     Epoch: 56
2022-12-31 08:27:01,064 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3568331107497215, 'Total loss': 0.3568331107497215} | train loss {'Reaction outcome loss': 0.13315566436854942, 'Total loss': 0.13315566436854942}
2022-12-31 08:27:01,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:01,064 INFO:     Epoch: 57
2022-12-31 08:27:02,706 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.34046449363231657, 'Total loss': 0.34046449363231657} | train loss {'Reaction outcome loss': 0.1271753297574038, 'Total loss': 0.1271753297574038}
2022-12-31 08:27:02,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:02,707 INFO:     Epoch: 58
2022-12-31 08:27:04,346 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3469712088505427, 'Total loss': 0.3469712088505427} | train loss {'Reaction outcome loss': 0.1293238799368445, 'Total loss': 0.1293238799368445}
2022-12-31 08:27:04,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:04,346 INFO:     Epoch: 59
2022-12-31 08:27:05,989 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.337819413592418, 'Total loss': 0.337819413592418} | train loss {'Reaction outcome loss': 0.13262706531702612, 'Total loss': 0.13262706531702612}
2022-12-31 08:27:05,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:05,989 INFO:     Epoch: 60
2022-12-31 08:27:07,628 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34581832190354667, 'Total loss': 0.34581832190354667} | train loss {'Reaction outcome loss': 0.13035039772827595, 'Total loss': 0.13035039772827595}
2022-12-31 08:27:07,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:07,629 INFO:     Epoch: 61
2022-12-31 08:27:09,278 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35120174251496794, 'Total loss': 0.35120174251496794} | train loss {'Reaction outcome loss': 0.12746278895149243, 'Total loss': 0.12746278895149243}
2022-12-31 08:27:09,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:09,278 INFO:     Epoch: 62
2022-12-31 08:27:10,906 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3671672483285268, 'Total loss': 0.3671672483285268} | train loss {'Reaction outcome loss': 0.13293480357013993, 'Total loss': 0.13293480357013993}
2022-12-31 08:27:10,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:10,906 INFO:     Epoch: 63
2022-12-31 08:27:12,546 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3755306979020437, 'Total loss': 0.3755306979020437} | train loss {'Reaction outcome loss': 0.12791956833392273, 'Total loss': 0.12791956833392273}
2022-12-31 08:27:12,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:12,546 INFO:     Epoch: 64
2022-12-31 08:27:14,185 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3470910921692848, 'Total loss': 0.3470910921692848} | train loss {'Reaction outcome loss': 0.12615008881090323, 'Total loss': 0.12615008881090323}
2022-12-31 08:27:14,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:14,186 INFO:     Epoch: 65
2022-12-31 08:27:15,827 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36809145311514535, 'Total loss': 0.36809145311514535} | train loss {'Reaction outcome loss': 0.12571468658153545, 'Total loss': 0.12571468658153545}
2022-12-31 08:27:15,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:15,827 INFO:     Epoch: 66
2022-12-31 08:27:17,460 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3450643017888069, 'Total loss': 0.3450643017888069} | train loss {'Reaction outcome loss': 0.1261779250936845, 'Total loss': 0.1261779250936845}
2022-12-31 08:27:17,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:17,461 INFO:     Epoch: 67
2022-12-31 08:27:19,086 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34630192071199417, 'Total loss': 0.34630192071199417} | train loss {'Reaction outcome loss': 0.1255104316277463, 'Total loss': 0.1255104316277463}
2022-12-31 08:27:19,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:19,087 INFO:     Epoch: 68
2022-12-31 08:27:20,756 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35548649181922276, 'Total loss': 0.35548649181922276} | train loss {'Reaction outcome loss': 0.12075899469763686, 'Total loss': 0.12075899469763686}
2022-12-31 08:27:20,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:20,757 INFO:     Epoch: 69
2022-12-31 08:27:22,376 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3455992211898168, 'Total loss': 0.3455992211898168} | train loss {'Reaction outcome loss': 0.12633622574892284, 'Total loss': 0.12633622574892284}
2022-12-31 08:27:22,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:22,376 INFO:     Epoch: 70
2022-12-31 08:27:24,046 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36515437016884483, 'Total loss': 0.36515437016884483} | train loss {'Reaction outcome loss': 0.12613598983365007, 'Total loss': 0.12613598983365007}
2022-12-31 08:27:24,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:24,046 INFO:     Epoch: 71
2022-12-31 08:27:25,664 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3709550306200981, 'Total loss': 0.3709550306200981} | train loss {'Reaction outcome loss': 0.1214475492839214, 'Total loss': 0.1214475492839214}
2022-12-31 08:27:25,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:25,664 INFO:     Epoch: 72
2022-12-31 08:27:27,321 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3290168285369873, 'Total loss': 0.3290168285369873} | train loss {'Reaction outcome loss': 0.11974593027182165, 'Total loss': 0.11974593027182165}
2022-12-31 08:27:27,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:27,321 INFO:     Epoch: 73
2022-12-31 08:27:28,953 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3395701130231222, 'Total loss': 0.3395701130231222} | train loss {'Reaction outcome loss': 0.12527467423397712, 'Total loss': 0.12527467423397712}
2022-12-31 08:27:28,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:28,953 INFO:     Epoch: 74
2022-12-31 08:27:30,623 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35427675147851306, 'Total loss': 0.35427675147851306} | train loss {'Reaction outcome loss': 0.1194376914731701, 'Total loss': 0.1194376914731701}
2022-12-31 08:27:30,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:30,623 INFO:     Epoch: 75
2022-12-31 08:27:32,294 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3424717466036479, 'Total loss': 0.3424717466036479} | train loss {'Reaction outcome loss': 0.1218680841133792, 'Total loss': 0.1218680841133792}
2022-12-31 08:27:32,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:32,294 INFO:     Epoch: 76
2022-12-31 08:27:33,912 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3310288024445375, 'Total loss': 0.3310288024445375} | train loss {'Reaction outcome loss': 0.11762938416304088, 'Total loss': 0.11762938416304088}
2022-12-31 08:27:33,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:33,913 INFO:     Epoch: 77
2022-12-31 08:27:35,539 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3500350107749303, 'Total loss': 0.3500350107749303} | train loss {'Reaction outcome loss': 0.11694031674919199, 'Total loss': 0.11694031674919199}
2022-12-31 08:27:35,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:35,539 INFO:     Epoch: 78
2022-12-31 08:27:37,193 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3318197752038638, 'Total loss': 0.3318197752038638} | train loss {'Reaction outcome loss': 0.12414667847152759, 'Total loss': 0.12414667847152759}
2022-12-31 08:27:37,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:37,193 INFO:     Epoch: 79
2022-12-31 08:27:38,860 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35679162889719007, 'Total loss': 0.35679162889719007} | train loss {'Reaction outcome loss': 0.12448001949163658, 'Total loss': 0.12448001949163658}
2022-12-31 08:27:38,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:38,860 INFO:     Epoch: 80
2022-12-31 08:27:40,478 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3834781348705292, 'Total loss': 0.3834781348705292} | train loss {'Reaction outcome loss': 0.12052465843445274, 'Total loss': 0.12052465843445274}
2022-12-31 08:27:40,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:40,479 INFO:     Epoch: 81
2022-12-31 08:27:42,145 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3393100326259931, 'Total loss': 0.3393100326259931} | train loss {'Reaction outcome loss': 0.11930245144413751, 'Total loss': 0.11930245144413751}
2022-12-31 08:27:42,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:42,146 INFO:     Epoch: 82
2022-12-31 08:27:43,764 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3551860372225443, 'Total loss': 0.3551860372225443} | train loss {'Reaction outcome loss': 0.1156037984439424, 'Total loss': 0.1156037984439424}
2022-12-31 08:27:43,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:43,764 INFO:     Epoch: 83
2022-12-31 08:27:45,405 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.31878491640090945, 'Total loss': 0.31878491640090945} | train loss {'Reaction outcome loss': 0.12193111511996345, 'Total loss': 0.12193111511996345}
2022-12-31 08:27:45,405 INFO:     Found new best model at epoch 83
2022-12-31 08:27:45,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:45,406 INFO:     Epoch: 84
2022-12-31 08:27:47,046 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3320943961540858, 'Total loss': 0.3320943961540858} | train loss {'Reaction outcome loss': 0.11882133570092895, 'Total loss': 0.11882133570092895}
2022-12-31 08:27:47,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:47,046 INFO:     Epoch: 85
2022-12-31 08:27:48,713 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33056927571694056, 'Total loss': 0.33056927571694056} | train loss {'Reaction outcome loss': 0.1162715736366405, 'Total loss': 0.1162715736366405}
2022-12-31 08:27:48,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:48,714 INFO:     Epoch: 86
2022-12-31 08:27:50,340 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34076612293720243, 'Total loss': 0.34076612293720243} | train loss {'Reaction outcome loss': 0.1113610126024334, 'Total loss': 0.1113610126024334}
2022-12-31 08:27:50,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:50,340 INFO:     Epoch: 87
2022-12-31 08:27:52,008 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34603628019491833, 'Total loss': 0.34603628019491833} | train loss {'Reaction outcome loss': 0.1165109069367353, 'Total loss': 0.1165109069367353}
2022-12-31 08:27:52,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:52,008 INFO:     Epoch: 88
2022-12-31 08:27:53,676 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3465061575174332, 'Total loss': 0.3465061575174332} | train loss {'Reaction outcome loss': 0.1198754309548825, 'Total loss': 0.1198754309548825}
2022-12-31 08:27:53,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:53,676 INFO:     Epoch: 89
2022-12-31 08:27:55,294 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35327319949865343, 'Total loss': 0.35327319949865343} | train loss {'Reaction outcome loss': 0.11792287233685705, 'Total loss': 0.11792287233685705}
2022-12-31 08:27:55,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:55,295 INFO:     Epoch: 90
2022-12-31 08:27:56,915 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33803226153055826, 'Total loss': 0.33803226153055826} | train loss {'Reaction outcome loss': 0.1166596923860644, 'Total loss': 0.1166596923860644}
2022-12-31 08:27:56,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:56,915 INFO:     Epoch: 91
2022-12-31 08:27:58,584 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3525546093781789, 'Total loss': 0.3525546093781789} | train loss {'Reaction outcome loss': 0.11749730861177567, 'Total loss': 0.11749730861177567}
2022-12-31 08:27:58,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:27:58,584 INFO:     Epoch: 92
2022-12-31 08:28:00,253 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35424990008274715, 'Total loss': 0.35424990008274715} | train loss {'Reaction outcome loss': 0.1163473049227471, 'Total loss': 0.1163473049227471}
2022-12-31 08:28:00,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:00,253 INFO:     Epoch: 93
2022-12-31 08:28:01,884 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3376454641421636, 'Total loss': 0.3376454641421636} | train loss {'Reaction outcome loss': 0.11107635641107437, 'Total loss': 0.11107635641107437}
2022-12-31 08:28:01,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:01,884 INFO:     Epoch: 94
2022-12-31 08:28:03,498 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34100939681132636, 'Total loss': 0.34100939681132636} | train loss {'Reaction outcome loss': 0.11042180015127231, 'Total loss': 0.11042180015127231}
2022-12-31 08:28:03,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:03,499 INFO:     Epoch: 95
2022-12-31 08:28:05,138 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3279763941963514, 'Total loss': 0.3279763941963514} | train loss {'Reaction outcome loss': 0.11031014535286958, 'Total loss': 0.11031014535286958}
2022-12-31 08:28:05,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:05,139 INFO:     Epoch: 96
2022-12-31 08:28:06,771 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.32612229883670807, 'Total loss': 0.32612229883670807} | train loss {'Reaction outcome loss': 0.11028392510639927, 'Total loss': 0.11028392510639927}
2022-12-31 08:28:06,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:06,772 INFO:     Epoch: 97
2022-12-31 08:28:08,402 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3501601537068685, 'Total loss': 0.3501601537068685} | train loss {'Reaction outcome loss': 0.11514986149919647, 'Total loss': 0.11514986149919647}
2022-12-31 08:28:08,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:08,403 INFO:     Epoch: 98
2022-12-31 08:28:10,039 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.32899514933427176, 'Total loss': 0.32899514933427176} | train loss {'Reaction outcome loss': 0.1112158875340858, 'Total loss': 0.1112158875340858}
2022-12-31 08:28:10,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:10,040 INFO:     Epoch: 99
2022-12-31 08:28:11,672 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3735937183101972, 'Total loss': 0.3735937183101972} | train loss {'Reaction outcome loss': 0.1144452938811672, 'Total loss': 0.1144452938811672}
2022-12-31 08:28:11,672 INFO:     Best model found after epoch 84 of 100.
2022-12-31 08:28:11,672 INFO:   Done with stage: TRAINING
2022-12-31 08:28:11,672 INFO:   Starting stage: EVALUATION
2022-12-31 08:28:11,797 INFO:   Done with stage: EVALUATION
2022-12-31 08:28:11,797 INFO:   Leaving out SEQ value Fold_7
2022-12-31 08:28:11,809 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:28:11,810 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:28:12,466 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:28:12,466 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:28:12,535 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:28:12,535 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:28:12,535 INFO:     No hyperparam tuning for this model
2022-12-31 08:28:12,535 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:28:12,535 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:28:12,536 INFO:     None feature selector for col prot
2022-12-31 08:28:12,536 INFO:     None feature selector for col prot
2022-12-31 08:28:12,536 INFO:     None feature selector for col prot
2022-12-31 08:28:12,537 INFO:     None feature selector for col chem
2022-12-31 08:28:12,537 INFO:     None feature selector for col chem
2022-12-31 08:28:12,537 INFO:     None feature selector for col chem
2022-12-31 08:28:12,537 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:28:12,537 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:28:12,539 INFO:     Number of params in model 224011
2022-12-31 08:28:12,542 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:28:12,542 INFO:   Starting stage: TRAINING
2022-12-31 08:28:12,588 INFO:     Val loss before train {'Reaction outcome loss': 0.9728594779968261, 'Total loss': 0.9728594779968261}
2022-12-31 08:28:12,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:12,588 INFO:     Epoch: 0
2022-12-31 08:28:14,218 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5576190908749898, 'Total loss': 0.5576190908749898} | train loss {'Reaction outcome loss': 0.7819874243615766, 'Total loss': 0.7819874243615766}
2022-12-31 08:28:14,218 INFO:     Found new best model at epoch 0
2022-12-31 08:28:14,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:14,219 INFO:     Epoch: 1
2022-12-31 08:28:15,851 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4545832316080729, 'Total loss': 0.4545832316080729} | train loss {'Reaction outcome loss': 0.5142572332267726, 'Total loss': 0.5142572332267726}
2022-12-31 08:28:15,851 INFO:     Found new best model at epoch 1
2022-12-31 08:28:15,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:15,852 INFO:     Epoch: 2
2022-12-31 08:28:17,520 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.42664076884587604, 'Total loss': 0.42664076884587604} | train loss {'Reaction outcome loss': 0.4417523109095191, 'Total loss': 0.4417523109095191}
2022-12-31 08:28:17,520 INFO:     Found new best model at epoch 2
2022-12-31 08:28:17,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:17,521 INFO:     Epoch: 3
2022-12-31 08:28:19,137 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42294901808102925, 'Total loss': 0.42294901808102925} | train loss {'Reaction outcome loss': 0.4006577125256242, 'Total loss': 0.4006577125256242}
2022-12-31 08:28:19,137 INFO:     Found new best model at epoch 3
2022-12-31 08:28:19,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:19,138 INFO:     Epoch: 4
2022-12-31 08:28:20,755 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4368937244017919, 'Total loss': 0.4368937244017919} | train loss {'Reaction outcome loss': 0.3738308444834358, 'Total loss': 0.3738308444834358}
2022-12-31 08:28:20,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:20,755 INFO:     Epoch: 5
2022-12-31 08:28:22,372 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4107587695121765, 'Total loss': 0.4107587695121765} | train loss {'Reaction outcome loss': 0.34929973068596654, 'Total loss': 0.34929973068596654}
2022-12-31 08:28:22,372 INFO:     Found new best model at epoch 5
2022-12-31 08:28:22,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:22,373 INFO:     Epoch: 6
2022-12-31 08:28:24,005 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4248178740342458, 'Total loss': 0.4248178740342458} | train loss {'Reaction outcome loss': 0.3294420726193848, 'Total loss': 0.3294420726193848}
2022-12-31 08:28:24,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:24,005 INFO:     Epoch: 7
2022-12-31 08:28:25,640 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42744579712549846, 'Total loss': 0.42744579712549846} | train loss {'Reaction outcome loss': 0.3103092469893638, 'Total loss': 0.3103092469893638}
2022-12-31 08:28:25,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:25,641 INFO:     Epoch: 8
2022-12-31 08:28:27,273 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46756157676378884, 'Total loss': 0.46756157676378884} | train loss {'Reaction outcome loss': 0.2938715630086536, 'Total loss': 0.2938715630086536}
2022-12-31 08:28:27,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:27,273 INFO:     Epoch: 9
2022-12-31 08:28:28,940 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47163695891698204, 'Total loss': 0.47163695891698204} | train loss {'Reaction outcome loss': 0.27900756155863565, 'Total loss': 0.27900756155863565}
2022-12-31 08:28:28,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:28,941 INFO:     Epoch: 10
2022-12-31 08:28:30,564 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41642301082611083, 'Total loss': 0.41642301082611083} | train loss {'Reaction outcome loss': 0.2670764247432943, 'Total loss': 0.2670764247432943}
2022-12-31 08:28:30,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:30,564 INFO:     Epoch: 11
2022-12-31 08:28:32,204 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43425900240739185, 'Total loss': 0.43425900240739185} | train loss {'Reaction outcome loss': 0.25538155347754377, 'Total loss': 0.25538155347754377}
2022-12-31 08:28:32,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:32,205 INFO:     Epoch: 12
2022-12-31 08:28:33,837 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4680633574724197, 'Total loss': 0.4680633574724197} | train loss {'Reaction outcome loss': 0.24403044944864424, 'Total loss': 0.24403044944864424}
2022-12-31 08:28:33,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:33,837 INFO:     Epoch: 13
2022-12-31 08:28:35,470 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4207867570221424, 'Total loss': 0.4207867570221424} | train loss {'Reaction outcome loss': 0.23525252538844135, 'Total loss': 0.23525252538844135}
2022-12-31 08:28:35,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:35,470 INFO:     Epoch: 14
2022-12-31 08:28:37,103 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4517422119776408, 'Total loss': 0.4517422119776408} | train loss {'Reaction outcome loss': 0.22557501628026635, 'Total loss': 0.22557501628026635}
2022-12-31 08:28:37,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:37,103 INFO:     Epoch: 15
2022-12-31 08:28:38,733 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4537603179613749, 'Total loss': 0.4537603179613749} | train loss {'Reaction outcome loss': 0.21927046387822835, 'Total loss': 0.21927046387822835}
2022-12-31 08:28:38,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:38,733 INFO:     Epoch: 16
2022-12-31 08:28:40,379 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43367096384366355, 'Total loss': 0.43367096384366355} | train loss {'Reaction outcome loss': 0.20932219014755224, 'Total loss': 0.20932219014755224}
2022-12-31 08:28:40,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:40,379 INFO:     Epoch: 17
2022-12-31 08:28:42,004 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46110801796118417, 'Total loss': 0.46110801796118417} | train loss {'Reaction outcome loss': 0.20470186771441667, 'Total loss': 0.20470186771441667}
2022-12-31 08:28:42,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:42,004 INFO:     Epoch: 18
2022-12-31 08:28:43,634 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4424968630075455, 'Total loss': 0.4424968630075455} | train loss {'Reaction outcome loss': 0.19912142376499486, 'Total loss': 0.19912142376499486}
2022-12-31 08:28:43,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:43,634 INFO:     Epoch: 19
2022-12-31 08:28:45,265 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4223673939704895, 'Total loss': 0.4223673939704895} | train loss {'Reaction outcome loss': 0.19538012898059742, 'Total loss': 0.19538012898059742}
2022-12-31 08:28:45,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:45,266 INFO:     Epoch: 20
2022-12-31 08:28:46,897 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43786466419696807, 'Total loss': 0.43786466419696807} | train loss {'Reaction outcome loss': 0.19057384550921108, 'Total loss': 0.19057384550921108}
2022-12-31 08:28:46,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:46,897 INFO:     Epoch: 21
2022-12-31 08:28:48,521 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45253074864546455, 'Total loss': 0.45253074864546455} | train loss {'Reaction outcome loss': 0.18711755809370792, 'Total loss': 0.18711755809370792}
2022-12-31 08:28:48,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:48,522 INFO:     Epoch: 22
2022-12-31 08:28:50,151 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4529274960358938, 'Total loss': 0.4529274960358938} | train loss {'Reaction outcome loss': 0.17903235487451621, 'Total loss': 0.17903235487451621}
2022-12-31 08:28:50,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:50,151 INFO:     Epoch: 23
2022-12-31 08:28:51,778 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44950195650259656, 'Total loss': 0.44950195650259656} | train loss {'Reaction outcome loss': 0.17755932383077885, 'Total loss': 0.17755932383077885}
2022-12-31 08:28:51,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:51,778 INFO:     Epoch: 24
2022-12-31 08:28:53,445 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.443276451031367, 'Total loss': 0.443276451031367} | train loss {'Reaction outcome loss': 0.17247675243590282, 'Total loss': 0.17247675243590282}
2022-12-31 08:28:53,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:53,445 INFO:     Epoch: 25
2022-12-31 08:28:55,112 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4866106947263082, 'Total loss': 0.4866106947263082} | train loss {'Reaction outcome loss': 0.17097650100527473, 'Total loss': 0.17097650100527473}
2022-12-31 08:28:55,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:55,112 INFO:     Epoch: 26
2022-12-31 08:28:56,735 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48169852296511334, 'Total loss': 0.48169852296511334} | train loss {'Reaction outcome loss': 0.16840425981309548, 'Total loss': 0.16840425981309548}
2022-12-31 08:28:56,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:56,735 INFO:     Epoch: 27
2022-12-31 08:28:58,365 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4921656330426534, 'Total loss': 0.4921656330426534} | train loss {'Reaction outcome loss': 0.16428059506119105, 'Total loss': 0.16428059506119105}
2022-12-31 08:28:58,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:58,365 INFO:     Epoch: 28
2022-12-31 08:28:59,993 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47673979500929514, 'Total loss': 0.47673979500929514} | train loss {'Reaction outcome loss': 0.16293961156179812, 'Total loss': 0.16293961156179812}
2022-12-31 08:28:59,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:28:59,993 INFO:     Epoch: 29
2022-12-31 08:29:01,625 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4480310082435608, 'Total loss': 0.4480310082435608} | train loss {'Reaction outcome loss': 0.15890206334715715, 'Total loss': 0.15890206334715715}
2022-12-31 08:29:01,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:01,626 INFO:     Epoch: 30
2022-12-31 08:29:03,255 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45689122279485067, 'Total loss': 0.45689122279485067} | train loss {'Reaction outcome loss': 0.15650513529817872, 'Total loss': 0.15650513529817872}
2022-12-31 08:29:03,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:03,255 INFO:     Epoch: 31
2022-12-31 08:29:04,888 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44890197515487673, 'Total loss': 0.44890197515487673} | train loss {'Reaction outcome loss': 0.15535879941381486, 'Total loss': 0.15535879941381486}
2022-12-31 08:29:04,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:04,889 INFO:     Epoch: 32
2022-12-31 08:29:06,516 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48168141543865206, 'Total loss': 0.48168141543865206} | train loss {'Reaction outcome loss': 0.1532621127704582, 'Total loss': 0.1532621127704582}
2022-12-31 08:29:06,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:06,517 INFO:     Epoch: 33
2022-12-31 08:29:08,136 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47725295623143515, 'Total loss': 0.47725295623143515} | train loss {'Reaction outcome loss': 0.15208473552811877, 'Total loss': 0.15208473552811877}
2022-12-31 08:29:08,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:08,137 INFO:     Epoch: 34
2022-12-31 08:29:09,758 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4702479134003321, 'Total loss': 0.4702479134003321} | train loss {'Reaction outcome loss': 0.1481987251715217, 'Total loss': 0.1481987251715217}
2022-12-31 08:29:09,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:09,758 INFO:     Epoch: 35
2022-12-31 08:29:11,375 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5315879921118418, 'Total loss': 0.5315879921118418} | train loss {'Reaction outcome loss': 0.14784830957583894, 'Total loss': 0.14784830957583894}
2022-12-31 08:29:11,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:11,375 INFO:     Epoch: 36
2022-12-31 08:29:13,042 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45027570525805155, 'Total loss': 0.45027570525805155} | train loss {'Reaction outcome loss': 0.1468519345379774, 'Total loss': 0.1468519345379774}
2022-12-31 08:29:13,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:13,042 INFO:     Epoch: 37
2022-12-31 08:29:14,661 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47780000070730844, 'Total loss': 0.47780000070730844} | train loss {'Reaction outcome loss': 0.14537729495389906, 'Total loss': 0.14537729495389906}
2022-12-31 08:29:14,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:14,661 INFO:     Epoch: 38
2022-12-31 08:29:16,316 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4767740875482559, 'Total loss': 0.4767740875482559} | train loss {'Reaction outcome loss': 0.1428479461120408, 'Total loss': 0.1428479461120408}
2022-12-31 08:29:16,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:16,316 INFO:     Epoch: 39
2022-12-31 08:29:17,942 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48921226561069486, 'Total loss': 0.48921226561069486} | train loss {'Reaction outcome loss': 0.1446405659944142, 'Total loss': 0.1446405659944142}
2022-12-31 08:29:17,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:17,942 INFO:     Epoch: 40
2022-12-31 08:29:19,571 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4804040690263112, 'Total loss': 0.4804040690263112} | train loss {'Reaction outcome loss': 0.1410748891915709, 'Total loss': 0.1410748891915709}
2022-12-31 08:29:19,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:19,571 INFO:     Epoch: 41
2022-12-31 08:29:21,239 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46876002798477806, 'Total loss': 0.46876002798477806} | train loss {'Reaction outcome loss': 0.1409721611595514, 'Total loss': 0.1409721611595514}
2022-12-31 08:29:21,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:21,240 INFO:     Epoch: 42
2022-12-31 08:29:22,866 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45979081789652504, 'Total loss': 0.45979081789652504} | train loss {'Reaction outcome loss': 0.13915939013463602, 'Total loss': 0.13915939013463602}
2022-12-31 08:29:22,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:22,866 INFO:     Epoch: 43
2022-12-31 08:29:24,534 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.477003941933314, 'Total loss': 0.477003941933314} | train loss {'Reaction outcome loss': 0.13614090117844432, 'Total loss': 0.13614090117844432}
2022-12-31 08:29:24,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:24,535 INFO:     Epoch: 44
2022-12-31 08:29:26,188 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4662635644276937, 'Total loss': 0.4662635644276937} | train loss {'Reaction outcome loss': 0.13761237451204836, 'Total loss': 0.13761237451204836}
2022-12-31 08:29:26,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:26,188 INFO:     Epoch: 45
2022-12-31 08:29:27,865 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44892695744832356, 'Total loss': 0.44892695744832356} | train loss {'Reaction outcome loss': 0.1360183361016671, 'Total loss': 0.1360183361016671}
2022-12-31 08:29:27,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:27,865 INFO:     Epoch: 46
2022-12-31 08:29:29,496 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5119183599948883, 'Total loss': 0.5119183599948883} | train loss {'Reaction outcome loss': 0.13425586553498942, 'Total loss': 0.13425586553498942}
2022-12-31 08:29:29,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:29,496 INFO:     Epoch: 47
2022-12-31 08:29:31,130 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4942454238732656, 'Total loss': 0.4942454238732656} | train loss {'Reaction outcome loss': 0.13803648739878344, 'Total loss': 0.13803648739878344}
2022-12-31 08:29:31,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:31,130 INFO:     Epoch: 48
2022-12-31 08:29:32,763 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46807411511739094, 'Total loss': 0.46807411511739094} | train loss {'Reaction outcome loss': 0.1291824107861906, 'Total loss': 0.1291824107861906}
2022-12-31 08:29:32,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:32,764 INFO:     Epoch: 49
2022-12-31 08:29:34,385 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4912990878025691, 'Total loss': 0.4912990878025691} | train loss {'Reaction outcome loss': 0.1347806014470245, 'Total loss': 0.1347806014470245}
2022-12-31 08:29:34,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:34,386 INFO:     Epoch: 50
2022-12-31 08:29:36,012 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48490892549355824, 'Total loss': 0.48490892549355824} | train loss {'Reaction outcome loss': 0.12849768872678763, 'Total loss': 0.12849768872678763}
2022-12-31 08:29:36,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:36,012 INFO:     Epoch: 51
2022-12-31 08:29:37,644 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.472779905796051, 'Total loss': 0.472779905796051} | train loss {'Reaction outcome loss': 0.1312621702231628, 'Total loss': 0.1312621702231628}
2022-12-31 08:29:37,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:37,645 INFO:     Epoch: 52
2022-12-31 08:29:39,277 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49235784709453584, 'Total loss': 0.49235784709453584} | train loss {'Reaction outcome loss': 0.13126207975542933, 'Total loss': 0.13126207975542933}
2022-12-31 08:29:39,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:39,277 INFO:     Epoch: 53
2022-12-31 08:29:40,908 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4662800838549932, 'Total loss': 0.4662800838549932} | train loss {'Reaction outcome loss': 0.12843205501907085, 'Total loss': 0.12843205501907085}
2022-12-31 08:29:40,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:40,908 INFO:     Epoch: 54
2022-12-31 08:29:42,539 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4766216297944387, 'Total loss': 0.4766216297944387} | train loss {'Reaction outcome loss': 0.12868808663621653, 'Total loss': 0.12868808663621653}
2022-12-31 08:29:42,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:42,540 INFO:     Epoch: 55
2022-12-31 08:29:44,185 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4892013301452001, 'Total loss': 0.4892013301452001} | train loss {'Reaction outcome loss': 0.12936348307017062, 'Total loss': 0.12936348307017062}
2022-12-31 08:29:44,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:44,186 INFO:     Epoch: 56
2022-12-31 08:29:45,792 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4669922351837158, 'Total loss': 0.4669922351837158} | train loss {'Reaction outcome loss': 0.12810281003465615, 'Total loss': 0.12810281003465615}
2022-12-31 08:29:45,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:45,792 INFO:     Epoch: 57
2022-12-31 08:29:47,407 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4844323436419169, 'Total loss': 0.4844323436419169} | train loss {'Reaction outcome loss': 0.1274351375143881, 'Total loss': 0.1274351375143881}
2022-12-31 08:29:47,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:47,407 INFO:     Epoch: 58
2022-12-31 08:29:49,071 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.477479887008667, 'Total loss': 0.477479887008667} | train loss {'Reaction outcome loss': 0.12613918066582902, 'Total loss': 0.12613918066582902}
2022-12-31 08:29:49,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:49,071 INFO:     Epoch: 59
2022-12-31 08:29:50,686 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4328399419784546, 'Total loss': 0.4328399419784546} | train loss {'Reaction outcome loss': 0.12642368111450103, 'Total loss': 0.12642368111450103}
2022-12-31 08:29:50,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:50,686 INFO:     Epoch: 60
2022-12-31 08:29:52,338 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4804298977057139, 'Total loss': 0.4804298977057139} | train loss {'Reaction outcome loss': 0.12136858311021156, 'Total loss': 0.12136858311021156}
2022-12-31 08:29:52,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:52,338 INFO:     Epoch: 61
2022-12-31 08:29:53,951 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4915801445643107, 'Total loss': 0.4915801445643107} | train loss {'Reaction outcome loss': 0.12088117319821558, 'Total loss': 0.12088117319821558}
2022-12-31 08:29:53,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:53,951 INFO:     Epoch: 62
2022-12-31 08:29:55,565 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4729387849569321, 'Total loss': 0.4729387849569321} | train loss {'Reaction outcome loss': 0.12228287175291012, 'Total loss': 0.12228287175291012}
2022-12-31 08:29:55,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:55,566 INFO:     Epoch: 63
2022-12-31 08:29:57,233 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46765881379445395, 'Total loss': 0.46765881379445395} | train loss {'Reaction outcome loss': 0.1199742305657359, 'Total loss': 0.1199742305657359}
2022-12-31 08:29:57,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:57,234 INFO:     Epoch: 64
2022-12-31 08:29:58,847 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.442269267141819, 'Total loss': 0.442269267141819} | train loss {'Reaction outcome loss': 0.1239235085193135, 'Total loss': 0.1239235085193135}
2022-12-31 08:29:58,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:29:58,847 INFO:     Epoch: 65
2022-12-31 08:30:00,515 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4748364215095838, 'Total loss': 0.4748364215095838} | train loss {'Reaction outcome loss': 0.11978680982896621, 'Total loss': 0.11978680982896621}
2022-12-31 08:30:00,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:00,516 INFO:     Epoch: 66
2022-12-31 08:30:02,136 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4609406510988871, 'Total loss': 0.4609406510988871} | train loss {'Reaction outcome loss': 0.12437433173160475, 'Total loss': 0.12437433173160475}
2022-12-31 08:30:02,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:02,137 INFO:     Epoch: 67
2022-12-31 08:30:03,757 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4689455032348633, 'Total loss': 0.4689455032348633} | train loss {'Reaction outcome loss': 0.12345473169238182, 'Total loss': 0.12345473169238182}
2022-12-31 08:30:03,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:03,758 INFO:     Epoch: 68
2022-12-31 08:30:05,391 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4864241272211075, 'Total loss': 0.4864241272211075} | train loss {'Reaction outcome loss': 0.12487931655289518, 'Total loss': 0.12487931655289518}
2022-12-31 08:30:05,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:05,391 INFO:     Epoch: 69
2022-12-31 08:30:07,023 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4597958301504453, 'Total loss': 0.4597958301504453} | train loss {'Reaction outcome loss': 0.12260004478449586, 'Total loss': 0.12260004478449586}
2022-12-31 08:30:07,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:07,023 INFO:     Epoch: 70
2022-12-31 08:30:08,657 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4625583526988824, 'Total loss': 0.4625583526988824} | train loss {'Reaction outcome loss': 0.11840113096732632, 'Total loss': 0.11840113096732632}
2022-12-31 08:30:08,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:08,657 INFO:     Epoch: 71
2022-12-31 08:30:10,285 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4585216909646988, 'Total loss': 0.4585216909646988} | train loss {'Reaction outcome loss': 0.11474452065539274, 'Total loss': 0.11474452065539274}
2022-12-31 08:30:10,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:10,286 INFO:     Epoch: 72
2022-12-31 08:30:11,903 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4570086359977722, 'Total loss': 0.4570086359977722} | train loss {'Reaction outcome loss': 0.11675556319419443, 'Total loss': 0.11675556319419443}
2022-12-31 08:30:11,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:11,904 INFO:     Epoch: 73
2022-12-31 08:30:13,525 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.458359357714653, 'Total loss': 0.458359357714653} | train loss {'Reaction outcome loss': 0.11558531533753573, 'Total loss': 0.11558531533753573}
2022-12-31 08:30:13,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:13,526 INFO:     Epoch: 74
2022-12-31 08:30:15,148 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48734154204527536, 'Total loss': 0.48734154204527536} | train loss {'Reaction outcome loss': 0.12039169054041324, 'Total loss': 0.12039169054041324}
2022-12-31 08:30:15,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:15,149 INFO:     Epoch: 75
2022-12-31 08:30:16,817 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44998893116911254, 'Total loss': 0.44998893116911254} | train loss {'Reaction outcome loss': 0.1196979049455361, 'Total loss': 0.1196979049455361}
2022-12-31 08:30:16,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:16,817 INFO:     Epoch: 76
2022-12-31 08:30:18,440 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5160148799419403, 'Total loss': 0.5160148799419403} | train loss {'Reaction outcome loss': 0.11636448088219718, 'Total loss': 0.11636448088219718}
2022-12-31 08:30:18,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:18,440 INFO:     Epoch: 77
2022-12-31 08:30:20,077 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4714889133969943, 'Total loss': 0.4714889133969943} | train loss {'Reaction outcome loss': 0.1164981327406282, 'Total loss': 0.1164981327406282}
2022-12-31 08:30:20,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:20,078 INFO:     Epoch: 78
2022-12-31 08:30:21,717 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49141044119993843, 'Total loss': 0.49141044119993843} | train loss {'Reaction outcome loss': 0.11724689256211589, 'Total loss': 0.11724689256211589}
2022-12-31 08:30:21,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:21,717 INFO:     Epoch: 79
2022-12-31 08:30:23,386 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48079788982868193, 'Total loss': 0.48079788982868193} | train loss {'Reaction outcome loss': 0.11451363452585811, 'Total loss': 0.11451363452585811}
2022-12-31 08:30:23,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:23,386 INFO:     Epoch: 80
2022-12-31 08:30:25,009 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.467607781291008, 'Total loss': 0.467607781291008} | train loss {'Reaction outcome loss': 0.11778269332769707, 'Total loss': 0.11778269332769707}
2022-12-31 08:30:25,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:25,010 INFO:     Epoch: 81
2022-12-31 08:30:26,629 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4640959084033966, 'Total loss': 0.4640959084033966} | train loss {'Reaction outcome loss': 0.11272977464008632, 'Total loss': 0.11272977464008632}
2022-12-31 08:30:26,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:26,629 INFO:     Epoch: 82
2022-12-31 08:30:28,297 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5090115249156952, 'Total loss': 0.5090115249156952} | train loss {'Reaction outcome loss': 0.11698159644723154, 'Total loss': 0.11698159644723154}
2022-12-31 08:30:28,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:28,298 INFO:     Epoch: 83
2022-12-31 08:30:29,911 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48566468954086306, 'Total loss': 0.48566468954086306} | train loss {'Reaction outcome loss': 0.11214050625884629, 'Total loss': 0.11214050625884629}
2022-12-31 08:30:29,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:29,911 INFO:     Epoch: 84
2022-12-31 08:30:31,540 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4491776863733927, 'Total loss': 0.4491776863733927} | train loss {'Reaction outcome loss': 0.11408297917704747, 'Total loss': 0.11408297917704747}
2022-12-31 08:30:31,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:31,540 INFO:     Epoch: 85
2022-12-31 08:30:33,168 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47412225206693015, 'Total loss': 0.47412225206693015} | train loss {'Reaction outcome loss': 0.11285162091403124, 'Total loss': 0.11285162091403124}
2022-12-31 08:30:33,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:33,168 INFO:     Epoch: 86
2022-12-31 08:30:34,795 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4583384315172831, 'Total loss': 0.4583384315172831} | train loss {'Reaction outcome loss': 0.11476336426811044, 'Total loss': 0.11476336426811044}
2022-12-31 08:30:34,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:34,795 INFO:     Epoch: 87
2022-12-31 08:30:36,423 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48518877029418944, 'Total loss': 0.48518877029418944} | train loss {'Reaction outcome loss': 0.1164088613666352, 'Total loss': 0.1164088613666352}
2022-12-31 08:30:36,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:36,423 INFO:     Epoch: 88
2022-12-31 08:30:38,043 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4856896668672562, 'Total loss': 0.4856896668672562} | train loss {'Reaction outcome loss': 0.11396920573914471, 'Total loss': 0.11396920573914471}
2022-12-31 08:30:38,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:38,043 INFO:     Epoch: 89
2022-12-31 08:30:39,663 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4422909061113993, 'Total loss': 0.4422909061113993} | train loss {'Reaction outcome loss': 0.1119427960197902, 'Total loss': 0.1119427960197902}
2022-12-31 08:30:39,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:39,663 INFO:     Epoch: 90
2022-12-31 08:30:41,292 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47527748545010884, 'Total loss': 0.47527748545010884} | train loss {'Reaction outcome loss': 0.11314924584957183, 'Total loss': 0.11314924584957183}
2022-12-31 08:30:41,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:41,292 INFO:     Epoch: 91
2022-12-31 08:30:42,925 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47376134594281516, 'Total loss': 0.47376134594281516} | train loss {'Reaction outcome loss': 0.10955562768672132, 'Total loss': 0.10955562768672132}
2022-12-31 08:30:42,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:42,926 INFO:     Epoch: 92
2022-12-31 08:30:44,557 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4730895111958186, 'Total loss': 0.4730895111958186} | train loss {'Reaction outcome loss': 0.11050396729580089, 'Total loss': 0.11050396729580089}
2022-12-31 08:30:44,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:44,558 INFO:     Epoch: 93
2022-12-31 08:30:46,191 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45859307249387105, 'Total loss': 0.45859307249387105} | train loss {'Reaction outcome loss': 0.10660634134536347, 'Total loss': 0.10660634134536347}
2022-12-31 08:30:46,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:46,191 INFO:     Epoch: 94
2022-12-31 08:30:47,835 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48489570369323093, 'Total loss': 0.48489570369323093} | train loss {'Reaction outcome loss': 0.11068467376333416, 'Total loss': 0.11068467376333416}
2022-12-31 08:30:47,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:47,836 INFO:     Epoch: 95
2022-12-31 08:30:49,462 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4927561620871226, 'Total loss': 0.4927561620871226} | train loss {'Reaction outcome loss': 0.1086748219776011, 'Total loss': 0.1086748219776011}
2022-12-31 08:30:49,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:49,462 INFO:     Epoch: 96
2022-12-31 08:30:51,135 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4557754218578339, 'Total loss': 0.4557754218578339} | train loss {'Reaction outcome loss': 0.11132500136593888, 'Total loss': 0.11132500136593888}
2022-12-31 08:30:51,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:51,135 INFO:     Epoch: 97
2022-12-31 08:30:52,808 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4835849483807882, 'Total loss': 0.4835849483807882} | train loss {'Reaction outcome loss': 0.1122134628853616, 'Total loss': 0.1122134628853616}
2022-12-31 08:30:52,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:52,808 INFO:     Epoch: 98
2022-12-31 08:30:54,438 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46670245826244355, 'Total loss': 0.46670245826244355} | train loss {'Reaction outcome loss': 0.10989726904867089, 'Total loss': 0.10989726904867089}
2022-12-31 08:30:54,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:54,439 INFO:     Epoch: 99
2022-12-31 08:30:56,060 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4684339741865794, 'Total loss': 0.4684339741865794} | train loss {'Reaction outcome loss': 0.10975272122632698, 'Total loss': 0.10975272122632698}
2022-12-31 08:30:56,060 INFO:     Best model found after epoch 6 of 100.
2022-12-31 08:30:56,060 INFO:   Done with stage: TRAINING
2022-12-31 08:30:56,060 INFO:   Starting stage: EVALUATION
2022-12-31 08:30:56,186 INFO:   Done with stage: EVALUATION
2022-12-31 08:30:56,186 INFO:   Leaving out SEQ value Fold_8
2022-12-31 08:30:56,198 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 08:30:56,198 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:30:56,853 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:30:56,854 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:30:56,920 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:30:56,920 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:30:56,921 INFO:     No hyperparam tuning for this model
2022-12-31 08:30:56,921 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:30:56,921 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:30:56,921 INFO:     None feature selector for col prot
2022-12-31 08:30:56,922 INFO:     None feature selector for col prot
2022-12-31 08:30:56,922 INFO:     None feature selector for col prot
2022-12-31 08:30:56,922 INFO:     None feature selector for col chem
2022-12-31 08:30:56,922 INFO:     None feature selector for col chem
2022-12-31 08:30:56,922 INFO:     None feature selector for col chem
2022-12-31 08:30:56,922 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:30:56,922 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:30:56,924 INFO:     Number of params in model 224011
2022-12-31 08:30:56,928 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:30:56,928 INFO:   Starting stage: TRAINING
2022-12-31 08:30:56,974 INFO:     Val loss before train {'Reaction outcome loss': 1.0490951816240945, 'Total loss': 1.0490951816240945}
2022-12-31 08:30:56,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:56,974 INFO:     Epoch: 0
2022-12-31 08:30:58,584 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5798564116160075, 'Total loss': 0.5798564116160075} | train loss {'Reaction outcome loss': 0.7815021882853369, 'Total loss': 0.7815021882853369}
2022-12-31 08:30:58,584 INFO:     Found new best model at epoch 0
2022-12-31 08:30:58,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:30:58,585 INFO:     Epoch: 1
2022-12-31 08:31:00,190 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4932844042778015, 'Total loss': 0.4932844042778015} | train loss {'Reaction outcome loss': 0.5216039880348818, 'Total loss': 0.5216039880348818}
2022-12-31 08:31:00,191 INFO:     Found new best model at epoch 1
2022-12-31 08:31:00,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:00,192 INFO:     Epoch: 2
2022-12-31 08:31:01,794 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46143753131230675, 'Total loss': 0.46143753131230675} | train loss {'Reaction outcome loss': 0.45719169330422893, 'Total loss': 0.45719169330422893}
2022-12-31 08:31:01,794 INFO:     Found new best model at epoch 2
2022-12-31 08:31:01,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:01,795 INFO:     Epoch: 3
2022-12-31 08:31:03,399 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43281794190406797, 'Total loss': 0.43281794190406797} | train loss {'Reaction outcome loss': 0.4158314316920991, 'Total loss': 0.4158314316920991}
2022-12-31 08:31:03,399 INFO:     Found new best model at epoch 3
2022-12-31 08:31:03,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:03,400 INFO:     Epoch: 4
2022-12-31 08:31:05,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45565103391806283, 'Total loss': 0.45565103391806283} | train loss {'Reaction outcome loss': 0.386961043955092, 'Total loss': 0.386961043955092}
2022-12-31 08:31:05,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:05,001 INFO:     Epoch: 5
2022-12-31 08:31:06,601 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.446947247783343, 'Total loss': 0.446947247783343} | train loss {'Reaction outcome loss': 0.3599860555335988, 'Total loss': 0.3599860555335988}
2022-12-31 08:31:06,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:06,602 INFO:     Epoch: 6
2022-12-31 08:31:08,214 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4017174164454142, 'Total loss': 0.4017174164454142} | train loss {'Reaction outcome loss': 0.34392587710035977, 'Total loss': 0.34392587710035977}
2022-12-31 08:31:08,214 INFO:     Found new best model at epoch 6
2022-12-31 08:31:08,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:08,215 INFO:     Epoch: 7
2022-12-31 08:31:09,826 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4129668434460958, 'Total loss': 0.4129668434460958} | train loss {'Reaction outcome loss': 0.3262587759344682, 'Total loss': 0.3262587759344682}
2022-12-31 08:31:09,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:09,827 INFO:     Epoch: 8
2022-12-31 08:31:11,439 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3992809265851974, 'Total loss': 0.3992809265851974} | train loss {'Reaction outcome loss': 0.30787580677845183, 'Total loss': 0.30787580677845183}
2022-12-31 08:31:11,439 INFO:     Found new best model at epoch 8
2022-12-31 08:31:11,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:11,440 INFO:     Epoch: 9
2022-12-31 08:31:13,052 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4090639034907023, 'Total loss': 0.4090639034907023} | train loss {'Reaction outcome loss': 0.29643566276959693, 'Total loss': 0.29643566276959693}
2022-12-31 08:31:13,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:13,052 INFO:     Epoch: 10
2022-12-31 08:31:14,654 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4299122949441274, 'Total loss': 0.4299122949441274} | train loss {'Reaction outcome loss': 0.28212719473199255, 'Total loss': 0.28212719473199255}
2022-12-31 08:31:14,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:14,654 INFO:     Epoch: 11
2022-12-31 08:31:16,293 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4094121515750885, 'Total loss': 0.4094121515750885} | train loss {'Reaction outcome loss': 0.2713026087323244, 'Total loss': 0.2713026087323244}
2022-12-31 08:31:16,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:16,294 INFO:     Epoch: 12
2022-12-31 08:31:17,896 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39539551039536797, 'Total loss': 0.39539551039536797} | train loss {'Reaction outcome loss': 0.2623466841849315, 'Total loss': 0.2623466841849315}
2022-12-31 08:31:17,896 INFO:     Found new best model at epoch 12
2022-12-31 08:31:17,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:17,897 INFO:     Epoch: 13
2022-12-31 08:31:19,500 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4115696946779887, 'Total loss': 0.4115696946779887} | train loss {'Reaction outcome loss': 0.25524152109712145, 'Total loss': 0.25524152109712145}
2022-12-31 08:31:19,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:19,500 INFO:     Epoch: 14
2022-12-31 08:31:21,103 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.403305313984553, 'Total loss': 0.403305313984553} | train loss {'Reaction outcome loss': 0.24357904206934203, 'Total loss': 0.24357904206934203}
2022-12-31 08:31:21,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:21,103 INFO:     Epoch: 15
2022-12-31 08:31:22,708 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40751814444859824, 'Total loss': 0.40751814444859824} | train loss {'Reaction outcome loss': 0.2420236619638048, 'Total loss': 0.2420236619638048}
2022-12-31 08:31:22,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:22,708 INFO:     Epoch: 16
2022-12-31 08:31:24,327 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40779345532258354, 'Total loss': 0.40779345532258354} | train loss {'Reaction outcome loss': 0.23168992250477963, 'Total loss': 0.23168992250477963}
2022-12-31 08:31:24,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:24,328 INFO:     Epoch: 17
2022-12-31 08:31:25,948 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38244906763235725, 'Total loss': 0.38244906763235725} | train loss {'Reaction outcome loss': 0.22354926045195464, 'Total loss': 0.22354926045195464}
2022-12-31 08:31:25,948 INFO:     Found new best model at epoch 17
2022-12-31 08:31:25,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:25,949 INFO:     Epoch: 18
2022-12-31 08:31:27,567 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4095798055330912, 'Total loss': 0.4095798055330912} | train loss {'Reaction outcome loss': 0.21497637711220632, 'Total loss': 0.21497637711220632}
2022-12-31 08:31:27,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:27,567 INFO:     Epoch: 19
2022-12-31 08:31:29,186 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3955413639545441, 'Total loss': 0.3955413639545441} | train loss {'Reaction outcome loss': 0.21209293527079978, 'Total loss': 0.21209293527079978}
2022-12-31 08:31:29,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:29,186 INFO:     Epoch: 20
2022-12-31 08:31:30,805 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4047888472676277, 'Total loss': 0.4047888472676277} | train loss {'Reaction outcome loss': 0.20945718284886683, 'Total loss': 0.20945718284886683}
2022-12-31 08:31:30,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:30,806 INFO:     Epoch: 21
2022-12-31 08:31:32,418 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3888483787576357, 'Total loss': 0.3888483787576357} | train loss {'Reaction outcome loss': 0.2004296212579484, 'Total loss': 0.2004296212579484}
2022-12-31 08:31:32,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:32,418 INFO:     Epoch: 22
2022-12-31 08:31:34,028 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41434227923552197, 'Total loss': 0.41434227923552197} | train loss {'Reaction outcome loss': 0.19916555606998013, 'Total loss': 0.19916555606998013}
2022-12-31 08:31:34,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:34,028 INFO:     Epoch: 23
2022-12-31 08:31:35,645 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4019245088100433, 'Total loss': 0.4019245088100433} | train loss {'Reaction outcome loss': 0.197769770126817, 'Total loss': 0.197769770126817}
2022-12-31 08:31:35,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:35,645 INFO:     Epoch: 24
2022-12-31 08:31:37,257 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4073926329612732, 'Total loss': 0.4073926329612732} | train loss {'Reaction outcome loss': 0.19079928580725933, 'Total loss': 0.19079928580725933}
2022-12-31 08:31:37,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:37,257 INFO:     Epoch: 25
2022-12-31 08:31:38,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3912157520651817, 'Total loss': 0.3912157520651817} | train loss {'Reaction outcome loss': 0.18984712790153976, 'Total loss': 0.18984712790153976}
2022-12-31 08:31:38,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:38,910 INFO:     Epoch: 26
2022-12-31 08:31:40,563 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41477493147055305, 'Total loss': 0.41477493147055305} | train loss {'Reaction outcome loss': 0.1870673874284338, 'Total loss': 0.1870673874284338}
2022-12-31 08:31:40,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:40,563 INFO:     Epoch: 27
2022-12-31 08:31:42,193 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4253941441575686, 'Total loss': 0.4253941441575686} | train loss {'Reaction outcome loss': 0.18115839455276728, 'Total loss': 0.18115839455276728}
2022-12-31 08:31:42,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:42,193 INFO:     Epoch: 28
2022-12-31 08:31:43,791 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43232970039049784, 'Total loss': 0.43232970039049784} | train loss {'Reaction outcome loss': 0.1778194075518281, 'Total loss': 0.1778194075518281}
2022-12-31 08:31:43,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:43,792 INFO:     Epoch: 29
2022-12-31 08:31:45,396 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3913444221019745, 'Total loss': 0.3913444221019745} | train loss {'Reaction outcome loss': 0.1734710514450269, 'Total loss': 0.1734710514450269}
2022-12-31 08:31:45,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:45,396 INFO:     Epoch: 30
2022-12-31 08:31:47,045 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3973636048535506, 'Total loss': 0.3973636048535506} | train loss {'Reaction outcome loss': 0.17776456255003484, 'Total loss': 0.17776456255003484}
2022-12-31 08:31:47,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:47,046 INFO:     Epoch: 31
2022-12-31 08:31:48,655 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4067744473616282, 'Total loss': 0.4067744473616282} | train loss {'Reaction outcome loss': 0.17194149412051604, 'Total loss': 0.17194149412051604}
2022-12-31 08:31:48,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:48,655 INFO:     Epoch: 32
2022-12-31 08:31:50,297 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4285787949959437, 'Total loss': 0.4285787949959437} | train loss {'Reaction outcome loss': 0.16453076910268324, 'Total loss': 0.16453076910268324}
2022-12-31 08:31:50,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:50,297 INFO:     Epoch: 33
2022-12-31 08:31:51,936 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40226929684480034, 'Total loss': 0.40226929684480034} | train loss {'Reaction outcome loss': 0.16505153394936428, 'Total loss': 0.16505153394936428}
2022-12-31 08:31:51,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:51,936 INFO:     Epoch: 34
2022-12-31 08:31:53,589 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4116404503583908, 'Total loss': 0.4116404503583908} | train loss {'Reaction outcome loss': 0.1641695059251285, 'Total loss': 0.1641695059251285}
2022-12-31 08:31:53,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:53,590 INFO:     Epoch: 35
2022-12-31 08:31:55,242 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4598859657843908, 'Total loss': 0.4598859657843908} | train loss {'Reaction outcome loss': 0.1590821903579644, 'Total loss': 0.1590821903579644}
2022-12-31 08:31:55,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:55,243 INFO:     Epoch: 36
2022-12-31 08:31:56,849 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4440500763555368, 'Total loss': 0.4440500763555368} | train loss {'Reaction outcome loss': 0.15835370369133178, 'Total loss': 0.15835370369133178}
2022-12-31 08:31:56,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:56,849 INFO:     Epoch: 37
2022-12-31 08:31:58,503 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4362000236908595, 'Total loss': 0.4362000236908595} | train loss {'Reaction outcome loss': 0.1564734995528294, 'Total loss': 0.1564734995528294}
2022-12-31 08:31:58,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:31:58,503 INFO:     Epoch: 38
2022-12-31 08:32:00,104 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42299574315547944, 'Total loss': 0.42299574315547944} | train loss {'Reaction outcome loss': 0.15426465558622332, 'Total loss': 0.15426465558622332}
2022-12-31 08:32:00,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:00,104 INFO:     Epoch: 39
2022-12-31 08:32:01,722 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4321214735507965, 'Total loss': 0.4321214735507965} | train loss {'Reaction outcome loss': 0.15461033420895573, 'Total loss': 0.15461033420895573}
2022-12-31 08:32:01,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:01,722 INFO:     Epoch: 40
2022-12-31 08:32:03,340 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42237658699353536, 'Total loss': 0.42237658699353536} | train loss {'Reaction outcome loss': 0.1499217607448027, 'Total loss': 0.1499217607448027}
2022-12-31 08:32:03,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:03,341 INFO:     Epoch: 41
2022-12-31 08:32:04,960 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4153705408175786, 'Total loss': 0.4153705408175786} | train loss {'Reaction outcome loss': 0.14896535336373062, 'Total loss': 0.14896535336373062}
2022-12-31 08:32:04,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:04,960 INFO:     Epoch: 42
2022-12-31 08:32:06,579 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4210400849580765, 'Total loss': 0.4210400849580765} | train loss {'Reaction outcome loss': 0.15184229902284097, 'Total loss': 0.15184229902284097}
2022-12-31 08:32:06,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:06,580 INFO:     Epoch: 43
2022-12-31 08:32:08,197 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42159957190354663, 'Total loss': 0.42159957190354663} | train loss {'Reaction outcome loss': 0.14862993678050865, 'Total loss': 0.14862993678050865}
2022-12-31 08:32:08,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:08,197 INFO:     Epoch: 44
2022-12-31 08:32:09,821 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4331459105014801, 'Total loss': 0.4331459105014801} | train loss {'Reaction outcome loss': 0.14309709782739352, 'Total loss': 0.14309709782739352}
2022-12-31 08:32:09,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:09,821 INFO:     Epoch: 45
2022-12-31 08:32:11,475 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41323765308285754, 'Total loss': 0.41323765308285754} | train loss {'Reaction outcome loss': 0.1443064692464188, 'Total loss': 0.1443064692464188}
2022-12-31 08:32:11,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:11,475 INFO:     Epoch: 46
2022-12-31 08:32:13,076 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39969538698593776, 'Total loss': 0.39969538698593776} | train loss {'Reaction outcome loss': 0.14707830307043301, 'Total loss': 0.14707830307043301}
2022-12-31 08:32:13,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:13,076 INFO:     Epoch: 47
2022-12-31 08:32:14,673 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45804055233796437, 'Total loss': 0.45804055233796437} | train loss {'Reaction outcome loss': 0.14723961139233768, 'Total loss': 0.14723961139233768}
2022-12-31 08:32:14,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:14,674 INFO:     Epoch: 48
2022-12-31 08:32:16,274 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.432673387726148, 'Total loss': 0.432673387726148} | train loss {'Reaction outcome loss': 0.1397685270491362, 'Total loss': 0.1397685270491362}
2022-12-31 08:32:16,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:16,274 INFO:     Epoch: 49
2022-12-31 08:32:17,913 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47667409827311835, 'Total loss': 0.47667409827311835} | train loss {'Reaction outcome loss': 0.13665736865517378, 'Total loss': 0.13665736865517378}
2022-12-31 08:32:17,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:17,913 INFO:     Epoch: 50
2022-12-31 08:32:19,530 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41451886743307115, 'Total loss': 0.41451886743307115} | train loss {'Reaction outcome loss': 0.14176291179245026, 'Total loss': 0.14176291179245026}
2022-12-31 08:32:19,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:19,531 INFO:     Epoch: 51
2022-12-31 08:32:21,184 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4471343477567037, 'Total loss': 0.4471343477567037} | train loss {'Reaction outcome loss': 0.14079949181241386, 'Total loss': 0.14079949181241386}
2022-12-31 08:32:21,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:21,184 INFO:     Epoch: 52
2022-12-31 08:32:22,788 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41515936752160393, 'Total loss': 0.41515936752160393} | train loss {'Reaction outcome loss': 0.13860449893400073, 'Total loss': 0.13860449893400073}
2022-12-31 08:32:22,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:22,788 INFO:     Epoch: 53
2022-12-31 08:32:24,392 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4334303120772044, 'Total loss': 0.4334303120772044} | train loss {'Reaction outcome loss': 0.13394614181780412, 'Total loss': 0.13394614181780412}
2022-12-31 08:32:24,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:24,392 INFO:     Epoch: 54
2022-12-31 08:32:26,047 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.428527957201004, 'Total loss': 0.428527957201004} | train loss {'Reaction outcome loss': 0.1365179239796053, 'Total loss': 0.1365179239796053}
2022-12-31 08:32:26,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:26,048 INFO:     Epoch: 55
2022-12-31 08:32:27,667 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40924551089604694, 'Total loss': 0.40924551089604694} | train loss {'Reaction outcome loss': 0.13157722211177766, 'Total loss': 0.13157722211177766}
2022-12-31 08:32:27,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:27,667 INFO:     Epoch: 56
2022-12-31 08:32:29,276 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.420263151327769, 'Total loss': 0.420263151327769} | train loss {'Reaction outcome loss': 0.12905478856125235, 'Total loss': 0.12905478856125235}
2022-12-31 08:32:29,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:29,276 INFO:     Epoch: 57
2022-12-31 08:32:30,893 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39777857065200806, 'Total loss': 0.39777857065200806} | train loss {'Reaction outcome loss': 0.13301610081443005, 'Total loss': 0.13301610081443005}
2022-12-31 08:32:30,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:30,894 INFO:     Epoch: 58
2022-12-31 08:32:32,511 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4194293260574341, 'Total loss': 0.4194293260574341} | train loss {'Reaction outcome loss': 0.13377820950402558, 'Total loss': 0.13377820950402558}
2022-12-31 08:32:32,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:32,512 INFO:     Epoch: 59
2022-12-31 08:32:34,128 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4289155294497808, 'Total loss': 0.4289155294497808} | train loss {'Reaction outcome loss': 0.1325363211816408, 'Total loss': 0.1325363211816408}
2022-12-31 08:32:34,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:34,128 INFO:     Epoch: 60
2022-12-31 08:32:35,744 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4168156584103902, 'Total loss': 0.4168156584103902} | train loss {'Reaction outcome loss': 0.12734523981157012, 'Total loss': 0.12734523981157012}
2022-12-31 08:32:35,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:35,745 INFO:     Epoch: 61
2022-12-31 08:32:37,348 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42689135770003, 'Total loss': 0.42689135770003} | train loss {'Reaction outcome loss': 0.13481869198973326, 'Total loss': 0.13481869198973326}
2022-12-31 08:32:37,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:37,348 INFO:     Epoch: 62
2022-12-31 08:32:38,966 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4113922288020452, 'Total loss': 0.4113922288020452} | train loss {'Reaction outcome loss': 0.1285312431439567, 'Total loss': 0.1285312431439567}
2022-12-31 08:32:38,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:38,966 INFO:     Epoch: 63
2022-12-31 08:32:40,583 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4122536997000376, 'Total loss': 0.4122536997000376} | train loss {'Reaction outcome loss': 0.1286362379935509, 'Total loss': 0.1286362379935509}
2022-12-31 08:32:40,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:40,583 INFO:     Epoch: 64
2022-12-31 08:32:42,201 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38845794995625815, 'Total loss': 0.38845794995625815} | train loss {'Reaction outcome loss': 0.12953626095949516, 'Total loss': 0.12953626095949516}
2022-12-31 08:32:42,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:42,201 INFO:     Epoch: 65
2022-12-31 08:32:43,817 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4489594464500745, 'Total loss': 0.4489594464500745} | train loss {'Reaction outcome loss': 0.1251782266759606, 'Total loss': 0.1251782266759606}
2022-12-31 08:32:43,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:43,818 INFO:     Epoch: 66
2022-12-31 08:32:45,427 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4276581759254138, 'Total loss': 0.4276581759254138} | train loss {'Reaction outcome loss': 0.12954957077592394, 'Total loss': 0.12954957077592394}
2022-12-31 08:32:45,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:45,427 INFO:     Epoch: 67
2022-12-31 08:32:47,024 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.426115620136261, 'Total loss': 0.426115620136261} | train loss {'Reaction outcome loss': 0.13213975029406103, 'Total loss': 0.13213975029406103}
2022-12-31 08:32:47,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:47,025 INFO:     Epoch: 68
2022-12-31 08:32:48,678 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40788412603239216, 'Total loss': 0.40788412603239216} | train loss {'Reaction outcome loss': 0.12213888877652668, 'Total loss': 0.12213888877652668}
2022-12-31 08:32:48,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:48,678 INFO:     Epoch: 69
2022-12-31 08:32:50,284 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41371723810831706, 'Total loss': 0.41371723810831706} | train loss {'Reaction outcome loss': 0.12927785027350713, 'Total loss': 0.12927785027350713}
2022-12-31 08:32:50,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:50,284 INFO:     Epoch: 70
2022-12-31 08:32:51,888 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41097807983557383, 'Total loss': 0.41097807983557383} | train loss {'Reaction outcome loss': 0.12667235372635624, 'Total loss': 0.12667235372635624}
2022-12-31 08:32:51,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:51,888 INFO:     Epoch: 71
2022-12-31 08:32:53,542 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46846035023530325, 'Total loss': 0.46846035023530325} | train loss {'Reaction outcome loss': 0.12221607868984533, 'Total loss': 0.12221607868984533}
2022-12-31 08:32:53,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:53,542 INFO:     Epoch: 72
2022-12-31 08:32:55,145 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41683123509089154, 'Total loss': 0.41683123509089154} | train loss {'Reaction outcome loss': 0.1248440969171152, 'Total loss': 0.1248440969171152}
2022-12-31 08:32:55,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:55,146 INFO:     Epoch: 73
2022-12-31 08:32:56,758 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46125921110312146, 'Total loss': 0.46125921110312146} | train loss {'Reaction outcome loss': 0.12538998988949876, 'Total loss': 0.12538998988949876}
2022-12-31 08:32:56,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:56,758 INFO:     Epoch: 74
2022-12-31 08:32:58,376 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42120298246542615, 'Total loss': 0.42120298246542615} | train loss {'Reaction outcome loss': 0.12397322452960223, 'Total loss': 0.12397322452960223}
2022-12-31 08:32:58,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:58,376 INFO:     Epoch: 75
2022-12-31 08:32:59,995 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4050616902609666, 'Total loss': 0.4050616902609666} | train loss {'Reaction outcome loss': 0.12141948064490066, 'Total loss': 0.12141948064490066}
2022-12-31 08:32:59,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:32:59,995 INFO:     Epoch: 76
2022-12-31 08:33:01,614 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45516860981782276, 'Total loss': 0.45516860981782276} | train loss {'Reaction outcome loss': 0.12233746329655558, 'Total loss': 0.12233746329655558}
2022-12-31 08:33:01,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:01,615 INFO:     Epoch: 77
2022-12-31 08:33:03,228 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4107883041103681, 'Total loss': 0.4107883041103681} | train loss {'Reaction outcome loss': 0.12280722791974834, 'Total loss': 0.12280722791974834}
2022-12-31 08:33:03,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:03,228 INFO:     Epoch: 78
2022-12-31 08:33:04,856 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4034228269631664, 'Total loss': 0.4034228269631664} | train loss {'Reaction outcome loss': 0.11702086606035757, 'Total loss': 0.11702086606035757}
2022-12-31 08:33:04,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:04,857 INFO:     Epoch: 79
2022-12-31 08:33:06,466 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43931989719470343, 'Total loss': 0.43931989719470343} | train loss {'Reaction outcome loss': 0.1186021831817925, 'Total loss': 0.1186021831817925}
2022-12-31 08:33:06,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:06,466 INFO:     Epoch: 80
2022-12-31 08:33:08,120 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41514466404914857, 'Total loss': 0.41514466404914857} | train loss {'Reaction outcome loss': 0.1254573192185702, 'Total loss': 0.1254573192185702}
2022-12-31 08:33:08,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:08,121 INFO:     Epoch: 81
2022-12-31 08:33:09,729 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45121252834796904, 'Total loss': 0.45121252834796904} | train loss {'Reaction outcome loss': 0.12192873228307351, 'Total loss': 0.12192873228307351}
2022-12-31 08:33:09,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:09,729 INFO:     Epoch: 82
2022-12-31 08:33:11,382 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42562178572018944, 'Total loss': 0.42562178572018944} | train loss {'Reaction outcome loss': 0.12177544098388213, 'Total loss': 0.12177544098388213}
2022-12-31 08:33:11,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:11,382 INFO:     Epoch: 83
2022-12-31 08:33:13,017 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4040468494097392, 'Total loss': 0.4040468494097392} | train loss {'Reaction outcome loss': 0.11874722639255117, 'Total loss': 0.11874722639255117}
2022-12-31 08:33:13,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:13,017 INFO:     Epoch: 84
2022-12-31 08:33:14,657 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4149531637628873, 'Total loss': 0.4149531637628873} | train loss {'Reaction outcome loss': 0.118820049181363, 'Total loss': 0.118820049181363}
2022-12-31 08:33:14,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:14,658 INFO:     Epoch: 85
2022-12-31 08:33:16,266 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4348561962445577, 'Total loss': 0.4348561962445577} | train loss {'Reaction outcome loss': 0.11974521028047876, 'Total loss': 0.11974521028047876}
2022-12-31 08:33:16,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:16,266 INFO:     Epoch: 86
2022-12-31 08:33:17,920 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41977416078249613, 'Total loss': 0.41977416078249613} | train loss {'Reaction outcome loss': 0.11824015963034037, 'Total loss': 0.11824015963034037}
2022-12-31 08:33:17,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:17,920 INFO:     Epoch: 87
2022-12-31 08:33:19,572 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42017842332522076, 'Total loss': 0.42017842332522076} | train loss {'Reaction outcome loss': 0.11587523389777617, 'Total loss': 0.11587523389777617}
2022-12-31 08:33:19,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:19,573 INFO:     Epoch: 88
2022-12-31 08:33:21,226 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4527553836504618, 'Total loss': 0.4527553836504618} | train loss {'Reaction outcome loss': 0.1200994359563873, 'Total loss': 0.1200994359563873}
2022-12-31 08:33:21,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:21,227 INFO:     Epoch: 89
2022-12-31 08:33:22,828 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.424393297235171, 'Total loss': 0.424393297235171} | train loss {'Reaction outcome loss': 0.11692751005774595, 'Total loss': 0.11692751005774595}
2022-12-31 08:33:22,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:22,829 INFO:     Epoch: 90
2022-12-31 08:33:24,482 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3907833541433016, 'Total loss': 0.3907833541433016} | train loss {'Reaction outcome loss': 0.11943867960163004, 'Total loss': 0.11943867960163004}
2022-12-31 08:33:24,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:24,483 INFO:     Epoch: 91
2022-12-31 08:33:26,136 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39772457629442215, 'Total loss': 0.39772457629442215} | train loss {'Reaction outcome loss': 0.11770057760478153, 'Total loss': 0.11770057760478153}
2022-12-31 08:33:26,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:26,136 INFO:     Epoch: 92
2022-12-31 08:33:27,744 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45952452917893727, 'Total loss': 0.45952452917893727} | train loss {'Reaction outcome loss': 0.11609257685690166, 'Total loss': 0.11609257685690166}
2022-12-31 08:33:27,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:27,744 INFO:     Epoch: 93
2022-12-31 08:33:29,397 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42214783529440564, 'Total loss': 0.42214783529440564} | train loss {'Reaction outcome loss': 0.11684832759337486, 'Total loss': 0.11684832759337486}
2022-12-31 08:33:29,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:29,397 INFO:     Epoch: 94
2022-12-31 08:33:30,992 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40610327025254567, 'Total loss': 0.40610327025254567} | train loss {'Reaction outcome loss': 0.11603413567789932, 'Total loss': 0.11603413567789932}
2022-12-31 08:33:30,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:30,992 INFO:     Epoch: 95
2022-12-31 08:33:32,600 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.389340990036726, 'Total loss': 0.389340990036726} | train loss {'Reaction outcome loss': 0.1180878291042508, 'Total loss': 0.1180878291042508}
2022-12-31 08:33:32,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:32,601 INFO:     Epoch: 96
2022-12-31 08:33:34,209 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4110254685084025, 'Total loss': 0.4110254685084025} | train loss {'Reaction outcome loss': 0.11457878720851439, 'Total loss': 0.11457878720851439}
2022-12-31 08:33:34,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:34,209 INFO:     Epoch: 97
2022-12-31 08:33:35,822 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4047114759683609, 'Total loss': 0.4047114759683609} | train loss {'Reaction outcome loss': 0.11212402510110044, 'Total loss': 0.11212402510110044}
2022-12-31 08:33:35,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:35,822 INFO:     Epoch: 98
2022-12-31 08:33:37,476 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42620134154955547, 'Total loss': 0.42620134154955547} | train loss {'Reaction outcome loss': 0.11766803292319668, 'Total loss': 0.11766803292319668}
2022-12-31 08:33:37,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:37,476 INFO:     Epoch: 99
2022-12-31 08:33:39,088 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46060778896013893, 'Total loss': 0.46060778896013893} | train loss {'Reaction outcome loss': 0.11698080163557817, 'Total loss': 0.11698080163557817}
2022-12-31 08:33:39,088 INFO:     Best model found after epoch 18 of 100.
2022-12-31 08:33:39,089 INFO:   Done with stage: TRAINING
2022-12-31 08:33:39,089 INFO:   Starting stage: EVALUATION
2022-12-31 08:33:39,225 INFO:   Done with stage: EVALUATION
2022-12-31 08:33:39,226 INFO:   Leaving out SEQ value Fold_9
2022-12-31 08:33:39,238 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 08:33:39,238 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:33:39,884 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:33:39,884 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:33:39,951 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:33:39,951 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:33:39,951 INFO:     No hyperparam tuning for this model
2022-12-31 08:33:39,951 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:33:39,951 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:33:39,952 INFO:     None feature selector for col prot
2022-12-31 08:33:39,952 INFO:     None feature selector for col prot
2022-12-31 08:33:39,952 INFO:     None feature selector for col prot
2022-12-31 08:33:39,953 INFO:     None feature selector for col chem
2022-12-31 08:33:39,953 INFO:     None feature selector for col chem
2022-12-31 08:33:39,953 INFO:     None feature selector for col chem
2022-12-31 08:33:39,953 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:33:39,953 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:33:39,955 INFO:     Number of params in model 224011
2022-12-31 08:33:39,958 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:33:39,958 INFO:   Starting stage: TRAINING
2022-12-31 08:33:40,004 INFO:     Val loss before train {'Reaction outcome loss': 1.0050241351127625, 'Total loss': 1.0050241351127625}
2022-12-31 08:33:40,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:40,004 INFO:     Epoch: 0
2022-12-31 08:33:41,632 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6151216864585877, 'Total loss': 0.6151216864585877} | train loss {'Reaction outcome loss': 0.7784902898027845, 'Total loss': 0.7784902898027845}
2022-12-31 08:33:41,632 INFO:     Found new best model at epoch 0
2022-12-31 08:33:41,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:41,633 INFO:     Epoch: 1
2022-12-31 08:33:43,265 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5476090550422669, 'Total loss': 0.5476090550422669} | train loss {'Reaction outcome loss': 0.5085676388179823, 'Total loss': 0.5085676388179823}
2022-12-31 08:33:43,265 INFO:     Found new best model at epoch 1
2022-12-31 08:33:43,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:43,266 INFO:     Epoch: 2
2022-12-31 08:33:44,897 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5013737738132477, 'Total loss': 0.5013737738132477} | train loss {'Reaction outcome loss': 0.4430954027651013, 'Total loss': 0.4430954027651013}
2022-12-31 08:33:44,897 INFO:     Found new best model at epoch 2
2022-12-31 08:33:44,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:44,898 INFO:     Epoch: 3
2022-12-31 08:33:46,517 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48243160049120587, 'Total loss': 0.48243160049120587} | train loss {'Reaction outcome loss': 0.403119654931209, 'Total loss': 0.403119654931209}
2022-12-31 08:33:46,518 INFO:     Found new best model at epoch 3
2022-12-31 08:33:46,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:46,519 INFO:     Epoch: 4
2022-12-31 08:33:48,142 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47055865128835045, 'Total loss': 0.47055865128835045} | train loss {'Reaction outcome loss': 0.38028755130759184, 'Total loss': 0.38028755130759184}
2022-12-31 08:33:48,142 INFO:     Found new best model at epoch 4
2022-12-31 08:33:48,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:48,143 INFO:     Epoch: 5
2022-12-31 08:33:49,751 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4675758918126424, 'Total loss': 0.4675758918126424} | train loss {'Reaction outcome loss': 0.36343758201500337, 'Total loss': 0.36343758201500337}
2022-12-31 08:33:49,751 INFO:     Found new best model at epoch 5
2022-12-31 08:33:49,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:49,752 INFO:     Epoch: 6
2022-12-31 08:33:51,418 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47096072435379027, 'Total loss': 0.47096072435379027} | train loss {'Reaction outcome loss': 0.33822013074667123, 'Total loss': 0.33822013074667123}
2022-12-31 08:33:51,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:51,419 INFO:     Epoch: 7
2022-12-31 08:33:53,039 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4682554682095846, 'Total loss': 0.4682554682095846} | train loss {'Reaction outcome loss': 0.3256920359056929, 'Total loss': 0.3256920359056929}
2022-12-31 08:33:53,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:53,039 INFO:     Epoch: 8
2022-12-31 08:33:54,661 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44250479886929195, 'Total loss': 0.44250479886929195} | train loss {'Reaction outcome loss': 0.3163505245870708, 'Total loss': 0.3163505245870708}
2022-12-31 08:33:54,661 INFO:     Found new best model at epoch 8
2022-12-31 08:33:54,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:54,663 INFO:     Epoch: 9
2022-12-31 08:33:56,284 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43414536913235985, 'Total loss': 0.43414536913235985} | train loss {'Reaction outcome loss': 0.29638810837438895, 'Total loss': 0.29638810837438895}
2022-12-31 08:33:56,284 INFO:     Found new best model at epoch 9
2022-12-31 08:33:56,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:56,286 INFO:     Epoch: 10
2022-12-31 08:33:57,900 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4566917657852173, 'Total loss': 0.4566917657852173} | train loss {'Reaction outcome loss': 0.28456062603863364, 'Total loss': 0.28456062603863364}
2022-12-31 08:33:57,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:57,901 INFO:     Epoch: 11
2022-12-31 08:33:59,165 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4797658671935399, 'Total loss': 0.4797658671935399} | train loss {'Reaction outcome loss': 0.2731740355620193, 'Total loss': 0.2731740355620193}
2022-12-31 08:33:59,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:33:59,166 INFO:     Epoch: 12
2022-12-31 08:34:00,575 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43841062088807425, 'Total loss': 0.43841062088807425} | train loss {'Reaction outcome loss': 0.2662880938867971, 'Total loss': 0.2662880938867971}
2022-12-31 08:34:00,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:00,575 INFO:     Epoch: 13
2022-12-31 08:34:01,985 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4478210896253586, 'Total loss': 0.4478210896253586} | train loss {'Reaction outcome loss': 0.25422422626170504, 'Total loss': 0.25422422626170504}
2022-12-31 08:34:01,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:01,985 INFO:     Epoch: 14
2022-12-31 08:34:03,548 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4436273217201233, 'Total loss': 0.4436273217201233} | train loss {'Reaction outcome loss': 0.24786277517737093, 'Total loss': 0.24786277517737093}
2022-12-31 08:34:03,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:03,548 INFO:     Epoch: 15
2022-12-31 08:34:05,163 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4403776953617732, 'Total loss': 0.4403776953617732} | train loss {'Reaction outcome loss': 0.2392692177045451, 'Total loss': 0.2392692177045451}
2022-12-31 08:34:05,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:05,163 INFO:     Epoch: 16
2022-12-31 08:34:06,778 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4492981553077698, 'Total loss': 0.4492981553077698} | train loss {'Reaction outcome loss': 0.2313057426324741, 'Total loss': 0.2313057426324741}
2022-12-31 08:34:06,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:06,778 INFO:     Epoch: 17
2022-12-31 08:34:08,387 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4269475996494293, 'Total loss': 0.4269475996494293} | train loss {'Reaction outcome loss': 0.22626904055065702, 'Total loss': 0.22626904055065702}
2022-12-31 08:34:08,389 INFO:     Found new best model at epoch 17
2022-12-31 08:34:08,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:08,390 INFO:     Epoch: 18
2022-12-31 08:34:10,004 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4143966297308604, 'Total loss': 0.4143966297308604} | train loss {'Reaction outcome loss': 0.2182502133393849, 'Total loss': 0.2182502133393849}
2022-12-31 08:34:10,004 INFO:     Found new best model at epoch 18
2022-12-31 08:34:10,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:10,005 INFO:     Epoch: 19
2022-12-31 08:34:11,618 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4402954995632172, 'Total loss': 0.4402954995632172} | train loss {'Reaction outcome loss': 0.21009891011973209, 'Total loss': 0.21009891011973209}
2022-12-31 08:34:11,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:11,618 INFO:     Epoch: 20
2022-12-31 08:34:13,253 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44177165428797405, 'Total loss': 0.44177165428797405} | train loss {'Reaction outcome loss': 0.2094201432723228, 'Total loss': 0.2094201432723228}
2022-12-31 08:34:13,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:13,253 INFO:     Epoch: 21
2022-12-31 08:34:14,879 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43928994983434677, 'Total loss': 0.43928994983434677} | train loss {'Reaction outcome loss': 0.21909180378872037, 'Total loss': 0.21909180378872037}
2022-12-31 08:34:14,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:14,879 INFO:     Epoch: 22
2022-12-31 08:34:16,503 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4209482858578364, 'Total loss': 0.4209482858578364} | train loss {'Reaction outcome loss': 0.20145180970734067, 'Total loss': 0.20145180970734067}
2022-12-31 08:34:16,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:16,503 INFO:     Epoch: 23
2022-12-31 08:34:18,167 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4385204871495565, 'Total loss': 0.4385204871495565} | train loss {'Reaction outcome loss': 0.19540307212087826, 'Total loss': 0.19540307212087826}
2022-12-31 08:34:18,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:18,168 INFO:     Epoch: 24
2022-12-31 08:34:19,790 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4493454496065776, 'Total loss': 0.4493454496065776} | train loss {'Reaction outcome loss': 0.19131108396149485, 'Total loss': 0.19131108396149485}
2022-12-31 08:34:19,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:19,790 INFO:     Epoch: 25
2022-12-31 08:34:21,440 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43390330076217654, 'Total loss': 0.43390330076217654} | train loss {'Reaction outcome loss': 0.18280394692598181, 'Total loss': 0.18280394692598181}
2022-12-31 08:34:21,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:21,440 INFO:     Epoch: 26
2022-12-31 08:34:23,104 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43382669389247897, 'Total loss': 0.43382669389247897} | train loss {'Reaction outcome loss': 0.18136986803543498, 'Total loss': 0.18136986803543498}
2022-12-31 08:34:23,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:23,105 INFO:     Epoch: 27
2022-12-31 08:34:24,726 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42178894008199375, 'Total loss': 0.42178894008199375} | train loss {'Reaction outcome loss': 0.17928358644797077, 'Total loss': 0.17928358644797077}
2022-12-31 08:34:24,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:24,726 INFO:     Epoch: 28
2022-12-31 08:34:26,345 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44023743470509846, 'Total loss': 0.44023743470509846} | train loss {'Reaction outcome loss': 0.18107923562975897, 'Total loss': 0.18107923562975897}
2022-12-31 08:34:26,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:26,345 INFO:     Epoch: 29
2022-12-31 08:34:27,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.438194144765536, 'Total loss': 0.438194144765536} | train loss {'Reaction outcome loss': 0.18496107700807246, 'Total loss': 0.18496107700807246}
2022-12-31 08:34:27,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:27,964 INFO:     Epoch: 30
2022-12-31 08:34:29,575 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45118500888347624, 'Total loss': 0.45118500888347624} | train loss {'Reaction outcome loss': 0.17057494508048546, 'Total loss': 0.17057494508048546}
2022-12-31 08:34:29,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:29,576 INFO:     Epoch: 31
2022-12-31 08:34:31,198 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4530165414015452, 'Total loss': 0.4530165414015452} | train loss {'Reaction outcome loss': 0.1682811668328266, 'Total loss': 0.1682811668328266}
2022-12-31 08:34:31,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:31,199 INFO:     Epoch: 32
2022-12-31 08:34:32,811 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42559806487212576, 'Total loss': 0.42559806487212576} | train loss {'Reaction outcome loss': 0.18273372531774035, 'Total loss': 0.18273372531774035}
2022-12-31 08:34:32,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:32,812 INFO:     Epoch: 33
2022-12-31 08:34:34,422 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46518379052480063, 'Total loss': 0.46518379052480063} | train loss {'Reaction outcome loss': 0.18397047658968865, 'Total loss': 0.18397047658968865}
2022-12-31 08:34:34,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:34,422 INFO:     Epoch: 34
2022-12-31 08:34:36,036 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.475589977701505, 'Total loss': 0.475589977701505} | train loss {'Reaction outcome loss': 0.16328080556263888, 'Total loss': 0.16328080556263888}
2022-12-31 08:34:36,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:36,036 INFO:     Epoch: 35
2022-12-31 08:34:37,701 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4456075762708982, 'Total loss': 0.4456075762708982} | train loss {'Reaction outcome loss': 0.15986282198244464, 'Total loss': 0.15986282198244464}
2022-12-31 08:34:37,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:37,701 INFO:     Epoch: 36
2022-12-31 08:34:39,313 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45629157026608785, 'Total loss': 0.45629157026608785} | train loss {'Reaction outcome loss': 0.16371005109470824, 'Total loss': 0.16371005109470824}
2022-12-31 08:34:39,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:39,314 INFO:     Epoch: 37
2022-12-31 08:34:40,949 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4559733748435974, 'Total loss': 0.4559733748435974} | train loss {'Reaction outcome loss': 0.1623627660637893, 'Total loss': 0.1623627660637893}
2022-12-31 08:34:40,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:40,949 INFO:     Epoch: 38
2022-12-31 08:34:42,585 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44154302378495536, 'Total loss': 0.44154302378495536} | train loss {'Reaction outcome loss': 0.15529698477189083, 'Total loss': 0.15529698477189083}
2022-12-31 08:34:42,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:42,585 INFO:     Epoch: 39
2022-12-31 08:34:44,211 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45769936541716255, 'Total loss': 0.45769936541716255} | train loss {'Reaction outcome loss': 0.1551546081558943, 'Total loss': 0.1551546081558943}
2022-12-31 08:34:44,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:44,211 INFO:     Epoch: 40
2022-12-31 08:34:45,844 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4456680317719777, 'Total loss': 0.4456680317719777} | train loss {'Reaction outcome loss': 0.1529051008055567, 'Total loss': 0.1529051008055567}
2022-12-31 08:34:45,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:45,845 INFO:     Epoch: 41
2022-12-31 08:34:47,480 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.451924654841423, 'Total loss': 0.451924654841423} | train loss {'Reaction outcome loss': 0.14882262734244106, 'Total loss': 0.14882262734244106}
2022-12-31 08:34:47,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:47,480 INFO:     Epoch: 42
2022-12-31 08:34:49,107 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43815708756446836, 'Total loss': 0.43815708756446836} | train loss {'Reaction outcome loss': 0.14916776738850193, 'Total loss': 0.14916776738850193}
2022-12-31 08:34:49,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:49,107 INFO:     Epoch: 43
2022-12-31 08:34:50,742 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4455792004863421, 'Total loss': 0.4455792004863421} | train loss {'Reaction outcome loss': 0.15018453757848887, 'Total loss': 0.15018453757848887}
2022-12-31 08:34:50,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:50,742 INFO:     Epoch: 44
2022-12-31 08:34:52,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4747444768746694, 'Total loss': 0.4747444768746694} | train loss {'Reaction outcome loss': 0.14523431630078593, 'Total loss': 0.14523431630078593}
2022-12-31 08:34:52,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:52,372 INFO:     Epoch: 45
2022-12-31 08:34:53,996 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43672328591346743, 'Total loss': 0.43672328591346743} | train loss {'Reaction outcome loss': 0.14469983847811818, 'Total loss': 0.14469983847811818}
2022-12-31 08:34:53,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:53,997 INFO:     Epoch: 46
2022-12-31 08:34:55,634 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46017382442951205, 'Total loss': 0.46017382442951205} | train loss {'Reaction outcome loss': 0.1477772943250349, 'Total loss': 0.1477772943250349}
2022-12-31 08:34:55,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:55,634 INFO:     Epoch: 47
2022-12-31 08:34:57,255 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47339680393536887, 'Total loss': 0.47339680393536887} | train loss {'Reaction outcome loss': 0.16985969656472688, 'Total loss': 0.16985969656472688}
2022-12-31 08:34:57,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:57,256 INFO:     Epoch: 48
2022-12-31 08:34:58,922 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4347375601530075, 'Total loss': 0.4347375601530075} | train loss {'Reaction outcome loss': 0.1432685083810888, 'Total loss': 0.1432685083810888}
2022-12-31 08:34:58,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:34:58,922 INFO:     Epoch: 49
2022-12-31 08:35:00,537 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46367845038572947, 'Total loss': 0.46367845038572947} | train loss {'Reaction outcome loss': 0.1399264537533821, 'Total loss': 0.1399264537533821}
2022-12-31 08:35:00,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:00,538 INFO:     Epoch: 50
2022-12-31 08:35:02,196 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4551681955655416, 'Total loss': 0.4551681955655416} | train loss {'Reaction outcome loss': 0.1421271561007218, 'Total loss': 0.1421271561007218}
2022-12-31 08:35:02,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:02,197 INFO:     Epoch: 51
2022-12-31 08:35:03,827 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4685797492663066, 'Total loss': 0.4685797492663066} | train loss {'Reaction outcome loss': 0.14103475460728657, 'Total loss': 0.14103475460728657}
2022-12-31 08:35:03,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:03,827 INFO:     Epoch: 52
2022-12-31 08:35:05,461 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4664645920197169, 'Total loss': 0.4664645920197169} | train loss {'Reaction outcome loss': 0.14085095359621555, 'Total loss': 0.14085095359621555}
2022-12-31 08:35:05,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:05,461 INFO:     Epoch: 53
2022-12-31 08:35:07,077 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4828505714734395, 'Total loss': 0.4828505714734395} | train loss {'Reaction outcome loss': 0.13730038575891557, 'Total loss': 0.13730038575891557}
2022-12-31 08:35:07,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:07,077 INFO:     Epoch: 54
2022-12-31 08:35:08,692 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4540126254161199, 'Total loss': 0.4540126254161199} | train loss {'Reaction outcome loss': 0.13667076231976735, 'Total loss': 0.13667076231976735}
2022-12-31 08:35:08,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:08,692 INFO:     Epoch: 55
2022-12-31 08:35:10,305 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44113307694594067, 'Total loss': 0.44113307694594067} | train loss {'Reaction outcome loss': 0.1335533347510795, 'Total loss': 0.1335533347510795}
2022-12-31 08:35:10,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:10,305 INFO:     Epoch: 56
2022-12-31 08:35:11,938 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48264949917793276, 'Total loss': 0.48264949917793276} | train loss {'Reaction outcome loss': 0.13120414935848743, 'Total loss': 0.13120414935848743}
2022-12-31 08:35:11,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:11,938 INFO:     Epoch: 57
2022-12-31 08:35:13,576 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4944486896197001, 'Total loss': 0.4944486896197001} | train loss {'Reaction outcome loss': 0.13843307458707874, 'Total loss': 0.13843307458707874}
2022-12-31 08:35:13,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:13,576 INFO:     Epoch: 58
2022-12-31 08:35:15,213 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45677788617710274, 'Total loss': 0.45677788617710274} | train loss {'Reaction outcome loss': 0.1355396046099064, 'Total loss': 0.1355396046099064}
2022-12-31 08:35:15,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:15,214 INFO:     Epoch: 59
2022-12-31 08:35:16,860 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.494509087006251, 'Total loss': 0.494509087006251} | train loss {'Reaction outcome loss': 0.1326185015622405, 'Total loss': 0.1326185015622405}
2022-12-31 08:35:16,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:16,860 INFO:     Epoch: 60
2022-12-31 08:35:18,521 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47897059718767804, 'Total loss': 0.47897059718767804} | train loss {'Reaction outcome loss': 0.1318064283890029, 'Total loss': 0.1318064283890029}
2022-12-31 08:35:18,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:18,521 INFO:     Epoch: 61
2022-12-31 08:35:20,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4791842669248581, 'Total loss': 0.4791842669248581} | train loss {'Reaction outcome loss': 0.13149860556628826, 'Total loss': 0.13149860556628826}
2022-12-31 08:35:20,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:20,165 INFO:     Epoch: 62
2022-12-31 08:35:21,824 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5064229120810827, 'Total loss': 0.5064229120810827} | train loss {'Reaction outcome loss': 0.12977352567448153, 'Total loss': 0.12977352567448153}
2022-12-31 08:35:21,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:21,825 INFO:     Epoch: 63
2022-12-31 08:35:23,440 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4767983595530192, 'Total loss': 0.4767983595530192} | train loss {'Reaction outcome loss': 0.1300434861568383, 'Total loss': 0.1300434861568383}
2022-12-31 08:35:23,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:23,440 INFO:     Epoch: 64
2022-12-31 08:35:25,078 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47780070106188455, 'Total loss': 0.47780070106188455} | train loss {'Reaction outcome loss': 0.13536420777996103, 'Total loss': 0.13536420777996103}
2022-12-31 08:35:25,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:25,078 INFO:     Epoch: 65
2022-12-31 08:35:26,696 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4551513190070788, 'Total loss': 0.4551513190070788} | train loss {'Reaction outcome loss': 0.12895834924874824, 'Total loss': 0.12895834924874824}
2022-12-31 08:35:26,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:26,697 INFO:     Epoch: 66
2022-12-31 08:35:28,357 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43673037787278496, 'Total loss': 0.43673037787278496} | train loss {'Reaction outcome loss': 0.12626945742907253, 'Total loss': 0.12626945742907253}
2022-12-31 08:35:28,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:28,357 INFO:     Epoch: 67
2022-12-31 08:35:29,983 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4964484184980392, 'Total loss': 0.4964484184980392} | train loss {'Reaction outcome loss': 0.12660703194315842, 'Total loss': 0.12660703194315842}
2022-12-31 08:35:29,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:29,984 INFO:     Epoch: 68
2022-12-31 08:35:31,609 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4879916171232859, 'Total loss': 0.4879916171232859} | train loss {'Reaction outcome loss': 0.1451445800046423, 'Total loss': 0.1451445800046423}
2022-12-31 08:35:31,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:31,609 INFO:     Epoch: 69
2022-12-31 08:35:33,236 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4837215214967728, 'Total loss': 0.4837215214967728} | train loss {'Reaction outcome loss': 0.17455824122779354, 'Total loss': 0.17455824122779354}
2022-12-31 08:35:33,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:33,236 INFO:     Epoch: 70
2022-12-31 08:35:34,855 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4694676578044891, 'Total loss': 0.4694676578044891} | train loss {'Reaction outcome loss': 0.13561725827689836, 'Total loss': 0.13561725827689836}
2022-12-31 08:35:34,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:34,856 INFO:     Epoch: 71
2022-12-31 08:35:36,482 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4996680955092112, 'Total loss': 0.4996680955092112} | train loss {'Reaction outcome loss': 0.12711101018678586, 'Total loss': 0.12711101018678586}
2022-12-31 08:35:36,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:36,483 INFO:     Epoch: 72
2022-12-31 08:35:38,103 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4881091554959615, 'Total loss': 0.4881091554959615} | train loss {'Reaction outcome loss': 0.12396116062439472, 'Total loss': 0.12396116062439472}
2022-12-31 08:35:38,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:38,103 INFO:     Epoch: 73
2022-12-31 08:35:39,718 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49253359958529475, 'Total loss': 0.49253359958529475} | train loss {'Reaction outcome loss': 0.12324847517859029, 'Total loss': 0.12324847517859029}
2022-12-31 08:35:39,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:39,718 INFO:     Epoch: 74
2022-12-31 08:35:41,371 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5611789246400197, 'Total loss': 0.5611789246400197} | train loss {'Reaction outcome loss': 0.12675891011486368, 'Total loss': 0.12675891011486368}
2022-12-31 08:35:41,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:41,371 INFO:     Epoch: 75
2022-12-31 08:35:43,022 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4672478561600049, 'Total loss': 0.4672478561600049} | train loss {'Reaction outcome loss': 0.12186719951273846, 'Total loss': 0.12186719951273846}
2022-12-31 08:35:43,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:43,022 INFO:     Epoch: 76
2022-12-31 08:35:44,649 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4649108201265335, 'Total loss': 0.4649108201265335} | train loss {'Reaction outcome loss': 0.12385309863911707, 'Total loss': 0.12385309863911707}
2022-12-31 08:35:44,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:44,650 INFO:     Epoch: 77
2022-12-31 08:35:46,279 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4602273633082708, 'Total loss': 0.4602273633082708} | train loss {'Reaction outcome loss': 0.12531906487487687, 'Total loss': 0.12531906487487687}
2022-12-31 08:35:46,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:46,279 INFO:     Epoch: 78
2022-12-31 08:35:47,890 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4726711601018906, 'Total loss': 0.4726711601018906} | train loss {'Reaction outcome loss': 0.12589224516009184, 'Total loss': 0.12589224516009184}
2022-12-31 08:35:47,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:47,890 INFO:     Epoch: 79
2022-12-31 08:35:49,555 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4767264723777771, 'Total loss': 0.4767264723777771} | train loss {'Reaction outcome loss': 0.12979143881776786, 'Total loss': 0.12979143881776786}
2022-12-31 08:35:49,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:49,555 INFO:     Epoch: 80
2022-12-31 08:35:51,220 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4788976420958837, 'Total loss': 0.4788976420958837} | train loss {'Reaction outcome loss': 0.12177617723194788, 'Total loss': 0.12177617723194788}
2022-12-31 08:35:51,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:51,221 INFO:     Epoch: 81
2022-12-31 08:35:52,862 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4648307094971339, 'Total loss': 0.4648307094971339} | train loss {'Reaction outcome loss': 0.11550729835500428, 'Total loss': 0.11550729835500428}
2022-12-31 08:35:52,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:52,862 INFO:     Epoch: 82
2022-12-31 08:35:54,528 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5139495839675268, 'Total loss': 0.5139495839675268} | train loss {'Reaction outcome loss': 0.11988216807620357, 'Total loss': 0.11988216807620357}
2022-12-31 08:35:54,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:54,528 INFO:     Epoch: 83
2022-12-31 08:35:56,145 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.463565664490064, 'Total loss': 0.463565664490064} | train loss {'Reaction outcome loss': 0.11821033531568768, 'Total loss': 0.11821033531568768}
2022-12-31 08:35:56,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:56,145 INFO:     Epoch: 84
2022-12-31 08:35:57,800 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48670080105463664, 'Total loss': 0.48670080105463664} | train loss {'Reaction outcome loss': 0.1143882034778379, 'Total loss': 0.1143882034778379}
2022-12-31 08:35:57,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:57,801 INFO:     Epoch: 85
2022-12-31 08:35:59,423 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4783792316913605, 'Total loss': 0.4783792316913605} | train loss {'Reaction outcome loss': 0.11756400934182634, 'Total loss': 0.11756400934182634}
2022-12-31 08:35:59,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:35:59,423 INFO:     Epoch: 86
2022-12-31 08:36:01,116 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45756472249825797, 'Total loss': 0.45756472249825797} | train loss {'Reaction outcome loss': 0.11319663110515503, 'Total loss': 0.11319663110515503}
2022-12-31 08:36:01,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:01,116 INFO:     Epoch: 87
2022-12-31 08:36:02,767 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4677548031012217, 'Total loss': 0.4677548031012217} | train loss {'Reaction outcome loss': 0.11465096382935504, 'Total loss': 0.11465096382935504}
2022-12-31 08:36:02,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:02,767 INFO:     Epoch: 88
2022-12-31 08:36:04,433 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5096644212802252, 'Total loss': 0.5096644212802252} | train loss {'Reaction outcome loss': 0.11747665789427128, 'Total loss': 0.11747665789427128}
2022-12-31 08:36:04,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:04,433 INFO:     Epoch: 89
2022-12-31 08:36:06,059 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4649994651476542, 'Total loss': 0.4649994651476542} | train loss {'Reaction outcome loss': 0.1152641462266584, 'Total loss': 0.1152641462266584}
2022-12-31 08:36:06,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:06,059 INFO:     Epoch: 90
2022-12-31 08:36:07,725 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4925542245308558, 'Total loss': 0.4925542245308558} | train loss {'Reaction outcome loss': 0.11601606170478444, 'Total loss': 0.11601606170478444}
2022-12-31 08:36:07,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:07,725 INFO:     Epoch: 91
2022-12-31 08:36:09,392 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45349641144275665, 'Total loss': 0.45349641144275665} | train loss {'Reaction outcome loss': 0.11826162536200845, 'Total loss': 0.11826162536200845}
2022-12-31 08:36:09,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:09,393 INFO:     Epoch: 92
2022-12-31 08:36:11,045 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49505992581446967, 'Total loss': 0.49505992581446967} | train loss {'Reaction outcome loss': 0.11815484499423608, 'Total loss': 0.11815484499423608}
2022-12-31 08:36:11,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:11,046 INFO:     Epoch: 93
2022-12-31 08:36:12,669 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.498021537065506, 'Total loss': 0.498021537065506} | train loss {'Reaction outcome loss': 0.11121098934318466, 'Total loss': 0.11121098934318466}
2022-12-31 08:36:12,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:12,669 INFO:     Epoch: 94
2022-12-31 08:36:14,334 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5289101560910543, 'Total loss': 0.5289101560910543} | train loss {'Reaction outcome loss': 0.1179164607998193, 'Total loss': 0.1179164607998193}
2022-12-31 08:36:14,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:14,334 INFO:     Epoch: 95
2022-12-31 08:36:15,982 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4742586314678192, 'Total loss': 0.4742586314678192} | train loss {'Reaction outcome loss': 0.11079368950964451, 'Total loss': 0.11079368950964451}
2022-12-31 08:36:15,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:15,982 INFO:     Epoch: 96
2022-12-31 08:36:17,647 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46025966505209603, 'Total loss': 0.46025966505209603} | train loss {'Reaction outcome loss': 0.11640616677249309, 'Total loss': 0.11640616677249309}
2022-12-31 08:36:17,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:17,647 INFO:     Epoch: 97
2022-12-31 08:36:19,313 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.459882515668869, 'Total loss': 0.459882515668869} | train loss {'Reaction outcome loss': 0.11548366264901562, 'Total loss': 0.11548366264901562}
2022-12-31 08:36:19,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:19,313 INFO:     Epoch: 98
2022-12-31 08:36:20,932 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4359901716777434, 'Total loss': 0.4359901716777434} | train loss {'Reaction outcome loss': 0.11107051639102292, 'Total loss': 0.11107051639102292}
2022-12-31 08:36:20,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:20,933 INFO:     Epoch: 99
2022-12-31 08:36:22,597 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4783145248889923, 'Total loss': 0.4783145248889923} | train loss {'Reaction outcome loss': 0.10918864782433957, 'Total loss': 0.10918864782433957}
2022-12-31 08:36:22,598 INFO:     Best model found after epoch 19 of 100.
2022-12-31 08:36:22,598 INFO:   Done with stage: TRAINING
2022-12-31 08:36:22,598 INFO:   Starting stage: EVALUATION
2022-12-31 08:36:22,730 INFO:   Done with stage: EVALUATION
2022-12-31 08:36:22,738 INFO:   Leaving out SEQ value Fold_0
2022-12-31 08:36:22,751 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 08:36:22,751 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:36:23,385 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:36:23,385 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:36:23,452 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:36:23,452 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:36:23,452 INFO:     No hyperparam tuning for this model
2022-12-31 08:36:23,452 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:36:23,452 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:36:23,453 INFO:     None feature selector for col prot
2022-12-31 08:36:23,453 INFO:     None feature selector for col prot
2022-12-31 08:36:23,453 INFO:     None feature selector for col prot
2022-12-31 08:36:23,454 INFO:     None feature selector for col chem
2022-12-31 08:36:23,454 INFO:     None feature selector for col chem
2022-12-31 08:36:23,454 INFO:     None feature selector for col chem
2022-12-31 08:36:23,454 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:36:23,454 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:36:23,456 INFO:     Number of params in model 224011
2022-12-31 08:36:23,459 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:36:23,459 INFO:   Starting stage: TRAINING
2022-12-31 08:36:23,504 INFO:     Val loss before train {'Reaction outcome loss': 0.9440984427928925, 'Total loss': 0.9440984427928925}
2022-12-31 08:36:23,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:23,504 INFO:     Epoch: 0
2022-12-31 08:36:25,099 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5190217852592468, 'Total loss': 0.5190217852592468} | train loss {'Reaction outcome loss': 0.7886263279457374, 'Total loss': 0.7886263279457374}
2022-12-31 08:36:25,099 INFO:     Found new best model at epoch 0
2022-12-31 08:36:25,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:25,100 INFO:     Epoch: 1
2022-12-31 08:36:26,705 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4222249130407969, 'Total loss': 0.4222249130407969} | train loss {'Reaction outcome loss': 0.5108764553751892, 'Total loss': 0.5108764553751892}
2022-12-31 08:36:26,706 INFO:     Found new best model at epoch 1
2022-12-31 08:36:26,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:26,707 INFO:     Epoch: 2
2022-12-31 08:36:28,311 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.41324523091316223, 'Total loss': 0.41324523091316223} | train loss {'Reaction outcome loss': 0.4397074664595822, 'Total loss': 0.4397074664595822}
2022-12-31 08:36:28,311 INFO:     Found new best model at epoch 2
2022-12-31 08:36:28,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:28,312 INFO:     Epoch: 3
2022-12-31 08:36:29,904 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.422589373588562, 'Total loss': 0.422589373588562} | train loss {'Reaction outcome loss': 0.40197124829811365, 'Total loss': 0.40197124829811365}
2022-12-31 08:36:29,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:29,904 INFO:     Epoch: 4
2022-12-31 08:36:31,511 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.37894907693068186, 'Total loss': 0.37894907693068186} | train loss {'Reaction outcome loss': 0.3739070292575993, 'Total loss': 0.3739070292575993}
2022-12-31 08:36:31,511 INFO:     Found new best model at epoch 4
2022-12-31 08:36:31,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:31,513 INFO:     Epoch: 5
2022-12-31 08:36:33,107 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.35236858973900476, 'Total loss': 0.35236858973900476} | train loss {'Reaction outcome loss': 0.350849856364771, 'Total loss': 0.350849856364771}
2022-12-31 08:36:33,108 INFO:     Found new best model at epoch 5
2022-12-31 08:36:33,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:33,109 INFO:     Epoch: 6
2022-12-31 08:36:34,711 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.36214823424816134, 'Total loss': 0.36214823424816134} | train loss {'Reaction outcome loss': 0.32684998898818485, 'Total loss': 0.32684998898818485}
2022-12-31 08:36:34,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:34,712 INFO:     Epoch: 7
2022-12-31 08:36:36,315 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38396234611670177, 'Total loss': 0.38396234611670177} | train loss {'Reaction outcome loss': 0.3098302684669345, 'Total loss': 0.3098302684669345}
2022-12-31 08:36:36,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:36,315 INFO:     Epoch: 8
2022-12-31 08:36:37,910 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.34968657394250235, 'Total loss': 0.34968657394250235} | train loss {'Reaction outcome loss': 0.29633527081391026, 'Total loss': 0.29633527081391026}
2022-12-31 08:36:37,910 INFO:     Found new best model at epoch 8
2022-12-31 08:36:37,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:37,911 INFO:     Epoch: 9
2022-12-31 08:36:39,502 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3893959830204646, 'Total loss': 0.3893959830204646} | train loss {'Reaction outcome loss': 0.2805583555787472, 'Total loss': 0.2805583555787472}
2022-12-31 08:36:39,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:39,502 INFO:     Epoch: 10
2022-12-31 08:36:41,087 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37137822806835175, 'Total loss': 0.37137822806835175} | train loss {'Reaction outcome loss': 0.2670328189031224, 'Total loss': 0.2670328189031224}
2022-12-31 08:36:41,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:41,087 INFO:     Epoch: 11
2022-12-31 08:36:42,686 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36121220886707306, 'Total loss': 0.36121220886707306} | train loss {'Reaction outcome loss': 0.2568065943643176, 'Total loss': 0.2568065943643176}
2022-12-31 08:36:42,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:42,686 INFO:     Epoch: 12
2022-12-31 08:36:44,318 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42806586623191833, 'Total loss': 0.42806586623191833} | train loss {'Reaction outcome loss': 0.2490126102942822, 'Total loss': 0.2490126102942822}
2022-12-31 08:36:44,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:44,318 INFO:     Epoch: 13
2022-12-31 08:36:45,951 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3715914616982142, 'Total loss': 0.3715914616982142} | train loss {'Reaction outcome loss': 0.2411983633805685, 'Total loss': 0.2411983633805685}
2022-12-31 08:36:45,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:45,952 INFO:     Epoch: 14
2022-12-31 08:36:47,563 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.34935499827067057, 'Total loss': 0.34935499827067057} | train loss {'Reaction outcome loss': 0.2291866695419009, 'Total loss': 0.2291866695419009}
2022-12-31 08:36:47,563 INFO:     Found new best model at epoch 14
2022-12-31 08:36:47,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:47,564 INFO:     Epoch: 15
2022-12-31 08:36:49,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3589981769522031, 'Total loss': 0.3589981769522031} | train loss {'Reaction outcome loss': 0.22357687083282593, 'Total loss': 0.22357687083282593}
2022-12-31 08:36:49,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:49,162 INFO:     Epoch: 16
2022-12-31 08:36:50,761 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.327408254891634, 'Total loss': 0.327408254891634} | train loss {'Reaction outcome loss': 0.2121868251901931, 'Total loss': 0.2121868251901931}
2022-12-31 08:36:50,761 INFO:     Found new best model at epoch 16
2022-12-31 08:36:50,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:50,762 INFO:     Epoch: 17
2022-12-31 08:36:52,352 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3627687096595764, 'Total loss': 0.3627687096595764} | train loss {'Reaction outcome loss': 0.20949216161569326, 'Total loss': 0.20949216161569326}
2022-12-31 08:36:52,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:52,353 INFO:     Epoch: 18
2022-12-31 08:36:53,952 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3572199702262878, 'Total loss': 0.3572199702262878} | train loss {'Reaction outcome loss': 0.20062024542903767, 'Total loss': 0.20062024542903767}
2022-12-31 08:36:53,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:53,952 INFO:     Epoch: 19
2022-12-31 08:36:55,550 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.34060563643773395, 'Total loss': 0.34060563643773395} | train loss {'Reaction outcome loss': 0.1971075686512728, 'Total loss': 0.1971075686512728}
2022-12-31 08:36:55,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:55,550 INFO:     Epoch: 20
2022-12-31 08:36:57,164 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3403819307684898, 'Total loss': 0.3403819307684898} | train loss {'Reaction outcome loss': 0.19248214317313858, 'Total loss': 0.19248214317313858}
2022-12-31 08:36:57,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:57,165 INFO:     Epoch: 21
2022-12-31 08:36:58,752 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40209075758854546, 'Total loss': 0.40209075758854546} | train loss {'Reaction outcome loss': 0.18840171372332365, 'Total loss': 0.18840171372332365}
2022-12-31 08:36:58,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:36:58,752 INFO:     Epoch: 22
2022-12-31 08:37:00,371 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4059895316759745, 'Total loss': 0.4059895316759745} | train loss {'Reaction outcome loss': 0.1829752930855839, 'Total loss': 0.1829752930855839}
2022-12-31 08:37:00,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:00,371 INFO:     Epoch: 23
2022-12-31 08:37:02,005 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37593671878178914, 'Total loss': 0.37593671878178914} | train loss {'Reaction outcome loss': 0.17866775097937163, 'Total loss': 0.17866775097937163}
2022-12-31 08:37:02,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:02,005 INFO:     Epoch: 24
2022-12-31 08:37:03,597 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36710657825072607, 'Total loss': 0.36710657825072607} | train loss {'Reaction outcome loss': 0.1751785994304612, 'Total loss': 0.1751785994304612}
2022-12-31 08:37:03,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:03,598 INFO:     Epoch: 25
2022-12-31 08:37:05,175 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35848962714274724, 'Total loss': 0.35848962714274724} | train loss {'Reaction outcome loss': 0.17008337110445948, 'Total loss': 0.17008337110445948}
2022-12-31 08:37:05,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:05,175 INFO:     Epoch: 26
2022-12-31 08:37:06,807 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3724116583665212, 'Total loss': 0.3724116583665212} | train loss {'Reaction outcome loss': 0.17106905665482322, 'Total loss': 0.17106905665482322}
2022-12-31 08:37:06,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:06,808 INFO:     Epoch: 27
2022-12-31 08:37:08,397 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38646912972132363, 'Total loss': 0.38646912972132363} | train loss {'Reaction outcome loss': 0.1628276494321348, 'Total loss': 0.1628276494321348}
2022-12-31 08:37:08,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:08,397 INFO:     Epoch: 28
2022-12-31 08:37:10,016 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38390380243460337, 'Total loss': 0.38390380243460337} | train loss {'Reaction outcome loss': 0.16114511930579628, 'Total loss': 0.16114511930579628}
2022-12-31 08:37:10,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:10,016 INFO:     Epoch: 29
2022-12-31 08:37:11,649 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3883376826842626, 'Total loss': 0.3883376826842626} | train loss {'Reaction outcome loss': 0.16098213117445967, 'Total loss': 0.16098213117445967}
2022-12-31 08:37:11,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:11,649 INFO:     Epoch: 30
2022-12-31 08:37:13,240 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37199534475803375, 'Total loss': 0.37199534475803375} | train loss {'Reaction outcome loss': 0.15562188227375714, 'Total loss': 0.15562188227375714}
2022-12-31 08:37:13,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:13,240 INFO:     Epoch: 31
2022-12-31 08:37:14,859 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3852018816396594, 'Total loss': 0.3852018816396594} | train loss {'Reaction outcome loss': 0.15367448233700326, 'Total loss': 0.15367448233700326}
2022-12-31 08:37:14,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:14,859 INFO:     Epoch: 32
2022-12-31 08:37:16,492 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35364475697278974, 'Total loss': 0.35364475697278974} | train loss {'Reaction outcome loss': 0.14927728846669197, 'Total loss': 0.14927728846669197}
2022-12-31 08:37:16,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:16,493 INFO:     Epoch: 33
2022-12-31 08:37:18,079 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36193574567635856, 'Total loss': 0.36193574567635856} | train loss {'Reaction outcome loss': 0.1483116295924101, 'Total loss': 0.1483116295924101}
2022-12-31 08:37:18,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:18,079 INFO:     Epoch: 34
2022-12-31 08:37:19,669 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38530041873455045, 'Total loss': 0.38530041873455045} | train loss {'Reaction outcome loss': 0.14713486513583424, 'Total loss': 0.14713486513583424}
2022-12-31 08:37:19,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:19,670 INFO:     Epoch: 35
2022-12-31 08:37:21,268 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40062979360421497, 'Total loss': 0.40062979360421497} | train loss {'Reaction outcome loss': 0.14273189744015133, 'Total loss': 0.14273189744015133}
2022-12-31 08:37:21,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:21,268 INFO:     Epoch: 36
2022-12-31 08:37:22,864 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39269883235295616, 'Total loss': 0.39269883235295616} | train loss {'Reaction outcome loss': 0.14176173716769777, 'Total loss': 0.14176173716769777}
2022-12-31 08:37:22,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:22,865 INFO:     Epoch: 37
2022-12-31 08:37:24,453 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3570994249389817, 'Total loss': 0.3570994249389817} | train loss {'Reaction outcome loss': 0.14218132154040067, 'Total loss': 0.14218132154040067}
2022-12-31 08:37:24,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:24,453 INFO:     Epoch: 38
2022-12-31 08:37:26,045 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40036328534285226, 'Total loss': 0.40036328534285226} | train loss {'Reaction outcome loss': 0.13724736936177329, 'Total loss': 0.13724736936177329}
2022-12-31 08:37:26,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:26,045 INFO:     Epoch: 39
2022-12-31 08:37:27,629 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36762916333973406, 'Total loss': 0.36762916333973406} | train loss {'Reaction outcome loss': 0.13512097896726258, 'Total loss': 0.13512097896726258}
2022-12-31 08:37:27,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:27,630 INFO:     Epoch: 40
2022-12-31 08:37:29,218 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3939491833249728, 'Total loss': 0.3939491833249728} | train loss {'Reaction outcome loss': 0.13361695579964517, 'Total loss': 0.13361695579964517}
2022-12-31 08:37:29,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:29,218 INFO:     Epoch: 41
2022-12-31 08:37:30,852 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41172374586264293, 'Total loss': 0.41172374586264293} | train loss {'Reaction outcome loss': 0.13476438551962486, 'Total loss': 0.13476438551962486}
2022-12-31 08:37:30,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:30,852 INFO:     Epoch: 42
2022-12-31 08:37:32,479 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37250677198171617, 'Total loss': 0.37250677198171617} | train loss {'Reaction outcome loss': 0.13133020611046864, 'Total loss': 0.13133020611046864}
2022-12-31 08:37:32,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:32,479 INFO:     Epoch: 43
2022-12-31 08:37:34,105 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44032515982786813, 'Total loss': 0.44032515982786813} | train loss {'Reaction outcome loss': 0.13386184637816245, 'Total loss': 0.13386184637816245}
2022-12-31 08:37:34,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:34,106 INFO:     Epoch: 44
2022-12-31 08:37:35,695 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3958875859777133, 'Total loss': 0.3958875859777133} | train loss {'Reaction outcome loss': 0.13177771004762268, 'Total loss': 0.13177771004762268}
2022-12-31 08:37:35,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:35,695 INFO:     Epoch: 45
2022-12-31 08:37:37,312 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3955381135145823, 'Total loss': 0.3955381135145823} | train loss {'Reaction outcome loss': 0.1262563343677065, 'Total loss': 0.1262563343677065}
2022-12-31 08:37:37,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:37,312 INFO:     Epoch: 46
2022-12-31 08:37:38,906 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3891345093647639, 'Total loss': 0.3891345093647639} | train loss {'Reaction outcome loss': 0.12883760484203532, 'Total loss': 0.12883760484203532}
2022-12-31 08:37:38,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:38,906 INFO:     Epoch: 47
2022-12-31 08:37:40,539 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3619586487611135, 'Total loss': 0.3619586487611135} | train loss {'Reaction outcome loss': 0.12762396523000405, 'Total loss': 0.12762396523000405}
2022-12-31 08:37:40,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:40,539 INFO:     Epoch: 48
2022-12-31 08:37:42,127 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39367030759652455, 'Total loss': 0.39367030759652455} | train loss {'Reaction outcome loss': 0.12376481097198445, 'Total loss': 0.12376481097198445}
2022-12-31 08:37:42,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:42,127 INFO:     Epoch: 49
2022-12-31 08:37:43,760 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3839045981566111, 'Total loss': 0.3839045981566111} | train loss {'Reaction outcome loss': 0.12154488241973563, 'Total loss': 0.12154488241973563}
2022-12-31 08:37:43,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:43,761 INFO:     Epoch: 50
2022-12-31 08:37:45,355 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4103979229927063, 'Total loss': 0.4103979229927063} | train loss {'Reaction outcome loss': 0.12190316591886081, 'Total loss': 0.12190316591886081}
2022-12-31 08:37:45,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:45,355 INFO:     Epoch: 51
2022-12-31 08:37:46,938 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4333387086788813, 'Total loss': 0.4333387086788813} | train loss {'Reaction outcome loss': 0.11960108945063724, 'Total loss': 0.11960108945063724}
2022-12-31 08:37:46,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:46,939 INFO:     Epoch: 52
2022-12-31 08:37:48,523 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3690991155182322, 'Total loss': 0.3690991155182322} | train loss {'Reaction outcome loss': 0.12004142867511214, 'Total loss': 0.12004142867511214}
2022-12-31 08:37:48,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:48,523 INFO:     Epoch: 53
2022-12-31 08:37:50,110 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40481797655423485, 'Total loss': 0.40481797655423485} | train loss {'Reaction outcome loss': 0.12131377238422852, 'Total loss': 0.12131377238422852}
2022-12-31 08:37:50,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:50,110 INFO:     Epoch: 54
2022-12-31 08:37:51,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.399864187836647, 'Total loss': 0.399864187836647} | train loss {'Reaction outcome loss': 0.1200481552340269, 'Total loss': 0.1200481552340269}
2022-12-31 08:37:51,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:51,714 INFO:     Epoch: 55
2022-12-31 08:37:53,347 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41204373066624006, 'Total loss': 0.41204373066624006} | train loss {'Reaction outcome loss': 0.11814369680961367, 'Total loss': 0.11814369680961367}
2022-12-31 08:37:53,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:53,347 INFO:     Epoch: 56
2022-12-31 08:37:54,972 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37914970765511197, 'Total loss': 0.37914970765511197} | train loss {'Reaction outcome loss': 0.12023376230136715, 'Total loss': 0.12023376230136715}
2022-12-31 08:37:54,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:54,972 INFO:     Epoch: 57
2022-12-31 08:37:56,545 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4080198384821415, 'Total loss': 0.4080198384821415} | train loss {'Reaction outcome loss': 0.11632766080865588, 'Total loss': 0.11632766080865588}
2022-12-31 08:37:56,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:56,545 INFO:     Epoch: 58
2022-12-31 08:37:58,178 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41150540510813394, 'Total loss': 0.41150540510813394} | train loss {'Reaction outcome loss': 0.11334536706932521, 'Total loss': 0.11334536706932521}
2022-12-31 08:37:58,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:58,180 INFO:     Epoch: 59
2022-12-31 08:37:59,755 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3970344136158625, 'Total loss': 0.3970344136158625} | train loss {'Reaction outcome loss': 0.1137310455371093, 'Total loss': 0.1137310455371093}
2022-12-31 08:37:59,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:37:59,755 INFO:     Epoch: 60
2022-12-31 08:38:01,346 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.414625941713651, 'Total loss': 0.414625941713651} | train loss {'Reaction outcome loss': 0.11516612625467794, 'Total loss': 0.11516612625467794}
2022-12-31 08:38:01,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:01,346 INFO:     Epoch: 61
2022-12-31 08:38:02,949 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3834669478237629, 'Total loss': 0.3834669478237629} | train loss {'Reaction outcome loss': 0.11421144629976407, 'Total loss': 0.11421144629976407}
2022-12-31 08:38:02,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:02,950 INFO:     Epoch: 62
2022-12-31 08:38:04,546 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37842825551827747, 'Total loss': 0.37842825551827747} | train loss {'Reaction outcome loss': 0.1123567386375692, 'Total loss': 0.1123567386375692}
2022-12-31 08:38:04,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:04,547 INFO:     Epoch: 63
2022-12-31 08:38:06,140 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3821240305900574, 'Total loss': 0.3821240305900574} | train loss {'Reaction outcome loss': 0.11071522623761058, 'Total loss': 0.11071522623761058}
2022-12-31 08:38:06,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:06,140 INFO:     Epoch: 64
2022-12-31 08:38:07,772 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38157992710669836, 'Total loss': 0.38157992710669836} | train loss {'Reaction outcome loss': 0.11000245343464189, 'Total loss': 0.11000245343464189}
2022-12-31 08:38:07,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:07,773 INFO:     Epoch: 65
2022-12-31 08:38:09,359 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3944790969292323, 'Total loss': 0.3944790969292323} | train loss {'Reaction outcome loss': 0.11094842460934361, 'Total loss': 0.11094842460934361}
2022-12-31 08:38:09,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:09,360 INFO:     Epoch: 66
2022-12-31 08:38:11,007 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3735798495511214, 'Total loss': 0.3735798495511214} | train loss {'Reaction outcome loss': 0.11265256118142765, 'Total loss': 0.11265256118142765}
2022-12-31 08:38:11,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:11,008 INFO:     Epoch: 67
2022-12-31 08:38:12,641 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38707968493302664, 'Total loss': 0.38707968493302664} | train loss {'Reaction outcome loss': 0.110294120817538, 'Total loss': 0.110294120817538}
2022-12-31 08:38:12,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:12,641 INFO:     Epoch: 68
2022-12-31 08:38:14,241 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39502868155638377, 'Total loss': 0.39502868155638377} | train loss {'Reaction outcome loss': 0.10799274108341698, 'Total loss': 0.10799274108341698}
2022-12-31 08:38:14,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:14,241 INFO:     Epoch: 69
2022-12-31 08:38:15,834 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4388129681348801, 'Total loss': 0.4388129681348801} | train loss {'Reaction outcome loss': 0.10923654273258887, 'Total loss': 0.10923654273258887}
2022-12-31 08:38:15,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:15,835 INFO:     Epoch: 70
2022-12-31 08:38:17,428 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3830719073613485, 'Total loss': 0.3830719073613485} | train loss {'Reaction outcome loss': 0.10519095663861044, 'Total loss': 0.10519095663861044}
2022-12-31 08:38:17,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:17,428 INFO:     Epoch: 71
2022-12-31 08:38:19,012 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41087589859962464, 'Total loss': 0.41087589859962464} | train loss {'Reaction outcome loss': 0.10589089253453393, 'Total loss': 0.10589089253453393}
2022-12-31 08:38:19,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:19,012 INFO:     Epoch: 72
2022-12-31 08:38:20,605 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41989437441031136, 'Total loss': 0.41989437441031136} | train loss {'Reaction outcome loss': 0.10318563126776766, 'Total loss': 0.10318563126776766}
2022-12-31 08:38:20,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:20,605 INFO:     Epoch: 73
2022-12-31 08:38:22,195 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4025117705265681, 'Total loss': 0.4025117705265681} | train loss {'Reaction outcome loss': 0.10765731241725852, 'Total loss': 0.10765731241725852}
2022-12-31 08:38:22,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:22,195 INFO:     Epoch: 74
2022-12-31 08:38:23,784 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36920681297779084, 'Total loss': 0.36920681297779084} | train loss {'Reaction outcome loss': 0.10732517217464635, 'Total loss': 0.10732517217464635}
2022-12-31 08:38:23,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:23,784 INFO:     Epoch: 75
2022-12-31 08:38:25,376 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.37519889761072894, 'Total loss': 0.37519889761072894} | train loss {'Reaction outcome loss': 0.10926047939552867, 'Total loss': 0.10926047939552867}
2022-12-31 08:38:25,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:25,377 INFO:     Epoch: 76
2022-12-31 08:38:26,974 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3804493596156438, 'Total loss': 0.3804493596156438} | train loss {'Reaction outcome loss': 0.10788406790973021, 'Total loss': 0.10788406790973021}
2022-12-31 08:38:26,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:26,974 INFO:     Epoch: 77
2022-12-31 08:38:28,570 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3684710420668125, 'Total loss': 0.3684710420668125} | train loss {'Reaction outcome loss': 0.10670152387531935, 'Total loss': 0.10670152387531935}
2022-12-31 08:38:28,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:28,571 INFO:     Epoch: 78
2022-12-31 08:38:30,172 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37082287470499675, 'Total loss': 0.37082287470499675} | train loss {'Reaction outcome loss': 0.10166173050956752, 'Total loss': 0.10166173050956752}
2022-12-31 08:38:30,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:30,172 INFO:     Epoch: 79
2022-12-31 08:38:31,764 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3592534434283152, 'Total loss': 0.3592534434283152} | train loss {'Reaction outcome loss': 0.10318941309982807, 'Total loss': 0.10318941309982807}
2022-12-31 08:38:31,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:31,765 INFO:     Epoch: 80
2022-12-31 08:38:33,366 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.391888294617335, 'Total loss': 0.391888294617335} | train loss {'Reaction outcome loss': 0.10246046106898092, 'Total loss': 0.10246046106898092}
2022-12-31 08:38:33,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:33,366 INFO:     Epoch: 81
2022-12-31 08:38:34,967 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3538265681922591, 'Total loss': 0.3538265681922591} | train loss {'Reaction outcome loss': 0.10456976442377863, 'Total loss': 0.10456976442377863}
2022-12-31 08:38:34,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:34,967 INFO:     Epoch: 82
2022-12-31 08:38:36,565 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38898481130599977, 'Total loss': 0.38898481130599977} | train loss {'Reaction outcome loss': 0.11092301042547717, 'Total loss': 0.11092301042547717}
2022-12-31 08:38:36,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:36,565 INFO:     Epoch: 83
2022-12-31 08:38:38,173 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39932748178641003, 'Total loss': 0.39932748178641003} | train loss {'Reaction outcome loss': 0.10569912700645791, 'Total loss': 0.10569912700645791}
2022-12-31 08:38:38,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:38,174 INFO:     Epoch: 84
2022-12-31 08:38:39,782 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4104215234518051, 'Total loss': 0.4104215234518051} | train loss {'Reaction outcome loss': 0.0978330195103033, 'Total loss': 0.0978330195103033}
2022-12-31 08:38:39,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:39,782 INFO:     Epoch: 85
2022-12-31 08:38:41,366 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3648679253955682, 'Total loss': 0.3648679253955682} | train loss {'Reaction outcome loss': 0.10422208620496506, 'Total loss': 0.10422208620496506}
2022-12-31 08:38:41,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:41,366 INFO:     Epoch: 86
2022-12-31 08:38:43,002 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.411352668205897, 'Total loss': 0.411352668205897} | train loss {'Reaction outcome loss': 0.10231541795140593, 'Total loss': 0.10231541795140593}
2022-12-31 08:38:43,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:43,002 INFO:     Epoch: 87
2022-12-31 08:38:44,638 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39307880302270254, 'Total loss': 0.39307880302270254} | train loss {'Reaction outcome loss': 0.10176941108498104, 'Total loss': 0.10176941108498104}
2022-12-31 08:38:44,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:44,639 INFO:     Epoch: 88
2022-12-31 08:38:46,253 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4499352355798086, 'Total loss': 0.4499352355798086} | train loss {'Reaction outcome loss': 0.1005208279346408, 'Total loss': 0.1005208279346408}
2022-12-31 08:38:46,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:46,253 INFO:     Epoch: 89
2022-12-31 08:38:47,860 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3949539949496587, 'Total loss': 0.3949539949496587} | train loss {'Reaction outcome loss': 0.10021138779227914, 'Total loss': 0.10021138779227914}
2022-12-31 08:38:47,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:47,861 INFO:     Epoch: 90
2022-12-31 08:38:49,468 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39199133510701356, 'Total loss': 0.39199133510701356} | train loss {'Reaction outcome loss': 0.10681500671108381, 'Total loss': 0.10681500671108381}
2022-12-31 08:38:49,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:49,468 INFO:     Epoch: 91
2022-12-31 08:38:51,068 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36387406090895336, 'Total loss': 0.36387406090895336} | train loss {'Reaction outcome loss': 0.10161021680526462, 'Total loss': 0.10161021680526462}
2022-12-31 08:38:51,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:51,069 INFO:     Epoch: 92
2022-12-31 08:38:52,675 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3774220942830046, 'Total loss': 0.3774220942830046} | train loss {'Reaction outcome loss': 0.10689771730054129, 'Total loss': 0.10689771730054129}
2022-12-31 08:38:52,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:52,675 INFO:     Epoch: 93
2022-12-31 08:38:54,286 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3737290671250472, 'Total loss': 0.3737290671250472} | train loss {'Reaction outcome loss': 0.10363495089818218, 'Total loss': 0.10363495089818218}
2022-12-31 08:38:54,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:54,286 INFO:     Epoch: 94
2022-12-31 08:38:55,874 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4027598430713018, 'Total loss': 0.4027598430713018} | train loss {'Reaction outcome loss': 0.10171536419100757, 'Total loss': 0.10171536419100757}
2022-12-31 08:38:55,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:55,874 INFO:     Epoch: 95
2022-12-31 08:38:57,466 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4343512341380119, 'Total loss': 0.4343512341380119} | train loss {'Reaction outcome loss': 0.09666900647025747, 'Total loss': 0.09666900647025747}
2022-12-31 08:38:57,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:57,467 INFO:     Epoch: 96
2022-12-31 08:38:58,996 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39179085354941584, 'Total loss': 0.39179085354941584} | train loss {'Reaction outcome loss': 0.0999871007754464, 'Total loss': 0.0999871007754464}
2022-12-31 08:38:58,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:38:58,996 INFO:     Epoch: 97
2022-12-31 08:39:00,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4109052399794261, 'Total loss': 0.4109052399794261} | train loss {'Reaction outcome loss': 0.10040800275995887, 'Total loss': 0.10040800275995887}
2022-12-31 08:39:00,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:00,087 INFO:     Epoch: 98
2022-12-31 08:39:01,170 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39861015031735103, 'Total loss': 0.39861015031735103} | train loss {'Reaction outcome loss': 0.10043827129091476, 'Total loss': 0.10043827129091476}
2022-12-31 08:39:01,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:01,171 INFO:     Epoch: 99
2022-12-31 08:39:02,267 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4084315498669942, 'Total loss': 0.4084315498669942} | train loss {'Reaction outcome loss': 0.09367913353030065, 'Total loss': 0.09367913353030065}
2022-12-31 08:39:02,267 INFO:     Best model found after epoch 17 of 100.
2022-12-31 08:39:02,268 INFO:   Done with stage: TRAINING
2022-12-31 08:39:02,268 INFO:   Starting stage: EVALUATION
2022-12-31 08:39:02,414 INFO:   Done with stage: EVALUATION
2022-12-31 08:39:02,414 INFO:   Leaving out SEQ value Fold_1
2022-12-31 08:39:02,427 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 08:39:02,427 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:39:03,067 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:39:03,067 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:39:03,134 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:39:03,134 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:39:03,134 INFO:     No hyperparam tuning for this model
2022-12-31 08:39:03,134 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:39:03,134 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:39:03,135 INFO:     None feature selector for col prot
2022-12-31 08:39:03,135 INFO:     None feature selector for col prot
2022-12-31 08:39:03,135 INFO:     None feature selector for col prot
2022-12-31 08:39:03,136 INFO:     None feature selector for col chem
2022-12-31 08:39:03,136 INFO:     None feature selector for col chem
2022-12-31 08:39:03,136 INFO:     None feature selector for col chem
2022-12-31 08:39:03,136 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:39:03,136 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:39:03,138 INFO:     Number of params in model 224011
2022-12-31 08:39:03,141 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:39:03,141 INFO:   Starting stage: TRAINING
2022-12-31 08:39:03,175 INFO:     Val loss before train {'Reaction outcome loss': 0.9242761770884196, 'Total loss': 0.9242761770884196}
2022-12-31 08:39:03,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:03,175 INFO:     Epoch: 0
2022-12-31 08:39:04,761 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.49044447938601177, 'Total loss': 0.49044447938601177} | train loss {'Reaction outcome loss': 0.7930908953621439, 'Total loss': 0.7930908953621439}
2022-12-31 08:39:04,762 INFO:     Found new best model at epoch 0
2022-12-31 08:39:04,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:04,763 INFO:     Epoch: 1
2022-12-31 08:39:06,417 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.413010170062383, 'Total loss': 0.413010170062383} | train loss {'Reaction outcome loss': 0.5306229673489167, 'Total loss': 0.5306229673489167}
2022-12-31 08:39:06,417 INFO:     Found new best model at epoch 1
2022-12-31 08:39:06,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:06,418 INFO:     Epoch: 2
2022-12-31 08:39:08,023 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.39113197127978006, 'Total loss': 0.39113197127978006} | train loss {'Reaction outcome loss': 0.459153415404097, 'Total loss': 0.459153415404097}
2022-12-31 08:39:08,023 INFO:     Found new best model at epoch 2
2022-12-31 08:39:08,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:08,024 INFO:     Epoch: 3
2022-12-31 08:39:09,630 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3433823784192403, 'Total loss': 0.3433823784192403} | train loss {'Reaction outcome loss': 0.4227014371622218, 'Total loss': 0.4227014371622218}
2022-12-31 08:39:09,630 INFO:     Found new best model at epoch 3
2022-12-31 08:39:09,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:09,631 INFO:     Epoch: 4
2022-12-31 08:39:11,239 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3269876738389333, 'Total loss': 0.3269876738389333} | train loss {'Reaction outcome loss': 0.3868578063854336, 'Total loss': 0.3868578063854336}
2022-12-31 08:39:11,240 INFO:     Found new best model at epoch 4
2022-12-31 08:39:11,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:11,241 INFO:     Epoch: 5
2022-12-31 08:39:12,844 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.2966667289535205, 'Total loss': 0.2966667289535205} | train loss {'Reaction outcome loss': 0.36270055294471937, 'Total loss': 0.36270055294471937}
2022-12-31 08:39:12,844 INFO:     Found new best model at epoch 5
2022-12-31 08:39:12,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:12,845 INFO:     Epoch: 6
2022-12-31 08:39:14,451 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3234346071879069, 'Total loss': 0.3234346071879069} | train loss {'Reaction outcome loss': 0.3403577610415264, 'Total loss': 0.3403577610415264}
2022-12-31 08:39:14,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:14,451 INFO:     Epoch: 7
2022-12-31 08:39:16,060 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.32663810104131696, 'Total loss': 0.32663810104131696} | train loss {'Reaction outcome loss': 0.3180125564282393, 'Total loss': 0.3180125564282393}
2022-12-31 08:39:16,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:16,060 INFO:     Epoch: 8
2022-12-31 08:39:17,715 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.29457044998804727, 'Total loss': 0.29457044998804727} | train loss {'Reaction outcome loss': 0.3034649546509677, 'Total loss': 0.3034649546509677}
2022-12-31 08:39:17,715 INFO:     Found new best model at epoch 8
2022-12-31 08:39:17,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:17,716 INFO:     Epoch: 9
2022-12-31 08:39:19,322 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.29499120091398556, 'Total loss': 0.29499120091398556} | train loss {'Reaction outcome loss': 0.28579652301260156, 'Total loss': 0.28579652301260156}
2022-12-31 08:39:19,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:19,322 INFO:     Epoch: 10
2022-12-31 08:39:20,938 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.303123672803243, 'Total loss': 0.303123672803243} | train loss {'Reaction outcome loss': 0.2746701737471523, 'Total loss': 0.2746701737471523}
2022-12-31 08:39:20,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:20,938 INFO:     Epoch: 11
2022-12-31 08:39:22,569 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3321856290102005, 'Total loss': 0.3321856290102005} | train loss {'Reaction outcome loss': 0.2646994511902767, 'Total loss': 0.2646994511902767}
2022-12-31 08:39:22,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:22,569 INFO:     Epoch: 12
2022-12-31 08:39:24,218 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3160415510336558, 'Total loss': 0.3160415510336558} | train loss {'Reaction outcome loss': 0.25266243990537895, 'Total loss': 0.25266243990537895}
2022-12-31 08:39:24,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:24,218 INFO:     Epoch: 13
2022-12-31 08:39:25,820 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.2909709721803665, 'Total loss': 0.2909709721803665} | train loss {'Reaction outcome loss': 0.2456028153372072, 'Total loss': 0.2456028153372072}
2022-12-31 08:39:25,820 INFO:     Found new best model at epoch 13
2022-12-31 08:39:25,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:25,821 INFO:     Epoch: 14
2022-12-31 08:39:27,425 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.2958531285325686, 'Total loss': 0.2958531285325686} | train loss {'Reaction outcome loss': 0.23380247504878654, 'Total loss': 0.23380247504878654}
2022-12-31 08:39:27,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:27,425 INFO:     Epoch: 15
2022-12-31 08:39:29,059 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.28374499728282293, 'Total loss': 0.28374499728282293} | train loss {'Reaction outcome loss': 0.22962865791535073, 'Total loss': 0.22962865791535073}
2022-12-31 08:39:29,059 INFO:     Found new best model at epoch 15
2022-12-31 08:39:29,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:29,060 INFO:     Epoch: 16
2022-12-31 08:39:30,662 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.2878534346818924, 'Total loss': 0.2878534346818924} | train loss {'Reaction outcome loss': 0.2251103204049605, 'Total loss': 0.2251103204049605}
2022-12-31 08:39:30,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:30,663 INFO:     Epoch: 17
2022-12-31 08:39:32,299 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.29823528230190277, 'Total loss': 0.29823528230190277} | train loss {'Reaction outcome loss': 0.21760837383649861, 'Total loss': 0.21760837383649861}
2022-12-31 08:39:32,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:32,299 INFO:     Epoch: 18
2022-12-31 08:39:33,948 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.30610279242197674, 'Total loss': 0.30610279242197674} | train loss {'Reaction outcome loss': 0.2131620146959585, 'Total loss': 0.2131620146959585}
2022-12-31 08:39:33,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:33,948 INFO:     Epoch: 19
2022-12-31 08:39:35,597 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3076342379053434, 'Total loss': 0.3076342379053434} | train loss {'Reaction outcome loss': 0.20830778382636989, 'Total loss': 0.20830778382636989}
2022-12-31 08:39:35,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:35,597 INFO:     Epoch: 20
2022-12-31 08:39:37,247 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.2832346464196841, 'Total loss': 0.2832346464196841} | train loss {'Reaction outcome loss': 0.20216609598783247, 'Total loss': 0.20216609598783247}
2022-12-31 08:39:37,254 INFO:     Found new best model at epoch 20
2022-12-31 08:39:37,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:37,255 INFO:     Epoch: 21
2022-12-31 08:39:38,872 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.299495796362559, 'Total loss': 0.299495796362559} | train loss {'Reaction outcome loss': 0.20046408154940518, 'Total loss': 0.20046408154940518}
2022-12-31 08:39:38,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:38,872 INFO:     Epoch: 22
2022-12-31 08:39:40,508 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.2987109829982122, 'Total loss': 0.2987109829982122} | train loss {'Reaction outcome loss': 0.19595464279562452, 'Total loss': 0.19595464279562452}
2022-12-31 08:39:40,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:40,510 INFO:     Epoch: 23
2022-12-31 08:39:42,116 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3098578890164693, 'Total loss': 0.3098578890164693} | train loss {'Reaction outcome loss': 0.19214552343163613, 'Total loss': 0.19214552343163613}
2022-12-31 08:39:42,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:42,116 INFO:     Epoch: 24
2022-12-31 08:39:43,766 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3045018052061399, 'Total loss': 0.3045018052061399} | train loss {'Reaction outcome loss': 0.18851596848481764, 'Total loss': 0.18851596848481764}
2022-12-31 08:39:43,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:43,767 INFO:     Epoch: 25
2022-12-31 08:39:45,416 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.2833862324555715, 'Total loss': 0.2833862324555715} | train loss {'Reaction outcome loss': 0.1853877014555309, 'Total loss': 0.1853877014555309}
2022-12-31 08:39:45,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:45,417 INFO:     Epoch: 26
2022-12-31 08:39:47,048 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.30809485018253324, 'Total loss': 0.30809485018253324} | train loss {'Reaction outcome loss': 0.1815766238668648, 'Total loss': 0.1815766238668648}
2022-12-31 08:39:47,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:47,049 INFO:     Epoch: 27
2022-12-31 08:39:48,683 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3212582434217135, 'Total loss': 0.3212582434217135} | train loss {'Reaction outcome loss': 0.1738396831414234, 'Total loss': 0.1738396831414234}
2022-12-31 08:39:48,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:48,683 INFO:     Epoch: 28
2022-12-31 08:39:50,291 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.311116087436676, 'Total loss': 0.311116087436676} | train loss {'Reaction outcome loss': 0.17638670390702949, 'Total loss': 0.17638670390702949}
2022-12-31 08:39:50,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:50,291 INFO:     Epoch: 29
2022-12-31 08:39:51,896 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.29300472935040794, 'Total loss': 0.29300472935040794} | train loss {'Reaction outcome loss': 0.17362723415241624, 'Total loss': 0.17362723415241624}
2022-12-31 08:39:51,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:51,897 INFO:     Epoch: 30
2022-12-31 08:39:53,502 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.30448949187994, 'Total loss': 0.30448949187994} | train loss {'Reaction outcome loss': 0.17171746938333024, 'Total loss': 0.17171746938333024}
2022-12-31 08:39:53,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:53,503 INFO:     Epoch: 31
2022-12-31 08:39:55,112 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.30653384029865266, 'Total loss': 0.30653384029865266} | train loss {'Reaction outcome loss': 0.1625734968926676, 'Total loss': 0.1625734968926676}
2022-12-31 08:39:55,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:55,112 INFO:     Epoch: 32
2022-12-31 08:39:56,714 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.30686838229497276, 'Total loss': 0.30686838229497276} | train loss {'Reaction outcome loss': 0.1615803767689062, 'Total loss': 0.1615803767689062}
2022-12-31 08:39:56,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:56,715 INFO:     Epoch: 33
2022-12-31 08:39:58,317 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.29310202995936074, 'Total loss': 0.29310202995936074} | train loss {'Reaction outcome loss': 0.16691132661390262, 'Total loss': 0.16691132661390262}
2022-12-31 08:39:58,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:58,317 INFO:     Epoch: 34
2022-12-31 08:39:59,928 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3281549726923307, 'Total loss': 0.3281549726923307} | train loss {'Reaction outcome loss': 0.1541795038421006, 'Total loss': 0.1541795038421006}
2022-12-31 08:39:59,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:39:59,928 INFO:     Epoch: 35
2022-12-31 08:40:01,538 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.31650435576836267, 'Total loss': 0.31650435576836267} | train loss {'Reaction outcome loss': 0.1562895343730729, 'Total loss': 0.1562895343730729}
2022-12-31 08:40:01,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:01,538 INFO:     Epoch: 36
2022-12-31 08:40:03,148 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.30404456704854965, 'Total loss': 0.30404456704854965} | train loss {'Reaction outcome loss': 0.15165953909516008, 'Total loss': 0.15165953909516008}
2022-12-31 08:40:03,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:03,148 INFO:     Epoch: 37
2022-12-31 08:40:04,757 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.2786310762166977, 'Total loss': 0.2786310762166977} | train loss {'Reaction outcome loss': 0.15267391258809906, 'Total loss': 0.15267391258809906}
2022-12-31 08:40:04,757 INFO:     Found new best model at epoch 37
2022-12-31 08:40:04,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:04,758 INFO:     Epoch: 38
2022-12-31 08:40:06,369 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3100788896282514, 'Total loss': 0.3100788896282514} | train loss {'Reaction outcome loss': 0.1504866756655167, 'Total loss': 0.1504866756655167}
2022-12-31 08:40:06,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:06,369 INFO:     Epoch: 39
2022-12-31 08:40:07,976 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.32491703927516935, 'Total loss': 0.32491703927516935} | train loss {'Reaction outcome loss': 0.14763300259849124, 'Total loss': 0.14763300259849124}
2022-12-31 08:40:07,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:07,976 INFO:     Epoch: 40
2022-12-31 08:40:09,629 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3218298296133677, 'Total loss': 0.3218298296133677} | train loss {'Reaction outcome loss': 0.14817486702036248, 'Total loss': 0.14817486702036248}
2022-12-31 08:40:09,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:09,629 INFO:     Epoch: 41
2022-12-31 08:40:11,281 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.30899909635384876, 'Total loss': 0.30899909635384876} | train loss {'Reaction outcome loss': 0.14488008387223647, 'Total loss': 0.14488008387223647}
2022-12-31 08:40:11,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:11,282 INFO:     Epoch: 42
2022-12-31 08:40:12,892 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.293781508008639, 'Total loss': 0.293781508008639} | train loss {'Reaction outcome loss': 0.14574519068641711, 'Total loss': 0.14574519068641711}
2022-12-31 08:40:12,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:12,892 INFO:     Epoch: 43
2022-12-31 08:40:14,541 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.2780921071767807, 'Total loss': 0.2780921071767807} | train loss {'Reaction outcome loss': 0.1422104307205627, 'Total loss': 0.1422104307205627}
2022-12-31 08:40:14,541 INFO:     Found new best model at epoch 43
2022-12-31 08:40:14,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:14,542 INFO:     Epoch: 44
2022-12-31 08:40:16,148 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.32310373286406197, 'Total loss': 0.32310373286406197} | train loss {'Reaction outcome loss': 0.1404487228184177, 'Total loss': 0.1404487228184177}
2022-12-31 08:40:16,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:16,149 INFO:     Epoch: 45
2022-12-31 08:40:17,753 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3003015877058109, 'Total loss': 0.3003015877058109} | train loss {'Reaction outcome loss': 0.1398597313567017, 'Total loss': 0.1398597313567017}
2022-12-31 08:40:17,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:17,754 INFO:     Epoch: 46
2022-12-31 08:40:19,367 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3201549182335536, 'Total loss': 0.3201549182335536} | train loss {'Reaction outcome loss': 0.14208854303906, 'Total loss': 0.14208854303906}
2022-12-31 08:40:19,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:19,367 INFO:     Epoch: 47
2022-12-31 08:40:20,983 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.28857409829894703, 'Total loss': 0.28857409829894703} | train loss {'Reaction outcome loss': 0.14180577330182503, 'Total loss': 0.14180577330182503}
2022-12-31 08:40:20,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:20,983 INFO:     Epoch: 48
2022-12-31 08:40:22,599 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3137566457192103, 'Total loss': 0.3137566457192103} | train loss {'Reaction outcome loss': 0.14038274294261677, 'Total loss': 0.14038274294261677}
2022-12-31 08:40:22,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:22,600 INFO:     Epoch: 49
2022-12-31 08:40:24,202 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3114587560296059, 'Total loss': 0.3114587560296059} | train loss {'Reaction outcome loss': 0.1364080995290683, 'Total loss': 0.1364080995290683}
2022-12-31 08:40:24,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:24,203 INFO:     Epoch: 50
2022-12-31 08:40:25,837 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.30186096429824827, 'Total loss': 0.30186096429824827} | train loss {'Reaction outcome loss': 0.13720243062864798, 'Total loss': 0.13720243062864798}
2022-12-31 08:40:25,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:25,837 INFO:     Epoch: 51
2022-12-31 08:40:27,453 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.31629926363627114, 'Total loss': 0.31629926363627114} | train loss {'Reaction outcome loss': 0.13944447148305766, 'Total loss': 0.13944447148305766}
2022-12-31 08:40:27,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:27,453 INFO:     Epoch: 52
2022-12-31 08:40:29,069 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.32766527831554415, 'Total loss': 0.32766527831554415} | train loss {'Reaction outcome loss': 0.13615389764444888, 'Total loss': 0.13615389764444888}
2022-12-31 08:40:29,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:29,070 INFO:     Epoch: 53
2022-12-31 08:40:30,687 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3127755949894587, 'Total loss': 0.3127755949894587} | train loss {'Reaction outcome loss': 0.13359233559819658, 'Total loss': 0.13359233559819658}
2022-12-31 08:40:30,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:30,688 INFO:     Epoch: 54
2022-12-31 08:40:32,301 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.2824702724814415, 'Total loss': 0.2824702724814415} | train loss {'Reaction outcome loss': 0.13255672274925576, 'Total loss': 0.13255672274925576}
2022-12-31 08:40:32,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:32,302 INFO:     Epoch: 55
2022-12-31 08:40:33,909 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3157345573107401, 'Total loss': 0.3157345573107401} | train loss {'Reaction outcome loss': 0.13488847909522425, 'Total loss': 0.13488847909522425}
2022-12-31 08:40:33,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:33,909 INFO:     Epoch: 56
2022-12-31 08:40:35,524 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3495764620602131, 'Total loss': 0.3495764620602131} | train loss {'Reaction outcome loss': 0.1327880039661579, 'Total loss': 0.1327880039661579}
2022-12-31 08:40:35,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:35,524 INFO:     Epoch: 57
2022-12-31 08:40:37,131 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3056847649315993, 'Total loss': 0.3056847649315993} | train loss {'Reaction outcome loss': 0.13428423105888612, 'Total loss': 0.13428423105888612}
2022-12-31 08:40:37,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:37,132 INFO:     Epoch: 58
2022-12-31 08:40:38,740 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3116835584243139, 'Total loss': 0.3116835584243139} | train loss {'Reaction outcome loss': 0.12919975541418174, 'Total loss': 0.12919975541418174}
2022-12-31 08:40:38,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:38,740 INFO:     Epoch: 59
2022-12-31 08:40:40,347 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33241788744926454, 'Total loss': 0.33241788744926454} | train loss {'Reaction outcome loss': 0.12692627058717945, 'Total loss': 0.12692627058717945}
2022-12-31 08:40:40,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:40,348 INFO:     Epoch: 60
2022-12-31 08:40:41,946 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3243134026726087, 'Total loss': 0.3243134026726087} | train loss {'Reaction outcome loss': 0.13273370955785208, 'Total loss': 0.13273370955785208}
2022-12-31 08:40:41,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:41,947 INFO:     Epoch: 61
2022-12-31 08:40:43,559 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.2855764217674732, 'Total loss': 0.2855764217674732} | train loss {'Reaction outcome loss': 0.12869071787100855, 'Total loss': 0.12869071787100855}
2022-12-31 08:40:43,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:43,560 INFO:     Epoch: 62
2022-12-31 08:40:45,149 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3177323823173841, 'Total loss': 0.3177323823173841} | train loss {'Reaction outcome loss': 0.12981917005181856, 'Total loss': 0.12981917005181856}
2022-12-31 08:40:45,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:45,150 INFO:     Epoch: 63
2022-12-31 08:40:46,797 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3236703644196192, 'Total loss': 0.3236703644196192} | train loss {'Reaction outcome loss': 0.12585552108990722, 'Total loss': 0.12585552108990722}
2022-12-31 08:40:46,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:46,798 INFO:     Epoch: 64
2022-12-31 08:40:48,394 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3292420576016108, 'Total loss': 0.3292420576016108} | train loss {'Reaction outcome loss': 0.12503163603025685, 'Total loss': 0.12503163603025685}
2022-12-31 08:40:48,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:48,395 INFO:     Epoch: 65
2022-12-31 08:40:49,993 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3269065901637077, 'Total loss': 0.3269065901637077} | train loss {'Reaction outcome loss': 0.12367447025659256, 'Total loss': 0.12367447025659256}
2022-12-31 08:40:49,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:49,993 INFO:     Epoch: 66
2022-12-31 08:40:51,594 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3188397566477458, 'Total loss': 0.3188397566477458} | train loss {'Reaction outcome loss': 0.12672171243092548, 'Total loss': 0.12672171243092548}
2022-12-31 08:40:51,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:51,594 INFO:     Epoch: 67
2022-12-31 08:40:53,186 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.31647550612688063, 'Total loss': 0.31647550612688063} | train loss {'Reaction outcome loss': 0.12819027919220283, 'Total loss': 0.12819027919220283}
2022-12-31 08:40:53,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:53,186 INFO:     Epoch: 68
2022-12-31 08:40:54,784 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3335676518579324, 'Total loss': 0.3335676518579324} | train loss {'Reaction outcome loss': 0.12462258303408803, 'Total loss': 0.12462258303408803}
2022-12-31 08:40:54,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:54,784 INFO:     Epoch: 69
2022-12-31 08:40:56,381 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.31829467639327047, 'Total loss': 0.31829467639327047} | train loss {'Reaction outcome loss': 0.12722751672930308, 'Total loss': 0.12722751672930308}
2022-12-31 08:40:56,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:56,381 INFO:     Epoch: 70
2022-12-31 08:40:58,029 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.31487234433492023, 'Total loss': 0.31487234433492023} | train loss {'Reaction outcome loss': 0.1268377774802927, 'Total loss': 0.1268377774802927}
2022-12-31 08:40:58,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:58,029 INFO:     Epoch: 71
2022-12-31 08:40:59,679 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3317627360423406, 'Total loss': 0.3317627360423406} | train loss {'Reaction outcome loss': 0.12545051149527686, 'Total loss': 0.12545051149527686}
2022-12-31 08:40:59,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:40:59,680 INFO:     Epoch: 72
2022-12-31 08:41:01,281 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3310183435678482, 'Total loss': 0.3310183435678482} | train loss {'Reaction outcome loss': 0.12352023022861158, 'Total loss': 0.12352023022861158}
2022-12-31 08:41:01,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:01,282 INFO:     Epoch: 73
2022-12-31 08:41:02,875 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3139172943929831, 'Total loss': 0.3139172943929831} | train loss {'Reaction outcome loss': 0.1253600636459751, 'Total loss': 0.1253600636459751}
2022-12-31 08:41:02,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:02,876 INFO:     Epoch: 74
2022-12-31 08:41:04,472 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3529544231792291, 'Total loss': 0.3529544231792291} | train loss {'Reaction outcome loss': 0.12130877326997201, 'Total loss': 0.12130877326997201}
2022-12-31 08:41:04,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:04,472 INFO:     Epoch: 75
2022-12-31 08:41:06,067 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3369922757148743, 'Total loss': 0.3369922757148743} | train loss {'Reaction outcome loss': 0.11774738798645346, 'Total loss': 0.11774738798645346}
2022-12-31 08:41:06,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:06,067 INFO:     Epoch: 76
2022-12-31 08:41:07,716 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3253155757983526, 'Total loss': 0.3253155757983526} | train loss {'Reaction outcome loss': 0.1200682541515243, 'Total loss': 0.1200682541515243}
2022-12-31 08:41:07,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:07,716 INFO:     Epoch: 77
2022-12-31 08:41:09,325 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.313625601430734, 'Total loss': 0.313625601430734} | train loss {'Reaction outcome loss': 0.12185018035637582, 'Total loss': 0.12185018035637582}
2022-12-31 08:41:09,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:09,325 INFO:     Epoch: 78
2022-12-31 08:41:10,966 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.29008038341999054, 'Total loss': 0.29008038341999054} | train loss {'Reaction outcome loss': 0.11896316205613641, 'Total loss': 0.11896316205613641}
2022-12-31 08:41:10,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:10,967 INFO:     Epoch: 79
2022-12-31 08:41:12,613 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3117270554105441, 'Total loss': 0.3117270554105441} | train loss {'Reaction outcome loss': 0.12148925587262986, 'Total loss': 0.12148925587262986}
2022-12-31 08:41:12,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:12,614 INFO:     Epoch: 80
2022-12-31 08:41:14,218 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.2918993851325164, 'Total loss': 0.2918993851325164} | train loss {'Reaction outcome loss': 0.12350336117092112, 'Total loss': 0.12350336117092112}
2022-12-31 08:41:14,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:14,218 INFO:     Epoch: 81
2022-12-31 08:41:15,866 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.30084550827741624, 'Total loss': 0.30084550827741624} | train loss {'Reaction outcome loss': 0.11452018813889502, 'Total loss': 0.11452018813889502}
2022-12-31 08:41:15,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:15,867 INFO:     Epoch: 82
2022-12-31 08:41:17,520 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3119408709307512, 'Total loss': 0.3119408709307512} | train loss {'Reaction outcome loss': 0.11758553858737658, 'Total loss': 0.11758553858737658}
2022-12-31 08:41:17,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:17,521 INFO:     Epoch: 83
2022-12-31 08:41:19,136 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.30160578911503155, 'Total loss': 0.30160578911503155} | train loss {'Reaction outcome loss': 0.11588996286031511, 'Total loss': 0.11588996286031511}
2022-12-31 08:41:19,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:19,137 INFO:     Epoch: 84
2022-12-31 08:41:20,755 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3222127671043078, 'Total loss': 0.3222127671043078} | train loss {'Reaction outcome loss': 0.11993378593525203, 'Total loss': 0.11993378593525203}
2022-12-31 08:41:20,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:20,755 INFO:     Epoch: 85
2022-12-31 08:41:22,408 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.34550772507985433, 'Total loss': 0.34550772507985433} | train loss {'Reaction outcome loss': 0.117014433266629, 'Total loss': 0.117014433266629}
2022-12-31 08:41:22,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:22,408 INFO:     Epoch: 86
2022-12-31 08:41:24,061 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33766281406084697, 'Total loss': 0.33766281406084697} | train loss {'Reaction outcome loss': 0.11707805473031137, 'Total loss': 0.11707805473031137}
2022-12-31 08:41:24,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:24,061 INFO:     Epoch: 87
2022-12-31 08:41:25,714 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3033156896630923, 'Total loss': 0.3033156896630923} | train loss {'Reaction outcome loss': 0.12092979064799274, 'Total loss': 0.12092979064799274}
2022-12-31 08:41:25,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:25,714 INFO:     Epoch: 88
2022-12-31 08:41:27,365 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.290078001221021, 'Total loss': 0.290078001221021} | train loss {'Reaction outcome loss': 0.1174737012836348, 'Total loss': 0.1174737012836348}
2022-12-31 08:41:27,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:27,365 INFO:     Epoch: 89
2022-12-31 08:41:29,114 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.30834698701898255, 'Total loss': 0.30834698701898255} | train loss {'Reaction outcome loss': 0.12398915764889305, 'Total loss': 0.12398915764889305}
2022-12-31 08:41:29,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:29,114 INFO:     Epoch: 90
2022-12-31 08:41:30,722 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.2888413737217585, 'Total loss': 0.2888413737217585} | train loss {'Reaction outcome loss': 0.11756302127240728, 'Total loss': 0.11756302127240728}
2022-12-31 08:41:30,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:30,722 INFO:     Epoch: 91
2022-12-31 08:41:32,330 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3232886149237553, 'Total loss': 0.3232886149237553} | train loss {'Reaction outcome loss': 0.11460098321719543, 'Total loss': 0.11460098321719543}
2022-12-31 08:41:32,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:32,331 INFO:     Epoch: 92
2022-12-31 08:41:33,939 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3087127566337585, 'Total loss': 0.3087127566337585} | train loss {'Reaction outcome loss': 0.11814188102708899, 'Total loss': 0.11814188102708899}
2022-12-31 08:41:33,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:33,939 INFO:     Epoch: 93
2022-12-31 08:41:35,547 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.30318964968125023, 'Total loss': 0.30318964968125023} | train loss {'Reaction outcome loss': 0.11567536474802076, 'Total loss': 0.11567536474802076}
2022-12-31 08:41:35,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:35,547 INFO:     Epoch: 94
2022-12-31 08:41:37,150 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3112457146247228, 'Total loss': 0.3112457146247228} | train loss {'Reaction outcome loss': 0.11202933087802228, 'Total loss': 0.11202933087802228}
2022-12-31 08:41:37,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:37,151 INFO:     Epoch: 95
2022-12-31 08:41:38,786 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.314711062113444, 'Total loss': 0.314711062113444} | train loss {'Reaction outcome loss': 0.1154862866043555, 'Total loss': 0.1154862866043555}
2022-12-31 08:41:38,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:38,787 INFO:     Epoch: 96
2022-12-31 08:41:40,404 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.27693601995706557, 'Total loss': 0.27693601995706557} | train loss {'Reaction outcome loss': 0.1220610186595293, 'Total loss': 0.1220610186595293}
2022-12-31 08:41:40,404 INFO:     Found new best model at epoch 96
2022-12-31 08:41:40,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:40,405 INFO:     Epoch: 97
2022-12-31 08:41:42,014 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3340887198845545, 'Total loss': 0.3340887198845545} | train loss {'Reaction outcome loss': 0.12026871363955285, 'Total loss': 0.12026871363955285}
2022-12-31 08:41:42,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:42,014 INFO:     Epoch: 98
2022-12-31 08:41:43,667 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3009379873673121, 'Total loss': 0.3009379873673121} | train loss {'Reaction outcome loss': 0.11939915906838447, 'Total loss': 0.11939915906838447}
2022-12-31 08:41:43,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:43,667 INFO:     Epoch: 99
2022-12-31 08:41:45,320 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.2999062975247701, 'Total loss': 0.2999062975247701} | train loss {'Reaction outcome loss': 0.11565206195465731, 'Total loss': 0.11565206195465731}
2022-12-31 08:41:45,320 INFO:     Best model found after epoch 97 of 100.
2022-12-31 08:41:45,320 INFO:   Done with stage: TRAINING
2022-12-31 08:41:45,320 INFO:   Starting stage: EVALUATION
2022-12-31 08:41:45,457 INFO:   Done with stage: EVALUATION
2022-12-31 08:41:45,457 INFO:   Leaving out SEQ value Fold_2
2022-12-31 08:41:45,470 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 08:41:45,470 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:41:46,106 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:41:46,106 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:41:46,173 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:41:46,173 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:41:46,173 INFO:     No hyperparam tuning for this model
2022-12-31 08:41:46,173 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:41:46,173 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:41:46,174 INFO:     None feature selector for col prot
2022-12-31 08:41:46,174 INFO:     None feature selector for col prot
2022-12-31 08:41:46,174 INFO:     None feature selector for col prot
2022-12-31 08:41:46,174 INFO:     None feature selector for col chem
2022-12-31 08:41:46,175 INFO:     None feature selector for col chem
2022-12-31 08:41:46,175 INFO:     None feature selector for col chem
2022-12-31 08:41:46,175 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:41:46,175 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:41:46,176 INFO:     Number of params in model 224011
2022-12-31 08:41:46,180 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:41:46,180 INFO:   Starting stage: TRAINING
2022-12-31 08:41:46,224 INFO:     Val loss before train {'Reaction outcome loss': 1.036465052763621, 'Total loss': 1.036465052763621}
2022-12-31 08:41:46,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:46,225 INFO:     Epoch: 0
2022-12-31 08:41:47,844 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5599551022052764, 'Total loss': 0.5599551022052764} | train loss {'Reaction outcome loss': 0.7889139115594436, 'Total loss': 0.7889139115594436}
2022-12-31 08:41:47,844 INFO:     Found new best model at epoch 0
2022-12-31 08:41:47,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:47,845 INFO:     Epoch: 1
2022-12-31 08:41:49,457 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48214425444602965, 'Total loss': 0.48214425444602965} | train loss {'Reaction outcome loss': 0.5232691912155977, 'Total loss': 0.5232691912155977}
2022-12-31 08:41:49,458 INFO:     Found new best model at epoch 1
2022-12-31 08:41:49,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:49,459 INFO:     Epoch: 2
2022-12-31 08:41:51,069 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44432390928268434, 'Total loss': 0.44432390928268434} | train loss {'Reaction outcome loss': 0.4505299551659635, 'Total loss': 0.4505299551659635}
2022-12-31 08:41:51,070 INFO:     Found new best model at epoch 2
2022-12-31 08:41:51,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:51,071 INFO:     Epoch: 3
2022-12-31 08:41:52,679 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43054946859677634, 'Total loss': 0.43054946859677634} | train loss {'Reaction outcome loss': 0.4102912372167128, 'Total loss': 0.4102912372167128}
2022-12-31 08:41:52,679 INFO:     Found new best model at epoch 3
2022-12-31 08:41:52,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:52,680 INFO:     Epoch: 4
2022-12-31 08:41:54,293 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.424468449751536, 'Total loss': 0.424468449751536} | train loss {'Reaction outcome loss': 0.37825965550491936, 'Total loss': 0.37825965550491936}
2022-12-31 08:41:54,293 INFO:     Found new best model at epoch 4
2022-12-31 08:41:54,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:54,294 INFO:     Epoch: 5
2022-12-31 08:41:55,918 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43979372382164, 'Total loss': 0.43979372382164} | train loss {'Reaction outcome loss': 0.36044711727594986, 'Total loss': 0.36044711727594986}
2022-12-31 08:41:55,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:55,919 INFO:     Epoch: 6
2022-12-31 08:41:57,544 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41750318904717765, 'Total loss': 0.41750318904717765} | train loss {'Reaction outcome loss': 0.34448769312702876, 'Total loss': 0.34448769312702876}
2022-12-31 08:41:57,544 INFO:     Found new best model at epoch 6
2022-12-31 08:41:57,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:57,545 INFO:     Epoch: 7
2022-12-31 08:41:59,178 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4179573277632395, 'Total loss': 0.4179573277632395} | train loss {'Reaction outcome loss': 0.32043434798623016, 'Total loss': 0.32043434798623016}
2022-12-31 08:41:59,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:41:59,178 INFO:     Epoch: 8
2022-12-31 08:42:00,819 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41275894343853, 'Total loss': 0.41275894343853} | train loss {'Reaction outcome loss': 0.3094310528696582, 'Total loss': 0.3094310528696582}
2022-12-31 08:42:00,819 INFO:     Found new best model at epoch 8
2022-12-31 08:42:00,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:00,820 INFO:     Epoch: 9
2022-12-31 08:42:02,436 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4012021760145823, 'Total loss': 0.4012021760145823} | train loss {'Reaction outcome loss': 0.29430526812844304, 'Total loss': 0.29430526812844304}
2022-12-31 08:42:02,436 INFO:     Found new best model at epoch 9
2022-12-31 08:42:02,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:02,437 INFO:     Epoch: 10
2022-12-31 08:42:04,055 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3961287587881088, 'Total loss': 0.3961287587881088} | train loss {'Reaction outcome loss': 0.28120339342791156, 'Total loss': 0.28120339342791156}
2022-12-31 08:42:04,055 INFO:     Found new best model at epoch 10
2022-12-31 08:42:04,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:04,056 INFO:     Epoch: 11
2022-12-31 08:42:05,669 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39357838332653045, 'Total loss': 0.39357838332653045} | train loss {'Reaction outcome loss': 0.27121932432055473, 'Total loss': 0.27121932432055473}
2022-12-31 08:42:05,669 INFO:     Found new best model at epoch 11
2022-12-31 08:42:05,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:05,670 INFO:     Epoch: 12
2022-12-31 08:42:07,290 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36906716922918953, 'Total loss': 0.36906716922918953} | train loss {'Reaction outcome loss': 0.26218586010973144, 'Total loss': 0.26218586010973144}
2022-12-31 08:42:07,290 INFO:     Found new best model at epoch 12
2022-12-31 08:42:07,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:07,291 INFO:     Epoch: 13
2022-12-31 08:42:08,909 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.402832967042923, 'Total loss': 0.402832967042923} | train loss {'Reaction outcome loss': 0.25448705746152817, 'Total loss': 0.25448705746152817}
2022-12-31 08:42:08,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:08,910 INFO:     Epoch: 14
2022-12-31 08:42:10,529 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38529067635536196, 'Total loss': 0.38529067635536196} | train loss {'Reaction outcome loss': 0.24795540835981703, 'Total loss': 0.24795540835981703}
2022-12-31 08:42:10,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:10,529 INFO:     Epoch: 15
2022-12-31 08:42:12,191 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4057069199780623, 'Total loss': 0.4057069199780623} | train loss {'Reaction outcome loss': 0.23750769647460032, 'Total loss': 0.23750769647460032}
2022-12-31 08:42:12,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:12,191 INFO:     Epoch: 16
2022-12-31 08:42:13,812 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40891892711321515, 'Total loss': 0.40891892711321515} | train loss {'Reaction outcome loss': 0.232383964198601, 'Total loss': 0.232383964198601}
2022-12-31 08:42:13,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:13,812 INFO:     Epoch: 17
2022-12-31 08:42:15,437 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4062183360258738, 'Total loss': 0.4062183360258738} | train loss {'Reaction outcome loss': 0.22584821664225974, 'Total loss': 0.22584821664225974}
2022-12-31 08:42:15,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:15,437 INFO:     Epoch: 18
2022-12-31 08:42:17,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3817942569653193, 'Total loss': 0.3817942569653193} | train loss {'Reaction outcome loss': 0.21955997174170436, 'Total loss': 0.21955997174170436}
2022-12-31 08:42:17,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:17,067 INFO:     Epoch: 19
2022-12-31 08:42:18,701 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41146799325942995, 'Total loss': 0.41146799325942995} | train loss {'Reaction outcome loss': 0.21439013478980548, 'Total loss': 0.21439013478980548}
2022-12-31 08:42:18,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:18,702 INFO:     Epoch: 20
2022-12-31 08:42:20,331 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4222564329703649, 'Total loss': 0.4222564329703649} | train loss {'Reaction outcome loss': 0.21666308292322725, 'Total loss': 0.21666308292322725}
2022-12-31 08:42:20,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:20,332 INFO:     Epoch: 21
2022-12-31 08:42:21,949 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3970216433207194, 'Total loss': 0.3970216433207194} | train loss {'Reaction outcome loss': 0.23669317654845223, 'Total loss': 0.23669317654845223}
2022-12-31 08:42:21,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:21,949 INFO:     Epoch: 22
2022-12-31 08:42:23,577 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42523358364899955, 'Total loss': 0.42523358364899955} | train loss {'Reaction outcome loss': 0.2002630254124676, 'Total loss': 0.2002630254124676}
2022-12-31 08:42:23,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:23,578 INFO:     Epoch: 23
2022-12-31 08:42:25,197 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3848555396000544, 'Total loss': 0.3848555396000544} | train loss {'Reaction outcome loss': 0.1971464932607162, 'Total loss': 0.1971464932607162}
2022-12-31 08:42:25,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:25,198 INFO:     Epoch: 24
2022-12-31 08:42:26,826 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3919641989904145, 'Total loss': 0.3919641989904145} | train loss {'Reaction outcome loss': 0.19085062988628837, 'Total loss': 0.19085062988628837}
2022-12-31 08:42:26,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:26,827 INFO:     Epoch: 25
2022-12-31 08:42:28,454 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.430311319231987, 'Total loss': 0.430311319231987} | train loss {'Reaction outcome loss': 0.18887393831518356, 'Total loss': 0.18887393831518356}
2022-12-31 08:42:28,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:28,454 INFO:     Epoch: 26
2022-12-31 08:42:30,082 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40647321144739784, 'Total loss': 0.40647321144739784} | train loss {'Reaction outcome loss': 0.1884650151056332, 'Total loss': 0.1884650151056332}
2022-12-31 08:42:30,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:30,082 INFO:     Epoch: 27
2022-12-31 08:42:31,716 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42046652138233187, 'Total loss': 0.42046652138233187} | train loss {'Reaction outcome loss': 0.19440299881608697, 'Total loss': 0.19440299881608697}
2022-12-31 08:42:31,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:31,716 INFO:     Epoch: 28
2022-12-31 08:42:33,323 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38051869298020996, 'Total loss': 0.38051869298020996} | train loss {'Reaction outcome loss': 0.1807861305685525, 'Total loss': 0.1807861305685525}
2022-12-31 08:42:33,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:33,323 INFO:     Epoch: 29
2022-12-31 08:42:34,983 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41483902831872305, 'Total loss': 0.41483902831872305} | train loss {'Reaction outcome loss': 0.17887916019780264, 'Total loss': 0.17887916019780264}
2022-12-31 08:42:34,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:34,984 INFO:     Epoch: 30
2022-12-31 08:42:36,595 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37144840161005654, 'Total loss': 0.37144840161005654} | train loss {'Reaction outcome loss': 0.19512368484140388, 'Total loss': 0.19512368484140388}
2022-12-31 08:42:36,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:36,595 INFO:     Epoch: 31
2022-12-31 08:42:38,205 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4087159107128779, 'Total loss': 0.4087159107128779} | train loss {'Reaction outcome loss': 0.17613653144620503, 'Total loss': 0.17613653144620503}
2022-12-31 08:42:38,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:38,205 INFO:     Epoch: 32
2022-12-31 08:42:39,866 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4270776351292928, 'Total loss': 0.4270776351292928} | train loss {'Reaction outcome loss': 0.17279669304063672, 'Total loss': 0.17279669304063672}
2022-12-31 08:42:39,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:39,867 INFO:     Epoch: 33
2022-12-31 08:42:41,513 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4059492280085882, 'Total loss': 0.4059492280085882} | train loss {'Reaction outcome loss': 0.16600808464207387, 'Total loss': 0.16600808464207387}
2022-12-31 08:42:41,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:41,514 INFO:     Epoch: 34
2022-12-31 08:42:43,136 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40290889541308084, 'Total loss': 0.40290889541308084} | train loss {'Reaction outcome loss': 0.16384984697722954, 'Total loss': 0.16384984697722954}
2022-12-31 08:42:43,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:43,136 INFO:     Epoch: 35
2022-12-31 08:42:44,763 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4205605576435725, 'Total loss': 0.4205605576435725} | train loss {'Reaction outcome loss': 0.16316331821945967, 'Total loss': 0.16316331821945967}
2022-12-31 08:42:44,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:44,763 INFO:     Epoch: 36
2022-12-31 08:42:46,390 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4091426213582357, 'Total loss': 0.4091426213582357} | train loss {'Reaction outcome loss': 0.17143826466728596, 'Total loss': 0.17143826466728596}
2022-12-31 08:42:46,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:46,390 INFO:     Epoch: 37
2022-12-31 08:42:48,016 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41064348419507346, 'Total loss': 0.41064348419507346} | train loss {'Reaction outcome loss': 0.18549305936421265, 'Total loss': 0.18549305936421265}
2022-12-31 08:42:48,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:48,016 INFO:     Epoch: 38
2022-12-31 08:42:49,636 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3777697145938873, 'Total loss': 0.3777697145938873} | train loss {'Reaction outcome loss': 0.1605737748220196, 'Total loss': 0.1605737748220196}
2022-12-31 08:42:49,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:49,636 INFO:     Epoch: 39
2022-12-31 08:42:51,255 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4071662704149882, 'Total loss': 0.4071662704149882} | train loss {'Reaction outcome loss': 0.15492814781474948, 'Total loss': 0.15492814781474948}
2022-12-31 08:42:51,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:51,256 INFO:     Epoch: 40
2022-12-31 08:42:52,916 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39814397593339285, 'Total loss': 0.39814397593339285} | train loss {'Reaction outcome loss': 0.1564128114555058, 'Total loss': 0.1564128114555058}
2022-12-31 08:42:52,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:52,917 INFO:     Epoch: 41
2022-12-31 08:42:54,578 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42642370661099754, 'Total loss': 0.42642370661099754} | train loss {'Reaction outcome loss': 0.1536497441587056, 'Total loss': 0.1536497441587056}
2022-12-31 08:42:54,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:54,578 INFO:     Epoch: 42
2022-12-31 08:42:56,194 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40057061016559603, 'Total loss': 0.40057061016559603} | train loss {'Reaction outcome loss': 0.14862316956261065, 'Total loss': 0.14862316956261065}
2022-12-31 08:42:56,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:56,195 INFO:     Epoch: 43
2022-12-31 08:42:57,809 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4387478550275167, 'Total loss': 0.4387478550275167} | train loss {'Reaction outcome loss': 0.1486716814294029, 'Total loss': 0.1486716814294029}
2022-12-31 08:42:57,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:57,809 INFO:     Epoch: 44
2022-12-31 08:42:59,426 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4316579391558965, 'Total loss': 0.4316579391558965} | train loss {'Reaction outcome loss': 0.14346308078283554, 'Total loss': 0.14346308078283554}
2022-12-31 08:42:59,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:42:59,426 INFO:     Epoch: 45
2022-12-31 08:43:01,073 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42266646126906077, 'Total loss': 0.42266646126906077} | train loss {'Reaction outcome loss': 0.14855224134526393, 'Total loss': 0.14855224134526393}
2022-12-31 08:43:01,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:01,074 INFO:     Epoch: 46
2022-12-31 08:43:02,688 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40875630974769595, 'Total loss': 0.40875630974769595} | train loss {'Reaction outcome loss': 0.14773479607758444, 'Total loss': 0.14773479607758444}
2022-12-31 08:43:02,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:02,689 INFO:     Epoch: 47
2022-12-31 08:43:04,304 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40808529655138653, 'Total loss': 0.40808529655138653} | train loss {'Reaction outcome loss': 0.14586118327966635, 'Total loss': 0.14586118327966635}
2022-12-31 08:43:04,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:04,304 INFO:     Epoch: 48
2022-12-31 08:43:05,965 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.412868000070254, 'Total loss': 0.412868000070254} | train loss {'Reaction outcome loss': 0.1405911116229802, 'Total loss': 0.1405911116229802}
2022-12-31 08:43:05,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:05,965 INFO:     Epoch: 49
2022-12-31 08:43:07,576 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4263404349486033, 'Total loss': 0.4263404349486033} | train loss {'Reaction outcome loss': 0.13917579166572186, 'Total loss': 0.13917579166572186}
2022-12-31 08:43:07,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:07,576 INFO:     Epoch: 50
2022-12-31 08:43:09,231 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4063806543747584, 'Total loss': 0.4063806543747584} | train loss {'Reaction outcome loss': 0.14529013699781068, 'Total loss': 0.14529013699781068}
2022-12-31 08:43:09,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:09,231 INFO:     Epoch: 51
2022-12-31 08:43:10,833 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41057961036761603, 'Total loss': 0.41057961036761603} | train loss {'Reaction outcome loss': 0.13974586053012425, 'Total loss': 0.13974586053012425}
2022-12-31 08:43:10,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:10,833 INFO:     Epoch: 52
2022-12-31 08:43:12,494 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40796621243158976, 'Total loss': 0.40796621243158976} | train loss {'Reaction outcome loss': 0.13912410331650407, 'Total loss': 0.13912410331650407}
2022-12-31 08:43:12,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:12,494 INFO:     Epoch: 53
2022-12-31 08:43:14,155 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4131418565909068, 'Total loss': 0.4131418565909068} | train loss {'Reaction outcome loss': 0.15006068673160305, 'Total loss': 0.15006068673160305}
2022-12-31 08:43:14,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:14,155 INFO:     Epoch: 54
2022-12-31 08:43:15,815 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44244577586650846, 'Total loss': 0.44244577586650846} | train loss {'Reaction outcome loss': 0.14050076708602474, 'Total loss': 0.14050076708602474}
2022-12-31 08:43:15,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:15,816 INFO:     Epoch: 55
2022-12-31 08:43:17,428 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4502164880434672, 'Total loss': 0.4502164880434672} | train loss {'Reaction outcome loss': 0.13178761107459044, 'Total loss': 0.13178761107459044}
2022-12-31 08:43:17,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:17,428 INFO:     Epoch: 56
2022-12-31 08:43:19,077 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41085353394349416, 'Total loss': 0.41085353394349416} | train loss {'Reaction outcome loss': 0.13380031202636336, 'Total loss': 0.13380031202636336}
2022-12-31 08:43:19,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:19,077 INFO:     Epoch: 57
2022-12-31 08:43:20,689 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4374690661827723, 'Total loss': 0.4374690661827723} | train loss {'Reaction outcome loss': 0.129565256320453, 'Total loss': 0.129565256320453}
2022-12-31 08:43:20,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:20,690 INFO:     Epoch: 58
2022-12-31 08:43:22,338 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43495123187700907, 'Total loss': 0.43495123187700907} | train loss {'Reaction outcome loss': 0.1322340372880717, 'Total loss': 0.1322340372880717}
2022-12-31 08:43:22,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:22,338 INFO:     Epoch: 59
2022-12-31 08:43:23,999 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42745281060536705, 'Total loss': 0.42745281060536705} | train loss {'Reaction outcome loss': 0.13232960504290636, 'Total loss': 0.13232960504290636}
2022-12-31 08:43:23,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:23,999 INFO:     Epoch: 60
2022-12-31 08:43:25,614 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4243164042631785, 'Total loss': 0.4243164042631785} | train loss {'Reaction outcome loss': 0.12903484954512207, 'Total loss': 0.12903484954512207}
2022-12-31 08:43:25,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:25,615 INFO:     Epoch: 61
2022-12-31 08:43:27,234 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4168169617652893, 'Total loss': 0.4168169617652893} | train loss {'Reaction outcome loss': 0.12921424917083746, 'Total loss': 0.12921424917083746}
2022-12-31 08:43:27,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:27,234 INFO:     Epoch: 62
2022-12-31 08:43:28,852 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40430572132269543, 'Total loss': 0.40430572132269543} | train loss {'Reaction outcome loss': 0.12787491084494884, 'Total loss': 0.12787491084494884}
2022-12-31 08:43:28,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:28,852 INFO:     Epoch: 63
2022-12-31 08:43:30,480 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4454067453742027, 'Total loss': 0.4454067453742027} | train loss {'Reaction outcome loss': 0.12865521766819427, 'Total loss': 0.12865521766819427}
2022-12-31 08:43:30,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:30,481 INFO:     Epoch: 64
2022-12-31 08:43:32,109 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3992167592048645, 'Total loss': 0.3992167592048645} | train loss {'Reaction outcome loss': 0.12785690160081434, 'Total loss': 0.12785690160081434}
2022-12-31 08:43:32,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:32,110 INFO:     Epoch: 65
2022-12-31 08:43:33,743 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40281172295411427, 'Total loss': 0.40281172295411427} | train loss {'Reaction outcome loss': 0.12452930343199009, 'Total loss': 0.12452930343199009}
2022-12-31 08:43:33,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:33,743 INFO:     Epoch: 66
2022-12-31 08:43:35,368 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41132545471191406, 'Total loss': 0.41132545471191406} | train loss {'Reaction outcome loss': 0.12309318296552257, 'Total loss': 0.12309318296552257}
2022-12-31 08:43:35,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:35,368 INFO:     Epoch: 67
2022-12-31 08:43:36,991 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3982050729294618, 'Total loss': 0.3982050729294618} | train loss {'Reaction outcome loss': 0.1235750256489247, 'Total loss': 0.1235750256489247}
2022-12-31 08:43:36,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:36,991 INFO:     Epoch: 68
2022-12-31 08:43:38,622 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4055378422141075, 'Total loss': 0.4055378422141075} | train loss {'Reaction outcome loss': 0.12286703866224, 'Total loss': 0.12286703866224}
2022-12-31 08:43:38,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:38,623 INFO:     Epoch: 69
2022-12-31 08:43:40,255 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3943564017613729, 'Total loss': 0.3943564017613729} | train loss {'Reaction outcome loss': 0.12198724542521751, 'Total loss': 0.12198724542521751}
2022-12-31 08:43:40,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:40,255 INFO:     Epoch: 70
2022-12-31 08:43:41,887 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41743868216872215, 'Total loss': 0.41743868216872215} | train loss {'Reaction outcome loss': 0.1400650489056294, 'Total loss': 0.1400650489056294}
2022-12-31 08:43:41,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:41,887 INFO:     Epoch: 71
2022-12-31 08:43:43,518 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40300172915061316, 'Total loss': 0.40300172915061316} | train loss {'Reaction outcome loss': 0.12682739253606365, 'Total loss': 0.12682739253606365}
2022-12-31 08:43:43,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:43,518 INFO:     Epoch: 72
2022-12-31 08:43:45,142 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43656993210315703, 'Total loss': 0.43656993210315703} | train loss {'Reaction outcome loss': 0.12272136943014945, 'Total loss': 0.12272136943014945}
2022-12-31 08:43:45,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:45,142 INFO:     Epoch: 73
2022-12-31 08:43:46,764 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.430999256670475, 'Total loss': 0.430999256670475} | train loss {'Reaction outcome loss': 0.12264950737217012, 'Total loss': 0.12264950737217012}
2022-12-31 08:43:46,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:46,764 INFO:     Epoch: 74
2022-12-31 08:43:48,400 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4017296721537908, 'Total loss': 0.4017296721537908} | train loss {'Reaction outcome loss': 0.12441139942224043, 'Total loss': 0.12441139942224043}
2022-12-31 08:43:48,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:48,400 INFO:     Epoch: 75
2022-12-31 08:43:50,035 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3933924436569214, 'Total loss': 0.3933924436569214} | train loss {'Reaction outcome loss': 0.11547953231142921, 'Total loss': 0.11547953231142921}
2022-12-31 08:43:50,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:50,035 INFO:     Epoch: 76
2022-12-31 08:43:51,671 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4098271911342939, 'Total loss': 0.4098271911342939} | train loss {'Reaction outcome loss': 0.11808554428811792, 'Total loss': 0.11808554428811792}
2022-12-31 08:43:51,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:51,672 INFO:     Epoch: 77
2022-12-31 08:43:53,296 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4134647404154142, 'Total loss': 0.4134647404154142} | train loss {'Reaction outcome loss': 0.12234625132660384, 'Total loss': 0.12234625132660384}
2022-12-31 08:43:53,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:53,296 INFO:     Epoch: 78
2022-12-31 08:43:54,947 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4064713423450788, 'Total loss': 0.4064713423450788} | train loss {'Reaction outcome loss': 0.11797586208094667, 'Total loss': 0.11797586208094667}
2022-12-31 08:43:54,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:54,947 INFO:     Epoch: 79
2022-12-31 08:43:56,614 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42711063027381896, 'Total loss': 0.42711063027381896} | train loss {'Reaction outcome loss': 0.11709819351296798, 'Total loss': 0.11709819351296798}
2022-12-31 08:43:56,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:56,614 INFO:     Epoch: 80
2022-12-31 08:43:58,231 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41237899161254365, 'Total loss': 0.41237899161254365} | train loss {'Reaction outcome loss': 0.12463714894218593, 'Total loss': 0.12463714894218593}
2022-12-31 08:43:58,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:58,231 INFO:     Epoch: 81
2022-12-31 08:43:59,894 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40012287298838295, 'Total loss': 0.40012287298838295} | train loss {'Reaction outcome loss': 0.1213794220754568, 'Total loss': 0.1213794220754568}
2022-12-31 08:43:59,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:43:59,894 INFO:     Epoch: 82
2022-12-31 08:44:01,558 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3727603207031886, 'Total loss': 0.3727603207031886} | train loss {'Reaction outcome loss': 0.11726108529114425, 'Total loss': 0.11726108529114425}
2022-12-31 08:44:01,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:01,558 INFO:     Epoch: 83
2022-12-31 08:44:03,176 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4086698114871979, 'Total loss': 0.4086698114871979} | train loss {'Reaction outcome loss': 0.1161241139388817, 'Total loss': 0.1161241139388817}
2022-12-31 08:44:03,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:03,176 INFO:     Epoch: 84
2022-12-31 08:44:04,818 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3958369721968969, 'Total loss': 0.3958369721968969} | train loss {'Reaction outcome loss': 0.11526415772327775, 'Total loss': 0.11526415772327775}
2022-12-31 08:44:04,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:04,818 INFO:     Epoch: 85
2022-12-31 08:44:06,452 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39640780886014304, 'Total loss': 0.39640780886014304} | train loss {'Reaction outcome loss': 0.11545425108330243, 'Total loss': 0.11545425108330243}
2022-12-31 08:44:06,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:06,452 INFO:     Epoch: 86
2022-12-31 08:44:08,088 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4002536714076996, 'Total loss': 0.4002536714076996} | train loss {'Reaction outcome loss': 0.11363473667871153, 'Total loss': 0.11363473667871153}
2022-12-31 08:44:08,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:08,089 INFO:     Epoch: 87
2022-12-31 08:44:09,726 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4177887956301371, 'Total loss': 0.4177887956301371} | train loss {'Reaction outcome loss': 0.11182987745606637, 'Total loss': 0.11182987745606637}
2022-12-31 08:44:09,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:09,727 INFO:     Epoch: 88
2022-12-31 08:44:11,357 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.403023199737072, 'Total loss': 0.403023199737072} | train loss {'Reaction outcome loss': 0.11315791896060176, 'Total loss': 0.11315791896060176}
2022-12-31 08:44:11,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:11,358 INFO:     Epoch: 89
2022-12-31 08:44:13,014 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42709630926450093, 'Total loss': 0.42709630926450093} | train loss {'Reaction outcome loss': 0.1168803671734286, 'Total loss': 0.1168803671734286}
2022-12-31 08:44:13,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:13,015 INFO:     Epoch: 90
2022-12-31 08:44:14,628 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4147447238365809, 'Total loss': 0.4147447238365809} | train loss {'Reaction outcome loss': 0.13179869725043292, 'Total loss': 0.13179869725043292}
2022-12-31 08:44:14,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:14,628 INFO:     Epoch: 91
2022-12-31 08:44:16,241 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41146858831246697, 'Total loss': 0.41146858831246697} | train loss {'Reaction outcome loss': 0.11471839769628654, 'Total loss': 0.11471839769628654}
2022-12-31 08:44:16,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:16,242 INFO:     Epoch: 92
2022-12-31 08:44:17,926 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4094311326742172, 'Total loss': 0.4094311326742172} | train loss {'Reaction outcome loss': 0.11367010531872782, 'Total loss': 0.11367010531872782}
2022-12-31 08:44:17,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:17,926 INFO:     Epoch: 93
2022-12-31 08:44:19,542 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4373864382505417, 'Total loss': 0.4373864382505417} | train loss {'Reaction outcome loss': 0.10909655750636349, 'Total loss': 0.10909655750636349}
2022-12-31 08:44:19,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:19,542 INFO:     Epoch: 94
2022-12-31 08:44:21,202 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3963906501730283, 'Total loss': 0.3963906501730283} | train loss {'Reaction outcome loss': 0.10927657941258004, 'Total loss': 0.10927657941258004}
2022-12-31 08:44:21,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:21,202 INFO:     Epoch: 95
2022-12-31 08:44:22,837 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40948034524917604, 'Total loss': 0.40948034524917604} | train loss {'Reaction outcome loss': 0.10749948198270141, 'Total loss': 0.10749948198270141}
2022-12-31 08:44:22,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:22,837 INFO:     Epoch: 96
2022-12-31 08:44:24,480 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3943583905696869, 'Total loss': 0.3943583905696869} | train loss {'Reaction outcome loss': 0.1201611945381982, 'Total loss': 0.1201611945381982}
2022-12-31 08:44:24,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:24,480 INFO:     Epoch: 97
2022-12-31 08:44:26,122 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4182034204403559, 'Total loss': 0.4182034204403559} | train loss {'Reaction outcome loss': 0.13431946759237032, 'Total loss': 0.13431946759237032}
2022-12-31 08:44:26,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:26,122 INFO:     Epoch: 98
2022-12-31 08:44:27,757 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4261533603072166, 'Total loss': 0.4261533603072166} | train loss {'Reaction outcome loss': 0.11828369407769482, 'Total loss': 0.11828369407769482}
2022-12-31 08:44:27,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:27,757 INFO:     Epoch: 99
2022-12-31 08:44:29,390 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4238860676685969, 'Total loss': 0.4238860676685969} | train loss {'Reaction outcome loss': 0.10734483254571492, 'Total loss': 0.10734483254571492}
2022-12-31 08:44:29,391 INFO:     Best model found after epoch 13 of 100.
2022-12-31 08:44:29,391 INFO:   Done with stage: TRAINING
2022-12-31 08:44:29,391 INFO:   Starting stage: EVALUATION
2022-12-31 08:44:29,524 INFO:   Done with stage: EVALUATION
2022-12-31 08:44:29,524 INFO:   Leaving out SEQ value Fold_3
2022-12-31 08:44:29,537 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 08:44:29,537 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:44:30,183 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:44:30,183 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:44:30,250 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:44:30,250 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:44:30,250 INFO:     No hyperparam tuning for this model
2022-12-31 08:44:30,250 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:44:30,250 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:44:30,251 INFO:     None feature selector for col prot
2022-12-31 08:44:30,251 INFO:     None feature selector for col prot
2022-12-31 08:44:30,251 INFO:     None feature selector for col prot
2022-12-31 08:44:30,252 INFO:     None feature selector for col chem
2022-12-31 08:44:30,252 INFO:     None feature selector for col chem
2022-12-31 08:44:30,252 INFO:     None feature selector for col chem
2022-12-31 08:44:30,252 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:44:30,252 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:44:30,254 INFO:     Number of params in model 224011
2022-12-31 08:44:30,257 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:44:30,257 INFO:   Starting stage: TRAINING
2022-12-31 08:44:30,301 INFO:     Val loss before train {'Reaction outcome loss': 1.087592355410258, 'Total loss': 1.087592355410258}
2022-12-31 08:44:30,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:30,301 INFO:     Epoch: 0
2022-12-31 08:44:31,923 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6073434948921204, 'Total loss': 0.6073434948921204} | train loss {'Reaction outcome loss': 0.7854021622569881, 'Total loss': 0.7854021622569881}
2022-12-31 08:44:31,923 INFO:     Found new best model at epoch 0
2022-12-31 08:44:31,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:31,924 INFO:     Epoch: 1
2022-12-31 08:44:33,543 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5489235858122508, 'Total loss': 0.5489235858122508} | train loss {'Reaction outcome loss': 0.5272458382490752, 'Total loss': 0.5272458382490752}
2022-12-31 08:44:33,544 INFO:     Found new best model at epoch 1
2022-12-31 08:44:33,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:33,545 INFO:     Epoch: 2
2022-12-31 08:44:35,163 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5121886690457662, 'Total loss': 0.5121886690457662} | train loss {'Reaction outcome loss': 0.45331451877701917, 'Total loss': 0.45331451877701917}
2022-12-31 08:44:35,163 INFO:     Found new best model at epoch 2
2022-12-31 08:44:35,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:35,164 INFO:     Epoch: 3
2022-12-31 08:44:36,782 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47858780225118003, 'Total loss': 0.47858780225118003} | train loss {'Reaction outcome loss': 0.4077565794189771, 'Total loss': 0.4077565794189771}
2022-12-31 08:44:36,782 INFO:     Found new best model at epoch 3
2022-12-31 08:44:36,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:36,783 INFO:     Epoch: 4
2022-12-31 08:44:38,401 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4606089154879252, 'Total loss': 0.4606089154879252} | train loss {'Reaction outcome loss': 0.3855578814889642, 'Total loss': 0.3855578814889642}
2022-12-31 08:44:38,401 INFO:     Found new best model at epoch 4
2022-12-31 08:44:38,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:38,402 INFO:     Epoch: 5
2022-12-31 08:44:40,015 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4650559077660243, 'Total loss': 0.4650559077660243} | train loss {'Reaction outcome loss': 0.36545342011632403, 'Total loss': 0.36545342011632403}
2022-12-31 08:44:40,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:40,016 INFO:     Epoch: 6
2022-12-31 08:44:41,640 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4615912238756816, 'Total loss': 0.4615912238756816} | train loss {'Reaction outcome loss': 0.33726212506830366, 'Total loss': 0.33726212506830366}
2022-12-31 08:44:41,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:41,640 INFO:     Epoch: 7
2022-12-31 08:44:43,271 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43537390828132627, 'Total loss': 0.43537390828132627} | train loss {'Reaction outcome loss': 0.3176526878218072, 'Total loss': 0.3176526878218072}
2022-12-31 08:44:43,272 INFO:     Found new best model at epoch 7
2022-12-31 08:44:43,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:43,273 INFO:     Epoch: 8
2022-12-31 08:44:44,903 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4751201977332433, 'Total loss': 0.4751201977332433} | train loss {'Reaction outcome loss': 0.30531991767254996, 'Total loss': 0.30531991767254996}
2022-12-31 08:44:44,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:44,904 INFO:     Epoch: 9
2022-12-31 08:44:46,538 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4227732867002487, 'Total loss': 0.4227732867002487} | train loss {'Reaction outcome loss': 0.2854415209007182, 'Total loss': 0.2854415209007182}
2022-12-31 08:44:46,538 INFO:     Found new best model at epoch 9
2022-12-31 08:44:46,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:46,539 INFO:     Epoch: 10
2022-12-31 08:44:48,159 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45257072647412616, 'Total loss': 0.45257072647412616} | train loss {'Reaction outcome loss': 0.27454902382864466, 'Total loss': 0.27454902382864466}
2022-12-31 08:44:48,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:48,159 INFO:     Epoch: 11
2022-12-31 08:44:49,780 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4551553547382355, 'Total loss': 0.4551553547382355} | train loss {'Reaction outcome loss': 0.2625734741610569, 'Total loss': 0.2625734741610569}
2022-12-31 08:44:49,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:49,781 INFO:     Epoch: 12
2022-12-31 08:44:51,410 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47776612838109334, 'Total loss': 0.47776612838109334} | train loss {'Reaction outcome loss': 0.25205736512240645, 'Total loss': 0.25205736512240645}
2022-12-31 08:44:51,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:51,411 INFO:     Epoch: 13
2022-12-31 08:44:53,039 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4407468232015769, 'Total loss': 0.4407468232015769} | train loss {'Reaction outcome loss': 0.24022572622313906, 'Total loss': 0.24022572622313906}
2022-12-31 08:44:53,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:53,040 INFO:     Epoch: 14
2022-12-31 08:44:54,668 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4487088511387507, 'Total loss': 0.4487088511387507} | train loss {'Reaction outcome loss': 0.2337549087739941, 'Total loss': 0.2337549087739941}
2022-12-31 08:44:54,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:54,668 INFO:     Epoch: 15
2022-12-31 08:44:56,299 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4510634630918503, 'Total loss': 0.4510634630918503} | train loss {'Reaction outcome loss': 0.23188165464586968, 'Total loss': 0.23188165464586968}
2022-12-31 08:44:56,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:56,299 INFO:     Epoch: 16
2022-12-31 08:44:57,921 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4569728563229243, 'Total loss': 0.4569728563229243} | train loss {'Reaction outcome loss': 0.22202215764580457, 'Total loss': 0.22202215764580457}
2022-12-31 08:44:57,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:57,921 INFO:     Epoch: 17
2022-12-31 08:44:59,543 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4570964654286703, 'Total loss': 0.4570964654286703} | train loss {'Reaction outcome loss': 0.21113376944339363, 'Total loss': 0.21113376944339363}
2022-12-31 08:44:59,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:44:59,543 INFO:     Epoch: 18
2022-12-31 08:45:01,172 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46306950946648917, 'Total loss': 0.46306950946648917} | train loss {'Reaction outcome loss': 0.20447537702998292, 'Total loss': 0.20447537702998292}
2022-12-31 08:45:01,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:01,173 INFO:     Epoch: 19
2022-12-31 08:45:02,803 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.457507786154747, 'Total loss': 0.457507786154747} | train loss {'Reaction outcome loss': 0.1956280622541891, 'Total loss': 0.1956280622541891}
2022-12-31 08:45:02,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:02,803 INFO:     Epoch: 20
2022-12-31 08:45:04,435 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.451364932457606, 'Total loss': 0.451364932457606} | train loss {'Reaction outcome loss': 0.19471967731521506, 'Total loss': 0.19471967731521506}
2022-12-31 08:45:04,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:04,435 INFO:     Epoch: 21
2022-12-31 08:45:06,057 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48740629305442174, 'Total loss': 0.48740629305442174} | train loss {'Reaction outcome loss': 0.18872162864283673, 'Total loss': 0.18872162864283673}
2022-12-31 08:45:06,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:06,058 INFO:     Epoch: 22
2022-12-31 08:45:07,743 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4564465453227361, 'Total loss': 0.4564465453227361} | train loss {'Reaction outcome loss': 0.18305501875803215, 'Total loss': 0.18305501875803215}
2022-12-31 08:45:07,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:07,743 INFO:     Epoch: 23
2022-12-31 08:45:09,455 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4521608223517736, 'Total loss': 0.4521608223517736} | train loss {'Reaction outcome loss': 0.1815024126621395, 'Total loss': 0.1815024126621395}
2022-12-31 08:45:09,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:09,456 INFO:     Epoch: 24
2022-12-31 08:45:11,167 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46474842975536984, 'Total loss': 0.46474842975536984} | train loss {'Reaction outcome loss': 0.17266950225630484, 'Total loss': 0.17266950225630484}
2022-12-31 08:45:11,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:11,168 INFO:     Epoch: 25
2022-12-31 08:45:12,781 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4778150737285614, 'Total loss': 0.4778150737285614} | train loss {'Reaction outcome loss': 0.17187114078990198, 'Total loss': 0.17187114078990198}
2022-12-31 08:45:12,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:12,781 INFO:     Epoch: 26
2022-12-31 08:45:14,495 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45742528041203817, 'Total loss': 0.45742528041203817} | train loss {'Reaction outcome loss': 0.1819741730240808, 'Total loss': 0.1819741730240808}
2022-12-31 08:45:14,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:14,497 INFO:     Epoch: 27
2022-12-31 08:45:16,107 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4604294151067734, 'Total loss': 0.4604294151067734} | train loss {'Reaction outcome loss': 0.20773847309275248, 'Total loss': 0.20773847309275248}
2022-12-31 08:45:16,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:16,107 INFO:     Epoch: 28
2022-12-31 08:45:17,719 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4597566246986389, 'Total loss': 0.4597566246986389} | train loss {'Reaction outcome loss': 0.1656035963864322, 'Total loss': 0.1656035963864322}
2022-12-31 08:45:17,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:17,719 INFO:     Epoch: 29
2022-12-31 08:45:19,332 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48034755463401474, 'Total loss': 0.48034755463401474} | train loss {'Reaction outcome loss': 0.15747306031593378, 'Total loss': 0.15747306031593378}
2022-12-31 08:45:19,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:19,332 INFO:     Epoch: 30
2022-12-31 08:45:20,943 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4474460631608963, 'Total loss': 0.4474460631608963} | train loss {'Reaction outcome loss': 0.16137547464028973, 'Total loss': 0.16137547464028973}
2022-12-31 08:45:20,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:20,944 INFO:     Epoch: 31
2022-12-31 08:45:22,555 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4864882379770279, 'Total loss': 0.4864882379770279} | train loss {'Reaction outcome loss': 0.1887322685451827, 'Total loss': 0.1887322685451827}
2022-12-31 08:45:22,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:22,555 INFO:     Epoch: 32
2022-12-31 08:45:24,169 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4583525409301122, 'Total loss': 0.4583525409301122} | train loss {'Reaction outcome loss': 0.16924734816690773, 'Total loss': 0.16924734816690773}
2022-12-31 08:45:24,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:24,170 INFO:     Epoch: 33
2022-12-31 08:45:25,792 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46435263951619465, 'Total loss': 0.46435263951619465} | train loss {'Reaction outcome loss': 0.14768432028190084, 'Total loss': 0.14768432028190084}
2022-12-31 08:45:25,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:25,792 INFO:     Epoch: 34
2022-12-31 08:45:27,417 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46849700013796486, 'Total loss': 0.46849700013796486} | train loss {'Reaction outcome loss': 0.1496873714816014, 'Total loss': 0.1496873714816014}
2022-12-31 08:45:27,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:27,418 INFO:     Epoch: 35
2022-12-31 08:45:29,083 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4740409811337789, 'Total loss': 0.4740409811337789} | train loss {'Reaction outcome loss': 0.14404882259828888, 'Total loss': 0.14404882259828888}
2022-12-31 08:45:29,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:29,083 INFO:     Epoch: 36
2022-12-31 08:45:30,706 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5045987367630005, 'Total loss': 0.5045987367630005} | train loss {'Reaction outcome loss': 0.14531749044803344, 'Total loss': 0.14531749044803344}
2022-12-31 08:45:30,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:30,707 INFO:     Epoch: 37
2022-12-31 08:45:32,370 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4739529410998026, 'Total loss': 0.4739529410998026} | train loss {'Reaction outcome loss': 0.14385998494861374, 'Total loss': 0.14385998494861374}
2022-12-31 08:45:32,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:32,371 INFO:     Epoch: 38
2022-12-31 08:45:34,024 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4743669927120209, 'Total loss': 0.4743669927120209} | train loss {'Reaction outcome loss': 0.1410697420585365, 'Total loss': 0.1410697420585365}
2022-12-31 08:45:34,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:34,025 INFO:     Epoch: 39
2022-12-31 08:45:35,700 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4460099826256434, 'Total loss': 0.4460099826256434} | train loss {'Reaction outcome loss': 0.13991652428766416, 'Total loss': 0.13991652428766416}
2022-12-31 08:45:35,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:35,700 INFO:     Epoch: 40
2022-12-31 08:45:37,365 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46108329196770986, 'Total loss': 0.46108329196770986} | train loss {'Reaction outcome loss': 0.14951294180144137, 'Total loss': 0.14951294180144137}
2022-12-31 08:45:37,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:37,365 INFO:     Epoch: 41
2022-12-31 08:45:39,035 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4570004016160965, 'Total loss': 0.4570004016160965} | train loss {'Reaction outcome loss': 0.13795923959688758, 'Total loss': 0.13795923959688758}
2022-12-31 08:45:39,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:39,035 INFO:     Epoch: 42
2022-12-31 08:45:40,700 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4736146797736486, 'Total loss': 0.4736146797736486} | train loss {'Reaction outcome loss': 0.1326387852010994, 'Total loss': 0.1326387852010994}
2022-12-31 08:45:40,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:40,701 INFO:     Epoch: 43
2022-12-31 08:45:42,369 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46354969243208566, 'Total loss': 0.46354969243208566} | train loss {'Reaction outcome loss': 0.13647635379617196, 'Total loss': 0.13647635379617196}
2022-12-31 08:45:42,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:42,370 INFO:     Epoch: 44
2022-12-31 08:45:44,026 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5069780856370926, 'Total loss': 0.5069780856370926} | train loss {'Reaction outcome loss': 0.13189177860086615, 'Total loss': 0.13189177860086615}
2022-12-31 08:45:44,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:44,026 INFO:     Epoch: 45
2022-12-31 08:45:45,704 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4638251190384229, 'Total loss': 0.4638251190384229} | train loss {'Reaction outcome loss': 0.13104130679815737, 'Total loss': 0.13104130679815737}
2022-12-31 08:45:45,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:45,704 INFO:     Epoch: 46
2022-12-31 08:45:47,380 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4674248913923899, 'Total loss': 0.4674248913923899} | train loss {'Reaction outcome loss': 0.1297065123770168, 'Total loss': 0.1297065123770168}
2022-12-31 08:45:47,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:47,380 INFO:     Epoch: 47
2022-12-31 08:45:49,053 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4757132023572922, 'Total loss': 0.4757132023572922} | train loss {'Reaction outcome loss': 0.1320570238892907, 'Total loss': 0.1320570238892907}
2022-12-31 08:45:49,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:49,054 INFO:     Epoch: 48
2022-12-31 08:45:50,726 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5100916355848313, 'Total loss': 0.5100916355848313} | train loss {'Reaction outcome loss': 0.12972300739931888, 'Total loss': 0.12972300739931888}
2022-12-31 08:45:50,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:50,726 INFO:     Epoch: 49
2022-12-31 08:45:52,382 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4781220604976018, 'Total loss': 0.4781220604976018} | train loss {'Reaction outcome loss': 0.13183550135252756, 'Total loss': 0.13183550135252756}
2022-12-31 08:45:52,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:52,382 INFO:     Epoch: 50
2022-12-31 08:45:54,058 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5240386654933293, 'Total loss': 0.5240386654933293} | train loss {'Reaction outcome loss': 0.12460530091702558, 'Total loss': 0.12460530091702558}
2022-12-31 08:45:54,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:54,059 INFO:     Epoch: 51
2022-12-31 08:45:55,732 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49947402675946556, 'Total loss': 0.49947402675946556} | train loss {'Reaction outcome loss': 0.12795218843920325, 'Total loss': 0.12795218843920325}
2022-12-31 08:45:55,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:55,733 INFO:     Epoch: 52
2022-12-31 08:45:57,405 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47927146355311073, 'Total loss': 0.47927146355311073} | train loss {'Reaction outcome loss': 0.12999117041118038, 'Total loss': 0.12999117041118038}
2022-12-31 08:45:57,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:57,405 INFO:     Epoch: 53
2022-12-31 08:45:59,078 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.511386509736379, 'Total loss': 0.511386509736379} | train loss {'Reaction outcome loss': 0.12895307216482857, 'Total loss': 0.12895307216482857}
2022-12-31 08:45:59,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:45:59,079 INFO:     Epoch: 54
2022-12-31 08:46:00,752 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48228320479393005, 'Total loss': 0.48228320479393005} | train loss {'Reaction outcome loss': 0.1386192157473145, 'Total loss': 0.1386192157473145}
2022-12-31 08:46:00,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:00,753 INFO:     Epoch: 55
2022-12-31 08:46:02,410 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5020863965153695, 'Total loss': 0.5020863965153695} | train loss {'Reaction outcome loss': 0.12463623002606808, 'Total loss': 0.12463623002606808}
2022-12-31 08:46:02,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:02,410 INFO:     Epoch: 56
2022-12-31 08:46:04,086 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48852763175964353, 'Total loss': 0.48852763175964353} | train loss {'Reaction outcome loss': 0.136911582208468, 'Total loss': 0.136911582208468}
2022-12-31 08:46:04,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:04,086 INFO:     Epoch: 57
2022-12-31 08:46:05,761 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4846642514069875, 'Total loss': 0.4846642514069875} | train loss {'Reaction outcome loss': 0.15340495954834574, 'Total loss': 0.15340495954834574}
2022-12-31 08:46:05,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:05,761 INFO:     Epoch: 58
2022-12-31 08:46:07,426 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49382887184619906, 'Total loss': 0.49382887184619906} | train loss {'Reaction outcome loss': 0.12585184397260268, 'Total loss': 0.12585184397260268}
2022-12-31 08:46:07,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:07,426 INFO:     Epoch: 59
2022-12-31 08:46:09,049 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5160459001859029, 'Total loss': 0.5160459001859029} | train loss {'Reaction outcome loss': 0.12013919888177306, 'Total loss': 0.12013919888177306}
2022-12-31 08:46:09,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:09,050 INFO:     Epoch: 60
2022-12-31 08:46:10,671 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4918566326300303, 'Total loss': 0.4918566326300303} | train loss {'Reaction outcome loss': 0.11611520867848905, 'Total loss': 0.11611520867848905}
2022-12-31 08:46:10,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:10,672 INFO:     Epoch: 61
2022-12-31 08:46:12,284 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5313045303026835, 'Total loss': 0.5313045303026835} | train loss {'Reaction outcome loss': 0.11575894969839441, 'Total loss': 0.11575894969839441}
2022-12-31 08:46:12,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:12,284 INFO:     Epoch: 62
2022-12-31 08:46:13,895 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5026106506586074, 'Total loss': 0.5026106506586074} | train loss {'Reaction outcome loss': 0.11910970353325694, 'Total loss': 0.11910970353325694}
2022-12-31 08:46:13,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:13,895 INFO:     Epoch: 63
2022-12-31 08:46:15,561 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5023450871308645, 'Total loss': 0.5023450871308645} | train loss {'Reaction outcome loss': 0.12637036643961133, 'Total loss': 0.12637036643961133}
2022-12-31 08:46:15,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:15,562 INFO:     Epoch: 64
2022-12-31 08:46:17,228 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5099718650182088, 'Total loss': 0.5099718650182088} | train loss {'Reaction outcome loss': 0.1185966711344641, 'Total loss': 0.1185966711344641}
2022-12-31 08:46:17,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:17,228 INFO:     Epoch: 65
2022-12-31 08:46:18,849 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4796728491783142, 'Total loss': 0.4796728491783142} | train loss {'Reaction outcome loss': 0.11654404528351311, 'Total loss': 0.11654404528351311}
2022-12-31 08:46:18,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:18,849 INFO:     Epoch: 66
2022-12-31 08:46:20,474 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47706559499104817, 'Total loss': 0.47706559499104817} | train loss {'Reaction outcome loss': 0.11279136887152572, 'Total loss': 0.11279136887152572}
2022-12-31 08:46:20,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:20,474 INFO:     Epoch: 67
2022-12-31 08:46:22,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48134385645389555, 'Total loss': 0.48134385645389555} | train loss {'Reaction outcome loss': 0.11703610552164416, 'Total loss': 0.11703610552164416}
2022-12-31 08:46:22,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:22,091 INFO:     Epoch: 68
2022-12-31 08:46:23,716 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5062839388847351, 'Total loss': 0.5062839388847351} | train loss {'Reaction outcome loss': 0.12258413057112931, 'Total loss': 0.12258413057112931}
2022-12-31 08:46:23,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:23,716 INFO:     Epoch: 69
2022-12-31 08:46:25,340 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5195957144101461, 'Total loss': 0.5195957144101461} | train loss {'Reaction outcome loss': 0.1174857437149183, 'Total loss': 0.1174857437149183}
2022-12-31 08:46:25,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:25,341 INFO:     Epoch: 70
2022-12-31 08:46:26,963 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49175241639216744, 'Total loss': 0.49175241639216744} | train loss {'Reaction outcome loss': 0.11562212435503329, 'Total loss': 0.11562212435503329}
2022-12-31 08:46:26,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:26,963 INFO:     Epoch: 71
2022-12-31 08:46:28,587 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48840106328328453, 'Total loss': 0.48840106328328453} | train loss {'Reaction outcome loss': 0.1161612504971951, 'Total loss': 0.1161612504971951}
2022-12-31 08:46:28,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:28,588 INFO:     Epoch: 72
2022-12-31 08:46:30,205 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5180894762277604, 'Total loss': 0.5180894762277604} | train loss {'Reaction outcome loss': 0.11023613567796428, 'Total loss': 0.11023613567796428}
2022-12-31 08:46:30,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:30,205 INFO:     Epoch: 73
2022-12-31 08:46:31,855 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4957315941651662, 'Total loss': 0.4957315941651662} | train loss {'Reaction outcome loss': 0.1153336366684095, 'Total loss': 0.1153336366684095}
2022-12-31 08:46:31,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:31,856 INFO:     Epoch: 74
2022-12-31 08:46:33,478 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4932665805021922, 'Total loss': 0.4932665805021922} | train loss {'Reaction outcome loss': 0.11616501028723744, 'Total loss': 0.11616501028723744}
2022-12-31 08:46:33,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:33,478 INFO:     Epoch: 75
2022-12-31 08:46:35,102 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5190042023857434, 'Total loss': 0.5190042023857434} | train loss {'Reaction outcome loss': 0.11620653869307505, 'Total loss': 0.11620653869307505}
2022-12-31 08:46:35,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:35,102 INFO:     Epoch: 76
2022-12-31 08:46:36,769 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.516534666220347, 'Total loss': 0.516534666220347} | train loss {'Reaction outcome loss': 0.11517164567413747, 'Total loss': 0.11517164567413747}
2022-12-31 08:46:36,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:36,769 INFO:     Epoch: 77
2022-12-31 08:46:38,381 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5470847308635711, 'Total loss': 0.5470847308635711} | train loss {'Reaction outcome loss': 0.11684967803581536, 'Total loss': 0.11684967803581536}
2022-12-31 08:46:38,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:38,381 INFO:     Epoch: 78
2022-12-31 08:46:40,033 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5268083761135737, 'Total loss': 0.5268083761135737} | train loss {'Reaction outcome loss': 0.11254757471328629, 'Total loss': 0.11254757471328629}
2022-12-31 08:46:40,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:40,033 INFO:     Epoch: 79
2022-12-31 08:46:41,655 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4907913327217102, 'Total loss': 0.4907913327217102} | train loss {'Reaction outcome loss': 0.11208612076507711, 'Total loss': 0.11208612076507711}
2022-12-31 08:46:41,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:41,656 INFO:     Epoch: 80
2022-12-31 08:46:43,322 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4873548746109009, 'Total loss': 0.4873548746109009} | train loss {'Reaction outcome loss': 0.10624281200317995, 'Total loss': 0.10624281200317995}
2022-12-31 08:46:43,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:43,322 INFO:     Epoch: 81
2022-12-31 08:46:44,943 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5052803834279378, 'Total loss': 0.5052803834279378} | train loss {'Reaction outcome loss': 0.10700730692116085, 'Total loss': 0.10700730692116085}
2022-12-31 08:46:44,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:44,944 INFO:     Epoch: 82
2022-12-31 08:46:46,578 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.488438680768013, 'Total loss': 0.488438680768013} | train loss {'Reaction outcome loss': 0.10905980212070669, 'Total loss': 0.10905980212070669}
2022-12-31 08:46:46,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:46,579 INFO:     Epoch: 83
2022-12-31 08:46:48,224 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.491089391708374, 'Total loss': 0.491089391708374} | train loss {'Reaction outcome loss': 0.11437473265491924, 'Total loss': 0.11437473265491924}
2022-12-31 08:46:48,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:48,224 INFO:     Epoch: 84
2022-12-31 08:46:49,883 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4982932984828949, 'Total loss': 0.4982932984828949} | train loss {'Reaction outcome loss': 0.11152399694833877, 'Total loss': 0.11152399694833877}
2022-12-31 08:46:49,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:49,883 INFO:     Epoch: 85
2022-12-31 08:46:51,566 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5198594689369201, 'Total loss': 0.5198594689369201} | train loss {'Reaction outcome loss': 0.10802072207316475, 'Total loss': 0.10802072207316475}
2022-12-31 08:46:51,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:51,567 INFO:     Epoch: 86
2022-12-31 08:46:53,208 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.504617910583814, 'Total loss': 0.504617910583814} | train loss {'Reaction outcome loss': 0.11296797827547551, 'Total loss': 0.11296797827547551}
2022-12-31 08:46:53,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:53,209 INFO:     Epoch: 87
2022-12-31 08:46:54,874 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.523296790321668, 'Total loss': 0.523296790321668} | train loss {'Reaction outcome loss': 0.1169064795628757, 'Total loss': 0.1169064795628757}
2022-12-31 08:46:54,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:54,874 INFO:     Epoch: 88
2022-12-31 08:46:56,495 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.525759204228719, 'Total loss': 0.525759204228719} | train loss {'Reaction outcome loss': 0.1507513076912669, 'Total loss': 0.1507513076912669}
2022-12-31 08:46:56,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:56,496 INFO:     Epoch: 89
2022-12-31 08:46:58,118 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4857310841480891, 'Total loss': 0.4857310841480891} | train loss {'Reaction outcome loss': 0.11354713828286153, 'Total loss': 0.11354713828286153}
2022-12-31 08:46:58,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:58,119 INFO:     Epoch: 90
2022-12-31 08:46:59,797 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5318533321221669, 'Total loss': 0.5318533321221669} | train loss {'Reaction outcome loss': 0.10636633403255077, 'Total loss': 0.10636633403255077}
2022-12-31 08:46:59,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:46:59,797 INFO:     Epoch: 91
2022-12-31 08:47:01,483 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5099857638279597, 'Total loss': 0.5099857638279597} | train loss {'Reaction outcome loss': 0.10404341232722378, 'Total loss': 0.10404341232722378}
2022-12-31 08:47:01,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:01,483 INFO:     Epoch: 92
2022-12-31 08:47:03,168 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.525494905312856, 'Total loss': 0.525494905312856} | train loss {'Reaction outcome loss': 0.1137155060980307, 'Total loss': 0.1137155060980307}
2022-12-31 08:47:03,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:03,169 INFO:     Epoch: 93
2022-12-31 08:47:04,858 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.497702486316363, 'Total loss': 0.497702486316363} | train loss {'Reaction outcome loss': 0.11305972681957824, 'Total loss': 0.11305972681957824}
2022-12-31 08:47:04,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:04,858 INFO:     Epoch: 94
2022-12-31 08:47:06,503 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5106077929337819, 'Total loss': 0.5106077929337819} | train loss {'Reaction outcome loss': 0.10682848447712773, 'Total loss': 0.10682848447712773}
2022-12-31 08:47:06,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:06,503 INFO:     Epoch: 95
2022-12-31 08:47:08,137 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5381569822629293, 'Total loss': 0.5381569822629293} | train loss {'Reaction outcome loss': 0.10660529553981336, 'Total loss': 0.10660529553981336}
2022-12-31 08:47:08,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:08,137 INFO:     Epoch: 96
2022-12-31 08:47:09,757 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5065456022818883, 'Total loss': 0.5065456022818883} | train loss {'Reaction outcome loss': 0.10757161590713585, 'Total loss': 0.10757161590713585}
2022-12-31 08:47:09,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:09,757 INFO:     Epoch: 97
2022-12-31 08:47:11,422 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5421195874611536, 'Total loss': 0.5421195874611536} | train loss {'Reaction outcome loss': 0.10423194270570883, 'Total loss': 0.10423194270570883}
2022-12-31 08:47:11,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:11,423 INFO:     Epoch: 98
2022-12-31 08:47:13,089 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5193101545174916, 'Total loss': 0.5193101545174916} | train loss {'Reaction outcome loss': 0.10460861275171646, 'Total loss': 0.10460861275171646}
2022-12-31 08:47:13,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:13,089 INFO:     Epoch: 99
2022-12-31 08:47:14,708 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5429556965827942, 'Total loss': 0.5429556965827942} | train loss {'Reaction outcome loss': 0.10330946124586395, 'Total loss': 0.10330946124586395}
2022-12-31 08:47:14,708 INFO:     Best model found after epoch 10 of 100.
2022-12-31 08:47:14,708 INFO:   Done with stage: TRAINING
2022-12-31 08:47:14,708 INFO:   Starting stage: EVALUATION
2022-12-31 08:47:14,840 INFO:   Done with stage: EVALUATION
2022-12-31 08:47:14,840 INFO:   Leaving out SEQ value Fold_4
2022-12-31 08:47:14,852 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:47:14,852 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:47:15,498 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:47:15,499 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:47:15,566 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:47:15,567 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:47:15,567 INFO:     No hyperparam tuning for this model
2022-12-31 08:47:15,567 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:47:15,567 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:47:15,567 INFO:     None feature selector for col prot
2022-12-31 08:47:15,568 INFO:     None feature selector for col prot
2022-12-31 08:47:15,568 INFO:     None feature selector for col prot
2022-12-31 08:47:15,568 INFO:     None feature selector for col chem
2022-12-31 08:47:15,568 INFO:     None feature selector for col chem
2022-12-31 08:47:15,568 INFO:     None feature selector for col chem
2022-12-31 08:47:15,568 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:47:15,568 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:47:15,570 INFO:     Number of params in model 224011
2022-12-31 08:47:15,573 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:47:15,573 INFO:   Starting stage: TRAINING
2022-12-31 08:47:15,618 INFO:     Val loss before train {'Reaction outcome loss': 0.9736696362495423, 'Total loss': 0.9736696362495423}
2022-12-31 08:47:15,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:15,618 INFO:     Epoch: 0
2022-12-31 08:47:17,245 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.604004544019699, 'Total loss': 0.604004544019699} | train loss {'Reaction outcome loss': 0.7821878095826518, 'Total loss': 0.7821878095826518}
2022-12-31 08:47:17,246 INFO:     Found new best model at epoch 0
2022-12-31 08:47:17,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:17,247 INFO:     Epoch: 1
2022-12-31 08:47:18,872 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5313499212265015, 'Total loss': 0.5313499212265015} | train loss {'Reaction outcome loss': 0.5127276864830768, 'Total loss': 0.5127276864830768}
2022-12-31 08:47:18,872 INFO:     Found new best model at epoch 1
2022-12-31 08:47:18,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:18,873 INFO:     Epoch: 2
2022-12-31 08:47:20,497 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47563952803611753, 'Total loss': 0.47563952803611753} | train loss {'Reaction outcome loss': 0.44720587328022565, 'Total loss': 0.44720587328022565}
2022-12-31 08:47:20,497 INFO:     Found new best model at epoch 2
2022-12-31 08:47:20,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:20,498 INFO:     Epoch: 3
2022-12-31 08:47:22,123 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49166313111782073, 'Total loss': 0.49166313111782073} | train loss {'Reaction outcome loss': 0.4051341713012771, 'Total loss': 0.4051341713012771}
2022-12-31 08:47:22,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:22,123 INFO:     Epoch: 4
2022-12-31 08:47:23,785 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4664055089155833, 'Total loss': 0.4664055089155833} | train loss {'Reaction outcome loss': 0.37855064473535177, 'Total loss': 0.37855064473535177}
2022-12-31 08:47:23,785 INFO:     Found new best model at epoch 4
2022-12-31 08:47:23,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:23,786 INFO:     Epoch: 5
2022-12-31 08:47:25,408 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4517382442951202, 'Total loss': 0.4517382442951202} | train loss {'Reaction outcome loss': 0.3560979523114349, 'Total loss': 0.3560979523114349}
2022-12-31 08:47:25,408 INFO:     Found new best model at epoch 5
2022-12-31 08:47:25,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:25,409 INFO:     Epoch: 6
2022-12-31 08:47:27,030 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45305148760477704, 'Total loss': 0.45305148760477704} | train loss {'Reaction outcome loss': 0.3332654183683413, 'Total loss': 0.3332654183683413}
2022-12-31 08:47:27,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:27,030 INFO:     Epoch: 7
2022-12-31 08:47:28,653 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45663523276646933, 'Total loss': 0.45663523276646933} | train loss {'Reaction outcome loss': 0.31566825963637457, 'Total loss': 0.31566825963637457}
2022-12-31 08:47:28,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:28,654 INFO:     Epoch: 8
2022-12-31 08:47:30,324 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4511966188748678, 'Total loss': 0.4511966188748678} | train loss {'Reaction outcome loss': 0.2990630030201661, 'Total loss': 0.2990630030201661}
2022-12-31 08:47:30,324 INFO:     Found new best model at epoch 8
2022-12-31 08:47:30,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:30,325 INFO:     Epoch: 9
2022-12-31 08:47:31,946 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46974717179934183, 'Total loss': 0.46974717179934183} | train loss {'Reaction outcome loss': 0.28755085008884596, 'Total loss': 0.28755085008884596}
2022-12-31 08:47:31,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:31,948 INFO:     Epoch: 10
2022-12-31 08:47:33,581 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46020469864209496, 'Total loss': 0.46020469864209496} | train loss {'Reaction outcome loss': 0.27529958796953036, 'Total loss': 0.27529958796953036}
2022-12-31 08:47:33,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:33,581 INFO:     Epoch: 11
2022-12-31 08:47:35,220 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4682967553536097, 'Total loss': 0.4682967553536097} | train loss {'Reaction outcome loss': 0.26297101165951375, 'Total loss': 0.26297101165951375}
2022-12-31 08:47:35,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:35,220 INFO:     Epoch: 12
2022-12-31 08:47:36,844 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45926600098609927, 'Total loss': 0.45926600098609927} | train loss {'Reaction outcome loss': 0.2525500270003446, 'Total loss': 0.2525500270003446}
2022-12-31 08:47:36,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:36,845 INFO:     Epoch: 13
2022-12-31 08:47:38,468 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47434171636899314, 'Total loss': 0.47434171636899314} | train loss {'Reaction outcome loss': 0.2460232852060442, 'Total loss': 0.2460232852060442}
2022-12-31 08:47:38,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:38,469 INFO:     Epoch: 14
2022-12-31 08:47:40,089 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45900557140509285, 'Total loss': 0.45900557140509285} | train loss {'Reaction outcome loss': 0.2385561326888494, 'Total loss': 0.2385561326888494}
2022-12-31 08:47:40,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:40,089 INFO:     Epoch: 15
2022-12-31 08:47:41,731 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48675418794155123, 'Total loss': 0.48675418794155123} | train loss {'Reaction outcome loss': 0.22976088078040294, 'Total loss': 0.22976088078040294}
2022-12-31 08:47:41,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:41,731 INFO:     Epoch: 16
2022-12-31 08:47:43,360 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4770662407080332, 'Total loss': 0.4770662407080332} | train loss {'Reaction outcome loss': 0.22410855711259567, 'Total loss': 0.22410855711259567}
2022-12-31 08:47:43,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:43,360 INFO:     Epoch: 17
2022-12-31 08:47:45,016 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4768598347902298, 'Total loss': 0.4768598347902298} | train loss {'Reaction outcome loss': 0.2188650464591997, 'Total loss': 0.2188650464591997}
2022-12-31 08:47:45,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:45,017 INFO:     Epoch: 18
2022-12-31 08:47:46,637 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48062912821769715, 'Total loss': 0.48062912821769715} | train loss {'Reaction outcome loss': 0.21308356354060157, 'Total loss': 0.21308356354060157}
2022-12-31 08:47:46,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:46,637 INFO:     Epoch: 19
2022-12-31 08:47:48,260 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46478465596834817, 'Total loss': 0.46478465596834817} | train loss {'Reaction outcome loss': 0.20519617621514558, 'Total loss': 0.20519617621514558}
2022-12-31 08:47:48,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:48,260 INFO:     Epoch: 20
2022-12-31 08:47:49,881 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48856667180856067, 'Total loss': 0.48856667180856067} | train loss {'Reaction outcome loss': 0.20343267276802432, 'Total loss': 0.20343267276802432}
2022-12-31 08:47:49,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:49,882 INFO:     Epoch: 21
2022-12-31 08:47:51,518 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4666929244995117, 'Total loss': 0.4666929244995117} | train loss {'Reaction outcome loss': 0.1969494028386764, 'Total loss': 0.1969494028386764}
2022-12-31 08:47:51,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:51,519 INFO:     Epoch: 22
2022-12-31 08:47:53,148 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4928019265333811, 'Total loss': 0.4928019265333811} | train loss {'Reaction outcome loss': 0.19329232658639497, 'Total loss': 0.19329232658639497}
2022-12-31 08:47:53,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:53,149 INFO:     Epoch: 23
2022-12-31 08:47:54,769 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47686294217904407, 'Total loss': 0.47686294217904407} | train loss {'Reaction outcome loss': 0.18725917986274734, 'Total loss': 0.18725917986274734}
2022-12-31 08:47:54,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:54,769 INFO:     Epoch: 24
2022-12-31 08:47:56,391 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5183877989649772, 'Total loss': 0.5183877989649772} | train loss {'Reaction outcome loss': 0.18425869012406157, 'Total loss': 0.18425869012406157}
2022-12-31 08:47:56,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:56,391 INFO:     Epoch: 25
2022-12-31 08:47:58,011 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48258614738782246, 'Total loss': 0.48258614738782246} | train loss {'Reaction outcome loss': 0.1823702316280683, 'Total loss': 0.1823702316280683}
2022-12-31 08:47:58,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:58,012 INFO:     Epoch: 26
2022-12-31 08:47:59,634 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4933807820081711, 'Total loss': 0.4933807820081711} | train loss {'Reaction outcome loss': 0.18006996357887445, 'Total loss': 0.18006996357887445}
2022-12-31 08:47:59,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:47:59,634 INFO:     Epoch: 27
2022-12-31 08:48:01,260 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4717883363366127, 'Total loss': 0.4717883363366127} | train loss {'Reaction outcome loss': 0.17869995147097412, 'Total loss': 0.17869995147097412}
2022-12-31 08:48:01,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:01,260 INFO:     Epoch: 28
2022-12-31 08:48:02,892 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5072313586870829, 'Total loss': 0.5072313586870829} | train loss {'Reaction outcome loss': 0.17004846957670222, 'Total loss': 0.17004846957670222}
2022-12-31 08:48:02,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:02,893 INFO:     Epoch: 29
2022-12-31 08:48:04,533 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4932907899220785, 'Total loss': 0.4932907899220785} | train loss {'Reaction outcome loss': 0.1733942425033138, 'Total loss': 0.1733942425033138}
2022-12-31 08:48:04,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:04,534 INFO:     Epoch: 30
2022-12-31 08:48:06,176 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4992823223272959, 'Total loss': 0.4992823223272959} | train loss {'Reaction outcome loss': 0.16890326326894523, 'Total loss': 0.16890326326894523}
2022-12-31 08:48:06,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:06,176 INFO:     Epoch: 31
2022-12-31 08:48:07,817 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5363796869913737, 'Total loss': 0.5363796869913737} | train loss {'Reaction outcome loss': 0.1658948448046181, 'Total loss': 0.1658948448046181}
2022-12-31 08:48:07,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:07,817 INFO:     Epoch: 32
2022-12-31 08:48:09,446 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4828269511461258, 'Total loss': 0.4828269511461258} | train loss {'Reaction outcome loss': 0.16332196679625272, 'Total loss': 0.16332196679625272}
2022-12-31 08:48:09,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:09,447 INFO:     Epoch: 33
2022-12-31 08:48:11,072 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4927257031202316, 'Total loss': 0.4927257031202316} | train loss {'Reaction outcome loss': 0.15937574509706093, 'Total loss': 0.15937574509706093}
2022-12-31 08:48:11,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:11,072 INFO:     Epoch: 34
2022-12-31 08:48:12,690 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46455182830492653, 'Total loss': 0.46455182830492653} | train loss {'Reaction outcome loss': 0.16117871107553747, 'Total loss': 0.16117871107553747}
2022-12-31 08:48:12,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:12,690 INFO:     Epoch: 35
2022-12-31 08:48:14,360 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5399531741937001, 'Total loss': 0.5399531741937001} | train loss {'Reaction outcome loss': 0.1557431964217164, 'Total loss': 0.1557431964217164}
2022-12-31 08:48:14,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:14,360 INFO:     Epoch: 36
2022-12-31 08:48:16,030 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5223677059014639, 'Total loss': 0.5223677059014639} | train loss {'Reaction outcome loss': 0.1576827343365023, 'Total loss': 0.1576827343365023}
2022-12-31 08:48:16,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:16,030 INFO:     Epoch: 37
2022-12-31 08:48:17,648 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5048004706700643, 'Total loss': 0.5048004706700643} | train loss {'Reaction outcome loss': 0.15829936543224035, 'Total loss': 0.15829936543224035}
2022-12-31 08:48:17,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:17,649 INFO:     Epoch: 38
2022-12-31 08:48:19,273 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5041323959827423, 'Total loss': 0.5041323959827423} | train loss {'Reaction outcome loss': 0.15510573984873532, 'Total loss': 0.15510573984873532}
2022-12-31 08:48:19,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:19,273 INFO:     Epoch: 39
2022-12-31 08:48:20,902 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49793986678123475, 'Total loss': 0.49793986678123475} | train loss {'Reaction outcome loss': 0.1527154882058555, 'Total loss': 0.1527154882058555}
2022-12-31 08:48:20,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:20,902 INFO:     Epoch: 40
2022-12-31 08:48:22,543 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49552599489688876, 'Total loss': 0.49552599489688876} | train loss {'Reaction outcome loss': 0.1472741005074784, 'Total loss': 0.1472741005074784}
2022-12-31 08:48:22,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:22,543 INFO:     Epoch: 41
2022-12-31 08:48:24,182 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4824704567591349, 'Total loss': 0.4824704567591349} | train loss {'Reaction outcome loss': 0.14706632248815216, 'Total loss': 0.14706632248815216}
2022-12-31 08:48:24,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:24,182 INFO:     Epoch: 42
2022-12-31 08:48:25,822 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.495117445786794, 'Total loss': 0.495117445786794} | train loss {'Reaction outcome loss': 0.14638124751969364, 'Total loss': 0.14638124751969364}
2022-12-31 08:48:25,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:25,823 INFO:     Epoch: 43
2022-12-31 08:48:27,457 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5036079307397207, 'Total loss': 0.5036079307397207} | train loss {'Reaction outcome loss': 0.14218225647839935, 'Total loss': 0.14218225647839935}
2022-12-31 08:48:27,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:27,457 INFO:     Epoch: 44
2022-12-31 08:48:29,073 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5039494057496389, 'Total loss': 0.5039494057496389} | train loss {'Reaction outcome loss': 0.1463412560979812, 'Total loss': 0.1463412560979812}
2022-12-31 08:48:29,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:29,073 INFO:     Epoch: 45
2022-12-31 08:48:30,742 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5072239836057028, 'Total loss': 0.5072239836057028} | train loss {'Reaction outcome loss': 0.14398366712127889, 'Total loss': 0.14398366712127889}
2022-12-31 08:48:30,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:30,742 INFO:     Epoch: 46
2022-12-31 08:48:32,413 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5224821309248606, 'Total loss': 0.5224821309248606} | train loss {'Reaction outcome loss': 0.14360581872823383, 'Total loss': 0.14360581872823383}
2022-12-31 08:48:32,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:32,413 INFO:     Epoch: 47
2022-12-31 08:48:34,032 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5074766407410304, 'Total loss': 0.5074766407410304} | train loss {'Reaction outcome loss': 0.13810244285659562, 'Total loss': 0.13810244285659562}
2022-12-31 08:48:34,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:34,033 INFO:     Epoch: 48
2022-12-31 08:48:35,653 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5254548132419586, 'Total loss': 0.5254548132419586} | train loss {'Reaction outcome loss': 0.13728078169620425, 'Total loss': 0.13728078169620425}
2022-12-31 08:48:35,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:35,653 INFO:     Epoch: 49
2022-12-31 08:48:37,279 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5033305784066519, 'Total loss': 0.5033305784066519} | train loss {'Reaction outcome loss': 0.1401450569818758, 'Total loss': 0.1401450569818758}
2022-12-31 08:48:37,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:37,279 INFO:     Epoch: 50
2022-12-31 08:48:38,936 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5048106302817662, 'Total loss': 0.5048106302817662} | train loss {'Reaction outcome loss': 0.13692475095330756, 'Total loss': 0.13692475095330756}
2022-12-31 08:48:38,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:38,937 INFO:     Epoch: 51
2022-12-31 08:48:40,606 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5035034184654553, 'Total loss': 0.5035034184654553} | train loss {'Reaction outcome loss': 0.13775940691726113, 'Total loss': 0.13775940691726113}
2022-12-31 08:48:40,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:40,607 INFO:     Epoch: 52
2022-12-31 08:48:42,228 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5278676400581995, 'Total loss': 0.5278676400581995} | train loss {'Reaction outcome loss': 0.13700865582976532, 'Total loss': 0.13700865582976532}
2022-12-31 08:48:42,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:42,229 INFO:     Epoch: 53
2022-12-31 08:48:43,851 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4944171726703644, 'Total loss': 0.4944171726703644} | train loss {'Reaction outcome loss': 0.13931051165954839, 'Total loss': 0.13931051165954839}
2022-12-31 08:48:43,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:43,851 INFO:     Epoch: 54
2022-12-31 08:48:45,521 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49625557065010073, 'Total loss': 0.49625557065010073} | train loss {'Reaction outcome loss': 0.13920550776430363, 'Total loss': 0.13920550776430363}
2022-12-31 08:48:45,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:45,521 INFO:     Epoch: 55
2022-12-31 08:48:47,141 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5059701750675837, 'Total loss': 0.5059701750675837} | train loss {'Reaction outcome loss': 0.13472611478795482, 'Total loss': 0.13472611478795482}
2022-12-31 08:48:47,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:47,141 INFO:     Epoch: 56
2022-12-31 08:48:48,771 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5099125941594441, 'Total loss': 0.5099125941594441} | train loss {'Reaction outcome loss': 0.1306760445109397, 'Total loss': 0.1306760445109397}
2022-12-31 08:48:48,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:48,772 INFO:     Epoch: 57
2022-12-31 08:48:50,410 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.528820518652598, 'Total loss': 0.528820518652598} | train loss {'Reaction outcome loss': 0.13150830965805194, 'Total loss': 0.13150830965805194}
2022-12-31 08:48:50,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:50,410 INFO:     Epoch: 58
2022-12-31 08:48:52,048 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49067198038101195, 'Total loss': 0.49067198038101195} | train loss {'Reaction outcome loss': 0.13243638567411298, 'Total loss': 0.13243638567411298}
2022-12-31 08:48:52,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:52,048 INFO:     Epoch: 59
2022-12-31 08:48:53,688 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49960125287373863, 'Total loss': 0.49960125287373863} | train loss {'Reaction outcome loss': 0.13198225887236772, 'Total loss': 0.13198225887236772}
2022-12-31 08:48:53,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:53,689 INFO:     Epoch: 60
2022-12-31 08:48:55,317 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4956461692849795, 'Total loss': 0.4956461692849795} | train loss {'Reaction outcome loss': 0.12919322356904456, 'Total loss': 0.12919322356904456}
2022-12-31 08:48:55,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:55,317 INFO:     Epoch: 61
2022-12-31 08:48:56,937 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5040346552928289, 'Total loss': 0.5040346552928289} | train loss {'Reaction outcome loss': 0.12897534529587745, 'Total loss': 0.12897534529587745}
2022-12-31 08:48:56,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:56,938 INFO:     Epoch: 62
2022-12-31 08:48:58,558 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5037818332513173, 'Total loss': 0.5037818332513173} | train loss {'Reaction outcome loss': 0.13000330977336863, 'Total loss': 0.13000330977336863}
2022-12-31 08:48:58,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:48:58,558 INFO:     Epoch: 63
2022-12-31 08:49:00,171 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49987119336922964, 'Total loss': 0.49987119336922964} | train loss {'Reaction outcome loss': 0.12680372117349495, 'Total loss': 0.12680372117349495}
2022-12-31 08:49:00,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:00,172 INFO:     Epoch: 64
2022-12-31 08:49:01,841 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4973071386416753, 'Total loss': 0.4973071386416753} | train loss {'Reaction outcome loss': 0.13211468426470346, 'Total loss': 0.13211468426470346}
2022-12-31 08:49:01,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:01,842 INFO:     Epoch: 65
2022-12-31 08:49:03,462 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5112866361935934, 'Total loss': 0.5112866361935934} | train loss {'Reaction outcome loss': 0.13006445432808048, 'Total loss': 0.13006445432808048}
2022-12-31 08:49:03,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:03,462 INFO:     Epoch: 66
2022-12-31 08:49:05,094 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4857123961051305, 'Total loss': 0.4857123961051305} | train loss {'Reaction outcome loss': 0.13431095687961642, 'Total loss': 0.13431095687961642}
2022-12-31 08:49:05,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:05,094 INFO:     Epoch: 67
2022-12-31 08:49:06,724 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4880705197652181, 'Total loss': 0.4880705197652181} | train loss {'Reaction outcome loss': 0.12765285146459668, 'Total loss': 0.12765285146459668}
2022-12-31 08:49:06,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:06,724 INFO:     Epoch: 68
2022-12-31 08:49:08,362 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49085482557614646, 'Total loss': 0.49085482557614646} | train loss {'Reaction outcome loss': 0.12805092913041477, 'Total loss': 0.12805092913041477}
2022-12-31 08:49:08,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:08,363 INFO:     Epoch: 69
2022-12-31 08:49:10,000 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5238468925158183, 'Total loss': 0.5238468925158183} | train loss {'Reaction outcome loss': 0.12569696735758806, 'Total loss': 0.12569696735758806}
2022-12-31 08:49:10,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:10,001 INFO:     Epoch: 70
2022-12-31 08:49:11,639 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49619631667931874, 'Total loss': 0.49619631667931874} | train loss {'Reaction outcome loss': 0.12958038304276792, 'Total loss': 0.12958038304276792}
2022-12-31 08:49:11,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:11,639 INFO:     Epoch: 71
2022-12-31 08:49:13,220 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5129438420136769, 'Total loss': 0.5129438420136769} | train loss {'Reaction outcome loss': 0.12200185430105036, 'Total loss': 0.12200185430105036}
2022-12-31 08:49:13,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:13,221 INFO:     Epoch: 72
2022-12-31 08:49:14,399 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5249165122707685, 'Total loss': 0.5249165122707685} | train loss {'Reaction outcome loss': 0.12439417836360553, 'Total loss': 0.12439417836360553}
2022-12-31 08:49:14,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:14,399 INFO:     Epoch: 73
2022-12-31 08:49:15,513 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48767303824424746, 'Total loss': 0.48767303824424746} | train loss {'Reaction outcome loss': 0.12489762836445244, 'Total loss': 0.12489762836445244}
2022-12-31 08:49:15,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:15,513 INFO:     Epoch: 74
2022-12-31 08:49:16,624 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4821481332182884, 'Total loss': 0.4821481332182884} | train loss {'Reaction outcome loss': 0.12420257348281462, 'Total loss': 0.12420257348281462}
2022-12-31 08:49:16,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:16,625 INFO:     Epoch: 75
2022-12-31 08:49:17,808 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5035675972700119, 'Total loss': 0.5035675972700119} | train loss {'Reaction outcome loss': 0.12430765490898264, 'Total loss': 0.12430765490898264}
2022-12-31 08:49:17,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:17,809 INFO:     Epoch: 76
2022-12-31 08:49:19,476 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5247541705767313, 'Total loss': 0.5247541705767313} | train loss {'Reaction outcome loss': 0.12456850783852357, 'Total loss': 0.12456850783852357}
2022-12-31 08:49:19,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:19,476 INFO:     Epoch: 77
2022-12-31 08:49:21,143 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5181056121985118, 'Total loss': 0.5181056121985118} | train loss {'Reaction outcome loss': 0.12405927251647848, 'Total loss': 0.12405927251647848}
2022-12-31 08:49:21,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:21,144 INFO:     Epoch: 78
2022-12-31 08:49:22,797 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5031202644109726, 'Total loss': 0.5031202644109726} | train loss {'Reaction outcome loss': 0.12172081321309781, 'Total loss': 0.12172081321309781}
2022-12-31 08:49:22,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:22,797 INFO:     Epoch: 79
2022-12-31 08:49:24,466 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5142186939716339, 'Total loss': 0.5142186939716339} | train loss {'Reaction outcome loss': 0.12053077344846531, 'Total loss': 0.12053077344846531}
2022-12-31 08:49:24,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:24,466 INFO:     Epoch: 80
2022-12-31 08:49:26,095 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49894965489705406, 'Total loss': 0.49894965489705406} | train loss {'Reaction outcome loss': 0.11919436041292623, 'Total loss': 0.11919436041292623}
2022-12-31 08:49:26,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:26,095 INFO:     Epoch: 81
2022-12-31 08:49:27,751 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4770396123329798, 'Total loss': 0.4770396123329798} | train loss {'Reaction outcome loss': 0.11994740387444999, 'Total loss': 0.11994740387444999}
2022-12-31 08:49:27,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:27,752 INFO:     Epoch: 82
2022-12-31 08:49:29,381 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48423966964085896, 'Total loss': 0.48423966964085896} | train loss {'Reaction outcome loss': 0.12018639199513041, 'Total loss': 0.12018639199513041}
2022-12-31 08:49:29,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:29,382 INFO:     Epoch: 83
2022-12-31 08:49:31,015 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4661243264873823, 'Total loss': 0.4661243264873823} | train loss {'Reaction outcome loss': 0.12024473308901629, 'Total loss': 0.12024473308901629}
2022-12-31 08:49:31,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:31,015 INFO:     Epoch: 84
2022-12-31 08:49:32,684 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48876136938730874, 'Total loss': 0.48876136938730874} | train loss {'Reaction outcome loss': 0.12097223899125488, 'Total loss': 0.12097223899125488}
2022-12-31 08:49:32,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:32,685 INFO:     Epoch: 85
2022-12-31 08:49:34,354 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5116620709498724, 'Total loss': 0.5116620709498724} | train loss {'Reaction outcome loss': 0.12129751383579111, 'Total loss': 0.12129751383579111}
2022-12-31 08:49:34,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:34,354 INFO:     Epoch: 86
2022-12-31 08:49:35,981 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.503970135251681, 'Total loss': 0.503970135251681} | train loss {'Reaction outcome loss': 0.1197241647034507, 'Total loss': 0.1197241647034507}
2022-12-31 08:49:35,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:35,981 INFO:     Epoch: 87
2022-12-31 08:49:37,635 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5205389281113942, 'Total loss': 0.5205389281113942} | train loss {'Reaction outcome loss': 0.12350603607937102, 'Total loss': 0.12350603607937102}
2022-12-31 08:49:37,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:37,635 INFO:     Epoch: 88
2022-12-31 08:49:39,304 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.516468858718872, 'Total loss': 0.516468858718872} | train loss {'Reaction outcome loss': 0.11856991100202345, 'Total loss': 0.11856991100202345}
2022-12-31 08:49:39,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:39,304 INFO:     Epoch: 89
2022-12-31 08:49:40,939 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48293325304985046, 'Total loss': 0.48293325304985046} | train loss {'Reaction outcome loss': 0.11743417629528292, 'Total loss': 0.11743417629528292}
2022-12-31 08:49:40,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:40,940 INFO:     Epoch: 90
2022-12-31 08:49:42,578 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5003702123959859, 'Total loss': 0.5003702123959859} | train loss {'Reaction outcome loss': 0.11498844403679405, 'Total loss': 0.11498844403679405}
2022-12-31 08:49:42,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:42,578 INFO:     Epoch: 91
2022-12-31 08:49:44,217 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5178389479716619, 'Total loss': 0.5178389479716619} | train loss {'Reaction outcome loss': 0.11401795130895472, 'Total loss': 0.11401795130895472}
2022-12-31 08:49:44,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:44,217 INFO:     Epoch: 92
2022-12-31 08:49:45,836 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.497882591933012, 'Total loss': 0.497882591933012} | train loss {'Reaction outcome loss': 0.11772048017615284, 'Total loss': 0.11772048017615284}
2022-12-31 08:49:45,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:45,837 INFO:     Epoch: 93
2022-12-31 08:49:47,462 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5213624437650045, 'Total loss': 0.5213624437650045} | train loss {'Reaction outcome loss': 0.12079485936177767, 'Total loss': 0.12079485936177767}
2022-12-31 08:49:47,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:47,463 INFO:     Epoch: 94
2022-12-31 08:49:49,129 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5333900153636932, 'Total loss': 0.5333900153636932} | train loss {'Reaction outcome loss': 0.1150006962484522, 'Total loss': 0.1150006962484522}
2022-12-31 08:49:49,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:49,129 INFO:     Epoch: 95
2022-12-31 08:49:50,787 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49325077831745145, 'Total loss': 0.49325077831745145} | train loss {'Reaction outcome loss': 0.1136479541081061, 'Total loss': 0.1136479541081061}
2022-12-31 08:49:50,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:50,787 INFO:     Epoch: 96
2022-12-31 08:49:52,407 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4915724356969198, 'Total loss': 0.4915724356969198} | train loss {'Reaction outcome loss': 0.11905740827510287, 'Total loss': 0.11905740827510287}
2022-12-31 08:49:52,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:52,408 INFO:     Epoch: 97
2022-12-31 08:49:54,029 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5017970432837804, 'Total loss': 0.5017970432837804} | train loss {'Reaction outcome loss': 0.11616231583559798, 'Total loss': 0.11616231583559798}
2022-12-31 08:49:54,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:54,029 INFO:     Epoch: 98
2022-12-31 08:49:55,687 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4863133688767751, 'Total loss': 0.4863133688767751} | train loss {'Reaction outcome loss': 0.12134018359245188, 'Total loss': 0.12134018359245188}
2022-12-31 08:49:55,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:55,687 INFO:     Epoch: 99
2022-12-31 08:49:57,356 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5156316131353378, 'Total loss': 0.5156316131353378} | train loss {'Reaction outcome loss': 0.11523589291962852, 'Total loss': 0.11523589291962852}
2022-12-31 08:49:57,356 INFO:     Best model found after epoch 9 of 100.
2022-12-31 08:49:57,356 INFO:   Done with stage: TRAINING
2022-12-31 08:49:57,356 INFO:   Starting stage: EVALUATION
2022-12-31 08:49:57,482 INFO:   Done with stage: EVALUATION
2022-12-31 08:49:57,482 INFO:   Leaving out SEQ value Fold_5
2022-12-31 08:49:57,494 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 08:49:57,494 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:49:58,144 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:49:58,144 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:49:58,210 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:49:58,211 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:49:58,211 INFO:     No hyperparam tuning for this model
2022-12-31 08:49:58,211 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:49:58,211 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:49:58,211 INFO:     None feature selector for col prot
2022-12-31 08:49:58,212 INFO:     None feature selector for col prot
2022-12-31 08:49:58,212 INFO:     None feature selector for col prot
2022-12-31 08:49:58,212 INFO:     None feature selector for col chem
2022-12-31 08:49:58,212 INFO:     None feature selector for col chem
2022-12-31 08:49:58,212 INFO:     None feature selector for col chem
2022-12-31 08:49:58,212 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:49:58,213 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:49:58,214 INFO:     Number of params in model 224011
2022-12-31 08:49:58,218 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:49:58,218 INFO:   Starting stage: TRAINING
2022-12-31 08:49:58,262 INFO:     Val loss before train {'Reaction outcome loss': 0.9032873074213664, 'Total loss': 0.9032873074213664}
2022-12-31 08:49:58,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:58,262 INFO:     Epoch: 0
2022-12-31 08:49:59,866 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5699568430582682, 'Total loss': 0.5699568430582682} | train loss {'Reaction outcome loss': 0.777027057035126, 'Total loss': 0.777027057035126}
2022-12-31 08:49:59,866 INFO:     Found new best model at epoch 0
2022-12-31 08:49:59,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:49:59,867 INFO:     Epoch: 1
2022-12-31 08:50:01,473 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4918596347173055, 'Total loss': 0.4918596347173055} | train loss {'Reaction outcome loss': 0.5098559424607423, 'Total loss': 0.5098559424607423}
2022-12-31 08:50:01,473 INFO:     Found new best model at epoch 1
2022-12-31 08:50:01,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:01,474 INFO:     Epoch: 2
2022-12-31 08:50:03,077 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4458440899848938, 'Total loss': 0.4458440899848938} | train loss {'Reaction outcome loss': 0.44345766757309, 'Total loss': 0.44345766757309}
2022-12-31 08:50:03,077 INFO:     Found new best model at epoch 2
2022-12-31 08:50:03,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:03,079 INFO:     Epoch: 3
2022-12-31 08:50:04,686 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4257662524779638, 'Total loss': 0.4257662524779638} | train loss {'Reaction outcome loss': 0.40058617098053007, 'Total loss': 0.40058617098053007}
2022-12-31 08:50:04,687 INFO:     Found new best model at epoch 3
2022-12-31 08:50:04,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:04,688 INFO:     Epoch: 4
2022-12-31 08:50:06,295 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4158558328946432, 'Total loss': 0.4158558328946432} | train loss {'Reaction outcome loss': 0.37618129798313127, 'Total loss': 0.37618129798313127}
2022-12-31 08:50:06,295 INFO:     Found new best model at epoch 4
2022-12-31 08:50:06,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:06,296 INFO:     Epoch: 5
2022-12-31 08:50:07,904 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.407314399878184, 'Total loss': 0.407314399878184} | train loss {'Reaction outcome loss': 0.35098889238969255, 'Total loss': 0.35098889238969255}
2022-12-31 08:50:07,904 INFO:     Found new best model at epoch 5
2022-12-31 08:50:07,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:07,905 INFO:     Epoch: 6
2022-12-31 08:50:09,520 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40254494349161785, 'Total loss': 0.40254494349161785} | train loss {'Reaction outcome loss': 0.3293251300869632, 'Total loss': 0.3293251300869632}
2022-12-31 08:50:09,520 INFO:     Found new best model at epoch 6
2022-12-31 08:50:09,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:09,521 INFO:     Epoch: 7
2022-12-31 08:50:11,137 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41798268258571625, 'Total loss': 0.41798268258571625} | train loss {'Reaction outcome loss': 0.31152986199425087, 'Total loss': 0.31152986199425087}
2022-12-31 08:50:11,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:11,138 INFO:     Epoch: 8
2022-12-31 08:50:12,754 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40502638220787046, 'Total loss': 0.40502638220787046} | train loss {'Reaction outcome loss': 0.29701222928009763, 'Total loss': 0.29701222928009763}
2022-12-31 08:50:12,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:12,754 INFO:     Epoch: 9
2022-12-31 08:50:14,362 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40898683071136477, 'Total loss': 0.40898683071136477} | train loss {'Reaction outcome loss': 0.28233610625195243, 'Total loss': 0.28233610625195243}
2022-12-31 08:50:14,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:14,363 INFO:     Epoch: 10
2022-12-31 08:50:16,014 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4108791023492813, 'Total loss': 0.4108791023492813} | train loss {'Reaction outcome loss': 0.2692329189502192, 'Total loss': 0.2692329189502192}
2022-12-31 08:50:16,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:16,014 INFO:     Epoch: 11
2022-12-31 08:50:17,628 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.437201980749766, 'Total loss': 0.437201980749766} | train loss {'Reaction outcome loss': 0.25971857277526905, 'Total loss': 0.25971857277526905}
2022-12-31 08:50:17,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:17,628 INFO:     Epoch: 12
2022-12-31 08:50:19,246 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40088162819544476, 'Total loss': 0.40088162819544476} | train loss {'Reaction outcome loss': 0.24885429898072986, 'Total loss': 0.24885429898072986}
2022-12-31 08:50:19,246 INFO:     Found new best model at epoch 12
2022-12-31 08:50:19,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:19,247 INFO:     Epoch: 13
2022-12-31 08:50:20,863 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43559428453445437, 'Total loss': 0.43559428453445437} | train loss {'Reaction outcome loss': 0.24081559643747596, 'Total loss': 0.24081559643747596}
2022-12-31 08:50:20,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:20,864 INFO:     Epoch: 14
2022-12-31 08:50:22,470 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43971508741378784, 'Total loss': 0.43971508741378784} | train loss {'Reaction outcome loss': 0.23021582354975006, 'Total loss': 0.23021582354975006}
2022-12-31 08:50:22,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:22,470 INFO:     Epoch: 15
2022-12-31 08:50:24,086 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39384218712026875, 'Total loss': 0.39384218712026875} | train loss {'Reaction outcome loss': 0.22809499114697432, 'Total loss': 0.22809499114697432}
2022-12-31 08:50:24,086 INFO:     Found new best model at epoch 15
2022-12-31 08:50:24,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:24,087 INFO:     Epoch: 16
2022-12-31 08:50:25,690 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4067803213993708, 'Total loss': 0.4067803213993708} | train loss {'Reaction outcome loss': 0.2191537302191349, 'Total loss': 0.2191537302191349}
2022-12-31 08:50:25,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:25,690 INFO:     Epoch: 17
2022-12-31 08:50:27,308 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41088561018308006, 'Total loss': 0.41088561018308006} | train loss {'Reaction outcome loss': 0.21335187453749407, 'Total loss': 0.21335187453749407}
2022-12-31 08:50:27,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:27,309 INFO:     Epoch: 18
2022-12-31 08:50:28,928 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4143568108479182, 'Total loss': 0.4143568108479182} | train loss {'Reaction outcome loss': 0.20846626772987145, 'Total loss': 0.20846626772987145}
2022-12-31 08:50:28,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:28,929 INFO:     Epoch: 19
2022-12-31 08:50:30,541 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42578171491622924, 'Total loss': 0.42578171491622924} | train loss {'Reaction outcome loss': 0.19937786194461868, 'Total loss': 0.19937786194461868}
2022-12-31 08:50:30,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:30,541 INFO:     Epoch: 20
2022-12-31 08:50:32,142 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43171117504437767, 'Total loss': 0.43171117504437767} | train loss {'Reaction outcome loss': 0.19201127425461573, 'Total loss': 0.19201127425461573}
2022-12-31 08:50:32,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:32,142 INFO:     Epoch: 21
2022-12-31 08:50:33,795 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40081046024958294, 'Total loss': 0.40081046024958294} | train loss {'Reaction outcome loss': 0.19022026331415468, 'Total loss': 0.19022026331415468}
2022-12-31 08:50:33,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:33,795 INFO:     Epoch: 22
2022-12-31 08:50:35,401 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4449803123871485, 'Total loss': 0.4449803123871485} | train loss {'Reaction outcome loss': 0.18642021685050134, 'Total loss': 0.18642021685050134}
2022-12-31 08:50:35,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:35,401 INFO:     Epoch: 23
2022-12-31 08:50:37,053 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39919434984525043, 'Total loss': 0.39919434984525043} | train loss {'Reaction outcome loss': 0.1788462294252032, 'Total loss': 0.1788462294252032}
2022-12-31 08:50:37,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:37,053 INFO:     Epoch: 24
2022-12-31 08:50:38,659 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46156896551450094, 'Total loss': 0.46156896551450094} | train loss {'Reaction outcome loss': 0.18065147392152653, 'Total loss': 0.18065147392152653}
2022-12-31 08:50:38,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:38,659 INFO:     Epoch: 25
2022-12-31 08:50:40,299 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4218900618453821, 'Total loss': 0.4218900618453821} | train loss {'Reaction outcome loss': 0.1748912616898, 'Total loss': 0.1748912616898}
2022-12-31 08:50:40,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:40,299 INFO:     Epoch: 26
2022-12-31 08:50:41,907 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44152799050013225, 'Total loss': 0.44152799050013225} | train loss {'Reaction outcome loss': 0.1739925647521541, 'Total loss': 0.1739925647521541}
2022-12-31 08:50:41,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:41,907 INFO:     Epoch: 27
2022-12-31 08:50:43,552 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43031532764434816, 'Total loss': 0.43031532764434816} | train loss {'Reaction outcome loss': 0.17062292324827752, 'Total loss': 0.17062292324827752}
2022-12-31 08:50:43,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:43,552 INFO:     Epoch: 28
2022-12-31 08:50:45,149 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4084793041149775, 'Total loss': 0.4084793041149775} | train loss {'Reaction outcome loss': 0.1627456010421262, 'Total loss': 0.1627456010421262}
2022-12-31 08:50:45,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:45,149 INFO:     Epoch: 29
2022-12-31 08:50:46,802 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44472179412841795, 'Total loss': 0.44472179412841795} | train loss {'Reaction outcome loss': 0.1650732749066975, 'Total loss': 0.1650732749066975}
2022-12-31 08:50:46,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:46,802 INFO:     Epoch: 30
2022-12-31 08:50:48,401 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43680606683095297, 'Total loss': 0.43680606683095297} | train loss {'Reaction outcome loss': 0.160898204828293, 'Total loss': 0.160898204828293}
2022-12-31 08:50:48,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:48,401 INFO:     Epoch: 31
2022-12-31 08:50:50,020 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4214683949947357, 'Total loss': 0.4214683949947357} | train loss {'Reaction outcome loss': 0.15846108144189971, 'Total loss': 0.15846108144189971}
2022-12-31 08:50:50,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:50,021 INFO:     Epoch: 32
2022-12-31 08:50:51,642 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44560324649016064, 'Total loss': 0.44560324649016064} | train loss {'Reaction outcome loss': 0.15813708760143413, 'Total loss': 0.15813708760143413}
2022-12-31 08:50:51,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:51,643 INFO:     Epoch: 33
2022-12-31 08:50:53,264 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41525704264640806, 'Total loss': 0.41525704264640806} | train loss {'Reaction outcome loss': 0.15195337757400243, 'Total loss': 0.15195337757400243}
2022-12-31 08:50:53,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:53,265 INFO:     Epoch: 34
2022-12-31 08:50:54,917 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4158940136432648, 'Total loss': 0.4158940136432648} | train loss {'Reaction outcome loss': 0.15091644618558242, 'Total loss': 0.15091644618558242}
2022-12-31 08:50:54,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:54,918 INFO:     Epoch: 35
2022-12-31 08:50:56,571 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4024592916170756, 'Total loss': 0.4024592916170756} | train loss {'Reaction outcome loss': 0.1490102963467693, 'Total loss': 0.1490102963467693}
2022-12-31 08:50:56,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:56,571 INFO:     Epoch: 36
2022-12-31 08:50:58,173 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.436228475968043, 'Total loss': 0.436228475968043} | train loss {'Reaction outcome loss': 0.1516818206988438, 'Total loss': 0.1516818206988438}
2022-12-31 08:50:58,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:58,174 INFO:     Epoch: 37
2022-12-31 08:50:59,783 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4092545285820961, 'Total loss': 0.4092545285820961} | train loss {'Reaction outcome loss': 0.1466393188342289, 'Total loss': 0.1466393188342289}
2022-12-31 08:50:59,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:50:59,784 INFO:     Epoch: 38
2022-12-31 08:51:01,437 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40732048749923705, 'Total loss': 0.40732048749923705} | train loss {'Reaction outcome loss': 0.1447809578402199, 'Total loss': 0.1447809578402199}
2022-12-31 08:51:01,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:01,437 INFO:     Epoch: 39
2022-12-31 08:51:03,046 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4651325156291326, 'Total loss': 0.4651325156291326} | train loss {'Reaction outcome loss': 0.14541406039638025, 'Total loss': 0.14541406039638025}
2022-12-31 08:51:03,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:03,047 INFO:     Epoch: 40
2022-12-31 08:51:04,699 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4605305910110474, 'Total loss': 0.4605305910110474} | train loss {'Reaction outcome loss': 0.1418938952171835, 'Total loss': 0.1418938952171835}
2022-12-31 08:51:04,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:04,699 INFO:     Epoch: 41
2022-12-31 08:51:06,352 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43844296112656594, 'Total loss': 0.43844296112656594} | train loss {'Reaction outcome loss': 0.14221569662573783, 'Total loss': 0.14221569662573783}
2022-12-31 08:51:06,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:06,352 INFO:     Epoch: 42
2022-12-31 08:51:07,955 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41350453396638237, 'Total loss': 0.41350453396638237} | train loss {'Reaction outcome loss': 0.13942162321717308, 'Total loss': 0.13942162321717308}
2022-12-31 08:51:07,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:07,956 INFO:     Epoch: 43
2022-12-31 08:51:09,569 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42443403402964275, 'Total loss': 0.42443403402964275} | train loss {'Reaction outcome loss': 0.13903825177410006, 'Total loss': 0.13903825177410006}
2022-12-31 08:51:09,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:09,569 INFO:     Epoch: 44
2022-12-31 08:51:11,178 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.423334147532781, 'Total loss': 0.423334147532781} | train loss {'Reaction outcome loss': 0.14317015977406425, 'Total loss': 0.14317015977406425}
2022-12-31 08:51:11,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:11,179 INFO:     Epoch: 45
2022-12-31 08:51:12,791 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3903353810310364, 'Total loss': 0.3903353810310364} | train loss {'Reaction outcome loss': 0.13744567275679515, 'Total loss': 0.13744567275679515}
2022-12-31 08:51:12,792 INFO:     Found new best model at epoch 45
2022-12-31 08:51:12,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:12,793 INFO:     Epoch: 46
2022-12-31 08:51:14,404 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4284523636102676, 'Total loss': 0.4284523636102676} | train loss {'Reaction outcome loss': 0.13399258569005307, 'Total loss': 0.13399258569005307}
2022-12-31 08:51:14,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:14,404 INFO:     Epoch: 47
2022-12-31 08:51:16,017 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4471667319536209, 'Total loss': 0.4471667319536209} | train loss {'Reaction outcome loss': 0.13985013543546582, 'Total loss': 0.13985013543546582}
2022-12-31 08:51:16,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:16,017 INFO:     Epoch: 48
2022-12-31 08:51:17,621 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42026830911636354, 'Total loss': 0.42026830911636354} | train loss {'Reaction outcome loss': 0.1346989031354251, 'Total loss': 0.1346989031354251}
2022-12-31 08:51:17,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:17,621 INFO:     Epoch: 49
2022-12-31 08:51:19,239 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.409768537680308, 'Total loss': 0.409768537680308} | train loss {'Reaction outcome loss': 0.13232414015181307, 'Total loss': 0.13232414015181307}
2022-12-31 08:51:19,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:19,239 INFO:     Epoch: 50
2022-12-31 08:51:20,843 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4325167749232302, 'Total loss': 0.4325167749232302} | train loss {'Reaction outcome loss': 0.13155545981390143, 'Total loss': 0.13155545981390143}
2022-12-31 08:51:20,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:20,843 INFO:     Epoch: 51
2022-12-31 08:51:22,461 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42134393254915875, 'Total loss': 0.42134393254915875} | train loss {'Reaction outcome loss': 0.13446593511999197, 'Total loss': 0.13446593511999197}
2022-12-31 08:51:22,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:22,462 INFO:     Epoch: 52
2022-12-31 08:51:24,077 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4378907918930054, 'Total loss': 0.4378907918930054} | train loss {'Reaction outcome loss': 0.13526271804351442, 'Total loss': 0.13526271804351442}
2022-12-31 08:51:24,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:24,078 INFO:     Epoch: 53
2022-12-31 08:51:25,685 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4585641344388326, 'Total loss': 0.4585641344388326} | train loss {'Reaction outcome loss': 0.1275579879743584, 'Total loss': 0.1275579879743584}
2022-12-31 08:51:25,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:25,686 INFO:     Epoch: 54
2022-12-31 08:51:27,302 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4737275421619415, 'Total loss': 0.4737275421619415} | train loss {'Reaction outcome loss': 0.13052374543282239, 'Total loss': 0.13052374543282239}
2022-12-31 08:51:27,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:27,302 INFO:     Epoch: 55
2022-12-31 08:51:28,917 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43875146508216856, 'Total loss': 0.43875146508216856} | train loss {'Reaction outcome loss': 0.1262768979760458, 'Total loss': 0.1262768979760458}
2022-12-31 08:51:28,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:28,918 INFO:     Epoch: 56
2022-12-31 08:51:30,557 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4381832579771678, 'Total loss': 0.4381832579771678} | train loss {'Reaction outcome loss': 0.13221025955863297, 'Total loss': 0.13221025955863297}
2022-12-31 08:51:30,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:30,557 INFO:     Epoch: 57
2022-12-31 08:51:32,210 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43154034664233526, 'Total loss': 0.43154034664233526} | train loss {'Reaction outcome loss': 0.12438426914550092, 'Total loss': 0.12438426914550092}
2022-12-31 08:51:32,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:32,210 INFO:     Epoch: 58
2022-12-31 08:51:33,863 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45912029842535657, 'Total loss': 0.45912029842535657} | train loss {'Reaction outcome loss': 0.12494683442433385, 'Total loss': 0.12494683442433385}
2022-12-31 08:51:33,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:33,863 INFO:     Epoch: 59
2022-12-31 08:51:35,479 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4130905946095785, 'Total loss': 0.4130905946095785} | train loss {'Reaction outcome loss': 0.12739251500988094, 'Total loss': 0.12739251500988094}
2022-12-31 08:51:35,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:35,480 INFO:     Epoch: 60
2022-12-31 08:51:37,133 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43220068415006, 'Total loss': 0.43220068415006} | train loss {'Reaction outcome loss': 0.1321125182486309, 'Total loss': 0.1321125182486309}
2022-12-31 08:51:37,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:37,133 INFO:     Epoch: 61
2022-12-31 08:51:38,741 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40415101250012714, 'Total loss': 0.40415101250012714} | train loss {'Reaction outcome loss': 0.1257033941538216, 'Total loss': 0.1257033941538216}
2022-12-31 08:51:38,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:38,741 INFO:     Epoch: 62
2022-12-31 08:51:40,353 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4409532537062963, 'Total loss': 0.4409532537062963} | train loss {'Reaction outcome loss': 0.12259583000814284, 'Total loss': 0.12259583000814284}
2022-12-31 08:51:40,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:40,353 INFO:     Epoch: 63
2022-12-31 08:51:42,005 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47828031877676647, 'Total loss': 0.47828031877676647} | train loss {'Reaction outcome loss': 0.11847957879063557, 'Total loss': 0.11847957879063557}
2022-12-31 08:51:42,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:42,006 INFO:     Epoch: 64
2022-12-31 08:51:43,613 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4757397552331289, 'Total loss': 0.4757397552331289} | train loss {'Reaction outcome loss': 0.12715415350657744, 'Total loss': 0.12715415350657744}
2022-12-31 08:51:43,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:43,613 INFO:     Epoch: 65
2022-12-31 08:51:45,256 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44092554847399396, 'Total loss': 0.44092554847399396} | train loss {'Reaction outcome loss': 0.12310513717047598, 'Total loss': 0.12310513717047598}
2022-12-31 08:51:45,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:45,256 INFO:     Epoch: 66
2022-12-31 08:51:46,861 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46504050890604653, 'Total loss': 0.46504050890604653} | train loss {'Reaction outcome loss': 0.11990170239090213, 'Total loss': 0.11990170239090213}
2022-12-31 08:51:46,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:46,861 INFO:     Epoch: 67
2022-12-31 08:51:48,469 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41105496088663734, 'Total loss': 0.41105496088663734} | train loss {'Reaction outcome loss': 0.12048422491490623, 'Total loss': 0.12048422491490623}
2022-12-31 08:51:48,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:48,470 INFO:     Epoch: 68
2022-12-31 08:51:50,122 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4605163683493932, 'Total loss': 0.4605163683493932} | train loss {'Reaction outcome loss': 0.12152170984033686, 'Total loss': 0.12152170984033686}
2022-12-31 08:51:50,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:50,123 INFO:     Epoch: 69
2022-12-31 08:51:51,745 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47754624038934707, 'Total loss': 0.47754624038934707} | train loss {'Reaction outcome loss': 0.12308719491987169, 'Total loss': 0.12308719491987169}
2022-12-31 08:51:51,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:51,745 INFO:     Epoch: 70
2022-12-31 08:51:53,365 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44652101000150046, 'Total loss': 0.44652101000150046} | train loss {'Reaction outcome loss': 0.12106457410251083, 'Total loss': 0.12106457410251083}
2022-12-31 08:51:53,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:53,366 INFO:     Epoch: 71
2022-12-31 08:51:54,974 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43838048179944356, 'Total loss': 0.43838048179944356} | train loss {'Reaction outcome loss': 0.12469110586408554, 'Total loss': 0.12469110586408554}
2022-12-31 08:51:54,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:54,974 INFO:     Epoch: 72
2022-12-31 08:51:56,615 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4428802266716957, 'Total loss': 0.4428802266716957} | train loss {'Reaction outcome loss': 0.11838811324453866, 'Total loss': 0.11838811324453866}
2022-12-31 08:51:56,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:56,615 INFO:     Epoch: 73
2022-12-31 08:51:58,228 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47848712702592217, 'Total loss': 0.47848712702592217} | train loss {'Reaction outcome loss': 0.11851748698696929, 'Total loss': 0.11851748698696929}
2022-12-31 08:51:58,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:58,228 INFO:     Epoch: 74
2022-12-31 08:51:59,843 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4705447554588318, 'Total loss': 0.4705447554588318} | train loss {'Reaction outcome loss': 0.11531501771018833, 'Total loss': 0.11531501771018833}
2022-12-31 08:51:59,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:51:59,844 INFO:     Epoch: 75
2022-12-31 08:52:01,456 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4272506142112737, 'Total loss': 0.4272506142112737} | train loss {'Reaction outcome loss': 0.12104045865499843, 'Total loss': 0.12104045865499843}
2022-12-31 08:52:01,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:01,456 INFO:     Epoch: 76
2022-12-31 08:52:03,061 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48238452871640525, 'Total loss': 0.48238452871640525} | train loss {'Reaction outcome loss': 0.11698347103890766, 'Total loss': 0.11698347103890766}
2022-12-31 08:52:03,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:03,062 INFO:     Epoch: 77
2022-12-31 08:52:04,675 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4772984633843104, 'Total loss': 0.4772984633843104} | train loss {'Reaction outcome loss': 0.11452187465021156, 'Total loss': 0.11452187465021156}
2022-12-31 08:52:04,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:04,676 INFO:     Epoch: 78
2022-12-31 08:52:06,286 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43588214218616483, 'Total loss': 0.43588214218616483} | train loss {'Reaction outcome loss': 0.11692257681147733, 'Total loss': 0.11692257681147733}
2022-12-31 08:52:06,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:06,286 INFO:     Epoch: 79
2022-12-31 08:52:07,908 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44051772852738696, 'Total loss': 0.44051772852738696} | train loss {'Reaction outcome loss': 0.12077216376095032, 'Total loss': 0.12077216376095032}
2022-12-31 08:52:07,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:07,909 INFO:     Epoch: 80
2022-12-31 08:52:09,539 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.407357428347071, 'Total loss': 0.407357428347071} | train loss {'Reaction outcome loss': 0.12085178256524305, 'Total loss': 0.12085178256524305}
2022-12-31 08:52:09,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:09,539 INFO:     Epoch: 81
2022-12-31 08:52:11,154 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45834316611289977, 'Total loss': 0.45834316611289977} | train loss {'Reaction outcome loss': 0.11567074511995552, 'Total loss': 0.11567074511995552}
2022-12-31 08:52:11,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:11,154 INFO:     Epoch: 82
2022-12-31 08:52:12,792 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48785515228907267, 'Total loss': 0.48785515228907267} | train loss {'Reaction outcome loss': 0.11306508365902967, 'Total loss': 0.11306508365902967}
2022-12-31 08:52:12,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:12,793 INFO:     Epoch: 83
2022-12-31 08:52:14,405 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4746380136658748, 'Total loss': 0.4746380136658748} | train loss {'Reaction outcome loss': 0.1139945008564251, 'Total loss': 0.1139945008564251}
2022-12-31 08:52:14,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:14,405 INFO:     Epoch: 84
2022-12-31 08:52:16,005 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4442230612039566, 'Total loss': 0.4442230612039566} | train loss {'Reaction outcome loss': 0.11625468546021593, 'Total loss': 0.11625468546021593}
2022-12-31 08:52:16,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:16,005 INFO:     Epoch: 85
2022-12-31 08:52:17,712 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4615458945433299, 'Total loss': 0.4615458945433299} | train loss {'Reaction outcome loss': 0.11427950839695596, 'Total loss': 0.11427950839695596}
2022-12-31 08:52:17,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:17,713 INFO:     Epoch: 86
2022-12-31 08:52:19,418 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43189604207873344, 'Total loss': 0.43189604207873344} | train loss {'Reaction outcome loss': 0.11408166262919396, 'Total loss': 0.11408166262919396}
2022-12-31 08:52:19,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:19,419 INFO:     Epoch: 87
2022-12-31 08:52:21,077 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42443334460258486, 'Total loss': 0.42443334460258486} | train loss {'Reaction outcome loss': 0.11227579105026803, 'Total loss': 0.11227579105026803}
2022-12-31 08:52:21,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:21,077 INFO:     Epoch: 88
2022-12-31 08:52:22,730 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46102092166741687, 'Total loss': 0.46102092166741687} | train loss {'Reaction outcome loss': 0.11400117395856982, 'Total loss': 0.11400117395856982}
2022-12-31 08:52:22,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:22,730 INFO:     Epoch: 89
2022-12-31 08:52:24,371 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4286883041262627, 'Total loss': 0.4286883041262627} | train loss {'Reaction outcome loss': 0.11189510759108964, 'Total loss': 0.11189510759108964}
2022-12-31 08:52:24,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:24,372 INFO:     Epoch: 90
2022-12-31 08:52:25,994 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48159102300802864, 'Total loss': 0.48159102300802864} | train loss {'Reaction outcome loss': 0.11107249549389511, 'Total loss': 0.11107249549389511}
2022-12-31 08:52:25,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:25,994 INFO:     Epoch: 91
2022-12-31 08:52:27,613 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5132952094078064, 'Total loss': 0.5132952094078064} | train loss {'Reaction outcome loss': 0.115049882494525, 'Total loss': 0.115049882494525}
2022-12-31 08:52:27,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:27,613 INFO:     Epoch: 92
2022-12-31 08:52:29,234 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5070154299338658, 'Total loss': 0.5070154299338658} | train loss {'Reaction outcome loss': 0.11236002182343253, 'Total loss': 0.11236002182343253}
2022-12-31 08:52:29,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:29,235 INFO:     Epoch: 93
2022-12-31 08:52:30,841 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46669053137302396, 'Total loss': 0.46669053137302396} | train loss {'Reaction outcome loss': 0.110167429427256, 'Total loss': 0.110167429427256}
2022-12-31 08:52:30,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:30,842 INFO:     Epoch: 94
2022-12-31 08:52:32,460 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4989624400933584, 'Total loss': 0.4989624400933584} | train loss {'Reaction outcome loss': 0.11120313891535964, 'Total loss': 0.11120313891535964}
2022-12-31 08:52:32,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:32,460 INFO:     Epoch: 95
2022-12-31 08:52:34,083 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4228182425101598, 'Total loss': 0.4228182425101598} | train loss {'Reaction outcome loss': 0.10800089005017177, 'Total loss': 0.10800089005017177}
2022-12-31 08:52:34,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:34,084 INFO:     Epoch: 96
2022-12-31 08:52:35,737 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4801536023616791, 'Total loss': 0.4801536023616791} | train loss {'Reaction outcome loss': 0.11173821214151426, 'Total loss': 0.11173821214151426}
2022-12-31 08:52:35,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:35,737 INFO:     Epoch: 97
2022-12-31 08:52:37,390 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4703971932331721, 'Total loss': 0.4703971932331721} | train loss {'Reaction outcome loss': 0.11051544512156397, 'Total loss': 0.11051544512156397}
2022-12-31 08:52:37,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:37,391 INFO:     Epoch: 98
2022-12-31 08:52:39,028 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4598186175028483, 'Total loss': 0.4598186175028483} | train loss {'Reaction outcome loss': 0.10742161936045073, 'Total loss': 0.10742161936045073}
2022-12-31 08:52:39,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:39,028 INFO:     Epoch: 99
2022-12-31 08:52:40,682 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47150840361913043, 'Total loss': 0.47150840361913043} | train loss {'Reaction outcome loss': 0.10841113382637718, 'Total loss': 0.10841113382637718}
2022-12-31 08:52:40,682 INFO:     Best model found after epoch 46 of 100.
2022-12-31 08:52:40,682 INFO:   Done with stage: TRAINING
2022-12-31 08:52:40,682 INFO:   Starting stage: EVALUATION
2022-12-31 08:52:40,820 INFO:   Done with stage: EVALUATION
2022-12-31 08:52:40,820 INFO:   Leaving out SEQ value Fold_6
2022-12-31 08:52:40,833 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 08:52:40,833 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:52:41,474 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:52:41,474 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:52:41,540 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:52:41,541 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:52:41,541 INFO:     No hyperparam tuning for this model
2022-12-31 08:52:41,541 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:52:41,541 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:52:41,541 INFO:     None feature selector for col prot
2022-12-31 08:52:41,542 INFO:     None feature selector for col prot
2022-12-31 08:52:41,542 INFO:     None feature selector for col prot
2022-12-31 08:52:41,542 INFO:     None feature selector for col chem
2022-12-31 08:52:41,542 INFO:     None feature selector for col chem
2022-12-31 08:52:41,542 INFO:     None feature selector for col chem
2022-12-31 08:52:41,542 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:52:41,542 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:52:41,544 INFO:     Number of params in model 224011
2022-12-31 08:52:41,548 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:52:41,548 INFO:   Starting stage: TRAINING
2022-12-31 08:52:41,592 INFO:     Val loss before train {'Reaction outcome loss': 1.1079163153966267, 'Total loss': 1.1079163153966267}
2022-12-31 08:52:41,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:41,593 INFO:     Epoch: 0
2022-12-31 08:52:43,196 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6077379922072093, 'Total loss': 0.6077379922072093} | train loss {'Reaction outcome loss': 0.7715479596193894, 'Total loss': 0.7715479596193894}
2022-12-31 08:52:43,197 INFO:     Found new best model at epoch 0
2022-12-31 08:52:43,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:43,198 INFO:     Epoch: 1
2022-12-31 08:52:44,799 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5474395672480266, 'Total loss': 0.5474395672480266} | train loss {'Reaction outcome loss': 0.5112560126698498, 'Total loss': 0.5112560126698498}
2022-12-31 08:52:44,799 INFO:     Found new best model at epoch 1
2022-12-31 08:52:44,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:44,800 INFO:     Epoch: 2
2022-12-31 08:52:46,403 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5063679317633311, 'Total loss': 0.5063679317633311} | train loss {'Reaction outcome loss': 0.44749925823220404, 'Total loss': 0.44749925823220404}
2022-12-31 08:52:46,403 INFO:     Found new best model at epoch 2
2022-12-31 08:52:46,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:46,404 INFO:     Epoch: 3
2022-12-31 08:52:48,013 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48337352474530537, 'Total loss': 0.48337352474530537} | train loss {'Reaction outcome loss': 0.4066690058607758, 'Total loss': 0.4066690058607758}
2022-12-31 08:52:48,013 INFO:     Found new best model at epoch 3
2022-12-31 08:52:48,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:48,014 INFO:     Epoch: 4
2022-12-31 08:52:49,602 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4889661232630412, 'Total loss': 0.4889661232630412} | train loss {'Reaction outcome loss': 0.3774766125767441, 'Total loss': 0.3774766125767441}
2022-12-31 08:52:49,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:49,602 INFO:     Epoch: 5
2022-12-31 08:52:51,243 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45877820005019504, 'Total loss': 0.45877820005019504} | train loss {'Reaction outcome loss': 0.35516526421784483, 'Total loss': 0.35516526421784483}
2022-12-31 08:52:51,243 INFO:     Found new best model at epoch 5
2022-12-31 08:52:51,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:51,244 INFO:     Epoch: 6
2022-12-31 08:52:52,848 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4724756340185801, 'Total loss': 0.4724756340185801} | train loss {'Reaction outcome loss': 0.33158874934737065, 'Total loss': 0.33158874934737065}
2022-12-31 08:52:52,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:52,849 INFO:     Epoch: 7
2022-12-31 08:52:54,462 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4756615062554677, 'Total loss': 0.4756615062554677} | train loss {'Reaction outcome loss': 0.3111346638846747, 'Total loss': 0.3111346638846747}
2022-12-31 08:52:54,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:54,462 INFO:     Epoch: 8
2022-12-31 08:52:56,076 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46398075024286906, 'Total loss': 0.46398075024286906} | train loss {'Reaction outcome loss': 0.29642412660049866, 'Total loss': 0.29642412660049866}
2022-12-31 08:52:56,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:56,076 INFO:     Epoch: 9
2022-12-31 08:52:57,677 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.476650083065033, 'Total loss': 0.476650083065033} | train loss {'Reaction outcome loss': 0.28619031790957783, 'Total loss': 0.28619031790957783}
2022-12-31 08:52:57,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:57,677 INFO:     Epoch: 10
2022-12-31 08:52:59,323 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4523136387268702, 'Total loss': 0.4523136387268702} | train loss {'Reaction outcome loss': 0.2762350996635554, 'Total loss': 0.2762350996635554}
2022-12-31 08:52:59,325 INFO:     Found new best model at epoch 10
2022-12-31 08:52:59,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:52:59,326 INFO:     Epoch: 11
2022-12-31 08:53:00,935 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4819444388151169, 'Total loss': 0.4819444388151169} | train loss {'Reaction outcome loss': 0.2605670737204971, 'Total loss': 0.2605670737204971}
2022-12-31 08:53:00,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:00,935 INFO:     Epoch: 12
2022-12-31 08:53:02,582 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.468391024072965, 'Total loss': 0.468391024072965} | train loss {'Reaction outcome loss': 0.2515662617763102, 'Total loss': 0.2515662617763102}
2022-12-31 08:53:02,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:02,583 INFO:     Epoch: 13
2022-12-31 08:53:04,184 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4958747347195943, 'Total loss': 0.4958747347195943} | train loss {'Reaction outcome loss': 0.23995534750895622, 'Total loss': 0.23995534750895622}
2022-12-31 08:53:04,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:04,185 INFO:     Epoch: 14
2022-12-31 08:53:05,831 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5122030347585678, 'Total loss': 0.5122030347585678} | train loss {'Reaction outcome loss': 0.23009657252566282, 'Total loss': 0.23009657252566282}
2022-12-31 08:53:05,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:05,832 INFO:     Epoch: 15
2022-12-31 08:53:07,431 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5077902009089788, 'Total loss': 0.5077902009089788} | train loss {'Reaction outcome loss': 0.2221401932038667, 'Total loss': 0.2221401932038667}
2022-12-31 08:53:07,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:07,432 INFO:     Epoch: 16
2022-12-31 08:53:09,079 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4565716897447904, 'Total loss': 0.4565716897447904} | train loss {'Reaction outcome loss': 0.21771858347368328, 'Total loss': 0.21771858347368328}
2022-12-31 08:53:09,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:09,079 INFO:     Epoch: 17
2022-12-31 08:53:10,687 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43859768013159434, 'Total loss': 0.43859768013159434} | train loss {'Reaction outcome loss': 0.21025693773431875, 'Total loss': 0.21025693773431875}
2022-12-31 08:53:10,687 INFO:     Found new best model at epoch 17
2022-12-31 08:53:10,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:10,688 INFO:     Epoch: 18
2022-12-31 08:53:12,320 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46090826292832693, 'Total loss': 0.46090826292832693} | train loss {'Reaction outcome loss': 0.20285467754353534, 'Total loss': 0.20285467754353534}
2022-12-31 08:53:12,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:12,320 INFO:     Epoch: 19
2022-12-31 08:53:13,969 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4951012214024862, 'Total loss': 0.4951012214024862} | train loss {'Reaction outcome loss': 0.19820057322363277, 'Total loss': 0.19820057322363277}
2022-12-31 08:53:13,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:13,969 INFO:     Epoch: 20
2022-12-31 08:53:15,572 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.476017743597428, 'Total loss': 0.476017743597428} | train loss {'Reaction outcome loss': 0.19051766050331323, 'Total loss': 0.19051766050331323}
2022-12-31 08:53:15,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:15,572 INFO:     Epoch: 21
2022-12-31 08:53:17,219 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44971875548362733, 'Total loss': 0.44971875548362733} | train loss {'Reaction outcome loss': 0.18784007483295032, 'Total loss': 0.18784007483295032}
2022-12-31 08:53:17,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:17,220 INFO:     Epoch: 22
2022-12-31 08:53:18,857 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4900600790977478, 'Total loss': 0.4900600790977478} | train loss {'Reaction outcome loss': 0.18242067366074294, 'Total loss': 0.18242067366074294}
2022-12-31 08:53:18,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:18,858 INFO:     Epoch: 23
2022-12-31 08:53:20,478 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4777698258558909, 'Total loss': 0.4777698258558909} | train loss {'Reaction outcome loss': 0.1770924525506003, 'Total loss': 0.1770924525506003}
2022-12-31 08:53:20,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:20,478 INFO:     Epoch: 24
2022-12-31 08:53:22,102 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4628079182701185, 'Total loss': 0.4628079182701185} | train loss {'Reaction outcome loss': 0.17238672206949293, 'Total loss': 0.17238672206949293}
2022-12-31 08:53:22,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:22,102 INFO:     Epoch: 25
2022-12-31 08:53:23,729 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48270180424054465, 'Total loss': 0.48270180424054465} | train loss {'Reaction outcome loss': 0.17064893738990958, 'Total loss': 0.17064893738990958}
2022-12-31 08:53:23,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:23,729 INFO:     Epoch: 26
2022-12-31 08:53:25,339 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4785526474316915, 'Total loss': 0.4785526474316915} | train loss {'Reaction outcome loss': 0.16786736683517475, 'Total loss': 0.16786736683517475}
2022-12-31 08:53:25,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:25,339 INFO:     Epoch: 27
2022-12-31 08:53:26,957 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.516640205681324, 'Total loss': 0.516640205681324} | train loss {'Reaction outcome loss': 0.16256556024386004, 'Total loss': 0.16256556024386004}
2022-12-31 08:53:26,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:26,958 INFO:     Epoch: 28
2022-12-31 08:53:28,573 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47606011082728705, 'Total loss': 0.47606011082728705} | train loss {'Reaction outcome loss': 0.16392612999011746, 'Total loss': 0.16392612999011746}
2022-12-31 08:53:28,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:28,574 INFO:     Epoch: 29
2022-12-31 08:53:30,222 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4822348783413569, 'Total loss': 0.4822348783413569} | train loss {'Reaction outcome loss': 0.1641498962417245, 'Total loss': 0.1641498962417245}
2022-12-31 08:53:30,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:30,223 INFO:     Epoch: 30
2022-12-31 08:53:31,842 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5583222349484761, 'Total loss': 0.5583222349484761} | train loss {'Reaction outcome loss': 0.15503485682642176, 'Total loss': 0.15503485682642176}
2022-12-31 08:53:31,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:31,842 INFO:     Epoch: 31
2022-12-31 08:53:33,483 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4709781676530838, 'Total loss': 0.4709781676530838} | train loss {'Reaction outcome loss': 0.1545801497501195, 'Total loss': 0.1545801497501195}
2022-12-31 08:53:33,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:33,483 INFO:     Epoch: 32
2022-12-31 08:53:35,125 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5015122652053833, 'Total loss': 0.5015122652053833} | train loss {'Reaction outcome loss': 0.15328702538004724, 'Total loss': 0.15328702538004724}
2022-12-31 08:53:35,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:35,125 INFO:     Epoch: 33
2022-12-31 08:53:36,772 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49711260994275414, 'Total loss': 0.49711260994275414} | train loss {'Reaction outcome loss': 0.1497612392918749, 'Total loss': 0.1497612392918749}
2022-12-31 08:53:36,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:36,773 INFO:     Epoch: 34
2022-12-31 08:53:38,377 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5005308151245117, 'Total loss': 0.5005308151245117} | train loss {'Reaction outcome loss': 0.15099245508375403, 'Total loss': 0.15099245508375403}
2022-12-31 08:53:38,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:38,377 INFO:     Epoch: 35
2022-12-31 08:53:40,022 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48440639674663544, 'Total loss': 0.48440639674663544} | train loss {'Reaction outcome loss': 0.14690574819747454, 'Total loss': 0.14690574819747454}
2022-12-31 08:53:40,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:40,022 INFO:     Epoch: 36
2022-12-31 08:53:41,660 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49237433274586995, 'Total loss': 0.49237433274586995} | train loss {'Reaction outcome loss': 0.14671758395848256, 'Total loss': 0.14671758395848256}
2022-12-31 08:53:41,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:41,660 INFO:     Epoch: 37
2022-12-31 08:53:43,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4797755112250646, 'Total loss': 0.4797755112250646} | train loss {'Reaction outcome loss': 0.14408088822409018, 'Total loss': 0.14408088822409018}
2022-12-31 08:53:43,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:43,255 INFO:     Epoch: 38
2022-12-31 08:53:44,893 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5077126135428747, 'Total loss': 0.5077126135428747} | train loss {'Reaction outcome loss': 0.14061930579825854, 'Total loss': 0.14061930579825854}
2022-12-31 08:53:44,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:44,893 INFO:     Epoch: 39
2022-12-31 08:53:46,514 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48483384648958844, 'Total loss': 0.48483384648958844} | train loss {'Reaction outcome loss': 0.14153486775104707, 'Total loss': 0.14153486775104707}
2022-12-31 08:53:46,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:46,514 INFO:     Epoch: 40
2022-12-31 08:53:48,156 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48558526833852134, 'Total loss': 0.48558526833852134} | train loss {'Reaction outcome loss': 0.14030229293778812, 'Total loss': 0.14030229293778812}
2022-12-31 08:53:48,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:48,157 INFO:     Epoch: 41
2022-12-31 08:53:49,749 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4993063807487488, 'Total loss': 0.4993063807487488} | train loss {'Reaction outcome loss': 0.13792572563493644, 'Total loss': 0.13792572563493644}
2022-12-31 08:53:49,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:49,750 INFO:     Epoch: 42
2022-12-31 08:53:51,340 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4918936908245087, 'Total loss': 0.4918936908245087} | train loss {'Reaction outcome loss': 0.13337669217696366, 'Total loss': 0.13337669217696366}
2022-12-31 08:53:51,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:51,341 INFO:     Epoch: 43
2022-12-31 08:53:52,955 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4624132789671421, 'Total loss': 0.4624132789671421} | train loss {'Reaction outcome loss': 0.13587987802465593, 'Total loss': 0.13587987802465593}
2022-12-31 08:53:52,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:52,955 INFO:     Epoch: 44
2022-12-31 08:53:54,574 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.452327494819959, 'Total loss': 0.452327494819959} | train loss {'Reaction outcome loss': 0.12911646435081603, 'Total loss': 0.12911646435081603}
2022-12-31 08:53:54,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:54,574 INFO:     Epoch: 45
2022-12-31 08:53:56,189 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4813600560029348, 'Total loss': 0.4813600560029348} | train loss {'Reaction outcome loss': 0.12983330880759128, 'Total loss': 0.12983330880759128}
2022-12-31 08:53:56,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:56,189 INFO:     Epoch: 46
2022-12-31 08:53:57,796 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5027197351058325, 'Total loss': 0.5027197351058325} | train loss {'Reaction outcome loss': 0.13260060291218778, 'Total loss': 0.13260060291218778}
2022-12-31 08:53:57,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:57,797 INFO:     Epoch: 47
2022-12-31 08:53:59,444 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5344174067179362, 'Total loss': 0.5344174067179362} | train loss {'Reaction outcome loss': 0.1341456546867778, 'Total loss': 0.1341456546867778}
2022-12-31 08:53:59,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:53:59,444 INFO:     Epoch: 48
2022-12-31 08:54:01,083 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47298850292960803, 'Total loss': 0.47298850292960803} | train loss {'Reaction outcome loss': 0.13163364914906017, 'Total loss': 0.13163364914906017}
2022-12-31 08:54:01,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:01,084 INFO:     Epoch: 49
2022-12-31 08:54:02,727 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5065809051195781, 'Total loss': 0.5065809051195781} | train loss {'Reaction outcome loss': 0.1299169605662671, 'Total loss': 0.1299169605662671}
2022-12-31 08:54:02,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:02,728 INFO:     Epoch: 50
2022-12-31 08:54:04,371 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5047884891430537, 'Total loss': 0.5047884891430537} | train loss {'Reaction outcome loss': 0.12699509136064913, 'Total loss': 0.12699509136064913}
2022-12-31 08:54:04,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:04,371 INFO:     Epoch: 51
2022-12-31 08:54:05,982 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49230599999427793, 'Total loss': 0.49230599999427793} | train loss {'Reaction outcome loss': 0.1260844015673267, 'Total loss': 0.1260844015673267}
2022-12-31 08:54:05,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:05,982 INFO:     Epoch: 52
2022-12-31 08:54:07,596 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49537935902674995, 'Total loss': 0.49537935902674995} | train loss {'Reaction outcome loss': 0.12579719169959153, 'Total loss': 0.12579719169959153}
2022-12-31 08:54:07,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:07,597 INFO:     Epoch: 53
2022-12-31 08:54:09,212 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5272704179088274, 'Total loss': 0.5272704179088274} | train loss {'Reaction outcome loss': 0.12811748235189652, 'Total loss': 0.12811748235189652}
2022-12-31 08:54:09,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:09,213 INFO:     Epoch: 54
2022-12-31 08:54:10,815 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49222325881322226, 'Total loss': 0.49222325881322226} | train loss {'Reaction outcome loss': 0.12768630000963915, 'Total loss': 0.12768630000963915}
2022-12-31 08:54:10,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:10,815 INFO:     Epoch: 55
2022-12-31 08:54:12,462 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45559260112543903, 'Total loss': 0.45559260112543903} | train loss {'Reaction outcome loss': 0.12423077751046573, 'Total loss': 0.12423077751046573}
2022-12-31 08:54:12,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:12,462 INFO:     Epoch: 56
2022-12-31 08:54:14,034 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4920113444328308, 'Total loss': 0.4920113444328308} | train loss {'Reaction outcome loss': 0.121963260860793, 'Total loss': 0.121963260860793}
2022-12-31 08:54:14,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:14,034 INFO:     Epoch: 57
2022-12-31 08:54:15,136 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5029790272315343, 'Total loss': 0.5029790272315343} | train loss {'Reaction outcome loss': 0.12125346723145672, 'Total loss': 0.12125346723145672}
2022-12-31 08:54:15,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:15,136 INFO:     Epoch: 58
2022-12-31 08:54:16,238 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5059583405653636, 'Total loss': 0.5059583405653636} | train loss {'Reaction outcome loss': 0.12457821243732567, 'Total loss': 0.12457821243732567}
2022-12-31 08:54:16,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:16,238 INFO:     Epoch: 59
2022-12-31 08:54:17,341 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4835715611775716, 'Total loss': 0.4835715611775716} | train loss {'Reaction outcome loss': 0.11978955499507186, 'Total loss': 0.11978955499507186}
2022-12-31 08:54:17,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:17,341 INFO:     Epoch: 60
2022-12-31 08:54:18,486 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5219264964262644, 'Total loss': 0.5219264964262644} | train loss {'Reaction outcome loss': 0.11848484416110203, 'Total loss': 0.11848484416110203}
2022-12-31 08:54:18,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:18,486 INFO:     Epoch: 61
2022-12-31 08:54:20,124 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49376432796319325, 'Total loss': 0.49376432796319325} | train loss {'Reaction outcome loss': 0.12476321657089305, 'Total loss': 0.12476321657089305}
2022-12-31 08:54:20,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:20,125 INFO:     Epoch: 62
2022-12-31 08:54:21,726 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4948492795228958, 'Total loss': 0.4948492795228958} | train loss {'Reaction outcome loss': 0.11810616929520727, 'Total loss': 0.11810616929520727}
2022-12-31 08:54:21,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:21,726 INFO:     Epoch: 63
2022-12-31 08:54:23,373 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49657521496216456, 'Total loss': 0.49657521496216456} | train loss {'Reaction outcome loss': 0.1184746156815071, 'Total loss': 0.1184746156815071}
2022-12-31 08:54:23,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:23,373 INFO:     Epoch: 64
2022-12-31 08:54:25,021 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4896722972393036, 'Total loss': 0.4896722972393036} | train loss {'Reaction outcome loss': 0.12257758231540193, 'Total loss': 0.12257758231540193}
2022-12-31 08:54:25,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:25,022 INFO:     Epoch: 65
2022-12-31 08:54:26,657 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.532427046696345, 'Total loss': 0.532427046696345} | train loss {'Reaction outcome loss': 0.12834579149779657, 'Total loss': 0.12834579149779657}
2022-12-31 08:54:26,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:26,658 INFO:     Epoch: 66
2022-12-31 08:54:28,290 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48268729348977407, 'Total loss': 0.48268729348977407} | train loss {'Reaction outcome loss': 0.12184897439482693, 'Total loss': 0.12184897439482693}
2022-12-31 08:54:28,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:28,290 INFO:     Epoch: 67
2022-12-31 08:54:29,937 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5032247150937716, 'Total loss': 0.5032247150937716} | train loss {'Reaction outcome loss': 0.11232779147922174, 'Total loss': 0.11232779147922174}
2022-12-31 08:54:29,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:29,938 INFO:     Epoch: 68
2022-12-31 08:54:31,585 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4909664069612821, 'Total loss': 0.4909664069612821} | train loss {'Reaction outcome loss': 0.1173604935878417, 'Total loss': 0.1173604935878417}
2022-12-31 08:54:31,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:31,586 INFO:     Epoch: 69
2022-12-31 08:54:33,188 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.477411217490832, 'Total loss': 0.477411217490832} | train loss {'Reaction outcome loss': 0.1151842860242304, 'Total loss': 0.1151842860242304}
2022-12-31 08:54:33,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:33,189 INFO:     Epoch: 70
2022-12-31 08:54:34,824 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5010730663935343, 'Total loss': 0.5010730663935343} | train loss {'Reaction outcome loss': 0.12853804745987712, 'Total loss': 0.12853804745987712}
2022-12-31 08:54:34,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:34,824 INFO:     Epoch: 71
2022-12-31 08:54:36,444 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.500883936882019, 'Total loss': 0.500883936882019} | train loss {'Reaction outcome loss': 0.11488018517003773, 'Total loss': 0.11488018517003773}
2022-12-31 08:54:36,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:36,444 INFO:     Epoch: 72
2022-12-31 08:54:38,078 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49489431579907733, 'Total loss': 0.49489431579907733} | train loss {'Reaction outcome loss': 0.1167329393613797, 'Total loss': 0.1167329393613797}
2022-12-31 08:54:38,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:38,079 INFO:     Epoch: 73
2022-12-31 08:54:39,678 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5056015183528264, 'Total loss': 0.5056015183528264} | train loss {'Reaction outcome loss': 0.11769551579796132, 'Total loss': 0.11769551579796132}
2022-12-31 08:54:39,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:39,678 INFO:     Epoch: 74
2022-12-31 08:54:41,326 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5099822044372558, 'Total loss': 0.5099822044372558} | train loss {'Reaction outcome loss': 0.1159718809359376, 'Total loss': 0.1159718809359376}
2022-12-31 08:54:41,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:41,326 INFO:     Epoch: 75
2022-12-31 08:54:42,973 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5289113581180572, 'Total loss': 0.5289113581180572} | train loss {'Reaction outcome loss': 0.11308949786808083, 'Total loss': 0.11308949786808083}
2022-12-31 08:54:42,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:42,974 INFO:     Epoch: 76
2022-12-31 08:54:44,620 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49129099448521935, 'Total loss': 0.49129099448521935} | train loss {'Reaction outcome loss': 0.1146055638999934, 'Total loss': 0.1146055638999934}
2022-12-31 08:54:44,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:44,620 INFO:     Epoch: 77
2022-12-31 08:54:46,223 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5411404440800349, 'Total loss': 0.5411404440800349} | train loss {'Reaction outcome loss': 0.10926313931463566, 'Total loss': 0.10926313931463566}
2022-12-31 08:54:46,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:46,223 INFO:     Epoch: 78
2022-12-31 08:54:47,841 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5099166929721832, 'Total loss': 0.5099166929721832} | train loss {'Reaction outcome loss': 0.11135590458101159, 'Total loss': 0.11135590458101159}
2022-12-31 08:54:47,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:47,841 INFO:     Epoch: 79
2022-12-31 08:54:49,458 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49318259954452515, 'Total loss': 0.49318259954452515} | train loss {'Reaction outcome loss': 0.11471863309835721, 'Total loss': 0.11471863309835721}
2022-12-31 08:54:49,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:49,458 INFO:     Epoch: 80
2022-12-31 08:54:51,076 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5374601384003957, 'Total loss': 0.5374601384003957} | train loss {'Reaction outcome loss': 0.11664950774791531, 'Total loss': 0.11664950774791531}
2022-12-31 08:54:51,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:51,077 INFO:     Epoch: 81
2022-12-31 08:54:52,693 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5157078663508098, 'Total loss': 0.5157078663508098} | train loss {'Reaction outcome loss': 0.12146647207459414, 'Total loss': 0.12146647207459414}
2022-12-31 08:54:52,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:52,694 INFO:     Epoch: 82
2022-12-31 08:54:54,301 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5525848130385081, 'Total loss': 0.5525848130385081} | train loss {'Reaction outcome loss': 0.11295187850090446, 'Total loss': 0.11295187850090446}
2022-12-31 08:54:54,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:54,302 INFO:     Epoch: 83
2022-12-31 08:54:55,917 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5010973612467448, 'Total loss': 0.5010973612467448} | train loss {'Reaction outcome loss': 0.11631155916875154, 'Total loss': 0.11631155916875154}
2022-12-31 08:54:55,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:55,917 INFO:     Epoch: 84
2022-12-31 08:54:57,518 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5071737130482992, 'Total loss': 0.5071737130482992} | train loss {'Reaction outcome loss': 0.10917019087739371, 'Total loss': 0.10917019087739371}
2022-12-31 08:54:57,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:57,518 INFO:     Epoch: 85
2022-12-31 08:54:59,165 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5042051374912262, 'Total loss': 0.5042051374912262} | train loss {'Reaction outcome loss': 0.10990026252235084, 'Total loss': 0.10990026252235084}
2022-12-31 08:54:59,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:54:59,165 INFO:     Epoch: 86
2022-12-31 08:55:00,769 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5146935264269511, 'Total loss': 0.5146935264269511} | train loss {'Reaction outcome loss': 0.11163901909929956, 'Total loss': 0.11163901909929956}
2022-12-31 08:55:00,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:00,770 INFO:     Epoch: 87
2022-12-31 08:55:02,418 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5257749448219935, 'Total loss': 0.5257749448219935} | train loss {'Reaction outcome loss': 0.11621327932511248, 'Total loss': 0.11621327932511248}
2022-12-31 08:55:02,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:02,419 INFO:     Epoch: 88
2022-12-31 08:55:04,016 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48044408212105433, 'Total loss': 0.48044408212105433} | train loss {'Reaction outcome loss': 0.10731965257920967, 'Total loss': 0.10731965257920967}
2022-12-31 08:55:04,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:04,016 INFO:     Epoch: 89
2022-12-31 08:55:05,650 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5023167272408803, 'Total loss': 0.5023167272408803} | train loss {'Reaction outcome loss': 0.11052427666718925, 'Total loss': 0.11052427666718925}
2022-12-31 08:55:05,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:05,651 INFO:     Epoch: 90
2022-12-31 08:55:07,252 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49830603394657375, 'Total loss': 0.49830603394657375} | train loss {'Reaction outcome loss': 0.11124364330583413, 'Total loss': 0.11124364330583413}
2022-12-31 08:55:07,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:07,252 INFO:     Epoch: 91
2022-12-31 08:55:08,899 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4860871503750483, 'Total loss': 0.4860871503750483} | train loss {'Reaction outcome loss': 0.10964358067174097, 'Total loss': 0.10964358067174097}
2022-12-31 08:55:08,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:08,900 INFO:     Epoch: 92
2022-12-31 08:55:10,506 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46122088013216855, 'Total loss': 0.46122088013216855} | train loss {'Reaction outcome loss': 0.11593645364353126, 'Total loss': 0.11593645364353126}
2022-12-31 08:55:10,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:10,506 INFO:     Epoch: 93
2022-12-31 08:55:12,153 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49098395705223086, 'Total loss': 0.49098395705223086} | train loss {'Reaction outcome loss': 0.10635229834652209, 'Total loss': 0.10635229834652209}
2022-12-31 08:55:12,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:12,153 INFO:     Epoch: 94
2022-12-31 08:55:13,746 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47141434053579967, 'Total loss': 0.47141434053579967} | train loss {'Reaction outcome loss': 0.1074947566783308, 'Total loss': 0.1074947566783308}
2022-12-31 08:55:13,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:13,746 INFO:     Epoch: 95
2022-12-31 08:55:15,390 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5054928794503212, 'Total loss': 0.5054928794503212} | train loss {'Reaction outcome loss': 0.10453176794696477, 'Total loss': 0.10453176794696477}
2022-12-31 08:55:15,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:15,390 INFO:     Epoch: 96
2022-12-31 08:55:16,992 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4946668083469073, 'Total loss': 0.4946668083469073} | train loss {'Reaction outcome loss': 0.10728292708496662, 'Total loss': 0.10728292708496662}
2022-12-31 08:55:16,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:16,992 INFO:     Epoch: 97
2022-12-31 08:55:18,594 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5030735611915589, 'Total loss': 0.5030735611915589} | train loss {'Reaction outcome loss': 0.10903168931746712, 'Total loss': 0.10903168931746712}
2022-12-31 08:55:18,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:18,594 INFO:     Epoch: 98
2022-12-31 08:55:20,195 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5676248560349146, 'Total loss': 0.5676248560349146} | train loss {'Reaction outcome loss': 0.1078321337367275, 'Total loss': 0.1078321337367275}
2022-12-31 08:55:20,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:20,195 INFO:     Epoch: 99
2022-12-31 08:55:21,786 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4638931522766749, 'Total loss': 0.4638931522766749} | train loss {'Reaction outcome loss': 0.10992108489516372, 'Total loss': 0.10992108489516372}
2022-12-31 08:55:21,787 INFO:     Best model found after epoch 18 of 100.
2022-12-31 08:55:21,787 INFO:   Done with stage: TRAINING
2022-12-31 08:55:21,787 INFO:   Starting stage: EVALUATION
2022-12-31 08:55:21,932 INFO:   Done with stage: EVALUATION
2022-12-31 08:55:21,932 INFO:   Leaving out SEQ value Fold_7
2022-12-31 08:55:21,944 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 08:55:21,945 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:55:22,586 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:55:22,586 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:55:22,654 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:55:22,654 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:55:22,654 INFO:     No hyperparam tuning for this model
2022-12-31 08:55:22,654 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:55:22,654 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:55:22,655 INFO:     None feature selector for col prot
2022-12-31 08:55:22,655 INFO:     None feature selector for col prot
2022-12-31 08:55:22,655 INFO:     None feature selector for col prot
2022-12-31 08:55:22,655 INFO:     None feature selector for col chem
2022-12-31 08:55:22,655 INFO:     None feature selector for col chem
2022-12-31 08:55:22,656 INFO:     None feature selector for col chem
2022-12-31 08:55:22,656 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:55:22,656 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:55:22,657 INFO:     Number of params in model 224011
2022-12-31 08:55:22,661 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:55:22,661 INFO:   Starting stage: TRAINING
2022-12-31 08:55:22,706 INFO:     Val loss before train {'Reaction outcome loss': 0.975303033987681, 'Total loss': 0.975303033987681}
2022-12-31 08:55:22,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:22,706 INFO:     Epoch: 0
2022-12-31 08:55:24,326 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6170332570870717, 'Total loss': 0.6170332570870717} | train loss {'Reaction outcome loss': 0.8024583014555356, 'Total loss': 0.8024583014555356}
2022-12-31 08:55:24,326 INFO:     Found new best model at epoch 0
2022-12-31 08:55:24,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:24,327 INFO:     Epoch: 1
2022-12-31 08:55:25,946 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.519089651107788, 'Total loss': 0.519089651107788} | train loss {'Reaction outcome loss': 0.5245412292248075, 'Total loss': 0.5245412292248075}
2022-12-31 08:55:25,946 INFO:     Found new best model at epoch 1
2022-12-31 08:55:25,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:25,947 INFO:     Epoch: 2
2022-12-31 08:55:27,564 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47549774249394733, 'Total loss': 0.47549774249394733} | train loss {'Reaction outcome loss': 0.45237746872411305, 'Total loss': 0.45237746872411305}
2022-12-31 08:55:27,564 INFO:     Found new best model at epoch 2
2022-12-31 08:55:27,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:27,565 INFO:     Epoch: 3
2022-12-31 08:55:29,183 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44575520753860476, 'Total loss': 0.44575520753860476} | train loss {'Reaction outcome loss': 0.4087246138104893, 'Total loss': 0.4087246138104893}
2022-12-31 08:55:29,184 INFO:     Found new best model at epoch 3
2022-12-31 08:55:29,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:29,185 INFO:     Epoch: 4
2022-12-31 08:55:30,799 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42382050106922786, 'Total loss': 0.42382050106922786} | train loss {'Reaction outcome loss': 0.379703194279533, 'Total loss': 0.379703194279533}
2022-12-31 08:55:30,800 INFO:     Found new best model at epoch 4
2022-12-31 08:55:30,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:30,801 INFO:     Epoch: 5
2022-12-31 08:55:32,429 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39714890023072563, 'Total loss': 0.39714890023072563} | train loss {'Reaction outcome loss': 0.35687584257835947, 'Total loss': 0.35687584257835947}
2022-12-31 08:55:32,429 INFO:     Found new best model at epoch 5
2022-12-31 08:55:32,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:32,431 INFO:     Epoch: 6
2022-12-31 08:55:34,066 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3987053463856379, 'Total loss': 0.3987053463856379} | train loss {'Reaction outcome loss': 0.33555179183448697, 'Total loss': 0.33555179183448697}
2022-12-31 08:55:34,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:34,068 INFO:     Epoch: 7
2022-12-31 08:55:35,715 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4403285016616186, 'Total loss': 0.4403285016616186} | train loss {'Reaction outcome loss': 0.31830435781487487, 'Total loss': 0.31830435781487487}
2022-12-31 08:55:35,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:35,716 INFO:     Epoch: 8
2022-12-31 08:55:37,348 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41020389795303347, 'Total loss': 0.41020389795303347} | train loss {'Reaction outcome loss': 0.3024497662909625, 'Total loss': 0.3024497662909625}
2022-12-31 08:55:37,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:37,348 INFO:     Epoch: 9
2022-12-31 08:55:38,981 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4216845045487086, 'Total loss': 0.4216845045487086} | train loss {'Reaction outcome loss': 0.28879139378720675, 'Total loss': 0.28879139378720675}
2022-12-31 08:55:38,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:38,981 INFO:     Epoch: 10
2022-12-31 08:55:40,594 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40746361315250396, 'Total loss': 0.40746361315250396} | train loss {'Reaction outcome loss': 0.2774053683591879, 'Total loss': 0.2774053683591879}
2022-12-31 08:55:40,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:40,595 INFO:     Epoch: 11
2022-12-31 08:55:42,216 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3954634060462316, 'Total loss': 0.3954634060462316} | train loss {'Reaction outcome loss': 0.26713854896193806, 'Total loss': 0.26713854896193806}
2022-12-31 08:55:42,216 INFO:     Found new best model at epoch 11
2022-12-31 08:55:42,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:42,217 INFO:     Epoch: 12
2022-12-31 08:55:43,838 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39089342976609864, 'Total loss': 0.39089342976609864} | train loss {'Reaction outcome loss': 0.25812398133940645, 'Total loss': 0.25812398133940645}
2022-12-31 08:55:43,838 INFO:     Found new best model at epoch 12
2022-12-31 08:55:43,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:43,839 INFO:     Epoch: 13
2022-12-31 08:55:45,464 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39931323130925495, 'Total loss': 0.39931323130925495} | train loss {'Reaction outcome loss': 0.24440154992716406, 'Total loss': 0.24440154992716406}
2022-12-31 08:55:45,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:45,464 INFO:     Epoch: 14
2022-12-31 08:55:47,140 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39795676271120706, 'Total loss': 0.39795676271120706} | train loss {'Reaction outcome loss': 0.2418988670562041, 'Total loss': 0.2418988670562041}
2022-12-31 08:55:47,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:47,140 INFO:     Epoch: 15
2022-12-31 08:55:48,756 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39553596526384355, 'Total loss': 0.39553596526384355} | train loss {'Reaction outcome loss': 0.23178854050780462, 'Total loss': 0.23178854050780462}
2022-12-31 08:55:48,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:48,756 INFO:     Epoch: 16
2022-12-31 08:55:50,373 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38854104379812876, 'Total loss': 0.38854104379812876} | train loss {'Reaction outcome loss': 0.2237168666587248, 'Total loss': 0.2237168666587248}
2022-12-31 08:55:50,373 INFO:     Found new best model at epoch 16
2022-12-31 08:55:50,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:50,374 INFO:     Epoch: 17
2022-12-31 08:55:51,990 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38704104274511336, 'Total loss': 0.38704104274511336} | train loss {'Reaction outcome loss': 0.21928709854341585, 'Total loss': 0.21928709854341585}
2022-12-31 08:55:51,990 INFO:     Found new best model at epoch 17
2022-12-31 08:55:51,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:51,991 INFO:     Epoch: 18
2022-12-31 08:55:53,605 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40249052494764326, 'Total loss': 0.40249052494764326} | train loss {'Reaction outcome loss': 0.21209027627583876, 'Total loss': 0.21209027627583876}
2022-12-31 08:55:53,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:53,606 INFO:     Epoch: 19
2022-12-31 08:55:55,224 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3761823962132136, 'Total loss': 0.3761823962132136} | train loss {'Reaction outcome loss': 0.20787653113826302, 'Total loss': 0.20787653113826302}
2022-12-31 08:55:55,224 INFO:     Found new best model at epoch 19
2022-12-31 08:55:55,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:55,225 INFO:     Epoch: 20
2022-12-31 08:55:56,845 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3889400069912275, 'Total loss': 0.3889400069912275} | train loss {'Reaction outcome loss': 0.20022378514927647, 'Total loss': 0.20022378514927647}
2022-12-31 08:55:56,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:56,846 INFO:     Epoch: 21
2022-12-31 08:55:58,463 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4088340533276399, 'Total loss': 0.4088340533276399} | train loss {'Reaction outcome loss': 0.19675698940934688, 'Total loss': 0.19675698940934688}
2022-12-31 08:55:58,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:55:58,463 INFO:     Epoch: 22
2022-12-31 08:56:00,075 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39315684586763383, 'Total loss': 0.39315684586763383} | train loss {'Reaction outcome loss': 0.18988473653551258, 'Total loss': 0.18988473653551258}
2022-12-31 08:56:00,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:00,075 INFO:     Epoch: 23
2022-12-31 08:56:01,743 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39948132932186126, 'Total loss': 0.39948132932186126} | train loss {'Reaction outcome loss': 0.18530656961515707, 'Total loss': 0.18530656961515707}
2022-12-31 08:56:01,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:01,743 INFO:     Epoch: 24
2022-12-31 08:56:03,364 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4042046546936035, 'Total loss': 0.4042046546936035} | train loss {'Reaction outcome loss': 0.18089417310344183, 'Total loss': 0.18089417310344183}
2022-12-31 08:56:03,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:03,364 INFO:     Epoch: 25
2022-12-31 08:56:05,032 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.383293871084849, 'Total loss': 0.383293871084849} | train loss {'Reaction outcome loss': 0.17983671977093935, 'Total loss': 0.17983671977093935}
2022-12-31 08:56:05,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:05,032 INFO:     Epoch: 26
2022-12-31 08:56:06,685 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4030025064945221, 'Total loss': 0.4030025064945221} | train loss {'Reaction outcome loss': 0.18026162541071322, 'Total loss': 0.18026162541071322}
2022-12-31 08:56:06,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:06,685 INFO:     Epoch: 27
2022-12-31 08:56:08,311 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39827877283096313, 'Total loss': 0.39827877283096313} | train loss {'Reaction outcome loss': 0.173408783716738, 'Total loss': 0.173408783716738}
2022-12-31 08:56:08,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:08,312 INFO:     Epoch: 28
2022-12-31 08:56:09,959 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3788437892993291, 'Total loss': 0.3788437892993291} | train loss {'Reaction outcome loss': 0.16975560309600743, 'Total loss': 0.16975560309600743}
2022-12-31 08:56:09,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:09,960 INFO:     Epoch: 29
2022-12-31 08:56:11,584 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3755351612965266, 'Total loss': 0.3755351612965266} | train loss {'Reaction outcome loss': 0.16994134510198225, 'Total loss': 0.16994134510198225}
2022-12-31 08:56:11,585 INFO:     Found new best model at epoch 29
2022-12-31 08:56:11,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:11,586 INFO:     Epoch: 30
2022-12-31 08:56:13,209 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40748471915721896, 'Total loss': 0.40748471915721896} | train loss {'Reaction outcome loss': 0.1677008759203478, 'Total loss': 0.1677008759203478}
2022-12-31 08:56:13,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:13,209 INFO:     Epoch: 31
2022-12-31 08:56:14,875 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3727965533733368, 'Total loss': 0.3727965533733368} | train loss {'Reaction outcome loss': 0.16787992449080577, 'Total loss': 0.16787992449080577}
2022-12-31 08:56:14,876 INFO:     Found new best model at epoch 31
2022-12-31 08:56:14,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:14,877 INFO:     Epoch: 32
2022-12-31 08:56:16,508 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3906943584481875, 'Total loss': 0.3906943584481875} | train loss {'Reaction outcome loss': 0.16141116668870303, 'Total loss': 0.16141116668870303}
2022-12-31 08:56:16,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:16,509 INFO:     Epoch: 33
2022-12-31 08:56:18,131 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38208053112030027, 'Total loss': 0.38208053112030027} | train loss {'Reaction outcome loss': 0.15805184380033654, 'Total loss': 0.15805184380033654}
2022-12-31 08:56:18,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:18,131 INFO:     Epoch: 34
2022-12-31 08:56:19,798 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38345692654450736, 'Total loss': 0.38345692654450736} | train loss {'Reaction outcome loss': 0.15569043217986714, 'Total loss': 0.15569043217986714}
2022-12-31 08:56:19,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:19,799 INFO:     Epoch: 35
2022-12-31 08:56:21,466 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36951932559410733, 'Total loss': 0.36951932559410733} | train loss {'Reaction outcome loss': 0.15961742300762113, 'Total loss': 0.15961742300762113}
2022-12-31 08:56:21,466 INFO:     Found new best model at epoch 35
2022-12-31 08:56:21,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:21,467 INFO:     Epoch: 36
2022-12-31 08:56:23,089 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3784085442622503, 'Total loss': 0.3784085442622503} | train loss {'Reaction outcome loss': 0.15419183182950377, 'Total loss': 0.15419183182950377}
2022-12-31 08:56:23,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:23,089 INFO:     Epoch: 37
2022-12-31 08:56:24,755 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37799845536549886, 'Total loss': 0.37799845536549886} | train loss {'Reaction outcome loss': 0.15037336516183958, 'Total loss': 0.15037336516183958}
2022-12-31 08:56:24,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:24,755 INFO:     Epoch: 38
2022-12-31 08:56:26,368 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39432494938373563, 'Total loss': 0.39432494938373563} | train loss {'Reaction outcome loss': 0.14931263380922674, 'Total loss': 0.14931263380922674}
2022-12-31 08:56:26,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:26,368 INFO:     Epoch: 39
2022-12-31 08:56:27,986 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38812070712447166, 'Total loss': 0.38812070712447166} | train loss {'Reaction outcome loss': 0.14484477564625253, 'Total loss': 0.14484477564625253}
2022-12-31 08:56:27,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:27,987 INFO:     Epoch: 40
2022-12-31 08:56:29,653 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3983089864253998, 'Total loss': 0.3983089864253998} | train loss {'Reaction outcome loss': 0.14589672173887813, 'Total loss': 0.14589672173887813}
2022-12-31 08:56:29,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:29,654 INFO:     Epoch: 41
2022-12-31 08:56:31,271 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3971357554197311, 'Total loss': 0.3971357554197311} | train loss {'Reaction outcome loss': 0.14256704312544113, 'Total loss': 0.14256704312544113}
2022-12-31 08:56:31,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:31,271 INFO:     Epoch: 42
2022-12-31 08:56:32,937 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40609953105449675, 'Total loss': 0.40609953105449675} | train loss {'Reaction outcome loss': 0.14473601302051317, 'Total loss': 0.14473601302051317}
2022-12-31 08:56:32,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:32,937 INFO:     Epoch: 43
2022-12-31 08:56:34,559 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39020102421442665, 'Total loss': 0.39020102421442665} | train loss {'Reaction outcome loss': 0.14517431384766144, 'Total loss': 0.14517431384766144}
2022-12-31 08:56:34,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:34,559 INFO:     Epoch: 44
2022-12-31 08:56:36,203 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42892885307470957, 'Total loss': 0.42892885307470957} | train loss {'Reaction outcome loss': 0.14199976570776493, 'Total loss': 0.14199976570776493}
2022-12-31 08:56:36,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:36,203 INFO:     Epoch: 45
2022-12-31 08:56:37,814 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3761961897214254, 'Total loss': 0.3761961897214254} | train loss {'Reaction outcome loss': 0.14441004879638175, 'Total loss': 0.14441004879638175}
2022-12-31 08:56:37,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:37,814 INFO:     Epoch: 46
2022-12-31 08:56:39,481 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4090582519769669, 'Total loss': 0.4090582519769669} | train loss {'Reaction outcome loss': 0.13751131314313583, 'Total loss': 0.13751131314313583}
2022-12-31 08:56:39,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:39,481 INFO:     Epoch: 47
2022-12-31 08:56:41,100 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41236890057722725, 'Total loss': 0.41236890057722725} | train loss {'Reaction outcome loss': 0.13857521640224255, 'Total loss': 0.13857521640224255}
2022-12-31 08:56:41,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:41,100 INFO:     Epoch: 48
2022-12-31 08:56:42,720 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4055619046092033, 'Total loss': 0.4055619046092033} | train loss {'Reaction outcome loss': 0.13710770406340003, 'Total loss': 0.13710770406340003}
2022-12-31 08:56:42,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:42,721 INFO:     Epoch: 49
2022-12-31 08:56:44,344 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4061108062664668, 'Total loss': 0.4061108062664668} | train loss {'Reaction outcome loss': 0.137907795998056, 'Total loss': 0.137907795998056}
2022-12-31 08:56:44,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:44,345 INFO:     Epoch: 50
2022-12-31 08:56:45,982 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40548943281173705, 'Total loss': 0.40548943281173705} | train loss {'Reaction outcome loss': 0.1340972471642661, 'Total loss': 0.1340972471642661}
2022-12-31 08:56:45,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:45,982 INFO:     Epoch: 51
2022-12-31 08:56:47,622 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4224287807941437, 'Total loss': 0.4224287807941437} | train loss {'Reaction outcome loss': 0.13423069190597062, 'Total loss': 0.13423069190597062}
2022-12-31 08:56:47,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:47,622 INFO:     Epoch: 52
2022-12-31 08:56:49,260 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4067886094252268, 'Total loss': 0.4067886094252268} | train loss {'Reaction outcome loss': 0.13319672641448596, 'Total loss': 0.13319672641448596}
2022-12-31 08:56:49,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:49,260 INFO:     Epoch: 53
2022-12-31 08:56:50,899 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3742678885658582, 'Total loss': 0.3742678885658582} | train loss {'Reaction outcome loss': 0.12814219573189906, 'Total loss': 0.12814219573189906}
2022-12-31 08:56:50,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:50,899 INFO:     Epoch: 54
2022-12-31 08:56:52,526 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3954481879870097, 'Total loss': 0.3954481879870097} | train loss {'Reaction outcome loss': 0.13131189077843775, 'Total loss': 0.13131189077843775}
2022-12-31 08:56:52,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:52,526 INFO:     Epoch: 55
2022-12-31 08:56:54,153 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4156744966904322, 'Total loss': 0.4156744966904322} | train loss {'Reaction outcome loss': 0.13153667455128923, 'Total loss': 0.13153667455128923}
2022-12-31 08:56:54,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:54,154 INFO:     Epoch: 56
2022-12-31 08:56:55,789 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3871351604660352, 'Total loss': 0.3871351604660352} | train loss {'Reaction outcome loss': 0.13250227841726817, 'Total loss': 0.13250227841726817}
2022-12-31 08:56:55,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:55,789 INFO:     Epoch: 57
2022-12-31 08:56:57,423 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38358099659283956, 'Total loss': 0.38358099659283956} | train loss {'Reaction outcome loss': 0.12885835736868936, 'Total loss': 0.12885835736868936}
2022-12-31 08:56:57,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:57,424 INFO:     Epoch: 58
2022-12-31 08:56:59,059 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4072445511817932, 'Total loss': 0.4072445511817932} | train loss {'Reaction outcome loss': 0.1288618932004063, 'Total loss': 0.1288618932004063}
2022-12-31 08:56:59,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:56:59,059 INFO:     Epoch: 59
2022-12-31 08:57:00,693 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3984785209099452, 'Total loss': 0.3984785209099452} | train loss {'Reaction outcome loss': 0.126553445755225, 'Total loss': 0.126553445755225}
2022-12-31 08:57:00,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:00,693 INFO:     Epoch: 60
2022-12-31 08:57:02,311 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39467405440906683, 'Total loss': 0.39467405440906683} | train loss {'Reaction outcome loss': 0.1242115546895413, 'Total loss': 0.1242115546895413}
2022-12-31 08:57:02,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:02,312 INFO:     Epoch: 61
2022-12-31 08:57:03,923 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38249043027559915, 'Total loss': 0.38249043027559915} | train loss {'Reaction outcome loss': 0.12227213947902625, 'Total loss': 0.12227213947902625}
2022-12-31 08:57:03,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:03,924 INFO:     Epoch: 62
2022-12-31 08:57:05,542 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3986469179391861, 'Total loss': 0.3986469179391861} | train loss {'Reaction outcome loss': 0.125998780206989, 'Total loss': 0.125998780206989}
2022-12-31 08:57:05,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:05,542 INFO:     Epoch: 63
2022-12-31 08:57:07,209 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41945606619119646, 'Total loss': 0.41945606619119646} | train loss {'Reaction outcome loss': 0.127698723942929, 'Total loss': 0.127698723942929}
2022-12-31 08:57:07,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:07,209 INFO:     Epoch: 64
2022-12-31 08:57:08,828 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39643426338831583, 'Total loss': 0.39643426338831583} | train loss {'Reaction outcome loss': 0.13102737472590986, 'Total loss': 0.13102737472590986}
2022-12-31 08:57:08,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:08,828 INFO:     Epoch: 65
2022-12-31 08:57:10,452 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3809650036195914, 'Total loss': 0.3809650036195914} | train loss {'Reaction outcome loss': 0.1259178777329543, 'Total loss': 0.1259178777329543}
2022-12-31 08:57:10,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:10,452 INFO:     Epoch: 66
2022-12-31 08:57:12,071 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4091712539394697, 'Total loss': 0.4091712539394697} | train loss {'Reaction outcome loss': 0.12293066124562914, 'Total loss': 0.12293066124562914}
2022-12-31 08:57:12,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:12,072 INFO:     Epoch: 67
2022-12-31 08:57:13,706 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.380839629471302, 'Total loss': 0.380839629471302} | train loss {'Reaction outcome loss': 0.12238404011885073, 'Total loss': 0.12238404011885073}
2022-12-31 08:57:13,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:13,706 INFO:     Epoch: 68
2022-12-31 08:57:15,340 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40339806377887727, 'Total loss': 0.40339806377887727} | train loss {'Reaction outcome loss': 0.12386125218567005, 'Total loss': 0.12386125218567005}
2022-12-31 08:57:15,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:15,341 INFO:     Epoch: 69
2022-12-31 08:57:16,976 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4231092810630798, 'Total loss': 0.4231092810630798} | train loss {'Reaction outcome loss': 0.11841049210407135, 'Total loss': 0.11841049210407135}
2022-12-31 08:57:16,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:16,976 INFO:     Epoch: 70
2022-12-31 08:57:18,612 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4056459089120229, 'Total loss': 0.4056459089120229} | train loss {'Reaction outcome loss': 0.1262274780344312, 'Total loss': 0.1262274780344312}
2022-12-31 08:57:18,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:18,612 INFO:     Epoch: 71
2022-12-31 08:57:20,239 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40195419639348984, 'Total loss': 0.40195419639348984} | train loss {'Reaction outcome loss': 0.11731755633297164, 'Total loss': 0.11731755633297164}
2022-12-31 08:57:20,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:20,240 INFO:     Epoch: 72
2022-12-31 08:57:21,898 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3641333858172099, 'Total loss': 0.3641333858172099} | train loss {'Reaction outcome loss': 0.11501958193122964, 'Total loss': 0.11501958193122964}
2022-12-31 08:57:21,898 INFO:     Found new best model at epoch 72
2022-12-31 08:57:21,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:21,899 INFO:     Epoch: 73
2022-12-31 08:57:23,514 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3984608938296636, 'Total loss': 0.3984608938296636} | train loss {'Reaction outcome loss': 0.11603497164256682, 'Total loss': 0.11603497164256682}
2022-12-31 08:57:23,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:23,514 INFO:     Epoch: 74
2022-12-31 08:57:25,149 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38383491287628807, 'Total loss': 0.38383491287628807} | train loss {'Reaction outcome loss': 0.11855702157660189, 'Total loss': 0.11855702157660189}
2022-12-31 08:57:25,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:25,150 INFO:     Epoch: 75
2022-12-31 08:57:26,790 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3902385580042998, 'Total loss': 0.3902385580042998} | train loss {'Reaction outcome loss': 0.12034741018660071, 'Total loss': 0.12034741018660071}
2022-12-31 08:57:26,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:26,791 INFO:     Epoch: 76
2022-12-31 08:57:28,436 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39304640591144563, 'Total loss': 0.39304640591144563} | train loss {'Reaction outcome loss': 0.12040106947147136, 'Total loss': 0.12040106947147136}
2022-12-31 08:57:28,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:28,436 INFO:     Epoch: 77
2022-12-31 08:57:30,079 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.416655487815539, 'Total loss': 0.416655487815539} | train loss {'Reaction outcome loss': 0.11605091238081697, 'Total loss': 0.11605091238081697}
2022-12-31 08:57:30,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:30,079 INFO:     Epoch: 78
2022-12-31 08:57:31,716 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40051006774107617, 'Total loss': 0.40051006774107617} | train loss {'Reaction outcome loss': 0.11537119669634648, 'Total loss': 0.11537119669634648}
2022-12-31 08:57:31,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:31,717 INFO:     Epoch: 79
2022-12-31 08:57:33,336 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3897315591573715, 'Total loss': 0.3897315591573715} | train loss {'Reaction outcome loss': 0.11874212904174271, 'Total loss': 0.11874212904174271}
2022-12-31 08:57:33,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:33,336 INFO:     Epoch: 80
2022-12-31 08:57:35,003 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41381513277689613, 'Total loss': 0.41381513277689613} | train loss {'Reaction outcome loss': 0.11648441852988264, 'Total loss': 0.11648441852988264}
2022-12-31 08:57:35,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:35,003 INFO:     Epoch: 81
2022-12-31 08:57:36,670 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3921318511168162, 'Total loss': 0.3921318511168162} | train loss {'Reaction outcome loss': 0.11833763263938067, 'Total loss': 0.11833763263938067}
2022-12-31 08:57:36,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:36,670 INFO:     Epoch: 82
2022-12-31 08:57:38,325 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4067212680975596, 'Total loss': 0.4067212680975596} | train loss {'Reaction outcome loss': 0.11449745539004245, 'Total loss': 0.11449745539004245}
2022-12-31 08:57:38,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:38,325 INFO:     Epoch: 83
2022-12-31 08:57:39,948 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3990797221660614, 'Total loss': 0.3990797221660614} | train loss {'Reaction outcome loss': 0.11664356852189002, 'Total loss': 0.11664356852189002}
2022-12-31 08:57:39,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:39,949 INFO:     Epoch: 84
2022-12-31 08:57:41,571 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4052998165289561, 'Total loss': 0.4052998165289561} | train loss {'Reaction outcome loss': 0.117190195402191, 'Total loss': 0.117190195402191}
2022-12-31 08:57:41,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:41,571 INFO:     Epoch: 85
2022-12-31 08:57:43,192 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39979786376158394, 'Total loss': 0.39979786376158394} | train loss {'Reaction outcome loss': 0.1166427393531299, 'Total loss': 0.1166427393531299}
2022-12-31 08:57:43,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:43,193 INFO:     Epoch: 86
2022-12-31 08:57:44,860 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40237038930257163, 'Total loss': 0.40237038930257163} | train loss {'Reaction outcome loss': 0.11822607103627619, 'Total loss': 0.11822607103627619}
2022-12-31 08:57:44,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:44,860 INFO:     Epoch: 87
2022-12-31 08:57:46,516 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4144202048579852, 'Total loss': 0.4144202048579852} | train loss {'Reaction outcome loss': 0.11488687253594129, 'Total loss': 0.11488687253594129}
2022-12-31 08:57:46,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:46,516 INFO:     Epoch: 88
2022-12-31 08:57:48,131 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40666101425886153, 'Total loss': 0.40666101425886153} | train loss {'Reaction outcome loss': 0.11508192812741502, 'Total loss': 0.11508192812741502}
2022-12-31 08:57:48,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:48,131 INFO:     Epoch: 89
2022-12-31 08:57:49,749 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4086201588312785, 'Total loss': 0.4086201588312785} | train loss {'Reaction outcome loss': 0.11711557357427446, 'Total loss': 0.11711557357427446}
2022-12-31 08:57:49,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:49,749 INFO:     Epoch: 90
2022-12-31 08:57:51,367 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.431358078867197, 'Total loss': 0.431358078867197} | train loss {'Reaction outcome loss': 0.1118086371385906, 'Total loss': 0.1118086371385906}
2022-12-31 08:57:51,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:51,367 INFO:     Epoch: 91
2022-12-31 08:57:52,985 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38358691533406575, 'Total loss': 0.38358691533406575} | train loss {'Reaction outcome loss': 0.11405020497826732, 'Total loss': 0.11405020497826732}
2022-12-31 08:57:52,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:52,985 INFO:     Epoch: 92
2022-12-31 08:57:54,601 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4260852336883545, 'Total loss': 0.4260852336883545} | train loss {'Reaction outcome loss': 0.11580270716066503, 'Total loss': 0.11580270716066503}
2022-12-31 08:57:54,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:54,601 INFO:     Epoch: 93
2022-12-31 08:57:56,251 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38774609913428626, 'Total loss': 0.38774609913428626} | train loss {'Reaction outcome loss': 0.11706128708735808, 'Total loss': 0.11706128708735808}
2022-12-31 08:57:56,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:56,252 INFO:     Epoch: 94
2022-12-31 08:57:57,878 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4168752630551656, 'Total loss': 0.4168752630551656} | train loss {'Reaction outcome loss': 0.11540823486307468, 'Total loss': 0.11540823486307468}
2022-12-31 08:57:57,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:57,878 INFO:     Epoch: 95
2022-12-31 08:57:59,508 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4122651040554047, 'Total loss': 0.4122651040554047} | train loss {'Reaction outcome loss': 0.11400330322710561, 'Total loss': 0.11400330322710561}
2022-12-31 08:57:59,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:57:59,508 INFO:     Epoch: 96
2022-12-31 08:58:01,146 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39162080412109695, 'Total loss': 0.39162080412109695} | train loss {'Reaction outcome loss': 0.1112465224588552, 'Total loss': 0.1112465224588552}
2022-12-31 08:58:01,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:01,146 INFO:     Epoch: 97
2022-12-31 08:58:02,781 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38421829293171567, 'Total loss': 0.38421829293171567} | train loss {'Reaction outcome loss': 0.11198203431758424, 'Total loss': 0.11198203431758424}
2022-12-31 08:58:02,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:02,782 INFO:     Epoch: 98
2022-12-31 08:58:04,417 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39959547221660613, 'Total loss': 0.39959547221660613} | train loss {'Reaction outcome loss': 0.11056385904093297, 'Total loss': 0.11056385904093297}
2022-12-31 08:58:04,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:04,418 INFO:     Epoch: 99
2022-12-31 08:58:06,036 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40999318460623424, 'Total loss': 0.40999318460623424} | train loss {'Reaction outcome loss': 0.11202577579705993, 'Total loss': 0.11202577579705993}
2022-12-31 08:58:06,036 INFO:     Best model found after epoch 73 of 100.
2022-12-31 08:58:06,036 INFO:   Done with stage: TRAINING
2022-12-31 08:58:06,036 INFO:   Starting stage: EVALUATION
2022-12-31 08:58:06,160 INFO:   Done with stage: EVALUATION
2022-12-31 08:58:06,160 INFO:   Leaving out SEQ value Fold_8
2022-12-31 08:58:06,172 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 08:58:06,172 INFO:   Starting stage: FEATURE SCALING
2022-12-31 08:58:06,810 INFO:   Done with stage: FEATURE SCALING
2022-12-31 08:58:06,811 INFO:   Starting stage: SCALING TARGETS
2022-12-31 08:58:06,878 INFO:   Done with stage: SCALING TARGETS
2022-12-31 08:58:06,878 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:58:06,878 INFO:     No hyperparam tuning for this model
2022-12-31 08:58:06,878 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 08:58:06,878 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 08:58:06,879 INFO:     None feature selector for col prot
2022-12-31 08:58:06,879 INFO:     None feature selector for col prot
2022-12-31 08:58:06,879 INFO:     None feature selector for col prot
2022-12-31 08:58:06,880 INFO:     None feature selector for col chem
2022-12-31 08:58:06,880 INFO:     None feature selector for col chem
2022-12-31 08:58:06,880 INFO:     None feature selector for col chem
2022-12-31 08:58:06,880 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 08:58:06,880 INFO:   Starting stage: BUILD MODEL
2022-12-31 08:58:06,882 INFO:     Number of params in model 224011
2022-12-31 08:58:06,885 INFO:   Done with stage: BUILD MODEL
2022-12-31 08:58:06,885 INFO:   Starting stage: TRAINING
2022-12-31 08:58:06,929 INFO:     Val loss before train {'Reaction outcome loss': 1.1019539395968119, 'Total loss': 1.1019539395968119}
2022-12-31 08:58:06,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:06,929 INFO:     Epoch: 0
2022-12-31 08:58:08,543 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6122317771116893, 'Total loss': 0.6122317771116893} | train loss {'Reaction outcome loss': 0.7834750264292529, 'Total loss': 0.7834750264292529}
2022-12-31 08:58:08,543 INFO:     Found new best model at epoch 0
2022-12-31 08:58:08,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:08,544 INFO:     Epoch: 1
2022-12-31 08:58:10,159 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5097657084465027, 'Total loss': 0.5097657084465027} | train loss {'Reaction outcome loss': 0.5189363169551328, 'Total loss': 0.5189363169551328}
2022-12-31 08:58:10,159 INFO:     Found new best model at epoch 1
2022-12-31 08:58:10,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:10,160 INFO:     Epoch: 2
2022-12-31 08:58:11,776 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4568003992239634, 'Total loss': 0.4568003992239634} | train loss {'Reaction outcome loss': 0.44893074944949424, 'Total loss': 0.44893074944949424}
2022-12-31 08:58:11,776 INFO:     Found new best model at epoch 2
2022-12-31 08:58:11,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:11,777 INFO:     Epoch: 3
2022-12-31 08:58:13,390 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.424494801958402, 'Total loss': 0.424494801958402} | train loss {'Reaction outcome loss': 0.4074327222786952, 'Total loss': 0.4074327222786952}
2022-12-31 08:58:13,390 INFO:     Found new best model at epoch 3
2022-12-31 08:58:13,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:13,391 INFO:     Epoch: 4
2022-12-31 08:58:15,005 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4301553855339686, 'Total loss': 0.4301553855339686} | train loss {'Reaction outcome loss': 0.3817850951564269, 'Total loss': 0.3817850951564269}
2022-12-31 08:58:15,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:15,006 INFO:     Epoch: 5
2022-12-31 08:58:16,625 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4190803557634354, 'Total loss': 0.4190803557634354} | train loss {'Reaction outcome loss': 0.35908065081668505, 'Total loss': 0.35908065081668505}
2022-12-31 08:58:16,625 INFO:     Found new best model at epoch 5
2022-12-31 08:58:16,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:16,626 INFO:     Epoch: 6
2022-12-31 08:58:18,243 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3980791628360748, 'Total loss': 0.3980791628360748} | train loss {'Reaction outcome loss': 0.3402451045458556, 'Total loss': 0.3402451045458556}
2022-12-31 08:58:18,243 INFO:     Found new best model at epoch 6
2022-12-31 08:58:18,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:18,245 INFO:     Epoch: 7
2022-12-31 08:58:19,860 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.411207714676857, 'Total loss': 0.411207714676857} | train loss {'Reaction outcome loss': 0.32487782569997775, 'Total loss': 0.32487782569997775}
2022-12-31 08:58:19,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:19,860 INFO:     Epoch: 8
2022-12-31 08:58:21,521 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4007431964079539, 'Total loss': 0.4007431964079539} | train loss {'Reaction outcome loss': 0.3132909271609632, 'Total loss': 0.3132909271609632}
2022-12-31 08:58:21,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:21,521 INFO:     Epoch: 9
2022-12-31 08:58:23,165 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4249444325764974, 'Total loss': 0.4249444325764974} | train loss {'Reaction outcome loss': 0.2942760585118895, 'Total loss': 0.2942760585118895}
2022-12-31 08:58:23,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:23,166 INFO:     Epoch: 10
2022-12-31 08:58:24,812 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.413615220785141, 'Total loss': 0.413615220785141} | train loss {'Reaction outcome loss': 0.28718770932460175, 'Total loss': 0.28718770932460175}
2022-12-31 08:58:24,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:24,812 INFO:     Epoch: 11
2022-12-31 08:58:26,473 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4312327245871226, 'Total loss': 0.4312327245871226} | train loss {'Reaction outcome loss': 0.2830303101058024, 'Total loss': 0.2830303101058024}
2022-12-31 08:58:26,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:26,474 INFO:     Epoch: 12
2022-12-31 08:58:28,091 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39478142658869425, 'Total loss': 0.39478142658869425} | train loss {'Reaction outcome loss': 0.2784562860278116, 'Total loss': 0.2784562860278116}
2022-12-31 08:58:28,092 INFO:     Found new best model at epoch 12
2022-12-31 08:58:28,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:28,093 INFO:     Epoch: 13
2022-12-31 08:58:29,755 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37140526125828427, 'Total loss': 0.37140526125828427} | train loss {'Reaction outcome loss': 0.26777683871973684, 'Total loss': 0.26777683871973684}
2022-12-31 08:58:29,756 INFO:     Found new best model at epoch 13
2022-12-31 08:58:29,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:29,757 INFO:     Epoch: 14
2022-12-31 08:58:31,374 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3661174277464549, 'Total loss': 0.3661174277464549} | train loss {'Reaction outcome loss': 0.25846088552624796, 'Total loss': 0.25846088552624796}
2022-12-31 08:58:31,374 INFO:     Found new best model at epoch 14
2022-12-31 08:58:31,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:31,375 INFO:     Epoch: 15
2022-12-31 08:58:32,982 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39856717685858406, 'Total loss': 0.39856717685858406} | train loss {'Reaction outcome loss': 0.23990753237951035, 'Total loss': 0.23990753237951035}
2022-12-31 08:58:32,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:32,983 INFO:     Epoch: 16
2022-12-31 08:58:34,590 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3762032444278399, 'Total loss': 0.3762032444278399} | train loss {'Reaction outcome loss': 0.23633703713531376, 'Total loss': 0.23633703713531376}
2022-12-31 08:58:34,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:34,591 INFO:     Epoch: 17
2022-12-31 08:58:36,203 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4095872660477956, 'Total loss': 0.4095872660477956} | train loss {'Reaction outcome loss': 0.2252939877233576, 'Total loss': 0.2252939877233576}
2022-12-31 08:58:36,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:36,203 INFO:     Epoch: 18
2022-12-31 08:58:37,865 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3938806881507238, 'Total loss': 0.3938806881507238} | train loss {'Reaction outcome loss': 0.21980961388304632, 'Total loss': 0.21980961388304632}
2022-12-31 08:58:37,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:37,865 INFO:     Epoch: 19
2022-12-31 08:58:39,477 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3897148152192434, 'Total loss': 0.3897148152192434} | train loss {'Reaction outcome loss': 0.21614184933107183, 'Total loss': 0.21614184933107183}
2022-12-31 08:58:39,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:39,477 INFO:     Epoch: 20
2022-12-31 08:58:41,135 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4130826622247696, 'Total loss': 0.4130826622247696} | train loss {'Reaction outcome loss': 0.22466825840967722, 'Total loss': 0.22466825840967722}
2022-12-31 08:58:41,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:41,135 INFO:     Epoch: 21
2022-12-31 08:58:42,745 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38468727469444275, 'Total loss': 0.38468727469444275} | train loss {'Reaction outcome loss': 0.2315075597860783, 'Total loss': 0.2315075597860783}
2022-12-31 08:58:42,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:42,745 INFO:     Epoch: 22
2022-12-31 08:58:44,406 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39110684593518574, 'Total loss': 0.39110684593518574} | train loss {'Reaction outcome loss': 0.20051184386028437, 'Total loss': 0.20051184386028437}
2022-12-31 08:58:44,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:44,406 INFO:     Epoch: 23
2022-12-31 08:58:46,068 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4118393580118815, 'Total loss': 0.4118393580118815} | train loss {'Reaction outcome loss': 0.19745346542554942, 'Total loss': 0.19745346542554942}
2022-12-31 08:58:46,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:46,068 INFO:     Epoch: 24
2022-12-31 08:58:47,729 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41140435735384623, 'Total loss': 0.41140435735384623} | train loss {'Reaction outcome loss': 0.19213056384266922, 'Total loss': 0.19213056384266922}
2022-12-31 08:58:47,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:47,730 INFO:     Epoch: 25
2022-12-31 08:58:49,340 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4075093328952789, 'Total loss': 0.4075093328952789} | train loss {'Reaction outcome loss': 0.1900010144547222, 'Total loss': 0.1900010144547222}
2022-12-31 08:58:49,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:49,340 INFO:     Epoch: 26
2022-12-31 08:58:50,987 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4382730315128962, 'Total loss': 0.4382730315128962} | train loss {'Reaction outcome loss': 0.18442586948082823, 'Total loss': 0.18442586948082823}
2022-12-31 08:58:50,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:50,987 INFO:     Epoch: 27
2022-12-31 08:58:52,611 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43400871058305107, 'Total loss': 0.43400871058305107} | train loss {'Reaction outcome loss': 0.18056718281055192, 'Total loss': 0.18056718281055192}
2022-12-31 08:58:52,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:52,611 INFO:     Epoch: 28
2022-12-31 08:58:54,245 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4185893038908641, 'Total loss': 0.4185893038908641} | train loss {'Reaction outcome loss': 0.17889705877093112, 'Total loss': 0.17889705877093112}
2022-12-31 08:58:54,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:54,245 INFO:     Epoch: 29
2022-12-31 08:58:55,882 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4285851756731669, 'Total loss': 0.4285851756731669} | train loss {'Reaction outcome loss': 0.17873581344705916, 'Total loss': 0.17873581344705916}
2022-12-31 08:58:55,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:55,882 INFO:     Epoch: 30
2022-12-31 08:58:57,516 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4487842400868734, 'Total loss': 0.4487842400868734} | train loss {'Reaction outcome loss': 0.17256664391944482, 'Total loss': 0.17256664391944482}
2022-12-31 08:58:57,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:57,516 INFO:     Epoch: 31
2022-12-31 08:58:59,153 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4246843010187149, 'Total loss': 0.4246843010187149} | train loss {'Reaction outcome loss': 0.17242972887533656, 'Total loss': 0.17242972887533656}
2022-12-31 08:58:59,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:58:59,153 INFO:     Epoch: 32
2022-12-31 08:59:00,774 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.382969664533933, 'Total loss': 0.382969664533933} | train loss {'Reaction outcome loss': 0.16966475231195058, 'Total loss': 0.16966475231195058}
2022-12-31 08:59:00,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:00,774 INFO:     Epoch: 33
2022-12-31 08:59:02,440 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3992292478680611, 'Total loss': 0.3992292478680611} | train loss {'Reaction outcome loss': 0.1640619624562585, 'Total loss': 0.1640619624562585}
2022-12-31 08:59:02,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:02,440 INFO:     Epoch: 34
2022-12-31 08:59:04,096 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3917502532402674, 'Total loss': 0.3917502532402674} | train loss {'Reaction outcome loss': 0.16389579401573798, 'Total loss': 0.16389579401573798}
2022-12-31 08:59:04,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:04,098 INFO:     Epoch: 35
2022-12-31 08:59:05,733 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44630493422349293, 'Total loss': 0.44630493422349293} | train loss {'Reaction outcome loss': 0.159143452630024, 'Total loss': 0.159143452630024}
2022-12-31 08:59:05,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:05,733 INFO:     Epoch: 36
2022-12-31 08:59:07,368 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40396279729902745, 'Total loss': 0.40396279729902745} | train loss {'Reaction outcome loss': 0.1631808898930393, 'Total loss': 0.1631808898930393}
2022-12-31 08:59:07,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:07,369 INFO:     Epoch: 37
2022-12-31 08:59:08,992 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4220320443312327, 'Total loss': 0.4220320443312327} | train loss {'Reaction outcome loss': 0.16024612882292655, 'Total loss': 0.16024612882292655}
2022-12-31 08:59:08,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:08,992 INFO:     Epoch: 38
2022-12-31 08:59:10,614 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4237835536400477, 'Total loss': 0.4237835536400477} | train loss {'Reaction outcome loss': 0.15397725650425698, 'Total loss': 0.15397725650425698}
2022-12-31 08:59:10,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:10,615 INFO:     Epoch: 39
2022-12-31 08:59:12,246 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41149299691120783, 'Total loss': 0.41149299691120783} | train loss {'Reaction outcome loss': 0.1562503618837766, 'Total loss': 0.1562503618837766}
2022-12-31 08:59:12,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:12,247 INFO:     Epoch: 40
2022-12-31 08:59:13,879 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40753639340400694, 'Total loss': 0.40753639340400694} | train loss {'Reaction outcome loss': 0.1515019091176868, 'Total loss': 0.1515019091176868}
2022-12-31 08:59:13,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:13,879 INFO:     Epoch: 41
2022-12-31 08:59:15,512 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45199606716632845, 'Total loss': 0.45199606716632845} | train loss {'Reaction outcome loss': 0.16385573624005623, 'Total loss': 0.16385573624005623}
2022-12-31 08:59:15,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:15,513 INFO:     Epoch: 42
2022-12-31 08:59:17,145 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43639390071233114, 'Total loss': 0.43639390071233114} | train loss {'Reaction outcome loss': 0.1461154786815894, 'Total loss': 0.1461154786815894}
2022-12-31 08:59:17,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:17,145 INFO:     Epoch: 43
2022-12-31 08:59:18,763 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4339553644259771, 'Total loss': 0.4339553644259771} | train loss {'Reaction outcome loss': 0.14483032079305555, 'Total loss': 0.14483032079305555}
2022-12-31 08:59:18,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:18,763 INFO:     Epoch: 44
2022-12-31 08:59:20,429 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4232851097981135, 'Total loss': 0.4232851097981135} | train loss {'Reaction outcome loss': 0.14579675091271635, 'Total loss': 0.14579675091271635}
2022-12-31 08:59:20,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:20,429 INFO:     Epoch: 45
2022-12-31 08:59:22,095 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4174907465775808, 'Total loss': 0.4174907465775808} | train loss {'Reaction outcome loss': 0.1441503402545451, 'Total loss': 0.1441503402545451}
2022-12-31 08:59:22,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:22,096 INFO:     Epoch: 46
2022-12-31 08:59:23,713 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42271508475144703, 'Total loss': 0.42271508475144703} | train loss {'Reaction outcome loss': 0.14136256957620694, 'Total loss': 0.14136256957620694}
2022-12-31 08:59:23,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:23,714 INFO:     Epoch: 47
2022-12-31 08:59:25,332 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39788806686798733, 'Total loss': 0.39788806686798733} | train loss {'Reaction outcome loss': 0.14418494650174357, 'Total loss': 0.14418494650174357}
2022-12-31 08:59:25,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:25,332 INFO:     Epoch: 48
2022-12-31 08:59:26,954 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.398622439801693, 'Total loss': 0.398622439801693} | train loss {'Reaction outcome loss': 0.14021180269386, 'Total loss': 0.14021180269386}
2022-12-31 08:59:26,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:26,954 INFO:     Epoch: 49
2022-12-31 08:59:28,573 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4236512174208959, 'Total loss': 0.4236512174208959} | train loss {'Reaction outcome loss': 0.13372184427958744, 'Total loss': 0.13372184427958744}
2022-12-31 08:59:28,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:28,573 INFO:     Epoch: 50
2022-12-31 08:59:30,210 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4089391350746155, 'Total loss': 0.4089391350746155} | train loss {'Reaction outcome loss': 0.13862764774598146, 'Total loss': 0.13862764774598146}
2022-12-31 08:59:30,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:30,210 INFO:     Epoch: 51
2022-12-31 08:59:31,844 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42638972103595735, 'Total loss': 0.42638972103595735} | train loss {'Reaction outcome loss': 0.1342175543591704, 'Total loss': 0.1342175543591704}
2022-12-31 08:59:31,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:31,844 INFO:     Epoch: 52
2022-12-31 08:59:33,478 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43021292239427567, 'Total loss': 0.43021292239427567} | train loss {'Reaction outcome loss': 0.1401400968974011, 'Total loss': 0.1401400968974011}
2022-12-31 08:59:33,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:33,479 INFO:     Epoch: 53
2022-12-31 08:59:35,113 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40272331635157266, 'Total loss': 0.40272331635157266} | train loss {'Reaction outcome loss': 0.1320027477235324, 'Total loss': 0.1320027477235324}
2022-12-31 08:59:35,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:35,113 INFO:     Epoch: 54
2022-12-31 08:59:36,738 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43848838210105895, 'Total loss': 0.43848838210105895} | train loss {'Reaction outcome loss': 0.12976953415383594, 'Total loss': 0.12976953415383594}
2022-12-31 08:59:36,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:36,739 INFO:     Epoch: 55
2022-12-31 08:59:38,347 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4429108728965124, 'Total loss': 0.4429108728965124} | train loss {'Reaction outcome loss': 0.13192208032326205, 'Total loss': 0.13192208032326205}
2022-12-31 08:59:38,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:38,348 INFO:     Epoch: 56
2022-12-31 08:59:39,959 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41945421397686006, 'Total loss': 0.41945421397686006} | train loss {'Reaction outcome loss': 0.15277211428811838, 'Total loss': 0.15277211428811838}
2022-12-31 08:59:39,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:39,959 INFO:     Epoch: 57
2022-12-31 08:59:41,620 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3996745005249977, 'Total loss': 0.3996745005249977} | train loss {'Reaction outcome loss': 0.13117949350861888, 'Total loss': 0.13117949350861888}
2022-12-31 08:59:41,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:41,621 INFO:     Epoch: 58
2022-12-31 08:59:43,282 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4001611908276876, 'Total loss': 0.4001611908276876} | train loss {'Reaction outcome loss': 0.1278007238418013, 'Total loss': 0.1278007238418013}
2022-12-31 08:59:43,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:43,282 INFO:     Epoch: 59
2022-12-31 08:59:44,943 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40040397047996523, 'Total loss': 0.40040397047996523} | train loss {'Reaction outcome loss': 0.12722652772925727, 'Total loss': 0.12722652772925727}
2022-12-31 08:59:44,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:44,944 INFO:     Epoch: 60
2022-12-31 08:59:46,546 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41971536179383595, 'Total loss': 0.41971536179383595} | train loss {'Reaction outcome loss': 0.1249702485711432, 'Total loss': 0.1249702485711432}
2022-12-31 08:59:46,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:46,547 INFO:     Epoch: 61
2022-12-31 08:59:48,175 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42186954120794934, 'Total loss': 0.42186954120794934} | train loss {'Reaction outcome loss': 0.12726643064187543, 'Total loss': 0.12726643064187543}
2022-12-31 08:59:48,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:48,176 INFO:     Epoch: 62
2022-12-31 08:59:49,837 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42900108893712363, 'Total loss': 0.42900108893712363} | train loss {'Reaction outcome loss': 0.1270537701624351, 'Total loss': 0.1270537701624351}
2022-12-31 08:59:49,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:49,837 INFO:     Epoch: 63
2022-12-31 08:59:51,451 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4201180030902227, 'Total loss': 0.4201180030902227} | train loss {'Reaction outcome loss': 0.14409356668044854, 'Total loss': 0.14409356668044854}
2022-12-31 08:59:51,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:51,452 INFO:     Epoch: 64
2022-12-31 08:59:53,113 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4317893366018931, 'Total loss': 0.4317893366018931} | train loss {'Reaction outcome loss': 0.15209699828731085, 'Total loss': 0.15209699828731085}
2022-12-31 08:59:53,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:53,113 INFO:     Epoch: 65
2022-12-31 08:59:54,763 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4115480214357376, 'Total loss': 0.4115480214357376} | train loss {'Reaction outcome loss': 0.13401469474226452, 'Total loss': 0.13401469474226452}
2022-12-31 08:59:54,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:54,764 INFO:     Epoch: 66
2022-12-31 08:59:56,380 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40367308259010315, 'Total loss': 0.40367308259010315} | train loss {'Reaction outcome loss': 0.12823115453078493, 'Total loss': 0.12823115453078493}
2022-12-31 08:59:56,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:56,380 INFO:     Epoch: 67
2022-12-31 08:59:57,993 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4267415950695674, 'Total loss': 0.4267415950695674} | train loss {'Reaction outcome loss': 0.12394436957876441, 'Total loss': 0.12394436957876441}
2022-12-31 08:59:57,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:57,994 INFO:     Epoch: 68
2022-12-31 08:59:59,610 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42072181701660155, 'Total loss': 0.42072181701660155} | train loss {'Reaction outcome loss': 0.12378046582750318, 'Total loss': 0.12378046582750318}
2022-12-31 08:59:59,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 08:59:59,611 INFO:     Epoch: 69
2022-12-31 09:00:01,273 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40992062787214917, 'Total loss': 0.40992062787214917} | train loss {'Reaction outcome loss': 0.12931135928459075, 'Total loss': 0.12931135928459075}
2022-12-31 09:00:01,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:01,273 INFO:     Epoch: 70
2022-12-31 09:00:02,891 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4106602261463801, 'Total loss': 0.4106602261463801} | train loss {'Reaction outcome loss': 0.12416788421704542, 'Total loss': 0.12416788421704542}
2022-12-31 09:00:02,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:02,891 INFO:     Epoch: 71
2022-12-31 09:00:04,513 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4439732074737549, 'Total loss': 0.4439732074737549} | train loss {'Reaction outcome loss': 0.12480859460471116, 'Total loss': 0.12480859460471116}
2022-12-31 09:00:04,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:04,514 INFO:     Epoch: 72
2022-12-31 09:00:06,137 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45776729186375936, 'Total loss': 0.45776729186375936} | train loss {'Reaction outcome loss': 0.12465898981452853, 'Total loss': 0.12465898981452853}
2022-12-31 09:00:06,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:06,137 INFO:     Epoch: 73
2022-12-31 09:00:07,766 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45561503420273464, 'Total loss': 0.45561503420273464} | train loss {'Reaction outcome loss': 0.12278742861994744, 'Total loss': 0.12278742861994744}
2022-12-31 09:00:07,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:07,766 INFO:     Epoch: 74
2022-12-31 09:00:09,389 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43106375137964886, 'Total loss': 0.43106375137964886} | train loss {'Reaction outcome loss': 0.12869377314819902, 'Total loss': 0.12869377314819902}
2022-12-31 09:00:09,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:09,390 INFO:     Epoch: 75
2022-12-31 09:00:11,021 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39656647195418676, 'Total loss': 0.39656647195418676} | train loss {'Reaction outcome loss': 0.11984274927965378, 'Total loss': 0.11984274927965378}
2022-12-31 09:00:11,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:11,021 INFO:     Epoch: 76
2022-12-31 09:00:12,647 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4397285163402557, 'Total loss': 0.4397285163402557} | train loss {'Reaction outcome loss': 0.11628201700881144, 'Total loss': 0.11628201700881144}
2022-12-31 09:00:12,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:12,648 INFO:     Epoch: 77
2022-12-31 09:00:14,293 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4109607105453809, 'Total loss': 0.4109607105453809} | train loss {'Reaction outcome loss': 0.11676770294982725, 'Total loss': 0.11676770294982725}
2022-12-31 09:00:14,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:14,294 INFO:     Epoch: 78
2022-12-31 09:00:15,976 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4551042060057322, 'Total loss': 0.4551042060057322} | train loss {'Reaction outcome loss': 0.11931048023010905, 'Total loss': 0.11931048023010905}
2022-12-31 09:00:15,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:15,976 INFO:     Epoch: 79
2022-12-31 09:00:17,596 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4276474893093109, 'Total loss': 0.4276474893093109} | train loss {'Reaction outcome loss': 0.12109777456203448, 'Total loss': 0.12109777456203448}
2022-12-31 09:00:17,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:17,596 INFO:     Epoch: 80
2022-12-31 09:00:19,264 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41725813448429105, 'Total loss': 0.41725813448429105} | train loss {'Reaction outcome loss': 0.11654392464481424, 'Total loss': 0.11654392464481424}
2022-12-31 09:00:19,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:19,264 INFO:     Epoch: 81
2022-12-31 09:00:20,884 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4442698240280151, 'Total loss': 0.4442698240280151} | train loss {'Reaction outcome loss': 0.11947249313580223, 'Total loss': 0.11947249313580223}
2022-12-31 09:00:20,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:20,885 INFO:     Epoch: 82
2022-12-31 09:00:22,510 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.416017460078001, 'Total loss': 0.416017460078001} | train loss {'Reaction outcome loss': 0.11479961650743001, 'Total loss': 0.11479961650743001}
2022-12-31 09:00:22,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:22,510 INFO:     Epoch: 83
2022-12-31 09:00:24,131 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4463866298397382, 'Total loss': 0.4463866298397382} | train loss {'Reaction outcome loss': 0.11437214795649567, 'Total loss': 0.11437214795649567}
2022-12-31 09:00:24,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:24,132 INFO:     Epoch: 84
2022-12-31 09:00:25,797 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44085080226262413, 'Total loss': 0.44085080226262413} | train loss {'Reaction outcome loss': 0.1124780276392509, 'Total loss': 0.1124780276392509}
2022-12-31 09:00:25,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:25,797 INFO:     Epoch: 85
2022-12-31 09:00:27,463 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43130889534950256, 'Total loss': 0.43130889534950256} | train loss {'Reaction outcome loss': 0.11590452258495305, 'Total loss': 0.11590452258495305}
2022-12-31 09:00:27,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:27,463 INFO:     Epoch: 86
2022-12-31 09:00:29,081 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38374812112500273, 'Total loss': 0.38374812112500273} | train loss {'Reaction outcome loss': 0.11726481620606029, 'Total loss': 0.11726481620606029}
2022-12-31 09:00:29,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:29,081 INFO:     Epoch: 87
2022-12-31 09:00:30,746 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3961950530608495, 'Total loss': 0.3961950530608495} | train loss {'Reaction outcome loss': 0.11537763724566279, 'Total loss': 0.11537763724566279}
2022-12-31 09:00:30,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:30,746 INFO:     Epoch: 88
2022-12-31 09:00:32,378 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4316785655915737, 'Total loss': 0.4316785655915737} | train loss {'Reaction outcome loss': 0.11213721633216862, 'Total loss': 0.11213721633216862}
2022-12-31 09:00:32,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:32,378 INFO:     Epoch: 89
2022-12-31 09:00:34,042 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43162406285603844, 'Total loss': 0.43162406285603844} | train loss {'Reaction outcome loss': 0.11159954213613621, 'Total loss': 0.11159954213613621}
2022-12-31 09:00:34,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:34,043 INFO:     Epoch: 90
2022-12-31 09:00:35,660 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4451717346906662, 'Total loss': 0.4451717346906662} | train loss {'Reaction outcome loss': 0.11141770194112526, 'Total loss': 0.11141770194112526}
2022-12-31 09:00:35,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:35,660 INFO:     Epoch: 91
2022-12-31 09:00:37,326 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39792780081431073, 'Total loss': 0.39792780081431073} | train loss {'Reaction outcome loss': 0.11649337765571756, 'Total loss': 0.11649337765571756}
2022-12-31 09:00:37,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:37,326 INFO:     Epoch: 92
2022-12-31 09:00:38,944 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39228805905828873, 'Total loss': 0.39228805905828873} | train loss {'Reaction outcome loss': 0.11433511136715095, 'Total loss': 0.11433511136715095}
2022-12-31 09:00:38,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:38,944 INFO:     Epoch: 93
2022-12-31 09:00:40,591 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4193894942601522, 'Total loss': 0.4193894942601522} | train loss {'Reaction outcome loss': 0.10767534327190505, 'Total loss': 0.10767534327190505}
2022-12-31 09:00:40,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:40,591 INFO:     Epoch: 94
2022-12-31 09:00:42,258 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4404674748579661, 'Total loss': 0.4404674748579661} | train loss {'Reaction outcome loss': 0.10958728898549452, 'Total loss': 0.10958728898549452}
2022-12-31 09:00:42,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:42,258 INFO:     Epoch: 95
2022-12-31 09:00:43,881 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4239755257964134, 'Total loss': 0.4239755257964134} | train loss {'Reaction outcome loss': 0.11168344632681945, 'Total loss': 0.11168344632681945}
2022-12-31 09:00:43,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:43,881 INFO:     Epoch: 96
2022-12-31 09:00:45,508 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40111493517955144, 'Total loss': 0.40111493517955144} | train loss {'Reaction outcome loss': 0.11040969947994134, 'Total loss': 0.11040969947994134}
2022-12-31 09:00:45,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:45,508 INFO:     Epoch: 97
2022-12-31 09:00:47,135 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.480641371011734, 'Total loss': 0.480641371011734} | train loss {'Reaction outcome loss': 0.11106202671931975, 'Total loss': 0.11106202671931975}
2022-12-31 09:00:47,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:47,136 INFO:     Epoch: 98
2022-12-31 09:00:48,758 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.442645267645518, 'Total loss': 0.442645267645518} | train loss {'Reaction outcome loss': 0.11205375011901934, 'Total loss': 0.11205375011901934}
2022-12-31 09:00:48,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:48,759 INFO:     Epoch: 99
2022-12-31 09:00:50,383 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43319882253805797, 'Total loss': 0.43319882253805797} | train loss {'Reaction outcome loss': 0.10951165489614537, 'Total loss': 0.10951165489614537}
2022-12-31 09:00:50,384 INFO:     Best model found after epoch 15 of 100.
2022-12-31 09:00:50,384 INFO:   Done with stage: TRAINING
2022-12-31 09:00:50,384 INFO:   Starting stage: EVALUATION
2022-12-31 09:00:50,517 INFO:   Done with stage: EVALUATION
2022-12-31 09:00:50,517 INFO:   Leaving out SEQ value Fold_9
2022-12-31 09:00:50,530 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 09:00:50,530 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:00:51,179 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:00:51,179 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:00:51,246 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:00:51,246 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:00:51,246 INFO:     No hyperparam tuning for this model
2022-12-31 09:00:51,246 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:00:51,246 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:00:51,247 INFO:     None feature selector for col prot
2022-12-31 09:00:51,247 INFO:     None feature selector for col prot
2022-12-31 09:00:51,247 INFO:     None feature selector for col prot
2022-12-31 09:00:51,248 INFO:     None feature selector for col chem
2022-12-31 09:00:51,248 INFO:     None feature selector for col chem
2022-12-31 09:00:51,248 INFO:     None feature selector for col chem
2022-12-31 09:00:51,248 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:00:51,248 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:00:51,250 INFO:     Number of params in model 224011
2022-12-31 09:00:51,253 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:00:51,253 INFO:   Starting stage: TRAINING
2022-12-31 09:00:51,300 INFO:     Val loss before train {'Reaction outcome loss': 1.002069107691447, 'Total loss': 1.002069107691447}
2022-12-31 09:00:51,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:51,300 INFO:     Epoch: 0
2022-12-31 09:00:52,932 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5743306616942088, 'Total loss': 0.5743306616942088} | train loss {'Reaction outcome loss': 0.7825559020472778, 'Total loss': 0.7825559020472778}
2022-12-31 09:00:52,932 INFO:     Found new best model at epoch 0
2022-12-31 09:00:52,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:52,933 INFO:     Epoch: 1
2022-12-31 09:00:54,567 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5214339564243953, 'Total loss': 0.5214339564243953} | train loss {'Reaction outcome loss': 0.5122502105653501, 'Total loss': 0.5122502105653501}
2022-12-31 09:00:54,568 INFO:     Found new best model at epoch 1
2022-12-31 09:00:54,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:54,569 INFO:     Epoch: 2
2022-12-31 09:00:56,201 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4711130956808726, 'Total loss': 0.4711130956808726} | train loss {'Reaction outcome loss': 0.45067826612761736, 'Total loss': 0.45067826612761736}
2022-12-31 09:00:56,201 INFO:     Found new best model at epoch 2
2022-12-31 09:00:56,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:56,202 INFO:     Epoch: 3
2022-12-31 09:00:57,836 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45695199569066364, 'Total loss': 0.45695199569066364} | train loss {'Reaction outcome loss': 0.4133789079929517, 'Total loss': 0.4133789079929517}
2022-12-31 09:00:57,837 INFO:     Found new best model at epoch 3
2022-12-31 09:00:57,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:57,838 INFO:     Epoch: 4
2022-12-31 09:00:59,453 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4754100938638051, 'Total loss': 0.4754100938638051} | train loss {'Reaction outcome loss': 0.38380889546139574, 'Total loss': 0.38380889546139574}
2022-12-31 09:00:59,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:00:59,453 INFO:     Epoch: 5
2022-12-31 09:01:01,118 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44323167006174724, 'Total loss': 0.44323167006174724} | train loss {'Reaction outcome loss': 0.358812824375793, 'Total loss': 0.358812824375793}
2022-12-31 09:01:01,118 INFO:     Found new best model at epoch 5
2022-12-31 09:01:01,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:01,119 INFO:     Epoch: 6
2022-12-31 09:01:02,739 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43673018117745716, 'Total loss': 0.43673018117745716} | train loss {'Reaction outcome loss': 0.34267312600294175, 'Total loss': 0.34267312600294175}
2022-12-31 09:01:02,739 INFO:     Found new best model at epoch 6
2022-12-31 09:01:02,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:02,740 INFO:     Epoch: 7
2022-12-31 09:01:04,362 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42953756749629973, 'Total loss': 0.42953756749629973} | train loss {'Reaction outcome loss': 0.32055972201837096, 'Total loss': 0.32055972201837096}
2022-12-31 09:01:04,362 INFO:     Found new best model at epoch 7
2022-12-31 09:01:04,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:04,363 INFO:     Epoch: 8
2022-12-31 09:01:05,984 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42262437641620637, 'Total loss': 0.42262437641620637} | train loss {'Reaction outcome loss': 0.30435745859189156, 'Total loss': 0.30435745859189156}
2022-12-31 09:01:05,984 INFO:     Found new best model at epoch 8
2022-12-31 09:01:05,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:05,985 INFO:     Epoch: 9
2022-12-31 09:01:07,600 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44104583859443663, 'Total loss': 0.44104583859443663} | train loss {'Reaction outcome loss': 0.2910259822215414, 'Total loss': 0.2910259822215414}
2022-12-31 09:01:07,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:07,601 INFO:     Epoch: 10
2022-12-31 09:01:09,230 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4397087852160136, 'Total loss': 0.4397087852160136} | train loss {'Reaction outcome loss': 0.277817718698122, 'Total loss': 0.277817718698122}
2022-12-31 09:01:09,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:09,230 INFO:     Epoch: 11
2022-12-31 09:01:10,861 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41999990145365396, 'Total loss': 0.41999990145365396} | train loss {'Reaction outcome loss': 0.26233869832721857, 'Total loss': 0.26233869832721857}
2022-12-31 09:01:10,862 INFO:     Found new best model at epoch 11
2022-12-31 09:01:10,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:10,863 INFO:     Epoch: 12
2022-12-31 09:01:12,489 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42515244483947756, 'Total loss': 0.42515244483947756} | train loss {'Reaction outcome loss': 0.25222498417196504, 'Total loss': 0.25222498417196504}
2022-12-31 09:01:12,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:12,489 INFO:     Epoch: 13
2022-12-31 09:01:14,112 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46176936229070026, 'Total loss': 0.46176936229070026} | train loss {'Reaction outcome loss': 0.24496955611484145, 'Total loss': 0.24496955611484145}
2022-12-31 09:01:14,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:14,112 INFO:     Epoch: 14
2022-12-31 09:01:15,736 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43582173188527423, 'Total loss': 0.43582173188527423} | train loss {'Reaction outcome loss': 0.23696336397625478, 'Total loss': 0.23696336397625478}
2022-12-31 09:01:15,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:15,736 INFO:     Epoch: 15
2022-12-31 09:01:17,345 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45084561506907145, 'Total loss': 0.45084561506907145} | train loss {'Reaction outcome loss': 0.2265114394228381, 'Total loss': 0.2265114394228381}
2022-12-31 09:01:17,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:17,346 INFO:     Epoch: 16
2022-12-31 09:01:18,967 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.428418863316377, 'Total loss': 0.428418863316377} | train loss {'Reaction outcome loss': 0.22144198680585686, 'Total loss': 0.22144198680585686}
2022-12-31 09:01:18,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:18,967 INFO:     Epoch: 17
2022-12-31 09:01:20,634 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43552602926890055, 'Total loss': 0.43552602926890055} | train loss {'Reaction outcome loss': 0.21805878049468735, 'Total loss': 0.21805878049468735}
2022-12-31 09:01:20,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:20,634 INFO:     Epoch: 18
2022-12-31 09:01:22,301 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44721501171588895, 'Total loss': 0.44721501171588895} | train loss {'Reaction outcome loss': 0.20693155249668158, 'Total loss': 0.20693155249668158}
2022-12-31 09:01:22,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:22,302 INFO:     Epoch: 19
2022-12-31 09:01:23,930 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4533574789762497, 'Total loss': 0.4533574789762497} | train loss {'Reaction outcome loss': 0.20257249703153377, 'Total loss': 0.20257249703153377}
2022-12-31 09:01:23,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:23,931 INFO:     Epoch: 20
2022-12-31 09:01:25,596 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45332089563210803, 'Total loss': 0.45332089563210803} | train loss {'Reaction outcome loss': 0.20192904777771084, 'Total loss': 0.20192904777771084}
2022-12-31 09:01:25,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:25,596 INFO:     Epoch: 21
2022-12-31 09:01:27,230 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4648994127909342, 'Total loss': 0.4648994127909342} | train loss {'Reaction outcome loss': 0.19842264148329355, 'Total loss': 0.19842264148329355}
2022-12-31 09:01:27,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:27,231 INFO:     Epoch: 22
2022-12-31 09:01:28,917 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46418032944202425, 'Total loss': 0.46418032944202425} | train loss {'Reaction outcome loss': 0.18817764798697043, 'Total loss': 0.18817764798697043}
2022-12-31 09:01:28,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:28,918 INFO:     Epoch: 23
2022-12-31 09:01:30,544 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4481326888004939, 'Total loss': 0.4481326888004939} | train loss {'Reaction outcome loss': 0.1866607613901907, 'Total loss': 0.1866607613901907}
2022-12-31 09:01:30,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:30,544 INFO:     Epoch: 24
2022-12-31 09:01:32,180 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4725925127665202, 'Total loss': 0.4725925127665202} | train loss {'Reaction outcome loss': 0.1820679988076621, 'Total loss': 0.1820679988076621}
2022-12-31 09:01:32,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:32,180 INFO:     Epoch: 25
2022-12-31 09:01:33,818 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48741502563158673, 'Total loss': 0.48741502563158673} | train loss {'Reaction outcome loss': 0.17701846387385245, 'Total loss': 0.17701846387385245}
2022-12-31 09:01:33,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:33,819 INFO:     Epoch: 26
2022-12-31 09:01:35,441 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4826959053675334, 'Total loss': 0.4826959053675334} | train loss {'Reaction outcome loss': 0.17497636994434393, 'Total loss': 0.17497636994434393}
2022-12-31 09:01:35,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:35,441 INFO:     Epoch: 27
2022-12-31 09:01:37,108 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4760901222626368, 'Total loss': 0.4760901222626368} | train loss {'Reaction outcome loss': 0.17698528218866472, 'Total loss': 0.17698528218866472}
2022-12-31 09:01:37,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:37,108 INFO:     Epoch: 28
2022-12-31 09:01:38,779 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45362316370010375, 'Total loss': 0.45362316370010375} | train loss {'Reaction outcome loss': 0.17109636692767324, 'Total loss': 0.17109636692767324}
2022-12-31 09:01:38,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:38,779 INFO:     Epoch: 29
2022-12-31 09:01:40,451 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4897212743759155, 'Total loss': 0.4897212743759155} | train loss {'Reaction outcome loss': 0.1733169964134747, 'Total loss': 0.1733169964134747}
2022-12-31 09:01:40,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:40,451 INFO:     Epoch: 30
2022-12-31 09:01:42,122 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47273384233315785, 'Total loss': 0.47273384233315785} | train loss {'Reaction outcome loss': 0.16383057118591848, 'Total loss': 0.16383057118591848}
2022-12-31 09:01:42,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:42,123 INFO:     Epoch: 31
2022-12-31 09:01:43,738 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49846572677294415, 'Total loss': 0.49846572677294415} | train loss {'Reaction outcome loss': 0.16483176576598996, 'Total loss': 0.16483176576598996}
2022-12-31 09:01:43,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:43,738 INFO:     Epoch: 32
2022-12-31 09:01:45,356 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5042772620916367, 'Total loss': 0.5042772620916367} | train loss {'Reaction outcome loss': 0.16333863857313183, 'Total loss': 0.16333863857313183}
2022-12-31 09:01:45,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:45,356 INFO:     Epoch: 33
2022-12-31 09:01:46,975 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5030500451723735, 'Total loss': 0.5030500451723735} | train loss {'Reaction outcome loss': 0.15899808675097807, 'Total loss': 0.15899808675097807}
2022-12-31 09:01:46,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:46,975 INFO:     Epoch: 34
2022-12-31 09:01:48,594 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.497325258453687, 'Total loss': 0.497325258453687} | train loss {'Reaction outcome loss': 0.16001233429772382, 'Total loss': 0.16001233429772382}
2022-12-31 09:01:48,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:48,594 INFO:     Epoch: 35
2022-12-31 09:01:50,214 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47924538056055704, 'Total loss': 0.47924538056055704} | train loss {'Reaction outcome loss': 0.1551550004079884, 'Total loss': 0.1551550004079884}
2022-12-31 09:01:50,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:50,215 INFO:     Epoch: 36
2022-12-31 09:01:51,833 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5048188452919324, 'Total loss': 0.5048188452919324} | train loss {'Reaction outcome loss': 0.15391409328873085, 'Total loss': 0.15391409328873085}
2022-12-31 09:01:51,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:51,834 INFO:     Epoch: 37
2022-12-31 09:01:53,485 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4890744532148043, 'Total loss': 0.4890744532148043} | train loss {'Reaction outcome loss': 0.15146767288876783, 'Total loss': 0.15146767288876783}
2022-12-31 09:01:53,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:53,485 INFO:     Epoch: 38
2022-12-31 09:01:55,138 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49563459952672323, 'Total loss': 0.49563459952672323} | train loss {'Reaction outcome loss': 0.15259007095033134, 'Total loss': 0.15259007095033134}
2022-12-31 09:01:55,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:55,138 INFO:     Epoch: 39
2022-12-31 09:01:56,760 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4956712742646535, 'Total loss': 0.4956712742646535} | train loss {'Reaction outcome loss': 0.15408227438803104, 'Total loss': 0.15408227438803104}
2022-12-31 09:01:56,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:56,761 INFO:     Epoch: 40
2022-12-31 09:01:58,384 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4985340088605881, 'Total loss': 0.4985340088605881} | train loss {'Reaction outcome loss': 0.15199656028885541, 'Total loss': 0.15199656028885541}
2022-12-31 09:01:58,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:01:58,384 INFO:     Epoch: 41
2022-12-31 09:02:00,054 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4827114005883535, 'Total loss': 0.4827114005883535} | train loss {'Reaction outcome loss': 0.14624599024606363, 'Total loss': 0.14624599024606363}
2022-12-31 09:02:00,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:00,055 INFO:     Epoch: 42
2022-12-31 09:02:01,724 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4704815576473872, 'Total loss': 0.4704815576473872} | train loss {'Reaction outcome loss': 0.1456979609091198, 'Total loss': 0.1456979609091198}
2022-12-31 09:02:01,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:01,725 INFO:     Epoch: 43
2022-12-31 09:02:03,355 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5339100663860639, 'Total loss': 0.5339100663860639} | train loss {'Reaction outcome loss': 0.14674251489862397, 'Total loss': 0.14674251489862397}
2022-12-31 09:02:03,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:03,356 INFO:     Epoch: 44
2022-12-31 09:02:04,978 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4874790981411934, 'Total loss': 0.4874790981411934} | train loss {'Reaction outcome loss': 0.14339062456202958, 'Total loss': 0.14339062456202958}
2022-12-31 09:02:04,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:04,979 INFO:     Epoch: 45
2022-12-31 09:02:06,651 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4802916139364243, 'Total loss': 0.4802916139364243} | train loss {'Reaction outcome loss': 0.1431571701272569, 'Total loss': 0.1431571701272569}
2022-12-31 09:02:06,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:06,651 INFO:     Epoch: 46
2022-12-31 09:02:08,297 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4991178760925929, 'Total loss': 0.4991178760925929} | train loss {'Reaction outcome loss': 0.1395708870559608, 'Total loss': 0.1395708870559608}
2022-12-31 09:02:08,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:08,298 INFO:     Epoch: 47
2022-12-31 09:02:09,934 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46746224761009214, 'Total loss': 0.46746224761009214} | train loss {'Reaction outcome loss': 0.14141821241113844, 'Total loss': 0.14141821241113844}
2022-12-31 09:02:09,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:09,934 INFO:     Epoch: 48
2022-12-31 09:02:11,565 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49328004121780394, 'Total loss': 0.49328004121780394} | train loss {'Reaction outcome loss': 0.13652124582362843, 'Total loss': 0.13652124582362843}
2022-12-31 09:02:11,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:11,565 INFO:     Epoch: 49
2022-12-31 09:02:13,192 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48966423869132997, 'Total loss': 0.48966423869132997} | train loss {'Reaction outcome loss': 0.13301080471873014, 'Total loss': 0.13301080471873014}
2022-12-31 09:02:13,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:13,193 INFO:     Epoch: 50
2022-12-31 09:02:14,825 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49996569255987805, 'Total loss': 0.49996569255987805} | train loss {'Reaction outcome loss': 0.13618485680831738, 'Total loss': 0.13618485680831738}
2022-12-31 09:02:14,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:14,825 INFO:     Epoch: 51
2022-12-31 09:02:16,469 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4807443141937256, 'Total loss': 0.4807443141937256} | train loss {'Reaction outcome loss': 0.13651724880567956, 'Total loss': 0.13651724880567956}
2022-12-31 09:02:16,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:16,470 INFO:     Epoch: 52
2022-12-31 09:02:18,104 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49200363755226134, 'Total loss': 0.49200363755226134} | train loss {'Reaction outcome loss': 0.13908542269867735, 'Total loss': 0.13908542269867735}
2022-12-31 09:02:18,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:18,104 INFO:     Epoch: 53
2022-12-31 09:02:19,742 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5227670073509216, 'Total loss': 0.5227670073509216} | train loss {'Reaction outcome loss': 0.13619897090947586, 'Total loss': 0.13619897090947586}
2022-12-31 09:02:19,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:19,742 INFO:     Epoch: 54
2022-12-31 09:02:21,372 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4797208582361539, 'Total loss': 0.4797208582361539} | train loss {'Reaction outcome loss': 0.13294705349467828, 'Total loss': 0.13294705349467828}
2022-12-31 09:02:21,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:21,372 INFO:     Epoch: 55
2022-12-31 09:02:23,098 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4755709980924924, 'Total loss': 0.4755709980924924} | train loss {'Reaction outcome loss': 0.13004664638977403, 'Total loss': 0.13004664638977403}
2022-12-31 09:02:23,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:23,098 INFO:     Epoch: 56
2022-12-31 09:02:24,727 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5018462444345156, 'Total loss': 0.5018462444345156} | train loss {'Reaction outcome loss': 0.13213620759170194, 'Total loss': 0.13213620759170194}
2022-12-31 09:02:24,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:24,727 INFO:     Epoch: 57
2022-12-31 09:02:26,353 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.505156738559405, 'Total loss': 0.505156738559405} | train loss {'Reaction outcome loss': 0.13288574813048118, 'Total loss': 0.13288574813048118}
2022-12-31 09:02:26,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:26,353 INFO:     Epoch: 58
2022-12-31 09:02:27,985 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4846525112787882, 'Total loss': 0.4846525112787882} | train loss {'Reaction outcome loss': 0.1270923404727427, 'Total loss': 0.1270923404727427}
2022-12-31 09:02:27,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:27,985 INFO:     Epoch: 59
2022-12-31 09:02:29,619 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4889062106609344, 'Total loss': 0.4889062106609344} | train loss {'Reaction outcome loss': 0.1284593948068951, 'Total loss': 0.1284593948068951}
2022-12-31 09:02:29,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:29,620 INFO:     Epoch: 60
2022-12-31 09:02:31,301 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5194210787614186, 'Total loss': 0.5194210787614186} | train loss {'Reaction outcome loss': 0.1294347547509099, 'Total loss': 0.1294347547509099}
2022-12-31 09:02:31,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:31,302 INFO:     Epoch: 61
2022-12-31 09:02:32,937 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4827676127354304, 'Total loss': 0.4827676127354304} | train loss {'Reaction outcome loss': 0.12685710942164224, 'Total loss': 0.12685710942164224}
2022-12-31 09:02:32,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:32,938 INFO:     Epoch: 62
2022-12-31 09:02:34,669 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4901793042818705, 'Total loss': 0.4901793042818705} | train loss {'Reaction outcome loss': 0.12524965996618656, 'Total loss': 0.12524965996618656}
2022-12-31 09:02:34,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:34,669 INFO:     Epoch: 63
2022-12-31 09:02:36,299 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5135728577772777, 'Total loss': 0.5135728577772777} | train loss {'Reaction outcome loss': 0.12331644304446365, 'Total loss': 0.12331644304446365}
2022-12-31 09:02:36,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:36,299 INFO:     Epoch: 64
2022-12-31 09:02:37,935 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47558720856904985, 'Total loss': 0.47558720856904985} | train loss {'Reaction outcome loss': 0.12450567897432736, 'Total loss': 0.12450567897432736}
2022-12-31 09:02:37,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:37,935 INFO:     Epoch: 65
2022-12-31 09:02:39,613 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.490429059167703, 'Total loss': 0.490429059167703} | train loss {'Reaction outcome loss': 0.12455917801707983, 'Total loss': 0.12455917801707983}
2022-12-31 09:02:39,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:39,614 INFO:     Epoch: 66
2022-12-31 09:02:41,244 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4883784284194311, 'Total loss': 0.4883784284194311} | train loss {'Reaction outcome loss': 0.12982545684290114, 'Total loss': 0.12982545684290114}
2022-12-31 09:02:41,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:41,245 INFO:     Epoch: 67
2022-12-31 09:02:42,876 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5017451028029124, 'Total loss': 0.5017451028029124} | train loss {'Reaction outcome loss': 0.1225523447150546, 'Total loss': 0.1225523447150546}
2022-12-31 09:02:42,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:42,877 INFO:     Epoch: 68
2022-12-31 09:02:44,572 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49754911263783774, 'Total loss': 0.49754911263783774} | train loss {'Reaction outcome loss': 0.12747593623811265, 'Total loss': 0.12747593623811265}
2022-12-31 09:02:44,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:44,572 INFO:     Epoch: 69
2022-12-31 09:02:46,199 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49937603970368705, 'Total loss': 0.49937603970368705} | train loss {'Reaction outcome loss': 0.12657296170383045, 'Total loss': 0.12657296170383045}
2022-12-31 09:02:46,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:46,199 INFO:     Epoch: 70
2022-12-31 09:02:47,868 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4833595871925354, 'Total loss': 0.4833595871925354} | train loss {'Reaction outcome loss': 0.12025963233461072, 'Total loss': 0.12025963233461072}
2022-12-31 09:02:47,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:47,868 INFO:     Epoch: 71
2022-12-31 09:02:49,489 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5093186189730962, 'Total loss': 0.5093186189730962} | train loss {'Reaction outcome loss': 0.11935511615214742, 'Total loss': 0.11935511615214742}
2022-12-31 09:02:49,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:49,490 INFO:     Epoch: 72
2022-12-31 09:02:51,122 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5282757600148519, 'Total loss': 0.5282757600148519} | train loss {'Reaction outcome loss': 0.11881264789023231, 'Total loss': 0.11881264789023231}
2022-12-31 09:02:51,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:51,122 INFO:     Epoch: 73
2022-12-31 09:02:52,758 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5048371891180674, 'Total loss': 0.5048371891180674} | train loss {'Reaction outcome loss': 0.11845097276264473, 'Total loss': 0.11845097276264473}
2022-12-31 09:02:52,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:52,759 INFO:     Epoch: 74
2022-12-31 09:02:54,391 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4741973340511322, 'Total loss': 0.4741973340511322} | train loss {'Reaction outcome loss': 0.11703129379593159, 'Total loss': 0.11703129379593159}
2022-12-31 09:02:54,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:54,391 INFO:     Epoch: 75
2022-12-31 09:02:56,025 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5032431443532308, 'Total loss': 0.5032431443532308} | train loss {'Reaction outcome loss': 0.11745299663670387, 'Total loss': 0.11745299663670387}
2022-12-31 09:02:56,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:56,025 INFO:     Epoch: 76
2022-12-31 09:02:57,657 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4960038433472315, 'Total loss': 0.4960038433472315} | train loss {'Reaction outcome loss': 0.11901573559087751, 'Total loss': 0.11901573559087751}
2022-12-31 09:02:57,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:57,657 INFO:     Epoch: 77
2022-12-31 09:02:59,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.511539467672507, 'Total loss': 0.511539467672507} | train loss {'Reaction outcome loss': 0.12410611355011536, 'Total loss': 0.12410611355011536}
2022-12-31 09:02:59,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:02:59,312 INFO:     Epoch: 78
2022-12-31 09:03:00,981 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.506192280848821, 'Total loss': 0.506192280848821} | train loss {'Reaction outcome loss': 0.12186652890134213, 'Total loss': 0.12186652890134213}
2022-12-31 09:03:00,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:00,981 INFO:     Epoch: 79
2022-12-31 09:03:02,608 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4920724113782247, 'Total loss': 0.4920724113782247} | train loss {'Reaction outcome loss': 0.11488708843719148, 'Total loss': 0.11488708843719148}
2022-12-31 09:03:02,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:02,609 INFO:     Epoch: 80
2022-12-31 09:03:04,276 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48845567206541696, 'Total loss': 0.48845567206541696} | train loss {'Reaction outcome loss': 0.11713816365857511, 'Total loss': 0.11713816365857511}
2022-12-31 09:03:04,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:04,278 INFO:     Epoch: 81
2022-12-31 09:03:05,901 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5110842486222585, 'Total loss': 0.5110842486222585} | train loss {'Reaction outcome loss': 0.12045605792848911, 'Total loss': 0.12045605792848911}
2022-12-31 09:03:05,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:05,901 INFO:     Epoch: 82
2022-12-31 09:03:07,523 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49525234699249265, 'Total loss': 0.49525234699249265} | train loss {'Reaction outcome loss': 0.11776766606643527, 'Total loss': 0.11776766606643527}
2022-12-31 09:03:07,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:07,524 INFO:     Epoch: 83
2022-12-31 09:03:09,157 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5016746823986371, 'Total loss': 0.5016746823986371} | train loss {'Reaction outcome loss': 0.115931781610669, 'Total loss': 0.115931781610669}
2022-12-31 09:03:09,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:09,157 INFO:     Epoch: 84
2022-12-31 09:03:10,791 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.459695087124904, 'Total loss': 0.459695087124904} | train loss {'Reaction outcome loss': 0.11690603557214249, 'Total loss': 0.11690603557214249}
2022-12-31 09:03:10,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:10,792 INFO:     Epoch: 85
2022-12-31 09:03:12,421 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.534857287009557, 'Total loss': 0.534857287009557} | train loss {'Reaction outcome loss': 0.12007286157190046, 'Total loss': 0.12007286157190046}
2022-12-31 09:03:12,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:12,422 INFO:     Epoch: 86
2022-12-31 09:03:14,054 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.482574259241422, 'Total loss': 0.482574259241422} | train loss {'Reaction outcome loss': 0.11696856206918424, 'Total loss': 0.11696856206918424}
2022-12-31 09:03:14,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:14,055 INFO:     Epoch: 87
2022-12-31 09:03:15,678 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4861471434434255, 'Total loss': 0.4861471434434255} | train loss {'Reaction outcome loss': 0.11735178859541294, 'Total loss': 0.11735178859541294}
2022-12-31 09:03:15,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:15,678 INFO:     Epoch: 88
2022-12-31 09:03:17,337 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4988791195054849, 'Total loss': 0.4988791195054849} | train loss {'Reaction outcome loss': 0.10992252899397716, 'Total loss': 0.10992252899397716}
2022-12-31 09:03:17,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:17,337 INFO:     Epoch: 89
2022-12-31 09:03:18,961 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4788454115390778, 'Total loss': 0.4788454115390778} | train loss {'Reaction outcome loss': 0.11509622043059191, 'Total loss': 0.11509622043059191}
2022-12-31 09:03:18,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:18,961 INFO:     Epoch: 90
2022-12-31 09:03:20,586 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.486142705877622, 'Total loss': 0.486142705877622} | train loss {'Reaction outcome loss': 0.11498550306972022, 'Total loss': 0.11498550306972022}
2022-12-31 09:03:20,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:20,586 INFO:     Epoch: 91
2022-12-31 09:03:22,208 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5220796058575312, 'Total loss': 0.5220796058575312} | train loss {'Reaction outcome loss': 0.1149139755106252, 'Total loss': 0.1149139755106252}
2022-12-31 09:03:22,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:22,208 INFO:     Epoch: 92
2022-12-31 09:03:23,827 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48685061633586885, 'Total loss': 0.48685061633586885} | train loss {'Reaction outcome loss': 0.11393259385422491, 'Total loss': 0.11393259385422491}
2022-12-31 09:03:23,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:23,828 INFO:     Epoch: 93
2022-12-31 09:03:25,435 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4946108420689901, 'Total loss': 0.4946108420689901} | train loss {'Reaction outcome loss': 0.11131956993218928, 'Total loss': 0.11131956993218928}
2022-12-31 09:03:25,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:25,435 INFO:     Epoch: 94
2022-12-31 09:03:27,066 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46702101131280266, 'Total loss': 0.46702101131280266} | train loss {'Reaction outcome loss': 0.11440459042972471, 'Total loss': 0.11440459042972471}
2022-12-31 09:03:27,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:27,067 INFO:     Epoch: 95
2022-12-31 09:03:28,703 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5293377031882603, 'Total loss': 0.5293377031882603} | train loss {'Reaction outcome loss': 0.1178053638549851, 'Total loss': 0.1178053638549851}
2022-12-31 09:03:28,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:28,703 INFO:     Epoch: 96
2022-12-31 09:03:30,337 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5340449154376984, 'Total loss': 0.5340449154376984} | train loss {'Reaction outcome loss': 0.12096022040203268, 'Total loss': 0.12096022040203268}
2022-12-31 09:03:30,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:30,337 INFO:     Epoch: 97
2022-12-31 09:03:31,975 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48990214268366494, 'Total loss': 0.48990214268366494} | train loss {'Reaction outcome loss': 0.11400818690617269, 'Total loss': 0.11400818690617269}
2022-12-31 09:03:31,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:31,976 INFO:     Epoch: 98
2022-12-31 09:03:33,608 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5080710103114446, 'Total loss': 0.5080710103114446} | train loss {'Reaction outcome loss': 0.11263876967132092, 'Total loss': 0.11263876967132092}
2022-12-31 09:03:33,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:33,609 INFO:     Epoch: 99
2022-12-31 09:03:35,230 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.511245055993398, 'Total loss': 0.511245055993398} | train loss {'Reaction outcome loss': 0.10924268281759715, 'Total loss': 0.10924268281759715}
2022-12-31 09:03:35,230 INFO:     Best model found after epoch 12 of 100.
2022-12-31 09:03:35,230 INFO:   Done with stage: TRAINING
2022-12-31 09:03:35,231 INFO:   Starting stage: EVALUATION
2022-12-31 09:03:35,356 INFO:   Done with stage: EVALUATION
2022-12-31 09:03:35,365 INFO:   Leaving out SEQ value Fold_0
2022-12-31 09:03:35,378 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:03:35,378 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:03:36,030 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:03:36,030 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:03:36,097 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:03:36,098 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:03:36,098 INFO:     No hyperparam tuning for this model
2022-12-31 09:03:36,098 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:03:36,098 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:03:36,098 INFO:     None feature selector for col prot
2022-12-31 09:03:36,099 INFO:     None feature selector for col prot
2022-12-31 09:03:36,099 INFO:     None feature selector for col prot
2022-12-31 09:03:36,099 INFO:     None feature selector for col chem
2022-12-31 09:03:36,099 INFO:     None feature selector for col chem
2022-12-31 09:03:36,099 INFO:     None feature selector for col chem
2022-12-31 09:03:36,099 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:03:36,100 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:03:36,101 INFO:     Number of params in model 224011
2022-12-31 09:03:36,105 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:03:36,105 INFO:   Starting stage: TRAINING
2022-12-31 09:03:36,150 INFO:     Val loss before train {'Reaction outcome loss': 0.9512225111325582, 'Total loss': 0.9512225111325582}
2022-12-31 09:03:36,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:36,150 INFO:     Epoch: 0
2022-12-31 09:03:37,770 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5950754284858704, 'Total loss': 0.5950754284858704} | train loss {'Reaction outcome loss': 0.7962840299891389, 'Total loss': 0.7962840299891389}
2022-12-31 09:03:37,770 INFO:     Found new best model at epoch 0
2022-12-31 09:03:37,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:37,771 INFO:     Epoch: 1
2022-12-31 09:03:39,386 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5158156126737594, 'Total loss': 0.5158156126737594} | train loss {'Reaction outcome loss': 0.5276927144631095, 'Total loss': 0.5276927144631095}
2022-12-31 09:03:39,388 INFO:     Found new best model at epoch 1
2022-12-31 09:03:39,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:39,389 INFO:     Epoch: 2
2022-12-31 09:03:41,050 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49032127658526103, 'Total loss': 0.49032127658526103} | train loss {'Reaction outcome loss': 0.45272690235920576, 'Total loss': 0.45272690235920576}
2022-12-31 09:03:41,050 INFO:     Found new best model at epoch 2
2022-12-31 09:03:41,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:41,051 INFO:     Epoch: 3
2022-12-31 09:03:42,666 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4819601058959961, 'Total loss': 0.4819601058959961} | train loss {'Reaction outcome loss': 0.40426499401961546, 'Total loss': 0.40426499401961546}
2022-12-31 09:03:42,666 INFO:     Found new best model at epoch 3
2022-12-31 09:03:42,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:42,667 INFO:     Epoch: 4
2022-12-31 09:03:44,289 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4846582919359207, 'Total loss': 0.4846582919359207} | train loss {'Reaction outcome loss': 0.38000113724906376, 'Total loss': 0.38000113724906376}
2022-12-31 09:03:44,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:44,289 INFO:     Epoch: 5
2022-12-31 09:03:45,911 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.474979422489802, 'Total loss': 0.474979422489802} | train loss {'Reaction outcome loss': 0.3562624637164898, 'Total loss': 0.3562624637164898}
2022-12-31 09:03:45,912 INFO:     Found new best model at epoch 5
2022-12-31 09:03:45,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:45,913 INFO:     Epoch: 6
2022-12-31 09:03:47,529 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4427976429462433, 'Total loss': 0.4427976429462433} | train loss {'Reaction outcome loss': 0.33068691997154465, 'Total loss': 0.33068691997154465}
2022-12-31 09:03:47,529 INFO:     Found new best model at epoch 6
2022-12-31 09:03:47,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:47,530 INFO:     Epoch: 7
2022-12-31 09:03:49,146 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4475543181101481, 'Total loss': 0.4475543181101481} | train loss {'Reaction outcome loss': 0.3116200514259222, 'Total loss': 0.3116200514259222}
2022-12-31 09:03:49,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:49,146 INFO:     Epoch: 8
2022-12-31 09:03:50,824 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4456698834896088, 'Total loss': 0.4456698834896088} | train loss {'Reaction outcome loss': 0.2972505940337399, 'Total loss': 0.2972505940337399}
2022-12-31 09:03:50,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:50,824 INFO:     Epoch: 9
2022-12-31 09:03:52,456 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46203482846419014, 'Total loss': 0.46203482846419014} | train loss {'Reaction outcome loss': 0.2845111202627447, 'Total loss': 0.2845111202627447}
2022-12-31 09:03:52,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:52,456 INFO:     Epoch: 10
2022-12-31 09:03:54,077 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4753688295682271, 'Total loss': 0.4753688295682271} | train loss {'Reaction outcome loss': 0.27167323278926714, 'Total loss': 0.27167323278926714}
2022-12-31 09:03:54,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:54,077 INFO:     Epoch: 11
2022-12-31 09:03:55,739 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44786368956168493, 'Total loss': 0.44786368956168493} | train loss {'Reaction outcome loss': 0.2627677650163895, 'Total loss': 0.2627677650163895}
2022-12-31 09:03:55,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:55,739 INFO:     Epoch: 12
2022-12-31 09:03:57,401 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44004552041490874, 'Total loss': 0.44004552041490874} | train loss {'Reaction outcome loss': 0.2704562158441927, 'Total loss': 0.2704562158441927}
2022-12-31 09:03:57,401 INFO:     Found new best model at epoch 12
2022-12-31 09:03:57,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:57,402 INFO:     Epoch: 13
2022-12-31 09:03:59,022 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4315932273864746, 'Total loss': 0.4315932273864746} | train loss {'Reaction outcome loss': 0.24020456713144772, 'Total loss': 0.24020456713144772}
2022-12-31 09:03:59,023 INFO:     Found new best model at epoch 13
2022-12-31 09:03:59,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:03:59,024 INFO:     Epoch: 14
2022-12-31 09:04:00,637 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4582825591166814, 'Total loss': 0.4582825591166814} | train loss {'Reaction outcome loss': 0.23023893765808232, 'Total loss': 0.23023893765808232}
2022-12-31 09:04:00,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:00,637 INFO:     Epoch: 15
2022-12-31 09:04:02,248 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4374682784080505, 'Total loss': 0.4374682784080505} | train loss {'Reaction outcome loss': 0.2240487990151767, 'Total loss': 0.2240487990151767}
2022-12-31 09:04:02,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:02,248 INFO:     Epoch: 16
2022-12-31 09:04:03,875 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4393627991278966, 'Total loss': 0.4393627991278966} | train loss {'Reaction outcome loss': 0.2152987919356404, 'Total loss': 0.2152987919356404}
2022-12-31 09:04:03,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:03,875 INFO:     Epoch: 17
2022-12-31 09:04:05,502 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4671505192915599, 'Total loss': 0.4671505192915599} | train loss {'Reaction outcome loss': 0.20948995011386232, 'Total loss': 0.20948995011386232}
2022-12-31 09:04:05,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:05,502 INFO:     Epoch: 18
2022-12-31 09:04:07,130 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46476344267527264, 'Total loss': 0.46476344267527264} | train loss {'Reaction outcome loss': 0.20810705390961273, 'Total loss': 0.20810705390961273}
2022-12-31 09:04:07,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:07,130 INFO:     Epoch: 19
2022-12-31 09:04:08,756 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4695645252863566, 'Total loss': 0.4695645252863566} | train loss {'Reaction outcome loss': 0.21608756393855572, 'Total loss': 0.21608756393855572}
2022-12-31 09:04:08,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:08,756 INFO:     Epoch: 20
2022-12-31 09:04:10,364 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46968398094177244, 'Total loss': 0.46968398094177244} | train loss {'Reaction outcome loss': 0.1987914307096946, 'Total loss': 0.1987914307096946}
2022-12-31 09:04:10,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:10,365 INFO:     Epoch: 21
2022-12-31 09:04:11,988 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.467138534784317, 'Total loss': 0.467138534784317} | train loss {'Reaction outcome loss': 0.18855412726870913, 'Total loss': 0.18855412726870913}
2022-12-31 09:04:11,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:11,988 INFO:     Epoch: 22
2022-12-31 09:04:13,613 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4387918909390767, 'Total loss': 0.4387918909390767} | train loss {'Reaction outcome loss': 0.18768486509499938, 'Total loss': 0.18768486509499938}
2022-12-31 09:04:13,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:13,613 INFO:     Epoch: 23
2022-12-31 09:04:15,235 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4431492269039154, 'Total loss': 0.4431492269039154} | train loss {'Reaction outcome loss': 0.18624751626571262, 'Total loss': 0.18624751626571262}
2022-12-31 09:04:15,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:15,235 INFO:     Epoch: 24
2022-12-31 09:04:16,896 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4485172539949417, 'Total loss': 0.4485172539949417} | train loss {'Reaction outcome loss': 0.17786444357150924, 'Total loss': 0.17786444357150924}
2022-12-31 09:04:16,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:16,897 INFO:     Epoch: 25
2022-12-31 09:04:18,514 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43655412991841636, 'Total loss': 0.43655412991841636} | train loss {'Reaction outcome loss': 0.194174834203137, 'Total loss': 0.194174834203137}
2022-12-31 09:04:18,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:18,514 INFO:     Epoch: 26
2022-12-31 09:04:20,122 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.431171449025472, 'Total loss': 0.431171449025472} | train loss {'Reaction outcome loss': 0.20609718094161456, 'Total loss': 0.20609718094161456}
2022-12-31 09:04:20,122 INFO:     Found new best model at epoch 26
2022-12-31 09:04:20,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:20,123 INFO:     Epoch: 27
2022-12-31 09:04:21,748 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4404131054878235, 'Total loss': 0.4404131054878235} | train loss {'Reaction outcome loss': 0.17579464921710905, 'Total loss': 0.17579464921710905}
2022-12-31 09:04:21,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:21,748 INFO:     Epoch: 28
2022-12-31 09:04:23,395 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45521245499451957, 'Total loss': 0.45521245499451957} | train loss {'Reaction outcome loss': 0.16631659692591158, 'Total loss': 0.16631659692591158}
2022-12-31 09:04:23,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:23,396 INFO:     Epoch: 29
2022-12-31 09:04:25,058 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4981443673372269, 'Total loss': 0.4981443673372269} | train loss {'Reaction outcome loss': 0.16355138084759346, 'Total loss': 0.16355138084759346}
2022-12-31 09:04:25,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:25,058 INFO:     Epoch: 30
2022-12-31 09:04:26,687 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4530761828025182, 'Total loss': 0.4530761828025182} | train loss {'Reaction outcome loss': 0.16429960965246393, 'Total loss': 0.16429960965246393}
2022-12-31 09:04:26,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:26,687 INFO:     Epoch: 31
2022-12-31 09:04:28,246 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4438954293727875, 'Total loss': 0.4438954293727875} | train loss {'Reaction outcome loss': 0.16088651474464036, 'Total loss': 0.16088651474464036}
2022-12-31 09:04:28,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:28,246 INFO:     Epoch: 32
2022-12-31 09:04:29,372 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46361476282278696, 'Total loss': 0.46361476282278696} | train loss {'Reaction outcome loss': 0.15658554652195628, 'Total loss': 0.15658554652195628}
2022-12-31 09:04:29,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:29,373 INFO:     Epoch: 33
2022-12-31 09:04:30,485 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4206070738534133, 'Total loss': 0.4206070738534133} | train loss {'Reaction outcome loss': 0.15665285662660186, 'Total loss': 0.15665285662660186}
2022-12-31 09:04:30,485 INFO:     Found new best model at epoch 33
2022-12-31 09:04:30,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:30,486 INFO:     Epoch: 34
2022-12-31 09:04:31,605 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4457927763462067, 'Total loss': 0.4457927763462067} | train loss {'Reaction outcome loss': 0.15674179215014758, 'Total loss': 0.15674179215014758}
2022-12-31 09:04:31,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:31,605 INFO:     Epoch: 35
2022-12-31 09:04:32,753 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4273360421260198, 'Total loss': 0.4273360421260198} | train loss {'Reaction outcome loss': 0.15764037110721288, 'Total loss': 0.15764037110721288}
2022-12-31 09:04:32,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:32,754 INFO:     Epoch: 36
2022-12-31 09:04:34,406 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4028211961189906, 'Total loss': 0.4028211961189906} | train loss {'Reaction outcome loss': 0.15236564201262334, 'Total loss': 0.15236564201262334}
2022-12-31 09:04:34,406 INFO:     Found new best model at epoch 36
2022-12-31 09:04:34,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:34,407 INFO:     Epoch: 37
2022-12-31 09:04:36,022 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44002797702948254, 'Total loss': 0.44002797702948254} | train loss {'Reaction outcome loss': 0.1518890996011433, 'Total loss': 0.1518890996011433}
2022-12-31 09:04:36,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:36,022 INFO:     Epoch: 38
2022-12-31 09:04:37,682 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41879086308181285, 'Total loss': 0.41879086308181285} | train loss {'Reaction outcome loss': 0.15341807132548033, 'Total loss': 0.15341807132548033}
2022-12-31 09:04:37,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:37,682 INFO:     Epoch: 39
2022-12-31 09:04:39,343 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4233425552646319, 'Total loss': 0.4233425552646319} | train loss {'Reaction outcome loss': 0.1491212431607984, 'Total loss': 0.1491212431607984}
2022-12-31 09:04:39,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:39,343 INFO:     Epoch: 40
2022-12-31 09:04:40,967 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43240633110205334, 'Total loss': 0.43240633110205334} | train loss {'Reaction outcome loss': 0.14577784881544506, 'Total loss': 0.14577784881544506}
2022-12-31 09:04:40,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:40,969 INFO:     Epoch: 41
2022-12-31 09:04:42,579 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.424083677927653, 'Total loss': 0.424083677927653} | train loss {'Reaction outcome loss': 0.14185008979947653, 'Total loss': 0.14185008979947653}
2022-12-31 09:04:42,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:42,579 INFO:     Epoch: 42
2022-12-31 09:04:44,240 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4209589252869288, 'Total loss': 0.4209589252869288} | train loss {'Reaction outcome loss': 0.1465287780361984, 'Total loss': 0.1465287780361984}
2022-12-31 09:04:44,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:44,240 INFO:     Epoch: 43
2022-12-31 09:04:45,867 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4640864203373591, 'Total loss': 0.4640864203373591} | train loss {'Reaction outcome loss': 0.14562732423318253, 'Total loss': 0.14562732423318253}
2022-12-31 09:04:45,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:45,867 INFO:     Epoch: 44
2022-12-31 09:04:47,529 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4155075967311859, 'Total loss': 0.4155075967311859} | train loss {'Reaction outcome loss': 0.14338368884510483, 'Total loss': 0.14338368884510483}
2022-12-31 09:04:47,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:47,530 INFO:     Epoch: 45
2022-12-31 09:04:49,152 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4456301728884379, 'Total loss': 0.4456301728884379} | train loss {'Reaction outcome loss': 0.13995169408609281, 'Total loss': 0.13995169408609281}
2022-12-31 09:04:49,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:49,152 INFO:     Epoch: 46
2022-12-31 09:04:50,770 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4350594719250997, 'Total loss': 0.4350594719250997} | train loss {'Reaction outcome loss': 0.13686765856457409, 'Total loss': 0.13686765856457409}
2022-12-31 09:04:50,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:50,770 INFO:     Epoch: 47
2022-12-31 09:04:52,417 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43373017460107804, 'Total loss': 0.43373017460107804} | train loss {'Reaction outcome loss': 0.13785381771083724, 'Total loss': 0.13785381771083724}
2022-12-31 09:04:52,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:52,417 INFO:     Epoch: 48
2022-12-31 09:04:54,069 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4577130228281021, 'Total loss': 0.4577130228281021} | train loss {'Reaction outcome loss': 0.13876286906652505, 'Total loss': 0.13876286906652505}
2022-12-31 09:04:54,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:54,069 INFO:     Epoch: 49
2022-12-31 09:04:55,695 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43864176074663797, 'Total loss': 0.43864176074663797} | train loss {'Reaction outcome loss': 0.13833148255429661, 'Total loss': 0.13833148255429661}
2022-12-31 09:04:55,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:55,696 INFO:     Epoch: 50
2022-12-31 09:04:57,324 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.452994079887867, 'Total loss': 0.452994079887867} | train loss {'Reaction outcome loss': 0.13626406532864127, 'Total loss': 0.13626406532864127}
2022-12-31 09:04:57,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:57,324 INFO:     Epoch: 51
2022-12-31 09:04:58,949 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43943914771080017, 'Total loss': 0.43943914771080017} | train loss {'Reaction outcome loss': 0.13748279972460822, 'Total loss': 0.13748279972460822}
2022-12-31 09:04:58,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:04:58,949 INFO:     Epoch: 52
2022-12-31 09:05:00,571 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42563414176305137, 'Total loss': 0.42563414176305137} | train loss {'Reaction outcome loss': 0.13923261064253206, 'Total loss': 0.13923261064253206}
2022-12-31 09:05:00,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:00,572 INFO:     Epoch: 53
2022-12-31 09:05:02,182 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43703612784544627, 'Total loss': 0.43703612784544627} | train loss {'Reaction outcome loss': 0.13625188469439678, 'Total loss': 0.13625188469439678}
2022-12-31 09:05:02,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:02,182 INFO:     Epoch: 54
2022-12-31 09:05:03,813 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4731263776620229, 'Total loss': 0.4731263776620229} | train loss {'Reaction outcome loss': 0.12847068624071561, 'Total loss': 0.12847068624071561}
2022-12-31 09:05:03,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:03,814 INFO:     Epoch: 55
2022-12-31 09:05:05,424 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4296535144249598, 'Total loss': 0.4296535144249598} | train loss {'Reaction outcome loss': 0.1288031971411513, 'Total loss': 0.1288031971411513}
2022-12-31 09:05:05,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:05,424 INFO:     Epoch: 56
2022-12-31 09:05:07,034 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44854119916756946, 'Total loss': 0.44854119916756946} | train loss {'Reaction outcome loss': 0.1303322666267311, 'Total loss': 0.1303322666267311}
2022-12-31 09:05:07,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:07,034 INFO:     Epoch: 57
2022-12-31 09:05:08,644 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4394955813884735, 'Total loss': 0.4394955813884735} | train loss {'Reaction outcome loss': 0.13225568305706079, 'Total loss': 0.13225568305706079}
2022-12-31 09:05:08,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:08,644 INFO:     Epoch: 58
2022-12-31 09:05:10,256 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41283560593922936, 'Total loss': 0.41283560593922936} | train loss {'Reaction outcome loss': 0.12857704051851254, 'Total loss': 0.12857704051851254}
2022-12-31 09:05:10,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:10,256 INFO:     Epoch: 59
2022-12-31 09:05:11,878 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45176680088043214, 'Total loss': 0.45176680088043214} | train loss {'Reaction outcome loss': 0.12717428834403635, 'Total loss': 0.12717428834403635}
2022-12-31 09:05:11,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:11,879 INFO:     Epoch: 60
2022-12-31 09:05:13,499 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.465030312538147, 'Total loss': 0.465030312538147} | train loss {'Reaction outcome loss': 0.12473945559569351, 'Total loss': 0.12473945559569351}
2022-12-31 09:05:13,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:13,499 INFO:     Epoch: 61
2022-12-31 09:05:15,123 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40828329424063364, 'Total loss': 0.40828329424063364} | train loss {'Reaction outcome loss': 0.12600716177552965, 'Total loss': 0.12600716177552965}
2022-12-31 09:05:15,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:15,124 INFO:     Epoch: 62
2022-12-31 09:05:16,749 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42796292106310524, 'Total loss': 0.42796292106310524} | train loss {'Reaction outcome loss': 0.12526368191491044, 'Total loss': 0.12526368191491044}
2022-12-31 09:05:16,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:16,750 INFO:     Epoch: 63
2022-12-31 09:05:18,367 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44219297369321187, 'Total loss': 0.44219297369321187} | train loss {'Reaction outcome loss': 0.1284632067385035, 'Total loss': 0.1284632067385035}
2022-12-31 09:05:18,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:18,368 INFO:     Epoch: 64
2022-12-31 09:05:20,021 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43644663095474245, 'Total loss': 0.43644663095474245} | train loss {'Reaction outcome loss': 0.12420300389319469, 'Total loss': 0.12420300389319469}
2022-12-31 09:05:20,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:20,022 INFO:     Epoch: 65
2022-12-31 09:05:21,658 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4240605661800752, 'Total loss': 0.4240605661800752} | train loss {'Reaction outcome loss': 0.12336144093980851, 'Total loss': 0.12336144093980851}
2022-12-31 09:05:21,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:21,659 INFO:     Epoch: 66
2022-12-31 09:05:23,281 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41352907319863635, 'Total loss': 0.41352907319863635} | train loss {'Reaction outcome loss': 0.12312107648113338, 'Total loss': 0.12312107648113338}
2022-12-31 09:05:23,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:23,281 INFO:     Epoch: 67
2022-12-31 09:05:24,908 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4331254700819651, 'Total loss': 0.4331254700819651} | train loss {'Reaction outcome loss': 0.12535312823424843, 'Total loss': 0.12535312823424843}
2022-12-31 09:05:24,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:24,908 INFO:     Epoch: 68
2022-12-31 09:05:26,535 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44763926764329276, 'Total loss': 0.44763926764329276} | train loss {'Reaction outcome loss': 0.12224463577908666, 'Total loss': 0.12224463577908666}
2022-12-31 09:05:26,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:26,535 INFO:     Epoch: 69
2022-12-31 09:05:28,153 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47820791602134705, 'Total loss': 0.47820791602134705} | train loss {'Reaction outcome loss': 0.1346172156720085, 'Total loss': 0.1346172156720085}
2022-12-31 09:05:28,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:28,153 INFO:     Epoch: 70
2022-12-31 09:05:29,770 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45012181003888446, 'Total loss': 0.45012181003888446} | train loss {'Reaction outcome loss': 0.1300525150305686, 'Total loss': 0.1300525150305686}
2022-12-31 09:05:29,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:29,770 INFO:     Epoch: 71
2022-12-31 09:05:31,389 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4237770030895869, 'Total loss': 0.4237770030895869} | train loss {'Reaction outcome loss': 0.120844031925064, 'Total loss': 0.120844031925064}
2022-12-31 09:05:31,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:31,390 INFO:     Epoch: 72
2022-12-31 09:05:33,017 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4360014726718267, 'Total loss': 0.4360014726718267} | train loss {'Reaction outcome loss': 0.11744006120420965, 'Total loss': 0.11744006120420965}
2022-12-31 09:05:33,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:33,017 INFO:     Epoch: 73
2022-12-31 09:05:34,643 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4199629892905553, 'Total loss': 0.4199629892905553} | train loss {'Reaction outcome loss': 0.12405774920024788, 'Total loss': 0.12405774920024788}
2022-12-31 09:05:34,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:34,643 INFO:     Epoch: 74
2022-12-31 09:05:36,268 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4254684458176295, 'Total loss': 0.4254684458176295} | train loss {'Reaction outcome loss': 0.1455694286673795, 'Total loss': 0.1455694286673795}
2022-12-31 09:05:36,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:36,268 INFO:     Epoch: 75
2022-12-31 09:05:37,879 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4488861173391342, 'Total loss': 0.4488861173391342} | train loss {'Reaction outcome loss': 0.12194097360454338, 'Total loss': 0.12194097360454338}
2022-12-31 09:05:37,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:37,879 INFO:     Epoch: 76
2022-12-31 09:05:39,505 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43343612253665925, 'Total loss': 0.43343612253665925} | train loss {'Reaction outcome loss': 0.11626927619600673, 'Total loss': 0.11626927619600673}
2022-12-31 09:05:39,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:39,506 INFO:     Epoch: 77
2022-12-31 09:05:41,183 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4467199265956879, 'Total loss': 0.4467199265956879} | train loss {'Reaction outcome loss': 0.11371904430869609, 'Total loss': 0.11371904430869609}
2022-12-31 09:05:41,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:41,183 INFO:     Epoch: 78
2022-12-31 09:05:42,846 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43004436095555626, 'Total loss': 0.43004436095555626} | train loss {'Reaction outcome loss': 0.1140362498116095, 'Total loss': 0.1140362498116095}
2022-12-31 09:05:42,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:42,848 INFO:     Epoch: 79
2022-12-31 09:05:44,468 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44927257200082144, 'Total loss': 0.44927257200082144} | train loss {'Reaction outcome loss': 0.11213861349476603, 'Total loss': 0.11213861349476603}
2022-12-31 09:05:44,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:44,468 INFO:     Epoch: 80
2022-12-31 09:05:46,109 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4461220194896062, 'Total loss': 0.4461220194896062} | train loss {'Reaction outcome loss': 0.11731817895152757, 'Total loss': 0.11731817895152757}
2022-12-31 09:05:46,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:46,109 INFO:     Epoch: 81
2022-12-31 09:05:47,771 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4344986130793889, 'Total loss': 0.4344986130793889} | train loss {'Reaction outcome loss': 0.1160283544009028, 'Total loss': 0.1160283544009028}
2022-12-31 09:05:47,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:47,771 INFO:     Epoch: 82
2022-12-31 09:05:49,401 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4316182802120844, 'Total loss': 0.4316182802120844} | train loss {'Reaction outcome loss': 0.11945387870123934, 'Total loss': 0.11945387870123934}
2022-12-31 09:05:49,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:49,402 INFO:     Epoch: 83
2022-12-31 09:05:51,022 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42913255939881007, 'Total loss': 0.42913255939881007} | train loss {'Reaction outcome loss': 0.11804242628711992, 'Total loss': 0.11804242628711992}
2022-12-31 09:05:51,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:51,023 INFO:     Epoch: 84
2022-12-31 09:05:52,646 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42552664820104835, 'Total loss': 0.42552664820104835} | train loss {'Reaction outcome loss': 0.11531976215840185, 'Total loss': 0.11531976215840185}
2022-12-31 09:05:52,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:52,646 INFO:     Epoch: 85
2022-12-31 09:05:54,273 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4483788470427195, 'Total loss': 0.4483788470427195} | train loss {'Reaction outcome loss': 0.11331625171020489, 'Total loss': 0.11331625171020489}
2022-12-31 09:05:54,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:54,273 INFO:     Epoch: 86
2022-12-31 09:05:55,892 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4439871927102407, 'Total loss': 0.4439871927102407} | train loss {'Reaction outcome loss': 0.11565815635612639, 'Total loss': 0.11565815635612639}
2022-12-31 09:05:55,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:55,892 INFO:     Epoch: 87
2022-12-31 09:05:57,509 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43279856344064077, 'Total loss': 0.43279856344064077} | train loss {'Reaction outcome loss': 0.11429555623149297, 'Total loss': 0.11429555623149297}
2022-12-31 09:05:57,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:57,509 INFO:     Epoch: 88
2022-12-31 09:05:59,126 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43384677916765213, 'Total loss': 0.43384677916765213} | train loss {'Reaction outcome loss': 0.11540903607867907, 'Total loss': 0.11540903607867907}
2022-12-31 09:05:59,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:05:59,127 INFO:     Epoch: 89
2022-12-31 09:06:00,788 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4723818878332774, 'Total loss': 0.4723818878332774} | train loss {'Reaction outcome loss': 0.11646773770579771, 'Total loss': 0.11646773770579771}
2022-12-31 09:06:00,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:00,788 INFO:     Epoch: 90
2022-12-31 09:06:02,405 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44460545778274535, 'Total loss': 0.44460545778274535} | train loss {'Reaction outcome loss': 0.11557448482135838, 'Total loss': 0.11557448482135838}
2022-12-31 09:06:02,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:02,406 INFO:     Epoch: 91
2022-12-31 09:06:04,021 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4599495078126589, 'Total loss': 0.4599495078126589} | train loss {'Reaction outcome loss': 0.11154985503958743, 'Total loss': 0.11154985503958743}
2022-12-31 09:06:04,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:04,021 INFO:     Epoch: 92
2022-12-31 09:06:05,636 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4216423273086548, 'Total loss': 0.4216423273086548} | train loss {'Reaction outcome loss': 0.11073075255072858, 'Total loss': 0.11073075255072858}
2022-12-31 09:06:05,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:05,636 INFO:     Epoch: 93
2022-12-31 09:06:07,267 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44523955285549166, 'Total loss': 0.44523955285549166} | train loss {'Reaction outcome loss': 0.1112493504996271, 'Total loss': 0.1112493504996271}
2022-12-31 09:06:07,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:07,267 INFO:     Epoch: 94
2022-12-31 09:06:08,884 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4582644065221151, 'Total loss': 0.4582644065221151} | train loss {'Reaction outcome loss': 0.12777158351230394, 'Total loss': 0.12777158351230394}
2022-12-31 09:06:08,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:08,884 INFO:     Epoch: 95
2022-12-31 09:06:10,498 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4358971496423086, 'Total loss': 0.4358971496423086} | train loss {'Reaction outcome loss': 0.15819971053523646, 'Total loss': 0.15819971053523646}
2022-12-31 09:06:10,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:10,499 INFO:     Epoch: 96
2022-12-31 09:06:12,115 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45491156975428265, 'Total loss': 0.45491156975428265} | train loss {'Reaction outcome loss': 0.11518345441352036, 'Total loss': 0.11518345441352036}
2022-12-31 09:06:12,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:12,115 INFO:     Epoch: 97
2022-12-31 09:06:13,723 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44659554958343506, 'Total loss': 0.44659554958343506} | train loss {'Reaction outcome loss': 0.10814087224138928, 'Total loss': 0.10814087224138928}
2022-12-31 09:06:13,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:13,724 INFO:     Epoch: 98
2022-12-31 09:06:15,336 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4398369441429774, 'Total loss': 0.4398369441429774} | train loss {'Reaction outcome loss': 0.11111083441832359, 'Total loss': 0.11111083441832359}
2022-12-31 09:06:15,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:15,336 INFO:     Epoch: 99
2022-12-31 09:06:16,939 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44071930249532065, 'Total loss': 0.44071930249532065} | train loss {'Reaction outcome loss': 0.11216468052800233, 'Total loss': 0.11216468052800233}
2022-12-31 09:06:16,939 INFO:     Best model found after epoch 37 of 100.
2022-12-31 09:06:16,939 INFO:   Done with stage: TRAINING
2022-12-31 09:06:16,939 INFO:   Starting stage: EVALUATION
2022-12-31 09:06:17,070 INFO:   Done with stage: EVALUATION
2022-12-31 09:06:17,071 INFO:   Leaving out SEQ value Fold_1
2022-12-31 09:06:17,083 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:06:17,084 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:06:17,728 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:06:17,728 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:06:17,796 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:06:17,796 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:06:17,796 INFO:     No hyperparam tuning for this model
2022-12-31 09:06:17,796 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:06:17,796 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:06:17,797 INFO:     None feature selector for col prot
2022-12-31 09:06:17,797 INFO:     None feature selector for col prot
2022-12-31 09:06:17,797 INFO:     None feature selector for col prot
2022-12-31 09:06:17,798 INFO:     None feature selector for col chem
2022-12-31 09:06:17,798 INFO:     None feature selector for col chem
2022-12-31 09:06:17,798 INFO:     None feature selector for col chem
2022-12-31 09:06:17,798 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:06:17,798 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:06:17,800 INFO:     Number of params in model 224011
2022-12-31 09:06:17,803 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:06:17,803 INFO:   Starting stage: TRAINING
2022-12-31 09:06:17,847 INFO:     Val loss before train {'Reaction outcome loss': 0.9174919068813324, 'Total loss': 0.9174919068813324}
2022-12-31 09:06:17,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:17,847 INFO:     Epoch: 0
2022-12-31 09:06:19,467 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5059197584788004, 'Total loss': 0.5059197584788004} | train loss {'Reaction outcome loss': 0.7790591563975465, 'Total loss': 0.7790591563975465}
2022-12-31 09:06:19,467 INFO:     Found new best model at epoch 0
2022-12-31 09:06:19,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:19,468 INFO:     Epoch: 1
2022-12-31 09:06:21,096 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4211923638979594, 'Total loss': 0.4211923638979594} | train loss {'Reaction outcome loss': 0.5175271247500095, 'Total loss': 0.5175271247500095}
2022-12-31 09:06:21,096 INFO:     Found new best model at epoch 1
2022-12-31 09:06:21,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:21,097 INFO:     Epoch: 2
2022-12-31 09:06:22,715 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.38962848484516144, 'Total loss': 0.38962848484516144} | train loss {'Reaction outcome loss': 0.44783354828309646, 'Total loss': 0.44783354828309646}
2022-12-31 09:06:22,715 INFO:     Found new best model at epoch 2
2022-12-31 09:06:22,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:22,716 INFO:     Epoch: 3
2022-12-31 09:06:24,340 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.39778076310952504, 'Total loss': 0.39778076310952504} | train loss {'Reaction outcome loss': 0.40686180302873254, 'Total loss': 0.40686180302873254}
2022-12-31 09:06:24,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:24,340 INFO:     Epoch: 4
2022-12-31 09:06:25,974 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3539639641841253, 'Total loss': 0.3539639641841253} | train loss {'Reaction outcome loss': 0.37784328915016807, 'Total loss': 0.37784328915016807}
2022-12-31 09:06:25,975 INFO:     Found new best model at epoch 4
2022-12-31 09:06:25,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:25,976 INFO:     Epoch: 5
2022-12-31 09:06:27,607 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.32382690012454984, 'Total loss': 0.32382690012454984} | train loss {'Reaction outcome loss': 0.35605210380120866, 'Total loss': 0.35605210380120866}
2022-12-31 09:06:27,607 INFO:     Found new best model at epoch 5
2022-12-31 09:06:27,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:27,608 INFO:     Epoch: 6
2022-12-31 09:06:29,236 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3251904437939326, 'Total loss': 0.3251904437939326} | train loss {'Reaction outcome loss': 0.338863460417707, 'Total loss': 0.338863460417707}
2022-12-31 09:06:29,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:29,236 INFO:     Epoch: 7
2022-12-31 09:06:30,857 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.32249679664770764, 'Total loss': 0.32249679664770764} | train loss {'Reaction outcome loss': 0.32089014025067614, 'Total loss': 0.32089014025067614}
2022-12-31 09:06:30,857 INFO:     Found new best model at epoch 7
2022-12-31 09:06:30,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:30,858 INFO:     Epoch: 8
2022-12-31 09:06:32,483 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.32576458404461545, 'Total loss': 0.32576458404461545} | train loss {'Reaction outcome loss': 0.3066545543006741, 'Total loss': 0.3066545543006741}
2022-12-31 09:06:32,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:32,483 INFO:     Epoch: 9
2022-12-31 09:06:34,103 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.35544820527235665, 'Total loss': 0.35544820527235665} | train loss {'Reaction outcome loss': 0.2931804930981541, 'Total loss': 0.2931804930981541}
2022-12-31 09:06:34,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:34,104 INFO:     Epoch: 10
2022-12-31 09:06:35,733 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3317187070846558, 'Total loss': 0.3317187070846558} | train loss {'Reaction outcome loss': 0.2921565389935521, 'Total loss': 0.2921565389935521}
2022-12-31 09:06:35,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:35,734 INFO:     Epoch: 11
2022-12-31 09:06:37,363 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.34114414354165395, 'Total loss': 0.34114414354165395} | train loss {'Reaction outcome loss': 0.29275786444423313, 'Total loss': 0.29275786444423313}
2022-12-31 09:06:37,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:37,363 INFO:     Epoch: 12
2022-12-31 09:06:38,992 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3307779391606649, 'Total loss': 0.3307779391606649} | train loss {'Reaction outcome loss': 0.2629826557468218, 'Total loss': 0.2629826557468218}
2022-12-31 09:06:38,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:38,992 INFO:     Epoch: 13
2022-12-31 09:06:40,614 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.32832712133725483, 'Total loss': 0.32832712133725483} | train loss {'Reaction outcome loss': 0.25228213049484877, 'Total loss': 0.25228213049484877}
2022-12-31 09:06:40,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:40,614 INFO:     Epoch: 14
2022-12-31 09:06:42,243 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.32700670858224234, 'Total loss': 0.32700670858224234} | train loss {'Reaction outcome loss': 0.24217031146500909, 'Total loss': 0.24217031146500909}
2022-12-31 09:06:42,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:42,244 INFO:     Epoch: 15
2022-12-31 09:06:43,867 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.325048041343689, 'Total loss': 0.325048041343689} | train loss {'Reaction outcome loss': 0.23640816472048964, 'Total loss': 0.23640816472048964}
2022-12-31 09:06:43,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:43,867 INFO:     Epoch: 16
2022-12-31 09:06:45,502 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3274718145529429, 'Total loss': 0.3274718145529429} | train loss {'Reaction outcome loss': 0.23940713995176813, 'Total loss': 0.23940713995176813}
2022-12-31 09:06:45,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:45,502 INFO:     Epoch: 17
2022-12-31 09:06:47,135 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.35664076705773673, 'Total loss': 0.35664076705773673} | train loss {'Reaction outcome loss': 0.2375839479019582, 'Total loss': 0.2375839479019582}
2022-12-31 09:06:47,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:47,135 INFO:     Epoch: 18
2022-12-31 09:06:48,768 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.36911399314800897, 'Total loss': 0.36911399314800897} | train loss {'Reaction outcome loss': 0.22300033593226387, 'Total loss': 0.22300033593226387}
2022-12-31 09:06:48,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:48,769 INFO:     Epoch: 19
2022-12-31 09:06:50,391 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.31570615867773694, 'Total loss': 0.31570615867773694} | train loss {'Reaction outcome loss': 0.22448613257554403, 'Total loss': 0.22448613257554403}
2022-12-31 09:06:50,391 INFO:     Found new best model at epoch 19
2022-12-31 09:06:50,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:50,393 INFO:     Epoch: 20
2022-12-31 09:06:52,022 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.31622230062882106, 'Total loss': 0.31622230062882106} | train loss {'Reaction outcome loss': 0.20665864812453155, 'Total loss': 0.20665864812453155}
2022-12-31 09:06:52,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:52,023 INFO:     Epoch: 21
2022-12-31 09:06:53,663 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.32950503875811893, 'Total loss': 0.32950503875811893} | train loss {'Reaction outcome loss': 0.20324914787467435, 'Total loss': 0.20324914787467435}
2022-12-31 09:06:53,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:53,663 INFO:     Epoch: 22
2022-12-31 09:06:55,328 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.33193003460764886, 'Total loss': 0.33193003460764886} | train loss {'Reaction outcome loss': 0.19563931405977253, 'Total loss': 0.19563931405977253}
2022-12-31 09:06:55,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:55,329 INFO:     Epoch: 23
2022-12-31 09:06:56,949 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.33963369727134707, 'Total loss': 0.33963369727134707} | train loss {'Reaction outcome loss': 0.19296919576911445, 'Total loss': 0.19296919576911445}
2022-12-31 09:06:56,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:56,949 INFO:     Epoch: 24
2022-12-31 09:06:58,593 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3410849690437317, 'Total loss': 0.3410849690437317} | train loss {'Reaction outcome loss': 0.1905035051311353, 'Total loss': 0.1905035051311353}
2022-12-31 09:06:58,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:06:58,593 INFO:     Epoch: 25
2022-12-31 09:07:00,259 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.31776097466548286, 'Total loss': 0.31776097466548286} | train loss {'Reaction outcome loss': 0.183597790257435, 'Total loss': 0.183597790257435}
2022-12-31 09:07:00,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:00,259 INFO:     Epoch: 26
2022-12-31 09:07:01,911 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3619058832526207, 'Total loss': 0.3619058832526207} | train loss {'Reaction outcome loss': 0.18462731462795343, 'Total loss': 0.18462731462795343}
2022-12-31 09:07:01,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:01,912 INFO:     Epoch: 27
2022-12-31 09:07:03,534 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3540061282614867, 'Total loss': 0.3540061282614867} | train loss {'Reaction outcome loss': 0.19239965444295734, 'Total loss': 0.19239965444295734}
2022-12-31 09:07:03,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:03,535 INFO:     Epoch: 28
2022-12-31 09:07:05,201 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.332850577433904, 'Total loss': 0.332850577433904} | train loss {'Reaction outcome loss': 0.1765898739213826, 'Total loss': 0.1765898739213826}
2022-12-31 09:07:05,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:05,202 INFO:     Epoch: 29
2022-12-31 09:07:06,823 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.34055669208367667, 'Total loss': 0.34055669208367667} | train loss {'Reaction outcome loss': 0.17636431610562664, 'Total loss': 0.17636431610562664}
2022-12-31 09:07:06,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:06,823 INFO:     Epoch: 30
2022-12-31 09:07:08,445 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3385627895593643, 'Total loss': 0.3385627895593643} | train loss {'Reaction outcome loss': 0.17124441543347674, 'Total loss': 0.17124441543347674}
2022-12-31 09:07:08,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:08,446 INFO:     Epoch: 31
2022-12-31 09:07:10,067 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.373911518851916, 'Total loss': 0.373911518851916} | train loss {'Reaction outcome loss': 0.16602725168991458, 'Total loss': 0.16602725168991458}
2022-12-31 09:07:10,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:10,067 INFO:     Epoch: 32
2022-12-31 09:07:11,731 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36833773404359815, 'Total loss': 0.36833773404359815} | train loss {'Reaction outcome loss': 0.16623110324165452, 'Total loss': 0.16623110324165452}
2022-12-31 09:07:11,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:11,732 INFO:     Epoch: 33
2022-12-31 09:07:13,396 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36083936790625254, 'Total loss': 0.36083936790625254} | train loss {'Reaction outcome loss': 0.16092754592650832, 'Total loss': 0.16092754592650832}
2022-12-31 09:07:13,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:13,397 INFO:     Epoch: 34
2022-12-31 09:07:15,061 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35111995339393615, 'Total loss': 0.35111995339393615} | train loss {'Reaction outcome loss': 0.15953700576469404, 'Total loss': 0.15953700576469404}
2022-12-31 09:07:15,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:15,062 INFO:     Epoch: 35
2022-12-31 09:07:16,672 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35882875124613445, 'Total loss': 0.35882875124613445} | train loss {'Reaction outcome loss': 0.15918074093043696, 'Total loss': 0.15918074093043696}
2022-12-31 09:07:16,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:16,672 INFO:     Epoch: 36
2022-12-31 09:07:18,300 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3740888863801956, 'Total loss': 0.3740888863801956} | train loss {'Reaction outcome loss': 0.15500568510714421, 'Total loss': 0.15500568510714421}
2022-12-31 09:07:18,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:18,301 INFO:     Epoch: 37
2022-12-31 09:07:19,916 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.33384318351745607, 'Total loss': 0.33384318351745607} | train loss {'Reaction outcome loss': 0.15384393190269938, 'Total loss': 0.15384393190269938}
2022-12-31 09:07:19,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:19,917 INFO:     Epoch: 38
2022-12-31 09:07:21,537 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34804145197073616, 'Total loss': 0.34804145197073616} | train loss {'Reaction outcome loss': 0.1534730496974932, 'Total loss': 0.1534730496974932}
2022-12-31 09:07:21,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:21,537 INFO:     Epoch: 39
2022-12-31 09:07:23,203 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3716186066468557, 'Total loss': 0.3716186066468557} | train loss {'Reaction outcome loss': 0.15115913500810257, 'Total loss': 0.15115913500810257}
2022-12-31 09:07:23,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:23,203 INFO:     Epoch: 40
2022-12-31 09:07:24,824 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35939162274201714, 'Total loss': 0.35939162274201714} | train loss {'Reaction outcome loss': 0.1493308598789778, 'Total loss': 0.1493308598789778}
2022-12-31 09:07:24,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:24,824 INFO:     Epoch: 41
2022-12-31 09:07:26,449 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3893360957503319, 'Total loss': 0.3893360957503319} | train loss {'Reaction outcome loss': 0.154026056525122, 'Total loss': 0.154026056525122}
2022-12-31 09:07:26,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:26,450 INFO:     Epoch: 42
2022-12-31 09:07:28,066 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35792478919029236, 'Total loss': 0.35792478919029236} | train loss {'Reaction outcome loss': 0.17717776398711832, 'Total loss': 0.17717776398711832}
2022-12-31 09:07:28,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:28,067 INFO:     Epoch: 43
2022-12-31 09:07:29,720 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36254079081118107, 'Total loss': 0.36254079081118107} | train loss {'Reaction outcome loss': 0.14598661242390348, 'Total loss': 0.14598661242390348}
2022-12-31 09:07:29,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:29,720 INFO:     Epoch: 44
2022-12-31 09:07:31,387 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4104903221130371, 'Total loss': 0.4104903221130371} | train loss {'Reaction outcome loss': 0.14120819668186005, 'Total loss': 0.14120819668186005}
2022-12-31 09:07:31,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:31,387 INFO:     Epoch: 45
2022-12-31 09:07:33,053 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.349255815645059, 'Total loss': 0.349255815645059} | train loss {'Reaction outcome loss': 0.14025373998742577, 'Total loss': 0.14025373998742577}
2022-12-31 09:07:33,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:33,053 INFO:     Epoch: 46
2022-12-31 09:07:34,671 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3988234390815099, 'Total loss': 0.3988234390815099} | train loss {'Reaction outcome loss': 0.1382688233818993, 'Total loss': 0.1382688233818993}
2022-12-31 09:07:34,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:34,671 INFO:     Epoch: 47
2022-12-31 09:07:36,292 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3806701421737671, 'Total loss': 0.3806701421737671} | train loss {'Reaction outcome loss': 0.13861047612896282, 'Total loss': 0.13861047612896282}
2022-12-31 09:07:36,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:36,292 INFO:     Epoch: 48
2022-12-31 09:07:37,909 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.356811914841334, 'Total loss': 0.356811914841334} | train loss {'Reaction outcome loss': 0.1356950308010077, 'Total loss': 0.1356950308010077}
2022-12-31 09:07:37,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:37,909 INFO:     Epoch: 49
2022-12-31 09:07:39,543 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.364321252455314, 'Total loss': 0.364321252455314} | train loss {'Reaction outcome loss': 0.1340248321973469, 'Total loss': 0.1340248321973469}
2022-12-31 09:07:39,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:39,544 INFO:     Epoch: 50
2022-12-31 09:07:41,177 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3462689220905304, 'Total loss': 0.3462689220905304} | train loss {'Reaction outcome loss': 0.13658039758498172, 'Total loss': 0.13658039758498172}
2022-12-31 09:07:41,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:41,177 INFO:     Epoch: 51
2022-12-31 09:07:42,814 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3547352741161982, 'Total loss': 0.3547352741161982} | train loss {'Reaction outcome loss': 0.13588947168334373, 'Total loss': 0.13588947168334373}
2022-12-31 09:07:42,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:42,814 INFO:     Epoch: 52
2022-12-31 09:07:44,439 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3827366203069687, 'Total loss': 0.3827366203069687} | train loss {'Reaction outcome loss': 0.12960672194826722, 'Total loss': 0.12960672194826722}
2022-12-31 09:07:44,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:44,439 INFO:     Epoch: 53
2022-12-31 09:07:46,061 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37973509828249613, 'Total loss': 0.37973509828249613} | train loss {'Reaction outcome loss': 0.1299088738168644, 'Total loss': 0.1299088738168644}
2022-12-31 09:07:46,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:46,062 INFO:     Epoch: 54
2022-12-31 09:07:47,682 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3756146637101968, 'Total loss': 0.3756146637101968} | train loss {'Reaction outcome loss': 0.13297453677269927, 'Total loss': 0.13297453677269927}
2022-12-31 09:07:47,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:47,682 INFO:     Epoch: 55
2022-12-31 09:07:49,312 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37703786194324496, 'Total loss': 0.37703786194324496} | train loss {'Reaction outcome loss': 0.13348134000873382, 'Total loss': 0.13348134000873382}
2022-12-31 09:07:49,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:49,312 INFO:     Epoch: 56
2022-12-31 09:07:50,939 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.410786098241806, 'Total loss': 0.410786098241806} | train loss {'Reaction outcome loss': 0.1308107610228404, 'Total loss': 0.1308107610228404}
2022-12-31 09:07:50,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:50,941 INFO:     Epoch: 57
2022-12-31 09:07:52,568 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3989397605260213, 'Total loss': 0.3989397605260213} | train loss {'Reaction outcome loss': 0.13508216198496867, 'Total loss': 0.13508216198496867}
2022-12-31 09:07:52,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:52,569 INFO:     Epoch: 58
2022-12-31 09:07:54,188 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3687284866968791, 'Total loss': 0.3687284866968791} | train loss {'Reaction outcome loss': 0.13020154440491225, 'Total loss': 0.13020154440491225}
2022-12-31 09:07:54,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:54,189 INFO:     Epoch: 59
2022-12-31 09:07:55,802 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.36120643417040504, 'Total loss': 0.36120643417040504} | train loss {'Reaction outcome loss': 0.12909633048600855, 'Total loss': 0.12909633048600855}
2022-12-31 09:07:55,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:55,802 INFO:     Epoch: 60
2022-12-31 09:07:57,420 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.364530290166537, 'Total loss': 0.364530290166537} | train loss {'Reaction outcome loss': 0.1259095821465514, 'Total loss': 0.1259095821465514}
2022-12-31 09:07:57,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:57,420 INFO:     Epoch: 61
2022-12-31 09:07:59,036 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37415641847377024, 'Total loss': 0.37415641847377024} | train loss {'Reaction outcome loss': 0.1278045508385559, 'Total loss': 0.1278045508385559}
2022-12-31 09:07:59,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:07:59,037 INFO:     Epoch: 62
2022-12-31 09:08:00,653 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37286639759937923, 'Total loss': 0.37286639759937923} | train loss {'Reaction outcome loss': 0.13375623338093198, 'Total loss': 0.13375623338093198}
2022-12-31 09:08:00,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:00,653 INFO:     Epoch: 63
2022-12-31 09:08:02,260 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36611430495977404, 'Total loss': 0.36611430495977404} | train loss {'Reaction outcome loss': 0.14141080292925387, 'Total loss': 0.14141080292925387}
2022-12-31 09:08:02,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:02,261 INFO:     Epoch: 64
2022-12-31 09:08:03,890 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39480773409207665, 'Total loss': 0.39480773409207665} | train loss {'Reaction outcome loss': 0.14811804078087426, 'Total loss': 0.14811804078087426}
2022-12-31 09:08:03,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:03,890 INFO:     Epoch: 65
2022-12-31 09:08:05,528 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3797846684853236, 'Total loss': 0.3797846684853236} | train loss {'Reaction outcome loss': 0.12632065568586637, 'Total loss': 0.12632065568586637}
2022-12-31 09:08:05,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:05,528 INFO:     Epoch: 66
2022-12-31 09:08:07,201 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39051919331153234, 'Total loss': 0.39051919331153234} | train loss {'Reaction outcome loss': 0.12038069478560078, 'Total loss': 0.12038069478560078}
2022-12-31 09:08:07,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:07,202 INFO:     Epoch: 67
2022-12-31 09:08:08,815 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38147735397020976, 'Total loss': 0.38147735397020976} | train loss {'Reaction outcome loss': 0.11924546839255375, 'Total loss': 0.11924546839255375}
2022-12-31 09:08:08,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:08,815 INFO:     Epoch: 68
2022-12-31 09:08:10,433 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3896979575355848, 'Total loss': 0.3896979575355848} | train loss {'Reaction outcome loss': 0.11954999528867463, 'Total loss': 0.11954999528867463}
2022-12-31 09:08:10,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:10,434 INFO:     Epoch: 69
2022-12-31 09:08:12,049 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3860277180870374, 'Total loss': 0.3860277180870374} | train loss {'Reaction outcome loss': 0.12316365892479224, 'Total loss': 0.12316365892479224}
2022-12-31 09:08:12,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:12,049 INFO:     Epoch: 70
2022-12-31 09:08:13,674 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36375827093919116, 'Total loss': 0.36375827093919116} | train loss {'Reaction outcome loss': 0.12101121432235654, 'Total loss': 0.12101121432235654}
2022-12-31 09:08:13,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:13,675 INFO:     Epoch: 71
2022-12-31 09:08:15,291 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39355405072371163, 'Total loss': 0.39355405072371163} | train loss {'Reaction outcome loss': 0.12307937558142694, 'Total loss': 0.12307937558142694}
2022-12-31 09:08:15,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:15,291 INFO:     Epoch: 72
2022-12-31 09:08:16,913 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38236942887306213, 'Total loss': 0.38236942887306213} | train loss {'Reaction outcome loss': 0.1250361341479457, 'Total loss': 0.1250361341479457}
2022-12-31 09:08:16,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:16,913 INFO:     Epoch: 73
2022-12-31 09:08:18,579 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39720785319805146, 'Total loss': 0.39720785319805146} | train loss {'Reaction outcome loss': 0.11869004758182859, 'Total loss': 0.11869004758182859}
2022-12-31 09:08:18,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:18,580 INFO:     Epoch: 74
2022-12-31 09:08:20,203 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37798994878927866, 'Total loss': 0.37798994878927866} | train loss {'Reaction outcome loss': 0.11900076674182723, 'Total loss': 0.11900076674182723}
2022-12-31 09:08:20,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:20,203 INFO:     Epoch: 75
2022-12-31 09:08:21,821 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3667553057273229, 'Total loss': 0.3667553057273229} | train loss {'Reaction outcome loss': 0.1192233343161575, 'Total loss': 0.1192233343161575}
2022-12-31 09:08:21,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:21,822 INFO:     Epoch: 76
2022-12-31 09:08:23,452 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3861583371957143, 'Total loss': 0.3861583371957143} | train loss {'Reaction outcome loss': 0.120848738614544, 'Total loss': 0.120848738614544}
2022-12-31 09:08:23,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:23,452 INFO:     Epoch: 77
2022-12-31 09:08:25,069 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3551949878533681, 'Total loss': 0.3551949878533681} | train loss {'Reaction outcome loss': 0.11577980614722196, 'Total loss': 0.11577980614722196}
2022-12-31 09:08:25,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:25,069 INFO:     Epoch: 78
2022-12-31 09:08:26,687 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37782889207204184, 'Total loss': 0.37782889207204184} | train loss {'Reaction outcome loss': 0.11719635307098422, 'Total loss': 0.11719635307098422}
2022-12-31 09:08:26,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:26,687 INFO:     Epoch: 79
2022-12-31 09:08:28,303 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3608532249927521, 'Total loss': 0.3608532249927521} | train loss {'Reaction outcome loss': 0.11481876741079074, 'Total loss': 0.11481876741079074}
2022-12-31 09:08:28,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:28,304 INFO:     Epoch: 80
2022-12-31 09:08:29,923 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3834805985291799, 'Total loss': 0.3834805985291799} | train loss {'Reaction outcome loss': 0.11876472045222054, 'Total loss': 0.11876472045222054}
2022-12-31 09:08:29,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:29,923 INFO:     Epoch: 81
2022-12-31 09:08:31,540 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39988992313543953, 'Total loss': 0.39988992313543953} | train loss {'Reaction outcome loss': 0.11816435351046613, 'Total loss': 0.11816435351046613}
2022-12-31 09:08:31,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:31,540 INFO:     Epoch: 82
2022-12-31 09:08:33,156 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3617834602793058, 'Total loss': 0.3617834602793058} | train loss {'Reaction outcome loss': 0.11228220566071273, 'Total loss': 0.11228220566071273}
2022-12-31 09:08:33,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:33,156 INFO:     Epoch: 83
2022-12-31 09:08:34,785 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3956601586192846, 'Total loss': 0.3956601586192846} | train loss {'Reaction outcome loss': 0.1116782882167752, 'Total loss': 0.1116782882167752}
2022-12-31 09:08:34,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:34,785 INFO:     Epoch: 84
2022-12-31 09:08:36,413 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37556139032046, 'Total loss': 0.37556139032046} | train loss {'Reaction outcome loss': 0.11251164596337006, 'Total loss': 0.11251164596337006}
2022-12-31 09:08:36,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:36,414 INFO:     Epoch: 85
2022-12-31 09:08:38,041 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.33609676410754524, 'Total loss': 0.33609676410754524} | train loss {'Reaction outcome loss': 0.11333781365259632, 'Total loss': 0.11333781365259632}
2022-12-31 09:08:38,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:38,041 INFO:     Epoch: 86
2022-12-31 09:08:39,661 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3855676834781965, 'Total loss': 0.3855676834781965} | train loss {'Reaction outcome loss': 0.12272293953582698, 'Total loss': 0.12272293953582698}
2022-12-31 09:08:39,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:39,661 INFO:     Epoch: 87
2022-12-31 09:08:41,284 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39826939602692923, 'Total loss': 0.39826939602692923} | train loss {'Reaction outcome loss': 0.11871640592015456, 'Total loss': 0.11871640592015456}
2022-12-31 09:08:41,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:41,285 INFO:     Epoch: 88
2022-12-31 09:08:42,909 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40993124643961587, 'Total loss': 0.40993124643961587} | train loss {'Reaction outcome loss': 0.11801319541671651, 'Total loss': 0.11801319541671651}
2022-12-31 09:08:42,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:42,909 INFO:     Epoch: 89
2022-12-31 09:08:44,575 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3793529247244199, 'Total loss': 0.3793529247244199} | train loss {'Reaction outcome loss': 0.11376276529952757, 'Total loss': 0.11376276529952757}
2022-12-31 09:08:44,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:44,576 INFO:     Epoch: 90
2022-12-31 09:08:46,201 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41961418787638344, 'Total loss': 0.41961418787638344} | train loss {'Reaction outcome loss': 0.10946438786239647, 'Total loss': 0.10946438786239647}
2022-12-31 09:08:46,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:46,201 INFO:     Epoch: 91
2022-12-31 09:08:47,820 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39823909029364585, 'Total loss': 0.39823909029364585} | train loss {'Reaction outcome loss': 0.10995609614653495, 'Total loss': 0.10995609614653495}
2022-12-31 09:08:47,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:47,821 INFO:     Epoch: 92
2022-12-31 09:08:49,488 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40330749452114106, 'Total loss': 0.40330749452114106} | train loss {'Reaction outcome loss': 0.10888211960322013, 'Total loss': 0.10888211960322013}
2022-12-31 09:08:49,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:49,488 INFO:     Epoch: 93
2022-12-31 09:08:51,099 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40084169308344525, 'Total loss': 0.40084169308344525} | train loss {'Reaction outcome loss': 0.11431184929518866, 'Total loss': 0.11431184929518866}
2022-12-31 09:08:51,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:51,099 INFO:     Epoch: 94
2022-12-31 09:08:52,766 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3664573833346367, 'Total loss': 0.3664573833346367} | train loss {'Reaction outcome loss': 0.11102980007569346, 'Total loss': 0.11102980007569346}
2022-12-31 09:08:52,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:52,767 INFO:     Epoch: 95
2022-12-31 09:08:54,384 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48048850893974304, 'Total loss': 0.48048850893974304} | train loss {'Reaction outcome loss': 0.1249641499412921, 'Total loss': 0.1249641499412921}
2022-12-31 09:08:54,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:54,384 INFO:     Epoch: 96
2022-12-31 09:08:56,000 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3785614567498366, 'Total loss': 0.3785614567498366} | train loss {'Reaction outcome loss': 0.1576960649205527, 'Total loss': 0.1576960649205527}
2022-12-31 09:08:56,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:56,000 INFO:     Epoch: 97
2022-12-31 09:08:57,616 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37198024392127993, 'Total loss': 0.37198024392127993} | train loss {'Reaction outcome loss': 0.11414364019388365, 'Total loss': 0.11414364019388365}
2022-12-31 09:08:57,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:57,617 INFO:     Epoch: 98
2022-12-31 09:08:59,239 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3598498716950417, 'Total loss': 0.3598498716950417} | train loss {'Reaction outcome loss': 0.1047862325942623, 'Total loss': 0.1047862325942623}
2022-12-31 09:08:59,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:08:59,240 INFO:     Epoch: 99
2022-12-31 09:09:00,865 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36440849732607605, 'Total loss': 0.36440849732607605} | train loss {'Reaction outcome loss': 0.10307304872456871, 'Total loss': 0.10307304872456871}
2022-12-31 09:09:00,865 INFO:     Best model found after epoch 20 of 100.
2022-12-31 09:09:00,865 INFO:   Done with stage: TRAINING
2022-12-31 09:09:00,865 INFO:   Starting stage: EVALUATION
2022-12-31 09:09:00,999 INFO:   Done with stage: EVALUATION
2022-12-31 09:09:00,999 INFO:   Leaving out SEQ value Fold_2
2022-12-31 09:09:01,012 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 09:09:01,012 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:09:01,656 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:09:01,656 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:09:01,722 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:09:01,723 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:09:01,723 INFO:     No hyperparam tuning for this model
2022-12-31 09:09:01,723 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:09:01,723 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:09:01,723 INFO:     None feature selector for col prot
2022-12-31 09:09:01,724 INFO:     None feature selector for col prot
2022-12-31 09:09:01,724 INFO:     None feature selector for col prot
2022-12-31 09:09:01,724 INFO:     None feature selector for col chem
2022-12-31 09:09:01,724 INFO:     None feature selector for col chem
2022-12-31 09:09:01,724 INFO:     None feature selector for col chem
2022-12-31 09:09:01,724 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:09:01,725 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:09:01,726 INFO:     Number of params in model 224011
2022-12-31 09:09:01,730 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:09:01,730 INFO:   Starting stage: TRAINING
2022-12-31 09:09:01,777 INFO:     Val loss before train {'Reaction outcome loss': 1.063242260615031, 'Total loss': 1.063242260615031}
2022-12-31 09:09:01,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:01,777 INFO:     Epoch: 0
2022-12-31 09:09:03,375 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5674814283847809, 'Total loss': 0.5674814283847809} | train loss {'Reaction outcome loss': 0.7987641341351935, 'Total loss': 0.7987641341351935}
2022-12-31 09:09:03,375 INFO:     Found new best model at epoch 0
2022-12-31 09:09:03,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:03,376 INFO:     Epoch: 1
2022-12-31 09:09:04,970 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4764170189698537, 'Total loss': 0.4764170189698537} | train loss {'Reaction outcome loss': 0.5225214443523506, 'Total loss': 0.5225214443523506}
2022-12-31 09:09:04,970 INFO:     Found new best model at epoch 1
2022-12-31 09:09:04,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:04,971 INFO:     Epoch: 2
2022-12-31 09:09:06,557 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4297143081823985, 'Total loss': 0.4297143081823985} | train loss {'Reaction outcome loss': 0.4548464871640575, 'Total loss': 0.4548464871640575}
2022-12-31 09:09:06,557 INFO:     Found new best model at epoch 2
2022-12-31 09:09:06,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:06,558 INFO:     Epoch: 3
2022-12-31 09:09:08,148 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4251231054464976, 'Total loss': 0.4251231054464976} | train loss {'Reaction outcome loss': 0.4109806833561936, 'Total loss': 0.4109806833561936}
2022-12-31 09:09:08,148 INFO:     Found new best model at epoch 3
2022-12-31 09:09:08,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:08,149 INFO:     Epoch: 4
2022-12-31 09:09:09,783 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4307651778062185, 'Total loss': 0.4307651778062185} | train loss {'Reaction outcome loss': 0.3801644598151045, 'Total loss': 0.3801644598151045}
2022-12-31 09:09:09,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:09,783 INFO:     Epoch: 5
2022-12-31 09:09:11,382 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4342587530612946, 'Total loss': 0.4342587530612946} | train loss {'Reaction outcome loss': 0.3606887593370522, 'Total loss': 0.3606887593370522}
2022-12-31 09:09:11,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:11,383 INFO:     Epoch: 6
2022-12-31 09:09:12,985 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4568489273389181, 'Total loss': 0.4568489273389181} | train loss {'Reaction outcome loss': 0.3400653250707911, 'Total loss': 0.3400653250707911}
2022-12-31 09:09:12,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:12,986 INFO:     Epoch: 7
2022-12-31 09:09:14,622 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43488649229208626, 'Total loss': 0.43488649229208626} | train loss {'Reaction outcome loss': 0.3219407562070227, 'Total loss': 0.3219407562070227}
2022-12-31 09:09:14,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:14,622 INFO:     Epoch: 8
2022-12-31 09:09:16,218 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4177103598912557, 'Total loss': 0.4177103598912557} | train loss {'Reaction outcome loss': 0.30850426114518265, 'Total loss': 0.30850426114518265}
2022-12-31 09:09:16,218 INFO:     Found new best model at epoch 8
2022-12-31 09:09:16,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:16,219 INFO:     Epoch: 9
2022-12-31 09:09:17,818 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42801468869050346, 'Total loss': 0.42801468869050346} | train loss {'Reaction outcome loss': 0.29734503354093683, 'Total loss': 0.29734503354093683}
2022-12-31 09:09:17,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:17,819 INFO:     Epoch: 10
2022-12-31 09:09:19,455 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44218966166178386, 'Total loss': 0.44218966166178386} | train loss {'Reaction outcome loss': 0.28298511951337, 'Total loss': 0.28298511951337}
2022-12-31 09:09:19,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:19,456 INFO:     Epoch: 11
2022-12-31 09:09:21,092 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4252854367097219, 'Total loss': 0.4252854367097219} | train loss {'Reaction outcome loss': 0.27493750657267674, 'Total loss': 0.27493750657267674}
2022-12-31 09:09:21,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:21,093 INFO:     Epoch: 12
2022-12-31 09:09:22,729 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42116505006949106, 'Total loss': 0.42116505006949106} | train loss {'Reaction outcome loss': 0.26197304984905184, 'Total loss': 0.26197304984905184}
2022-12-31 09:09:22,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:22,730 INFO:     Epoch: 13
2022-12-31 09:09:24,312 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4135329693555832, 'Total loss': 0.4135329693555832} | train loss {'Reaction outcome loss': 0.2535165147752779, 'Total loss': 0.2535165147752779}
2022-12-31 09:09:24,312 INFO:     Found new best model at epoch 13
2022-12-31 09:09:24,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:24,313 INFO:     Epoch: 14
2022-12-31 09:09:25,912 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4048724911486109, 'Total loss': 0.4048724911486109} | train loss {'Reaction outcome loss': 0.24336328826212356, 'Total loss': 0.24336328826212356}
2022-12-31 09:09:25,912 INFO:     Found new best model at epoch 14
2022-12-31 09:09:25,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:25,913 INFO:     Epoch: 15
2022-12-31 09:09:27,208 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4886129468679428, 'Total loss': 0.4886129468679428} | train loss {'Reaction outcome loss': 0.23643307061350433, 'Total loss': 0.23643307061350433}
2022-12-31 09:09:27,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:27,208 INFO:     Epoch: 16
2022-12-31 09:09:28,299 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40172787954409916, 'Total loss': 0.40172787954409916} | train loss {'Reaction outcome loss': 0.23186774543276903, 'Total loss': 0.23186774543276903}
2022-12-31 09:09:28,299 INFO:     Found new best model at epoch 16
2022-12-31 09:09:28,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:28,300 INFO:     Epoch: 17
2022-12-31 09:09:29,385 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.456155526638031, 'Total loss': 0.456155526638031} | train loss {'Reaction outcome loss': 0.22381261098318875, 'Total loss': 0.22381261098318875}
2022-12-31 09:09:29,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:29,386 INFO:     Epoch: 18
2022-12-31 09:09:30,473 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42948539555072784, 'Total loss': 0.42948539555072784} | train loss {'Reaction outcome loss': 0.2169362855216014, 'Total loss': 0.2169362855216014}
2022-12-31 09:09:30,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:30,473 INFO:     Epoch: 19
2022-12-31 09:09:31,694 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4193679342667262, 'Total loss': 0.4193679342667262} | train loss {'Reaction outcome loss': 0.21272303851328214, 'Total loss': 0.21272303851328214}
2022-12-31 09:09:31,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:31,694 INFO:     Epoch: 20
2022-12-31 09:09:33,293 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45776055951913197, 'Total loss': 0.45776055951913197} | train loss {'Reaction outcome loss': 0.20896626159383802, 'Total loss': 0.20896626159383802}
2022-12-31 09:09:33,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:33,294 INFO:     Epoch: 21
2022-12-31 09:09:34,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43496595323085785, 'Total loss': 0.43496595323085785} | train loss {'Reaction outcome loss': 0.2037387099941828, 'Total loss': 0.2037387099941828}
2022-12-31 09:09:34,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:34,882 INFO:     Epoch: 22
2022-12-31 09:09:36,469 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46841370364030205, 'Total loss': 0.46841370364030205} | train loss {'Reaction outcome loss': 0.20219684472630606, 'Total loss': 0.20219684472630606}
2022-12-31 09:09:36,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:36,469 INFO:     Epoch: 23
2022-12-31 09:09:38,055 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4137613649169604, 'Total loss': 0.4137613649169604} | train loss {'Reaction outcome loss': 0.19685915858240804, 'Total loss': 0.19685915858240804}
2022-12-31 09:09:38,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:38,055 INFO:     Epoch: 24
2022-12-31 09:09:39,642 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43854162047306694, 'Total loss': 0.43854162047306694} | train loss {'Reaction outcome loss': 0.19102944294162563, 'Total loss': 0.19102944294162563}
2022-12-31 09:09:39,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:39,642 INFO:     Epoch: 25
2022-12-31 09:09:41,235 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42361421287059786, 'Total loss': 0.42361421287059786} | train loss {'Reaction outcome loss': 0.18702582998469308, 'Total loss': 0.18702582998469308}
2022-12-31 09:09:41,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:41,235 INFO:     Epoch: 26
2022-12-31 09:09:42,831 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4505551849802335, 'Total loss': 0.4505551849802335} | train loss {'Reaction outcome loss': 0.18381088470345933, 'Total loss': 0.18381088470345933}
2022-12-31 09:09:42,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:42,832 INFO:     Epoch: 27
2022-12-31 09:09:44,430 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46058196723461153, 'Total loss': 0.46058196723461153} | train loss {'Reaction outcome loss': 0.1800038035945259, 'Total loss': 0.1800038035945259}
2022-12-31 09:09:44,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:44,430 INFO:     Epoch: 28
2022-12-31 09:09:46,024 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43293724755446117, 'Total loss': 0.43293724755446117} | train loss {'Reaction outcome loss': 0.17243938170359693, 'Total loss': 0.17243938170359693}
2022-12-31 09:09:46,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:46,025 INFO:     Epoch: 29
2022-12-31 09:09:47,619 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45396918853123985, 'Total loss': 0.45396918853123985} | train loss {'Reaction outcome loss': 0.16958913603811301, 'Total loss': 0.16958913603811301}
2022-12-31 09:09:47,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:47,620 INFO:     Epoch: 30
2022-12-31 09:09:49,207 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47473080853621163, 'Total loss': 0.47473080853621163} | train loss {'Reaction outcome loss': 0.16449291733990515, 'Total loss': 0.16449291733990515}
2022-12-31 09:09:49,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:49,207 INFO:     Epoch: 31
2022-12-31 09:09:50,804 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4292443518837293, 'Total loss': 0.4292443518837293} | train loss {'Reaction outcome loss': 0.16487270946755345, 'Total loss': 0.16487270946755345}
2022-12-31 09:09:50,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:50,804 INFO:     Epoch: 32
2022-12-31 09:09:52,411 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4514244298140208, 'Total loss': 0.4514244298140208} | train loss {'Reaction outcome loss': 0.16418041873077185, 'Total loss': 0.16418041873077185}
2022-12-31 09:09:52,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:52,412 INFO:     Epoch: 33
2022-12-31 09:09:54,005 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5102764974037807, 'Total loss': 0.5102764974037807} | train loss {'Reaction outcome loss': 0.16432837287919438, 'Total loss': 0.16432837287919438}
2022-12-31 09:09:54,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:54,006 INFO:     Epoch: 34
2022-12-31 09:09:55,601 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43193882604440054, 'Total loss': 0.43193882604440054} | train loss {'Reaction outcome loss': 0.1562646691759574, 'Total loss': 0.1562646691759574}
2022-12-31 09:09:55,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:55,602 INFO:     Epoch: 35
2022-12-31 09:09:57,214 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43123674392700195, 'Total loss': 0.43123674392700195} | train loss {'Reaction outcome loss': 0.16004901044276917, 'Total loss': 0.16004901044276917}
2022-12-31 09:09:57,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:57,215 INFO:     Epoch: 36
2022-12-31 09:09:58,828 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4354778786500295, 'Total loss': 0.4354778786500295} | train loss {'Reaction outcome loss': 0.15219706992491586, 'Total loss': 0.15219706992491586}
2022-12-31 09:09:58,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:09:58,829 INFO:     Epoch: 37
2022-12-31 09:10:00,432 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4383180757363637, 'Total loss': 0.4383180757363637} | train loss {'Reaction outcome loss': 0.1490024513224779, 'Total loss': 0.1490024513224779}
2022-12-31 09:10:00,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:00,432 INFO:     Epoch: 38
2022-12-31 09:10:02,069 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43629038461173575, 'Total loss': 0.43629038461173575} | train loss {'Reaction outcome loss': 0.15211369050838522, 'Total loss': 0.15211369050838522}
2022-12-31 09:10:02,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:02,069 INFO:     Epoch: 39
2022-12-31 09:10:03,705 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4104409982760747, 'Total loss': 0.4104409982760747} | train loss {'Reaction outcome loss': 0.14706087205215354, 'Total loss': 0.14706087205215354}
2022-12-31 09:10:03,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:03,705 INFO:     Epoch: 40
2022-12-31 09:10:05,341 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45257289508978527, 'Total loss': 0.45257289508978527} | train loss {'Reaction outcome loss': 0.14527165690760002, 'Total loss': 0.14527165690760002}
2022-12-31 09:10:05,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:05,341 INFO:     Epoch: 41
2022-12-31 09:10:06,941 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4638904313246409, 'Total loss': 0.4638904313246409} | train loss {'Reaction outcome loss': 0.14587360596442356, 'Total loss': 0.14587360596442356}
2022-12-31 09:10:06,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:06,941 INFO:     Epoch: 42
2022-12-31 09:10:08,542 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4726828803618749, 'Total loss': 0.4726828803618749} | train loss {'Reaction outcome loss': 0.14237308254417347, 'Total loss': 0.14237308254417347}
2022-12-31 09:10:08,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:08,542 INFO:     Epoch: 43
2022-12-31 09:10:10,150 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46104155977567035, 'Total loss': 0.46104155977567035} | train loss {'Reaction outcome loss': 0.14324862621312212, 'Total loss': 0.14324862621312212}
2022-12-31 09:10:10,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:10,150 INFO:     Epoch: 44
2022-12-31 09:10:11,751 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4569356371959051, 'Total loss': 0.4569356371959051} | train loss {'Reaction outcome loss': 0.1379745875337467, 'Total loss': 0.1379745875337467}
2022-12-31 09:10:11,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:11,751 INFO:     Epoch: 45
2022-12-31 09:10:13,354 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43741238514582315, 'Total loss': 0.43741238514582315} | train loss {'Reaction outcome loss': 0.13834111548863984, 'Total loss': 0.13834111548863984}
2022-12-31 09:10:13,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:13,354 INFO:     Epoch: 46
2022-12-31 09:10:14,952 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46672149101893107, 'Total loss': 0.46672149101893107} | train loss {'Reaction outcome loss': 0.13955432999659179, 'Total loss': 0.13955432999659179}
2022-12-31 09:10:14,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:14,953 INFO:     Epoch: 47
2022-12-31 09:10:16,553 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4282038986682892, 'Total loss': 0.4282038986682892} | train loss {'Reaction outcome loss': 0.1389367258145278, 'Total loss': 0.1389367258145278}
2022-12-31 09:10:16,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:16,553 INFO:     Epoch: 48
2022-12-31 09:10:18,142 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4400523553291957, 'Total loss': 0.4400523553291957} | train loss {'Reaction outcome loss': 0.13399571432075652, 'Total loss': 0.13399571432075652}
2022-12-31 09:10:18,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:18,142 INFO:     Epoch: 49
2022-12-31 09:10:19,743 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.430704802274704, 'Total loss': 0.430704802274704} | train loss {'Reaction outcome loss': 0.13524103395097864, 'Total loss': 0.13524103395097864}
2022-12-31 09:10:19,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:19,743 INFO:     Epoch: 50
2022-12-31 09:10:21,348 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40966202057898043, 'Total loss': 0.40966202057898043} | train loss {'Reaction outcome loss': 0.13645986304532504, 'Total loss': 0.13645986304532504}
2022-12-31 09:10:21,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:21,348 INFO:     Epoch: 51
2022-12-31 09:10:22,950 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45330530603726704, 'Total loss': 0.45330530603726704} | train loss {'Reaction outcome loss': 0.13470963564979743, 'Total loss': 0.13470963564979743}
2022-12-31 09:10:22,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:22,951 INFO:     Epoch: 52
2022-12-31 09:10:24,554 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43874778946240744, 'Total loss': 0.43874778946240744} | train loss {'Reaction outcome loss': 0.135902947057176, 'Total loss': 0.135902947057176}
2022-12-31 09:10:24,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:24,555 INFO:     Epoch: 53
2022-12-31 09:10:26,140 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4120066111286481, 'Total loss': 0.4120066111286481} | train loss {'Reaction outcome loss': 0.12989063509757118, 'Total loss': 0.12989063509757118}
2022-12-31 09:10:26,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:26,141 INFO:     Epoch: 54
2022-12-31 09:10:27,769 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41941224932670595, 'Total loss': 0.41941224932670595} | train loss {'Reaction outcome loss': 0.12994346166943713, 'Total loss': 0.12994346166943713}
2022-12-31 09:10:27,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:27,769 INFO:     Epoch: 55
2022-12-31 09:10:29,360 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5042556583881378, 'Total loss': 0.5042556583881378} | train loss {'Reaction outcome loss': 0.130759586447788, 'Total loss': 0.130759586447788}
2022-12-31 09:10:29,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:29,362 INFO:     Epoch: 56
2022-12-31 09:10:30,953 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44779055217901864, 'Total loss': 0.44779055217901864} | train loss {'Reaction outcome loss': 0.13041460318181566, 'Total loss': 0.13041460318181566}
2022-12-31 09:10:30,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:30,953 INFO:     Epoch: 57
2022-12-31 09:10:32,542 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47072125573952994, 'Total loss': 0.47072125573952994} | train loss {'Reaction outcome loss': 0.13144216418517168, 'Total loss': 0.13144216418517168}
2022-12-31 09:10:32,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:32,542 INFO:     Epoch: 58
2022-12-31 09:10:34,172 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4717945598065853, 'Total loss': 0.4717945598065853} | train loss {'Reaction outcome loss': 0.13229916606277117, 'Total loss': 0.13229916606277117}
2022-12-31 09:10:34,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:34,173 INFO:     Epoch: 59
2022-12-31 09:10:35,767 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4667122890551885, 'Total loss': 0.4667122890551885} | train loss {'Reaction outcome loss': 0.13031312400935652, 'Total loss': 0.13031312400935652}
2022-12-31 09:10:35,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:35,768 INFO:     Epoch: 60
2022-12-31 09:10:37,351 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44126928051312764, 'Total loss': 0.44126928051312764} | train loss {'Reaction outcome loss': 0.12825411487528815, 'Total loss': 0.12825411487528815}
2022-12-31 09:10:37,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:37,352 INFO:     Epoch: 61
2022-12-31 09:10:38,983 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4383576107521852, 'Total loss': 0.4383576107521852} | train loss {'Reaction outcome loss': 0.12666824641311025, 'Total loss': 0.12666824641311025}
2022-12-31 09:10:38,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:38,983 INFO:     Epoch: 62
2022-12-31 09:10:40,568 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4019044933219751, 'Total loss': 0.4019044933219751} | train loss {'Reaction outcome loss': 0.12793480123417295, 'Total loss': 0.12793480123417295}
2022-12-31 09:10:40,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:40,569 INFO:     Epoch: 63
2022-12-31 09:10:42,200 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42958051760991417, 'Total loss': 0.42958051760991417} | train loss {'Reaction outcome loss': 0.1252803092451278, 'Total loss': 0.1252803092451278}
2022-12-31 09:10:42,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:42,201 INFO:     Epoch: 64
2022-12-31 09:10:43,832 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40665387293944755, 'Total loss': 0.40665387293944755} | train loss {'Reaction outcome loss': 0.12484450597913997, 'Total loss': 0.12484450597913997}
2022-12-31 09:10:43,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:43,832 INFO:     Epoch: 65
2022-12-31 09:10:45,413 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42872528337563076, 'Total loss': 0.42872528337563076} | train loss {'Reaction outcome loss': 0.12481703757861719, 'Total loss': 0.12481703757861719}
2022-12-31 09:10:45,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:45,413 INFO:     Epoch: 66
2022-12-31 09:10:47,005 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41099601847430073, 'Total loss': 0.41099601847430073} | train loss {'Reaction outcome loss': 0.12673402956525393, 'Total loss': 0.12673402956525393}
2022-12-31 09:10:47,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:47,005 INFO:     Epoch: 67
2022-12-31 09:10:48,595 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42697317600250245, 'Total loss': 0.42697317600250245} | train loss {'Reaction outcome loss': 0.12460663502802213, 'Total loss': 0.12460663502802213}
2022-12-31 09:10:48,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:48,596 INFO:     Epoch: 68
2022-12-31 09:10:50,191 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48671510418256125, 'Total loss': 0.48671510418256125} | train loss {'Reaction outcome loss': 0.12040579237552476, 'Total loss': 0.12040579237552476}
2022-12-31 09:10:50,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:50,191 INFO:     Epoch: 69
2022-12-31 09:10:51,780 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.478026748696963, 'Total loss': 0.478026748696963} | train loss {'Reaction outcome loss': 0.1198285278104713, 'Total loss': 0.1198285278104713}
2022-12-31 09:10:51,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:51,781 INFO:     Epoch: 70
2022-12-31 09:10:53,362 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47986162106196084, 'Total loss': 0.47986162106196084} | train loss {'Reaction outcome loss': 0.12167273289300638, 'Total loss': 0.12167273289300638}
2022-12-31 09:10:53,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:53,363 INFO:     Epoch: 71
2022-12-31 09:10:54,960 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5128627359867096, 'Total loss': 0.5128627359867096} | train loss {'Reaction outcome loss': 0.1190341923203718, 'Total loss': 0.1190341923203718}
2022-12-31 09:10:54,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:54,960 INFO:     Epoch: 72
2022-12-31 09:10:56,555 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42247037837902707, 'Total loss': 0.42247037837902707} | train loss {'Reaction outcome loss': 0.12345237423995736, 'Total loss': 0.12345237423995736}
2022-12-31 09:10:56,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:56,555 INFO:     Epoch: 73
2022-12-31 09:10:58,152 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4060212343931198, 'Total loss': 0.4060212343931198} | train loss {'Reaction outcome loss': 0.12095872876560831, 'Total loss': 0.12095872876560831}
2022-12-31 09:10:58,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:58,152 INFO:     Epoch: 74
2022-12-31 09:10:59,748 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.416346829632918, 'Total loss': 0.416346829632918} | train loss {'Reaction outcome loss': 0.1181150449343658, 'Total loss': 0.1181150449343658}
2022-12-31 09:10:59,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:10:59,749 INFO:     Epoch: 75
2022-12-31 09:11:01,342 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4408831199010213, 'Total loss': 0.4408831199010213} | train loss {'Reaction outcome loss': 0.11971714729408826, 'Total loss': 0.11971714729408826}
2022-12-31 09:11:01,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:01,343 INFO:     Epoch: 76
2022-12-31 09:11:02,928 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4935353765885035, 'Total loss': 0.4935353765885035} | train loss {'Reaction outcome loss': 0.1207391541911722, 'Total loss': 0.1207391541911722}
2022-12-31 09:11:02,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:02,928 INFO:     Epoch: 77
2022-12-31 09:11:04,524 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4252398451169332, 'Total loss': 0.4252398451169332} | train loss {'Reaction outcome loss': 0.1225955295350705, 'Total loss': 0.1225955295350705}
2022-12-31 09:11:04,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:04,524 INFO:     Epoch: 78
2022-12-31 09:11:06,120 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47210534413655597, 'Total loss': 0.47210534413655597} | train loss {'Reaction outcome loss': 0.12424740272770014, 'Total loss': 0.12424740272770014}
2022-12-31 09:11:06,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:06,120 INFO:     Epoch: 79
2022-12-31 09:11:07,714 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4158714453379313, 'Total loss': 0.4158714453379313} | train loss {'Reaction outcome loss': 0.12231355206826118, 'Total loss': 0.12231355206826118}
2022-12-31 09:11:07,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:07,715 INFO:     Epoch: 80
2022-12-31 09:11:09,311 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42087714970111845, 'Total loss': 0.42087714970111845} | train loss {'Reaction outcome loss': 0.11894714161478726, 'Total loss': 0.11894714161478726}
2022-12-31 09:11:09,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:09,311 INFO:     Epoch: 81
2022-12-31 09:11:10,907 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43888067131241165, 'Total loss': 0.43888067131241165} | train loss {'Reaction outcome loss': 0.11584632044032601, 'Total loss': 0.11584632044032601}
2022-12-31 09:11:10,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:10,907 INFO:     Epoch: 82
2022-12-31 09:11:12,504 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45338005721569063, 'Total loss': 0.45338005721569063} | train loss {'Reaction outcome loss': 0.11487111855363577, 'Total loss': 0.11487111855363577}
2022-12-31 09:11:12,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:12,504 INFO:     Epoch: 83
2022-12-31 09:11:14,103 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40848115781943, 'Total loss': 0.40848115781943} | train loss {'Reaction outcome loss': 0.11952432126796554, 'Total loss': 0.11952432126796554}
2022-12-31 09:11:14,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:14,103 INFO:     Epoch: 84
2022-12-31 09:11:15,700 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46485554178555805, 'Total loss': 0.46485554178555805} | train loss {'Reaction outcome loss': 0.11372921612058728, 'Total loss': 0.11372921612058728}
2022-12-31 09:11:15,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:15,701 INFO:     Epoch: 85
2022-12-31 09:11:17,298 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42142593463261924, 'Total loss': 0.42142593463261924} | train loss {'Reaction outcome loss': 0.11525102552865044, 'Total loss': 0.11525102552865044}
2022-12-31 09:11:17,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:17,298 INFO:     Epoch: 86
2022-12-31 09:11:18,909 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44541978240013125, 'Total loss': 0.44541978240013125} | train loss {'Reaction outcome loss': 0.11506514630806237, 'Total loss': 0.11506514630806237}
2022-12-31 09:11:18,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:18,909 INFO:     Epoch: 87
2022-12-31 09:11:20,496 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41502575675646464, 'Total loss': 0.41502575675646464} | train loss {'Reaction outcome loss': 0.11864561243996546, 'Total loss': 0.11864561243996546}
2022-12-31 09:11:20,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:20,497 INFO:     Epoch: 88
2022-12-31 09:11:22,089 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4356146345535914, 'Total loss': 0.4356146345535914} | train loss {'Reaction outcome loss': 0.11983331075329952, 'Total loss': 0.11983331075329952}
2022-12-31 09:11:22,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:22,090 INFO:     Epoch: 89
2022-12-31 09:11:23,682 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4509210467338562, 'Total loss': 0.4509210467338562} | train loss {'Reaction outcome loss': 0.11877564540840822, 'Total loss': 0.11877564540840822}
2022-12-31 09:11:23,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:23,683 INFO:     Epoch: 90
2022-12-31 09:11:25,277 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4152129751940568, 'Total loss': 0.4152129751940568} | train loss {'Reaction outcome loss': 0.11796400408394553, 'Total loss': 0.11796400408394553}
2022-12-31 09:11:25,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:25,277 INFO:     Epoch: 91
2022-12-31 09:11:26,877 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43078288038571677, 'Total loss': 0.43078288038571677} | train loss {'Reaction outcome loss': 0.11089493001886812, 'Total loss': 0.11089493001886812}
2022-12-31 09:11:26,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:26,877 INFO:     Epoch: 92
2022-12-31 09:11:28,478 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45161276360352837, 'Total loss': 0.45161276360352837} | train loss {'Reaction outcome loss': 0.11179353469704377, 'Total loss': 0.11179353469704377}
2022-12-31 09:11:28,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:28,478 INFO:     Epoch: 93
2022-12-31 09:11:30,064 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4242148458957672, 'Total loss': 0.4242148458957672} | train loss {'Reaction outcome loss': 0.11367136076852212, 'Total loss': 0.11367136076852212}
2022-12-31 09:11:30,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:30,064 INFO:     Epoch: 94
2022-12-31 09:11:31,657 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4804979850848516, 'Total loss': 0.4804979850848516} | train loss {'Reaction outcome loss': 0.11667305975722843, 'Total loss': 0.11667305975722843}
2022-12-31 09:11:31,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:31,658 INFO:     Epoch: 95
2022-12-31 09:11:33,251 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4303626924753189, 'Total loss': 0.4303626924753189} | train loss {'Reaction outcome loss': 0.11459085112093945, 'Total loss': 0.11459085112093945}
2022-12-31 09:11:33,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:33,251 INFO:     Epoch: 96
2022-12-31 09:11:34,844 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44116997690871357, 'Total loss': 0.44116997690871357} | train loss {'Reaction outcome loss': 0.11034196899083487, 'Total loss': 0.11034196899083487}
2022-12-31 09:11:34,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:34,844 INFO:     Epoch: 97
2022-12-31 09:11:36,443 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4385588233669599, 'Total loss': 0.4385588233669599} | train loss {'Reaction outcome loss': 0.11040998733777732, 'Total loss': 0.11040998733777732}
2022-12-31 09:11:36,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:36,444 INFO:     Epoch: 98
2022-12-31 09:11:38,036 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4416835824648539, 'Total loss': 0.4416835824648539} | train loss {'Reaction outcome loss': 0.1056048149806602, 'Total loss': 0.1056048149806602}
2022-12-31 09:11:38,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:38,037 INFO:     Epoch: 99
2022-12-31 09:11:39,624 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46463689605395, 'Total loss': 0.46463689605395} | train loss {'Reaction outcome loss': 0.11162328553760624, 'Total loss': 0.11162328553760624}
2022-12-31 09:11:39,624 INFO:     Best model found after epoch 17 of 100.
2022-12-31 09:11:39,624 INFO:   Done with stage: TRAINING
2022-12-31 09:11:39,624 INFO:   Starting stage: EVALUATION
2022-12-31 09:11:39,773 INFO:   Done with stage: EVALUATION
2022-12-31 09:11:39,773 INFO:   Leaving out SEQ value Fold_3
2022-12-31 09:11:39,786 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 09:11:39,786 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:11:40,431 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:11:40,431 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:11:40,497 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:11:40,497 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:11:40,497 INFO:     No hyperparam tuning for this model
2022-12-31 09:11:40,498 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:11:40,498 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:11:40,498 INFO:     None feature selector for col prot
2022-12-31 09:11:40,498 INFO:     None feature selector for col prot
2022-12-31 09:11:40,499 INFO:     None feature selector for col prot
2022-12-31 09:11:40,499 INFO:     None feature selector for col chem
2022-12-31 09:11:40,499 INFO:     None feature selector for col chem
2022-12-31 09:11:40,499 INFO:     None feature selector for col chem
2022-12-31 09:11:40,499 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:11:40,499 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:11:40,501 INFO:     Number of params in model 224011
2022-12-31 09:11:40,504 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:11:40,505 INFO:   Starting stage: TRAINING
2022-12-31 09:11:40,550 INFO:     Val loss before train {'Reaction outcome loss': 1.1376041611035665, 'Total loss': 1.1376041611035665}
2022-12-31 09:11:40,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:40,550 INFO:     Epoch: 0
2022-12-31 09:11:42,130 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5393898338079453, 'Total loss': 0.5393898338079453} | train loss {'Reaction outcome loss': 0.7632591893202264, 'Total loss': 0.7632591893202264}
2022-12-31 09:11:42,130 INFO:     Found new best model at epoch 0
2022-12-31 09:11:42,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:42,131 INFO:     Epoch: 1
2022-12-31 09:11:43,711 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46930835843086244, 'Total loss': 0.46930835843086244} | train loss {'Reaction outcome loss': 0.4975250403489574, 'Total loss': 0.4975250403489574}
2022-12-31 09:11:43,712 INFO:     Found new best model at epoch 1
2022-12-31 09:11:43,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:43,713 INFO:     Epoch: 2
2022-12-31 09:11:45,294 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45288573106129965, 'Total loss': 0.45288573106129965} | train loss {'Reaction outcome loss': 0.43878831469704743, 'Total loss': 0.43878831469704743}
2022-12-31 09:11:45,294 INFO:     Found new best model at epoch 2
2022-12-31 09:11:45,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:45,295 INFO:     Epoch: 3
2022-12-31 09:11:46,875 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4144359896580378, 'Total loss': 0.4144359896580378} | train loss {'Reaction outcome loss': 0.3998674105069294, 'Total loss': 0.3998674105069294}
2022-12-31 09:11:46,876 INFO:     Found new best model at epoch 3
2022-12-31 09:11:46,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:46,877 INFO:     Epoch: 4
2022-12-31 09:11:48,455 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4324238042036692, 'Total loss': 0.4324238042036692} | train loss {'Reaction outcome loss': 0.3734939007356598, 'Total loss': 0.3734939007356598}
2022-12-31 09:11:48,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:48,456 INFO:     Epoch: 5
2022-12-31 09:11:50,052 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4163444697856903, 'Total loss': 0.4163444697856903} | train loss {'Reaction outcome loss': 0.35139131447046007, 'Total loss': 0.35139131447046007}
2022-12-31 09:11:50,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:50,052 INFO:     Epoch: 6
2022-12-31 09:11:51,651 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41875580747922264, 'Total loss': 0.41875580747922264} | train loss {'Reaction outcome loss': 0.32789747379857676, 'Total loss': 0.32789747379857676}
2022-12-31 09:11:51,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:51,651 INFO:     Epoch: 7
2022-12-31 09:11:53,250 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41216249267260235, 'Total loss': 0.41216249267260235} | train loss {'Reaction outcome loss': 0.3088387010062313, 'Total loss': 0.3088387010062313}
2022-12-31 09:11:53,250 INFO:     Found new best model at epoch 7
2022-12-31 09:11:53,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:53,251 INFO:     Epoch: 8
2022-12-31 09:11:54,850 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42676181892553966, 'Total loss': 0.42676181892553966} | train loss {'Reaction outcome loss': 0.29176622258011264, 'Total loss': 0.29176622258011264}
2022-12-31 09:11:54,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:54,850 INFO:     Epoch: 9
2022-12-31 09:11:56,436 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44954347709814707, 'Total loss': 0.44954347709814707} | train loss {'Reaction outcome loss': 0.2783547576338163, 'Total loss': 0.2783547576338163}
2022-12-31 09:11:56,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:56,437 INFO:     Epoch: 10
2022-12-31 09:11:58,025 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4137223521868388, 'Total loss': 0.4137223521868388} | train loss {'Reaction outcome loss': 0.2646603365720858, 'Total loss': 0.2646603365720858}
2022-12-31 09:11:58,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:58,025 INFO:     Epoch: 11
2022-12-31 09:11:59,656 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41198716362317406, 'Total loss': 0.41198716362317406} | train loss {'Reaction outcome loss': 0.2545501790198453, 'Total loss': 0.2545501790198453}
2022-12-31 09:11:59,656 INFO:     Found new best model at epoch 11
2022-12-31 09:11:59,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:11:59,657 INFO:     Epoch: 12
2022-12-31 09:12:01,245 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41266827781995136, 'Total loss': 0.41266827781995136} | train loss {'Reaction outcome loss': 0.2402876159554258, 'Total loss': 0.2402876159554258}
2022-12-31 09:12:01,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:01,245 INFO:     Epoch: 13
2022-12-31 09:12:02,876 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4549881279468536, 'Total loss': 0.4549881279468536} | train loss {'Reaction outcome loss': 0.2293607033376764, 'Total loss': 0.2293607033376764}
2022-12-31 09:12:02,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:02,876 INFO:     Epoch: 14
2022-12-31 09:12:04,464 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42121008733908333, 'Total loss': 0.42121008733908333} | train loss {'Reaction outcome loss': 0.2257271668430404, 'Total loss': 0.2257271668430404}
2022-12-31 09:12:04,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:04,464 INFO:     Epoch: 15
2022-12-31 09:12:06,068 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3763512348135312, 'Total loss': 0.3763512348135312} | train loss {'Reaction outcome loss': 0.21780874882566972, 'Total loss': 0.21780874882566972}
2022-12-31 09:12:06,068 INFO:     Found new best model at epoch 15
2022-12-31 09:12:06,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:06,069 INFO:     Epoch: 16
2022-12-31 09:12:07,665 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4024496853351593, 'Total loss': 0.4024496853351593} | train loss {'Reaction outcome loss': 0.21277394273569222, 'Total loss': 0.21277394273569222}
2022-12-31 09:12:07,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:07,667 INFO:     Epoch: 17
2022-12-31 09:12:09,263 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3962652663389842, 'Total loss': 0.3962652663389842} | train loss {'Reaction outcome loss': 0.20360545815411968, 'Total loss': 0.20360545815411968}
2022-12-31 09:12:09,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:09,263 INFO:     Epoch: 18
2022-12-31 09:12:10,862 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4032643715540568, 'Total loss': 0.4032643715540568} | train loss {'Reaction outcome loss': 0.19813854843927925, 'Total loss': 0.19813854843927925}
2022-12-31 09:12:10,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:10,862 INFO:     Epoch: 19
2022-12-31 09:12:12,461 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4469101985295614, 'Total loss': 0.4469101985295614} | train loss {'Reaction outcome loss': 0.19335309512968213, 'Total loss': 0.19335309512968213}
2022-12-31 09:12:12,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:12,461 INFO:     Epoch: 20
2022-12-31 09:12:14,058 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47024676005045574, 'Total loss': 0.47024676005045574} | train loss {'Reaction outcome loss': 0.18793001023853176, 'Total loss': 0.18793001023853176}
2022-12-31 09:12:14,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:14,058 INFO:     Epoch: 21
2022-12-31 09:12:15,640 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4112158412734667, 'Total loss': 0.4112158412734667} | train loss {'Reaction outcome loss': 0.1831458402295834, 'Total loss': 0.1831458402295834}
2022-12-31 09:12:15,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:15,641 INFO:     Epoch: 22
2022-12-31 09:12:17,239 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47133684158325195, 'Total loss': 0.47133684158325195} | train loss {'Reaction outcome loss': 0.17920688134910215, 'Total loss': 0.17920688134910215}
2022-12-31 09:12:17,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:17,239 INFO:     Epoch: 23
2022-12-31 09:12:18,837 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44376897712548574, 'Total loss': 0.44376897712548574} | train loss {'Reaction outcome loss': 0.17671110951496335, 'Total loss': 0.17671110951496335}
2022-12-31 09:12:18,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:18,837 INFO:     Epoch: 24
2022-12-31 09:12:20,435 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4429698556661606, 'Total loss': 0.4429698556661606} | train loss {'Reaction outcome loss': 0.1715772918483923, 'Total loss': 0.1715772918483923}
2022-12-31 09:12:20,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:20,435 INFO:     Epoch: 25
2022-12-31 09:12:22,034 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4450848350922267, 'Total loss': 0.4450848350922267} | train loss {'Reaction outcome loss': 0.1683089777593573, 'Total loss': 0.1683089777593573}
2022-12-31 09:12:22,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:22,034 INFO:     Epoch: 26
2022-12-31 09:12:23,630 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4137732985119025, 'Total loss': 0.4137732985119025} | train loss {'Reaction outcome loss': 0.1634668315764228, 'Total loss': 0.1634668315764228}
2022-12-31 09:12:23,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:23,630 INFO:     Epoch: 27
2022-12-31 09:12:25,261 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4750090499718984, 'Total loss': 0.4750090499718984} | train loss {'Reaction outcome loss': 0.1616086852719588, 'Total loss': 0.1616086852719588}
2022-12-31 09:12:25,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:25,262 INFO:     Epoch: 28
2022-12-31 09:12:26,860 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4277599294980367, 'Total loss': 0.4277599294980367} | train loss {'Reaction outcome loss': 0.1551882461868089, 'Total loss': 0.1551882461868089}
2022-12-31 09:12:26,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:26,860 INFO:     Epoch: 29
2022-12-31 09:12:28,453 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43929403126239774, 'Total loss': 0.43929403126239774} | train loss {'Reaction outcome loss': 0.1553037872613576, 'Total loss': 0.1553037872613576}
2022-12-31 09:12:28,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:28,453 INFO:     Epoch: 30
2022-12-31 09:12:30,089 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4671976794799169, 'Total loss': 0.4671976794799169} | train loss {'Reaction outcome loss': 0.15246456433293784, 'Total loss': 0.15246456433293784}
2022-12-31 09:12:30,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:30,089 INFO:     Epoch: 31
2022-12-31 09:12:31,684 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43956318000952405, 'Total loss': 0.43956318000952405} | train loss {'Reaction outcome loss': 0.15095691510727044, 'Total loss': 0.15095691510727044}
2022-12-31 09:12:31,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:31,684 INFO:     Epoch: 32
2022-12-31 09:12:33,272 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44146812881032627, 'Total loss': 0.44146812881032627} | train loss {'Reaction outcome loss': 0.1486301237126173, 'Total loss': 0.1486301237126173}
2022-12-31 09:12:33,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:33,273 INFO:     Epoch: 33
2022-12-31 09:12:34,873 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42786216114958125, 'Total loss': 0.42786216114958125} | train loss {'Reaction outcome loss': 0.14392368073104383, 'Total loss': 0.14392368073104383}
2022-12-31 09:12:34,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:34,874 INFO:     Epoch: 34
2022-12-31 09:12:36,472 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5171648581822713, 'Total loss': 0.5171648581822713} | train loss {'Reaction outcome loss': 0.1433257754596562, 'Total loss': 0.1433257754596562}
2022-12-31 09:12:36,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:36,473 INFO:     Epoch: 35
2022-12-31 09:12:38,072 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47367390592892966, 'Total loss': 0.47367390592892966} | train loss {'Reaction outcome loss': 0.1444281264838876, 'Total loss': 0.1444281264838876}
2022-12-31 09:12:38,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:38,072 INFO:     Epoch: 36
2022-12-31 09:12:39,672 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4662118156750997, 'Total loss': 0.4662118156750997} | train loss {'Reaction outcome loss': 0.14400077386109703, 'Total loss': 0.14400077386109703}
2022-12-31 09:12:39,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:39,673 INFO:     Epoch: 37
2022-12-31 09:12:41,272 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4336459485193094, 'Total loss': 0.4336459485193094} | train loss {'Reaction outcome loss': 0.1406400879240179, 'Total loss': 0.1406400879240179}
2022-12-31 09:12:41,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:41,272 INFO:     Epoch: 38
2022-12-31 09:12:42,844 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48036016821861266, 'Total loss': 0.48036016821861266} | train loss {'Reaction outcome loss': 0.13776052128729785, 'Total loss': 0.13776052128729785}
2022-12-31 09:12:42,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:42,845 INFO:     Epoch: 39
2022-12-31 09:12:44,479 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4747549166282018, 'Total loss': 0.4747549166282018} | train loss {'Reaction outcome loss': 0.13548676184691297, 'Total loss': 0.13548676184691297}
2022-12-31 09:12:44,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:44,480 INFO:     Epoch: 40
2022-12-31 09:12:46,115 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.496550323565801, 'Total loss': 0.496550323565801} | train loss {'Reaction outcome loss': 0.13205364686729062, 'Total loss': 0.13205364686729062}
2022-12-31 09:12:46,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:46,116 INFO:     Epoch: 41
2022-12-31 09:12:47,705 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5012910939753056, 'Total loss': 0.5012910939753056} | train loss {'Reaction outcome loss': 0.13260012788945513, 'Total loss': 0.13260012788945513}
2022-12-31 09:12:47,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:47,706 INFO:     Epoch: 42
2022-12-31 09:12:49,342 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4790184696515401, 'Total loss': 0.4790184696515401} | train loss {'Reaction outcome loss': 0.13177237938058553, 'Total loss': 0.13177237938058553}
2022-12-31 09:12:49,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:49,342 INFO:     Epoch: 43
2022-12-31 09:12:50,934 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47053552071253457, 'Total loss': 0.47053552071253457} | train loss {'Reaction outcome loss': 0.1285972322983413, 'Total loss': 0.1285972322983413}
2022-12-31 09:12:50,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:50,935 INFO:     Epoch: 44
2022-12-31 09:12:52,513 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49355570077896116, 'Total loss': 0.49355570077896116} | train loss {'Reaction outcome loss': 0.1302067780011502, 'Total loss': 0.1302067780011502}
2022-12-31 09:12:52,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:52,513 INFO:     Epoch: 45
2022-12-31 09:12:54,115 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5160807311534882, 'Total loss': 0.5160807311534882} | train loss {'Reaction outcome loss': 0.1307600876728822, 'Total loss': 0.1307600876728822}
2022-12-31 09:12:54,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:54,115 INFO:     Epoch: 46
2022-12-31 09:12:55,718 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5347397436698278, 'Total loss': 0.5347397436698278} | train loss {'Reaction outcome loss': 0.12517219318448122, 'Total loss': 0.12517219318448122}
2022-12-31 09:12:55,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:55,718 INFO:     Epoch: 47
2022-12-31 09:12:57,319 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4599033951759338, 'Total loss': 0.4599033951759338} | train loss {'Reaction outcome loss': 0.12390763145043236, 'Total loss': 0.12390763145043236}
2022-12-31 09:12:57,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:57,319 INFO:     Epoch: 48
2022-12-31 09:12:58,921 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.50693252881368, 'Total loss': 0.50693252881368} | train loss {'Reaction outcome loss': 0.12481485881303124, 'Total loss': 0.12481485881303124}
2022-12-31 09:12:58,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:12:58,922 INFO:     Epoch: 49
2022-12-31 09:13:00,499 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4693022191524506, 'Total loss': 0.4693022191524506} | train loss {'Reaction outcome loss': 0.1263708015525803, 'Total loss': 0.1263708015525803}
2022-12-31 09:13:00,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:00,499 INFO:     Epoch: 50
2022-12-31 09:13:02,135 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49575120707352954, 'Total loss': 0.49575120707352954} | train loss {'Reaction outcome loss': 0.1266506545355619, 'Total loss': 0.1266506545355619}
2022-12-31 09:13:02,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:02,135 INFO:     Epoch: 51
2022-12-31 09:13:03,770 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5019465645154317, 'Total loss': 0.5019465645154317} | train loss {'Reaction outcome loss': 0.12451074868303164, 'Total loss': 0.12451074868303164}
2022-12-31 09:13:03,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:03,770 INFO:     Epoch: 52
2022-12-31 09:13:05,364 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4836434641232093, 'Total loss': 0.4836434641232093} | train loss {'Reaction outcome loss': 0.12586678642559646, 'Total loss': 0.12586678642559646}
2022-12-31 09:13:05,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:05,364 INFO:     Epoch: 53
2022-12-31 09:13:06,999 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4562742513914903, 'Total loss': 0.4562742513914903} | train loss {'Reaction outcome loss': 0.12373624844785876, 'Total loss': 0.12373624844785876}
2022-12-31 09:13:06,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:07,000 INFO:     Epoch: 54
2022-12-31 09:13:08,635 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44924627693059543, 'Total loss': 0.44924627693059543} | train loss {'Reaction outcome loss': 0.1190172545302563, 'Total loss': 0.1190172545302563}
2022-12-31 09:13:08,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:08,635 INFO:     Epoch: 55
2022-12-31 09:13:10,219 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49699741999308267, 'Total loss': 0.49699741999308267} | train loss {'Reaction outcome loss': 0.1174336689605113, 'Total loss': 0.1174336689605113}
2022-12-31 09:13:10,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:10,219 INFO:     Epoch: 56
2022-12-31 09:13:11,856 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47891633411248524, 'Total loss': 0.47891633411248524} | train loss {'Reaction outcome loss': 0.11892105529524688, 'Total loss': 0.11892105529524688}
2022-12-31 09:13:11,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:11,857 INFO:     Epoch: 57
2022-12-31 09:13:13,494 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47297126551469165, 'Total loss': 0.47297126551469165} | train loss {'Reaction outcome loss': 0.11683832595599093, 'Total loss': 0.11683832595599093}
2022-12-31 09:13:13,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:13,494 INFO:     Epoch: 58
2022-12-31 09:13:15,081 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4608227292696635, 'Total loss': 0.4608227292696635} | train loss {'Reaction outcome loss': 0.11944285891537737, 'Total loss': 0.11944285891537737}
2022-12-31 09:13:15,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:15,082 INFO:     Epoch: 59
2022-12-31 09:13:16,667 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5391030083100001, 'Total loss': 0.5391030083100001} | train loss {'Reaction outcome loss': 0.11877346792553871, 'Total loss': 0.11877346792553871}
2022-12-31 09:13:16,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:16,667 INFO:     Epoch: 60
2022-12-31 09:13:18,303 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46454933285713196, 'Total loss': 0.46454933285713196} | train loss {'Reaction outcome loss': 0.1223542722572686, 'Total loss': 0.1223542722572686}
2022-12-31 09:13:18,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:18,303 INFO:     Epoch: 61
2022-12-31 09:13:19,873 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46023857523687184, 'Total loss': 0.46023857523687184} | train loss {'Reaction outcome loss': 0.11782456263109382, 'Total loss': 0.11782456263109382}
2022-12-31 09:13:19,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:19,874 INFO:     Epoch: 62
2022-12-31 09:13:21,476 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4554704988491721, 'Total loss': 0.4554704988491721} | train loss {'Reaction outcome loss': 0.11530091201309184, 'Total loss': 0.11530091201309184}
2022-12-31 09:13:21,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:21,477 INFO:     Epoch: 63
2022-12-31 09:13:23,079 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48266794135173163, 'Total loss': 0.48266794135173163} | train loss {'Reaction outcome loss': 0.11231666892368306, 'Total loss': 0.11231666892368306}
2022-12-31 09:13:23,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:23,079 INFO:     Epoch: 64
2022-12-31 09:13:24,682 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5083044370015463, 'Total loss': 0.5083044370015463} | train loss {'Reaction outcome loss': 0.11481598298653026, 'Total loss': 0.11481598298653026}
2022-12-31 09:13:24,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:24,682 INFO:     Epoch: 65
2022-12-31 09:13:26,286 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47585403037567936, 'Total loss': 0.47585403037567936} | train loss {'Reaction outcome loss': 0.1118909561683551, 'Total loss': 0.1118909561683551}
2022-12-31 09:13:26,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:26,286 INFO:     Epoch: 66
2022-12-31 09:13:27,857 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4625369685391585, 'Total loss': 0.4625369685391585} | train loss {'Reaction outcome loss': 0.11594142457573396, 'Total loss': 0.11594142457573396}
2022-12-31 09:13:27,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:27,858 INFO:     Epoch: 67
2022-12-31 09:13:29,458 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49280751049518584, 'Total loss': 0.49280751049518584} | train loss {'Reaction outcome loss': 0.11977877449914401, 'Total loss': 0.11977877449914401}
2022-12-31 09:13:29,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:29,458 INFO:     Epoch: 68
2022-12-31 09:13:31,075 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44886316986133656, 'Total loss': 0.44886316986133656} | train loss {'Reaction outcome loss': 0.11540095898154366, 'Total loss': 0.11540095898154366}
2022-12-31 09:13:31,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:31,075 INFO:     Epoch: 69
2022-12-31 09:13:32,714 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4671474228302638, 'Total loss': 0.4671474228302638} | train loss {'Reaction outcome loss': 0.11670312731495862, 'Total loss': 0.11670312731495862}
2022-12-31 09:13:32,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:32,715 INFO:     Epoch: 70
2022-12-31 09:13:34,351 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45657056098182996, 'Total loss': 0.45657056098182996} | train loss {'Reaction outcome loss': 0.11296349700464699, 'Total loss': 0.11296349700464699}
2022-12-31 09:13:34,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:34,352 INFO:     Epoch: 71
2022-12-31 09:13:35,936 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5061374078194301, 'Total loss': 0.5061374078194301} | train loss {'Reaction outcome loss': 0.10956538886835325, 'Total loss': 0.10956538886835325}
2022-12-31 09:13:35,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:35,936 INFO:     Epoch: 72
2022-12-31 09:13:37,527 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5060418645540873, 'Total loss': 0.5060418645540873} | train loss {'Reaction outcome loss': 0.11224342157851176, 'Total loss': 0.11224342157851176}
2022-12-31 09:13:37,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:37,528 INFO:     Epoch: 73
2022-12-31 09:13:39,163 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5139492998520533, 'Total loss': 0.5139492998520533} | train loss {'Reaction outcome loss': 0.11366589453476876, 'Total loss': 0.11366589453476876}
2022-12-31 09:13:39,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:39,163 INFO:     Epoch: 74
2022-12-31 09:13:40,795 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48757318953673046, 'Total loss': 0.48757318953673046} | train loss {'Reaction outcome loss': 0.11568880122072472, 'Total loss': 0.11568880122072472}
2022-12-31 09:13:40,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:40,795 INFO:     Epoch: 75
2022-12-31 09:13:42,427 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48483024835586547, 'Total loss': 0.48483024835586547} | train loss {'Reaction outcome loss': 0.1098341397602606, 'Total loss': 0.1098341397602606}
2022-12-31 09:13:42,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:42,428 INFO:     Epoch: 76
2022-12-31 09:13:44,059 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48608394463857013, 'Total loss': 0.48608394463857013} | train loss {'Reaction outcome loss': 0.10614312582089122, 'Total loss': 0.10614312582089122}
2022-12-31 09:13:44,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:44,059 INFO:     Epoch: 77
2022-12-31 09:13:45,693 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5432282184561094, 'Total loss': 0.5432282184561094} | train loss {'Reaction outcome loss': 0.10785581883235501, 'Total loss': 0.10785581883235501}
2022-12-31 09:13:45,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:45,693 INFO:     Epoch: 78
2022-12-31 09:13:47,236 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.511760209997495, 'Total loss': 0.511760209997495} | train loss {'Reaction outcome loss': 0.11046249221673586, 'Total loss': 0.11046249221673586}
2022-12-31 09:13:47,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:47,236 INFO:     Epoch: 79
2022-12-31 09:13:48,869 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.470516744752725, 'Total loss': 0.470516744752725} | train loss {'Reaction outcome loss': 0.11861922318627886, 'Total loss': 0.11861922318627886}
2022-12-31 09:13:48,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:48,870 INFO:     Epoch: 80
2022-12-31 09:13:50,449 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48457816541194915, 'Total loss': 0.48457816541194915} | train loss {'Reaction outcome loss': 0.11149773418016705, 'Total loss': 0.11149773418016705}
2022-12-31 09:13:50,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:50,451 INFO:     Epoch: 81
2022-12-31 09:13:52,028 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4730068196853002, 'Total loss': 0.4730068196853002} | train loss {'Reaction outcome loss': 0.10580677043765137, 'Total loss': 0.10580677043765137}
2022-12-31 09:13:52,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:52,028 INFO:     Epoch: 82
2022-12-31 09:13:53,661 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5006133655707041, 'Total loss': 0.5006133655707041} | train loss {'Reaction outcome loss': 0.10346343090957051, 'Total loss': 0.10346343090957051}
2022-12-31 09:13:53,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:53,661 INFO:     Epoch: 83
2022-12-31 09:13:55,289 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4551331251859665, 'Total loss': 0.4551331251859665} | train loss {'Reaction outcome loss': 0.11315565125851779, 'Total loss': 0.11315565125851779}
2022-12-31 09:13:55,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:55,289 INFO:     Epoch: 84
2022-12-31 09:13:56,898 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47510585486888884, 'Total loss': 0.47510585486888884} | train loss {'Reaction outcome loss': 0.11412139674236249, 'Total loss': 0.11412139674236249}
2022-12-31 09:13:56,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:56,899 INFO:     Epoch: 85
2022-12-31 09:13:58,485 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4906264583269755, 'Total loss': 0.4906264583269755} | train loss {'Reaction outcome loss': 0.11712160967359134, 'Total loss': 0.11712160967359134}
2022-12-31 09:13:58,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:13:58,485 INFO:     Epoch: 86
2022-12-31 09:14:00,118 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5284205377101898, 'Total loss': 0.5284205377101898} | train loss {'Reaction outcome loss': 0.1080249039940811, 'Total loss': 0.1080249039940811}
2022-12-31 09:14:00,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:00,118 INFO:     Epoch: 87
2022-12-31 09:14:01,706 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4767751932144165, 'Total loss': 0.4767751932144165} | train loss {'Reaction outcome loss': 0.10815681206797871, 'Total loss': 0.10815681206797871}
2022-12-31 09:14:01,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:01,706 INFO:     Epoch: 88
2022-12-31 09:14:03,340 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49780012369155885, 'Total loss': 0.49780012369155885} | train loss {'Reaction outcome loss': 0.10393388608360588, 'Total loss': 0.10393388608360588}
2022-12-31 09:14:03,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:03,340 INFO:     Epoch: 89
2022-12-31 09:14:04,880 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.452124128252035, 'Total loss': 0.452124128252035} | train loss {'Reaction outcome loss': 0.1016072696452871, 'Total loss': 0.1016072696452871}
2022-12-31 09:14:04,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:04,881 INFO:     Epoch: 90
2022-12-31 09:14:06,476 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4878996044397354, 'Total loss': 0.4878996044397354} | train loss {'Reaction outcome loss': 0.10506811725771281, 'Total loss': 0.10506811725771281}
2022-12-31 09:14:06,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:06,477 INFO:     Epoch: 91
2022-12-31 09:14:08,074 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4497326875726382, 'Total loss': 0.4497326875726382} | train loss {'Reaction outcome loss': 0.10576504639288019, 'Total loss': 0.10576504639288019}
2022-12-31 09:14:08,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:08,074 INFO:     Epoch: 92
2022-12-31 09:14:09,667 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4364107340574265, 'Total loss': 0.4364107340574265} | train loss {'Reaction outcome loss': 0.1059668255399404, 'Total loss': 0.1059668255399404}
2022-12-31 09:14:09,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:09,668 INFO:     Epoch: 93
2022-12-31 09:14:11,263 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4640918125708898, 'Total loss': 0.4640918125708898} | train loss {'Reaction outcome loss': 0.10703695086140282, 'Total loss': 0.10703695086140282}
2022-12-31 09:14:11,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:11,264 INFO:     Epoch: 94
2022-12-31 09:14:12,857 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5023056358098984, 'Total loss': 0.5023056358098984} | train loss {'Reaction outcome loss': 0.10979320184152394, 'Total loss': 0.10979320184152394}
2022-12-31 09:14:12,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:12,857 INFO:     Epoch: 95
2022-12-31 09:14:14,412 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4734718171413988, 'Total loss': 0.4734718171413988} | train loss {'Reaction outcome loss': 0.1056647711997075, 'Total loss': 0.1056647711997075}
2022-12-31 09:14:14,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:14,412 INFO:     Epoch: 96
2022-12-31 09:14:16,000 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4477007200320562, 'Total loss': 0.4477007200320562} | train loss {'Reaction outcome loss': 0.10652819554565468, 'Total loss': 0.10652819554565468}
2022-12-31 09:14:16,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:16,000 INFO:     Epoch: 97
2022-12-31 09:14:17,634 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.442629542776073, 'Total loss': 0.442629542776073} | train loss {'Reaction outcome loss': 0.10469458957213043, 'Total loss': 0.10469458957213043}
2022-12-31 09:14:17,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:17,634 INFO:     Epoch: 98
2022-12-31 09:14:19,268 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4779817958672841, 'Total loss': 0.4779817958672841} | train loss {'Reaction outcome loss': 0.10582185791104318, 'Total loss': 0.10582185791104318}
2022-12-31 09:14:19,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:19,268 INFO:     Epoch: 99
2022-12-31 09:14:20,902 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4906293590863546, 'Total loss': 0.4906293590863546} | train loss {'Reaction outcome loss': 0.10515088568754302, 'Total loss': 0.10515088568754302}
2022-12-31 09:14:20,903 INFO:     Best model found after epoch 16 of 100.
2022-12-31 09:14:20,903 INFO:   Done with stage: TRAINING
2022-12-31 09:14:20,903 INFO:   Starting stage: EVALUATION
2022-12-31 09:14:21,051 INFO:   Done with stage: EVALUATION
2022-12-31 09:14:21,051 INFO:   Leaving out SEQ value Fold_4
2022-12-31 09:14:21,064 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 09:14:21,064 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:14:21,709 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:14:21,709 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:14:21,776 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:14:21,776 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:14:21,776 INFO:     No hyperparam tuning for this model
2022-12-31 09:14:21,776 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:14:21,776 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:14:21,777 INFO:     None feature selector for col prot
2022-12-31 09:14:21,777 INFO:     None feature selector for col prot
2022-12-31 09:14:21,777 INFO:     None feature selector for col prot
2022-12-31 09:14:21,778 INFO:     None feature selector for col chem
2022-12-31 09:14:21,778 INFO:     None feature selector for col chem
2022-12-31 09:14:21,778 INFO:     None feature selector for col chem
2022-12-31 09:14:21,778 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:14:21,778 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:14:21,780 INFO:     Number of params in model 224011
2022-12-31 09:14:21,783 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:14:21,783 INFO:   Starting stage: TRAINING
2022-12-31 09:14:21,827 INFO:     Val loss before train {'Reaction outcome loss': 0.9053754806518555, 'Total loss': 0.9053754806518555}
2022-12-31 09:14:21,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:21,827 INFO:     Epoch: 0
2022-12-31 09:14:23,383 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5451547980308533, 'Total loss': 0.5451547980308533} | train loss {'Reaction outcome loss': 0.7655778360495928, 'Total loss': 0.7655778360495928}
2022-12-31 09:14:23,384 INFO:     Found new best model at epoch 0
2022-12-31 09:14:23,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:23,385 INFO:     Epoch: 1
2022-12-31 09:14:25,001 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5104652374982834, 'Total loss': 0.5104652374982834} | train loss {'Reaction outcome loss': 0.5069088125702276, 'Total loss': 0.5069088125702276}
2022-12-31 09:14:25,001 INFO:     Found new best model at epoch 1
2022-12-31 09:14:25,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:25,003 INFO:     Epoch: 2
2022-12-31 09:14:26,625 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4404908359050751, 'Total loss': 0.4404908359050751} | train loss {'Reaction outcome loss': 0.4429822136456355, 'Total loss': 0.4429822136456355}
2022-12-31 09:14:26,625 INFO:     Found new best model at epoch 2
2022-12-31 09:14:26,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:26,626 INFO:     Epoch: 3
2022-12-31 09:14:28,250 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42172902822494507, 'Total loss': 0.42172902822494507} | train loss {'Reaction outcome loss': 0.4036609457287978, 'Total loss': 0.4036609457287978}
2022-12-31 09:14:28,251 INFO:     Found new best model at epoch 3
2022-12-31 09:14:28,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:28,252 INFO:     Epoch: 4
2022-12-31 09:14:29,877 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4313616712888082, 'Total loss': 0.4313616712888082} | train loss {'Reaction outcome loss': 0.37370990598675147, 'Total loss': 0.37370990598675147}
2022-12-31 09:14:29,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:29,877 INFO:     Epoch: 5
2022-12-31 09:14:31,505 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4257959614197413, 'Total loss': 0.4257959614197413} | train loss {'Reaction outcome loss': 0.3523300477313651, 'Total loss': 0.3523300477313651}
2022-12-31 09:14:31,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:31,505 INFO:     Epoch: 6
2022-12-31 09:14:33,119 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4647865295410156, 'Total loss': 0.4647865295410156} | train loss {'Reaction outcome loss': 0.3333567091623583, 'Total loss': 0.3333567091623583}
2022-12-31 09:14:33,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:33,119 INFO:     Epoch: 7
2022-12-31 09:14:34,786 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.39619372338056563, 'Total loss': 0.39619372338056563} | train loss {'Reaction outcome loss': 0.31540093726952584, 'Total loss': 0.31540093726952584}
2022-12-31 09:14:34,786 INFO:     Found new best model at epoch 7
2022-12-31 09:14:34,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:34,787 INFO:     Epoch: 8
2022-12-31 09:14:36,407 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3971743534008662, 'Total loss': 0.3971743534008662} | train loss {'Reaction outcome loss': 0.2989031249650549, 'Total loss': 0.2989031249650549}
2022-12-31 09:14:36,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:36,408 INFO:     Epoch: 9
2022-12-31 09:14:38,033 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38078530728816984, 'Total loss': 0.38078530728816984} | train loss {'Reaction outcome loss': 0.28474512048038764, 'Total loss': 0.28474512048038764}
2022-12-31 09:14:38,033 INFO:     Found new best model at epoch 9
2022-12-31 09:14:38,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:38,034 INFO:     Epoch: 10
2022-12-31 09:14:39,654 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4035239110390345, 'Total loss': 0.4035239110390345} | train loss {'Reaction outcome loss': 0.2763694091044393, 'Total loss': 0.2763694091044393}
2022-12-31 09:14:39,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:39,654 INFO:     Epoch: 11
2022-12-31 09:14:41,237 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41580536564191184, 'Total loss': 0.41580536564191184} | train loss {'Reaction outcome loss': 0.2645716863391847, 'Total loss': 0.2645716863391847}
2022-12-31 09:14:41,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:41,238 INFO:     Epoch: 12
2022-12-31 09:14:42,861 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41284399628639223, 'Total loss': 0.41284399628639223} | train loss {'Reaction outcome loss': 0.25159163418014124, 'Total loss': 0.25159163418014124}
2022-12-31 09:14:42,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:42,861 INFO:     Epoch: 13
2022-12-31 09:14:44,528 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4031852493683497, 'Total loss': 0.4031852493683497} | train loss {'Reaction outcome loss': 0.2433751425722661, 'Total loss': 0.2433751425722661}
2022-12-31 09:14:44,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:44,528 INFO:     Epoch: 14
2022-12-31 09:14:46,151 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40483586887518563, 'Total loss': 0.40483586887518563} | train loss {'Reaction outcome loss': 0.23972000314817102, 'Total loss': 0.23972000314817102}
2022-12-31 09:14:46,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:46,151 INFO:     Epoch: 15
2022-12-31 09:14:47,818 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42313425143559774, 'Total loss': 0.42313425143559774} | train loss {'Reaction outcome loss': 0.23160889364160356, 'Total loss': 0.23160889364160356}
2022-12-31 09:14:47,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:47,818 INFO:     Epoch: 16
2022-12-31 09:14:49,484 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3921627600987752, 'Total loss': 0.3921627600987752} | train loss {'Reaction outcome loss': 0.22397156250713535, 'Total loss': 0.22397156250713535}
2022-12-31 09:14:49,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:49,485 INFO:     Epoch: 17
2022-12-31 09:14:51,077 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3897230292359988, 'Total loss': 0.3897230292359988} | train loss {'Reaction outcome loss': 0.21725605738883844, 'Total loss': 0.21725605738883844}
2022-12-31 09:14:51,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:51,078 INFO:     Epoch: 18
2022-12-31 09:14:52,694 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40639411509037016, 'Total loss': 0.40639411509037016} | train loss {'Reaction outcome loss': 0.20935947624193202, 'Total loss': 0.20935947624193202}
2022-12-31 09:14:52,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:52,695 INFO:     Epoch: 19
2022-12-31 09:14:54,312 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41156528492768607, 'Total loss': 0.41156528492768607} | train loss {'Reaction outcome loss': 0.2049492112350808, 'Total loss': 0.2049492112350808}
2022-12-31 09:14:54,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:54,313 INFO:     Epoch: 20
2022-12-31 09:14:55,931 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40901034673055015, 'Total loss': 0.40901034673055015} | train loss {'Reaction outcome loss': 0.20246807757482632, 'Total loss': 0.20246807757482632}
2022-12-31 09:14:55,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:55,931 INFO:     Epoch: 21
2022-12-31 09:14:57,550 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39724955161412556, 'Total loss': 0.39724955161412556} | train loss {'Reaction outcome loss': 0.19570945565746795, 'Total loss': 0.19570945565746795}
2022-12-31 09:14:57,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:57,550 INFO:     Epoch: 22
2022-12-31 09:14:59,139 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39806124766667683, 'Total loss': 0.39806124766667683} | train loss {'Reaction outcome loss': 0.19304125491085897, 'Total loss': 0.19304125491085897}
2022-12-31 09:14:59,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:14:59,140 INFO:     Epoch: 23
2022-12-31 09:15:00,766 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41228394508361815, 'Total loss': 0.41228394508361815} | train loss {'Reaction outcome loss': 0.1893631961156315, 'Total loss': 0.1893631961156315}
2022-12-31 09:15:00,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:00,766 INFO:     Epoch: 24
2022-12-31 09:15:02,432 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4233485778172811, 'Total loss': 0.4233485778172811} | train loss {'Reaction outcome loss': 0.1831440004765557, 'Total loss': 0.1831440004765557}
2022-12-31 09:15:02,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:02,432 INFO:     Epoch: 25
2022-12-31 09:15:04,098 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.394179567694664, 'Total loss': 0.394179567694664} | train loss {'Reaction outcome loss': 0.18526449840892414, 'Total loss': 0.18526449840892414}
2022-12-31 09:15:04,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:04,098 INFO:     Epoch: 26
2022-12-31 09:15:05,765 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41299592355887094, 'Total loss': 0.41299592355887094} | train loss {'Reaction outcome loss': 0.17959974743156873, 'Total loss': 0.17959974743156873}
2022-12-31 09:15:05,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:05,765 INFO:     Epoch: 27
2022-12-31 09:15:07,431 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3859352747599284, 'Total loss': 0.3859352747599284} | train loss {'Reaction outcome loss': 0.17729292534264846, 'Total loss': 0.17729292534264846}
2022-12-31 09:15:07,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:07,432 INFO:     Epoch: 28
2022-12-31 09:15:09,009 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4008048752943675, 'Total loss': 0.4008048752943675} | train loss {'Reaction outcome loss': 0.17631040476531543, 'Total loss': 0.17631040476531543}
2022-12-31 09:15:09,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:09,009 INFO:     Epoch: 29
2022-12-31 09:15:10,625 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41919348190228145, 'Total loss': 0.41919348190228145} | train loss {'Reaction outcome loss': 0.1690337801426111, 'Total loss': 0.1690337801426111}
2022-12-31 09:15:10,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:10,625 INFO:     Epoch: 30
2022-12-31 09:15:12,238 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39391557772954305, 'Total loss': 0.39391557772954305} | train loss {'Reaction outcome loss': 0.17120275099085988, 'Total loss': 0.17120275099085988}
2022-12-31 09:15:12,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:12,239 INFO:     Epoch: 31
2022-12-31 09:15:13,857 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4198798934618632, 'Total loss': 0.4198798934618632} | train loss {'Reaction outcome loss': 0.16714832849719893, 'Total loss': 0.16714832849719893}
2022-12-31 09:15:13,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:13,858 INFO:     Epoch: 32
2022-12-31 09:15:15,475 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4303309887647629, 'Total loss': 0.4303309887647629} | train loss {'Reaction outcome loss': 0.16422377104807093, 'Total loss': 0.16422377104807093}
2022-12-31 09:15:15,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:15,475 INFO:     Epoch: 33
2022-12-31 09:15:17,079 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40856638352076213, 'Total loss': 0.40856638352076213} | train loss {'Reaction outcome loss': 0.16178027509177098, 'Total loss': 0.16178027509177098}
2022-12-31 09:15:17,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:17,079 INFO:     Epoch: 34
2022-12-31 09:15:18,679 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41873922348022463, 'Total loss': 0.41873922348022463} | train loss {'Reaction outcome loss': 0.16173195059239756, 'Total loss': 0.16173195059239756}
2022-12-31 09:15:18,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:18,679 INFO:     Epoch: 35
2022-12-31 09:15:20,346 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42476844290892285, 'Total loss': 0.42476844290892285} | train loss {'Reaction outcome loss': 0.15680467747555313, 'Total loss': 0.15680467747555313}
2022-12-31 09:15:20,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:20,346 INFO:     Epoch: 36
2022-12-31 09:15:21,961 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4209913452466329, 'Total loss': 0.4209913452466329} | train loss {'Reaction outcome loss': 0.1570375739270653, 'Total loss': 0.1570375739270653}
2022-12-31 09:15:21,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:21,962 INFO:     Epoch: 37
2022-12-31 09:15:23,628 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40639792929093044, 'Total loss': 0.40639792929093044} | train loss {'Reaction outcome loss': 0.1521351101139177, 'Total loss': 0.1521351101139177}
2022-12-31 09:15:23,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:23,628 INFO:     Epoch: 38
2022-12-31 09:15:25,241 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40278072555859884, 'Total loss': 0.40278072555859884} | train loss {'Reaction outcome loss': 0.15222294853549678, 'Total loss': 0.15222294853549678}
2022-12-31 09:15:25,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:25,241 INFO:     Epoch: 39
2022-12-31 09:15:26,826 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4256891826788584, 'Total loss': 0.4256891826788584} | train loss {'Reaction outcome loss': 0.15156210809677087, 'Total loss': 0.15156210809677087}
2022-12-31 09:15:26,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:26,827 INFO:     Epoch: 40
2022-12-31 09:15:28,464 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4165155589580536, 'Total loss': 0.4165155589580536} | train loss {'Reaction outcome loss': 0.14961321626383045, 'Total loss': 0.14961321626383045}
2022-12-31 09:15:28,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:28,465 INFO:     Epoch: 41
2022-12-31 09:15:30,131 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41235365172227223, 'Total loss': 0.41235365172227223} | train loss {'Reaction outcome loss': 0.14895932107915033, 'Total loss': 0.14895932107915033}
2022-12-31 09:15:30,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:30,131 INFO:     Epoch: 42
2022-12-31 09:15:31,754 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4245364477237066, 'Total loss': 0.4245364477237066} | train loss {'Reaction outcome loss': 0.14633642788640214, 'Total loss': 0.14633642788640214}
2022-12-31 09:15:31,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:31,754 INFO:     Epoch: 43
2022-12-31 09:15:33,377 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3937155415614446, 'Total loss': 0.3937155415614446} | train loss {'Reaction outcome loss': 0.14546598660480567, 'Total loss': 0.14546598660480567}
2022-12-31 09:15:33,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:33,378 INFO:     Epoch: 44
2022-12-31 09:15:35,044 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4069591512282689, 'Total loss': 0.4069591512282689} | train loss {'Reaction outcome loss': 0.14511937080522738, 'Total loss': 0.14511937080522738}
2022-12-31 09:15:35,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:35,045 INFO:     Epoch: 45
2022-12-31 09:15:36,609 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4043362577756246, 'Total loss': 0.4043362577756246} | train loss {'Reaction outcome loss': 0.14187782807847224, 'Total loss': 0.14187782807847224}
2022-12-31 09:15:36,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:36,609 INFO:     Epoch: 46
2022-12-31 09:15:38,244 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40749712685743966, 'Total loss': 0.40749712685743966} | train loss {'Reaction outcome loss': 0.14080922882533245, 'Total loss': 0.14080922882533245}
2022-12-31 09:15:38,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:38,244 INFO:     Epoch: 47
2022-12-31 09:15:39,888 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41733968009551364, 'Total loss': 0.41733968009551364} | train loss {'Reaction outcome loss': 0.13833401404280848, 'Total loss': 0.13833401404280848}
2022-12-31 09:15:39,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:39,888 INFO:     Epoch: 48
2022-12-31 09:15:41,520 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4179490327835083, 'Total loss': 0.4179490327835083} | train loss {'Reaction outcome loss': 0.14099131082941102, 'Total loss': 0.14099131082941102}
2022-12-31 09:15:41,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:41,521 INFO:     Epoch: 49
2022-12-31 09:15:43,150 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40032525211572645, 'Total loss': 0.40032525211572645} | train loss {'Reaction outcome loss': 0.13661601168981044, 'Total loss': 0.13661601168981044}
2022-12-31 09:15:43,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:43,151 INFO:     Epoch: 50
2022-12-31 09:15:44,722 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4113950073719025, 'Total loss': 0.4113950073719025} | train loss {'Reaction outcome loss': 0.13570471011129098, 'Total loss': 0.13570471011129098}
2022-12-31 09:15:44,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:44,722 INFO:     Epoch: 51
2022-12-31 09:15:46,388 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.415471946199735, 'Total loss': 0.415471946199735} | train loss {'Reaction outcome loss': 0.13568066060038733, 'Total loss': 0.13568066060038733}
2022-12-31 09:15:46,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:46,388 INFO:     Epoch: 52
2022-12-31 09:15:48,055 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36421695674459137, 'Total loss': 0.36421695674459137} | train loss {'Reaction outcome loss': 0.13536524022206503, 'Total loss': 0.13536524022206503}
2022-12-31 09:15:48,055 INFO:     Found new best model at epoch 52
2022-12-31 09:15:48,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:48,056 INFO:     Epoch: 53
2022-12-31 09:15:49,723 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4282551015416781, 'Total loss': 0.4282551015416781} | train loss {'Reaction outcome loss': 0.13352874557349817, 'Total loss': 0.13352874557349817}
2022-12-31 09:15:49,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:49,723 INFO:     Epoch: 54
2022-12-31 09:15:51,338 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41368305683135986, 'Total loss': 0.41368305683135986} | train loss {'Reaction outcome loss': 0.135911203514018, 'Total loss': 0.135911203514018}
2022-12-31 09:15:51,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:51,338 INFO:     Epoch: 55
2022-12-31 09:15:52,951 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.377946878472964, 'Total loss': 0.377946878472964} | train loss {'Reaction outcome loss': 0.13310765562115057, 'Total loss': 0.13310765562115057}
2022-12-31 09:15:52,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:52,951 INFO:     Epoch: 56
2022-12-31 09:15:54,537 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.391164198021094, 'Total loss': 0.391164198021094} | train loss {'Reaction outcome loss': 0.13127821077347232, 'Total loss': 0.13127821077347232}
2022-12-31 09:15:54,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:54,538 INFO:     Epoch: 57
2022-12-31 09:15:56,180 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4021610081195831, 'Total loss': 0.4021610081195831} | train loss {'Reaction outcome loss': 0.12911263213657675, 'Total loss': 0.12911263213657675}
2022-12-31 09:15:56,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:56,180 INFO:     Epoch: 58
2022-12-31 09:15:57,822 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4142763150235017, 'Total loss': 0.4142763150235017} | train loss {'Reaction outcome loss': 0.1281112640464026, 'Total loss': 0.1281112640464026}
2022-12-31 09:15:57,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:57,822 INFO:     Epoch: 59
2022-12-31 09:15:59,462 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3959476624925931, 'Total loss': 0.3959476624925931} | train loss {'Reaction outcome loss': 0.12783932183038726, 'Total loss': 0.12783932183038726}
2022-12-31 09:15:59,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:15:59,463 INFO:     Epoch: 60
2022-12-31 09:16:01,102 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40758885939915973, 'Total loss': 0.40758885939915973} | train loss {'Reaction outcome loss': 0.12423052486798823, 'Total loss': 0.12423052486798823}
2022-12-31 09:16:01,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:01,102 INFO:     Epoch: 61
2022-12-31 09:16:02,717 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4139019081989924, 'Total loss': 0.4139019081989924} | train loss {'Reaction outcome loss': 0.12723922117828435, 'Total loss': 0.12723922117828435}
2022-12-31 09:16:02,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:02,718 INFO:     Epoch: 62
2022-12-31 09:16:04,357 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42052991191546124, 'Total loss': 0.42052991191546124} | train loss {'Reaction outcome loss': 0.1280387051433782, 'Total loss': 0.1280387051433782}
2022-12-31 09:16:04,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:04,358 INFO:     Epoch: 63
2022-12-31 09:16:05,969 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3905872941017151, 'Total loss': 0.3905872941017151} | train loss {'Reaction outcome loss': 0.1254723684421811, 'Total loss': 0.1254723684421811}
2022-12-31 09:16:05,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:05,969 INFO:     Epoch: 64
2022-12-31 09:16:07,589 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3957341820001602, 'Total loss': 0.3957341820001602} | train loss {'Reaction outcome loss': 0.1255924650215769, 'Total loss': 0.1255924650215769}
2022-12-31 09:16:07,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:07,589 INFO:     Epoch: 65
2022-12-31 09:16:09,255 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4458906501531601, 'Total loss': 0.4458906501531601} | train loss {'Reaction outcome loss': 0.12535980399126448, 'Total loss': 0.12535980399126448}
2022-12-31 09:16:09,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:09,256 INFO:     Epoch: 66
2022-12-31 09:16:10,876 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4030212094386419, 'Total loss': 0.4030212094386419} | train loss {'Reaction outcome loss': 0.12758754334237682, 'Total loss': 0.12758754334237682}
2022-12-31 09:16:10,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:10,877 INFO:     Epoch: 67
2022-12-31 09:16:12,456 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40990929702917733, 'Total loss': 0.40990929702917733} | train loss {'Reaction outcome loss': 0.12572592159225487, 'Total loss': 0.12572592159225487}
2022-12-31 09:16:12,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:12,456 INFO:     Epoch: 68
2022-12-31 09:16:14,090 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4335119207700094, 'Total loss': 0.4335119207700094} | train loss {'Reaction outcome loss': 0.12318954706807295, 'Total loss': 0.12318954706807295}
2022-12-31 09:16:14,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:14,090 INFO:     Epoch: 69
2022-12-31 09:16:15,724 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.407248322168986, 'Total loss': 0.407248322168986} | train loss {'Reaction outcome loss': 0.12274438263142368, 'Total loss': 0.12274438263142368}
2022-12-31 09:16:15,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:15,724 INFO:     Epoch: 70
2022-12-31 09:16:17,358 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42378512720266975, 'Total loss': 0.42378512720266975} | train loss {'Reaction outcome loss': 0.11723413026054468, 'Total loss': 0.11723413026054468}
2022-12-31 09:16:17,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:17,358 INFO:     Epoch: 71
2022-12-31 09:16:18,995 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38985815544923147, 'Total loss': 0.38985815544923147} | train loss {'Reaction outcome loss': 0.12355277495751231, 'Total loss': 0.12355277495751231}
2022-12-31 09:16:18,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:18,995 INFO:     Epoch: 72
2022-12-31 09:16:20,634 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41910922825336455, 'Total loss': 0.41910922825336455} | train loss {'Reaction outcome loss': 0.1217179672947214, 'Total loss': 0.1217179672947214}
2022-12-31 09:16:20,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:20,634 INFO:     Epoch: 73
2022-12-31 09:16:22,211 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3964308979610602, 'Total loss': 0.3964308979610602} | train loss {'Reaction outcome loss': 0.1232719445510327, 'Total loss': 0.1232719445510327}
2022-12-31 09:16:22,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:22,211 INFO:     Epoch: 74
2022-12-31 09:16:23,880 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4484491854906082, 'Total loss': 0.4484491854906082} | train loss {'Reaction outcome loss': 0.12550257904613088, 'Total loss': 0.12550257904613088}
2022-12-31 09:16:23,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:23,881 INFO:     Epoch: 75
2022-12-31 09:16:25,545 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3918079435825348, 'Total loss': 0.3918079435825348} | train loss {'Reaction outcome loss': 0.12190561314930447, 'Total loss': 0.12190561314930447}
2022-12-31 09:16:25,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:25,546 INFO:     Epoch: 76
2022-12-31 09:16:27,170 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39199694419900577, 'Total loss': 0.39199694419900577} | train loss {'Reaction outcome loss': 0.11459106256654117, 'Total loss': 0.11459106256654117}
2022-12-31 09:16:27,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:27,170 INFO:     Epoch: 77
2022-12-31 09:16:28,837 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4080789218346278, 'Total loss': 0.4080789218346278} | train loss {'Reaction outcome loss': 0.11541808125544474, 'Total loss': 0.11541808125544474}
2022-12-31 09:16:28,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:28,837 INFO:     Epoch: 78
2022-12-31 09:16:30,430 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.408736356596152, 'Total loss': 0.408736356596152} | train loss {'Reaction outcome loss': 0.11193909752098608, 'Total loss': 0.11193909752098608}
2022-12-31 09:16:30,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:30,430 INFO:     Epoch: 79
2022-12-31 09:16:32,065 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38010970850785575, 'Total loss': 0.38010970850785575} | train loss {'Reaction outcome loss': 0.11729364347936659, 'Total loss': 0.11729364347936659}
2022-12-31 09:16:32,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:32,066 INFO:     Epoch: 80
2022-12-31 09:16:33,695 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.403650796910127, 'Total loss': 0.403650796910127} | train loss {'Reaction outcome loss': 0.11380814915751561, 'Total loss': 0.11380814915751561}
2022-12-31 09:16:33,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:33,695 INFO:     Epoch: 81
2022-12-31 09:16:35,323 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4075892051060995, 'Total loss': 0.4075892051060995} | train loss {'Reaction outcome loss': 0.11638376975115994, 'Total loss': 0.11638376975115994}
2022-12-31 09:16:35,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:35,323 INFO:     Epoch: 82
2022-12-31 09:16:36,954 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4103974958260854, 'Total loss': 0.4103974958260854} | train loss {'Reaction outcome loss': 0.12133482112112162, 'Total loss': 0.12133482112112162}
2022-12-31 09:16:36,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:36,955 INFO:     Epoch: 83
2022-12-31 09:16:38,584 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.398315188785394, 'Total loss': 0.398315188785394} | train loss {'Reaction outcome loss': 0.12156400959165464, 'Total loss': 0.12156400959165464}
2022-12-31 09:16:38,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:38,584 INFO:     Epoch: 84
2022-12-31 09:16:40,179 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4008372674385707, 'Total loss': 0.4008372674385707} | train loss {'Reaction outcome loss': 0.11733786480935014, 'Total loss': 0.11733786480935014}
2022-12-31 09:16:40,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:40,180 INFO:     Epoch: 85
2022-12-31 09:16:41,820 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4452274958292643, 'Total loss': 0.4452274958292643} | train loss {'Reaction outcome loss': 0.11881778130159858, 'Total loss': 0.11881778130159858}
2022-12-31 09:16:41,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:41,820 INFO:     Epoch: 86
2022-12-31 09:16:43,454 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4158948838710785, 'Total loss': 0.4158948838710785} | train loss {'Reaction outcome loss': 0.11672892376430843, 'Total loss': 0.11672892376430843}
2022-12-31 09:16:43,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:43,454 INFO:     Epoch: 87
2022-12-31 09:16:45,085 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4266059791048368, 'Total loss': 0.4266059791048368} | train loss {'Reaction outcome loss': 0.1129254575933091, 'Total loss': 0.1129254575933091}
2022-12-31 09:16:45,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:45,086 INFO:     Epoch: 88
2022-12-31 09:16:46,733 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3805663168430328, 'Total loss': 0.3805663168430328} | train loss {'Reaction outcome loss': 0.11494036865528229, 'Total loss': 0.11494036865528229}
2022-12-31 09:16:46,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:46,734 INFO:     Epoch: 89
2022-12-31 09:16:48,339 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4185746649901072, 'Total loss': 0.4185746649901072} | train loss {'Reaction outcome loss': 0.11666346088956221, 'Total loss': 0.11666346088956221}
2022-12-31 09:16:48,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:48,339 INFO:     Epoch: 90
2022-12-31 09:16:49,960 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4058144330978394, 'Total loss': 0.4058144330978394} | train loss {'Reaction outcome loss': 0.11605155878340563, 'Total loss': 0.11605155878340563}
2022-12-31 09:16:49,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:49,960 INFO:     Epoch: 91
2022-12-31 09:16:51,626 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4242662688096364, 'Total loss': 0.4242662688096364} | train loss {'Reaction outcome loss': 0.11391501034532643, 'Total loss': 0.11391501034532643}
2022-12-31 09:16:51,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:51,627 INFO:     Epoch: 92
2022-12-31 09:16:53,252 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42418196698029836, 'Total loss': 0.42418196698029836} | train loss {'Reaction outcome loss': 0.11584258854510229, 'Total loss': 0.11584258854510229}
2022-12-31 09:16:53,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:53,252 INFO:     Epoch: 93
2022-12-31 09:16:54,920 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41469253500302633, 'Total loss': 0.41469253500302633} | train loss {'Reaction outcome loss': 0.11382058184738489, 'Total loss': 0.11382058184738489}
2022-12-31 09:16:54,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:54,920 INFO:     Epoch: 94
2022-12-31 09:16:56,548 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3941731795668602, 'Total loss': 0.3941731795668602} | train loss {'Reaction outcome loss': 0.1097788875065206, 'Total loss': 0.1097788875065206}
2022-12-31 09:16:56,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:56,548 INFO:     Epoch: 95
2022-12-31 09:16:58,164 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4268629918495814, 'Total loss': 0.4268629918495814} | train loss {'Reaction outcome loss': 0.1125162293586463, 'Total loss': 0.1125162293586463}
2022-12-31 09:16:58,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:58,164 INFO:     Epoch: 96
2022-12-31 09:16:59,790 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4036278280119101, 'Total loss': 0.4036278280119101} | train loss {'Reaction outcome loss': 0.11811180175315683, 'Total loss': 0.11811180175315683}
2022-12-31 09:16:59,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:16:59,791 INFO:     Epoch: 97
2022-12-31 09:17:01,416 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38110085427761076, 'Total loss': 0.38110085427761076} | train loss {'Reaction outcome loss': 0.11578733995825806, 'Total loss': 0.11578733995825806}
2022-12-31 09:17:01,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:01,416 INFO:     Epoch: 98
2022-12-31 09:17:03,084 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39088059067726133, 'Total loss': 0.39088059067726133} | train loss {'Reaction outcome loss': 0.11705616959925431, 'Total loss': 0.11705616959925431}
2022-12-31 09:17:03,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:03,084 INFO:     Epoch: 99
2022-12-31 09:17:04,751 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41092844009399415, 'Total loss': 0.41092844009399415} | train loss {'Reaction outcome loss': 0.1127323231303439, 'Total loss': 0.1127323231303439}
2022-12-31 09:17:04,752 INFO:     Best model found after epoch 53 of 100.
2022-12-31 09:17:04,752 INFO:   Done with stage: TRAINING
2022-12-31 09:17:04,752 INFO:   Starting stage: EVALUATION
2022-12-31 09:17:04,877 INFO:   Done with stage: EVALUATION
2022-12-31 09:17:04,877 INFO:   Leaving out SEQ value Fold_5
2022-12-31 09:17:04,889 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 09:17:04,890 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:17:05,537 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:17:05,537 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:17:05,604 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:17:05,605 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:17:05,605 INFO:     No hyperparam tuning for this model
2022-12-31 09:17:05,605 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:17:05,605 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:17:05,605 INFO:     None feature selector for col prot
2022-12-31 09:17:05,606 INFO:     None feature selector for col prot
2022-12-31 09:17:05,606 INFO:     None feature selector for col prot
2022-12-31 09:17:05,606 INFO:     None feature selector for col chem
2022-12-31 09:17:05,606 INFO:     None feature selector for col chem
2022-12-31 09:17:05,606 INFO:     None feature selector for col chem
2022-12-31 09:17:05,606 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:17:05,606 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:17:05,608 INFO:     Number of params in model 224011
2022-12-31 09:17:05,612 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:17:05,612 INFO:   Starting stage: TRAINING
2022-12-31 09:17:05,656 INFO:     Val loss before train {'Reaction outcome loss': 1.038627771536509, 'Total loss': 1.038627771536509}
2022-12-31 09:17:05,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:05,656 INFO:     Epoch: 0
2022-12-31 09:17:07,241 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5737714558839798, 'Total loss': 0.5737714558839798} | train loss {'Reaction outcome loss': 0.7842505343639068, 'Total loss': 0.7842505343639068}
2022-12-31 09:17:07,241 INFO:     Found new best model at epoch 0
2022-12-31 09:17:07,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:07,242 INFO:     Epoch: 1
2022-12-31 09:17:08,853 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49087800780932106, 'Total loss': 0.49087800780932106} | train loss {'Reaction outcome loss': 0.5086208933787625, 'Total loss': 0.5086208933787625}
2022-12-31 09:17:08,853 INFO:     Found new best model at epoch 1
2022-12-31 09:17:08,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:08,854 INFO:     Epoch: 2
2022-12-31 09:17:10,466 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4712308019399643, 'Total loss': 0.4712308019399643} | train loss {'Reaction outcome loss': 0.4414631125048129, 'Total loss': 0.4414631125048129}
2022-12-31 09:17:10,466 INFO:     Found new best model at epoch 2
2022-12-31 09:17:10,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:10,467 INFO:     Epoch: 3
2022-12-31 09:17:12,078 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.430126953125, 'Total loss': 0.430126953125} | train loss {'Reaction outcome loss': 0.40246405854929973, 'Total loss': 0.40246405854929973}
2022-12-31 09:17:12,078 INFO:     Found new best model at epoch 3
2022-12-31 09:17:12,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:12,080 INFO:     Epoch: 4
2022-12-31 09:17:13,690 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40061597724755604, 'Total loss': 0.40061597724755604} | train loss {'Reaction outcome loss': 0.37266955383285116, 'Total loss': 0.37266955383285116}
2022-12-31 09:17:13,690 INFO:     Found new best model at epoch 4
2022-12-31 09:17:13,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:13,691 INFO:     Epoch: 5
2022-12-31 09:17:15,291 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.423406974474589, 'Total loss': 0.423406974474589} | train loss {'Reaction outcome loss': 0.34841423688361245, 'Total loss': 0.34841423688361245}
2022-12-31 09:17:15,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:15,292 INFO:     Epoch: 6
2022-12-31 09:17:16,903 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43463361263275146, 'Total loss': 0.43463361263275146} | train loss {'Reaction outcome loss': 0.32508212068274506, 'Total loss': 0.32508212068274506}
2022-12-31 09:17:16,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:16,903 INFO:     Epoch: 7
2022-12-31 09:17:18,512 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40456508497397103, 'Total loss': 0.40456508497397103} | train loss {'Reaction outcome loss': 0.3077416415904125, 'Total loss': 0.3077416415904125}
2022-12-31 09:17:18,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:18,512 INFO:     Epoch: 8
2022-12-31 09:17:20,123 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43626704017321266, 'Total loss': 0.43626704017321266} | train loss {'Reaction outcome loss': 0.2938893704545976, 'Total loss': 0.2938893704545976}
2022-12-31 09:17:20,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:20,123 INFO:     Epoch: 9
2022-12-31 09:17:21,732 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38680648704369863, 'Total loss': 0.38680648704369863} | train loss {'Reaction outcome loss': 0.27566705551678244, 'Total loss': 0.27566705551678244}
2022-12-31 09:17:21,733 INFO:     Found new best model at epoch 9
2022-12-31 09:17:21,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:21,734 INFO:     Epoch: 10
2022-12-31 09:17:23,342 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4317876199881236, 'Total loss': 0.4317876199881236} | train loss {'Reaction outcome loss': 0.26474149075139614, 'Total loss': 0.26474149075139614}
2022-12-31 09:17:23,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:23,342 INFO:     Epoch: 11
2022-12-31 09:17:24,945 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4558772703011831, 'Total loss': 0.4558772703011831} | train loss {'Reaction outcome loss': 0.2580217085506794, 'Total loss': 0.2580217085506794}
2022-12-31 09:17:24,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:24,945 INFO:     Epoch: 12
2022-12-31 09:17:26,565 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3944098075230916, 'Total loss': 0.3944098075230916} | train loss {'Reaction outcome loss': 0.24609284778635432, 'Total loss': 0.24609284778635432}
2022-12-31 09:17:26,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:26,565 INFO:     Epoch: 13
2022-12-31 09:17:28,213 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4076305111249288, 'Total loss': 0.4076305111249288} | train loss {'Reaction outcome loss': 0.2356438973687426, 'Total loss': 0.2356438973687426}
2022-12-31 09:17:28,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:28,214 INFO:     Epoch: 14
2022-12-31 09:17:29,863 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41200969119866687, 'Total loss': 0.41200969119866687} | train loss {'Reaction outcome loss': 0.22625243355159777, 'Total loss': 0.22625243355159777}
2022-12-31 09:17:29,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:29,863 INFO:     Epoch: 15
2022-12-31 09:17:31,470 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4187605212132136, 'Total loss': 0.4187605212132136} | train loss {'Reaction outcome loss': 0.21847898565423096, 'Total loss': 0.21847898565423096}
2022-12-31 09:17:31,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:31,470 INFO:     Epoch: 16
2022-12-31 09:17:33,123 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42595506409804024, 'Total loss': 0.42595506409804024} | train loss {'Reaction outcome loss': 0.21481296653267892, 'Total loss': 0.21481296653267892}
2022-12-31 09:17:33,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:33,123 INFO:     Epoch: 17
2022-12-31 09:17:34,725 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43854472438494363, 'Total loss': 0.43854472438494363} | train loss {'Reaction outcome loss': 0.20706107845720256, 'Total loss': 0.20706107845720256}
2022-12-31 09:17:34,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:34,726 INFO:     Epoch: 18
2022-12-31 09:17:36,356 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40387193659941356, 'Total loss': 0.40387193659941356} | train loss {'Reaction outcome loss': 0.2028062874111381, 'Total loss': 0.2028062874111381}
2022-12-31 09:17:36,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:36,356 INFO:     Epoch: 19
2022-12-31 09:17:37,963 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4256792962551117, 'Total loss': 0.4256792962551117} | train loss {'Reaction outcome loss': 0.1941892134848248, 'Total loss': 0.1941892134848248}
2022-12-31 09:17:37,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:37,963 INFO:     Epoch: 20
2022-12-31 09:17:39,570 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42617040673891704, 'Total loss': 0.42617040673891704} | train loss {'Reaction outcome loss': 0.18661382366107762, 'Total loss': 0.18661382366107762}
2022-12-31 09:17:39,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:39,570 INFO:     Epoch: 21
2022-12-31 09:17:41,219 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4398981809616089, 'Total loss': 0.4398981809616089} | train loss {'Reaction outcome loss': 0.18209018172818597, 'Total loss': 0.18209018172818597}
2022-12-31 09:17:41,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:41,220 INFO:     Epoch: 22
2022-12-31 09:17:42,843 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4155898446838061, 'Total loss': 0.4155898446838061} | train loss {'Reaction outcome loss': 0.17737738083177892, 'Total loss': 0.17737738083177892}
2022-12-31 09:17:42,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:42,844 INFO:     Epoch: 23
2022-12-31 09:17:44,446 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4202133297920227, 'Total loss': 0.4202133297920227} | train loss {'Reaction outcome loss': 0.17574768128335802, 'Total loss': 0.17574768128335802}
2022-12-31 09:17:44,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:44,446 INFO:     Epoch: 24
2022-12-31 09:17:46,097 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47908916473388674, 'Total loss': 0.47908916473388674} | train loss {'Reaction outcome loss': 0.17353996323136084, 'Total loss': 0.17353996323136084}
2022-12-31 09:17:46,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:46,099 INFO:     Epoch: 25
2022-12-31 09:17:47,706 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47058405975500744, 'Total loss': 0.47058405975500744} | train loss {'Reaction outcome loss': 0.1678085816364708, 'Total loss': 0.1678085816364708}
2022-12-31 09:17:47,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:47,706 INFO:     Epoch: 26
2022-12-31 09:17:49,356 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41858765482902527, 'Total loss': 0.41858765482902527} | train loss {'Reaction outcome loss': 0.16494044617335074, 'Total loss': 0.16494044617335074}
2022-12-31 09:17:49,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:49,356 INFO:     Epoch: 27
2022-12-31 09:17:50,962 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4448222448428472, 'Total loss': 0.4448222448428472} | train loss {'Reaction outcome loss': 0.15895867906170932, 'Total loss': 0.15895867906170932}
2022-12-31 09:17:50,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:50,962 INFO:     Epoch: 28
2022-12-31 09:17:52,574 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4377392550309499, 'Total loss': 0.4377392550309499} | train loss {'Reaction outcome loss': 0.15984356563443142, 'Total loss': 0.15984356563443142}
2022-12-31 09:17:52,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:52,575 INFO:     Epoch: 29
2022-12-31 09:17:54,178 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44048207501570386, 'Total loss': 0.44048207501570386} | train loss {'Reaction outcome loss': 0.1526160719430577, 'Total loss': 0.1526160719430577}
2022-12-31 09:17:54,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:54,178 INFO:     Epoch: 30
2022-12-31 09:17:55,780 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4376581713557243, 'Total loss': 0.4376581713557243} | train loss {'Reaction outcome loss': 0.15551927322045947, 'Total loss': 0.15551927322045947}
2022-12-31 09:17:55,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:55,781 INFO:     Epoch: 31
2022-12-31 09:17:57,381 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4213663180669149, 'Total loss': 0.4213663180669149} | train loss {'Reaction outcome loss': 0.1465559608955616, 'Total loss': 0.1465559608955616}
2022-12-31 09:17:57,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:57,381 INFO:     Epoch: 32
2022-12-31 09:17:59,030 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4602987209955851, 'Total loss': 0.4602987209955851} | train loss {'Reaction outcome loss': 0.1470498547134717, 'Total loss': 0.1470498547134717}
2022-12-31 09:17:59,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:17:59,030 INFO:     Epoch: 33
2022-12-31 09:18:00,631 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4381254216035207, 'Total loss': 0.4381254216035207} | train loss {'Reaction outcome loss': 0.14757601185497848, 'Total loss': 0.14757601185497848}
2022-12-31 09:18:00,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:00,631 INFO:     Epoch: 34
2022-12-31 09:18:02,228 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4309134281473234, 'Total loss': 0.4309134281473234} | train loss {'Reaction outcome loss': 0.14491630814983136, 'Total loss': 0.14491630814983136}
2022-12-31 09:18:02,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:02,228 INFO:     Epoch: 35
2022-12-31 09:18:03,829 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40937450975179673, 'Total loss': 0.40937450975179673} | train loss {'Reaction outcome loss': 0.1463553363246585, 'Total loss': 0.1463553363246585}
2022-12-31 09:18:03,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:03,829 INFO:     Epoch: 36
2022-12-31 09:18:05,433 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43831293483575184, 'Total loss': 0.43831293483575184} | train loss {'Reaction outcome loss': 0.1405564366880614, 'Total loss': 0.1405564366880614}
2022-12-31 09:18:05,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:05,434 INFO:     Epoch: 37
2022-12-31 09:18:07,037 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4374213233590126, 'Total loss': 0.4374213233590126} | train loss {'Reaction outcome loss': 0.13984484548755263, 'Total loss': 0.13984484548755263}
2022-12-31 09:18:07,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:07,037 INFO:     Epoch: 38
2022-12-31 09:18:08,640 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46161170390745004, 'Total loss': 0.46161170390745004} | train loss {'Reaction outcome loss': 0.1356899253140292, 'Total loss': 0.1356899253140292}
2022-12-31 09:18:08,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:08,641 INFO:     Epoch: 39
2022-12-31 09:18:10,262 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41287814180056254, 'Total loss': 0.41287814180056254} | train loss {'Reaction outcome loss': 0.13804337511138215, 'Total loss': 0.13804337511138215}
2022-12-31 09:18:10,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:10,262 INFO:     Epoch: 40
2022-12-31 09:18:11,874 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4334709276755651, 'Total loss': 0.4334709276755651} | train loss {'Reaction outcome loss': 0.13381900230803304, 'Total loss': 0.13381900230803304}
2022-12-31 09:18:11,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:11,874 INFO:     Epoch: 41
2022-12-31 09:18:13,490 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4204267144203186, 'Total loss': 0.4204267144203186} | train loss {'Reaction outcome loss': 0.1362933762113217, 'Total loss': 0.1362933762113217}
2022-12-31 09:18:13,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:13,491 INFO:     Epoch: 42
2022-12-31 09:18:15,105 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4537550151348114, 'Total loss': 0.4537550151348114} | train loss {'Reaction outcome loss': 0.1319965945240654, 'Total loss': 0.1319965945240654}
2022-12-31 09:18:15,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:15,106 INFO:     Epoch: 43
2022-12-31 09:18:16,721 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4264420340458552, 'Total loss': 0.4264420340458552} | train loss {'Reaction outcome loss': 0.13175355411223033, 'Total loss': 0.13175355411223033}
2022-12-31 09:18:16,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:16,722 INFO:     Epoch: 44
2022-12-31 09:18:18,330 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4162865236479168, 'Total loss': 0.4162865236479168} | train loss {'Reaction outcome loss': 0.12919300787633517, 'Total loss': 0.12919300787633517}
2022-12-31 09:18:18,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:18,330 INFO:     Epoch: 45
2022-12-31 09:18:19,923 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4266742753485839, 'Total loss': 0.4266742753485839} | train loss {'Reaction outcome loss': 0.13078177162364507, 'Total loss': 0.13078177162364507}
2022-12-31 09:18:19,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:19,924 INFO:     Epoch: 46
2022-12-31 09:18:21,533 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42352757751941683, 'Total loss': 0.42352757751941683} | train loss {'Reaction outcome loss': 0.12536644469606725, 'Total loss': 0.12536644469606725}
2022-12-31 09:18:21,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:21,533 INFO:     Epoch: 47
2022-12-31 09:18:23,143 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4549195478359858, 'Total loss': 0.4549195478359858} | train loss {'Reaction outcome loss': 0.12915843911468983, 'Total loss': 0.12915843911468983}
2022-12-31 09:18:23,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:23,144 INFO:     Epoch: 48
2022-12-31 09:18:24,757 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4006369640429815, 'Total loss': 0.4006369640429815} | train loss {'Reaction outcome loss': 0.13193271163235806, 'Total loss': 0.13193271163235806}
2022-12-31 09:18:24,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:24,757 INFO:     Epoch: 49
2022-12-31 09:18:26,372 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47829617460568746, 'Total loss': 0.47829617460568746} | train loss {'Reaction outcome loss': 0.1274659482203084, 'Total loss': 0.1274659482203084}
2022-12-31 09:18:26,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:26,372 INFO:     Epoch: 50
2022-12-31 09:18:27,980 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4335291137297948, 'Total loss': 0.4335291137297948} | train loss {'Reaction outcome loss': 0.12291597521245262, 'Total loss': 0.12291597521245262}
2022-12-31 09:18:27,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:27,981 INFO:     Epoch: 51
2022-12-31 09:18:29,577 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42337493151426314, 'Total loss': 0.42337493151426314} | train loss {'Reaction outcome loss': 0.12530669985155501, 'Total loss': 0.12530669985155501}
2022-12-31 09:18:29,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:29,578 INFO:     Epoch: 52
2022-12-31 09:18:31,227 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4281466603279114, 'Total loss': 0.4281466603279114} | train loss {'Reaction outcome loss': 0.1215930558098684, 'Total loss': 0.1215930558098684}
2022-12-31 09:18:31,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:31,228 INFO:     Epoch: 53
2022-12-31 09:18:32,830 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5021583035588264, 'Total loss': 0.5021583035588264} | train loss {'Reaction outcome loss': 0.12153261224059456, 'Total loss': 0.12153261224059456}
2022-12-31 09:18:32,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:32,830 INFO:     Epoch: 54
2022-12-31 09:18:34,479 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43810971776644386, 'Total loss': 0.43810971776644386} | train loss {'Reaction outcome loss': 0.12449197894995556, 'Total loss': 0.12449197894995556}
2022-12-31 09:18:34,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:34,479 INFO:     Epoch: 55
2022-12-31 09:18:36,129 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4454963202277819, 'Total loss': 0.4454963202277819} | train loss {'Reaction outcome loss': 0.12253023737728813, 'Total loss': 0.12253023737728813}
2022-12-31 09:18:36,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:36,130 INFO:     Epoch: 56
2022-12-31 09:18:37,728 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4427268366018931, 'Total loss': 0.4427268366018931} | train loss {'Reaction outcome loss': 0.12068236015234006, 'Total loss': 0.12068236015234006}
2022-12-31 09:18:37,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:37,728 INFO:     Epoch: 57
2022-12-31 09:18:39,378 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42802816927433013, 'Total loss': 0.42802816927433013} | train loss {'Reaction outcome loss': 0.12129949618056145, 'Total loss': 0.12129949618056145}
2022-12-31 09:18:39,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:39,378 INFO:     Epoch: 58
2022-12-31 09:18:41,027 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4295944412549337, 'Total loss': 0.4295944412549337} | train loss {'Reaction outcome loss': 0.11686854474127538, 'Total loss': 0.11686854474127538}
2022-12-31 09:18:41,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:41,028 INFO:     Epoch: 59
2022-12-31 09:18:42,679 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4370688691735268, 'Total loss': 0.4370688691735268} | train loss {'Reaction outcome loss': 0.12018563635698282, 'Total loss': 0.12018563635698282}
2022-12-31 09:18:42,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:42,679 INFO:     Epoch: 60
2022-12-31 09:18:44,274 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.421442570288976, 'Total loss': 0.421442570288976} | train loss {'Reaction outcome loss': 0.11403235982437313, 'Total loss': 0.11403235982437313}
2022-12-31 09:18:44,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:44,274 INFO:     Epoch: 61
2022-12-31 09:18:45,924 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43194498121738434, 'Total loss': 0.43194498121738434} | train loss {'Reaction outcome loss': 0.11694724725246647, 'Total loss': 0.11694724725246647}
2022-12-31 09:18:45,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:45,924 INFO:     Epoch: 62
2022-12-31 09:18:47,556 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4639139433701833, 'Total loss': 0.4639139433701833} | train loss {'Reaction outcome loss': 0.11712302487805812, 'Total loss': 0.11712302487805812}
2022-12-31 09:18:47,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:47,557 INFO:     Epoch: 63
2022-12-31 09:18:49,160 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4560266504685084, 'Total loss': 0.4560266504685084} | train loss {'Reaction outcome loss': 0.1174966467401679, 'Total loss': 0.1174966467401679}
2022-12-31 09:18:49,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:49,161 INFO:     Epoch: 64
2022-12-31 09:18:50,810 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4185413802663485, 'Total loss': 0.4185413802663485} | train loss {'Reaction outcome loss': 0.1145667858017323, 'Total loss': 0.1145667858017323}
2022-12-31 09:18:50,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:50,811 INFO:     Epoch: 65
2022-12-31 09:18:52,412 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41639375388622285, 'Total loss': 0.41639375388622285} | train loss {'Reaction outcome loss': 0.11444891111782488, 'Total loss': 0.11444891111782488}
2022-12-31 09:18:52,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:52,413 INFO:     Epoch: 66
2022-12-31 09:18:54,062 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4372638496415069, 'Total loss': 0.4372638496415069} | train loss {'Reaction outcome loss': 0.11642753461589969, 'Total loss': 0.11642753461589969}
2022-12-31 09:18:54,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:54,063 INFO:     Epoch: 67
2022-12-31 09:18:55,669 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4340703586737315, 'Total loss': 0.4340703586737315} | train loss {'Reaction outcome loss': 0.11741003581071205, 'Total loss': 0.11741003581071205}
2022-12-31 09:18:55,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:55,670 INFO:     Epoch: 68
2022-12-31 09:18:57,271 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44865713914235433, 'Total loss': 0.44865713914235433} | train loss {'Reaction outcome loss': 0.11186252719719289, 'Total loss': 0.11186252719719289}
2022-12-31 09:18:57,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:57,271 INFO:     Epoch: 69
2022-12-31 09:18:58,883 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4723102211952209, 'Total loss': 0.4723102211952209} | train loss {'Reaction outcome loss': 0.1159176995287765, 'Total loss': 0.1159176995287765}
2022-12-31 09:18:58,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:18:58,883 INFO:     Epoch: 70
2022-12-31 09:19:00,493 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4301951597134272, 'Total loss': 0.4301951597134272} | train loss {'Reaction outcome loss': 0.10850049255425995, 'Total loss': 0.10850049255425995}
2022-12-31 09:19:00,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:00,493 INFO:     Epoch: 71
2022-12-31 09:19:02,105 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4305947333574295, 'Total loss': 0.4305947333574295} | train loss {'Reaction outcome loss': 0.11090496441869432, 'Total loss': 0.11090496441869432}
2022-12-31 09:19:02,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:02,105 INFO:     Epoch: 72
2022-12-31 09:19:03,717 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4097029000520706, 'Total loss': 0.4097029000520706} | train loss {'Reaction outcome loss': 0.11540609548534572, 'Total loss': 0.11540609548534572}
2022-12-31 09:19:03,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:03,717 INFO:     Epoch: 73
2022-12-31 09:19:05,327 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4298064609368642, 'Total loss': 0.4298064609368642} | train loss {'Reaction outcome loss': 0.11262745764038533, 'Total loss': 0.11262745764038533}
2022-12-31 09:19:05,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:05,327 INFO:     Epoch: 74
2022-12-31 09:19:06,943 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4324296752611796, 'Total loss': 0.4324296752611796} | train loss {'Reaction outcome loss': 0.11098752356130956, 'Total loss': 0.11098752356130956}
2022-12-31 09:19:06,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:06,943 INFO:     Epoch: 75
2022-12-31 09:19:08,554 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43196358780066174, 'Total loss': 0.43196358780066174} | train loss {'Reaction outcome loss': 0.10903000794597527, 'Total loss': 0.10903000794597527}
2022-12-31 09:19:08,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:08,555 INFO:     Epoch: 76
2022-12-31 09:19:10,164 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4320388515790304, 'Total loss': 0.4320388515790304} | train loss {'Reaction outcome loss': 0.11004121314961952, 'Total loss': 0.11004121314961952}
2022-12-31 09:19:10,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:10,165 INFO:     Epoch: 77
2022-12-31 09:19:11,779 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45520127564668655, 'Total loss': 0.45520127564668655} | train loss {'Reaction outcome loss': 0.11203157736573123, 'Total loss': 0.11203157736573123}
2022-12-31 09:19:11,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:11,779 INFO:     Epoch: 78
2022-12-31 09:19:13,386 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42080190777778625, 'Total loss': 0.42080190777778625} | train loss {'Reaction outcome loss': 0.11128379366306221, 'Total loss': 0.11128379366306221}
2022-12-31 09:19:13,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:13,387 INFO:     Epoch: 79
2022-12-31 09:19:15,003 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45928778648376467, 'Total loss': 0.45928778648376467} | train loss {'Reaction outcome loss': 0.10870149285688888, 'Total loss': 0.10870149285688888}
2022-12-31 09:19:15,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:15,003 INFO:     Epoch: 80
2022-12-31 09:19:16,653 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42483485241731006, 'Total loss': 0.42483485241731006} | train loss {'Reaction outcome loss': 0.1057745719364212, 'Total loss': 0.1057745719364212}
2022-12-31 09:19:16,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:16,653 INFO:     Epoch: 81
2022-12-31 09:19:18,257 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4191239724556605, 'Total loss': 0.4191239724556605} | train loss {'Reaction outcome loss': 0.10413673180019496, 'Total loss': 0.10413673180019496}
2022-12-31 09:19:18,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:18,259 INFO:     Epoch: 82
2022-12-31 09:19:19,863 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41541883250077566, 'Total loss': 0.41541883250077566} | train loss {'Reaction outcome loss': 0.11083260365340342, 'Total loss': 0.11083260365340342}
2022-12-31 09:19:19,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:19,864 INFO:     Epoch: 83
2022-12-31 09:19:21,513 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4349275569121043, 'Total loss': 0.4349275569121043} | train loss {'Reaction outcome loss': 0.11323550239079598, 'Total loss': 0.11323550239079598}
2022-12-31 09:19:21,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:21,513 INFO:     Epoch: 84
2022-12-31 09:19:23,105 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45342704753081003, 'Total loss': 0.45342704753081003} | train loss {'Reaction outcome loss': 0.1110409557408089, 'Total loss': 0.1110409557408089}
2022-12-31 09:19:23,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:23,106 INFO:     Epoch: 85
2022-12-31 09:19:24,716 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40710022250811256, 'Total loss': 0.40710022250811256} | train loss {'Reaction outcome loss': 0.10786145457056398, 'Total loss': 0.10786145457056398}
2022-12-31 09:19:24,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:24,717 INFO:     Epoch: 86
2022-12-31 09:19:26,327 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42409489552179974, 'Total loss': 0.42409489552179974} | train loss {'Reaction outcome loss': 0.1093019397213824, 'Total loss': 0.1093019397213824}
2022-12-31 09:19:26,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:26,328 INFO:     Epoch: 87
2022-12-31 09:19:27,949 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4282784362634023, 'Total loss': 0.4282784362634023} | train loss {'Reaction outcome loss': 0.10433810167558437, 'Total loss': 0.10433810167558437}
2022-12-31 09:19:27,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:27,949 INFO:     Epoch: 88
2022-12-31 09:19:29,567 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44265719105799994, 'Total loss': 0.44265719105799994} | train loss {'Reaction outcome loss': 0.10596520817468119, 'Total loss': 0.10596520817468119}
2022-12-31 09:19:29,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:29,567 INFO:     Epoch: 89
2022-12-31 09:19:31,186 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4320392390092214, 'Total loss': 0.4320392390092214} | train loss {'Reaction outcome loss': 0.11069702137309215, 'Total loss': 0.11069702137309215}
2022-12-31 09:19:31,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:31,186 INFO:     Epoch: 90
2022-12-31 09:19:32,795 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43438073992729187, 'Total loss': 0.43438073992729187} | train loss {'Reaction outcome loss': 0.10696523043456195, 'Total loss': 0.10696523043456195}
2022-12-31 09:19:32,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:32,795 INFO:     Epoch: 91
2022-12-31 09:19:34,445 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41288458506266273, 'Total loss': 0.41288458506266273} | train loss {'Reaction outcome loss': 0.10227242497689885, 'Total loss': 0.10227242497689885}
2022-12-31 09:19:34,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:34,445 INFO:     Epoch: 92
2022-12-31 09:19:36,094 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4255064969261487, 'Total loss': 0.4255064969261487} | train loss {'Reaction outcome loss': 0.10495388052973516, 'Total loss': 0.10495388052973516}
2022-12-31 09:19:36,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:36,094 INFO:     Epoch: 93
2022-12-31 09:19:37,696 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4176672637462616, 'Total loss': 0.4176672637462616} | train loss {'Reaction outcome loss': 0.10592569952259642, 'Total loss': 0.10592569952259642}
2022-12-31 09:19:37,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:37,696 INFO:     Epoch: 94
2022-12-31 09:19:39,301 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48615970214207965, 'Total loss': 0.48615970214207965} | train loss {'Reaction outcome loss': 0.11195335315921119, 'Total loss': 0.11195335315921119}
2022-12-31 09:19:39,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:39,301 INFO:     Epoch: 95
2022-12-31 09:19:40,944 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4255676011244456, 'Total loss': 0.4255676011244456} | train loss {'Reaction outcome loss': 0.10301769208536912, 'Total loss': 0.10301769208536912}
2022-12-31 09:19:40,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:40,944 INFO:     Epoch: 96
2022-12-31 09:19:42,186 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45296356280644734, 'Total loss': 0.45296356280644734} | train loss {'Reaction outcome loss': 0.1026045280911477, 'Total loss': 0.1026045280911477}
2022-12-31 09:19:42,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:42,186 INFO:     Epoch: 97
2022-12-31 09:19:43,298 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4373978813489278, 'Total loss': 0.4373978813489278} | train loss {'Reaction outcome loss': 0.10635195103988908, 'Total loss': 0.10635195103988908}
2022-12-31 09:19:43,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:43,298 INFO:     Epoch: 98
2022-12-31 09:19:44,406 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4530757009983063, 'Total loss': 0.4530757009983063} | train loss {'Reaction outcome loss': 0.10413680194085125, 'Total loss': 0.10413680194085125}
2022-12-31 09:19:44,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:44,406 INFO:     Epoch: 99
2022-12-31 09:19:45,515 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44836386311799287, 'Total loss': 0.44836386311799287} | train loss {'Reaction outcome loss': 0.09967649054380447, 'Total loss': 0.09967649054380447}
2022-12-31 09:19:45,515 INFO:     Best model found after epoch 10 of 100.
2022-12-31 09:19:45,515 INFO:   Done with stage: TRAINING
2022-12-31 09:19:45,515 INFO:   Starting stage: EVALUATION
2022-12-31 09:19:45,651 INFO:   Done with stage: EVALUATION
2022-12-31 09:19:45,651 INFO:   Leaving out SEQ value Fold_6
2022-12-31 09:19:45,664 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 09:19:45,664 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:19:46,312 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:19:46,312 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:19:46,380 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:19:46,380 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:19:46,380 INFO:     No hyperparam tuning for this model
2022-12-31 09:19:46,380 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:19:46,380 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:19:46,381 INFO:     None feature selector for col prot
2022-12-31 09:19:46,381 INFO:     None feature selector for col prot
2022-12-31 09:19:46,381 INFO:     None feature selector for col prot
2022-12-31 09:19:46,382 INFO:     None feature selector for col chem
2022-12-31 09:19:46,382 INFO:     None feature selector for col chem
2022-12-31 09:19:46,382 INFO:     None feature selector for col chem
2022-12-31 09:19:46,382 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:19:46,382 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:19:46,384 INFO:     Number of params in model 224011
2022-12-31 09:19:46,387 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:19:46,387 INFO:   Starting stage: TRAINING
2022-12-31 09:19:46,433 INFO:     Val loss before train {'Reaction outcome loss': 0.997280486424764, 'Total loss': 0.997280486424764}
2022-12-31 09:19:46,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:46,433 INFO:     Epoch: 0
2022-12-31 09:19:48,054 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.530092469851176, 'Total loss': 0.530092469851176} | train loss {'Reaction outcome loss': 0.7764601810744524, 'Total loss': 0.7764601810744524}
2022-12-31 09:19:48,054 INFO:     Found new best model at epoch 0
2022-12-31 09:19:48,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:48,055 INFO:     Epoch: 1
2022-12-31 09:19:49,672 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45641162395477297, 'Total loss': 0.45641162395477297} | train loss {'Reaction outcome loss': 0.5097394927206452, 'Total loss': 0.5097394927206452}
2022-12-31 09:19:49,673 INFO:     Found new best model at epoch 1
2022-12-31 09:19:49,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:49,674 INFO:     Epoch: 2
2022-12-31 09:19:51,289 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.40827831824620564, 'Total loss': 0.40827831824620564} | train loss {'Reaction outcome loss': 0.44446671996198406, 'Total loss': 0.44446671996198406}
2022-12-31 09:19:51,289 INFO:     Found new best model at epoch 2
2022-12-31 09:19:51,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:51,290 INFO:     Epoch: 3
2022-12-31 09:19:52,905 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.39466892679532367, 'Total loss': 0.39466892679532367} | train loss {'Reaction outcome loss': 0.4092290705399393, 'Total loss': 0.4092290705399393}
2022-12-31 09:19:52,905 INFO:     Found new best model at epoch 3
2022-12-31 09:19:52,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:52,906 INFO:     Epoch: 4
2022-12-31 09:19:54,520 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3869606703519821, 'Total loss': 0.3869606703519821} | train loss {'Reaction outcome loss': 0.3801880024830787, 'Total loss': 0.3801880024830787}
2022-12-31 09:19:54,520 INFO:     Found new best model at epoch 4
2022-12-31 09:19:54,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:54,521 INFO:     Epoch: 5
2022-12-31 09:19:56,169 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4109486202398936, 'Total loss': 0.4109486202398936} | train loss {'Reaction outcome loss': 0.35676900569067105, 'Total loss': 0.35676900569067105}
2022-12-31 09:19:56,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:56,170 INFO:     Epoch: 6
2022-12-31 09:19:57,791 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.367710738008221, 'Total loss': 0.367710738008221} | train loss {'Reaction outcome loss': 0.3359820711887055, 'Total loss': 0.3359820711887055}
2022-12-31 09:19:57,791 INFO:     Found new best model at epoch 6
2022-12-31 09:19:57,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:57,792 INFO:     Epoch: 7
2022-12-31 09:19:59,424 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38385722736517586, 'Total loss': 0.38385722736517586} | train loss {'Reaction outcome loss': 0.3220391735528673, 'Total loss': 0.3220391735528673}
2022-12-31 09:19:59,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:19:59,424 INFO:     Epoch: 8
2022-12-31 09:20:01,056 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37394856015841166, 'Total loss': 0.37394856015841166} | train loss {'Reaction outcome loss': 0.30275885163661803, 'Total loss': 0.30275885163661803}
2022-12-31 09:20:01,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:01,056 INFO:     Epoch: 9
2022-12-31 09:20:02,686 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3989004552364349, 'Total loss': 0.3989004552364349} | train loss {'Reaction outcome loss': 0.2953853940167582, 'Total loss': 0.2953853940167582}
2022-12-31 09:20:02,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:02,687 INFO:     Epoch: 10
2022-12-31 09:20:04,317 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3533341030279795, 'Total loss': 0.3533341030279795} | train loss {'Reaction outcome loss': 0.2814148816848275, 'Total loss': 0.2814148816848275}
2022-12-31 09:20:04,317 INFO:     Found new best model at epoch 10
2022-12-31 09:20:04,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:04,318 INFO:     Epoch: 11
2022-12-31 09:20:05,933 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3869021018346151, 'Total loss': 0.3869021018346151} | train loss {'Reaction outcome loss': 0.26850062888451864, 'Total loss': 0.26850062888451864}
2022-12-31 09:20:05,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:05,934 INFO:     Epoch: 12
2022-12-31 09:20:07,560 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3721013993024826, 'Total loss': 0.3721013993024826} | train loss {'Reaction outcome loss': 0.26124279626009694, 'Total loss': 0.26124279626009694}
2022-12-31 09:20:07,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:07,561 INFO:     Epoch: 13
2022-12-31 09:20:09,230 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3586049109697342, 'Total loss': 0.3586049109697342} | train loss {'Reaction outcome loss': 0.2545045223557777, 'Total loss': 0.2545045223557777}
2022-12-31 09:20:09,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:09,231 INFO:     Epoch: 14
2022-12-31 09:20:10,850 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3623191932837168, 'Total loss': 0.3623191932837168} | train loss {'Reaction outcome loss': 0.24374120125701712, 'Total loss': 0.24374120125701712}
2022-12-31 09:20:10,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:10,850 INFO:     Epoch: 15
2022-12-31 09:20:12,468 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3500853637854258, 'Total loss': 0.3500853637854258} | train loss {'Reaction outcome loss': 0.2341475102660458, 'Total loss': 0.2341475102660458}
2022-12-31 09:20:12,468 INFO:     Found new best model at epoch 15
2022-12-31 09:20:12,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:12,469 INFO:     Epoch: 16
2022-12-31 09:20:14,107 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35837712585926057, 'Total loss': 0.35837712585926057} | train loss {'Reaction outcome loss': 0.22659914259418898, 'Total loss': 0.22659914259418898}
2022-12-31 09:20:14,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:14,107 INFO:     Epoch: 17
2022-12-31 09:20:15,733 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3640747288862864, 'Total loss': 0.3640747288862864} | train loss {'Reaction outcome loss': 0.22099275912565014, 'Total loss': 0.22099275912565014}
2022-12-31 09:20:15,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:15,733 INFO:     Epoch: 18
2022-12-31 09:20:17,368 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.35989507138729093, 'Total loss': 0.35989507138729093} | train loss {'Reaction outcome loss': 0.21552676186032782, 'Total loss': 0.21552676186032782}
2022-12-31 09:20:17,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:17,368 INFO:     Epoch: 19
2022-12-31 09:20:19,002 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3624269157648087, 'Total loss': 0.3624269157648087} | train loss {'Reaction outcome loss': 0.20944506503534016, 'Total loss': 0.20944506503534016}
2022-12-31 09:20:19,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:19,003 INFO:     Epoch: 20
2022-12-31 09:20:20,637 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36375589470068614, 'Total loss': 0.36375589470068614} | train loss {'Reaction outcome loss': 0.2018319417181213, 'Total loss': 0.2018319417181213}
2022-12-31 09:20:20,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:20,638 INFO:     Epoch: 21
2022-12-31 09:20:22,264 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3775971710681915, 'Total loss': 0.3775971710681915} | train loss {'Reaction outcome loss': 0.20037798825584163, 'Total loss': 0.20037798825584163}
2022-12-31 09:20:22,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:22,265 INFO:     Epoch: 22
2022-12-31 09:20:23,895 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3840001334746679, 'Total loss': 0.3840001334746679} | train loss {'Reaction outcome loss': 0.19839493228317598, 'Total loss': 0.19839493228317598}
2022-12-31 09:20:23,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:23,896 INFO:     Epoch: 23
2022-12-31 09:20:25,521 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3781880517800649, 'Total loss': 0.3781880517800649} | train loss {'Reaction outcome loss': 0.18936249101366376, 'Total loss': 0.18936249101366376}
2022-12-31 09:20:25,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:25,521 INFO:     Epoch: 24
2022-12-31 09:20:27,190 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35974146127700807, 'Total loss': 0.35974146127700807} | train loss {'Reaction outcome loss': 0.1930352573077924, 'Total loss': 0.1930352573077924}
2022-12-31 09:20:27,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:27,191 INFO:     Epoch: 25
2022-12-31 09:20:28,815 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37446348170439403, 'Total loss': 0.37446348170439403} | train loss {'Reaction outcome loss': 0.1877412161107313, 'Total loss': 0.1877412161107313}
2022-12-31 09:20:28,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:28,815 INFO:     Epoch: 26
2022-12-31 09:20:30,484 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38582174728314084, 'Total loss': 0.38582174728314084} | train loss {'Reaction outcome loss': 0.18407184837742402, 'Total loss': 0.18407184837742402}
2022-12-31 09:20:30,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:30,484 INFO:     Epoch: 27
2022-12-31 09:20:32,126 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.36383198300997416, 'Total loss': 0.36383198300997416} | train loss {'Reaction outcome loss': 0.1762820432359346, 'Total loss': 0.1762820432359346}
2022-12-31 09:20:32,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:32,126 INFO:     Epoch: 28
2022-12-31 09:20:33,753 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3582609623670578, 'Total loss': 0.3582609623670578} | train loss {'Reaction outcome loss': 0.1800410521858866, 'Total loss': 0.1800410521858866}
2022-12-31 09:20:33,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:33,754 INFO:     Epoch: 29
2022-12-31 09:20:35,423 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3706584493319193, 'Total loss': 0.3706584493319193} | train loss {'Reaction outcome loss': 0.1729420522086672, 'Total loss': 0.1729420522086672}
2022-12-31 09:20:35,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:35,423 INFO:     Epoch: 30
2022-12-31 09:20:37,049 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37386985272169115, 'Total loss': 0.37386985272169115} | train loss {'Reaction outcome loss': 0.17254758664887626, 'Total loss': 0.17254758664887626}
2022-12-31 09:20:37,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:37,049 INFO:     Epoch: 31
2022-12-31 09:20:38,718 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38781697750091554, 'Total loss': 0.38781697750091554} | train loss {'Reaction outcome loss': 0.17446581772881617, 'Total loss': 0.17446581772881617}
2022-12-31 09:20:38,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:38,718 INFO:     Epoch: 32
2022-12-31 09:20:40,340 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3898046190539996, 'Total loss': 0.3898046190539996} | train loss {'Reaction outcome loss': 0.1666116103469411, 'Total loss': 0.1666116103469411}
2022-12-31 09:20:40,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:40,341 INFO:     Epoch: 33
2022-12-31 09:20:41,983 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.371198042233785, 'Total loss': 0.371198042233785} | train loss {'Reaction outcome loss': 0.1644354241997649, 'Total loss': 0.1644354241997649}
2022-12-31 09:20:41,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:41,983 INFO:     Epoch: 34
2022-12-31 09:20:43,636 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40960939476887387, 'Total loss': 0.40960939476887387} | train loss {'Reaction outcome loss': 0.16169301094823527, 'Total loss': 0.16169301094823527}
2022-12-31 09:20:43,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:43,636 INFO:     Epoch: 35
2022-12-31 09:20:45,259 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40535268088181814, 'Total loss': 0.40535268088181814} | train loss {'Reaction outcome loss': 0.16436366505907438, 'Total loss': 0.16436366505907438}
2022-12-31 09:20:45,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:45,259 INFO:     Epoch: 36
2022-12-31 09:20:46,928 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39825354516506195, 'Total loss': 0.39825354516506195} | train loss {'Reaction outcome loss': 0.16177229744647814, 'Total loss': 0.16177229744647814}
2022-12-31 09:20:46,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:46,928 INFO:     Epoch: 37
2022-12-31 09:20:48,552 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36368168145418167, 'Total loss': 0.36368168145418167} | train loss {'Reaction outcome loss': 0.15724491252352077, 'Total loss': 0.15724491252352077}
2022-12-31 09:20:48,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:48,552 INFO:     Epoch: 38
2022-12-31 09:20:50,192 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39177464817961055, 'Total loss': 0.39177464817961055} | train loss {'Reaction outcome loss': 0.15518749516712846, 'Total loss': 0.15518749516712846}
2022-12-31 09:20:50,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:50,192 INFO:     Epoch: 39
2022-12-31 09:20:51,841 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3872515678405762, 'Total loss': 0.3872515678405762} | train loss {'Reaction outcome loss': 0.15274862541954978, 'Total loss': 0.15274862541954978}
2022-12-31 09:20:51,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:51,841 INFO:     Epoch: 40
2022-12-31 09:20:53,474 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3647450680534045, 'Total loss': 0.3647450680534045} | train loss {'Reaction outcome loss': 0.15285895912427228, 'Total loss': 0.15285895912427228}
2022-12-31 09:20:53,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:53,474 INFO:     Epoch: 41
2022-12-31 09:20:55,108 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36404048974315323, 'Total loss': 0.36404048974315323} | train loss {'Reaction outcome loss': 0.14855050348377508, 'Total loss': 0.14855050348377508}
2022-12-31 09:20:55,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:55,108 INFO:     Epoch: 42
2022-12-31 09:20:56,743 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3786234075513979, 'Total loss': 0.3786234075513979} | train loss {'Reaction outcome loss': 0.1510450313664596, 'Total loss': 0.1510450313664596}
2022-12-31 09:20:56,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:56,744 INFO:     Epoch: 43
2022-12-31 09:20:58,378 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34953891187906266, 'Total loss': 0.34953891187906266} | train loss {'Reaction outcome loss': 0.14461523237964308, 'Total loss': 0.14461523237964308}
2022-12-31 09:20:58,379 INFO:     Found new best model at epoch 43
2022-12-31 09:20:58,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:20:58,380 INFO:     Epoch: 44
2022-12-31 09:21:00,005 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3578241318464279, 'Total loss': 0.3578241318464279} | train loss {'Reaction outcome loss': 0.14436982493067585, 'Total loss': 0.14436982493067585}
2022-12-31 09:21:00,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:00,005 INFO:     Epoch: 45
2022-12-31 09:21:01,630 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3697604616483053, 'Total loss': 0.3697604616483053} | train loss {'Reaction outcome loss': 0.1447975474732528, 'Total loss': 0.1447975474732528}
2022-12-31 09:21:01,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:01,631 INFO:     Epoch: 46
2022-12-31 09:21:03,267 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3920838018258413, 'Total loss': 0.3920838018258413} | train loss {'Reaction outcome loss': 0.14594281047569177, 'Total loss': 0.14594281047569177}
2022-12-31 09:21:03,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:03,268 INFO:     Epoch: 47
2022-12-31 09:21:04,903 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3762345078090827, 'Total loss': 0.3762345078090827} | train loss {'Reaction outcome loss': 0.1410417219519696, 'Total loss': 0.1410417219519696}
2022-12-31 09:21:04,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:04,903 INFO:     Epoch: 48
2022-12-31 09:21:06,538 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36134953796863556, 'Total loss': 0.36134953796863556} | train loss {'Reaction outcome loss': 0.1407767191145986, 'Total loss': 0.1407767191145986}
2022-12-31 09:21:06,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:06,538 INFO:     Epoch: 49
2022-12-31 09:21:08,173 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3740965336561203, 'Total loss': 0.3740965336561203} | train loss {'Reaction outcome loss': 0.1397417642458574, 'Total loss': 0.1397417642458574}
2022-12-31 09:21:08,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:08,173 INFO:     Epoch: 50
2022-12-31 09:21:09,830 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.35906161268552145, 'Total loss': 0.35906161268552145} | train loss {'Reaction outcome loss': 0.13789537402428015, 'Total loss': 0.13789537402428015}
2022-12-31 09:21:09,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:09,830 INFO:     Epoch: 51
2022-12-31 09:21:11,466 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38437307327985765, 'Total loss': 0.38437307327985765} | train loss {'Reaction outcome loss': 0.13771558160614558, 'Total loss': 0.13771558160614558}
2022-12-31 09:21:11,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:11,466 INFO:     Epoch: 52
2022-12-31 09:21:13,102 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3601380124688148, 'Total loss': 0.3601380124688148} | train loss {'Reaction outcome loss': 0.13861284242095662, 'Total loss': 0.13861284242095662}
2022-12-31 09:21:13,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:13,102 INFO:     Epoch: 53
2022-12-31 09:21:14,738 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39460980097452797, 'Total loss': 0.39460980097452797} | train loss {'Reaction outcome loss': 0.13551028267672077, 'Total loss': 0.13551028267672077}
2022-12-31 09:21:14,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:14,739 INFO:     Epoch: 54
2022-12-31 09:21:16,376 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3698417107264201, 'Total loss': 0.3698417107264201} | train loss {'Reaction outcome loss': 0.13394930931009916, 'Total loss': 0.13394930931009916}
2022-12-31 09:21:16,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:16,377 INFO:     Epoch: 55
2022-12-31 09:21:18,004 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39277018457651136, 'Total loss': 0.39277018457651136} | train loss {'Reaction outcome loss': 0.13404481680996527, 'Total loss': 0.13404481680996527}
2022-12-31 09:21:18,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:18,005 INFO:     Epoch: 56
2022-12-31 09:21:19,638 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37452296117941536, 'Total loss': 0.37452296117941536} | train loss {'Reaction outcome loss': 0.1330987923502895, 'Total loss': 0.1330987923502895}
2022-12-31 09:21:19,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:19,639 INFO:     Epoch: 57
2022-12-31 09:21:21,308 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3700135429700216, 'Total loss': 0.3700135429700216} | train loss {'Reaction outcome loss': 0.13096735363032683, 'Total loss': 0.13096735363032683}
2022-12-31 09:21:21,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:21,309 INFO:     Epoch: 58
2022-12-31 09:21:22,979 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3710523078838984, 'Total loss': 0.3710523078838984} | train loss {'Reaction outcome loss': 0.13118595353895898, 'Total loss': 0.13118595353895898}
2022-12-31 09:21:22,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:22,979 INFO:     Epoch: 59
2022-12-31 09:21:24,599 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3701101909081141, 'Total loss': 0.3701101909081141} | train loss {'Reaction outcome loss': 0.1297010928560519, 'Total loss': 0.1297010928560519}
2022-12-31 09:21:24,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:24,599 INFO:     Epoch: 60
2022-12-31 09:21:26,255 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3896171674132347, 'Total loss': 0.3896171674132347} | train loss {'Reaction outcome loss': 0.12897617761499588, 'Total loss': 0.12897617761499588}
2022-12-31 09:21:26,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:26,255 INFO:     Epoch: 61
2022-12-31 09:21:27,890 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3953550189733505, 'Total loss': 0.3953550189733505} | train loss {'Reaction outcome loss': 0.13195639937806752, 'Total loss': 0.13195639937806752}
2022-12-31 09:21:27,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:27,890 INFO:     Epoch: 62
2022-12-31 09:21:29,514 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39183263580004374, 'Total loss': 0.39183263580004374} | train loss {'Reaction outcome loss': 0.1293568229134655, 'Total loss': 0.1293568229134655}
2022-12-31 09:21:29,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:29,514 INFO:     Epoch: 63
2022-12-31 09:21:31,184 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4098789046208064, 'Total loss': 0.4098789046208064} | train loss {'Reaction outcome loss': 0.12809169869399242, 'Total loss': 0.12809169869399242}
2022-12-31 09:21:31,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:31,185 INFO:     Epoch: 64
2022-12-31 09:21:32,806 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3927167634169261, 'Total loss': 0.3927167634169261} | train loss {'Reaction outcome loss': 0.12383425925162349, 'Total loss': 0.12383425925162349}
2022-12-31 09:21:32,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:32,806 INFO:     Epoch: 65
2022-12-31 09:21:34,476 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42420470317204795, 'Total loss': 0.42420470317204795} | train loss {'Reaction outcome loss': 0.1205232111293325, 'Total loss': 0.1205232111293325}
2022-12-31 09:21:34,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:34,476 INFO:     Epoch: 66
2022-12-31 09:21:36,107 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4044724524021149, 'Total loss': 0.4044724524021149} | train loss {'Reaction outcome loss': 0.12283264238568904, 'Total loss': 0.12283264238568904}
2022-12-31 09:21:36,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:36,107 INFO:     Epoch: 67
2022-12-31 09:21:37,753 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3828478189806143, 'Total loss': 0.3828478189806143} | train loss {'Reaction outcome loss': 0.1278221118852281, 'Total loss': 0.1278221118852281}
2022-12-31 09:21:37,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:37,754 INFO:     Epoch: 68
2022-12-31 09:21:39,394 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39929739832878114, 'Total loss': 0.39929739832878114} | train loss {'Reaction outcome loss': 0.12890194957430343, 'Total loss': 0.12890194957430343}
2022-12-31 09:21:39,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:39,394 INFO:     Epoch: 69
2022-12-31 09:21:41,034 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40794158975283307, 'Total loss': 0.40794158975283307} | train loss {'Reaction outcome loss': 0.12603640343257586, 'Total loss': 0.12603640343257586}
2022-12-31 09:21:41,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:41,034 INFO:     Epoch: 70
2022-12-31 09:21:42,674 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3815736879905065, 'Total loss': 0.3815736879905065} | train loss {'Reaction outcome loss': 0.12448621524787014, 'Total loss': 0.12448621524787014}
2022-12-31 09:21:42,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:42,674 INFO:     Epoch: 71
2022-12-31 09:21:44,309 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39786576678355534, 'Total loss': 0.39786576678355534} | train loss {'Reaction outcome loss': 0.1258377780060247, 'Total loss': 0.1258377780060247}
2022-12-31 09:21:44,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:44,309 INFO:     Epoch: 72
2022-12-31 09:21:45,969 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3881040533383687, 'Total loss': 0.3881040533383687} | train loss {'Reaction outcome loss': 0.1190962652971679, 'Total loss': 0.1190962652971679}
2022-12-31 09:21:45,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:45,969 INFO:     Epoch: 73
2022-12-31 09:21:47,600 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40869561533133186, 'Total loss': 0.40869561533133186} | train loss {'Reaction outcome loss': 0.11791717957550599, 'Total loss': 0.11791717957550599}
2022-12-31 09:21:47,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:47,600 INFO:     Epoch: 74
2022-12-31 09:21:49,240 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3806602656841278, 'Total loss': 0.3806602656841278} | train loss {'Reaction outcome loss': 0.12163537318586282, 'Total loss': 0.12163537318586282}
2022-12-31 09:21:49,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:49,240 INFO:     Epoch: 75
2022-12-31 09:21:50,878 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3931233654419581, 'Total loss': 0.3931233654419581} | train loss {'Reaction outcome loss': 0.12182535392161634, 'Total loss': 0.12182535392161634}
2022-12-31 09:21:50,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:50,879 INFO:     Epoch: 76
2022-12-31 09:21:52,516 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41819692502419153, 'Total loss': 0.41819692502419153} | train loss {'Reaction outcome loss': 0.12613194884349077, 'Total loss': 0.12613194884349077}
2022-12-31 09:21:52,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:52,517 INFO:     Epoch: 77
2022-12-31 09:21:54,145 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3974405368169149, 'Total loss': 0.3974405368169149} | train loss {'Reaction outcome loss': 0.12690272074972786, 'Total loss': 0.12690272074972786}
2022-12-31 09:21:54,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:54,145 INFO:     Epoch: 78
2022-12-31 09:21:55,783 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4016583763062954, 'Total loss': 0.4016583763062954} | train loss {'Reaction outcome loss': 0.11733501211366876, 'Total loss': 0.11733501211366876}
2022-12-31 09:21:55,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:55,783 INFO:     Epoch: 79
2022-12-31 09:21:57,455 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3853107829888662, 'Total loss': 0.3853107829888662} | train loss {'Reaction outcome loss': 0.11877877347251999, 'Total loss': 0.11877877347251999}
2022-12-31 09:21:57,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:57,455 INFO:     Epoch: 80
2022-12-31 09:21:59,126 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3868725965420405, 'Total loss': 0.3868725965420405} | train loss {'Reaction outcome loss': 0.11802921679529903, 'Total loss': 0.11802921679529903}
2022-12-31 09:21:59,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:21:59,126 INFO:     Epoch: 81
2022-12-31 09:22:00,755 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39805588821570076, 'Total loss': 0.39805588821570076} | train loss {'Reaction outcome loss': 0.11867667736472151, 'Total loss': 0.11867667736472151}
2022-12-31 09:22:00,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:00,756 INFO:     Epoch: 82
2022-12-31 09:22:02,426 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4223195652167002, 'Total loss': 0.4223195652167002} | train loss {'Reaction outcome loss': 0.1175412933076547, 'Total loss': 0.1175412933076547}
2022-12-31 09:22:02,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:02,426 INFO:     Epoch: 83
2022-12-31 09:22:04,052 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4219314008951187, 'Total loss': 0.4219314008951187} | train loss {'Reaction outcome loss': 0.12040373733744617, 'Total loss': 0.12040373733744617}
2022-12-31 09:22:04,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:04,052 INFO:     Epoch: 84
2022-12-31 09:22:05,677 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3675953169663747, 'Total loss': 0.3675953169663747} | train loss {'Reaction outcome loss': 0.11594244283506318, 'Total loss': 0.11594244283506318}
2022-12-31 09:22:05,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:05,678 INFO:     Epoch: 85
2022-12-31 09:22:07,307 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38382921665906905, 'Total loss': 0.38382921665906905} | train loss {'Reaction outcome loss': 0.11882717601302675, 'Total loss': 0.11882717601302675}
2022-12-31 09:22:07,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:07,309 INFO:     Epoch: 86
2022-12-31 09:22:08,935 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3908723652362823, 'Total loss': 0.3908723652362823} | train loss {'Reaction outcome loss': 0.11932521369577208, 'Total loss': 0.11932521369577208}
2022-12-31 09:22:08,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:08,935 INFO:     Epoch: 87
2022-12-31 09:22:10,562 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3943949629863103, 'Total loss': 0.3943949629863103} | train loss {'Reaction outcome loss': 0.11558350592444816, 'Total loss': 0.11558350592444816}
2022-12-31 09:22:10,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:10,563 INFO:     Epoch: 88
2022-12-31 09:22:12,199 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41587117115656536, 'Total loss': 0.41587117115656536} | train loss {'Reaction outcome loss': 0.11429540032440198, 'Total loss': 0.11429540032440198}
2022-12-31 09:22:12,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:12,199 INFO:     Epoch: 89
2022-12-31 09:22:13,822 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3979356974363327, 'Total loss': 0.3979356974363327} | train loss {'Reaction outcome loss': 0.11582144931637907, 'Total loss': 0.11582144931637907}
2022-12-31 09:22:13,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:13,823 INFO:     Epoch: 90
2022-12-31 09:22:15,451 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3836209632456303, 'Total loss': 0.3836209632456303} | train loss {'Reaction outcome loss': 0.11888116841046442, 'Total loss': 0.11888116841046442}
2022-12-31 09:22:15,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:15,451 INFO:     Epoch: 91
2022-12-31 09:22:17,122 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3895803640286128, 'Total loss': 0.3895803640286128} | train loss {'Reaction outcome loss': 0.11236753301032641, 'Total loss': 0.11236753301032641}
2022-12-31 09:22:17,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:17,123 INFO:     Epoch: 92
2022-12-31 09:22:18,749 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3798154840866725, 'Total loss': 0.3798154840866725} | train loss {'Reaction outcome loss': 0.11384560417094762, 'Total loss': 0.11384560417094762}
2022-12-31 09:22:18,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:18,750 INFO:     Epoch: 93
2022-12-31 09:22:20,382 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3972836666119595, 'Total loss': 0.3972836666119595} | train loss {'Reaction outcome loss': 0.11467096058732497, 'Total loss': 0.11467096058732497}
2022-12-31 09:22:20,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:20,382 INFO:     Epoch: 94
2022-12-31 09:22:22,030 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3957432856162389, 'Total loss': 0.3957432856162389} | train loss {'Reaction outcome loss': 0.11786533821212794, 'Total loss': 0.11786533821212794}
2022-12-31 09:22:22,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:22,031 INFO:     Epoch: 95
2022-12-31 09:22:23,676 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42282705903053286, 'Total loss': 0.42282705903053286} | train loss {'Reaction outcome loss': 0.11405800248492873, 'Total loss': 0.11405800248492873}
2022-12-31 09:22:23,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:23,676 INFO:     Epoch: 96
2022-12-31 09:22:25,303 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3885038807988167, 'Total loss': 0.3885038807988167} | train loss {'Reaction outcome loss': 0.11241249826195437, 'Total loss': 0.11241249826195437}
2022-12-31 09:22:25,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:25,304 INFO:     Epoch: 97
2022-12-31 09:22:26,931 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40848047385613123, 'Total loss': 0.40848047385613123} | train loss {'Reaction outcome loss': 0.11299295404872148, 'Total loss': 0.11299295404872148}
2022-12-31 09:22:26,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:26,932 INFO:     Epoch: 98
2022-12-31 09:22:28,555 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3993664890527725, 'Total loss': 0.3993664890527725} | train loss {'Reaction outcome loss': 0.11355792303798243, 'Total loss': 0.11355792303798243}
2022-12-31 09:22:28,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:28,555 INFO:     Epoch: 99
2022-12-31 09:22:30,171 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39892450273036956, 'Total loss': 0.39892450273036956} | train loss {'Reaction outcome loss': 0.11497753078457547, 'Total loss': 0.11497753078457547}
2022-12-31 09:22:30,171 INFO:     Best model found after epoch 44 of 100.
2022-12-31 09:22:30,172 INFO:   Done with stage: TRAINING
2022-12-31 09:22:30,172 INFO:   Starting stage: EVALUATION
2022-12-31 09:22:30,299 INFO:   Done with stage: EVALUATION
2022-12-31 09:22:30,299 INFO:   Leaving out SEQ value Fold_7
2022-12-31 09:22:30,312 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 09:22:30,312 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:22:30,965 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:22:30,965 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:22:31,034 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:22:31,034 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:22:31,034 INFO:     No hyperparam tuning for this model
2022-12-31 09:22:31,034 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:22:31,034 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:22:31,035 INFO:     None feature selector for col prot
2022-12-31 09:22:31,035 INFO:     None feature selector for col prot
2022-12-31 09:22:31,035 INFO:     None feature selector for col prot
2022-12-31 09:22:31,036 INFO:     None feature selector for col chem
2022-12-31 09:22:31,036 INFO:     None feature selector for col chem
2022-12-31 09:22:31,036 INFO:     None feature selector for col chem
2022-12-31 09:22:31,036 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:22:31,036 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:22:31,038 INFO:     Number of params in model 224011
2022-12-31 09:22:31,041 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:22:31,041 INFO:   Starting stage: TRAINING
2022-12-31 09:22:31,087 INFO:     Val loss before train {'Reaction outcome loss': 1.010222065448761, 'Total loss': 1.010222065448761}
2022-12-31 09:22:31,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:31,088 INFO:     Epoch: 0
2022-12-31 09:22:32,732 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5732529044151307, 'Total loss': 0.5732529044151307} | train loss {'Reaction outcome loss': 0.7947892798413438, 'Total loss': 0.7947892798413438}
2022-12-31 09:22:32,732 INFO:     Found new best model at epoch 0
2022-12-31 09:22:32,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:32,733 INFO:     Epoch: 1
2022-12-31 09:22:34,352 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48602327704429626, 'Total loss': 0.48602327704429626} | train loss {'Reaction outcome loss': 0.5213395758441209, 'Total loss': 0.5213395758441209}
2022-12-31 09:22:34,353 INFO:     Found new best model at epoch 1
2022-12-31 09:22:34,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:34,354 INFO:     Epoch: 2
2022-12-31 09:22:35,973 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4659671743710836, 'Total loss': 0.4659671743710836} | train loss {'Reaction outcome loss': 0.44879014962201513, 'Total loss': 0.44879014962201513}
2022-12-31 09:22:35,974 INFO:     Found new best model at epoch 2
2022-12-31 09:22:35,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:35,975 INFO:     Epoch: 3
2022-12-31 09:22:37,596 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47205616732438405, 'Total loss': 0.47205616732438405} | train loss {'Reaction outcome loss': 0.4153973144421939, 'Total loss': 0.4153973144421939}
2022-12-31 09:22:37,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:37,596 INFO:     Epoch: 4
2022-12-31 09:22:39,212 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4422173023223877, 'Total loss': 0.4422173023223877} | train loss {'Reaction outcome loss': 0.3843463341359197, 'Total loss': 0.3843463341359197}
2022-12-31 09:22:39,213 INFO:     Found new best model at epoch 4
2022-12-31 09:22:39,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:39,214 INFO:     Epoch: 5
2022-12-31 09:22:40,821 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43407955368359885, 'Total loss': 0.43407955368359885} | train loss {'Reaction outcome loss': 0.36242067854219395, 'Total loss': 0.36242067854219395}
2022-12-31 09:22:40,821 INFO:     Found new best model at epoch 5
2022-12-31 09:22:40,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:40,822 INFO:     Epoch: 6
2022-12-31 09:22:42,444 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4362248589595159, 'Total loss': 0.4362248589595159} | train loss {'Reaction outcome loss': 0.3425105775198782, 'Total loss': 0.3425105775198782}
2022-12-31 09:22:42,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:42,444 INFO:     Epoch: 7
2022-12-31 09:22:44,066 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4273191377520561, 'Total loss': 0.4273191377520561} | train loss {'Reaction outcome loss': 0.3277946310084219, 'Total loss': 0.3277946310084219}
2022-12-31 09:22:44,066 INFO:     Found new best model at epoch 7
2022-12-31 09:22:44,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:44,067 INFO:     Epoch: 8
2022-12-31 09:22:45,689 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44174022078514097, 'Total loss': 0.44174022078514097} | train loss {'Reaction outcome loss': 0.3097082990682297, 'Total loss': 0.3097082990682297}
2022-12-31 09:22:45,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:45,690 INFO:     Epoch: 9
2022-12-31 09:22:47,313 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42770737409591675, 'Total loss': 0.42770737409591675} | train loss {'Reaction outcome loss': 0.2977311804433377, 'Total loss': 0.2977311804433377}
2022-12-31 09:22:47,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:47,313 INFO:     Epoch: 10
2022-12-31 09:22:48,935 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44464102387428284, 'Total loss': 0.44464102387428284} | train loss {'Reaction outcome loss': 0.28340764860168693, 'Total loss': 0.28340764860168693}
2022-12-31 09:22:48,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:48,936 INFO:     Epoch: 11
2022-12-31 09:22:50,554 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4317230500280857, 'Total loss': 0.4317230500280857} | train loss {'Reaction outcome loss': 0.2730233883653307, 'Total loss': 0.2730233883653307}
2022-12-31 09:22:50,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:50,554 INFO:     Epoch: 12
2022-12-31 09:22:52,184 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46512091755867, 'Total loss': 0.46512091755867} | train loss {'Reaction outcome loss': 0.2648842245985885, 'Total loss': 0.2648842245985885}
2022-12-31 09:22:52,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:52,185 INFO:     Epoch: 13
2022-12-31 09:22:53,814 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45551908810933434, 'Total loss': 0.45551908810933434} | train loss {'Reaction outcome loss': 0.2549798673402101, 'Total loss': 0.2549798673402101}
2022-12-31 09:22:53,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:53,814 INFO:     Epoch: 14
2022-12-31 09:22:55,444 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4418180614709854, 'Total loss': 0.4418180614709854} | train loss {'Reaction outcome loss': 0.24392941393738188, 'Total loss': 0.24392941393738188}
2022-12-31 09:22:55,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:55,444 INFO:     Epoch: 15
2022-12-31 09:22:57,068 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46188308199246725, 'Total loss': 0.46188308199246725} | train loss {'Reaction outcome loss': 0.23823051364413236, 'Total loss': 0.23823051364413236}
2022-12-31 09:22:57,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:57,068 INFO:     Epoch: 16
2022-12-31 09:22:58,681 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43945143818855287, 'Total loss': 0.43945143818855287} | train loss {'Reaction outcome loss': 0.23068553234857342, 'Total loss': 0.23068553234857342}
2022-12-31 09:22:58,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:22:58,682 INFO:     Epoch: 17
2022-12-31 09:23:00,339 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45693211555480956, 'Total loss': 0.45693211555480956} | train loss {'Reaction outcome loss': 0.2217221196861904, 'Total loss': 0.2217221196861904}
2022-12-31 09:23:00,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:00,340 INFO:     Epoch: 18
2022-12-31 09:23:01,960 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4737078939874967, 'Total loss': 0.4737078939874967} | train loss {'Reaction outcome loss': 0.2160401789854795, 'Total loss': 0.2160401789854795}
2022-12-31 09:23:01,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:01,960 INFO:     Epoch: 19
2022-12-31 09:23:03,626 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4809536308050156, 'Total loss': 0.4809536308050156} | train loss {'Reaction outcome loss': 0.2144370415997742, 'Total loss': 0.2144370415997742}
2022-12-31 09:23:03,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:03,626 INFO:     Epoch: 20
2022-12-31 09:23:05,246 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45712550431489946, 'Total loss': 0.45712550431489946} | train loss {'Reaction outcome loss': 0.20486500636012114, 'Total loss': 0.20486500636012114}
2022-12-31 09:23:05,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:05,247 INFO:     Epoch: 21
2022-12-31 09:23:06,888 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4571295529603958, 'Total loss': 0.4571295529603958} | train loss {'Reaction outcome loss': 0.20157663436734288, 'Total loss': 0.20157663436734288}
2022-12-31 09:23:06,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:06,889 INFO:     Epoch: 22
2022-12-31 09:23:08,515 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47448661625385286, 'Total loss': 0.47448661625385286} | train loss {'Reaction outcome loss': 0.19897856488016968, 'Total loss': 0.19897856488016968}
2022-12-31 09:23:08,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:08,516 INFO:     Epoch: 23
2022-12-31 09:23:10,148 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45096503496170043, 'Total loss': 0.45096503496170043} | train loss {'Reaction outcome loss': 0.19256663579318928, 'Total loss': 0.19256663579318928}
2022-12-31 09:23:10,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:10,149 INFO:     Epoch: 24
2022-12-31 09:23:11,783 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46181259453296664, 'Total loss': 0.46181259453296664} | train loss {'Reaction outcome loss': 0.19150227245736853, 'Total loss': 0.19150227245736853}
2022-12-31 09:23:11,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:11,783 INFO:     Epoch: 25
2022-12-31 09:23:13,418 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4839247723420461, 'Total loss': 0.4839247723420461} | train loss {'Reaction outcome loss': 0.1867532402357685, 'Total loss': 0.1867532402357685}
2022-12-31 09:23:13,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:13,418 INFO:     Epoch: 26
2022-12-31 09:23:15,084 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46132791340351104, 'Total loss': 0.46132791340351104} | train loss {'Reaction outcome loss': 0.18193176185665147, 'Total loss': 0.18193176185665147}
2022-12-31 09:23:15,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:15,086 INFO:     Epoch: 27
2022-12-31 09:23:16,702 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48373219519853594, 'Total loss': 0.48373219519853594} | train loss {'Reaction outcome loss': 0.1826178508235767, 'Total loss': 0.1826178508235767}
2022-12-31 09:23:16,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:16,702 INFO:     Epoch: 28
2022-12-31 09:23:18,326 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4403676509857178, 'Total loss': 0.4403676509857178} | train loss {'Reaction outcome loss': 0.1797599835987018, 'Total loss': 0.1797599835987018}
2022-12-31 09:23:18,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:18,326 INFO:     Epoch: 29
2022-12-31 09:23:19,991 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4599180519580841, 'Total loss': 0.4599180519580841} | train loss {'Reaction outcome loss': 0.17328656088251498, 'Total loss': 0.17328656088251498}
2022-12-31 09:23:19,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:19,991 INFO:     Epoch: 30
2022-12-31 09:23:21,657 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45129172106583915, 'Total loss': 0.45129172106583915} | train loss {'Reaction outcome loss': 0.17240326927591532, 'Total loss': 0.17240326927591532}
2022-12-31 09:23:21,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:21,658 INFO:     Epoch: 31
2022-12-31 09:23:23,281 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44187340637048084, 'Total loss': 0.44187340637048084} | train loss {'Reaction outcome loss': 0.16855628274730827, 'Total loss': 0.16855628274730827}
2022-12-31 09:23:23,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:23,281 INFO:     Epoch: 32
2022-12-31 09:23:24,937 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45488926271597546, 'Total loss': 0.45488926271597546} | train loss {'Reaction outcome loss': 0.1658099627236597, 'Total loss': 0.1658099627236597}
2022-12-31 09:23:24,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:24,937 INFO:     Epoch: 33
2022-12-31 09:23:26,583 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45847447315851847, 'Total loss': 0.45847447315851847} | train loss {'Reaction outcome loss': 0.1678112651413098, 'Total loss': 0.1678112651413098}
2022-12-31 09:23:26,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:26,583 INFO:     Epoch: 34
2022-12-31 09:23:28,218 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4704211046298345, 'Total loss': 0.4704211046298345} | train loss {'Reaction outcome loss': 0.16456981747333863, 'Total loss': 0.16456981747333863}
2022-12-31 09:23:28,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:28,218 INFO:     Epoch: 35
2022-12-31 09:23:29,852 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.462397305170695, 'Total loss': 0.462397305170695} | train loss {'Reaction outcome loss': 0.15905625163325335, 'Total loss': 0.15905625163325335}
2022-12-31 09:23:29,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:29,852 INFO:     Epoch: 36
2022-12-31 09:23:31,486 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4660662323236465, 'Total loss': 0.4660662323236465} | train loss {'Reaction outcome loss': 0.15643496228388715, 'Total loss': 0.15643496228388715}
2022-12-31 09:23:31,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:31,486 INFO:     Epoch: 37
2022-12-31 09:23:33,120 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4553900082906087, 'Total loss': 0.4553900082906087} | train loss {'Reaction outcome loss': 0.15709891907924564, 'Total loss': 0.15709891907924564}
2022-12-31 09:23:33,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:33,120 INFO:     Epoch: 38
2022-12-31 09:23:34,742 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4612814466158549, 'Total loss': 0.4612814466158549} | train loss {'Reaction outcome loss': 0.15500328938950808, 'Total loss': 0.15500328938950808}
2022-12-31 09:23:34,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:34,743 INFO:     Epoch: 39
2022-12-31 09:23:36,361 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4561518083016078, 'Total loss': 0.4561518083016078} | train loss {'Reaction outcome loss': 0.15330176772919588, 'Total loss': 0.15330176772919588}
2022-12-31 09:23:36,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:36,361 INFO:     Epoch: 40
2022-12-31 09:23:37,981 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47641772826512657, 'Total loss': 0.47641772826512657} | train loss {'Reaction outcome loss': 0.14919819552384128, 'Total loss': 0.14919819552384128}
2022-12-31 09:23:37,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:37,982 INFO:     Epoch: 41
2022-12-31 09:23:39,600 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4554668764273326, 'Total loss': 0.4554668764273326} | train loss {'Reaction outcome loss': 0.15613983481759305, 'Total loss': 0.15613983481759305}
2022-12-31 09:23:39,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:39,601 INFO:     Epoch: 42
2022-12-31 09:23:41,220 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4465124239524206, 'Total loss': 0.4465124239524206} | train loss {'Reaction outcome loss': 0.14753144506082638, 'Total loss': 0.14753144506082638}
2022-12-31 09:23:41,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:41,221 INFO:     Epoch: 43
2022-12-31 09:23:42,872 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4284030596415202, 'Total loss': 0.4284030596415202} | train loss {'Reaction outcome loss': 0.14667169083689846, 'Total loss': 0.14667169083689846}
2022-12-31 09:23:42,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:42,872 INFO:     Epoch: 44
2022-12-31 09:23:44,495 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42531280368566515, 'Total loss': 0.42531280368566515} | train loss {'Reaction outcome loss': 0.15091772610825968, 'Total loss': 0.15091772610825968}
2022-12-31 09:23:44,496 INFO:     Found new best model at epoch 44
2022-12-31 09:23:44,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:44,497 INFO:     Epoch: 45
2022-12-31 09:23:46,122 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43449749251206715, 'Total loss': 0.43449749251206715} | train loss {'Reaction outcome loss': 0.14615458123627983, 'Total loss': 0.14615458123627983}
2022-12-31 09:23:46,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:46,122 INFO:     Epoch: 46
2022-12-31 09:23:47,789 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4381202459335327, 'Total loss': 0.4381202459335327} | train loss {'Reaction outcome loss': 0.1461851283612019, 'Total loss': 0.1461851283612019}
2022-12-31 09:23:47,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:47,790 INFO:     Epoch: 47
2022-12-31 09:23:49,457 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41671822195251784, 'Total loss': 0.41671822195251784} | train loss {'Reaction outcome loss': 0.14005328957596624, 'Total loss': 0.14005328957596624}
2022-12-31 09:23:49,459 INFO:     Found new best model at epoch 47
2022-12-31 09:23:49,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:49,460 INFO:     Epoch: 48
2022-12-31 09:23:51,126 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4297858655452728, 'Total loss': 0.4297858655452728} | train loss {'Reaction outcome loss': 0.14185012018960305, 'Total loss': 0.14185012018960305}
2022-12-31 09:23:51,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:51,126 INFO:     Epoch: 49
2022-12-31 09:23:52,752 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4715523302555084, 'Total loss': 0.4715523302555084} | train loss {'Reaction outcome loss': 0.13935719295623392, 'Total loss': 0.13935719295623392}
2022-12-31 09:23:52,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:52,753 INFO:     Epoch: 50
2022-12-31 09:23:54,378 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4380684862534205, 'Total loss': 0.4380684862534205} | train loss {'Reaction outcome loss': 0.13875875119388856, 'Total loss': 0.13875875119388856}
2022-12-31 09:23:54,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:54,378 INFO:     Epoch: 51
2022-12-31 09:23:56,011 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45551529824733733, 'Total loss': 0.45551529824733733} | train loss {'Reaction outcome loss': 0.1393292551416406, 'Total loss': 0.1393292551416406}
2022-12-31 09:23:56,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:56,012 INFO:     Epoch: 52
2022-12-31 09:23:57,640 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43969149589538575, 'Total loss': 0.43969149589538575} | train loss {'Reaction outcome loss': 0.13638158198378791, 'Total loss': 0.13638158198378791}
2022-12-31 09:23:57,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:57,640 INFO:     Epoch: 53
2022-12-31 09:23:59,270 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4882112661997477, 'Total loss': 0.4882112661997477} | train loss {'Reaction outcome loss': 0.13467038286150523, 'Total loss': 0.13467038286150523}
2022-12-31 09:23:59,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:23:59,270 INFO:     Epoch: 54
2022-12-31 09:24:00,894 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4424332539240519, 'Total loss': 0.4424332539240519} | train loss {'Reaction outcome loss': 0.1433035245380408, 'Total loss': 0.1433035245380408}
2022-12-31 09:24:00,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:00,894 INFO:     Epoch: 55
2022-12-31 09:24:02,516 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42800529599189757, 'Total loss': 0.42800529599189757} | train loss {'Reaction outcome loss': 0.1353627433462425, 'Total loss': 0.1353627433462425}
2022-12-31 09:24:02,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:02,516 INFO:     Epoch: 56
2022-12-31 09:24:04,145 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4752570663889249, 'Total loss': 0.4752570663889249} | train loss {'Reaction outcome loss': 0.1340103582176464, 'Total loss': 0.1340103582176464}
2022-12-31 09:24:04,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:04,145 INFO:     Epoch: 57
2022-12-31 09:24:05,776 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44981231167912483, 'Total loss': 0.44981231167912483} | train loss {'Reaction outcome loss': 0.1309594883102695, 'Total loss': 0.1309594883102695}
2022-12-31 09:24:05,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:05,777 INFO:     Epoch: 58
2022-12-31 09:24:07,407 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4450351496537526, 'Total loss': 0.4450351496537526} | train loss {'Reaction outcome loss': 0.13156984502025998, 'Total loss': 0.13156984502025998}
2022-12-31 09:24:07,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:07,408 INFO:     Epoch: 59
2022-12-31 09:24:09,038 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45551223357518517, 'Total loss': 0.45551223357518517} | train loss {'Reaction outcome loss': 0.13217370427257316, 'Total loss': 0.13217370427257316}
2022-12-31 09:24:09,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:09,039 INFO:     Epoch: 60
2022-12-31 09:24:10,658 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44176809787750243, 'Total loss': 0.44176809787750243} | train loss {'Reaction outcome loss': 0.13198477803773181, 'Total loss': 0.13198477803773181}
2022-12-31 09:24:10,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:10,659 INFO:     Epoch: 61
2022-12-31 09:24:12,294 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4331224411725998, 'Total loss': 0.4331224411725998} | train loss {'Reaction outcome loss': 0.13226868065968425, 'Total loss': 0.13226868065968425}
2022-12-31 09:24:12,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:12,294 INFO:     Epoch: 62
2022-12-31 09:24:13,911 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43794613778591157, 'Total loss': 0.43794613778591157} | train loss {'Reaction outcome loss': 0.1314202578610569, 'Total loss': 0.1314202578610569}
2022-12-31 09:24:13,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:13,911 INFO:     Epoch: 63
2022-12-31 09:24:15,577 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4489343285560608, 'Total loss': 0.4489343285560608} | train loss {'Reaction outcome loss': 0.13328001485962676, 'Total loss': 0.13328001485962676}
2022-12-31 09:24:15,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:15,577 INFO:     Epoch: 64
2022-12-31 09:24:17,190 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4328944593667984, 'Total loss': 0.4328944593667984} | train loss {'Reaction outcome loss': 0.13099134816293898, 'Total loss': 0.13099134816293898}
2022-12-31 09:24:17,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:17,190 INFO:     Epoch: 65
2022-12-31 09:24:18,857 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45775722364584603, 'Total loss': 0.45775722364584603} | train loss {'Reaction outcome loss': 0.1344942736039308, 'Total loss': 0.1344942736039308}
2022-12-31 09:24:18,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:18,857 INFO:     Epoch: 66
2022-12-31 09:24:20,508 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43405510584513346, 'Total loss': 0.43405510584513346} | train loss {'Reaction outcome loss': 0.1263744271098088, 'Total loss': 0.1263744271098088}
2022-12-31 09:24:20,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:20,509 INFO:     Epoch: 67
2022-12-31 09:24:22,158 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42238640288511914, 'Total loss': 0.42238640288511914} | train loss {'Reaction outcome loss': 0.1284094035343035, 'Total loss': 0.1284094035343035}
2022-12-31 09:24:22,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:22,159 INFO:     Epoch: 68
2022-12-31 09:24:23,780 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49306569894154867, 'Total loss': 0.49306569894154867} | train loss {'Reaction outcome loss': 0.133894279814369, 'Total loss': 0.133894279814369}
2022-12-31 09:24:23,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:23,780 INFO:     Epoch: 69
2022-12-31 09:24:25,449 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46137346426645914, 'Total loss': 0.46137346426645914} | train loss {'Reaction outcome loss': 0.12833981512497694, 'Total loss': 0.12833981512497694}
2022-12-31 09:24:25,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:25,450 INFO:     Epoch: 70
2022-12-31 09:24:27,074 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4587120237449805, 'Total loss': 0.4587120237449805} | train loss {'Reaction outcome loss': 0.12401961893287054, 'Total loss': 0.12401961893287054}
2022-12-31 09:24:27,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:27,075 INFO:     Epoch: 71
2022-12-31 09:24:28,734 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4184331389764945, 'Total loss': 0.4184331389764945} | train loss {'Reaction outcome loss': 0.12313556832863212, 'Total loss': 0.12313556832863212}
2022-12-31 09:24:28,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:28,734 INFO:     Epoch: 72
2022-12-31 09:24:30,359 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44049789806207024, 'Total loss': 0.44049789806207024} | train loss {'Reaction outcome loss': 0.12516567258951036, 'Total loss': 0.12516567258951036}
2022-12-31 09:24:30,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:30,360 INFO:     Epoch: 73
2022-12-31 09:24:31,993 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4853746066490809, 'Total loss': 0.4853746066490809} | train loss {'Reaction outcome loss': 0.1269482501516865, 'Total loss': 0.1269482501516865}
2022-12-31 09:24:31,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:31,994 INFO:     Epoch: 74
2022-12-31 09:24:33,617 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4704392820596695, 'Total loss': 0.4704392820596695} | train loss {'Reaction outcome loss': 0.12608863578416704, 'Total loss': 0.12608863578416704}
2022-12-31 09:24:33,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:33,617 INFO:     Epoch: 75
2022-12-31 09:24:35,293 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4590754186113675, 'Total loss': 0.4590754186113675} | train loss {'Reaction outcome loss': 0.12339227817387788, 'Total loss': 0.12339227817387788}
2022-12-31 09:24:35,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:35,293 INFO:     Epoch: 76
2022-12-31 09:24:36,918 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4327985346317291, 'Total loss': 0.4327985346317291} | train loss {'Reaction outcome loss': 0.12245127284186573, 'Total loss': 0.12245127284186573}
2022-12-31 09:24:36,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:36,918 INFO:     Epoch: 77
2022-12-31 09:24:38,543 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44877162675062815, 'Total loss': 0.44877162675062815} | train loss {'Reaction outcome loss': 0.12268667919174617, 'Total loss': 0.12268667919174617}
2022-12-31 09:24:38,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:38,544 INFO:     Epoch: 78
2022-12-31 09:24:39,846 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45247713041802246, 'Total loss': 0.45247713041802246} | train loss {'Reaction outcome loss': 0.12492235590424725, 'Total loss': 0.12492235590424725}
2022-12-31 09:24:39,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:39,846 INFO:     Epoch: 79
2022-12-31 09:24:40,977 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4479382514953613, 'Total loss': 0.4479382514953613} | train loss {'Reaction outcome loss': 0.12459662778888046, 'Total loss': 0.12459662778888046}
2022-12-31 09:24:40,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:40,977 INFO:     Epoch: 80
2022-12-31 09:24:42,117 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46133946379025775, 'Total loss': 0.46133946379025775} | train loss {'Reaction outcome loss': 0.11963941276473555, 'Total loss': 0.11963941276473555}
2022-12-31 09:24:42,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:42,117 INFO:     Epoch: 81
2022-12-31 09:24:43,257 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48593137562274935, 'Total loss': 0.48593137562274935} | train loss {'Reaction outcome loss': 0.11835313088425338, 'Total loss': 0.11835313088425338}
2022-12-31 09:24:43,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:43,257 INFO:     Epoch: 82
2022-12-31 09:24:44,713 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4413945702215036, 'Total loss': 0.4413945702215036} | train loss {'Reaction outcome loss': 0.11975679369744195, 'Total loss': 0.11975679369744195}
2022-12-31 09:24:44,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:44,714 INFO:     Epoch: 83
2022-12-31 09:24:46,365 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4176765198508898, 'Total loss': 0.4176765198508898} | train loss {'Reaction outcome loss': 0.12256687906123563, 'Total loss': 0.12256687906123563}
2022-12-31 09:24:46,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:46,365 INFO:     Epoch: 84
2022-12-31 09:24:47,991 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46196990509827934, 'Total loss': 0.46196990509827934} | train loss {'Reaction outcome loss': 0.12239682006007498, 'Total loss': 0.12239682006007498}
2022-12-31 09:24:47,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:47,991 INFO:     Epoch: 85
2022-12-31 09:24:49,619 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4552880384027958, 'Total loss': 0.4552880384027958} | train loss {'Reaction outcome loss': 0.11940691846301812, 'Total loss': 0.11940691846301812}
2022-12-31 09:24:49,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:49,619 INFO:     Epoch: 86
2022-12-31 09:24:51,245 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4694582442442576, 'Total loss': 0.4694582442442576} | train loss {'Reaction outcome loss': 0.11713246248380049, 'Total loss': 0.11713246248380049}
2022-12-31 09:24:51,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:51,246 INFO:     Epoch: 87
2022-12-31 09:24:52,868 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4674505710601807, 'Total loss': 0.4674505710601807} | train loss {'Reaction outcome loss': 0.11810855713205594, 'Total loss': 0.11810855713205594}
2022-12-31 09:24:52,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:52,868 INFO:     Epoch: 88
2022-12-31 09:24:54,483 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47176492810249326, 'Total loss': 0.47176492810249326} | train loss {'Reaction outcome loss': 0.12159935362378156, 'Total loss': 0.12159935362378156}
2022-12-31 09:24:54,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:54,483 INFO:     Epoch: 89
2022-12-31 09:24:56,114 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43546941205859185, 'Total loss': 0.43546941205859185} | train loss {'Reaction outcome loss': 0.12680134062893986, 'Total loss': 0.12680134062893986}
2022-12-31 09:24:56,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:56,114 INFO:     Epoch: 90
2022-12-31 09:24:57,743 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.466561288634936, 'Total loss': 0.466561288634936} | train loss {'Reaction outcome loss': 0.1237146158598444, 'Total loss': 0.1237146158598444}
2022-12-31 09:24:57,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:57,744 INFO:     Epoch: 91
2022-12-31 09:24:59,375 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46280690232912697, 'Total loss': 0.46280690232912697} | train loss {'Reaction outcome loss': 0.12069189594554235, 'Total loss': 0.12069189594554235}
2022-12-31 09:24:59,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:24:59,375 INFO:     Epoch: 92
2022-12-31 09:25:01,006 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45356319348017377, 'Total loss': 0.45356319348017377} | train loss {'Reaction outcome loss': 0.11424216987491193, 'Total loss': 0.11424216987491193}
2022-12-31 09:25:01,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:01,007 INFO:     Epoch: 93
2022-12-31 09:25:02,647 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43367234120766324, 'Total loss': 0.43367234120766324} | train loss {'Reaction outcome loss': 0.11603174528480248, 'Total loss': 0.11603174528480248}
2022-12-31 09:25:02,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:02,648 INFO:     Epoch: 94
2022-12-31 09:25:04,272 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4716026435295741, 'Total loss': 0.4716026435295741} | train loss {'Reaction outcome loss': 0.11635693902694469, 'Total loss': 0.11635693902694469}
2022-12-31 09:25:04,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:04,273 INFO:     Epoch: 95
2022-12-31 09:25:05,939 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.495231102903684, 'Total loss': 0.495231102903684} | train loss {'Reaction outcome loss': 0.11788349912169016, 'Total loss': 0.11788349912169016}
2022-12-31 09:25:05,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:05,939 INFO:     Epoch: 96
2022-12-31 09:25:07,575 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.466336128115654, 'Total loss': 0.466336128115654} | train loss {'Reaction outcome loss': 0.11740817089938299, 'Total loss': 0.11740817089938299}
2022-12-31 09:25:07,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:07,576 INFO:     Epoch: 97
2022-12-31 09:25:09,243 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45324360330899555, 'Total loss': 0.45324360330899555} | train loss {'Reaction outcome loss': 0.11546602147540569, 'Total loss': 0.11546602147540569}
2022-12-31 09:25:09,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:09,244 INFO:     Epoch: 98
2022-12-31 09:25:10,868 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.463138351837794, 'Total loss': 0.463138351837794} | train loss {'Reaction outcome loss': 0.11731989355925941, 'Total loss': 0.11731989355925941}
2022-12-31 09:25:10,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:10,868 INFO:     Epoch: 99
2022-12-31 09:25:12,483 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4549576034148534, 'Total loss': 0.4549576034148534} | train loss {'Reaction outcome loss': 0.116617397210201, 'Total loss': 0.116617397210201}
2022-12-31 09:25:12,483 INFO:     Best model found after epoch 48 of 100.
2022-12-31 09:25:12,483 INFO:   Done with stage: TRAINING
2022-12-31 09:25:12,483 INFO:   Starting stage: EVALUATION
2022-12-31 09:25:12,609 INFO:   Done with stage: EVALUATION
2022-12-31 09:25:12,609 INFO:   Leaving out SEQ value Fold_8
2022-12-31 09:25:12,622 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 09:25:12,622 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:25:13,259 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:25:13,259 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:25:13,325 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:25:13,325 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:25:13,325 INFO:     No hyperparam tuning for this model
2022-12-31 09:25:13,325 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:25:13,325 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:25:13,326 INFO:     None feature selector for col prot
2022-12-31 09:25:13,326 INFO:     None feature selector for col prot
2022-12-31 09:25:13,326 INFO:     None feature selector for col prot
2022-12-31 09:25:13,327 INFO:     None feature selector for col chem
2022-12-31 09:25:13,327 INFO:     None feature selector for col chem
2022-12-31 09:25:13,327 INFO:     None feature selector for col chem
2022-12-31 09:25:13,327 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:25:13,327 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:25:13,329 INFO:     Number of params in model 224011
2022-12-31 09:25:13,332 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:25:13,332 INFO:   Starting stage: TRAINING
2022-12-31 09:25:13,379 INFO:     Val loss before train {'Reaction outcome loss': 0.9406624436378479, 'Total loss': 0.9406624436378479}
2022-12-31 09:25:13,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:13,379 INFO:     Epoch: 0
2022-12-31 09:25:14,992 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5246129930019379, 'Total loss': 0.5246129930019379} | train loss {'Reaction outcome loss': 0.7738558923023461, 'Total loss': 0.7738558923023461}
2022-12-31 09:25:14,992 INFO:     Found new best model at epoch 0
2022-12-31 09:25:14,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:14,993 INFO:     Epoch: 1
2022-12-31 09:25:16,604 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4722195585568746, 'Total loss': 0.4722195585568746} | train loss {'Reaction outcome loss': 0.5076969861440415, 'Total loss': 0.5076969861440415}
2022-12-31 09:25:16,604 INFO:     Found new best model at epoch 1
2022-12-31 09:25:16,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:16,605 INFO:     Epoch: 2
2022-12-31 09:25:18,217 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4165403574705124, 'Total loss': 0.4165403574705124} | train loss {'Reaction outcome loss': 0.43740508112594156, 'Total loss': 0.43740508112594156}
2022-12-31 09:25:18,217 INFO:     Found new best model at epoch 2
2022-12-31 09:25:18,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:18,218 INFO:     Epoch: 3
2022-12-31 09:25:19,827 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.41057827373345696, 'Total loss': 0.41057827373345696} | train loss {'Reaction outcome loss': 0.3978058430400208, 'Total loss': 0.3978058430400208}
2022-12-31 09:25:19,827 INFO:     Found new best model at epoch 3
2022-12-31 09:25:19,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:19,828 INFO:     Epoch: 4
2022-12-31 09:25:21,432 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4060593624909719, 'Total loss': 0.4060593624909719} | train loss {'Reaction outcome loss': 0.36489585347908693, 'Total loss': 0.36489585347908693}
2022-12-31 09:25:21,432 INFO:     Found new best model at epoch 4
2022-12-31 09:25:21,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:21,433 INFO:     Epoch: 5
2022-12-31 09:25:23,037 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39771843552589414, 'Total loss': 0.39771843552589414} | train loss {'Reaction outcome loss': 0.34345971235502376, 'Total loss': 0.34345971235502376}
2022-12-31 09:25:23,037 INFO:     Found new best model at epoch 5
2022-12-31 09:25:23,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:23,038 INFO:     Epoch: 6
2022-12-31 09:25:24,638 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4156188786029816, 'Total loss': 0.4156188786029816} | train loss {'Reaction outcome loss': 0.324296821955673, 'Total loss': 0.324296821955673}
2022-12-31 09:25:24,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:24,638 INFO:     Epoch: 7
2022-12-31 09:25:26,287 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3816508695483208, 'Total loss': 0.3816508695483208} | train loss {'Reaction outcome loss': 0.3036520834876238, 'Total loss': 0.3036520834876238}
2022-12-31 09:25:26,287 INFO:     Found new best model at epoch 7
2022-12-31 09:25:26,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:26,288 INFO:     Epoch: 8
2022-12-31 09:25:27,887 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4059232215086619, 'Total loss': 0.4059232215086619} | train loss {'Reaction outcome loss': 0.2893501084678582, 'Total loss': 0.2893501084678582}
2022-12-31 09:25:27,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:27,887 INFO:     Epoch: 9
2022-12-31 09:25:29,525 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39877450168132783, 'Total loss': 0.39877450168132783} | train loss {'Reaction outcome loss': 0.2766854270857616, 'Total loss': 0.2766854270857616}
2022-12-31 09:25:29,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:29,526 INFO:     Epoch: 10
2022-12-31 09:25:31,136 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39652882317701976, 'Total loss': 0.39652882317701976} | train loss {'Reaction outcome loss': 0.2632156390914299, 'Total loss': 0.2632156390914299}
2022-12-31 09:25:31,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:31,137 INFO:     Epoch: 11
2022-12-31 09:25:32,735 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.375297815601031, 'Total loss': 0.375297815601031} | train loss {'Reaction outcome loss': 0.24869291348396427, 'Total loss': 0.24869291348396427}
2022-12-31 09:25:32,735 INFO:     Found new best model at epoch 11
2022-12-31 09:25:32,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:32,736 INFO:     Epoch: 12
2022-12-31 09:25:34,335 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37828447471062343, 'Total loss': 0.37828447471062343} | train loss {'Reaction outcome loss': 0.23856516538636527, 'Total loss': 0.23856516538636527}
2022-12-31 09:25:34,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:34,335 INFO:     Epoch: 13
2022-12-31 09:25:36,008 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39697711567083993, 'Total loss': 0.39697711567083993} | train loss {'Reaction outcome loss': 0.2323158070390677, 'Total loss': 0.2323158070390677}
2022-12-31 09:25:36,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:36,008 INFO:     Epoch: 14
2022-12-31 09:25:37,614 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3690044956902663, 'Total loss': 0.3690044956902663} | train loss {'Reaction outcome loss': 0.22411283854748645, 'Total loss': 0.22411283854748645}
2022-12-31 09:25:37,615 INFO:     Found new best model at epoch 14
2022-12-31 09:25:37,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:37,616 INFO:     Epoch: 15
2022-12-31 09:25:39,220 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.377572076022625, 'Total loss': 0.377572076022625} | train loss {'Reaction outcome loss': 0.21241768465860048, 'Total loss': 0.21241768465860048}
2022-12-31 09:25:39,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:39,221 INFO:     Epoch: 16
2022-12-31 09:25:40,861 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3850172956784566, 'Total loss': 0.3850172956784566} | train loss {'Reaction outcome loss': 0.2072935159025836, 'Total loss': 0.2072935159025836}
2022-12-31 09:25:40,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:40,862 INFO:     Epoch: 17
2022-12-31 09:25:42,472 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38787277589241664, 'Total loss': 0.38787277589241664} | train loss {'Reaction outcome loss': 0.1995264848517458, 'Total loss': 0.1995264848517458}
2022-12-31 09:25:42,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:42,472 INFO:     Epoch: 18
2022-12-31 09:25:44,082 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.37811509271462757, 'Total loss': 0.37811509271462757} | train loss {'Reaction outcome loss': 0.19351992142271168, 'Total loss': 0.19351992142271168}
2022-12-31 09:25:44,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:44,083 INFO:     Epoch: 19
2022-12-31 09:25:45,693 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.374017987648646, 'Total loss': 0.374017987648646} | train loss {'Reaction outcome loss': 0.18955852987285512, 'Total loss': 0.18955852987285512}
2022-12-31 09:25:45,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:45,693 INFO:     Epoch: 20
2022-12-31 09:25:47,297 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3674921810626984, 'Total loss': 0.3674921810626984} | train loss {'Reaction outcome loss': 0.18300960516135623, 'Total loss': 0.18300960516135623}
2022-12-31 09:25:47,297 INFO:     Found new best model at epoch 20
2022-12-31 09:25:47,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:47,298 INFO:     Epoch: 21
2022-12-31 09:25:48,897 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3876072625319163, 'Total loss': 0.3876072625319163} | train loss {'Reaction outcome loss': 0.180703442278624, 'Total loss': 0.180703442278624}
2022-12-31 09:25:48,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:48,897 INFO:     Epoch: 22
2022-12-31 09:25:50,505 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38459368447462716, 'Total loss': 0.38459368447462716} | train loss {'Reaction outcome loss': 0.17580297587942467, 'Total loss': 0.17580297587942467}
2022-12-31 09:25:50,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:50,506 INFO:     Epoch: 23
2022-12-31 09:25:52,114 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3865225791931152, 'Total loss': 0.3865225791931152} | train loss {'Reaction outcome loss': 0.16961212756696845, 'Total loss': 0.16961212756696845}
2022-12-31 09:25:52,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:52,114 INFO:     Epoch: 24
2022-12-31 09:25:53,722 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3881535549958547, 'Total loss': 0.3881535549958547} | train loss {'Reaction outcome loss': 0.16591053120248075, 'Total loss': 0.16591053120248075}
2022-12-31 09:25:53,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:53,723 INFO:     Epoch: 25
2022-12-31 09:25:55,332 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38769937455654147, 'Total loss': 0.38769937455654147} | train loss {'Reaction outcome loss': 0.16222940191599358, 'Total loss': 0.16222940191599358}
2022-12-31 09:25:55,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:55,332 INFO:     Epoch: 26
2022-12-31 09:25:56,933 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39296446641286215, 'Total loss': 0.39296446641286215} | train loss {'Reaction outcome loss': 0.16112004543049602, 'Total loss': 0.16112004543049602}
2022-12-31 09:25:56,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:56,933 INFO:     Epoch: 27
2022-12-31 09:25:58,532 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4024207691351573, 'Total loss': 0.4024207691351573} | train loss {'Reaction outcome loss': 0.161021676458364, 'Total loss': 0.161021676458364}
2022-12-31 09:25:58,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:25:58,532 INFO:     Epoch: 28
2022-12-31 09:26:00,181 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.375700909892718, 'Total loss': 0.375700909892718} | train loss {'Reaction outcome loss': 0.15401568816784417, 'Total loss': 0.15401568816784417}
2022-12-31 09:26:00,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:00,182 INFO:     Epoch: 29
2022-12-31 09:26:01,796 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3618071366722385, 'Total loss': 0.3618071366722385} | train loss {'Reaction outcome loss': 0.154022631160643, 'Total loss': 0.154022631160643}
2022-12-31 09:26:01,796 INFO:     Found new best model at epoch 29
2022-12-31 09:26:01,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:01,798 INFO:     Epoch: 30
2022-12-31 09:26:03,406 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3753750413656235, 'Total loss': 0.3753750413656235} | train loss {'Reaction outcome loss': 0.14968778976123698, 'Total loss': 0.14968778976123698}
2022-12-31 09:26:03,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:03,407 INFO:     Epoch: 31
2022-12-31 09:26:05,014 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3962584267059962, 'Total loss': 0.3962584267059962} | train loss {'Reaction outcome loss': 0.1494254911433987, 'Total loss': 0.1494254911433987}
2022-12-31 09:26:05,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:05,014 INFO:     Epoch: 32
2022-12-31 09:26:06,678 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3764122347036997, 'Total loss': 0.3764122347036997} | train loss {'Reaction outcome loss': 0.1489054963815223, 'Total loss': 0.1489054963815223}
2022-12-31 09:26:06,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:06,678 INFO:     Epoch: 33
2022-12-31 09:26:08,328 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39760926564534504, 'Total loss': 0.39760926564534504} | train loss {'Reaction outcome loss': 0.14261113610254586, 'Total loss': 0.14261113610254586}
2022-12-31 09:26:08,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:08,329 INFO:     Epoch: 34
2022-12-31 09:26:09,933 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41453509628772733, 'Total loss': 0.41453509628772733} | train loss {'Reaction outcome loss': 0.13764270048003888, 'Total loss': 0.13764270048003888}
2022-12-31 09:26:09,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:09,934 INFO:     Epoch: 35
2022-12-31 09:26:11,581 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39167170226573944, 'Total loss': 0.39167170226573944} | train loss {'Reaction outcome loss': 0.143624136788621, 'Total loss': 0.143624136788621}
2022-12-31 09:26:11,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:11,581 INFO:     Epoch: 36
2022-12-31 09:26:13,191 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3993695954481761, 'Total loss': 0.3993695954481761} | train loss {'Reaction outcome loss': 0.13876226952598586, 'Total loss': 0.13876226952598586}
2022-12-31 09:26:13,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:13,191 INFO:     Epoch: 37
2022-12-31 09:26:14,798 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4032772560914358, 'Total loss': 0.4032772560914358} | train loss {'Reaction outcome loss': 0.13931470935701998, 'Total loss': 0.13931470935701998}
2022-12-31 09:26:14,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:14,798 INFO:     Epoch: 38
2022-12-31 09:26:16,401 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4047750860452652, 'Total loss': 0.4047750860452652} | train loss {'Reaction outcome loss': 0.13365406975197694, 'Total loss': 0.13365406975197694}
2022-12-31 09:26:16,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:16,401 INFO:     Epoch: 39
2022-12-31 09:26:18,010 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39224834740161896, 'Total loss': 0.39224834740161896} | train loss {'Reaction outcome loss': 0.1368241011790496, 'Total loss': 0.1368241011790496}
2022-12-31 09:26:18,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:18,010 INFO:     Epoch: 40
2022-12-31 09:26:19,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.407586004336675, 'Total loss': 0.407586004336675} | train loss {'Reaction outcome loss': 0.13413911802782574, 'Total loss': 0.13413911802782574}
2022-12-31 09:26:19,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:19,612 INFO:     Epoch: 41
2022-12-31 09:26:21,211 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39747176071008045, 'Total loss': 0.39747176071008045} | train loss {'Reaction outcome loss': 0.12914936689075326, 'Total loss': 0.12914936689075326}
2022-12-31 09:26:21,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:21,211 INFO:     Epoch: 42
2022-12-31 09:26:22,811 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3989174688855807, 'Total loss': 0.3989174688855807} | train loss {'Reaction outcome loss': 0.1279111172745589, 'Total loss': 0.1279111172745589}
2022-12-31 09:26:22,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:22,812 INFO:     Epoch: 43
2022-12-31 09:26:24,416 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40704411069552104, 'Total loss': 0.40704411069552104} | train loss {'Reaction outcome loss': 0.13236594364305374, 'Total loss': 0.13236594364305374}
2022-12-31 09:26:24,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:24,416 INFO:     Epoch: 44
2022-12-31 09:26:26,027 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43498660375674564, 'Total loss': 0.43498660375674564} | train loss {'Reaction outcome loss': 0.13159568599989488, 'Total loss': 0.13159568599989488}
2022-12-31 09:26:26,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:26,027 INFO:     Epoch: 45
2022-12-31 09:26:27,629 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40598917603492735, 'Total loss': 0.40598917603492735} | train loss {'Reaction outcome loss': 0.1302693338901566, 'Total loss': 0.1302693338901566}
2022-12-31 09:26:27,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:27,630 INFO:     Epoch: 46
2022-12-31 09:26:29,239 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41488511065642036, 'Total loss': 0.41488511065642036} | train loss {'Reaction outcome loss': 0.1249601880537115, 'Total loss': 0.1249601880537115}
2022-12-31 09:26:29,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:29,239 INFO:     Epoch: 47
2022-12-31 09:26:30,841 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4027653342733781, 'Total loss': 0.4027653342733781} | train loss {'Reaction outcome loss': 0.12332724643374936, 'Total loss': 0.12332724643374936}
2022-12-31 09:26:30,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:30,842 INFO:     Epoch: 48
2022-12-31 09:26:32,449 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40030764242013295, 'Total loss': 0.40030764242013295} | train loss {'Reaction outcome loss': 0.12501023867826935, 'Total loss': 0.12501023867826935}
2022-12-31 09:26:32,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:32,449 INFO:     Epoch: 49
2022-12-31 09:26:34,058 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40592093964417775, 'Total loss': 0.40592093964417775} | train loss {'Reaction outcome loss': 0.12101648567774653, 'Total loss': 0.12101648567774653}
2022-12-31 09:26:34,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:34,058 INFO:     Epoch: 50
2022-12-31 09:26:35,662 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4011647793173324, 'Total loss': 0.4011647793173324} | train loss {'Reaction outcome loss': 0.12297975627474324, 'Total loss': 0.12297975627474324}
2022-12-31 09:26:35,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:35,662 INFO:     Epoch: 51
2022-12-31 09:26:37,317 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40460727413495384, 'Total loss': 0.40460727413495384} | train loss {'Reaction outcome loss': 0.12328897220300117, 'Total loss': 0.12328897220300117}
2022-12-31 09:26:37,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:37,317 INFO:     Epoch: 52
2022-12-31 09:26:38,969 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4063376079003016, 'Total loss': 0.4063376079003016} | train loss {'Reaction outcome loss': 0.12054085489498438, 'Total loss': 0.12054085489498438}
2022-12-31 09:26:38,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:38,971 INFO:     Epoch: 53
2022-12-31 09:26:40,576 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3960819939772288, 'Total loss': 0.3960819939772288} | train loss {'Reaction outcome loss': 0.12074442675174044, 'Total loss': 0.12074442675174044}
2022-12-31 09:26:40,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:40,576 INFO:     Epoch: 54
2022-12-31 09:26:42,218 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3987546607851982, 'Total loss': 0.3987546607851982} | train loss {'Reaction outcome loss': 0.11916078279223156, 'Total loss': 0.11916078279223156}
2022-12-31 09:26:42,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:42,219 INFO:     Epoch: 55
2022-12-31 09:26:43,829 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3960964173078537, 'Total loss': 0.3960964173078537} | train loss {'Reaction outcome loss': 0.12380595134577993, 'Total loss': 0.12380595134577993}
2022-12-31 09:26:43,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:43,829 INFO:     Epoch: 56
2022-12-31 09:26:45,466 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4163644740978877, 'Total loss': 0.4163644740978877} | train loss {'Reaction outcome loss': 0.11744167417437382, 'Total loss': 0.11744167417437382}
2022-12-31 09:26:45,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:45,467 INFO:     Epoch: 57
2022-12-31 09:26:47,071 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4133151277899742, 'Total loss': 0.4133151277899742} | train loss {'Reaction outcome loss': 0.11651404233934888, 'Total loss': 0.11651404233934888}
2022-12-31 09:26:47,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:47,071 INFO:     Epoch: 58
2022-12-31 09:26:48,723 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4146709640820821, 'Total loss': 0.4146709640820821} | train loss {'Reaction outcome loss': 0.11716546597006819, 'Total loss': 0.11716546597006819}
2022-12-31 09:26:48,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:48,723 INFO:     Epoch: 59
2022-12-31 09:26:50,375 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4169053892294566, 'Total loss': 0.4169053892294566} | train loss {'Reaction outcome loss': 0.1133292136819231, 'Total loss': 0.1133292136819231}
2022-12-31 09:26:50,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:50,375 INFO:     Epoch: 60
2022-12-31 09:26:51,971 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40162434776624045, 'Total loss': 0.40162434776624045} | train loss {'Reaction outcome loss': 0.11564686987719015, 'Total loss': 0.11564686987719015}
2022-12-31 09:26:51,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:51,971 INFO:     Epoch: 61
2022-12-31 09:26:53,587 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4170318506658077, 'Total loss': 0.4170318506658077} | train loss {'Reaction outcome loss': 0.11601195316829711, 'Total loss': 0.11601195316829711}
2022-12-31 09:26:53,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:53,587 INFO:     Epoch: 62
2022-12-31 09:26:55,204 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4029534061749776, 'Total loss': 0.4029534061749776} | train loss {'Reaction outcome loss': 0.11521766679429442, 'Total loss': 0.11521766679429442}
2022-12-31 09:26:55,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:55,205 INFO:     Epoch: 63
2022-12-31 09:26:56,822 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42816851039727527, 'Total loss': 0.42816851039727527} | train loss {'Reaction outcome loss': 0.1108862789837222, 'Total loss': 0.1108862789837222}
2022-12-31 09:26:56,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:56,822 INFO:     Epoch: 64
2022-12-31 09:26:58,441 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39052929878234866, 'Total loss': 0.39052929878234866} | train loss {'Reaction outcome loss': 0.11234608782713648, 'Total loss': 0.11234608782713648}
2022-12-31 09:26:58,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:26:58,442 INFO:     Epoch: 65
2022-12-31 09:27:00,056 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3987838953733444, 'Total loss': 0.3987838953733444} | train loss {'Reaction outcome loss': 0.11160660544189414, 'Total loss': 0.11160660544189414}
2022-12-31 09:27:00,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:00,056 INFO:     Epoch: 66
2022-12-31 09:27:01,656 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3637197785079479, 'Total loss': 0.3637197785079479} | train loss {'Reaction outcome loss': 0.11257197927975905, 'Total loss': 0.11257197927975905}
2022-12-31 09:27:01,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:01,656 INFO:     Epoch: 67
2022-12-31 09:27:03,307 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39591998755931856, 'Total loss': 0.39591998755931856} | train loss {'Reaction outcome loss': 0.11028526408468665, 'Total loss': 0.11028526408468665}
2022-12-31 09:27:03,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:03,308 INFO:     Epoch: 68
2022-12-31 09:27:04,961 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4361571937799454, 'Total loss': 0.4361571937799454} | train loss {'Reaction outcome loss': 0.10940272377355255, 'Total loss': 0.10940272377355255}
2022-12-31 09:27:04,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:04,961 INFO:     Epoch: 69
2022-12-31 09:27:06,565 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41153438488642374, 'Total loss': 0.41153438488642374} | train loss {'Reaction outcome loss': 0.11253552343594386, 'Total loss': 0.11253552343594386}
2022-12-31 09:27:06,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:06,565 INFO:     Epoch: 70
2022-12-31 09:27:08,217 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3874532769123713, 'Total loss': 0.3874532769123713} | train loss {'Reaction outcome loss': 0.11304517443050514, 'Total loss': 0.11304517443050514}
2022-12-31 09:27:08,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:08,217 INFO:     Epoch: 71
2022-12-31 09:27:09,832 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4308323472738266, 'Total loss': 0.4308323472738266} | train loss {'Reaction outcome loss': 0.11123800858936823, 'Total loss': 0.11123800858936823}
2022-12-31 09:27:09,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:09,833 INFO:     Epoch: 72
2022-12-31 09:27:11,438 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4042782876640558, 'Total loss': 0.4042782876640558} | train loss {'Reaction outcome loss': 0.10897474413581301, 'Total loss': 0.10897474413581301}
2022-12-31 09:27:11,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:11,438 INFO:     Epoch: 73
2022-12-31 09:27:13,041 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41521614889303843, 'Total loss': 0.41521614889303843} | train loss {'Reaction outcome loss': 0.1040120543096296, 'Total loss': 0.1040120543096296}
2022-12-31 09:27:13,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:13,041 INFO:     Epoch: 74
2022-12-31 09:27:14,693 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42536812225977577, 'Total loss': 0.42536812225977577} | train loss {'Reaction outcome loss': 0.10576025301243865, 'Total loss': 0.10576025301243865}
2022-12-31 09:27:14,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:14,693 INFO:     Epoch: 75
2022-12-31 09:27:16,345 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40034567068020505, 'Total loss': 0.40034567068020505} | train loss {'Reaction outcome loss': 0.10590516325055764, 'Total loss': 0.10590516325055764}
2022-12-31 09:27:16,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:16,346 INFO:     Epoch: 76
2022-12-31 09:27:17,950 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4071184535821279, 'Total loss': 0.4071184535821279} | train loss {'Reaction outcome loss': 0.1089464831539858, 'Total loss': 0.1089464831539858}
2022-12-31 09:27:17,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:17,950 INFO:     Epoch: 77
2022-12-31 09:27:19,567 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.388262592915756, 'Total loss': 0.388262592915756} | train loss {'Reaction outcome loss': 0.10322036277706714, 'Total loss': 0.10322036277706714}
2022-12-31 09:27:19,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:19,567 INFO:     Epoch: 78
2022-12-31 09:27:21,176 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3973180810610453, 'Total loss': 0.3973180810610453} | train loss {'Reaction outcome loss': 0.10796560328555749, 'Total loss': 0.10796560328555749}
2022-12-31 09:27:21,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:21,177 INFO:     Epoch: 79
2022-12-31 09:27:22,794 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41047772814830147, 'Total loss': 0.41047772814830147} | train loss {'Reaction outcome loss': 0.11110661911479042, 'Total loss': 0.11110661911479042}
2022-12-31 09:27:22,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:22,794 INFO:     Epoch: 80
2022-12-31 09:27:24,411 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41220609545707704, 'Total loss': 0.41220609545707704} | train loss {'Reaction outcome loss': 0.10564012867976388, 'Total loss': 0.10564012867976388}
2022-12-31 09:27:24,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:24,411 INFO:     Epoch: 81
2022-12-31 09:27:26,023 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4106480489174525, 'Total loss': 0.4106480489174525} | train loss {'Reaction outcome loss': 0.10368729599268876, 'Total loss': 0.10368729599268876}
2022-12-31 09:27:26,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:26,023 INFO:     Epoch: 82
2022-12-31 09:27:27,633 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4074588974316915, 'Total loss': 0.4074588974316915} | train loss {'Reaction outcome loss': 0.10413691447707858, 'Total loss': 0.10413691447707858}
2022-12-31 09:27:27,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:27,633 INFO:     Epoch: 83
2022-12-31 09:27:29,260 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4362662556270758, 'Total loss': 0.4362662556270758} | train loss {'Reaction outcome loss': 0.10361268890878852, 'Total loss': 0.10361268890878852}
2022-12-31 09:27:29,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:29,261 INFO:     Epoch: 84
2022-12-31 09:27:30,870 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38500087757905327, 'Total loss': 0.38500087757905327} | train loss {'Reaction outcome loss': 0.09980957871251978, 'Total loss': 0.09980957871251978}
2022-12-31 09:27:30,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:30,870 INFO:     Epoch: 85
2022-12-31 09:27:32,522 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40108795116345086, 'Total loss': 0.40108795116345086} | train loss {'Reaction outcome loss': 0.10083162129336601, 'Total loss': 0.10083162129336601}
2022-12-31 09:27:32,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:32,523 INFO:     Epoch: 86
2022-12-31 09:27:34,132 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4242786248524984, 'Total loss': 0.4242786248524984} | train loss {'Reaction outcome loss': 0.10308882655460305, 'Total loss': 0.10308882655460305}
2022-12-31 09:27:34,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:34,132 INFO:     Epoch: 87
2022-12-31 09:27:35,784 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4401529788970947, 'Total loss': 0.4401529788970947} | train loss {'Reaction outcome loss': 0.1087163985914204, 'Total loss': 0.1087163985914204}
2022-12-31 09:27:35,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:35,785 INFO:     Epoch: 88
2022-12-31 09:27:37,391 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4472607026497523, 'Total loss': 0.4472607026497523} | train loss {'Reaction outcome loss': 0.10872508388226784, 'Total loss': 0.10872508388226784}
2022-12-31 09:27:37,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:37,391 INFO:     Epoch: 89
2022-12-31 09:27:39,033 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43042200108369194, 'Total loss': 0.43042200108369194} | train loss {'Reaction outcome loss': 0.10392410064500206, 'Total loss': 0.10392410064500206}
2022-12-31 09:27:39,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:39,033 INFO:     Epoch: 90
2022-12-31 09:27:40,686 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3901765540242195, 'Total loss': 0.3901765540242195} | train loss {'Reaction outcome loss': 0.09928485731437911, 'Total loss': 0.09928485731437911}
2022-12-31 09:27:40,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:40,687 INFO:     Epoch: 91
2022-12-31 09:27:42,292 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4396573732296626, 'Total loss': 0.4396573732296626} | train loss {'Reaction outcome loss': 0.09810859763172258, 'Total loss': 0.09810859763172258}
2022-12-31 09:27:42,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:42,292 INFO:     Epoch: 92
2022-12-31 09:27:43,944 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40866248110930126, 'Total loss': 0.40866248110930126} | train loss {'Reaction outcome loss': 0.0989063843442331, 'Total loss': 0.0989063843442331}
2022-12-31 09:27:43,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:43,944 INFO:     Epoch: 93
2022-12-31 09:27:45,550 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3831501558423042, 'Total loss': 0.3831501558423042} | train loss {'Reaction outcome loss': 0.10356736533262216, 'Total loss': 0.10356736533262216}
2022-12-31 09:27:45,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:45,550 INFO:     Epoch: 94
2022-12-31 09:27:47,151 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44262358645598093, 'Total loss': 0.44262358645598093} | train loss {'Reaction outcome loss': 0.10125769558022764, 'Total loss': 0.10125769558022764}
2022-12-31 09:27:47,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:47,152 INFO:     Epoch: 95
2022-12-31 09:27:48,755 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4235004256169001, 'Total loss': 0.4235004256169001} | train loss {'Reaction outcome loss': 0.09998270024861597, 'Total loss': 0.09998270024861597}
2022-12-31 09:27:48,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:48,755 INFO:     Epoch: 96
2022-12-31 09:27:50,407 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42577288101116817, 'Total loss': 0.42577288101116817} | train loss {'Reaction outcome loss': 0.09969649912048485, 'Total loss': 0.09969649912048485}
2022-12-31 09:27:50,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:50,407 INFO:     Epoch: 97
2022-12-31 09:27:52,009 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42937203248341876, 'Total loss': 0.42937203248341876} | train loss {'Reaction outcome loss': 0.10011880604013203, 'Total loss': 0.10011880604013203}
2022-12-31 09:27:52,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:52,009 INFO:     Epoch: 98
2022-12-31 09:27:53,612 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4020447115103404, 'Total loss': 0.4020447115103404} | train loss {'Reaction outcome loss': 0.09853800222699116, 'Total loss': 0.09853800222699116}
2022-12-31 09:27:53,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:53,612 INFO:     Epoch: 99
2022-12-31 09:27:55,209 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4239715566237768, 'Total loss': 0.4239715566237768} | train loss {'Reaction outcome loss': 0.0976466451020381, 'Total loss': 0.0976466451020381}
2022-12-31 09:27:55,209 INFO:     Best model found after epoch 30 of 100.
2022-12-31 09:27:55,209 INFO:   Done with stage: TRAINING
2022-12-31 09:27:55,209 INFO:   Starting stage: EVALUATION
2022-12-31 09:27:55,348 INFO:   Done with stage: EVALUATION
2022-12-31 09:27:55,348 INFO:   Leaving out SEQ value Fold_9
2022-12-31 09:27:55,361 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 09:27:55,361 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:27:56,026 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:27:56,026 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:27:56,095 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:27:56,095 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:27:56,095 INFO:     No hyperparam tuning for this model
2022-12-31 09:27:56,095 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:27:56,095 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:27:56,096 INFO:     None feature selector for col prot
2022-12-31 09:27:56,096 INFO:     None feature selector for col prot
2022-12-31 09:27:56,096 INFO:     None feature selector for col prot
2022-12-31 09:27:56,096 INFO:     None feature selector for col chem
2022-12-31 09:27:56,096 INFO:     None feature selector for col chem
2022-12-31 09:27:56,096 INFO:     None feature selector for col chem
2022-12-31 09:27:56,097 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:27:56,097 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:27:56,098 INFO:     Number of params in model 224011
2022-12-31 09:27:56,102 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:27:56,102 INFO:   Starting stage: TRAINING
2022-12-31 09:27:56,147 INFO:     Val loss before train {'Reaction outcome loss': 0.8712728142738342, 'Total loss': 0.8712728142738342}
2022-12-31 09:27:56,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:56,147 INFO:     Epoch: 0
2022-12-31 09:27:57,766 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5575655361016592, 'Total loss': 0.5575655361016592} | train loss {'Reaction outcome loss': 0.7683855712628967, 'Total loss': 0.7683855712628967}
2022-12-31 09:27:57,766 INFO:     Found new best model at epoch 0
2022-12-31 09:27:57,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:57,767 INFO:     Epoch: 1
2022-12-31 09:27:59,386 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4459232449531555, 'Total loss': 0.4459232449531555} | train loss {'Reaction outcome loss': 0.5130460211193518, 'Total loss': 0.5130460211193518}
2022-12-31 09:27:59,387 INFO:     Found new best model at epoch 1
2022-12-31 09:27:59,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:27:59,388 INFO:     Epoch: 2
2022-12-31 09:28:01,007 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4184392362833023, 'Total loss': 0.4184392362833023} | train loss {'Reaction outcome loss': 0.45285594885637614, 'Total loss': 0.45285594885637614}
2022-12-31 09:28:01,007 INFO:     Found new best model at epoch 2
2022-12-31 09:28:01,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:01,008 INFO:     Epoch: 3
2022-12-31 09:28:02,620 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4196118632952372, 'Total loss': 0.4196118632952372} | train loss {'Reaction outcome loss': 0.41172628064340633, 'Total loss': 0.41172628064340633}
2022-12-31 09:28:02,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:02,621 INFO:     Epoch: 4
2022-12-31 09:28:04,234 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3871671795845032, 'Total loss': 0.3871671795845032} | train loss {'Reaction outcome loss': 0.38498633919747727, 'Total loss': 0.38498633919747727}
2022-12-31 09:28:04,234 INFO:     Found new best model at epoch 4
2022-12-31 09:28:04,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:04,235 INFO:     Epoch: 5
2022-12-31 09:28:05,852 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4104394793510437, 'Total loss': 0.4104394793510437} | train loss {'Reaction outcome loss': 0.36369393354396096, 'Total loss': 0.36369393354396096}
2022-12-31 09:28:05,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:05,852 INFO:     Epoch: 6
2022-12-31 09:28:07,521 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3812605698903402, 'Total loss': 0.3812605698903402} | train loss {'Reaction outcome loss': 0.3454173530320829, 'Total loss': 0.3454173530320829}
2022-12-31 09:28:07,521 INFO:     Found new best model at epoch 6
2022-12-31 09:28:07,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:07,523 INFO:     Epoch: 7
2022-12-31 09:28:09,146 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37682241400082905, 'Total loss': 0.37682241400082905} | train loss {'Reaction outcome loss': 0.32985810413687666, 'Total loss': 0.32985810413687666}
2022-12-31 09:28:09,146 INFO:     Found new best model at epoch 7
2022-12-31 09:28:09,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:09,148 INFO:     Epoch: 8
2022-12-31 09:28:10,771 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3975572953621546, 'Total loss': 0.3975572953621546} | train loss {'Reaction outcome loss': 0.31158313442976465, 'Total loss': 0.31158313442976465}
2022-12-31 09:28:10,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:10,773 INFO:     Epoch: 9
2022-12-31 09:28:12,398 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37916702826817833, 'Total loss': 0.37916702826817833} | train loss {'Reaction outcome loss': 0.2994402857894071, 'Total loss': 0.2994402857894071}
2022-12-31 09:28:12,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:12,398 INFO:     Epoch: 10
2022-12-31 09:28:14,022 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4129178022344907, 'Total loss': 0.4129178022344907} | train loss {'Reaction outcome loss': 0.28407343620911835, 'Total loss': 0.28407343620911835}
2022-12-31 09:28:14,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:14,022 INFO:     Epoch: 11
2022-12-31 09:28:15,648 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37138964533805846, 'Total loss': 0.37138964533805846} | train loss {'Reaction outcome loss': 0.27685703576579423, 'Total loss': 0.27685703576579423}
2022-12-31 09:28:15,648 INFO:     Found new best model at epoch 11
2022-12-31 09:28:15,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:15,649 INFO:     Epoch: 12
2022-12-31 09:28:17,275 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3419040898482005, 'Total loss': 0.3419040898482005} | train loss {'Reaction outcome loss': 0.26524199023573836, 'Total loss': 0.26524199023573836}
2022-12-31 09:28:17,276 INFO:     Found new best model at epoch 12
2022-12-31 09:28:17,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:17,277 INFO:     Epoch: 13
2022-12-31 09:28:18,901 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.34353589738408724, 'Total loss': 0.34353589738408724} | train loss {'Reaction outcome loss': 0.2598253147750555, 'Total loss': 0.2598253147750555}
2022-12-31 09:28:18,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:18,902 INFO:     Epoch: 14
2022-12-31 09:28:20,571 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3461918224891027, 'Total loss': 0.3461918224891027} | train loss {'Reaction outcome loss': 0.24852612061890023, 'Total loss': 0.24852612061890023}
2022-12-31 09:28:20,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:20,571 INFO:     Epoch: 15
2022-12-31 09:28:22,205 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3494144529104233, 'Total loss': 0.3494144529104233} | train loss {'Reaction outcome loss': 0.241068856084605, 'Total loss': 0.241068856084605}
2022-12-31 09:28:22,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:22,205 INFO:     Epoch: 16
2022-12-31 09:28:23,832 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3799216071764628, 'Total loss': 0.3799216071764628} | train loss {'Reaction outcome loss': 0.2318176714575678, 'Total loss': 0.2318176714575678}
2022-12-31 09:28:23,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:23,833 INFO:     Epoch: 17
2022-12-31 09:28:25,472 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3808568179607391, 'Total loss': 0.3808568179607391} | train loss {'Reaction outcome loss': 0.2248090930040993, 'Total loss': 0.2248090930040993}
2022-12-31 09:28:25,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:25,473 INFO:     Epoch: 18
2022-12-31 09:28:27,112 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.369438045223554, 'Total loss': 0.369438045223554} | train loss {'Reaction outcome loss': 0.22297609423956286, 'Total loss': 0.22297609423956286}
2022-12-31 09:28:27,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:27,112 INFO:     Epoch: 19
2022-12-31 09:28:28,752 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.380660010377566, 'Total loss': 0.380660010377566} | train loss {'Reaction outcome loss': 0.217679617785267, 'Total loss': 0.217679617785267}
2022-12-31 09:28:28,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:28,752 INFO:     Epoch: 20
2022-12-31 09:28:30,388 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.382927135626475, 'Total loss': 0.382927135626475} | train loss {'Reaction outcome loss': 0.2065626717902155, 'Total loss': 0.2065626717902155}
2022-12-31 09:28:30,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:30,388 INFO:     Epoch: 21
2022-12-31 09:28:31,997 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39612240294615425, 'Total loss': 0.39612240294615425} | train loss {'Reaction outcome loss': 0.19969125330744023, 'Total loss': 0.19969125330744023}
2022-12-31 09:28:31,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:31,997 INFO:     Epoch: 22
2022-12-31 09:28:33,632 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.36115282674630483, 'Total loss': 0.36115282674630483} | train loss {'Reaction outcome loss': 0.20123681029647805, 'Total loss': 0.20123681029647805}
2022-12-31 09:28:33,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:33,633 INFO:     Epoch: 23
2022-12-31 09:28:35,246 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36660716533660886, 'Total loss': 0.36660716533660886} | train loss {'Reaction outcome loss': 0.1935171228211494, 'Total loss': 0.1935171228211494}
2022-12-31 09:28:35,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:35,246 INFO:     Epoch: 24
2022-12-31 09:28:36,860 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37581450839837394, 'Total loss': 0.37581450839837394} | train loss {'Reaction outcome loss': 0.18630985506147899, 'Total loss': 0.18630985506147899}
2022-12-31 09:28:36,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:36,860 INFO:     Epoch: 25
2022-12-31 09:28:38,474 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37497005860010785, 'Total loss': 0.37497005860010785} | train loss {'Reaction outcome loss': 0.186602502916721, 'Total loss': 0.186602502916721}
2022-12-31 09:28:38,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:38,474 INFO:     Epoch: 26
2022-12-31 09:28:40,149 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.35732727746168774, 'Total loss': 0.35732727746168774} | train loss {'Reaction outcome loss': 0.17983039677990365, 'Total loss': 0.17983039677990365}
2022-12-31 09:28:40,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:40,149 INFO:     Epoch: 27
2022-12-31 09:28:41,850 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38348161975542705, 'Total loss': 0.38348161975542705} | train loss {'Reaction outcome loss': 0.17847265205631832, 'Total loss': 0.17847265205631832}
2022-12-31 09:28:41,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:41,851 INFO:     Epoch: 28
2022-12-31 09:28:43,464 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37931797504425047, 'Total loss': 0.37931797504425047} | train loss {'Reaction outcome loss': 0.1749744793393444, 'Total loss': 0.1749744793393444}
2022-12-31 09:28:43,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:43,465 INFO:     Epoch: 29
2022-12-31 09:28:45,080 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3838864743709564, 'Total loss': 0.3838864743709564} | train loss {'Reaction outcome loss': 0.1728978725217471, 'Total loss': 0.1728978725217471}
2022-12-31 09:28:45,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:45,080 INFO:     Epoch: 30
2022-12-31 09:28:46,697 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38358594303329785, 'Total loss': 0.38358594303329785} | train loss {'Reaction outcome loss': 0.1680598695046312, 'Total loss': 0.1680598695046312}
2022-12-31 09:28:46,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:46,697 INFO:     Epoch: 31
2022-12-31 09:28:48,405 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3895436018705368, 'Total loss': 0.3895436018705368} | train loss {'Reaction outcome loss': 0.16305919365775823, 'Total loss': 0.16305919365775823}
2022-12-31 09:28:48,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:48,406 INFO:     Epoch: 32
2022-12-31 09:28:50,028 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3878278414408366, 'Total loss': 0.3878278414408366} | train loss {'Reaction outcome loss': 0.1627456724831989, 'Total loss': 0.1627456724831989}
2022-12-31 09:28:50,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:50,029 INFO:     Epoch: 33
2022-12-31 09:28:51,709 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.373848549524943, 'Total loss': 0.373848549524943} | train loss {'Reaction outcome loss': 0.16462747829828397, 'Total loss': 0.16462747829828397}
2022-12-31 09:28:51,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:51,709 INFO:     Epoch: 34
2022-12-31 09:28:53,329 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36811839540799457, 'Total loss': 0.36811839540799457} | train loss {'Reaction outcome loss': 0.1593517302720394, 'Total loss': 0.1593517302720394}
2022-12-31 09:28:53,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:53,329 INFO:     Epoch: 35
2022-12-31 09:28:54,954 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39444694221019744, 'Total loss': 0.39444694221019744} | train loss {'Reaction outcome loss': 0.15647146790641417, 'Total loss': 0.15647146790641417}
2022-12-31 09:28:54,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:54,954 INFO:     Epoch: 36
2022-12-31 09:28:56,625 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3730825533469518, 'Total loss': 0.3730825533469518} | train loss {'Reaction outcome loss': 0.15708824264605123, 'Total loss': 0.15708824264605123}
2022-12-31 09:28:56,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:56,625 INFO:     Epoch: 37
2022-12-31 09:28:58,289 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3799630676706632, 'Total loss': 0.3799630676706632} | train loss {'Reaction outcome loss': 0.15484430652031075, 'Total loss': 0.15484430652031075}
2022-12-31 09:28:58,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:58,289 INFO:     Epoch: 38
2022-12-31 09:28:59,924 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40237777531147, 'Total loss': 0.40237777531147} | train loss {'Reaction outcome loss': 0.1512921561910653, 'Total loss': 0.1512921561910653}
2022-12-31 09:28:59,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:28:59,924 INFO:     Epoch: 39
2022-12-31 09:29:01,594 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3733560840288798, 'Total loss': 0.3733560840288798} | train loss {'Reaction outcome loss': 0.15243212548454396, 'Total loss': 0.15243212548454396}
2022-12-31 09:29:01,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:01,595 INFO:     Epoch: 40
2022-12-31 09:29:03,214 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39084574977556863, 'Total loss': 0.39084574977556863} | train loss {'Reaction outcome loss': 0.1509597646442346, 'Total loss': 0.1509597646442346}
2022-12-31 09:29:03,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:03,214 INFO:     Epoch: 41
2022-12-31 09:29:04,884 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39524955451488497, 'Total loss': 0.39524955451488497} | train loss {'Reaction outcome loss': 0.148168158775451, 'Total loss': 0.148168158775451}
2022-12-31 09:29:04,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:04,884 INFO:     Epoch: 42
2022-12-31 09:29:06,509 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39747416575749717, 'Total loss': 0.39747416575749717} | train loss {'Reaction outcome loss': 0.14285118827455096, 'Total loss': 0.14285118827455096}
2022-12-31 09:29:06,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:06,509 INFO:     Epoch: 43
2022-12-31 09:29:08,138 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3980822165807088, 'Total loss': 0.3980822165807088} | train loss {'Reaction outcome loss': 0.15060414086072454, 'Total loss': 0.15060414086072454}
2022-12-31 09:29:08,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:08,139 INFO:     Epoch: 44
2022-12-31 09:29:09,762 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3807995518048604, 'Total loss': 0.3807995518048604} | train loss {'Reaction outcome loss': 0.14495283185373253, 'Total loss': 0.14495283185373253}
2022-12-31 09:29:09,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:09,763 INFO:     Epoch: 45
2022-12-31 09:29:11,397 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38739548561473686, 'Total loss': 0.38739548561473686} | train loss {'Reaction outcome loss': 0.14313003320973164, 'Total loss': 0.14313003320973164}
2022-12-31 09:29:11,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:11,397 INFO:     Epoch: 46
2022-12-31 09:29:13,031 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3695667167504629, 'Total loss': 0.3695667167504629} | train loss {'Reaction outcome loss': 0.14413051607107427, 'Total loss': 0.14413051607107427}
2022-12-31 09:29:13,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:13,033 INFO:     Epoch: 47
2022-12-31 09:29:14,666 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39115000069141387, 'Total loss': 0.39115000069141387} | train loss {'Reaction outcome loss': 0.13909342774569936, 'Total loss': 0.13909342774569936}
2022-12-31 09:29:14,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:14,666 INFO:     Epoch: 48
2022-12-31 09:29:16,303 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3881847277283669, 'Total loss': 0.3881847277283669} | train loss {'Reaction outcome loss': 0.13813369824056806, 'Total loss': 0.13813369824056806}
2022-12-31 09:29:16,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:16,303 INFO:     Epoch: 49
2022-12-31 09:29:17,922 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.374774303038915, 'Total loss': 0.374774303038915} | train loss {'Reaction outcome loss': 0.13691045399351778, 'Total loss': 0.13691045399351778}
2022-12-31 09:29:17,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:17,923 INFO:     Epoch: 50
2022-12-31 09:29:19,557 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3755985935529073, 'Total loss': 0.3755985935529073} | train loss {'Reaction outcome loss': 0.13751902976258246, 'Total loss': 0.13751902976258246}
2022-12-31 09:29:19,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:19,558 INFO:     Epoch: 51
2022-12-31 09:29:21,192 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3974824289480845, 'Total loss': 0.3974824289480845} | train loss {'Reaction outcome loss': 0.1347879053493592, 'Total loss': 0.1347879053493592}
2022-12-31 09:29:21,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:21,192 INFO:     Epoch: 52
2022-12-31 09:29:22,828 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3958755023777485, 'Total loss': 0.3958755023777485} | train loss {'Reaction outcome loss': 0.13467149313754445, 'Total loss': 0.13467149313754445}
2022-12-31 09:29:22,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:22,829 INFO:     Epoch: 53
2022-12-31 09:29:24,463 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39628519473286966, 'Total loss': 0.39628519473286966} | train loss {'Reaction outcome loss': 0.13611903542060982, 'Total loss': 0.13611903542060982}
2022-12-31 09:29:24,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:24,464 INFO:     Epoch: 54
2022-12-31 09:29:26,090 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4147702823082606, 'Total loss': 0.4147702823082606} | train loss {'Reaction outcome loss': 0.13208491129830938, 'Total loss': 0.13208491129830938}
2022-12-31 09:29:26,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:26,090 INFO:     Epoch: 55
2022-12-31 09:29:27,718 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4168511172135671, 'Total loss': 0.4168511172135671} | train loss {'Reaction outcome loss': 0.1309190614196045, 'Total loss': 0.1309190614196045}
2022-12-31 09:29:27,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:27,719 INFO:     Epoch: 56
2022-12-31 09:29:29,356 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4303823709487915, 'Total loss': 0.4303823709487915} | train loss {'Reaction outcome loss': 0.13154742801864547, 'Total loss': 0.13154742801864547}
2022-12-31 09:29:29,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:29,356 INFO:     Epoch: 57
2022-12-31 09:29:30,994 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4091387510299683, 'Total loss': 0.4091387510299683} | train loss {'Reaction outcome loss': 0.12896676602628795, 'Total loss': 0.12896676602628795}
2022-12-31 09:29:30,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:30,995 INFO:     Epoch: 58
2022-12-31 09:29:32,634 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4277572174866994, 'Total loss': 0.4277572174866994} | train loss {'Reaction outcome loss': 0.1281833845537008, 'Total loss': 0.1281833845537008}
2022-12-31 09:29:32,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:32,635 INFO:     Epoch: 59
2022-12-31 09:29:34,274 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41150103211402894, 'Total loss': 0.41150103211402894} | train loss {'Reaction outcome loss': 0.12836555208227451, 'Total loss': 0.12836555208227451}
2022-12-31 09:29:34,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:34,274 INFO:     Epoch: 60
2022-12-31 09:29:35,904 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41729699273904164, 'Total loss': 0.41729699273904164} | train loss {'Reaction outcome loss': 0.12593035444798828, 'Total loss': 0.12593035444798828}
2022-12-31 09:29:35,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:35,904 INFO:     Epoch: 61
2022-12-31 09:29:37,574 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4569367195169131, 'Total loss': 0.4569367195169131} | train loss {'Reaction outcome loss': 0.1324705851587067, 'Total loss': 0.1324705851587067}
2022-12-31 09:29:37,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:37,574 INFO:     Epoch: 62
2022-12-31 09:29:39,219 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40004273454348244, 'Total loss': 0.40004273454348244} | train loss {'Reaction outcome loss': 0.13141478309306964, 'Total loss': 0.13141478309306964}
2022-12-31 09:29:39,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:39,219 INFO:     Epoch: 63
2022-12-31 09:29:40,898 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4218963543574015, 'Total loss': 0.4218963543574015} | train loss {'Reaction outcome loss': 0.12829568308344386, 'Total loss': 0.12829568308344386}
2022-12-31 09:29:40,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:40,898 INFO:     Epoch: 64
2022-12-31 09:29:42,520 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41010894974072776, 'Total loss': 0.41010894974072776} | train loss {'Reaction outcome loss': 0.12586995729141018, 'Total loss': 0.12586995729141018}
2022-12-31 09:29:42,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:42,521 INFO:     Epoch: 65
2022-12-31 09:29:44,132 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3767718841632207, 'Total loss': 0.3767718841632207} | train loss {'Reaction outcome loss': 0.12387707555794329, 'Total loss': 0.12387707555794329}
2022-12-31 09:29:44,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:44,132 INFO:     Epoch: 66
2022-12-31 09:29:45,760 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40542852928241097, 'Total loss': 0.40542852928241097} | train loss {'Reaction outcome loss': 0.12646586123168038, 'Total loss': 0.12646586123168038}
2022-12-31 09:29:45,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:45,760 INFO:     Epoch: 67
2022-12-31 09:29:47,430 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40692958335081736, 'Total loss': 0.40692958335081736} | train loss {'Reaction outcome loss': 0.1239544733524968, 'Total loss': 0.1239544733524968}
2022-12-31 09:29:47,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:47,431 INFO:     Epoch: 68
2022-12-31 09:29:49,100 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42278095086415607, 'Total loss': 0.42278095086415607} | train loss {'Reaction outcome loss': 0.12139484064236607, 'Total loss': 0.12139484064236607}
2022-12-31 09:29:49,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:49,101 INFO:     Epoch: 69
2022-12-31 09:29:50,725 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4120931228001912, 'Total loss': 0.4120931228001912} | train loss {'Reaction outcome loss': 0.12400184100702244, 'Total loss': 0.12400184100702244}
2022-12-31 09:29:50,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:50,725 INFO:     Epoch: 70
2022-12-31 09:29:52,394 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44039688011010486, 'Total loss': 0.44039688011010486} | train loss {'Reaction outcome loss': 0.12067502339972377, 'Total loss': 0.12067502339972377}
2022-12-31 09:29:52,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:52,394 INFO:     Epoch: 71
2022-12-31 09:29:54,041 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40458477040131885, 'Total loss': 0.40458477040131885} | train loss {'Reaction outcome loss': 0.12619080223876056, 'Total loss': 0.12619080223876056}
2022-12-31 09:29:54,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:54,041 INFO:     Epoch: 72
2022-12-31 09:29:55,671 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4199427326520284, 'Total loss': 0.4199427326520284} | train loss {'Reaction outcome loss': 0.12337741439166859, 'Total loss': 0.12337741439166859}
2022-12-31 09:29:55,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:55,672 INFO:     Epoch: 73
2022-12-31 09:29:57,304 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4100492517153422, 'Total loss': 0.4100492517153422} | train loss {'Reaction outcome loss': 0.1302284723608368, 'Total loss': 0.1302284723608368}
2022-12-31 09:29:57,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:57,304 INFO:     Epoch: 74
2022-12-31 09:29:58,930 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4387357940276464, 'Total loss': 0.4387357940276464} | train loss {'Reaction outcome loss': 0.12254329911846708, 'Total loss': 0.12254329911846708}
2022-12-31 09:29:58,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:29:58,931 INFO:     Epoch: 75
2022-12-31 09:30:00,555 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4178481618563334, 'Total loss': 0.4178481618563334} | train loss {'Reaction outcome loss': 0.11823186316167673, 'Total loss': 0.11823186316167673}
2022-12-31 09:30:00,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:00,556 INFO:     Epoch: 76
2022-12-31 09:30:02,175 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4008184755841891, 'Total loss': 0.4008184755841891} | train loss {'Reaction outcome loss': 0.12073968705260582, 'Total loss': 0.12073968705260582}
2022-12-31 09:30:02,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:02,176 INFO:     Epoch: 77
2022-12-31 09:30:03,808 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45824190179506935, 'Total loss': 0.45824190179506935} | train loss {'Reaction outcome loss': 0.1226638006096847, 'Total loss': 0.1226638006096847}
2022-12-31 09:30:03,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:03,808 INFO:     Epoch: 78
2022-12-31 09:30:05,474 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4111342754525443, 'Total loss': 0.4111342754525443} | train loss {'Reaction outcome loss': 0.1216742701505711, 'Total loss': 0.1216742701505711}
2022-12-31 09:30:05,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:05,475 INFO:     Epoch: 79
2022-12-31 09:30:07,141 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41691890060901643, 'Total loss': 0.41691890060901643} | train loss {'Reaction outcome loss': 0.1164245657763185, 'Total loss': 0.1164245657763185}
2022-12-31 09:30:07,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:07,142 INFO:     Epoch: 80
2022-12-31 09:30:08,762 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42289741734663644, 'Total loss': 0.42289741734663644} | train loss {'Reaction outcome loss': 0.11841681925916123, 'Total loss': 0.11841681925916123}
2022-12-31 09:30:08,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:08,763 INFO:     Epoch: 81
2022-12-31 09:30:10,384 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42445096373558044, 'Total loss': 0.42445096373558044} | train loss {'Reaction outcome loss': 0.1203387673449995, 'Total loss': 0.1203387673449995}
2022-12-31 09:30:10,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:10,384 INFO:     Epoch: 82
2022-12-31 09:30:12,030 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40877005954583484, 'Total loss': 0.40877005954583484} | train loss {'Reaction outcome loss': 0.114214766343605, 'Total loss': 0.114214766343605}
2022-12-31 09:30:12,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:12,030 INFO:     Epoch: 83
2022-12-31 09:30:13,646 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46385375956694286, 'Total loss': 0.46385375956694286} | train loss {'Reaction outcome loss': 0.12617337539630677, 'Total loss': 0.12617337539630677}
2022-12-31 09:30:13,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:13,647 INFO:     Epoch: 84
2022-12-31 09:30:15,314 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4298272748788198, 'Total loss': 0.4298272748788198} | train loss {'Reaction outcome loss': 0.12283686248985681, 'Total loss': 0.12283686248985681}
2022-12-31 09:30:15,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:15,314 INFO:     Epoch: 85
2022-12-31 09:30:16,939 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41446474293867747, 'Total loss': 0.41446474293867747} | train loss {'Reaction outcome loss': 0.11903570861041222, 'Total loss': 0.11903570861041222}
2022-12-31 09:30:16,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:16,940 INFO:     Epoch: 86
2022-12-31 09:30:18,607 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45477540194988253, 'Total loss': 0.45477540194988253} | train loss {'Reaction outcome loss': 0.1188203946204809, 'Total loss': 0.1188203946204809}
2022-12-31 09:30:18,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:18,607 INFO:     Epoch: 87
2022-12-31 09:30:20,229 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43954004247983297, 'Total loss': 0.43954004247983297} | train loss {'Reaction outcome loss': 0.11996265198524356, 'Total loss': 0.11996265198524356}
2022-12-31 09:30:20,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:20,229 INFO:     Epoch: 88
2022-12-31 09:30:21,846 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4406716530521711, 'Total loss': 0.4406716530521711} | train loss {'Reaction outcome loss': 0.114199919784139, 'Total loss': 0.114199919784139}
2022-12-31 09:30:21,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:21,846 INFO:     Epoch: 89
2022-12-31 09:30:23,464 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.435081551472346, 'Total loss': 0.435081551472346} | train loss {'Reaction outcome loss': 0.11164975586424612, 'Total loss': 0.11164975586424612}
2022-12-31 09:30:23,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:23,464 INFO:     Epoch: 90
2022-12-31 09:30:25,082 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39678767919540403, 'Total loss': 0.39678767919540403} | train loss {'Reaction outcome loss': 0.11420445731716627, 'Total loss': 0.11420445731716627}
2022-12-31 09:30:25,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:25,083 INFO:     Epoch: 91
2022-12-31 09:30:26,701 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41388275623321535, 'Total loss': 0.41388275623321535} | train loss {'Reaction outcome loss': 0.11748045511940487, 'Total loss': 0.11748045511940487}
2022-12-31 09:30:26,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:26,702 INFO:     Epoch: 92
2022-12-31 09:30:28,321 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41042372783025105, 'Total loss': 0.41042372783025105} | train loss {'Reaction outcome loss': 0.11714131687263478, 'Total loss': 0.11714131687263478}
2022-12-31 09:30:28,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:28,321 INFO:     Epoch: 93
2022-12-31 09:30:29,943 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.430637859304746, 'Total loss': 0.430637859304746} | train loss {'Reaction outcome loss': 0.11594635327447488, 'Total loss': 0.11594635327447488}
2022-12-31 09:30:29,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:29,943 INFO:     Epoch: 94
2022-12-31 09:30:31,565 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40283428331216176, 'Total loss': 0.40283428331216176} | train loss {'Reaction outcome loss': 0.11721718914484074, 'Total loss': 0.11721718914484074}
2022-12-31 09:30:31,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:31,566 INFO:     Epoch: 95
2022-12-31 09:30:33,185 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4180493202060461, 'Total loss': 0.4180493202060461} | train loss {'Reaction outcome loss': 0.11611031786629439, 'Total loss': 0.11611031786629439}
2022-12-31 09:30:33,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:33,185 INFO:     Epoch: 96
2022-12-31 09:30:34,795 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39984083026647566, 'Total loss': 0.39984083026647566} | train loss {'Reaction outcome loss': 0.11873539391693252, 'Total loss': 0.11873539391693252}
2022-12-31 09:30:34,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:34,795 INFO:     Epoch: 97
2022-12-31 09:30:36,414 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39962844451268514, 'Total loss': 0.39962844451268514} | train loss {'Reaction outcome loss': 0.11902600477890041, 'Total loss': 0.11902600477890041}
2022-12-31 09:30:36,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:36,415 INFO:     Epoch: 98
2022-12-31 09:30:38,033 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41420305520296097, 'Total loss': 0.41420305520296097} | train loss {'Reaction outcome loss': 0.11323989954329892, 'Total loss': 0.11323989954329892}
2022-12-31 09:30:38,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:38,033 INFO:     Epoch: 99
2022-12-31 09:30:39,665 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39671934644381207, 'Total loss': 0.39671934644381207} | train loss {'Reaction outcome loss': 0.11212189530109859, 'Total loss': 0.11212189530109859}
2022-12-31 09:30:39,666 INFO:     Best model found after epoch 13 of 100.
2022-12-31 09:30:39,666 INFO:   Done with stage: TRAINING
2022-12-31 09:30:39,666 INFO:   Starting stage: EVALUATION
2022-12-31 09:30:39,792 INFO:   Done with stage: EVALUATION
2022-12-31 09:30:39,792 INFO: Done with stage: RUNNING SPLITS
2022-12-31 09:30:39,792 INFO: Starting stage: COMPUTE METRICS
2022-12-31 09:30:40,965 INFO: Done with stage: COMPUTE METRICS
2022-12-31 09:30:40,965 INFO: Starting stage: EXPORT RESULTS
2022-12-31 09:30:40,982 INFO:   Final results averaged over 50 folds: 
2022-12-31 09:30:40,986 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.164443           NaN  0.312013       NaN
2022-12-31 09:30:42,602 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-31 09:30:42,607 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-31 09:30:42,609 DEBUG:   interactive is False
2022-12-31 09:30:42,609 DEBUG:   platform is linux
2022-12-31 09:30:42,609 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-31 09:30:42,780 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-31 09:30:42,782 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-31 09:30:43,216 DEBUG:   Loaded backend agg version unknown.
2022-12-31 09:30:43,218 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 09:30:43,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,218 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,219 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,220 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 09:30:43,221 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,221 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 09:30:43,258 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,258 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,259 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 09:30:43,260 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,261 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 09:30:43,269 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 09:30:43,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,269 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 09:30:43,270 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,271 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 09:30:43,272 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 09:30:43,272 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,272 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,272 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 09:30:43,272 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 09:30:43,272 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 09:30:43,272 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 09:30:43,634 INFO: Done with stage: EXPORT RESULTS
2022-12-31 09:30:43,634 INFO: Starting stage: SAVE MODEL
2022-12-31 09:30:43,690 INFO: Done with stage: SAVE MODEL
2022-12-31 09:30:43,690 INFO: Wall time for program:  8151.50 seconds
