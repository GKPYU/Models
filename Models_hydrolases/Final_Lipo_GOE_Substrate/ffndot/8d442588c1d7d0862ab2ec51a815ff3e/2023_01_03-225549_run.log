2023-01-04 03:23:04,081 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/8d442588c1d7d0862ab2ec51a815ff3e/2023_01_03-225549",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-04 03:23:04,089 INFO: Starting stage: BUILD FEATURIZERS
2023-01-04 03:23:04,091 INFO:   Creating esm representation model
2023-01-04 03:23:04,091 INFO:   Done esm representation model
2023-01-04 03:23:04,091 INFO: Done with stage: BUILD FEATURIZERS
2023-01-04 03:23:04,091 INFO: Starting stage: BUILDING DATASET
2023-01-04 03:23:04,158 INFO: Done with stage: BUILDING DATASET
2023-01-04 03:23:04,158 INFO: Starting stage: FEATURIZING DATA
2023-01-04 03:23:04,158 INFO:   Featurizing proteins
2023-01-04 03:23:04,160 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-04 03:23:04,195 INFO:   Loaded feature cache of size 489
2023-01-04 03:23:04,197 INFO:   Starting to pool ESM Embeddings
2023-01-04 03:23:04,324 INFO:   Featurizing molecules
2023-01-04 03:23:04,326 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-04 03:23:04,328 INFO:   Loaded feature cache of size 498
2023-01-04 03:23:05,684 INFO: Done with stage: FEATURIZING DATA
2023-01-04 03:23:05,684 INFO: Starting stage: RUNNING SPLITS
2023-01-04 03:23:05,693 INFO:   Leaving out SEQ value Fold_0
2023-01-04 03:23:05,706 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 03:23:05,707 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:23:06,364 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:23:06,364 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:23:06,429 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:23:06,429 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:23:06,429 INFO:     No hyperparam tuning for this model
2023-01-04 03:23:06,429 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:23:06,429 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:23:06,430 INFO:     None feature selector for col prot
2023-01-04 03:23:06,430 INFO:     None feature selector for col prot
2023-01-04 03:23:06,430 INFO:     None feature selector for col prot
2023-01-04 03:23:06,431 INFO:     None feature selector for col chem
2023-01-04 03:23:06,431 INFO:     None feature selector for col chem
2023-01-04 03:23:06,431 INFO:     None feature selector for col chem
2023-01-04 03:23:06,431 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:23:06,431 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:23:06,432 INFO:     Number of params in model 70141
2023-01-04 03:23:06,432 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:23:06,432 INFO:   Starting stage: TRAINING
2023-01-04 03:23:08,020 INFO:     Val loss before train {'Reaction outcome loss': 1.0867226004600525, 'Total loss': 1.0867226004600525}
2023-01-04 03:23:08,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:08,021 INFO:     Epoch: 0
2023-01-04 03:23:09,597 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7179911255836486, 'Total loss': 0.7179911255836486} | train loss {'Reaction outcome loss': 0.8619357100227377, 'Total loss': 0.8619357100227377}
2023-01-04 03:23:09,597 INFO:     Found new best model at epoch 0
2023-01-04 03:23:09,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:09,598 INFO:     Epoch: 1
2023-01-04 03:23:11,222 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6084764897823334, 'Total loss': 0.6084764897823334} | train loss {'Reaction outcome loss': 0.6097128970800957, 'Total loss': 0.6097128970800957}
2023-01-04 03:23:11,222 INFO:     Found new best model at epoch 1
2023-01-04 03:23:11,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:11,223 INFO:     Epoch: 2
2023-01-04 03:23:12,789 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.548557722568512, 'Total loss': 0.548557722568512} | train loss {'Reaction outcome loss': 0.538852463438834, 'Total loss': 0.538852463438834}
2023-01-04 03:23:12,789 INFO:     Found new best model at epoch 2
2023-01-04 03:23:12,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:12,790 INFO:     Epoch: 3
2023-01-04 03:23:14,379 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5259157518545786, 'Total loss': 0.5259157518545786} | train loss {'Reaction outcome loss': 0.4997612937138631, 'Total loss': 0.4997612937138631}
2023-01-04 03:23:14,380 INFO:     Found new best model at epoch 3
2023-01-04 03:23:14,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:14,380 INFO:     Epoch: 4
2023-01-04 03:23:15,952 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48539481361707054, 'Total loss': 0.48539481361707054} | train loss {'Reaction outcome loss': 0.473006865971691, 'Total loss': 0.473006865971691}
2023-01-04 03:23:15,952 INFO:     Found new best model at epoch 4
2023-01-04 03:23:15,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:15,953 INFO:     Epoch: 5
2023-01-04 03:23:17,540 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4809489667415619, 'Total loss': 0.4809489667415619} | train loss {'Reaction outcome loss': 0.45370064195477483, 'Total loss': 0.45370064195477483}
2023-01-04 03:23:17,540 INFO:     Found new best model at epoch 5
2023-01-04 03:23:17,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:17,541 INFO:     Epoch: 6
2023-01-04 03:23:19,130 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47316073775291445, 'Total loss': 0.47316073775291445} | train loss {'Reaction outcome loss': 0.4373818358113041, 'Total loss': 0.4373818358113041}
2023-01-04 03:23:19,130 INFO:     Found new best model at epoch 6
2023-01-04 03:23:19,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:19,131 INFO:     Epoch: 7
2023-01-04 03:23:20,694 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49076376159985863, 'Total loss': 0.49076376159985863} | train loss {'Reaction outcome loss': 0.4209265564824199, 'Total loss': 0.4209265564824199}
2023-01-04 03:23:20,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:20,694 INFO:     Epoch: 8
2023-01-04 03:23:22,283 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46207061807314553, 'Total loss': 0.46207061807314553} | train loss {'Reaction outcome loss': 0.40778522007849627, 'Total loss': 0.40778522007849627}
2023-01-04 03:23:22,283 INFO:     Found new best model at epoch 8
2023-01-04 03:23:22,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:22,284 INFO:     Epoch: 9
2023-01-04 03:23:23,848 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44986513356367747, 'Total loss': 0.44986513356367747} | train loss {'Reaction outcome loss': 0.3971941360296347, 'Total loss': 0.3971941360296347}
2023-01-04 03:23:23,848 INFO:     Found new best model at epoch 9
2023-01-04 03:23:23,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:23,849 INFO:     Epoch: 10
2023-01-04 03:23:25,460 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45746607780456544, 'Total loss': 0.45746607780456544} | train loss {'Reaction outcome loss': 0.3822754193438497, 'Total loss': 0.3822754193438497}
2023-01-04 03:23:25,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:25,460 INFO:     Epoch: 11
2023-01-04 03:23:27,066 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4809500962495804, 'Total loss': 0.4809500962495804} | train loss {'Reaction outcome loss': 0.3733081681919949, 'Total loss': 0.3733081681919949}
2023-01-04 03:23:27,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:27,067 INFO:     Epoch: 12
2023-01-04 03:23:28,671 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4746592442194621, 'Total loss': 0.4746592442194621} | train loss {'Reaction outcome loss': 0.3675804640347268, 'Total loss': 0.3675804640347268}
2023-01-04 03:23:28,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:28,672 INFO:     Epoch: 13
2023-01-04 03:23:30,257 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45727392435073855, 'Total loss': 0.45727392435073855} | train loss {'Reaction outcome loss': 0.35837192838881915, 'Total loss': 0.35837192838881915}
2023-01-04 03:23:30,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:30,257 INFO:     Epoch: 14
2023-01-04 03:23:31,849 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4844724218050639, 'Total loss': 0.4844724218050639} | train loss {'Reaction outcome loss': 0.35241983170474406, 'Total loss': 0.35241983170474406}
2023-01-04 03:23:31,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:31,849 INFO:     Epoch: 15
2023-01-04 03:23:33,410 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46175007621447245, 'Total loss': 0.46175007621447245} | train loss {'Reaction outcome loss': 0.34491627584228585, 'Total loss': 0.34491627584228585}
2023-01-04 03:23:33,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:33,410 INFO:     Epoch: 16
2023-01-04 03:23:34,997 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45223265290260317, 'Total loss': 0.45223265290260317} | train loss {'Reaction outcome loss': 0.3355987547136052, 'Total loss': 0.3355987547136052}
2023-01-04 03:23:34,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:34,997 INFO:     Epoch: 17
2023-01-04 03:23:36,585 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44288426289955773, 'Total loss': 0.44288426289955773} | train loss {'Reaction outcome loss': 0.3301528367783615, 'Total loss': 0.3301528367783615}
2023-01-04 03:23:36,585 INFO:     Found new best model at epoch 17
2023-01-04 03:23:36,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:36,586 INFO:     Epoch: 18
2023-01-04 03:23:38,173 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4665391226609548, 'Total loss': 0.4665391226609548} | train loss {'Reaction outcome loss': 0.329575614178137, 'Total loss': 0.329575614178137}
2023-01-04 03:23:38,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:38,174 INFO:     Epoch: 19
2023-01-04 03:23:39,742 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.467606391509374, 'Total loss': 0.467606391509374} | train loss {'Reaction outcome loss': 0.3202238230805694, 'Total loss': 0.3202238230805694}
2023-01-04 03:23:39,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:39,742 INFO:     Epoch: 20
2023-01-04 03:23:41,336 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4683785021305084, 'Total loss': 0.4683785021305084} | train loss {'Reaction outcome loss': 0.31434754909940693, 'Total loss': 0.31434754909940693}
2023-01-04 03:23:41,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:41,336 INFO:     Epoch: 21
2023-01-04 03:23:42,913 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45607228577136993, 'Total loss': 0.45607228577136993} | train loss {'Reaction outcome loss': 0.3080479208748419, 'Total loss': 0.3080479208748419}
2023-01-04 03:23:42,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:42,914 INFO:     Epoch: 22
2023-01-04 03:23:44,522 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44709121783574424, 'Total loss': 0.44709121783574424} | train loss {'Reaction outcome loss': 0.30235268754181843, 'Total loss': 0.30235268754181843}
2023-01-04 03:23:44,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:44,522 INFO:     Epoch: 23
2023-01-04 03:23:46,088 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45584684213002524, 'Total loss': 0.45584684213002524} | train loss {'Reaction outcome loss': 0.29908279998180193, 'Total loss': 0.29908279998180193}
2023-01-04 03:23:46,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:46,088 INFO:     Epoch: 24
2023-01-04 03:23:47,672 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4450428823630015, 'Total loss': 0.4450428823630015} | train loss {'Reaction outcome loss': 0.2942815208227643, 'Total loss': 0.2942815208227643}
2023-01-04 03:23:47,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:47,672 INFO:     Epoch: 25
2023-01-04 03:23:49,281 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4424071153004964, 'Total loss': 0.4424071153004964} | train loss {'Reaction outcome loss': 0.2925207821768282, 'Total loss': 0.2925207821768282}
2023-01-04 03:23:49,281 INFO:     Found new best model at epoch 25
2023-01-04 03:23:49,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:49,282 INFO:     Epoch: 26
2023-01-04 03:23:50,879 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4376242438952128, 'Total loss': 0.4376242438952128} | train loss {'Reaction outcome loss': 0.2866205034893511, 'Total loss': 0.2866205034893511}
2023-01-04 03:23:50,879 INFO:     Found new best model at epoch 26
2023-01-04 03:23:50,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:50,880 INFO:     Epoch: 27
2023-01-04 03:23:52,479 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46210923393567405, 'Total loss': 0.46210923393567405} | train loss {'Reaction outcome loss': 0.281924253036251, 'Total loss': 0.281924253036251}
2023-01-04 03:23:52,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:52,480 INFO:     Epoch: 28
2023-01-04 03:23:54,059 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45688217381636304, 'Total loss': 0.45688217381636304} | train loss {'Reaction outcome loss': 0.2790744922263718, 'Total loss': 0.2790744922263718}
2023-01-04 03:23:54,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:54,059 INFO:     Epoch: 29
2023-01-04 03:23:55,649 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4574693481127421, 'Total loss': 0.4574693481127421} | train loss {'Reaction outcome loss': 0.27474755370791576, 'Total loss': 0.27474755370791576}
2023-01-04 03:23:55,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:55,650 INFO:     Epoch: 30
2023-01-04 03:23:57,228 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4519910564025243, 'Total loss': 0.4519910564025243} | train loss {'Reaction outcome loss': 0.27087572609985267, 'Total loss': 0.27087572609985267}
2023-01-04 03:23:57,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:57,229 INFO:     Epoch: 31
2023-01-04 03:23:58,833 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44978965719540914, 'Total loss': 0.44978965719540914} | train loss {'Reaction outcome loss': 0.26932055688712186, 'Total loss': 0.26932055688712186}
2023-01-04 03:23:58,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:23:58,834 INFO:     Epoch: 32
2023-01-04 03:24:00,410 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45363885859648384, 'Total loss': 0.45363885859648384} | train loss {'Reaction outcome loss': 0.26555928680704627, 'Total loss': 0.26555928680704627}
2023-01-04 03:24:00,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:00,411 INFO:     Epoch: 33
2023-01-04 03:24:02,011 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.454719141125679, 'Total loss': 0.454719141125679} | train loss {'Reaction outcome loss': 0.26338808170277556, 'Total loss': 0.26338808170277556}
2023-01-04 03:24:02,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:02,011 INFO:     Epoch: 34
2023-01-04 03:24:03,617 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4597124437491099, 'Total loss': 0.4597124437491099} | train loss {'Reaction outcome loss': 0.26171068192183317, 'Total loss': 0.26171068192183317}
2023-01-04 03:24:03,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:03,617 INFO:     Epoch: 35
2023-01-04 03:24:05,219 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46350294947624204, 'Total loss': 0.46350294947624204} | train loss {'Reaction outcome loss': 0.2561243746579785, 'Total loss': 0.2561243746579785}
2023-01-04 03:24:05,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:05,220 INFO:     Epoch: 36
2023-01-04 03:24:06,783 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4589983284473419, 'Total loss': 0.4589983284473419} | train loss {'Reaction outcome loss': 0.2539413514591399, 'Total loss': 0.2539413514591399}
2023-01-04 03:24:06,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:06,783 INFO:     Epoch: 37
2023-01-04 03:24:08,365 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45636108915011087, 'Total loss': 0.45636108915011087} | train loss {'Reaction outcome loss': 0.2506189105056581, 'Total loss': 0.2506189105056581}
2023-01-04 03:24:08,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:08,366 INFO:     Epoch: 38
2023-01-04 03:24:09,942 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46147607068220775, 'Total loss': 0.46147607068220775} | train loss {'Reaction outcome loss': 0.2480146710252587, 'Total loss': 0.2480146710252587}
2023-01-04 03:24:09,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:09,942 INFO:     Epoch: 39
2023-01-04 03:24:11,544 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45600614746411644, 'Total loss': 0.45600614746411644} | train loss {'Reaction outcome loss': 0.24731739383914095, 'Total loss': 0.24731739383914095}
2023-01-04 03:24:11,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:11,544 INFO:     Epoch: 40
2023-01-04 03:24:13,148 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44982548952102663, 'Total loss': 0.44982548952102663} | train loss {'Reaction outcome loss': 0.2445987349191865, 'Total loss': 0.2445987349191865}
2023-01-04 03:24:13,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:13,148 INFO:     Epoch: 41
2023-01-04 03:24:14,743 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4610324323177338, 'Total loss': 0.4610324323177338} | train loss {'Reaction outcome loss': 0.24371457035779517, 'Total loss': 0.24371457035779517}
2023-01-04 03:24:14,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:14,744 INFO:     Epoch: 42
2023-01-04 03:24:16,326 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4442429065704346, 'Total loss': 0.4442429065704346} | train loss {'Reaction outcome loss': 0.2419682345711268, 'Total loss': 0.2419682345711268}
2023-01-04 03:24:16,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:16,326 INFO:     Epoch: 43
2023-01-04 03:24:17,889 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48098332683245343, 'Total loss': 0.48098332683245343} | train loss {'Reaction outcome loss': 0.23610412078353513, 'Total loss': 0.23610412078353513}
2023-01-04 03:24:17,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:17,890 INFO:     Epoch: 44
2023-01-04 03:24:19,497 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43407937983671824, 'Total loss': 0.43407937983671824} | train loss {'Reaction outcome loss': 0.23488371640498384, 'Total loss': 0.23488371640498384}
2023-01-04 03:24:19,497 INFO:     Found new best model at epoch 44
2023-01-04 03:24:19,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:19,498 INFO:     Epoch: 45
2023-01-04 03:24:21,110 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4290139049291611, 'Total loss': 0.4290139049291611} | train loss {'Reaction outcome loss': 0.23217648000289232, 'Total loss': 0.23217648000289232}
2023-01-04 03:24:21,110 INFO:     Found new best model at epoch 45
2023-01-04 03:24:21,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:21,111 INFO:     Epoch: 46
2023-01-04 03:24:22,717 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4410594562689463, 'Total loss': 0.4410594562689463} | train loss {'Reaction outcome loss': 0.23053096319402094, 'Total loss': 0.23053096319402094}
2023-01-04 03:24:22,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:22,717 INFO:     Epoch: 47
2023-01-04 03:24:24,305 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45172500908374785, 'Total loss': 0.45172500908374785} | train loss {'Reaction outcome loss': 0.23066574303713036, 'Total loss': 0.23066574303713036}
2023-01-04 03:24:24,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:24,305 INFO:     Epoch: 48
2023-01-04 03:24:25,920 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44152389963467914, 'Total loss': 0.44152389963467914} | train loss {'Reaction outcome loss': 0.22965613665270718, 'Total loss': 0.22965613665270718}
2023-01-04 03:24:25,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:25,920 INFO:     Epoch: 49
2023-01-04 03:24:27,501 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.470613557100296, 'Total loss': 0.470613557100296} | train loss {'Reaction outcome loss': 0.22825766755302093, 'Total loss': 0.22825766755302093}
2023-01-04 03:24:27,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:27,501 INFO:     Epoch: 50
2023-01-04 03:24:29,109 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4582533886035283, 'Total loss': 0.4582533886035283} | train loss {'Reaction outcome loss': 0.22548003246386847, 'Total loss': 0.22548003246386847}
2023-01-04 03:24:29,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:29,109 INFO:     Epoch: 51
2023-01-04 03:24:30,716 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41881994605064393, 'Total loss': 0.41881994605064393} | train loss {'Reaction outcome loss': 0.22230203610745977, 'Total loss': 0.22230203610745977}
2023-01-04 03:24:30,717 INFO:     Found new best model at epoch 51
2023-01-04 03:24:30,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:30,717 INFO:     Epoch: 52
2023-01-04 03:24:32,324 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43251900672912597, 'Total loss': 0.43251900672912597} | train loss {'Reaction outcome loss': 0.21958603468406332, 'Total loss': 0.21958603468406332}
2023-01-04 03:24:32,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:32,324 INFO:     Epoch: 53
2023-01-04 03:24:33,915 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44890015025933583, 'Total loss': 0.44890015025933583} | train loss {'Reaction outcome loss': 0.2169766280213337, 'Total loss': 0.2169766280213337}
2023-01-04 03:24:33,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:33,915 INFO:     Epoch: 54
2023-01-04 03:24:35,536 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4398399899403254, 'Total loss': 0.4398399899403254} | train loss {'Reaction outcome loss': 0.2158960755948564, 'Total loss': 0.2158960755948564}
2023-01-04 03:24:35,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:35,537 INFO:     Epoch: 55
2023-01-04 03:24:37,119 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4498573005199432, 'Total loss': 0.4498573005199432} | train loss {'Reaction outcome loss': 0.21598284698395065, 'Total loss': 0.21598284698395065}
2023-01-04 03:24:37,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:37,120 INFO:     Epoch: 56
2023-01-04 03:24:38,731 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44290564954280853, 'Total loss': 0.44290564954280853} | train loss {'Reaction outcome loss': 0.21355159603905327, 'Total loss': 0.21355159603905327}
2023-01-04 03:24:38,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:38,732 INFO:     Epoch: 57
2023-01-04 03:24:40,355 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42877660890420277, 'Total loss': 0.42877660890420277} | train loss {'Reaction outcome loss': 0.21184767526148002, 'Total loss': 0.21184767526148002}
2023-01-04 03:24:40,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:40,356 INFO:     Epoch: 58
2023-01-04 03:24:41,955 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4465746432542801, 'Total loss': 0.4465746432542801} | train loss {'Reaction outcome loss': 0.2132806135239182, 'Total loss': 0.2132806135239182}
2023-01-04 03:24:41,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:41,955 INFO:     Epoch: 59
2023-01-04 03:24:43,540 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45584113597869874, 'Total loss': 0.45584113597869874} | train loss {'Reaction outcome loss': 0.20941653604970584, 'Total loss': 0.20941653604970584}
2023-01-04 03:24:43,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:43,541 INFO:     Epoch: 60
2023-01-04 03:24:45,148 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46915735602378844, 'Total loss': 0.46915735602378844} | train loss {'Reaction outcome loss': 0.20758702506348764, 'Total loss': 0.20758702506348764}
2023-01-04 03:24:45,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:45,149 INFO:     Epoch: 61
2023-01-04 03:24:46,731 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42760263780752816, 'Total loss': 0.42760263780752816} | train loss {'Reaction outcome loss': 0.20727077056909657, 'Total loss': 0.20727077056909657}
2023-01-04 03:24:46,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:46,732 INFO:     Epoch: 62
2023-01-04 03:24:48,314 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.451628436644872, 'Total loss': 0.451628436644872} | train loss {'Reaction outcome loss': 0.20512015845681175, 'Total loss': 0.20512015845681175}
2023-01-04 03:24:48,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:48,314 INFO:     Epoch: 63
2023-01-04 03:24:49,898 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45070059796174367, 'Total loss': 0.45070059796174367} | train loss {'Reaction outcome loss': 0.20204436448795018, 'Total loss': 0.20204436448795018}
2023-01-04 03:24:49,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:49,898 INFO:     Epoch: 64
2023-01-04 03:24:51,470 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46072886884212494, 'Total loss': 0.46072886884212494} | train loss {'Reaction outcome loss': 0.20162580182755385, 'Total loss': 0.20162580182755385}
2023-01-04 03:24:51,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:51,471 INFO:     Epoch: 65
2023-01-04 03:24:53,075 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4223076735933622, 'Total loss': 0.4223076735933622} | train loss {'Reaction outcome loss': 0.1993536552748619, 'Total loss': 0.1993536552748619}
2023-01-04 03:24:53,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:53,076 INFO:     Epoch: 66
2023-01-04 03:24:54,658 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46415648063023884, 'Total loss': 0.46415648063023884} | train loss {'Reaction outcome loss': 0.19673020520926396, 'Total loss': 0.19673020520926396}
2023-01-04 03:24:54,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:54,658 INFO:     Epoch: 67
2023-01-04 03:24:56,247 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4425614992777506, 'Total loss': 0.4425614992777506} | train loss {'Reaction outcome loss': 0.19878122997862516, 'Total loss': 0.19878122997862516}
2023-01-04 03:24:56,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:56,247 INFO:     Epoch: 68
2023-01-04 03:24:57,847 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47118849158287046, 'Total loss': 0.47118849158287046} | train loss {'Reaction outcome loss': 0.19829274087653057, 'Total loss': 0.19829274087653057}
2023-01-04 03:24:57,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:57,847 INFO:     Epoch: 69
2023-01-04 03:24:59,448 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42866736551125845, 'Total loss': 0.42866736551125845} | train loss {'Reaction outcome loss': 0.19681860188588554, 'Total loss': 0.19681860188588554}
2023-01-04 03:24:59,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:24:59,449 INFO:     Epoch: 70
2023-01-04 03:25:00,638 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4498935413857301, 'Total loss': 0.4498935413857301} | train loss {'Reaction outcome loss': 0.1944223699797859, 'Total loss': 0.1944223699797859}
2023-01-04 03:25:00,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:00,638 INFO:     Epoch: 71
2023-01-04 03:25:01,694 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47526141703128816, 'Total loss': 0.47526141703128816} | train loss {'Reaction outcome loss': 0.19489056200826124, 'Total loss': 0.19489056200826124}
2023-01-04 03:25:01,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:01,694 INFO:     Epoch: 72
2023-01-04 03:25:02,763 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4414553463459015, 'Total loss': 0.4414553463459015} | train loss {'Reaction outcome loss': 0.19604993577459792, 'Total loss': 0.19604993577459792}
2023-01-04 03:25:02,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:02,763 INFO:     Epoch: 73
2023-01-04 03:25:03,821 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4713649392127991, 'Total loss': 0.4713649392127991} | train loss {'Reaction outcome loss': 0.19364728633955722, 'Total loss': 0.19364728633955722}
2023-01-04 03:25:03,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:03,822 INFO:     Epoch: 74
2023-01-04 03:25:05,313 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4414285530646642, 'Total loss': 0.4414285530646642} | train loss {'Reaction outcome loss': 0.19061907071743037, 'Total loss': 0.19061907071743037}
2023-01-04 03:25:05,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:05,314 INFO:     Epoch: 75
2023-01-04 03:25:06,916 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4570391774177551, 'Total loss': 0.4570391774177551} | train loss {'Reaction outcome loss': 0.18865383438247463, 'Total loss': 0.18865383438247463}
2023-01-04 03:25:06,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:06,916 INFO:     Epoch: 76
2023-01-04 03:25:08,520 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48668281237284344, 'Total loss': 0.48668281237284344} | train loss {'Reaction outcome loss': 0.18795022634523256, 'Total loss': 0.18795022634523256}
2023-01-04 03:25:08,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:08,520 INFO:     Epoch: 77
2023-01-04 03:25:10,096 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4361392746369044, 'Total loss': 0.4361392746369044} | train loss {'Reaction outcome loss': 0.1885267666407994, 'Total loss': 0.1885267666407994}
2023-01-04 03:25:10,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:10,096 INFO:     Epoch: 78
2023-01-04 03:25:11,677 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4478033438324928, 'Total loss': 0.4478033438324928} | train loss {'Reaction outcome loss': 0.1882857907556625, 'Total loss': 0.1882857907556625}
2023-01-04 03:25:11,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:11,677 INFO:     Epoch: 79
2023-01-04 03:25:13,263 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4448777993520101, 'Total loss': 0.4448777993520101} | train loss {'Reaction outcome loss': 0.18770814846839495, 'Total loss': 0.18770814846839495}
2023-01-04 03:25:13,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:13,263 INFO:     Epoch: 80
2023-01-04 03:25:14,844 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45782794803380966, 'Total loss': 0.45782794803380966} | train loss {'Reaction outcome loss': 0.18514942652085326, 'Total loss': 0.18514942652085326}
2023-01-04 03:25:14,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:14,845 INFO:     Epoch: 81
2023-01-04 03:25:16,423 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4459188610315323, 'Total loss': 0.4459188610315323} | train loss {'Reaction outcome loss': 0.18227674135249175, 'Total loss': 0.18227674135249175}
2023-01-04 03:25:16,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:16,423 INFO:     Epoch: 82
2023-01-04 03:25:18,029 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4746420303980509, 'Total loss': 0.4746420303980509} | train loss {'Reaction outcome loss': 0.18258701818875778, 'Total loss': 0.18258701818875778}
2023-01-04 03:25:18,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:18,029 INFO:     Epoch: 83
2023-01-04 03:25:19,600 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48274513880411785, 'Total loss': 0.48274513880411785} | train loss {'Reaction outcome loss': 0.18300588233839898, 'Total loss': 0.18300588233839898}
2023-01-04 03:25:19,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:19,600 INFO:     Epoch: 84
2023-01-04 03:25:21,207 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5026919523874919, 'Total loss': 0.5026919523874919} | train loss {'Reaction outcome loss': 0.18112752766727092, 'Total loss': 0.18112752766727092}
2023-01-04 03:25:21,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:21,207 INFO:     Epoch: 85
2023-01-04 03:25:22,782 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47822951277097064, 'Total loss': 0.47822951277097064} | train loss {'Reaction outcome loss': 0.18035820935726601, 'Total loss': 0.18035820935726601}
2023-01-04 03:25:22,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:22,783 INFO:     Epoch: 86
2023-01-04 03:25:24,386 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4600960532824198, 'Total loss': 0.4600960532824198} | train loss {'Reaction outcome loss': 0.17751516497447906, 'Total loss': 0.17751516497447906}
2023-01-04 03:25:24,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:24,386 INFO:     Epoch: 87
2023-01-04 03:25:25,988 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48465240796407066, 'Total loss': 0.48465240796407066} | train loss {'Reaction outcome loss': 0.17871714662419352, 'Total loss': 0.17871714662419352}
2023-01-04 03:25:25,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:25,988 INFO:     Epoch: 88
2023-01-04 03:25:27,588 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46218928694725037, 'Total loss': 0.46218928694725037} | train loss {'Reaction outcome loss': 0.1773981809234008, 'Total loss': 0.1773981809234008}
2023-01-04 03:25:27,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:27,588 INFO:     Epoch: 89
2023-01-04 03:25:29,164 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4862524429957072, 'Total loss': 0.4862524429957072} | train loss {'Reaction outcome loss': 0.17690732267995676, 'Total loss': 0.17690732267995676}
2023-01-04 03:25:29,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:29,165 INFO:     Epoch: 90
2023-01-04 03:25:30,750 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.485963374376297, 'Total loss': 0.485963374376297} | train loss {'Reaction outcome loss': 0.17899543512271437, 'Total loss': 0.17899543512271437}
2023-01-04 03:25:30,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:30,750 INFO:     Epoch: 91
2023-01-04 03:25:32,336 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48249628245830534, 'Total loss': 0.48249628245830534} | train loss {'Reaction outcome loss': 0.17732210768448128, 'Total loss': 0.17732210768448128}
2023-01-04 03:25:32,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:32,336 INFO:     Epoch: 92
2023-01-04 03:25:33,918 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46638496418793995, 'Total loss': 0.46638496418793995} | train loss {'Reaction outcome loss': 0.17869313748983237, 'Total loss': 0.17869313748983237}
2023-01-04 03:25:33,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:33,919 INFO:     Epoch: 93
2023-01-04 03:25:35,524 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47463127275307976, 'Total loss': 0.47463127275307976} | train loss {'Reaction outcome loss': 0.17780931731993024, 'Total loss': 0.17780931731993024}
2023-01-04 03:25:35,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:35,524 INFO:     Epoch: 94
2023-01-04 03:25:37,110 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4578616201877594, 'Total loss': 0.4578616201877594} | train loss {'Reaction outcome loss': 0.17499818164691494, 'Total loss': 0.17499818164691494}
2023-01-04 03:25:37,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:37,110 INFO:     Epoch: 95
2023-01-04 03:25:38,712 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47109386722246804, 'Total loss': 0.47109386722246804} | train loss {'Reaction outcome loss': 0.1733694364872826, 'Total loss': 0.1733694364872826}
2023-01-04 03:25:38,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:38,712 INFO:     Epoch: 96
2023-01-04 03:25:40,295 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4532536367575328, 'Total loss': 0.4532536367575328} | train loss {'Reaction outcome loss': 0.16933851956557006, 'Total loss': 0.16933851956557006}
2023-01-04 03:25:40,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:40,295 INFO:     Epoch: 97
2023-01-04 03:25:41,899 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4785197486480077, 'Total loss': 0.4785197486480077} | train loss {'Reaction outcome loss': 0.1727340391328756, 'Total loss': 0.1727340391328756}
2023-01-04 03:25:41,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:41,899 INFO:     Epoch: 98
2023-01-04 03:25:43,508 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4707192291816076, 'Total loss': 0.4707192291816076} | train loss {'Reaction outcome loss': 0.17329369800253994, 'Total loss': 0.17329369800253994}
2023-01-04 03:25:43,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:43,508 INFO:     Epoch: 99
2023-01-04 03:25:45,090 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44805269440015155, 'Total loss': 0.44805269440015155} | train loss {'Reaction outcome loss': 0.17197071013787946, 'Total loss': 0.17197071013787946}
2023-01-04 03:25:45,090 INFO:     Best model found after epoch 52 of 100.
2023-01-04 03:25:45,091 INFO:   Done with stage: TRAINING
2023-01-04 03:25:45,091 INFO:   Starting stage: EVALUATION
2023-01-04 03:25:45,231 INFO:   Done with stage: EVALUATION
2023-01-04 03:25:45,232 INFO:   Leaving out SEQ value Fold_1
2023-01-04 03:25:45,244 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:25:45,244 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:25:45,898 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:25:45,899 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:25:45,967 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:25:45,967 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:25:45,967 INFO:     No hyperparam tuning for this model
2023-01-04 03:25:45,967 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:25:45,967 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:25:45,968 INFO:     None feature selector for col prot
2023-01-04 03:25:45,968 INFO:     None feature selector for col prot
2023-01-04 03:25:45,968 INFO:     None feature selector for col prot
2023-01-04 03:25:45,968 INFO:     None feature selector for col chem
2023-01-04 03:25:45,968 INFO:     None feature selector for col chem
2023-01-04 03:25:45,969 INFO:     None feature selector for col chem
2023-01-04 03:25:45,969 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:25:45,969 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:25:45,970 INFO:     Number of params in model 70141
2023-01-04 03:25:45,973 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:25:45,973 INFO:   Starting stage: TRAINING
2023-01-04 03:25:46,018 INFO:     Val loss before train {'Reaction outcome loss': 1.0404638449350994, 'Total loss': 1.0404638449350994}
2023-01-04 03:25:46,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:46,018 INFO:     Epoch: 0
2023-01-04 03:25:47,613 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7692679266134897, 'Total loss': 0.7692679266134897} | train loss {'Reaction outcome loss': 0.8713067889557746, 'Total loss': 0.8713067889557746}
2023-01-04 03:25:47,613 INFO:     Found new best model at epoch 0
2023-01-04 03:25:47,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:47,614 INFO:     Epoch: 1
2023-01-04 03:25:49,193 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6091779947280884, 'Total loss': 0.6091779947280884} | train loss {'Reaction outcome loss': 0.6444071957814521, 'Total loss': 0.6444071957814521}
2023-01-04 03:25:49,193 INFO:     Found new best model at epoch 1
2023-01-04 03:25:49,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:49,194 INFO:     Epoch: 2
2023-01-04 03:25:50,813 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5711389680703481, 'Total loss': 0.5711389680703481} | train loss {'Reaction outcome loss': 0.5474748263885082, 'Total loss': 0.5474748263885082}
2023-01-04 03:25:50,813 INFO:     Found new best model at epoch 2
2023-01-04 03:25:50,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:50,814 INFO:     Epoch: 3
2023-01-04 03:25:52,434 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5480534474054972, 'Total loss': 0.5480534474054972} | train loss {'Reaction outcome loss': 0.5071260680822467, 'Total loss': 0.5071260680822467}
2023-01-04 03:25:52,435 INFO:     Found new best model at epoch 3
2023-01-04 03:25:52,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:52,436 INFO:     Epoch: 4
2023-01-04 03:25:54,054 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5261941075325012, 'Total loss': 0.5261941075325012} | train loss {'Reaction outcome loss': 0.47345245562061883, 'Total loss': 0.47345245562061883}
2023-01-04 03:25:54,054 INFO:     Found new best model at epoch 4
2023-01-04 03:25:54,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:54,055 INFO:     Epoch: 5
2023-01-04 03:25:55,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5039564708868662, 'Total loss': 0.5039564708868662} | train loss {'Reaction outcome loss': 0.452577430943864, 'Total loss': 0.452577430943864}
2023-01-04 03:25:55,652 INFO:     Found new best model at epoch 5
2023-01-04 03:25:55,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:55,653 INFO:     Epoch: 6
2023-01-04 03:25:57,250 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5012383043766022, 'Total loss': 0.5012383043766022} | train loss {'Reaction outcome loss': 0.4358185106159552, 'Total loss': 0.4358185106159552}
2023-01-04 03:25:57,250 INFO:     Found new best model at epoch 6
2023-01-04 03:25:57,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:57,251 INFO:     Epoch: 7
2023-01-04 03:25:58,849 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4880660931269328, 'Total loss': 0.4880660931269328} | train loss {'Reaction outcome loss': 0.4196457415515476, 'Total loss': 0.4196457415515476}
2023-01-04 03:25:58,849 INFO:     Found new best model at epoch 7
2023-01-04 03:25:58,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:25:58,850 INFO:     Epoch: 8
2023-01-04 03:26:00,457 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48044989705085756, 'Total loss': 0.48044989705085756} | train loss {'Reaction outcome loss': 0.4376826301433038, 'Total loss': 0.4376826301433038}
2023-01-04 03:26:00,458 INFO:     Found new best model at epoch 8
2023-01-04 03:26:00,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:00,458 INFO:     Epoch: 9
2023-01-04 03:26:02,082 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46117211182912193, 'Total loss': 0.46117211182912193} | train loss {'Reaction outcome loss': 0.39979343003579887, 'Total loss': 0.39979343003579887}
2023-01-04 03:26:02,082 INFO:     Found new best model at epoch 9
2023-01-04 03:26:02,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:02,083 INFO:     Epoch: 10
2023-01-04 03:26:03,700 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4709619343280792, 'Total loss': 0.4709619343280792} | train loss {'Reaction outcome loss': 0.38694633060858113, 'Total loss': 0.38694633060858113}
2023-01-04 03:26:03,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:03,700 INFO:     Epoch: 11
2023-01-04 03:26:05,293 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46030200521151227, 'Total loss': 0.46030200521151227} | train loss {'Reaction outcome loss': 0.3769775061071783, 'Total loss': 0.3769775061071783}
2023-01-04 03:26:05,294 INFO:     Found new best model at epoch 11
2023-01-04 03:26:05,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:05,295 INFO:     Epoch: 12
2023-01-04 03:26:06,921 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46759551763534546, 'Total loss': 0.46759551763534546} | train loss {'Reaction outcome loss': 0.3871343821503114, 'Total loss': 0.3871343821503114}
2023-01-04 03:26:06,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:06,921 INFO:     Epoch: 13
2023-01-04 03:26:08,534 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4584390838940938, 'Total loss': 0.4584390838940938} | train loss {'Reaction outcome loss': 0.36904633757860766, 'Total loss': 0.36904633757860766}
2023-01-04 03:26:08,534 INFO:     Found new best model at epoch 13
2023-01-04 03:26:08,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:08,535 INFO:     Epoch: 14
2023-01-04 03:26:10,115 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4604866067568461, 'Total loss': 0.4604866067568461} | train loss {'Reaction outcome loss': 0.36037768472148024, 'Total loss': 0.36037768472148024}
2023-01-04 03:26:10,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:10,115 INFO:     Epoch: 15
2023-01-04 03:26:11,736 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46410467525323235, 'Total loss': 0.46410467525323235} | train loss {'Reaction outcome loss': 0.3630340339049049, 'Total loss': 0.3630340339049049}
2023-01-04 03:26:11,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:11,736 INFO:     Epoch: 16
2023-01-04 03:26:13,334 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45902936657269794, 'Total loss': 0.45902936657269794} | train loss {'Reaction outcome loss': 0.351726776920259, 'Total loss': 0.351726776920259}
2023-01-04 03:26:13,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:13,334 INFO:     Epoch: 17
2023-01-04 03:26:14,937 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46860792934894563, 'Total loss': 0.46860792934894563} | train loss {'Reaction outcome loss': 0.33614251210752444, 'Total loss': 0.33614251210752444}
2023-01-04 03:26:14,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:14,937 INFO:     Epoch: 18
2023-01-04 03:26:16,517 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46781538327534994, 'Total loss': 0.46781538327534994} | train loss {'Reaction outcome loss': 0.329778334206861, 'Total loss': 0.329778334206861}
2023-01-04 03:26:16,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:16,517 INFO:     Epoch: 19
2023-01-04 03:26:18,148 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4620957295099894, 'Total loss': 0.4620957295099894} | train loss {'Reaction outcome loss': 0.32572131196333876, 'Total loss': 0.32572131196333876}
2023-01-04 03:26:18,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:18,149 INFO:     Epoch: 20
2023-01-04 03:26:19,750 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45939980347951254, 'Total loss': 0.45939980347951254} | train loss {'Reaction outcome loss': 0.3211483476764482, 'Total loss': 0.3211483476764482}
2023-01-04 03:26:19,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:19,751 INFO:     Epoch: 21
2023-01-04 03:26:21,368 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4466105302174886, 'Total loss': 0.4466105302174886} | train loss {'Reaction outcome loss': 0.31462723933467374, 'Total loss': 0.31462723933467374}
2023-01-04 03:26:21,369 INFO:     Found new best model at epoch 21
2023-01-04 03:26:21,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:21,370 INFO:     Epoch: 22
2023-01-04 03:26:22,944 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43749307543039323, 'Total loss': 0.43749307543039323} | train loss {'Reaction outcome loss': 0.30926516627136996, 'Total loss': 0.30926516627136996}
2023-01-04 03:26:22,944 INFO:     Found new best model at epoch 22
2023-01-04 03:26:22,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:22,945 INFO:     Epoch: 23
2023-01-04 03:26:24,517 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46654456853866577, 'Total loss': 0.46654456853866577} | train loss {'Reaction outcome loss': 0.30535444070456846, 'Total loss': 0.30535444070456846}
2023-01-04 03:26:24,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:24,518 INFO:     Epoch: 24
2023-01-04 03:26:26,104 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4562399615844091, 'Total loss': 0.4562399615844091} | train loss {'Reaction outcome loss': 0.3006910069717391, 'Total loss': 0.3006910069717391}
2023-01-04 03:26:26,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:26,104 INFO:     Epoch: 25
2023-01-04 03:26:27,706 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45708384215831754, 'Total loss': 0.45708384215831754} | train loss {'Reaction outcome loss': 0.29547979621449905, 'Total loss': 0.29547979621449905}
2023-01-04 03:26:27,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:27,707 INFO:     Epoch: 26
2023-01-04 03:26:29,307 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46360910336176553, 'Total loss': 0.46360910336176553} | train loss {'Reaction outcome loss': 0.29337813463601947, 'Total loss': 0.29337813463601947}
2023-01-04 03:26:29,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:29,307 INFO:     Epoch: 27
2023-01-04 03:26:30,899 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45717901388804116, 'Total loss': 0.45717901388804116} | train loss {'Reaction outcome loss': 0.2901018744037635, 'Total loss': 0.2901018744037635}
2023-01-04 03:26:30,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:30,900 INFO:     Epoch: 28
2023-01-04 03:26:32,504 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45759056210517884, 'Total loss': 0.45759056210517884} | train loss {'Reaction outcome loss': 0.28547728856337135, 'Total loss': 0.28547728856337135}
2023-01-04 03:26:32,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:32,504 INFO:     Epoch: 29
2023-01-04 03:26:34,109 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4540329724550247, 'Total loss': 0.4540329724550247} | train loss {'Reaction outcome loss': 0.28385238657179085, 'Total loss': 0.28385238657179085}
2023-01-04 03:26:34,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:34,109 INFO:     Epoch: 30
2023-01-04 03:26:35,731 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45912181536356605, 'Total loss': 0.45912181536356605} | train loss {'Reaction outcome loss': 0.2901734706905225, 'Total loss': 0.2901734706905225}
2023-01-04 03:26:35,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:35,732 INFO:     Epoch: 31
2023-01-04 03:26:37,324 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46631593108177183, 'Total loss': 0.46631593108177183} | train loss {'Reaction outcome loss': 0.27714432658546645, 'Total loss': 0.27714432658546645}
2023-01-04 03:26:37,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:37,324 INFO:     Epoch: 32
2023-01-04 03:26:38,916 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46196866234143574, 'Total loss': 0.46196866234143574} | train loss {'Reaction outcome loss': 0.2717722184902084, 'Total loss': 0.2717722184902084}
2023-01-04 03:26:38,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:38,916 INFO:     Epoch: 33
2023-01-04 03:26:40,503 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4849816123644511, 'Total loss': 0.4849816123644511} | train loss {'Reaction outcome loss': 0.2712916970958231, 'Total loss': 0.2712916970958231}
2023-01-04 03:26:40,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:40,504 INFO:     Epoch: 34
2023-01-04 03:26:42,117 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44812529558936753, 'Total loss': 0.44812529558936753} | train loss {'Reaction outcome loss': 0.2656102629240933, 'Total loss': 0.2656102629240933}
2023-01-04 03:26:42,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:42,117 INFO:     Epoch: 35
2023-01-04 03:26:43,697 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4624206384023031, 'Total loss': 0.4624206384023031} | train loss {'Reaction outcome loss': 0.2629383856943552, 'Total loss': 0.2629383856943552}
2023-01-04 03:26:43,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:43,698 INFO:     Epoch: 36
2023-01-04 03:26:45,317 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4570607254902522, 'Total loss': 0.4570607254902522} | train loss {'Reaction outcome loss': 0.25938907652902266, 'Total loss': 0.25938907652902266}
2023-01-04 03:26:45,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:45,317 INFO:     Epoch: 37
2023-01-04 03:26:46,935 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44779932300249736, 'Total loss': 0.44779932300249736} | train loss {'Reaction outcome loss': 0.25724884984083474, 'Total loss': 0.25724884984083474}
2023-01-04 03:26:46,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:46,935 INFO:     Epoch: 38
2023-01-04 03:26:48,523 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4715296814839045, 'Total loss': 0.4715296814839045} | train loss {'Reaction outcome loss': 0.25405954998121527, 'Total loss': 0.25405954998121527}
2023-01-04 03:26:48,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:48,524 INFO:     Epoch: 39
2023-01-04 03:26:50,110 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4483435114224752, 'Total loss': 0.4483435114224752} | train loss {'Reaction outcome loss': 0.25302868254864047, 'Total loss': 0.25302868254864047}
2023-01-04 03:26:50,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:50,110 INFO:     Epoch: 40
2023-01-04 03:26:51,714 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4670159121354421, 'Total loss': 0.4670159121354421} | train loss {'Reaction outcome loss': 0.2503064090396156, 'Total loss': 0.2503064090396156}
2023-01-04 03:26:51,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:51,714 INFO:     Epoch: 41
2023-01-04 03:26:53,322 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4661230703194936, 'Total loss': 0.4661230703194936} | train loss {'Reaction outcome loss': 0.2480733787128027, 'Total loss': 0.2480733787128027}
2023-01-04 03:26:53,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:53,323 INFO:     Epoch: 42
2023-01-04 03:26:54,938 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4489417165517807, 'Total loss': 0.4489417165517807} | train loss {'Reaction outcome loss': 0.24959419954541154, 'Total loss': 0.24959419954541154}
2023-01-04 03:26:54,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:54,938 INFO:     Epoch: 43
2023-01-04 03:26:56,570 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44397924343744916, 'Total loss': 0.44397924343744916} | train loss {'Reaction outcome loss': 0.24089174880308734, 'Total loss': 0.24089174880308734}
2023-01-04 03:26:56,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:56,571 INFO:     Epoch: 44
2023-01-04 03:26:58,168 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44728981057802836, 'Total loss': 0.44728981057802836} | train loss {'Reaction outcome loss': 0.23864213231675988, 'Total loss': 0.23864213231675988}
2023-01-04 03:26:58,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:58,168 INFO:     Epoch: 45
2023-01-04 03:26:59,784 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4641997694969177, 'Total loss': 0.4641997694969177} | train loss {'Reaction outcome loss': 0.23766035060121016, 'Total loss': 0.23766035060121016}
2023-01-04 03:26:59,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:26:59,785 INFO:     Epoch: 46
2023-01-04 03:27:01,375 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4402747372786204, 'Total loss': 0.4402747372786204} | train loss {'Reaction outcome loss': 0.23529536340459137, 'Total loss': 0.23529536340459137}
2023-01-04 03:27:01,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:01,376 INFO:     Epoch: 47
2023-01-04 03:27:02,996 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43737010260423026, 'Total loss': 0.43737010260423026} | train loss {'Reaction outcome loss': 0.23437236314234527, 'Total loss': 0.23437236314234527}
2023-01-04 03:27:02,996 INFO:     Found new best model at epoch 47
2023-01-04 03:27:02,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:02,997 INFO:     Epoch: 48
2023-01-04 03:27:04,611 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45464102427164715, 'Total loss': 0.45464102427164715} | train loss {'Reaction outcome loss': 0.22918313391425688, 'Total loss': 0.22918313391425688}
2023-01-04 03:27:04,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:04,612 INFO:     Epoch: 49
2023-01-04 03:27:06,212 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44278428753217064, 'Total loss': 0.44278428753217064} | train loss {'Reaction outcome loss': 0.22897094785087352, 'Total loss': 0.22897094785087352}
2023-01-04 03:27:06,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:06,212 INFO:     Epoch: 50
2023-01-04 03:27:07,798 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4504124661286672, 'Total loss': 0.4504124661286672} | train loss {'Reaction outcome loss': 0.23297928067167167, 'Total loss': 0.23297928067167167}
2023-01-04 03:27:07,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:07,799 INFO:     Epoch: 51
2023-01-04 03:27:09,395 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45608299573262534, 'Total loss': 0.45608299573262534} | train loss {'Reaction outcome loss': 0.23058190803461964, 'Total loss': 0.23058190803461964}
2023-01-04 03:27:09,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:09,395 INFO:     Epoch: 52
2023-01-04 03:27:10,979 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4525610526402791, 'Total loss': 0.4525610526402791} | train loss {'Reaction outcome loss': 0.2242621022953139, 'Total loss': 0.2242621022953139}
2023-01-04 03:27:10,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:10,979 INFO:     Epoch: 53
2023-01-04 03:27:12,579 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4424984191854795, 'Total loss': 0.4424984191854795} | train loss {'Reaction outcome loss': 0.22201805727714943, 'Total loss': 0.22201805727714943}
2023-01-04 03:27:12,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:12,580 INFO:     Epoch: 54
2023-01-04 03:27:14,185 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47068131864070895, 'Total loss': 0.47068131864070895} | train loss {'Reaction outcome loss': 0.218448849638293, 'Total loss': 0.218448849638293}
2023-01-04 03:27:14,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:14,186 INFO:     Epoch: 55
2023-01-04 03:27:15,797 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4337680160999298, 'Total loss': 0.4337680160999298} | train loss {'Reaction outcome loss': 0.21814760689259224, 'Total loss': 0.21814760689259224}
2023-01-04 03:27:15,797 INFO:     Found new best model at epoch 55
2023-01-04 03:27:15,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:15,798 INFO:     Epoch: 56
2023-01-04 03:27:17,383 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43914383128285406, 'Total loss': 0.43914383128285406} | train loss {'Reaction outcome loss': 0.21725842605593387, 'Total loss': 0.21725842605593387}
2023-01-04 03:27:17,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:17,384 INFO:     Epoch: 57
2023-01-04 03:27:18,967 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43171411405007043, 'Total loss': 0.43171411405007043} | train loss {'Reaction outcome loss': 0.21485291191282263, 'Total loss': 0.21485291191282263}
2023-01-04 03:27:18,967 INFO:     Found new best model at epoch 57
2023-01-04 03:27:18,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:18,968 INFO:     Epoch: 58
2023-01-04 03:27:20,562 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4443217356999715, 'Total loss': 0.4443217356999715} | train loss {'Reaction outcome loss': 0.21559904957109172, 'Total loss': 0.21559904957109172}
2023-01-04 03:27:20,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:20,562 INFO:     Epoch: 59
2023-01-04 03:27:22,161 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4499682495991389, 'Total loss': 0.4499682495991389} | train loss {'Reaction outcome loss': 0.22093103089086388, 'Total loss': 0.22093103089086388}
2023-01-04 03:27:22,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:22,161 INFO:     Epoch: 60
2023-01-04 03:27:23,757 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4548234611749649, 'Total loss': 0.4548234611749649} | train loss {'Reaction outcome loss': 0.2174422666772127, 'Total loss': 0.2174422666772127}
2023-01-04 03:27:23,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:23,758 INFO:     Epoch: 61
2023-01-04 03:27:25,362 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4347281018892924, 'Total loss': 0.4347281018892924} | train loss {'Reaction outcome loss': 0.20792253356624485, 'Total loss': 0.20792253356624485}
2023-01-04 03:27:25,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:25,362 INFO:     Epoch: 62
2023-01-04 03:27:26,962 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4606809675693512, 'Total loss': 0.4606809675693512} | train loss {'Reaction outcome loss': 0.20386510572153266, 'Total loss': 0.20386510572153266}
2023-01-04 03:27:26,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:26,962 INFO:     Epoch: 63
2023-01-04 03:27:28,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4440833846728007, 'Total loss': 0.4440833846728007} | train loss {'Reaction outcome loss': 0.20450888117235425, 'Total loss': 0.20450888117235425}
2023-01-04 03:27:28,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:28,552 INFO:     Epoch: 64
2023-01-04 03:27:30,143 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4366559237241745, 'Total loss': 0.4366559237241745} | train loss {'Reaction outcome loss': 0.20181207017352185, 'Total loss': 0.20181207017352185}
2023-01-04 03:27:30,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:30,143 INFO:     Epoch: 65
2023-01-04 03:27:31,774 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42254379292329153, 'Total loss': 0.42254379292329153} | train loss {'Reaction outcome loss': 0.20026122077009254, 'Total loss': 0.20026122077009254}
2023-01-04 03:27:31,774 INFO:     Found new best model at epoch 65
2023-01-04 03:27:31,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:31,775 INFO:     Epoch: 66
2023-01-04 03:27:33,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43159319857756295, 'Total loss': 0.43159319857756295} | train loss {'Reaction outcome loss': 0.20029572408162968, 'Total loss': 0.20029572408162968}
2023-01-04 03:27:33,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:33,385 INFO:     Epoch: 67
2023-01-04 03:27:34,975 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4352167715628942, 'Total loss': 0.4352167715628942} | train loss {'Reaction outcome loss': 0.200439906274171, 'Total loss': 0.200439906274171}
2023-01-04 03:27:34,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:34,976 INFO:     Epoch: 68
2023-01-04 03:27:36,571 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4456232517957687, 'Total loss': 0.4456232517957687} | train loss {'Reaction outcome loss': 0.19733671907443498, 'Total loss': 0.19733671907443498}
2023-01-04 03:27:36,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:36,571 INFO:     Epoch: 69
2023-01-04 03:27:38,145 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44011520644028984, 'Total loss': 0.44011520644028984} | train loss {'Reaction outcome loss': 0.19820499786304857, 'Total loss': 0.19820499786304857}
2023-01-04 03:27:38,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:38,145 INFO:     Epoch: 70
2023-01-04 03:27:39,766 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46085784236590066, 'Total loss': 0.46085784236590066} | train loss {'Reaction outcome loss': 0.19239768955647352, 'Total loss': 0.19239768955647352}
2023-01-04 03:27:39,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:39,766 INFO:     Epoch: 71
2023-01-04 03:27:41,384 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45067904392878216, 'Total loss': 0.45067904392878216} | train loss {'Reaction outcome loss': 0.19811988210447296, 'Total loss': 0.19811988210447296}
2023-01-04 03:27:41,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:41,384 INFO:     Epoch: 72
2023-01-04 03:27:42,965 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46176073551177976, 'Total loss': 0.46176073551177976} | train loss {'Reaction outcome loss': 0.19240958389907947, 'Total loss': 0.19240958389907947}
2023-01-04 03:27:42,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:42,966 INFO:     Epoch: 73
2023-01-04 03:27:44,577 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4341876059770584, 'Total loss': 0.4341876059770584} | train loss {'Reaction outcome loss': 0.19254965144479513, 'Total loss': 0.19254965144479513}
2023-01-04 03:27:44,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:44,578 INFO:     Epoch: 74
2023-01-04 03:27:46,173 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45226851453383765, 'Total loss': 0.45226851453383765} | train loss {'Reaction outcome loss': 0.1905419807408707, 'Total loss': 0.1905419807408707}
2023-01-04 03:27:46,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:46,174 INFO:     Epoch: 75
2023-01-04 03:27:47,794 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.444752448797226, 'Total loss': 0.444752448797226} | train loss {'Reaction outcome loss': 0.1904915026065335, 'Total loss': 0.1904915026065335}
2023-01-04 03:27:47,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:47,795 INFO:     Epoch: 76
2023-01-04 03:27:49,408 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42664892425139744, 'Total loss': 0.42664892425139744} | train loss {'Reaction outcome loss': 0.18937294340719454, 'Total loss': 0.18937294340719454}
2023-01-04 03:27:49,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:49,409 INFO:     Epoch: 77
2023-01-04 03:27:51,030 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4171014199654261, 'Total loss': 0.4171014199654261} | train loss {'Reaction outcome loss': 0.18963952303148698, 'Total loss': 0.18963952303148698}
2023-01-04 03:27:51,030 INFO:     Found new best model at epoch 77
2023-01-04 03:27:51,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:51,031 INFO:     Epoch: 78
2023-01-04 03:27:52,623 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4488917390505473, 'Total loss': 0.4488917390505473} | train loss {'Reaction outcome loss': 0.18595356561675452, 'Total loss': 0.18595356561675452}
2023-01-04 03:27:52,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:52,623 INFO:     Epoch: 79
2023-01-04 03:27:54,221 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4414952983458837, 'Total loss': 0.4414952983458837} | train loss {'Reaction outcome loss': 0.18453549677371114, 'Total loss': 0.18453549677371114}
2023-01-04 03:27:54,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:54,221 INFO:     Epoch: 80
2023-01-04 03:27:55,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4386768122514089, 'Total loss': 0.4386768122514089} | train loss {'Reaction outcome loss': 0.18690681458494932, 'Total loss': 0.18690681458494932}
2023-01-04 03:27:55,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:55,811 INFO:     Epoch: 81
2023-01-04 03:27:57,428 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4710559407869975, 'Total loss': 0.4710559407869975} | train loss {'Reaction outcome loss': 0.1836790200120405, 'Total loss': 0.1836790200120405}
2023-01-04 03:27:57,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:57,428 INFO:     Epoch: 82
2023-01-04 03:27:59,048 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43520141740640006, 'Total loss': 0.43520141740640006} | train loss {'Reaction outcome loss': 0.18237225049423336, 'Total loss': 0.18237225049423336}
2023-01-04 03:27:59,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:27:59,049 INFO:     Epoch: 83
2023-01-04 03:28:00,671 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45383219917615253, 'Total loss': 0.45383219917615253} | train loss {'Reaction outcome loss': 0.18347126480353915, 'Total loss': 0.18347126480353915}
2023-01-04 03:28:00,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:00,671 INFO:     Epoch: 84
2023-01-04 03:28:02,249 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43078315208355583, 'Total loss': 0.43078315208355583} | train loss {'Reaction outcome loss': 0.17883854056197088, 'Total loss': 0.17883854056197088}
2023-01-04 03:28:02,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:02,249 INFO:     Epoch: 85
2023-01-04 03:28:03,836 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42285404056310655, 'Total loss': 0.42285404056310655} | train loss {'Reaction outcome loss': 0.17778633722185117, 'Total loss': 0.17778633722185117}
2023-01-04 03:28:03,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:03,836 INFO:     Epoch: 86
2023-01-04 03:28:05,444 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43668934106826784, 'Total loss': 0.43668934106826784} | train loss {'Reaction outcome loss': 0.179995856300883, 'Total loss': 0.179995856300883}
2023-01-04 03:28:05,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:05,445 INFO:     Epoch: 87
2023-01-04 03:28:07,040 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4412273108959198, 'Total loss': 0.4412273108959198} | train loss {'Reaction outcome loss': 0.17614754911187777, 'Total loss': 0.17614754911187777}
2023-01-04 03:28:07,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:07,040 INFO:     Epoch: 88
2023-01-04 03:28:08,662 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43136035799980166, 'Total loss': 0.43136035799980166} | train loss {'Reaction outcome loss': 0.1771770012146326, 'Total loss': 0.1771770012146326}
2023-01-04 03:28:08,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:08,662 INFO:     Epoch: 89
2023-01-04 03:28:10,242 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46888174811999, 'Total loss': 0.46888174811999} | train loss {'Reaction outcome loss': 0.17623812930685454, 'Total loss': 0.17623812930685454}
2023-01-04 03:28:10,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:10,243 INFO:     Epoch: 90
2023-01-04 03:28:11,843 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4504755824804306, 'Total loss': 0.4504755824804306} | train loss {'Reaction outcome loss': 0.17605957243443077, 'Total loss': 0.17605957243443077}
2023-01-04 03:28:11,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:11,843 INFO:     Epoch: 91
2023-01-04 03:28:13,422 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44223914941151937, 'Total loss': 0.44223914941151937} | train loss {'Reaction outcome loss': 0.17384216752058515, 'Total loss': 0.17384216752058515}
2023-01-04 03:28:13,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:13,422 INFO:     Epoch: 92
2023-01-04 03:28:15,046 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45216020693381626, 'Total loss': 0.45216020693381626} | train loss {'Reaction outcome loss': 0.1741400335247264, 'Total loss': 0.1741400335247264}
2023-01-04 03:28:15,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:15,046 INFO:     Epoch: 93
2023-01-04 03:28:16,664 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4347819526990255, 'Total loss': 0.4347819526990255} | train loss {'Reaction outcome loss': 0.17908351071874032, 'Total loss': 0.17908351071874032}
2023-01-04 03:28:16,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:16,664 INFO:     Epoch: 94
2023-01-04 03:28:18,278 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44490542511145276, 'Total loss': 0.44490542511145276} | train loss {'Reaction outcome loss': 0.1732394988378645, 'Total loss': 0.1732394988378645}
2023-01-04 03:28:18,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:18,279 INFO:     Epoch: 95
2023-01-04 03:28:19,860 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4550767163435618, 'Total loss': 0.4550767163435618} | train loss {'Reaction outcome loss': 0.17150065981527932, 'Total loss': 0.17150065981527932}
2023-01-04 03:28:19,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:19,860 INFO:     Epoch: 96
2023-01-04 03:28:21,476 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44406196400523185, 'Total loss': 0.44406196400523185} | train loss {'Reaction outcome loss': 0.17043454009842168, 'Total loss': 0.17043454009842168}
2023-01-04 03:28:21,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:21,476 INFO:     Epoch: 97
2023-01-04 03:28:23,075 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44329609274864196, 'Total loss': 0.44329609274864196} | train loss {'Reaction outcome loss': 0.1779714481284221, 'Total loss': 0.1779714481284221}
2023-01-04 03:28:23,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:23,076 INFO:     Epoch: 98
2023-01-04 03:28:24,699 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4426157623529434, 'Total loss': 0.4426157623529434} | train loss {'Reaction outcome loss': 0.1914210962873978, 'Total loss': 0.1914210962873978}
2023-01-04 03:28:24,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:24,699 INFO:     Epoch: 99
2023-01-04 03:28:26,279 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45241102079550427, 'Total loss': 0.45241102079550427} | train loss {'Reaction outcome loss': 0.16708593238159875, 'Total loss': 0.16708593238159875}
2023-01-04 03:28:26,279 INFO:     Best model found after epoch 78 of 100.
2023-01-04 03:28:26,279 INFO:   Done with stage: TRAINING
2023-01-04 03:28:26,279 INFO:   Starting stage: EVALUATION
2023-01-04 03:28:26,408 INFO:   Done with stage: EVALUATION
2023-01-04 03:28:26,408 INFO:   Leaving out SEQ value Fold_2
2023-01-04 03:28:26,421 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 03:28:26,421 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:28:27,078 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:28:27,078 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:28:27,146 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:28:27,146 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:28:27,146 INFO:     No hyperparam tuning for this model
2023-01-04 03:28:27,146 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:28:27,146 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:28:27,147 INFO:     None feature selector for col prot
2023-01-04 03:28:27,147 INFO:     None feature selector for col prot
2023-01-04 03:28:27,147 INFO:     None feature selector for col prot
2023-01-04 03:28:27,148 INFO:     None feature selector for col chem
2023-01-04 03:28:27,148 INFO:     None feature selector for col chem
2023-01-04 03:28:27,148 INFO:     None feature selector for col chem
2023-01-04 03:28:27,148 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:28:27,148 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:28:27,149 INFO:     Number of params in model 70141
2023-01-04 03:28:27,152 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:28:27,152 INFO:   Starting stage: TRAINING
2023-01-04 03:28:27,195 INFO:     Val loss before train {'Reaction outcome loss': 1.0101094404856363, 'Total loss': 1.0101094404856363}
2023-01-04 03:28:27,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:27,195 INFO:     Epoch: 0
2023-01-04 03:28:28,762 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6976684828599294, 'Total loss': 0.6976684828599294} | train loss {'Reaction outcome loss': 0.8740885842850793, 'Total loss': 0.8740885842850793}
2023-01-04 03:28:28,762 INFO:     Found new best model at epoch 0
2023-01-04 03:28:28,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:28,763 INFO:     Epoch: 1
2023-01-04 03:28:30,340 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5775715857744217, 'Total loss': 0.5775715857744217} | train loss {'Reaction outcome loss': 0.6331456846697426, 'Total loss': 0.6331456846697426}
2023-01-04 03:28:30,341 INFO:     Found new best model at epoch 1
2023-01-04 03:28:30,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:30,342 INFO:     Epoch: 2
2023-01-04 03:28:31,924 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5651268263657888, 'Total loss': 0.5651268263657888} | train loss {'Reaction outcome loss': 0.5551541336290129, 'Total loss': 0.5551541336290129}
2023-01-04 03:28:31,924 INFO:     Found new best model at epoch 2
2023-01-04 03:28:31,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:31,925 INFO:     Epoch: 3
2023-01-04 03:28:33,513 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5393806219100952, 'Total loss': 0.5393806219100952} | train loss {'Reaction outcome loss': 0.5088232574991254, 'Total loss': 0.5088232574991254}
2023-01-04 03:28:33,513 INFO:     Found new best model at epoch 3
2023-01-04 03:28:33,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:33,514 INFO:     Epoch: 4
2023-01-04 03:28:35,115 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5496208290259044, 'Total loss': 0.5496208290259044} | train loss {'Reaction outcome loss': 0.47600326045747204, 'Total loss': 0.47600326045747204}
2023-01-04 03:28:35,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:35,115 INFO:     Epoch: 5
2023-01-04 03:28:36,700 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5142229159673055, 'Total loss': 0.5142229159673055} | train loss {'Reaction outcome loss': 0.45764646774683243, 'Total loss': 0.45764646774683243}
2023-01-04 03:28:36,701 INFO:     Found new best model at epoch 5
2023-01-04 03:28:36,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:36,702 INFO:     Epoch: 6
2023-01-04 03:28:38,305 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4767783562342326, 'Total loss': 0.4767783562342326} | train loss {'Reaction outcome loss': 0.43842365873820616, 'Total loss': 0.43842365873820616}
2023-01-04 03:28:38,305 INFO:     Found new best model at epoch 6
2023-01-04 03:28:38,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:38,306 INFO:     Epoch: 7
2023-01-04 03:28:39,884 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46966026226679486, 'Total loss': 0.46966026226679486} | train loss {'Reaction outcome loss': 0.4248116707954651, 'Total loss': 0.4248116707954651}
2023-01-04 03:28:39,884 INFO:     Found new best model at epoch 7
2023-01-04 03:28:39,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:39,885 INFO:     Epoch: 8
2023-01-04 03:28:41,459 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4795624872048696, 'Total loss': 0.4795624872048696} | train loss {'Reaction outcome loss': 0.41348030060638874, 'Total loss': 0.41348030060638874}
2023-01-04 03:28:41,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:41,459 INFO:     Epoch: 9
2023-01-04 03:28:43,068 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.454079928000768, 'Total loss': 0.454079928000768} | train loss {'Reaction outcome loss': 0.403397768217347, 'Total loss': 0.403397768217347}
2023-01-04 03:28:43,069 INFO:     Found new best model at epoch 9
2023-01-04 03:28:43,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:43,069 INFO:     Epoch: 10
2023-01-04 03:28:44,672 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4569003343582153, 'Total loss': 0.4569003343582153} | train loss {'Reaction outcome loss': 0.39368826699453396, 'Total loss': 0.39368826699453396}
2023-01-04 03:28:44,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:44,672 INFO:     Epoch: 11
2023-01-04 03:28:46,252 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44023547768592836, 'Total loss': 0.44023547768592836} | train loss {'Reaction outcome loss': 0.38258242006703613, 'Total loss': 0.38258242006703613}
2023-01-04 03:28:46,253 INFO:     Found new best model at epoch 11
2023-01-04 03:28:46,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:46,254 INFO:     Epoch: 12
2023-01-04 03:28:47,827 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4396837999423345, 'Total loss': 0.4396837999423345} | train loss {'Reaction outcome loss': 0.37756540031332675, 'Total loss': 0.37756540031332675}
2023-01-04 03:28:47,827 INFO:     Found new best model at epoch 12
2023-01-04 03:28:47,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:47,828 INFO:     Epoch: 13
2023-01-04 03:28:49,403 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43974909782409666, 'Total loss': 0.43974909782409666} | train loss {'Reaction outcome loss': 0.3764433727050439, 'Total loss': 0.3764433727050439}
2023-01-04 03:28:49,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:49,403 INFO:     Epoch: 14
2023-01-04 03:28:51,002 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4460642735163371, 'Total loss': 0.4460642735163371} | train loss {'Reaction outcome loss': 0.3653254531351201, 'Total loss': 0.3653254531351201}
2023-01-04 03:28:51,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:51,002 INFO:     Epoch: 15
2023-01-04 03:28:52,607 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42719147304693855, 'Total loss': 0.42719147304693855} | train loss {'Reaction outcome loss': 0.35540188450516363, 'Total loss': 0.35540188450516363}
2023-01-04 03:28:52,607 INFO:     Found new best model at epoch 15
2023-01-04 03:28:52,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:52,608 INFO:     Epoch: 16
2023-01-04 03:28:54,210 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.442385200659434, 'Total loss': 0.442385200659434} | train loss {'Reaction outcome loss': 0.34995200023764655, 'Total loss': 0.34995200023764655}
2023-01-04 03:28:54,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:54,211 INFO:     Epoch: 17
2023-01-04 03:28:55,774 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.406495663523674, 'Total loss': 0.406495663523674} | train loss {'Reaction outcome loss': 0.3414780817134476, 'Total loss': 0.3414780817134476}
2023-01-04 03:28:55,774 INFO:     Found new best model at epoch 17
2023-01-04 03:28:55,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:55,775 INFO:     Epoch: 18
2023-01-04 03:28:57,347 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4147359112898509, 'Total loss': 0.4147359112898509} | train loss {'Reaction outcome loss': 0.3400270707714252, 'Total loss': 0.3400270707714252}
2023-01-04 03:28:57,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:57,347 INFO:     Epoch: 19
2023-01-04 03:28:58,910 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4079654355843862, 'Total loss': 0.4079654355843862} | train loss {'Reaction outcome loss': 0.33190950427900306, 'Total loss': 0.33190950427900306}
2023-01-04 03:28:58,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:28:58,910 INFO:     Epoch: 20
2023-01-04 03:29:00,487 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41416974465052286, 'Total loss': 0.41416974465052286} | train loss {'Reaction outcome loss': 0.3273245651588772, 'Total loss': 0.3273245651588772}
2023-01-04 03:29:00,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:00,488 INFO:     Epoch: 21
2023-01-04 03:29:02,063 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44473181466261547, 'Total loss': 0.44473181466261547} | train loss {'Reaction outcome loss': 0.32382787267367047, 'Total loss': 0.32382787267367047}
2023-01-04 03:29:02,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:02,063 INFO:     Epoch: 22
2023-01-04 03:29:03,630 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42130863666534424, 'Total loss': 0.42130863666534424} | train loss {'Reaction outcome loss': 0.3194040228568372, 'Total loss': 0.3194040228568372}
2023-01-04 03:29:03,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:03,630 INFO:     Epoch: 23
2023-01-04 03:29:05,205 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3899801845351855, 'Total loss': 0.3899801845351855} | train loss {'Reaction outcome loss': 0.3144578099141627, 'Total loss': 0.3144578099141627}
2023-01-04 03:29:05,205 INFO:     Found new best model at epoch 23
2023-01-04 03:29:05,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:05,206 INFO:     Epoch: 24
2023-01-04 03:29:06,761 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41910600463549297, 'Total loss': 0.41910600463549297} | train loss {'Reaction outcome loss': 0.30838258733679524, 'Total loss': 0.30838258733679524}
2023-01-04 03:29:06,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:06,762 INFO:     Epoch: 25
2023-01-04 03:29:08,369 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4218724280595779, 'Total loss': 0.4218724280595779} | train loss {'Reaction outcome loss': 0.3041855778831702, 'Total loss': 0.3041855778831702}
2023-01-04 03:29:08,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:08,369 INFO:     Epoch: 26
2023-01-04 03:29:09,973 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40893510182698567, 'Total loss': 0.40893510182698567} | train loss {'Reaction outcome loss': 0.30265434864130647, 'Total loss': 0.30265434864130647}
2023-01-04 03:29:09,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:09,973 INFO:     Epoch: 27
2023-01-04 03:29:11,576 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4144612103700638, 'Total loss': 0.4144612103700638} | train loss {'Reaction outcome loss': 0.29709477088117336, 'Total loss': 0.29709477088117336}
2023-01-04 03:29:11,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:11,576 INFO:     Epoch: 28
2023-01-04 03:29:13,140 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4109225789705912, 'Total loss': 0.4109225789705912} | train loss {'Reaction outcome loss': 0.29490309798128, 'Total loss': 0.29490309798128}
2023-01-04 03:29:13,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:13,140 INFO:     Epoch: 29
2023-01-04 03:29:14,743 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4119550347328186, 'Total loss': 0.4119550347328186} | train loss {'Reaction outcome loss': 0.28866457909127297, 'Total loss': 0.28866457909127297}
2023-01-04 03:29:14,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:14,743 INFO:     Epoch: 30
2023-01-04 03:29:16,327 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4075068324804306, 'Total loss': 0.4075068324804306} | train loss {'Reaction outcome loss': 0.2868535692766036, 'Total loss': 0.2868535692766036}
2023-01-04 03:29:16,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:16,327 INFO:     Epoch: 31
2023-01-04 03:29:17,925 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3845484291513761, 'Total loss': 0.3845484291513761} | train loss {'Reaction outcome loss': 0.2832416708789247, 'Total loss': 0.2832416708789247}
2023-01-04 03:29:17,925 INFO:     Found new best model at epoch 31
2023-01-04 03:29:17,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:17,926 INFO:     Epoch: 32
2023-01-04 03:29:19,529 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43695677220821383, 'Total loss': 0.43695677220821383} | train loss {'Reaction outcome loss': 0.27846339076839305, 'Total loss': 0.27846339076839305}
2023-01-04 03:29:19,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:19,530 INFO:     Epoch: 33
2023-01-04 03:29:21,134 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4184352229038874, 'Total loss': 0.4184352229038874} | train loss {'Reaction outcome loss': 0.2754327803304344, 'Total loss': 0.2754327803304344}
2023-01-04 03:29:21,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:21,134 INFO:     Epoch: 34
2023-01-04 03:29:22,698 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41358545819918313, 'Total loss': 0.41358545819918313} | train loss {'Reaction outcome loss': 0.2727244546834802, 'Total loss': 0.2727244546834802}
2023-01-04 03:29:22,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:22,698 INFO:     Epoch: 35
2023-01-04 03:29:24,269 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3877766380707423, 'Total loss': 0.3877766380707423} | train loss {'Reaction outcome loss': 0.2705958172296866, 'Total loss': 0.2705958172296866}
2023-01-04 03:29:24,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:24,269 INFO:     Epoch: 36
2023-01-04 03:29:25,856 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4132917513449987, 'Total loss': 0.4132917513449987} | train loss {'Reaction outcome loss': 0.2681619490704912, 'Total loss': 0.2681619490704912}
2023-01-04 03:29:25,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:25,857 INFO:     Epoch: 37
2023-01-04 03:29:27,463 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4024474730094274, 'Total loss': 0.4024474730094274} | train loss {'Reaction outcome loss': 0.26399116671129025, 'Total loss': 0.26399116671129025}
2023-01-04 03:29:27,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:27,464 INFO:     Epoch: 38
2023-01-04 03:29:29,068 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4080668012301127, 'Total loss': 0.4080668012301127} | train loss {'Reaction outcome loss': 0.26127975955332594, 'Total loss': 0.26127975955332594}
2023-01-04 03:29:29,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:29,068 INFO:     Epoch: 39
2023-01-04 03:29:30,647 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.407264123360316, 'Total loss': 0.407264123360316} | train loss {'Reaction outcome loss': 0.25771963656385305, 'Total loss': 0.25771963656385305}
2023-01-04 03:29:30,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:30,649 INFO:     Epoch: 40
2023-01-04 03:29:32,225 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40294281442960106, 'Total loss': 0.40294281442960106} | train loss {'Reaction outcome loss': 0.2544613021934207, 'Total loss': 0.2544613021934207}
2023-01-04 03:29:32,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:32,225 INFO:     Epoch: 41
2023-01-04 03:29:33,788 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4315443456172943, 'Total loss': 0.4315443456172943} | train loss {'Reaction outcome loss': 0.2526745871118792, 'Total loss': 0.2526745871118792}
2023-01-04 03:29:33,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:33,789 INFO:     Epoch: 42
2023-01-04 03:29:35,397 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4235407590866089, 'Total loss': 0.4235407590866089} | train loss {'Reaction outcome loss': 0.2501655150846247, 'Total loss': 0.2501655150846247}
2023-01-04 03:29:35,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:35,397 INFO:     Epoch: 43
2023-01-04 03:29:37,002 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40449112256368003, 'Total loss': 0.40449112256368003} | train loss {'Reaction outcome loss': 0.24579999471704164, 'Total loss': 0.24579999471704164}
2023-01-04 03:29:37,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:37,003 INFO:     Epoch: 44
2023-01-04 03:29:38,578 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4246925155321757, 'Total loss': 0.4246925155321757} | train loss {'Reaction outcome loss': 0.2453995153799162, 'Total loss': 0.2453995153799162}
2023-01-04 03:29:38,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:38,578 INFO:     Epoch: 45
2023-01-04 03:29:40,142 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4081424534320831, 'Total loss': 0.4081424534320831} | train loss {'Reaction outcome loss': 0.24416465853978864, 'Total loss': 0.24416465853978864}
2023-01-04 03:29:40,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:40,142 INFO:     Epoch: 46
2023-01-04 03:29:41,718 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.398451042175293, 'Total loss': 0.398451042175293} | train loss {'Reaction outcome loss': 0.24428858900026523, 'Total loss': 0.24428858900026523}
2023-01-04 03:29:41,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:41,718 INFO:     Epoch: 47
2023-01-04 03:29:43,292 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.417808535695076, 'Total loss': 0.417808535695076} | train loss {'Reaction outcome loss': 0.24113981133743084, 'Total loss': 0.24113981133743084}
2023-01-04 03:29:43,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:43,293 INFO:     Epoch: 48
2023-01-04 03:29:44,892 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40093911985556285, 'Total loss': 0.40093911985556285} | train loss {'Reaction outcome loss': 0.2378231412816397, 'Total loss': 0.2378231412816397}
2023-01-04 03:29:44,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:44,892 INFO:     Epoch: 49
2023-01-04 03:29:46,496 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4331544746955236, 'Total loss': 0.4331544746955236} | train loss {'Reaction outcome loss': 0.2336681862071757, 'Total loss': 0.2336681862071757}
2023-01-04 03:29:46,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:46,496 INFO:     Epoch: 50
2023-01-04 03:29:48,099 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4239940697948138, 'Total loss': 0.4239940697948138} | train loss {'Reaction outcome loss': 0.2315693714625233, 'Total loss': 0.2315693714625233}
2023-01-04 03:29:48,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:48,100 INFO:     Epoch: 51
2023-01-04 03:29:49,682 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42405633131663006, 'Total loss': 0.42405633131663006} | train loss {'Reaction outcome loss': 0.23311455465935088, 'Total loss': 0.23311455465935088}
2023-01-04 03:29:49,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:49,683 INFO:     Epoch: 52
2023-01-04 03:29:51,241 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3985312129060427, 'Total loss': 0.3985312129060427} | train loss {'Reaction outcome loss': 0.22968196576877392, 'Total loss': 0.22968196576877392}
2023-01-04 03:29:51,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:51,242 INFO:     Epoch: 53
2023-01-04 03:29:52,817 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4385895262161891, 'Total loss': 0.4385895262161891} | train loss {'Reaction outcome loss': 0.22780114772555593, 'Total loss': 0.22780114772555593}
2023-01-04 03:29:52,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:52,817 INFO:     Epoch: 54
2023-01-04 03:29:54,420 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4231448998053869, 'Total loss': 0.4231448998053869} | train loss {'Reaction outcome loss': 0.22396721247406232, 'Total loss': 0.22396721247406232}
2023-01-04 03:29:54,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:54,421 INFO:     Epoch: 55
2023-01-04 03:29:56,012 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41728191673755644, 'Total loss': 0.41728191673755644} | train loss {'Reaction outcome loss': 0.22392613638615433, 'Total loss': 0.22392613638615433}
2023-01-04 03:29:56,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:56,013 INFO:     Epoch: 56
2023-01-04 03:29:57,594 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4140850603580475, 'Total loss': 0.4140850603580475} | train loss {'Reaction outcome loss': 0.2220280731963369, 'Total loss': 0.2220280731963369}
2023-01-04 03:29:57,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:57,595 INFO:     Epoch: 57
2023-01-04 03:29:59,171 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4331463565429052, 'Total loss': 0.4331463565429052} | train loss {'Reaction outcome loss': 0.218822858913805, 'Total loss': 0.218822858913805}
2023-01-04 03:29:59,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:29:59,171 INFO:     Epoch: 58
2023-01-04 03:30:00,730 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4204359769821167, 'Total loss': 0.4204359769821167} | train loss {'Reaction outcome loss': 0.2164792823485839, 'Total loss': 0.2164792823485839}
2023-01-04 03:30:00,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:00,730 INFO:     Epoch: 59
2023-01-04 03:30:02,306 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.433032896121343, 'Total loss': 0.433032896121343} | train loss {'Reaction outcome loss': 0.216558950240195, 'Total loss': 0.216558950240195}
2023-01-04 03:30:02,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:02,306 INFO:     Epoch: 60
2023-01-04 03:30:03,881 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40456309417883557, 'Total loss': 0.40456309417883557} | train loss {'Reaction outcome loss': 0.21630526752971904, 'Total loss': 0.21630526752971904}
2023-01-04 03:30:03,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:03,882 INFO:     Epoch: 61
2023-01-04 03:30:05,455 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41662211418151857, 'Total loss': 0.41662211418151857} | train loss {'Reaction outcome loss': 0.21563300433749463, 'Total loss': 0.21563300433749463}
2023-01-04 03:30:05,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:05,455 INFO:     Epoch: 62
2023-01-04 03:30:07,029 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43805650969346366, 'Total loss': 0.43805650969346366} | train loss {'Reaction outcome loss': 0.21273420976249727, 'Total loss': 0.21273420976249727}
2023-01-04 03:30:07,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:07,030 INFO:     Epoch: 63
2023-01-04 03:30:08,591 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41203946073849995, 'Total loss': 0.41203946073849995} | train loss {'Reaction outcome loss': 0.21067038918043668, 'Total loss': 0.21067038918043668}
2023-01-04 03:30:08,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:08,591 INFO:     Epoch: 64
2023-01-04 03:30:10,175 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4428673654794693, 'Total loss': 0.4428673654794693} | train loss {'Reaction outcome loss': 0.2106673241603178, 'Total loss': 0.2106673241603178}
2023-01-04 03:30:10,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:10,176 INFO:     Epoch: 65
2023-01-04 03:30:11,780 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4371727337439855, 'Total loss': 0.4371727337439855} | train loss {'Reaction outcome loss': 0.2100202467142444, 'Total loss': 0.2100202467142444}
2023-01-04 03:30:11,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:11,780 INFO:     Epoch: 66
2023-01-04 03:30:13,383 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4456832547982534, 'Total loss': 0.4456832547982534} | train loss {'Reaction outcome loss': 0.20430994534996363, 'Total loss': 0.20430994534996363}
2023-01-04 03:30:13,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:13,384 INFO:     Epoch: 67
2023-01-04 03:30:14,948 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4113894542058309, 'Total loss': 0.4113894542058309} | train loss {'Reaction outcome loss': 0.20400023299027167, 'Total loss': 0.20400023299027167}
2023-01-04 03:30:14,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:14,948 INFO:     Epoch: 68
2023-01-04 03:30:16,511 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4435180803140005, 'Total loss': 0.4435180803140005} | train loss {'Reaction outcome loss': 0.20667875258613638, 'Total loss': 0.20667875258613638}
2023-01-04 03:30:16,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:16,511 INFO:     Epoch: 69
2023-01-04 03:30:18,082 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4399349371592204, 'Total loss': 0.4399349371592204} | train loss {'Reaction outcome loss': 0.20188674509470717, 'Total loss': 0.20188674509470717}
2023-01-04 03:30:18,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:18,082 INFO:     Epoch: 70
2023-01-04 03:30:19,644 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4066427856683731, 'Total loss': 0.4066427856683731} | train loss {'Reaction outcome loss': 0.20043692174248207, 'Total loss': 0.20043692174248207}
2023-01-04 03:30:19,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:19,644 INFO:     Epoch: 71
2023-01-04 03:30:21,219 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46032894452412926, 'Total loss': 0.46032894452412926} | train loss {'Reaction outcome loss': 0.19958045711611216, 'Total loss': 0.19958045711611216}
2023-01-04 03:30:21,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:21,219 INFO:     Epoch: 72
2023-01-04 03:30:22,793 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.427070670388639, 'Total loss': 0.427070670388639} | train loss {'Reaction outcome loss': 0.20004570867607008, 'Total loss': 0.20004570867607008}
2023-01-04 03:30:22,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:22,793 INFO:     Epoch: 73
2023-01-04 03:30:24,349 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4352313036719958, 'Total loss': 0.4352313036719958} | train loss {'Reaction outcome loss': 0.20046165581424158, 'Total loss': 0.20046165581424158}
2023-01-04 03:30:24,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:24,349 INFO:     Epoch: 74
2023-01-04 03:30:25,961 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45583743453025816, 'Total loss': 0.45583743453025816} | train loss {'Reaction outcome loss': 0.19617955288900943, 'Total loss': 0.19617955288900943}
2023-01-04 03:30:25,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:25,962 INFO:     Epoch: 75
2023-01-04 03:30:27,539 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41860078771909076, 'Total loss': 0.41860078771909076} | train loss {'Reaction outcome loss': 0.19236951105760566, 'Total loss': 0.19236951105760566}
2023-01-04 03:30:27,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:27,539 INFO:     Epoch: 76
2023-01-04 03:30:29,116 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4271029363075892, 'Total loss': 0.4271029363075892} | train loss {'Reaction outcome loss': 0.19683918028032824, 'Total loss': 0.19683918028032824}
2023-01-04 03:30:29,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:29,117 INFO:     Epoch: 77
2023-01-04 03:30:30,696 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47000725169976554, 'Total loss': 0.47000725169976554} | train loss {'Reaction outcome loss': 0.19500789658299514, 'Total loss': 0.19500789658299514}
2023-01-04 03:30:30,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:30,696 INFO:     Epoch: 78
2023-01-04 03:30:32,274 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4492111245791117, 'Total loss': 0.4492111245791117} | train loss {'Reaction outcome loss': 0.19045178848745187, 'Total loss': 0.19045178848745187}
2023-01-04 03:30:32,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:32,274 INFO:     Epoch: 79
2023-01-04 03:30:33,839 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44632567663987477, 'Total loss': 0.44632567663987477} | train loss {'Reaction outcome loss': 0.187584721302484, 'Total loss': 0.187584721302484}
2023-01-04 03:30:33,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:33,839 INFO:     Epoch: 80
2023-01-04 03:30:35,418 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48284726639588677, 'Total loss': 0.48284726639588677} | train loss {'Reaction outcome loss': 0.19078553159594971, 'Total loss': 0.19078553159594971}
2023-01-04 03:30:35,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:35,418 INFO:     Epoch: 81
2023-01-04 03:30:36,974 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44763242105642953, 'Total loss': 0.44763242105642953} | train loss {'Reaction outcome loss': 0.1887070854286571, 'Total loss': 0.1887070854286571}
2023-01-04 03:30:36,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:36,975 INFO:     Epoch: 82
2023-01-04 03:30:38,577 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4353899528582891, 'Total loss': 0.4353899528582891} | train loss {'Reaction outcome loss': 0.1902090068838317, 'Total loss': 0.1902090068838317}
2023-01-04 03:30:38,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:38,579 INFO:     Epoch: 83
2023-01-04 03:30:40,180 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46189072330792746, 'Total loss': 0.46189072330792746} | train loss {'Reaction outcome loss': 0.18626356223127344, 'Total loss': 0.18626356223127344}
2023-01-04 03:30:40,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:40,180 INFO:     Epoch: 84
2023-01-04 03:30:41,782 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4469215710957845, 'Total loss': 0.4469215710957845} | train loss {'Reaction outcome loss': 0.18521271752459662, 'Total loss': 0.18521271752459662}
2023-01-04 03:30:41,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:41,783 INFO:     Epoch: 85
2023-01-04 03:30:43,347 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4835800806681315, 'Total loss': 0.4835800806681315} | train loss {'Reaction outcome loss': 0.18571212149528793, 'Total loss': 0.18571212149528793}
2023-01-04 03:30:43,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:43,347 INFO:     Epoch: 86
2023-01-04 03:30:44,917 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47695763806502023, 'Total loss': 0.47695763806502023} | train loss {'Reaction outcome loss': 0.18637147921754982, 'Total loss': 0.18637147921754982}
2023-01-04 03:30:44,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:44,918 INFO:     Epoch: 87
2023-01-04 03:30:46,480 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44119295875231423, 'Total loss': 0.44119295875231423} | train loss {'Reaction outcome loss': 0.1837491875466628, 'Total loss': 0.1837491875466628}
2023-01-04 03:30:46,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:46,480 INFO:     Epoch: 88
2023-01-04 03:30:48,046 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46650187770525614, 'Total loss': 0.46650187770525614} | train loss {'Reaction outcome loss': 0.18474527588284714, 'Total loss': 0.18474527588284714}
2023-01-04 03:30:48,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:48,046 INFO:     Epoch: 89
2023-01-04 03:30:49,649 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.484418660402298, 'Total loss': 0.484418660402298} | train loss {'Reaction outcome loss': 0.18140346582828862, 'Total loss': 0.18140346582828862}
2023-01-04 03:30:49,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:49,649 INFO:     Epoch: 90
2023-01-04 03:30:51,209 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45170752008756004, 'Total loss': 0.45170752008756004} | train loss {'Reaction outcome loss': 0.18166597244148944, 'Total loss': 0.18166597244148944}
2023-01-04 03:30:51,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:51,209 INFO:     Epoch: 91
2023-01-04 03:30:52,787 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4730844646692276, 'Total loss': 0.4730844646692276} | train loss {'Reaction outcome loss': 0.18279103693235052, 'Total loss': 0.18279103693235052}
2023-01-04 03:30:52,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:52,787 INFO:     Epoch: 92
2023-01-04 03:30:54,358 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44610169182221093, 'Total loss': 0.44610169182221093} | train loss {'Reaction outcome loss': 0.1783895581796929, 'Total loss': 0.1783895581796929}
2023-01-04 03:30:54,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:54,358 INFO:     Epoch: 93
2023-01-04 03:30:55,971 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4309677542808155, 'Total loss': 0.4309677542808155} | train loss {'Reaction outcome loss': 0.18055944862492354, 'Total loss': 0.18055944862492354}
2023-01-04 03:30:55,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:55,971 INFO:     Epoch: 94
2023-01-04 03:30:57,591 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47419897516568504, 'Total loss': 0.47419897516568504} | train loss {'Reaction outcome loss': 0.1795278767758346, 'Total loss': 0.1795278767758346}
2023-01-04 03:30:57,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:57,592 INFO:     Epoch: 95
2023-01-04 03:30:59,219 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4399670844276746, 'Total loss': 0.4399670844276746} | train loss {'Reaction outcome loss': 0.17709644668268196, 'Total loss': 0.17709644668268196}
2023-01-04 03:30:59,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:30:59,219 INFO:     Epoch: 96
2023-01-04 03:31:00,799 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4453602333863576, 'Total loss': 0.4453602333863576} | train loss {'Reaction outcome loss': 0.17922805603798275, 'Total loss': 0.17922805603798275}
2023-01-04 03:31:00,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:00,799 INFO:     Epoch: 97
2023-01-04 03:31:02,371 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4848037014404933, 'Total loss': 0.4848037014404933} | train loss {'Reaction outcome loss': 0.17888307703774928, 'Total loss': 0.17888307703774928}
2023-01-04 03:31:02,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:02,372 INFO:     Epoch: 98
2023-01-04 03:31:03,945 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4765776331226031, 'Total loss': 0.4765776331226031} | train loss {'Reaction outcome loss': 0.174388870248919, 'Total loss': 0.174388870248919}
2023-01-04 03:31:03,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:03,945 INFO:     Epoch: 99
2023-01-04 03:31:05,550 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4897184868653615, 'Total loss': 0.4897184868653615} | train loss {'Reaction outcome loss': 0.17391544480163318, 'Total loss': 0.17391544480163318}
2023-01-04 03:31:05,550 INFO:     Best model found after epoch 32 of 100.
2023-01-04 03:31:05,550 INFO:   Done with stage: TRAINING
2023-01-04 03:31:05,550 INFO:   Starting stage: EVALUATION
2023-01-04 03:31:05,690 INFO:   Done with stage: EVALUATION
2023-01-04 03:31:05,690 INFO:   Leaving out SEQ value Fold_3
2023-01-04 03:31:05,703 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 03:31:05,703 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:31:06,349 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:31:06,349 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:31:06,416 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:31:06,416 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:31:06,416 INFO:     No hyperparam tuning for this model
2023-01-04 03:31:06,416 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:31:06,416 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:31:06,417 INFO:     None feature selector for col prot
2023-01-04 03:31:06,417 INFO:     None feature selector for col prot
2023-01-04 03:31:06,417 INFO:     None feature selector for col prot
2023-01-04 03:31:06,417 INFO:     None feature selector for col chem
2023-01-04 03:31:06,418 INFO:     None feature selector for col chem
2023-01-04 03:31:06,418 INFO:     None feature selector for col chem
2023-01-04 03:31:06,418 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:31:06,418 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:31:06,419 INFO:     Number of params in model 70141
2023-01-04 03:31:06,422 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:31:06,422 INFO:   Starting stage: TRAINING
2023-01-04 03:31:06,466 INFO:     Val loss before train {'Reaction outcome loss': 0.9936837355295817, 'Total loss': 0.9936837355295817}
2023-01-04 03:31:06,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:06,466 INFO:     Epoch: 0
2023-01-04 03:31:08,018 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6539287010828654, 'Total loss': 0.6539287010828654} | train loss {'Reaction outcome loss': 0.8704615666417618, 'Total loss': 0.8704615666417618}
2023-01-04 03:31:08,018 INFO:     Found new best model at epoch 0
2023-01-04 03:31:08,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:08,019 INFO:     Epoch: 1
2023-01-04 03:31:09,578 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4824703216552734, 'Total loss': 0.4824703216552734} | train loss {'Reaction outcome loss': 0.6215473251809054, 'Total loss': 0.6215473251809054}
2023-01-04 03:31:09,578 INFO:     Found new best model at epoch 1
2023-01-04 03:31:09,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:09,579 INFO:     Epoch: 2
2023-01-04 03:31:11,140 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46404992739359535, 'Total loss': 0.46404992739359535} | train loss {'Reaction outcome loss': 0.5203314590168175, 'Total loss': 0.5203314590168175}
2023-01-04 03:31:11,140 INFO:     Found new best model at epoch 2
2023-01-04 03:31:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:11,141 INFO:     Epoch: 3
2023-01-04 03:31:12,703 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44263397057851156, 'Total loss': 0.44263397057851156} | train loss {'Reaction outcome loss': 0.4716458189751389, 'Total loss': 0.4716458189751389}
2023-01-04 03:31:12,703 INFO:     Found new best model at epoch 3
2023-01-04 03:31:12,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:12,704 INFO:     Epoch: 4
2023-01-04 03:31:14,297 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4177342419823011, 'Total loss': 0.4177342419823011} | train loss {'Reaction outcome loss': 0.4444144704135142, 'Total loss': 0.4444144704135142}
2023-01-04 03:31:14,298 INFO:     Found new best model at epoch 4
2023-01-04 03:31:14,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:14,300 INFO:     Epoch: 5
2023-01-04 03:31:15,891 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4109316805998484, 'Total loss': 0.4109316805998484} | train loss {'Reaction outcome loss': 0.4227232042273912, 'Total loss': 0.4227232042273912}
2023-01-04 03:31:15,892 INFO:     Found new best model at epoch 5
2023-01-04 03:31:15,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:15,892 INFO:     Epoch: 6
2023-01-04 03:31:17,494 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42450283964474994, 'Total loss': 0.42450283964474994} | train loss {'Reaction outcome loss': 0.40919043085231993, 'Total loss': 0.40919043085231993}
2023-01-04 03:31:17,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:17,494 INFO:     Epoch: 7
2023-01-04 03:31:19,061 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4120811015367508, 'Total loss': 0.4120811015367508} | train loss {'Reaction outcome loss': 0.3950188749940633, 'Total loss': 0.3950188749940633}
2023-01-04 03:31:19,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:19,061 INFO:     Epoch: 8
2023-01-04 03:31:20,611 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4030651787916819, 'Total loss': 0.4030651787916819} | train loss {'Reaction outcome loss': 0.38469240041896424, 'Total loss': 0.38469240041896424}
2023-01-04 03:31:20,612 INFO:     Found new best model at epoch 8
2023-01-04 03:31:20,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:20,613 INFO:     Epoch: 9
2023-01-04 03:31:22,223 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.414122990767161, 'Total loss': 0.414122990767161} | train loss {'Reaction outcome loss': 0.37348749659048236, 'Total loss': 0.37348749659048236}
2023-01-04 03:31:22,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:22,223 INFO:     Epoch: 10
2023-01-04 03:31:23,830 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4035526712735494, 'Total loss': 0.4035526712735494} | train loss {'Reaction outcome loss': 0.3628009625356576, 'Total loss': 0.3628009625356576}
2023-01-04 03:31:23,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:23,830 INFO:     Epoch: 11
2023-01-04 03:31:25,437 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39856040676434834, 'Total loss': 0.39856040676434834} | train loss {'Reaction outcome loss': 0.3543369953977666, 'Total loss': 0.3543369953977666}
2023-01-04 03:31:25,437 INFO:     Found new best model at epoch 11
2023-01-04 03:31:25,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:25,438 INFO:     Epoch: 12
2023-01-04 03:31:27,011 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3772240827480952, 'Total loss': 0.3772240827480952} | train loss {'Reaction outcome loss': 0.3443681186553077, 'Total loss': 0.3443681186553077}
2023-01-04 03:31:27,011 INFO:     Found new best model at epoch 12
2023-01-04 03:31:27,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:27,012 INFO:     Epoch: 13
2023-01-04 03:31:28,608 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37779411375522615, 'Total loss': 0.37779411375522615} | train loss {'Reaction outcome loss': 0.3405559481125036, 'Total loss': 0.3405559481125036}
2023-01-04 03:31:28,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:28,609 INFO:     Epoch: 14
2023-01-04 03:31:30,170 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3658124526341756, 'Total loss': 0.3658124526341756} | train loss {'Reaction outcome loss': 0.3336264766010411, 'Total loss': 0.3336264766010411}
2023-01-04 03:31:30,170 INFO:     Found new best model at epoch 14
2023-01-04 03:31:30,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:30,171 INFO:     Epoch: 15
2023-01-04 03:31:31,742 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3685442693531513, 'Total loss': 0.3685442693531513} | train loss {'Reaction outcome loss': 0.3243030672033774, 'Total loss': 0.3243030672033774}
2023-01-04 03:31:31,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:31,743 INFO:     Epoch: 16
2023-01-04 03:31:33,316 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3917338122924169, 'Total loss': 0.3917338122924169} | train loss {'Reaction outcome loss': 0.3191529272667156, 'Total loss': 0.3191529272667156}
2023-01-04 03:31:33,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:33,317 INFO:     Epoch: 17
2023-01-04 03:31:34,889 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38562205334504446, 'Total loss': 0.38562205334504446} | train loss {'Reaction outcome loss': 0.3130335503178769, 'Total loss': 0.3130335503178769}
2023-01-04 03:31:34,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:34,890 INFO:     Epoch: 18
2023-01-04 03:31:36,444 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39335607091585795, 'Total loss': 0.39335607091585795} | train loss {'Reaction outcome loss': 0.3065636825792464, 'Total loss': 0.3065636825792464}
2023-01-04 03:31:36,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:36,445 INFO:     Epoch: 19
2023-01-04 03:31:38,017 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3698406368494034, 'Total loss': 0.3698406368494034} | train loss {'Reaction outcome loss': 0.30180446264708616, 'Total loss': 0.30180446264708616}
2023-01-04 03:31:38,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:38,017 INFO:     Epoch: 20
2023-01-04 03:31:39,582 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3739366888999939, 'Total loss': 0.3739366888999939} | train loss {'Reaction outcome loss': 0.29673366713237936, 'Total loss': 0.29673366713237936}
2023-01-04 03:31:39,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:39,583 INFO:     Epoch: 21
2023-01-04 03:31:41,179 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3602354695399602, 'Total loss': 0.3602354695399602} | train loss {'Reaction outcome loss': 0.29090900199549663, 'Total loss': 0.29090900199549663}
2023-01-04 03:31:41,180 INFO:     Found new best model at epoch 21
2023-01-04 03:31:41,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:41,180 INFO:     Epoch: 22
2023-01-04 03:31:42,770 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3690873881181081, 'Total loss': 0.3690873881181081} | train loss {'Reaction outcome loss': 0.2863348580319503, 'Total loss': 0.2863348580319503}
2023-01-04 03:31:42,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:42,770 INFO:     Epoch: 23
2023-01-04 03:31:44,359 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3699766864379247, 'Total loss': 0.3699766864379247} | train loss {'Reaction outcome loss': 0.2814729409464171, 'Total loss': 0.2814729409464171}
2023-01-04 03:31:44,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:44,360 INFO:     Epoch: 24
2023-01-04 03:31:45,914 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.34460145731767017, 'Total loss': 0.34460145731767017} | train loss {'Reaction outcome loss': 0.27594004095810365, 'Total loss': 0.27594004095810365}
2023-01-04 03:31:45,915 INFO:     Found new best model at epoch 24
2023-01-04 03:31:45,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:45,915 INFO:     Epoch: 25
2023-01-04 03:31:47,507 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3531532679994901, 'Total loss': 0.3531532679994901} | train loss {'Reaction outcome loss': 0.2735857604641976, 'Total loss': 0.2735857604641976}
2023-01-04 03:31:47,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:47,507 INFO:     Epoch: 26
2023-01-04 03:31:49,092 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.355702339609464, 'Total loss': 0.355702339609464} | train loss {'Reaction outcome loss': 0.2701447910983184, 'Total loss': 0.2701447910983184}
2023-01-04 03:31:49,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:49,093 INFO:     Epoch: 27
2023-01-04 03:31:50,695 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38028080662091573, 'Total loss': 0.38028080662091573} | train loss {'Reaction outcome loss': 0.26668228844105096, 'Total loss': 0.26668228844105096}
2023-01-04 03:31:50,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:50,695 INFO:     Epoch: 28
2023-01-04 03:31:52,281 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3911179234584173, 'Total loss': 0.3911179234584173} | train loss {'Reaction outcome loss': 0.260212727495885, 'Total loss': 0.260212727495885}
2023-01-04 03:31:52,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:52,281 INFO:     Epoch: 29
2023-01-04 03:31:53,847 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36368541220823924, 'Total loss': 0.36368541220823924} | train loss {'Reaction outcome loss': 0.2566985956967097, 'Total loss': 0.2566985956967097}
2023-01-04 03:31:53,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:53,848 INFO:     Epoch: 30
2023-01-04 03:31:55,420 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3711657504240672, 'Total loss': 0.3711657504240672} | train loss {'Reaction outcome loss': 0.25356821230581766, 'Total loss': 0.25356821230581766}
2023-01-04 03:31:55,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:55,420 INFO:     Epoch: 31
2023-01-04 03:31:56,970 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3708795815706253, 'Total loss': 0.3708795815706253} | train loss {'Reaction outcome loss': 0.25378550591833915, 'Total loss': 0.25378550591833915}
2023-01-04 03:31:56,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:56,970 INFO:     Epoch: 32
2023-01-04 03:31:58,577 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35851664406557876, 'Total loss': 0.35851664406557876} | train loss {'Reaction outcome loss': 0.2481020709630308, 'Total loss': 0.2481020709630308}
2023-01-04 03:31:58,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:31:58,578 INFO:     Epoch: 33
2023-01-04 03:32:00,178 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.380097567041715, 'Total loss': 0.380097567041715} | train loss {'Reaction outcome loss': 0.24595752633365758, 'Total loss': 0.24595752633365758}
2023-01-04 03:32:00,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:00,178 INFO:     Epoch: 34
2023-01-04 03:32:01,777 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.35639611383279163, 'Total loss': 0.35639611383279163} | train loss {'Reaction outcome loss': 0.24145358399491468, 'Total loss': 0.24145358399491468}
2023-01-04 03:32:01,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:01,777 INFO:     Epoch: 35
2023-01-04 03:32:03,344 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3481976052125295, 'Total loss': 0.3481976052125295} | train loss {'Reaction outcome loss': 0.23777774053306158, 'Total loss': 0.23777774053306158}
2023-01-04 03:32:03,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:03,344 INFO:     Epoch: 36
2023-01-04 03:32:04,932 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3649631867806117, 'Total loss': 0.3649631867806117} | train loss {'Reaction outcome loss': 0.23668628038900366, 'Total loss': 0.23668628038900366}
2023-01-04 03:32:04,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:04,932 INFO:     Epoch: 37
2023-01-04 03:32:06,476 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36591818034648893, 'Total loss': 0.36591818034648893} | train loss {'Reaction outcome loss': 0.23294404582068928, 'Total loss': 0.23294404582068928}
2023-01-04 03:32:06,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:06,476 INFO:     Epoch: 38
2023-01-04 03:32:08,038 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3508231562872728, 'Total loss': 0.3508231562872728} | train loss {'Reaction outcome loss': 0.2305674990054866, 'Total loss': 0.2305674990054866}
2023-01-04 03:32:08,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:08,039 INFO:     Epoch: 39
2023-01-04 03:32:09,594 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.349198838075002, 'Total loss': 0.349198838075002} | train loss {'Reaction outcome loss': 0.22772471883035234, 'Total loss': 0.22772471883035234}
2023-01-04 03:32:09,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:09,595 INFO:     Epoch: 40
2023-01-04 03:32:11,184 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38851193686326346, 'Total loss': 0.38851193686326346} | train loss {'Reaction outcome loss': 0.22567156247272263, 'Total loss': 0.22567156247272263}
2023-01-04 03:32:11,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:11,184 INFO:     Epoch: 41
2023-01-04 03:32:12,745 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3677962988615036, 'Total loss': 0.3677962988615036} | train loss {'Reaction outcome loss': 0.22338809144452929, 'Total loss': 0.22338809144452929}
2023-01-04 03:32:12,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:12,745 INFO:     Epoch: 42
2023-01-04 03:32:14,315 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3529375433921814, 'Total loss': 0.3529375433921814} | train loss {'Reaction outcome loss': 0.21920713547246043, 'Total loss': 0.21920713547246043}
2023-01-04 03:32:14,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:14,316 INFO:     Epoch: 43
2023-01-04 03:32:15,889 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3540773347020149, 'Total loss': 0.3540773347020149} | train loss {'Reaction outcome loss': 0.2166436328466748, 'Total loss': 0.2166436328466748}
2023-01-04 03:32:15,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:15,889 INFO:     Epoch: 44
2023-01-04 03:32:17,449 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38956286708513893, 'Total loss': 0.38956286708513893} | train loss {'Reaction outcome loss': 0.21673647952145755, 'Total loss': 0.21673647952145755}
2023-01-04 03:32:17,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:17,449 INFO:     Epoch: 45
2023-01-04 03:32:19,043 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3527218386530876, 'Total loss': 0.3527218386530876} | train loss {'Reaction outcome loss': 0.21292912280977433, 'Total loss': 0.21292912280977433}
2023-01-04 03:32:19,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:19,043 INFO:     Epoch: 46
2023-01-04 03:32:20,618 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3550763063132763, 'Total loss': 0.3550763063132763} | train loss {'Reaction outcome loss': 0.21118949878809637, 'Total loss': 0.21118949878809637}
2023-01-04 03:32:20,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:20,619 INFO:     Epoch: 47
2023-01-04 03:32:22,200 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3722749315202236, 'Total loss': 0.3722749315202236} | train loss {'Reaction outcome loss': 0.2084396636161637, 'Total loss': 0.2084396636161637}
2023-01-04 03:32:22,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:22,201 INFO:     Epoch: 48
2023-01-04 03:32:23,749 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3643435080846151, 'Total loss': 0.3643435080846151} | train loss {'Reaction outcome loss': 0.20658298190064536, 'Total loss': 0.20658298190064536}
2023-01-04 03:32:23,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:23,749 INFO:     Epoch: 49
2023-01-04 03:32:25,340 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40334524313608805, 'Total loss': 0.40334524313608805} | train loss {'Reaction outcome loss': 0.2054197401000785, 'Total loss': 0.2054197401000785}
2023-01-04 03:32:25,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:25,340 INFO:     Epoch: 50
2023-01-04 03:32:26,932 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37049866120020547, 'Total loss': 0.37049866120020547} | train loss {'Reaction outcome loss': 0.20214299467216998, 'Total loss': 0.20214299467216998}
2023-01-04 03:32:26,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:26,933 INFO:     Epoch: 51
2023-01-04 03:32:28,492 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3755001833041509, 'Total loss': 0.3755001833041509} | train loss {'Reaction outcome loss': 0.20069315494811402, 'Total loss': 0.20069315494811402}
2023-01-04 03:32:28,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:28,492 INFO:     Epoch: 52
2023-01-04 03:32:30,063 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3789628932873408, 'Total loss': 0.3789628932873408} | train loss {'Reaction outcome loss': 0.20160136971196566, 'Total loss': 0.20160136971196566}
2023-01-04 03:32:30,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:30,063 INFO:     Epoch: 53
2023-01-04 03:32:31,662 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4047917981942495, 'Total loss': 0.4047917981942495} | train loss {'Reaction outcome loss': 0.1989698330442184, 'Total loss': 0.1989698330442184}
2023-01-04 03:32:31,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:31,662 INFO:     Epoch: 54
2023-01-04 03:32:33,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3795100892583529, 'Total loss': 0.3795100892583529} | train loss {'Reaction outcome loss': 0.19759094869078744, 'Total loss': 0.19759094869078744}
2023-01-04 03:32:33,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:33,228 INFO:     Epoch: 55
2023-01-04 03:32:34,800 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38112569053967793, 'Total loss': 0.38112569053967793} | train loss {'Reaction outcome loss': 0.19396194849314505, 'Total loss': 0.19396194849314505}
2023-01-04 03:32:34,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:34,801 INFO:     Epoch: 56
2023-01-04 03:32:36,372 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3822697728872299, 'Total loss': 0.3822697728872299} | train loss {'Reaction outcome loss': 0.19384938006966315, 'Total loss': 0.19384938006966315}
2023-01-04 03:32:36,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:36,373 INFO:     Epoch: 57
2023-01-04 03:32:37,946 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36531862256427605, 'Total loss': 0.36531862256427605} | train loss {'Reaction outcome loss': 0.19072656303891616, 'Total loss': 0.19072656303891616}
2023-01-04 03:32:37,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:37,947 INFO:     Epoch: 58
2023-01-04 03:32:39,503 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3731377641359965, 'Total loss': 0.3731377641359965} | train loss {'Reaction outcome loss': 0.1912472372654674, 'Total loss': 0.1912472372654674}
2023-01-04 03:32:39,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:39,504 INFO:     Epoch: 59
2023-01-04 03:32:41,077 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3722568174203237, 'Total loss': 0.3722568174203237} | train loss {'Reaction outcome loss': 0.18967551469967814, 'Total loss': 0.18967551469967814}
2023-01-04 03:32:41,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:41,077 INFO:     Epoch: 60
2023-01-04 03:32:42,633 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3601408530647556, 'Total loss': 0.3601408530647556} | train loss {'Reaction outcome loss': 0.18958598061213855, 'Total loss': 0.18958598061213855}
2023-01-04 03:32:42,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:42,633 INFO:     Epoch: 61
2023-01-04 03:32:44,206 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40114563206831616, 'Total loss': 0.40114563206831616} | train loss {'Reaction outcome loss': 0.1872630291429393, 'Total loss': 0.1872630291429393}
2023-01-04 03:32:44,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:44,207 INFO:     Epoch: 62
2023-01-04 03:32:45,781 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.376411385089159, 'Total loss': 0.376411385089159} | train loss {'Reaction outcome loss': 0.18576374376447, 'Total loss': 0.18576374376447}
2023-01-04 03:32:45,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:45,781 INFO:     Epoch: 63
2023-01-04 03:32:47,344 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3842626621325811, 'Total loss': 0.3842626621325811} | train loss {'Reaction outcome loss': 0.18471803841253268, 'Total loss': 0.18471803841253268}
2023-01-04 03:32:47,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:47,344 INFO:     Epoch: 64
2023-01-04 03:32:48,920 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37970178623994194, 'Total loss': 0.37970178623994194} | train loss {'Reaction outcome loss': 0.18251297175471853, 'Total loss': 0.18251297175471853}
2023-01-04 03:32:48,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:48,920 INFO:     Epoch: 65
2023-01-04 03:32:50,487 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40622204045454663, 'Total loss': 0.40622204045454663} | train loss {'Reaction outcome loss': 0.18175537609306208, 'Total loss': 0.18175537609306208}
2023-01-04 03:32:50,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:50,487 INFO:     Epoch: 66
2023-01-04 03:32:52,047 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39368332382291554, 'Total loss': 0.39368332382291554} | train loss {'Reaction outcome loss': 0.18393735646706666, 'Total loss': 0.18393735646706666}
2023-01-04 03:32:52,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:52,047 INFO:     Epoch: 67
2023-01-04 03:32:53,619 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41764114002386726, 'Total loss': 0.41764114002386726} | train loss {'Reaction outcome loss': 0.1819997281248499, 'Total loss': 0.1819997281248499}
2023-01-04 03:32:53,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:53,619 INFO:     Epoch: 68
2023-01-04 03:32:55,191 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4352232207854589, 'Total loss': 0.4352232207854589} | train loss {'Reaction outcome loss': 0.17822907691842077, 'Total loss': 0.17822907691842077}
2023-01-04 03:32:55,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:55,192 INFO:     Epoch: 69
2023-01-04 03:32:56,758 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40014658073584236, 'Total loss': 0.40014658073584236} | train loss {'Reaction outcome loss': 0.17490728565137764, 'Total loss': 0.17490728565137764}
2023-01-04 03:32:56,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:56,760 INFO:     Epoch: 70
2023-01-04 03:32:58,331 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4571889340877533, 'Total loss': 0.4571889340877533} | train loss {'Reaction outcome loss': 0.17698412966601743, 'Total loss': 0.17698412966601743}
2023-01-04 03:32:58,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:58,332 INFO:     Epoch: 71
2023-01-04 03:32:59,888 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42091421286265057, 'Total loss': 0.42091421286265057} | train loss {'Reaction outcome loss': 0.17359715601175033, 'Total loss': 0.17359715601175033}
2023-01-04 03:32:59,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:32:59,889 INFO:     Epoch: 72
2023-01-04 03:33:01,459 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4118448570370674, 'Total loss': 0.4118448570370674} | train loss {'Reaction outcome loss': 0.17280312200726397, 'Total loss': 0.17280312200726397}
2023-01-04 03:33:01,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:01,460 INFO:     Epoch: 73
2023-01-04 03:33:03,030 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4035333335399628, 'Total loss': 0.4035333335399628} | train loss {'Reaction outcome loss': 0.17368780717088728, 'Total loss': 0.17368780717088728}
2023-01-04 03:33:03,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:03,031 INFO:     Epoch: 74
2023-01-04 03:33:04,615 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40366832315921786, 'Total loss': 0.40366832315921786} | train loss {'Reaction outcome loss': 0.17234396287738396, 'Total loss': 0.17234396287738396}
2023-01-04 03:33:04,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:04,615 INFO:     Epoch: 75
2023-01-04 03:33:06,174 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38415003518263496, 'Total loss': 0.38415003518263496} | train loss {'Reaction outcome loss': 0.17259804123662054, 'Total loss': 0.17259804123662054}
2023-01-04 03:33:06,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:06,174 INFO:     Epoch: 76
2023-01-04 03:33:07,746 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39051955143610634, 'Total loss': 0.39051955143610634} | train loss {'Reaction outcome loss': 0.16807402899949314, 'Total loss': 0.16807402899949314}
2023-01-04 03:33:07,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:07,746 INFO:     Epoch: 77
2023-01-04 03:33:09,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4409610678752263, 'Total loss': 0.4409610678752263} | train loss {'Reaction outcome loss': 0.16939283782320708, 'Total loss': 0.16939283782320708}
2023-01-04 03:33:09,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:09,313 INFO:     Epoch: 78
2023-01-04 03:33:10,900 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3959354301293691, 'Total loss': 0.3959354301293691} | train loss {'Reaction outcome loss': 0.17028802137038365, 'Total loss': 0.17028802137038365}
2023-01-04 03:33:10,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:10,900 INFO:     Epoch: 79
2023-01-04 03:33:12,486 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4218086451292038, 'Total loss': 0.4218086451292038} | train loss {'Reaction outcome loss': 0.16667008481067486, 'Total loss': 0.16667008481067486}
2023-01-04 03:33:12,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:12,486 INFO:     Epoch: 80
2023-01-04 03:33:14,077 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4107814778884252, 'Total loss': 0.4107814778884252} | train loss {'Reaction outcome loss': 0.16575685870658427, 'Total loss': 0.16575685870658427}
2023-01-04 03:33:14,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:14,077 INFO:     Epoch: 81
2023-01-04 03:33:15,630 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40947017868359886, 'Total loss': 0.40947017868359886} | train loss {'Reaction outcome loss': 0.16513471136976213, 'Total loss': 0.16513471136976213}
2023-01-04 03:33:15,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:15,631 INFO:     Epoch: 82
2023-01-04 03:33:17,203 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43236159483591713, 'Total loss': 0.43236159483591713} | train loss {'Reaction outcome loss': 0.1649341964235055, 'Total loss': 0.1649341964235055}
2023-01-04 03:33:17,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:17,203 INFO:     Epoch: 83
2023-01-04 03:33:18,773 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4625345379114151, 'Total loss': 0.4625345379114151} | train loss {'Reaction outcome loss': 0.16655238068274247, 'Total loss': 0.16655238068274247}
2023-01-04 03:33:18,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:18,773 INFO:     Epoch: 84
2023-01-04 03:33:20,364 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4064891442656517, 'Total loss': 0.4064891442656517} | train loss {'Reaction outcome loss': 0.16513593257765707, 'Total loss': 0.16513593257765707}
2023-01-04 03:33:20,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:20,365 INFO:     Epoch: 85
2023-01-04 03:33:21,957 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4265811577439308, 'Total loss': 0.4265811577439308} | train loss {'Reaction outcome loss': 0.16427218597863433, 'Total loss': 0.16427218597863433}
2023-01-04 03:33:21,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:21,957 INFO:     Epoch: 86
2023-01-04 03:33:23,517 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4230252275864283, 'Total loss': 0.4230252275864283} | train loss {'Reaction outcome loss': 0.16262941420545657, 'Total loss': 0.16262941420545657}
2023-01-04 03:33:23,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:23,517 INFO:     Epoch: 87
2023-01-04 03:33:25,107 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4466837465763092, 'Total loss': 0.4466837465763092} | train loss {'Reaction outcome loss': 0.16149132834176955, 'Total loss': 0.16149132834176955}
2023-01-04 03:33:25,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:25,108 INFO:     Epoch: 88
2023-01-04 03:33:26,662 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.414259014527003, 'Total loss': 0.414259014527003} | train loss {'Reaction outcome loss': 0.16278323599195788, 'Total loss': 0.16278323599195788}
2023-01-04 03:33:26,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:26,662 INFO:     Epoch: 89
2023-01-04 03:33:28,234 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46252714693546293, 'Total loss': 0.46252714693546293} | train loss {'Reaction outcome loss': 0.1603240587394616, 'Total loss': 0.1603240587394616}
2023-01-04 03:33:28,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:28,234 INFO:     Epoch: 90
2023-01-04 03:33:29,807 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41728796263535817, 'Total loss': 0.41728796263535817} | train loss {'Reaction outcome loss': 0.16090693268443826, 'Total loss': 0.16090693268443826}
2023-01-04 03:33:29,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:29,807 INFO:     Epoch: 91
2023-01-04 03:33:31,380 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4323483407497406, 'Total loss': 0.4323483407497406} | train loss {'Reaction outcome loss': 0.15831602535234607, 'Total loss': 0.15831602535234607}
2023-01-04 03:33:31,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:31,381 INFO:     Epoch: 92
2023-01-04 03:33:32,923 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40881725947062175, 'Total loss': 0.40881725947062175} | train loss {'Reaction outcome loss': 0.15797059990575613, 'Total loss': 0.15797059990575613}
2023-01-04 03:33:32,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:32,923 INFO:     Epoch: 93
2023-01-04 03:33:34,515 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42054401834805805, 'Total loss': 0.42054401834805805} | train loss {'Reaction outcome loss': 0.15954148979699478, 'Total loss': 0.15954148979699478}
2023-01-04 03:33:34,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:34,515 INFO:     Epoch: 94
2023-01-04 03:33:36,071 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47118873496850333, 'Total loss': 0.47118873496850333} | train loss {'Reaction outcome loss': 0.1567637053253026, 'Total loss': 0.1567637053253026}
2023-01-04 03:33:36,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:36,071 INFO:     Epoch: 95
2023-01-04 03:33:37,663 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4322565237681071, 'Total loss': 0.4322565237681071} | train loss {'Reaction outcome loss': 0.15601704262087046, 'Total loss': 0.15601704262087046}
2023-01-04 03:33:37,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:37,663 INFO:     Epoch: 96
2023-01-04 03:33:39,251 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4511246860027313, 'Total loss': 0.4511246860027313} | train loss {'Reaction outcome loss': 0.1575730611394912, 'Total loss': 0.1575730611394912}
2023-01-04 03:33:39,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:39,252 INFO:     Epoch: 97
2023-01-04 03:33:40,843 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39849744538466136, 'Total loss': 0.39849744538466136} | train loss {'Reaction outcome loss': 0.15463764197107172, 'Total loss': 0.15463764197107172}
2023-01-04 03:33:40,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:40,843 INFO:     Epoch: 98
2023-01-04 03:33:42,397 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4201453149318695, 'Total loss': 0.4201453149318695} | train loss {'Reaction outcome loss': 0.15431339588579876, 'Total loss': 0.15431339588579876}
2023-01-04 03:33:42,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:42,398 INFO:     Epoch: 99
2023-01-04 03:33:43,962 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4175639510154724, 'Total loss': 0.4175639510154724} | train loss {'Reaction outcome loss': 0.15308345881087973, 'Total loss': 0.15308345881087973}
2023-01-04 03:33:43,962 INFO:     Best model found after epoch 25 of 100.
2023-01-04 03:33:43,962 INFO:   Done with stage: TRAINING
2023-01-04 03:33:43,962 INFO:   Starting stage: EVALUATION
2023-01-04 03:33:44,108 INFO:   Done with stage: EVALUATION
2023-01-04 03:33:44,109 INFO:   Leaving out SEQ value Fold_4
2023-01-04 03:33:44,121 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:33:44,121 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:33:44,775 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:33:44,775 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:33:44,842 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:33:44,842 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:33:44,842 INFO:     No hyperparam tuning for this model
2023-01-04 03:33:44,842 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:33:44,842 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:33:44,843 INFO:     None feature selector for col prot
2023-01-04 03:33:44,843 INFO:     None feature selector for col prot
2023-01-04 03:33:44,843 INFO:     None feature selector for col prot
2023-01-04 03:33:44,844 INFO:     None feature selector for col chem
2023-01-04 03:33:44,844 INFO:     None feature selector for col chem
2023-01-04 03:33:44,844 INFO:     None feature selector for col chem
2023-01-04 03:33:44,844 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:33:44,844 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:33:44,845 INFO:     Number of params in model 70141
2023-01-04 03:33:44,848 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:33:44,848 INFO:   Starting stage: TRAINING
2023-01-04 03:33:44,892 INFO:     Val loss before train {'Reaction outcome loss': 1.077068599065145, 'Total loss': 1.077068599065145}
2023-01-04 03:33:44,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:44,892 INFO:     Epoch: 0
2023-01-04 03:33:46,504 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6706079622109731, 'Total loss': 0.6706079622109731} | train loss {'Reaction outcome loss': 0.845084989288201, 'Total loss': 0.845084989288201}
2023-01-04 03:33:46,504 INFO:     Found new best model at epoch 0
2023-01-04 03:33:46,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:46,505 INFO:     Epoch: 1
2023-01-04 03:33:48,093 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5278321484724681, 'Total loss': 0.5278321484724681} | train loss {'Reaction outcome loss': 0.598452920992555, 'Total loss': 0.598452920992555}
2023-01-04 03:33:48,093 INFO:     Found new best model at epoch 1
2023-01-04 03:33:48,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:48,094 INFO:     Epoch: 2
2023-01-04 03:33:49,704 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48975953261057537, 'Total loss': 0.48975953261057537} | train loss {'Reaction outcome loss': 0.5214630957098975, 'Total loss': 0.5214630957098975}
2023-01-04 03:33:49,704 INFO:     Found new best model at epoch 2
2023-01-04 03:33:49,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:49,705 INFO:     Epoch: 3
2023-01-04 03:33:51,283 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4600767721732458, 'Total loss': 0.4600767721732458} | train loss {'Reaction outcome loss': 0.4835452475666028, 'Total loss': 0.4835452475666028}
2023-01-04 03:33:51,283 INFO:     Found new best model at epoch 3
2023-01-04 03:33:51,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:51,284 INFO:     Epoch: 4
2023-01-04 03:33:52,895 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4468307177225749, 'Total loss': 0.4468307177225749} | train loss {'Reaction outcome loss': 0.45743534171386907, 'Total loss': 0.45743534171386907}
2023-01-04 03:33:52,895 INFO:     Found new best model at epoch 4
2023-01-04 03:33:52,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:52,896 INFO:     Epoch: 5
2023-01-04 03:33:54,482 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4295273770888646, 'Total loss': 0.4295273770888646} | train loss {'Reaction outcome loss': 0.43853148409718834, 'Total loss': 0.43853148409718834}
2023-01-04 03:33:54,482 INFO:     Found new best model at epoch 5
2023-01-04 03:33:54,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:54,483 INFO:     Epoch: 6
2023-01-04 03:33:56,081 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42730578084786736, 'Total loss': 0.42730578084786736} | train loss {'Reaction outcome loss': 0.42414721797989763, 'Total loss': 0.42414721797989763}
2023-01-04 03:33:56,081 INFO:     Found new best model at epoch 6
2023-01-04 03:33:56,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:56,082 INFO:     Epoch: 7
2023-01-04 03:33:57,681 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4094602018594742, 'Total loss': 0.4094602018594742} | train loss {'Reaction outcome loss': 0.411108635507686, 'Total loss': 0.411108635507686}
2023-01-04 03:33:57,681 INFO:     Found new best model at epoch 7
2023-01-04 03:33:57,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:57,682 INFO:     Epoch: 8
2023-01-04 03:33:59,270 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42014165421326954, 'Total loss': 0.42014165421326954} | train loss {'Reaction outcome loss': 0.39838536693782045, 'Total loss': 0.39838536693782045}
2023-01-04 03:33:59,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:33:59,270 INFO:     Epoch: 9
2023-01-04 03:34:00,901 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42771169145902, 'Total loss': 0.42771169145902} | train loss {'Reaction outcome loss': 0.38873508144035074, 'Total loss': 0.38873508144035074}
2023-01-04 03:34:00,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:00,901 INFO:     Epoch: 10
2023-01-04 03:34:02,499 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42460296750068666, 'Total loss': 0.42460296750068666} | train loss {'Reaction outcome loss': 0.38539587177228235, 'Total loss': 0.38539587177228235}
2023-01-04 03:34:02,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:02,500 INFO:     Epoch: 11
2023-01-04 03:34:04,081 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4164773503939311, 'Total loss': 0.4164773503939311} | train loss {'Reaction outcome loss': 0.3779278556829777, 'Total loss': 0.3779278556829777}
2023-01-04 03:34:04,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:04,081 INFO:     Epoch: 12
2023-01-04 03:34:05,702 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43561216990152996, 'Total loss': 0.43561216990152996} | train loss {'Reaction outcome loss': 0.3725238437561885, 'Total loss': 0.3725238437561885}
2023-01-04 03:34:05,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:05,702 INFO:     Epoch: 13
2023-01-04 03:34:07,336 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41381997565428413, 'Total loss': 0.41381997565428413} | train loss {'Reaction outcome loss': 0.3662259254918393, 'Total loss': 0.3662259254918393}
2023-01-04 03:34:07,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:07,336 INFO:     Epoch: 14
2023-01-04 03:34:08,909 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39185040493806206, 'Total loss': 0.39185040493806206} | train loss {'Reaction outcome loss': 0.3546342925013353, 'Total loss': 0.3546342925013353}
2023-01-04 03:34:08,910 INFO:     Found new best model at epoch 14
2023-01-04 03:34:08,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:08,911 INFO:     Epoch: 15
2023-01-04 03:34:10,491 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3902632455031077, 'Total loss': 0.3902632455031077} | train loss {'Reaction outcome loss': 0.34716307687694614, 'Total loss': 0.34716307687694614}
2023-01-04 03:34:10,491 INFO:     Found new best model at epoch 15
2023-01-04 03:34:10,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:10,492 INFO:     Epoch: 16
2023-01-04 03:34:12,090 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3998695482810338, 'Total loss': 0.3998695482810338} | train loss {'Reaction outcome loss': 0.3417513807615488, 'Total loss': 0.3417513807615488}
2023-01-04 03:34:12,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:12,090 INFO:     Epoch: 17
2023-01-04 03:34:13,669 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40321522851785024, 'Total loss': 0.40321522851785024} | train loss {'Reaction outcome loss': 0.33696418867169786, 'Total loss': 0.33696418867169786}
2023-01-04 03:34:13,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:13,669 INFO:     Epoch: 18
2023-01-04 03:34:15,301 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38687124848365784, 'Total loss': 0.38687124848365784} | train loss {'Reaction outcome loss': 0.3300324098571487, 'Total loss': 0.3300324098571487}
2023-01-04 03:34:15,301 INFO:     Found new best model at epoch 18
2023-01-04 03:34:15,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:15,302 INFO:     Epoch: 19
2023-01-04 03:34:16,913 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39717882573604585, 'Total loss': 0.39717882573604585} | train loss {'Reaction outcome loss': 0.3442696052185003, 'Total loss': 0.3442696052185003}
2023-01-04 03:34:16,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:16,913 INFO:     Epoch: 20
2023-01-04 03:34:18,517 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39941548903783164, 'Total loss': 0.39941548903783164} | train loss {'Reaction outcome loss': 0.347391904750164, 'Total loss': 0.347391904750164}
2023-01-04 03:34:18,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:18,517 INFO:     Epoch: 21
2023-01-04 03:34:20,096 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41197048127651215, 'Total loss': 0.41197048127651215} | train loss {'Reaction outcome loss': 0.3253397344733062, 'Total loss': 0.3253397344733062}
2023-01-04 03:34:20,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:20,096 INFO:     Epoch: 22
2023-01-04 03:34:21,722 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4034085154533386, 'Total loss': 0.4034085154533386} | train loss {'Reaction outcome loss': 0.31373358137679513, 'Total loss': 0.31373358137679513}
2023-01-04 03:34:21,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:21,723 INFO:     Epoch: 23
2023-01-04 03:34:23,338 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38518862426280975, 'Total loss': 0.38518862426280975} | train loss {'Reaction outcome loss': 0.3080274331956204, 'Total loss': 0.3080274331956204}
2023-01-04 03:34:23,338 INFO:     Found new best model at epoch 23
2023-01-04 03:34:23,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:23,339 INFO:     Epoch: 24
2023-01-04 03:34:24,959 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3878290057182312, 'Total loss': 0.3878290057182312} | train loss {'Reaction outcome loss': 0.3035115239014714, 'Total loss': 0.3035115239014714}
2023-01-04 03:34:24,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:24,960 INFO:     Epoch: 25
2023-01-04 03:34:26,554 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39048532346884407, 'Total loss': 0.39048532346884407} | train loss {'Reaction outcome loss': 0.29723195966518845, 'Total loss': 0.29723195966518845}
2023-01-04 03:34:26,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:26,554 INFO:     Epoch: 26
2023-01-04 03:34:28,152 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3896846741437912, 'Total loss': 0.3896846741437912} | train loss {'Reaction outcome loss': 0.2964164968028302, 'Total loss': 0.2964164968028302}
2023-01-04 03:34:28,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:28,152 INFO:     Epoch: 27
2023-01-04 03:34:29,744 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3857627133528391, 'Total loss': 0.3857627133528391} | train loss {'Reaction outcome loss': 0.29830841166709643, 'Total loss': 0.29830841166709643}
2023-01-04 03:34:29,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:29,744 INFO:     Epoch: 28
2023-01-04 03:34:31,347 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3966668883959452, 'Total loss': 0.3966668883959452} | train loss {'Reaction outcome loss': 0.32108049073081085, 'Total loss': 0.32108049073081085}
2023-01-04 03:34:31,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:31,347 INFO:     Epoch: 29
2023-01-04 03:34:32,950 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4123028089602788, 'Total loss': 0.4123028089602788} | train loss {'Reaction outcome loss': 0.2899302610759691, 'Total loss': 0.2899302610759691}
2023-01-04 03:34:32,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:32,952 INFO:     Epoch: 30
2023-01-04 03:34:34,546 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.372459747393926, 'Total loss': 0.372459747393926} | train loss {'Reaction outcome loss': 0.28287447107942315, 'Total loss': 0.28287447107942315}
2023-01-04 03:34:34,546 INFO:     Found new best model at epoch 30
2023-01-04 03:34:34,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:34,547 INFO:     Epoch: 31
2023-01-04 03:34:35,733 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39520320494969685, 'Total loss': 0.39520320494969685} | train loss {'Reaction outcome loss': 0.2790733264030322, 'Total loss': 0.2790733264030322}
2023-01-04 03:34:35,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:35,733 INFO:     Epoch: 32
2023-01-04 03:34:36,824 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38871776858965557, 'Total loss': 0.38871776858965557} | train loss {'Reaction outcome loss': 0.27989475327489927, 'Total loss': 0.27989475327489927}
2023-01-04 03:34:36,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:36,824 INFO:     Epoch: 33
2023-01-04 03:34:37,917 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3938199212153753, 'Total loss': 0.3938199212153753} | train loss {'Reaction outcome loss': 0.2727752181471906, 'Total loss': 0.2727752181471906}
2023-01-04 03:34:37,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:37,917 INFO:     Epoch: 34
2023-01-04 03:34:39,005 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3735843762755394, 'Total loss': 0.3735843762755394} | train loss {'Reaction outcome loss': 0.268767557228389, 'Total loss': 0.268767557228389}
2023-01-04 03:34:39,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:39,006 INFO:     Epoch: 35
2023-01-04 03:34:40,422 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39169314404328665, 'Total loss': 0.39169314404328665} | train loss {'Reaction outcome loss': 0.2650559930092858, 'Total loss': 0.2650559930092858}
2023-01-04 03:34:40,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:40,422 INFO:     Epoch: 36
2023-01-04 03:34:42,019 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38422450025876365, 'Total loss': 0.38422450025876365} | train loss {'Reaction outcome loss': 0.26462095449476136, 'Total loss': 0.26462095449476136}
2023-01-04 03:34:42,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:42,019 INFO:     Epoch: 37
2023-01-04 03:34:43,631 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3696108142534892, 'Total loss': 0.3696108142534892} | train loss {'Reaction outcome loss': 0.2621047012305454, 'Total loss': 0.2621047012305454}
2023-01-04 03:34:43,631 INFO:     Found new best model at epoch 37
2023-01-04 03:34:43,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:43,632 INFO:     Epoch: 38
2023-01-04 03:34:45,197 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3984428346157074, 'Total loss': 0.3984428346157074} | train loss {'Reaction outcome loss': 0.2591196010969039, 'Total loss': 0.2591196010969039}
2023-01-04 03:34:45,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:45,197 INFO:     Epoch: 39
2023-01-04 03:34:46,802 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36028388341267903, 'Total loss': 0.36028388341267903} | train loss {'Reaction outcome loss': 0.26045579559960996, 'Total loss': 0.26045579559960996}
2023-01-04 03:34:46,802 INFO:     Found new best model at epoch 39
2023-01-04 03:34:46,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:46,803 INFO:     Epoch: 40
2023-01-04 03:34:48,403 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37003289262453715, 'Total loss': 0.37003289262453715} | train loss {'Reaction outcome loss': 0.2500041442191645, 'Total loss': 0.2500041442191645}
2023-01-04 03:34:48,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:48,403 INFO:     Epoch: 41
2023-01-04 03:34:49,990 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3671945720911026, 'Total loss': 0.3671945720911026} | train loss {'Reaction outcome loss': 0.24872281345575914, 'Total loss': 0.24872281345575914}
2023-01-04 03:34:49,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:49,990 INFO:     Epoch: 42
2023-01-04 03:34:51,589 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3863863786061605, 'Total loss': 0.3863863786061605} | train loss {'Reaction outcome loss': 0.2462525828505286, 'Total loss': 0.2462525828505286}
2023-01-04 03:34:51,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:51,590 INFO:     Epoch: 43
2023-01-04 03:34:53,188 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3681789517402649, 'Total loss': 0.3681789517402649} | train loss {'Reaction outcome loss': 0.2447701108277492, 'Total loss': 0.2447701108277492}
2023-01-04 03:34:53,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:53,189 INFO:     Epoch: 44
2023-01-04 03:34:54,782 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.372969459493955, 'Total loss': 0.372969459493955} | train loss {'Reaction outcome loss': 0.24118655282781337, 'Total loss': 0.24118655282781337}
2023-01-04 03:34:54,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:54,782 INFO:     Epoch: 45
2023-01-04 03:34:56,379 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.373565932114919, 'Total loss': 0.373565932114919} | train loss {'Reaction outcome loss': 0.23854436680678348, 'Total loss': 0.23854436680678348}
2023-01-04 03:34:56,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:56,379 INFO:     Epoch: 46
2023-01-04 03:34:57,979 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3641184578339259, 'Total loss': 0.3641184578339259} | train loss {'Reaction outcome loss': 0.23819138945174823, 'Total loss': 0.23819138945174823}
2023-01-04 03:34:57,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:57,979 INFO:     Epoch: 47
2023-01-04 03:34:59,579 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35654880801836647, 'Total loss': 0.35654880801836647} | train loss {'Reaction outcome loss': 0.23803903438053658, 'Total loss': 0.23803903438053658}
2023-01-04 03:34:59,579 INFO:     Found new best model at epoch 47
2023-01-04 03:34:59,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:34:59,580 INFO:     Epoch: 48
2023-01-04 03:35:01,174 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36365383863449097, 'Total loss': 0.36365383863449097} | train loss {'Reaction outcome loss': 0.23262499389660451, 'Total loss': 0.23262499389660451}
2023-01-04 03:35:01,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:01,174 INFO:     Epoch: 49
2023-01-04 03:35:02,768 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37785543004671734, 'Total loss': 0.37785543004671734} | train loss {'Reaction outcome loss': 0.2292366852716309, 'Total loss': 0.2292366852716309}
2023-01-04 03:35:02,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:02,768 INFO:     Epoch: 50
2023-01-04 03:35:04,359 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3931613892316818, 'Total loss': 0.3931613892316818} | train loss {'Reaction outcome loss': 0.2295063763087218, 'Total loss': 0.2295063763087218}
2023-01-04 03:35:04,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:04,360 INFO:     Epoch: 51
2023-01-04 03:35:05,957 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3875449558099111, 'Total loss': 0.3875449558099111} | train loss {'Reaction outcome loss': 0.22629012062426898, 'Total loss': 0.22629012062426898}
2023-01-04 03:35:05,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:05,957 INFO:     Epoch: 52
2023-01-04 03:35:07,542 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3926408484578133, 'Total loss': 0.3926408484578133} | train loss {'Reaction outcome loss': 0.22383389065878978, 'Total loss': 0.22383389065878978}
2023-01-04 03:35:07,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:07,543 INFO:     Epoch: 53
2023-01-04 03:35:09,130 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37466796338558195, 'Total loss': 0.37466796338558195} | train loss {'Reaction outcome loss': 0.22248075908401402, 'Total loss': 0.22248075908401402}
2023-01-04 03:35:09,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:09,130 INFO:     Epoch: 54
2023-01-04 03:35:10,747 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37468599776426953, 'Total loss': 0.37468599776426953} | train loss {'Reaction outcome loss': 0.21913399130542108, 'Total loss': 0.21913399130542108}
2023-01-04 03:35:10,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:10,748 INFO:     Epoch: 55
2023-01-04 03:35:12,329 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39150772492090863, 'Total loss': 0.39150772492090863} | train loss {'Reaction outcome loss': 0.2194266529969763, 'Total loss': 0.2194266529969763}
2023-01-04 03:35:12,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:12,330 INFO:     Epoch: 56
2023-01-04 03:35:13,928 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36877843340237937, 'Total loss': 0.36877843340237937} | train loss {'Reaction outcome loss': 0.2189290191317264, 'Total loss': 0.2189290191317264}
2023-01-04 03:35:13,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:13,928 INFO:     Epoch: 57
2023-01-04 03:35:15,507 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39043964445590973, 'Total loss': 0.39043964445590973} | train loss {'Reaction outcome loss': 0.21659640947599773, 'Total loss': 0.21659640947599773}
2023-01-04 03:35:15,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:15,507 INFO:     Epoch: 58
2023-01-04 03:35:17,100 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38456083834171295, 'Total loss': 0.38456083834171295} | train loss {'Reaction outcome loss': 0.21975542523938676, 'Total loss': 0.21975542523938676}
2023-01-04 03:35:17,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:17,100 INFO:     Epoch: 59
2023-01-04 03:35:18,707 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39057175517082215, 'Total loss': 0.39057175517082215} | train loss {'Reaction outcome loss': 0.22180625158336395, 'Total loss': 0.22180625158336395}
2023-01-04 03:35:18,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:18,708 INFO:     Epoch: 60
2023-01-04 03:35:20,324 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36334168414274853, 'Total loss': 0.36334168414274853} | train loss {'Reaction outcome loss': 0.21989170550976112, 'Total loss': 0.21989170550976112}
2023-01-04 03:35:20,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:20,325 INFO:     Epoch: 61
2023-01-04 03:35:21,899 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37570284058650333, 'Total loss': 0.37570284058650333} | train loss {'Reaction outcome loss': 0.2143678927011248, 'Total loss': 0.2143678927011248}
2023-01-04 03:35:21,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:21,899 INFO:     Epoch: 62
2023-01-04 03:35:23,493 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3856045881907145, 'Total loss': 0.3856045881907145} | train loss {'Reaction outcome loss': 0.21491573890602592, 'Total loss': 0.21491573890602592}
2023-01-04 03:35:23,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:23,494 INFO:     Epoch: 63
2023-01-04 03:35:25,065 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36786123787363373, 'Total loss': 0.36786123787363373} | train loss {'Reaction outcome loss': 0.20744395724403253, 'Total loss': 0.20744395724403253}
2023-01-04 03:35:25,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:25,065 INFO:     Epoch: 64
2023-01-04 03:35:26,684 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3870057861010234, 'Total loss': 0.3870057861010234} | train loss {'Reaction outcome loss': 0.2041980525050283, 'Total loss': 0.2041980525050283}
2023-01-04 03:35:26,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:26,684 INFO:     Epoch: 65
2023-01-04 03:35:28,305 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3774788036942482, 'Total loss': 0.3774788036942482} | train loss {'Reaction outcome loss': 0.20347017110527857, 'Total loss': 0.20347017110527857}
2023-01-04 03:35:28,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:28,306 INFO:     Epoch: 66
2023-01-04 03:35:29,877 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3883645832538605, 'Total loss': 0.3883645832538605} | train loss {'Reaction outcome loss': 0.2071551431874758, 'Total loss': 0.2071551431874758}
2023-01-04 03:35:29,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:29,877 INFO:     Epoch: 67
2023-01-04 03:35:31,460 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3873193482557932, 'Total loss': 0.3873193482557932} | train loss {'Reaction outcome loss': 0.20098282091076608, 'Total loss': 0.20098282091076608}
2023-01-04 03:35:31,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:31,461 INFO:     Epoch: 68
2023-01-04 03:35:33,080 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3735038548707962, 'Total loss': 0.3735038548707962} | train loss {'Reaction outcome loss': 0.20169250768663335, 'Total loss': 0.20169250768663335}
2023-01-04 03:35:33,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:33,080 INFO:     Epoch: 69
2023-01-04 03:35:34,684 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3666637897491455, 'Total loss': 0.3666637897491455} | train loss {'Reaction outcome loss': 0.1973095148180922, 'Total loss': 0.1973095148180922}
2023-01-04 03:35:34,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:34,685 INFO:     Epoch: 70
2023-01-04 03:35:36,305 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37552607158819834, 'Total loss': 0.37552607158819834} | train loss {'Reaction outcome loss': 0.197532308298358, 'Total loss': 0.197532308298358}
2023-01-04 03:35:36,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:36,305 INFO:     Epoch: 71
2023-01-04 03:35:37,894 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38010136981805165, 'Total loss': 0.38010136981805165} | train loss {'Reaction outcome loss': 0.19626007948502683, 'Total loss': 0.19626007948502683}
2023-01-04 03:35:37,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:37,895 INFO:     Epoch: 72
2023-01-04 03:35:39,486 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39752645095189415, 'Total loss': 0.39752645095189415} | train loss {'Reaction outcome loss': 0.19351040285434556, 'Total loss': 0.19351040285434556}
2023-01-04 03:35:39,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:39,487 INFO:     Epoch: 73
2023-01-04 03:35:41,078 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3806335637966792, 'Total loss': 0.3806335637966792} | train loss {'Reaction outcome loss': 0.1925616226685436, 'Total loss': 0.1925616226685436}
2023-01-04 03:35:41,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:41,078 INFO:     Epoch: 74
2023-01-04 03:35:42,662 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37648936808109285, 'Total loss': 0.37648936808109285} | train loss {'Reaction outcome loss': 0.1945221177063196, 'Total loss': 0.1945221177063196}
2023-01-04 03:35:42,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:42,662 INFO:     Epoch: 75
2023-01-04 03:35:44,255 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38755935430526733, 'Total loss': 0.38755935430526733} | train loss {'Reaction outcome loss': 0.19037022336683088, 'Total loss': 0.19037022336683088}
2023-01-04 03:35:44,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:44,255 INFO:     Epoch: 76
2023-01-04 03:35:45,847 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3836100697517395, 'Total loss': 0.3836100697517395} | train loss {'Reaction outcome loss': 0.1938208809526623, 'Total loss': 0.1938208809526623}
2023-01-04 03:35:45,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:45,848 INFO:     Epoch: 77
2023-01-04 03:35:47,451 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3917994995911916, 'Total loss': 0.3917994995911916} | train loss {'Reaction outcome loss': 0.18987439049242708, 'Total loss': 0.18987439049242708}
2023-01-04 03:35:47,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:47,451 INFO:     Epoch: 78
2023-01-04 03:35:49,063 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40771669149398804, 'Total loss': 0.40771669149398804} | train loss {'Reaction outcome loss': 0.18995936159921836, 'Total loss': 0.18995936159921836}
2023-01-04 03:35:49,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:49,063 INFO:     Epoch: 79
2023-01-04 03:35:50,683 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39754560192426047, 'Total loss': 0.39754560192426047} | train loss {'Reaction outcome loss': 0.18760961110798974, 'Total loss': 0.18760961110798974}
2023-01-04 03:35:50,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:50,683 INFO:     Epoch: 80
2023-01-04 03:35:52,260 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39316145380338036, 'Total loss': 0.39316145380338036} | train loss {'Reaction outcome loss': 0.18647270452651277, 'Total loss': 0.18647270452651277}
2023-01-04 03:35:52,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:52,261 INFO:     Epoch: 81
2023-01-04 03:35:53,887 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4314677894115448, 'Total loss': 0.4314677894115448} | train loss {'Reaction outcome loss': 0.20035497500709648, 'Total loss': 0.20035497500709648}
2023-01-04 03:35:53,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:53,887 INFO:     Epoch: 82
2023-01-04 03:35:55,505 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3842714796463648, 'Total loss': 0.3842714796463648} | train loss {'Reaction outcome loss': 0.20185358290547045, 'Total loss': 0.20185358290547045}
2023-01-04 03:35:55,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:55,506 INFO:     Epoch: 83
2023-01-04 03:35:57,111 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36742421289285027, 'Total loss': 0.36742421289285027} | train loss {'Reaction outcome loss': 0.18770014053966472, 'Total loss': 0.18770014053966472}
2023-01-04 03:35:57,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:57,111 INFO:     Epoch: 84
2023-01-04 03:35:58,735 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3811097164948781, 'Total loss': 0.3811097164948781} | train loss {'Reaction outcome loss': 0.18975420130975207, 'Total loss': 0.18975420130975207}
2023-01-04 03:35:58,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:35:58,736 INFO:     Epoch: 85
2023-01-04 03:36:00,342 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3931460797786713, 'Total loss': 0.3931460797786713} | train loss {'Reaction outcome loss': 0.18169184059218463, 'Total loss': 0.18169184059218463}
2023-01-04 03:36:00,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:00,342 INFO:     Epoch: 86
2023-01-04 03:36:01,962 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4015188733736674, 'Total loss': 0.4015188733736674} | train loss {'Reaction outcome loss': 0.18388321201917648, 'Total loss': 0.18388321201917648}
2023-01-04 03:36:01,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:01,962 INFO:     Epoch: 87
2023-01-04 03:36:03,550 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4019138296445211, 'Total loss': 0.4019138296445211} | train loss {'Reaction outcome loss': 0.180473281117831, 'Total loss': 0.180473281117831}
2023-01-04 03:36:03,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:03,551 INFO:     Epoch: 88
2023-01-04 03:36:05,172 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3894884169101715, 'Total loss': 0.3894884169101715} | train loss {'Reaction outcome loss': 0.18612972665173205, 'Total loss': 0.18612972665173205}
2023-01-04 03:36:05,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:05,172 INFO:     Epoch: 89
2023-01-04 03:36:06,750 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4048850287993749, 'Total loss': 0.4048850287993749} | train loss {'Reaction outcome loss': 0.1791094257774682, 'Total loss': 0.1791094257774682}
2023-01-04 03:36:06,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:06,750 INFO:     Epoch: 90
2023-01-04 03:36:08,343 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37754839460055034, 'Total loss': 0.37754839460055034} | train loss {'Reaction outcome loss': 0.17752472418114718, 'Total loss': 0.17752472418114718}
2023-01-04 03:36:08,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:08,343 INFO:     Epoch: 91
2023-01-04 03:36:09,928 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39958468874295555, 'Total loss': 0.39958468874295555} | train loss {'Reaction outcome loss': 0.1819633630414804, 'Total loss': 0.1819633630414804}
2023-01-04 03:36:09,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:09,928 INFO:     Epoch: 92
2023-01-04 03:36:11,540 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39244578580061595, 'Total loss': 0.39244578580061595} | train loss {'Reaction outcome loss': 0.18663080474207294, 'Total loss': 0.18663080474207294}
2023-01-04 03:36:11,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:11,541 INFO:     Epoch: 93
2023-01-04 03:36:13,128 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40647704601287843, 'Total loss': 0.40647704601287843} | train loss {'Reaction outcome loss': 0.17662820838613433, 'Total loss': 0.17662820838613433}
2023-01-04 03:36:13,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:13,129 INFO:     Epoch: 94
2023-01-04 03:36:14,723 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3854412873586019, 'Total loss': 0.3854412873586019} | train loss {'Reaction outcome loss': 0.17782146822107767, 'Total loss': 0.17782146822107767}
2023-01-04 03:36:14,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:14,723 INFO:     Epoch: 95
2023-01-04 03:36:16,316 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41362046301364896, 'Total loss': 0.41362046301364896} | train loss {'Reaction outcome loss': 0.17670654421546317, 'Total loss': 0.17670654421546317}
2023-01-04 03:36:16,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:16,317 INFO:     Epoch: 96
2023-01-04 03:36:17,910 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4107828636964162, 'Total loss': 0.4107828636964162} | train loss {'Reaction outcome loss': 0.17451642066969172, 'Total loss': 0.17451642066969172}
2023-01-04 03:36:17,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:17,910 INFO:     Epoch: 97
2023-01-04 03:36:19,487 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4155620614687602, 'Total loss': 0.4155620614687602} | train loss {'Reaction outcome loss': 0.18127847690324206, 'Total loss': 0.18127847690324206}
2023-01-04 03:36:19,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:19,487 INFO:     Epoch: 98
2023-01-04 03:36:21,101 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38686476250489554, 'Total loss': 0.38686476250489554} | train loss {'Reaction outcome loss': 0.19911230538391333, 'Total loss': 0.19911230538391333}
2023-01-04 03:36:21,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:21,101 INFO:     Epoch: 99
2023-01-04 03:36:22,721 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38973482251167296, 'Total loss': 0.38973482251167296} | train loss {'Reaction outcome loss': 0.1751513038234774, 'Total loss': 0.1751513038234774}
2023-01-04 03:36:22,721 INFO:     Best model found after epoch 48 of 100.
2023-01-04 03:36:22,721 INFO:   Done with stage: TRAINING
2023-01-04 03:36:22,721 INFO:   Starting stage: EVALUATION
2023-01-04 03:36:22,849 INFO:   Done with stage: EVALUATION
2023-01-04 03:36:22,849 INFO:   Leaving out SEQ value Fold_5
2023-01-04 03:36:22,862 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:36:22,862 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:36:23,515 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:36:23,515 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:36:23,583 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:36:23,583 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:36:23,583 INFO:     No hyperparam tuning for this model
2023-01-04 03:36:23,583 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:36:23,583 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:36:23,584 INFO:     None feature selector for col prot
2023-01-04 03:36:23,584 INFO:     None feature selector for col prot
2023-01-04 03:36:23,584 INFO:     None feature selector for col prot
2023-01-04 03:36:23,585 INFO:     None feature selector for col chem
2023-01-04 03:36:23,585 INFO:     None feature selector for col chem
2023-01-04 03:36:23,585 INFO:     None feature selector for col chem
2023-01-04 03:36:23,585 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:36:23,585 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:36:23,586 INFO:     Number of params in model 70141
2023-01-04 03:36:23,589 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:36:23,589 INFO:   Starting stage: TRAINING
2023-01-04 03:36:23,633 INFO:     Val loss before train {'Reaction outcome loss': 1.0856647849082948, 'Total loss': 1.0856647849082948}
2023-01-04 03:36:23,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:23,633 INFO:     Epoch: 0
2023-01-04 03:36:25,233 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7670843283335368, 'Total loss': 0.7670843283335368} | train loss {'Reaction outcome loss': 0.8432251298327701, 'Total loss': 0.8432251298327701}
2023-01-04 03:36:25,233 INFO:     Found new best model at epoch 0
2023-01-04 03:36:25,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:25,234 INFO:     Epoch: 1
2023-01-04 03:36:26,811 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6276349345842998, 'Total loss': 0.6276349345842998} | train loss {'Reaction outcome loss': 0.6269434223152306, 'Total loss': 0.6269434223152306}
2023-01-04 03:36:26,812 INFO:     Found new best model at epoch 1
2023-01-04 03:36:26,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:26,812 INFO:     Epoch: 2
2023-01-04 03:36:28,421 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5898970007896424, 'Total loss': 0.5898970007896424} | train loss {'Reaction outcome loss': 0.5286702127600817, 'Total loss': 0.5286702127600817}
2023-01-04 03:36:28,422 INFO:     Found new best model at epoch 2
2023-01-04 03:36:28,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:28,422 INFO:     Epoch: 3
2023-01-04 03:36:30,040 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5443382302920023, 'Total loss': 0.5443382302920023} | train loss {'Reaction outcome loss': 0.4814132830209058, 'Total loss': 0.4814132830209058}
2023-01-04 03:36:30,041 INFO:     Found new best model at epoch 3
2023-01-04 03:36:30,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:30,042 INFO:     Epoch: 4
2023-01-04 03:36:31,651 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5298872530460358, 'Total loss': 0.5298872530460358} | train loss {'Reaction outcome loss': 0.4612882955242758, 'Total loss': 0.4612882955242758}
2023-01-04 03:36:31,651 INFO:     Found new best model at epoch 4
2023-01-04 03:36:31,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:31,652 INFO:     Epoch: 5
2023-01-04 03:36:33,230 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5169023752212525, 'Total loss': 0.5169023752212525} | train loss {'Reaction outcome loss': 0.4438801504995512, 'Total loss': 0.4438801504995512}
2023-01-04 03:36:33,231 INFO:     Found new best model at epoch 5
2023-01-04 03:36:33,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:33,231 INFO:     Epoch: 6
2023-01-04 03:36:34,839 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5454133450984955, 'Total loss': 0.5454133450984955} | train loss {'Reaction outcome loss': 0.42196590434489906, 'Total loss': 0.42196590434489906}
2023-01-04 03:36:34,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:34,839 INFO:     Epoch: 7
2023-01-04 03:36:36,429 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4945975383122762, 'Total loss': 0.4945975383122762} | train loss {'Reaction outcome loss': 0.4102161986351796, 'Total loss': 0.4102161986351796}
2023-01-04 03:36:36,429 INFO:     Found new best model at epoch 7
2023-01-04 03:36:36,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:36,430 INFO:     Epoch: 8
2023-01-04 03:36:38,029 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5060000836849212, 'Total loss': 0.5060000836849212} | train loss {'Reaction outcome loss': 0.3954257107629994, 'Total loss': 0.3954257107629994}
2023-01-04 03:36:38,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:38,029 INFO:     Epoch: 9
2023-01-04 03:36:39,628 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47988195419311525, 'Total loss': 0.47988195419311525} | train loss {'Reaction outcome loss': 0.386608490963345, 'Total loss': 0.386608490963345}
2023-01-04 03:36:39,628 INFO:     Found new best model at epoch 9
2023-01-04 03:36:39,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:39,629 INFO:     Epoch: 10
2023-01-04 03:36:41,206 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49937471946080525, 'Total loss': 0.49937471946080525} | train loss {'Reaction outcome loss': 0.3777343961511455, 'Total loss': 0.3777343961511455}
2023-01-04 03:36:41,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:41,206 INFO:     Epoch: 11
2023-01-04 03:36:42,788 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5034957816203435, 'Total loss': 0.5034957816203435} | train loss {'Reaction outcome loss': 0.365418636361542, 'Total loss': 0.365418636361542}
2023-01-04 03:36:42,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:42,798 INFO:     Epoch: 12
2023-01-04 03:36:44,405 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4903894086678823, 'Total loss': 0.4903894086678823} | train loss {'Reaction outcome loss': 0.3629974782689596, 'Total loss': 0.3629974782689596}
2023-01-04 03:36:44,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:44,405 INFO:     Epoch: 13
2023-01-04 03:36:45,979 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4961679140726725, 'Total loss': 0.4961679140726725} | train loss {'Reaction outcome loss': 0.3526519766563307, 'Total loss': 0.3526519766563307}
2023-01-04 03:36:45,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:45,980 INFO:     Epoch: 14
2023-01-04 03:36:47,593 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4905128449201584, 'Total loss': 0.4905128449201584} | train loss {'Reaction outcome loss': 0.34701158365477686, 'Total loss': 0.34701158365477686}
2023-01-04 03:36:47,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:47,593 INFO:     Epoch: 15
2023-01-04 03:36:49,203 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4853220383326213, 'Total loss': 0.4853220383326213} | train loss {'Reaction outcome loss': 0.33844262472532294, 'Total loss': 0.33844262472532294}
2023-01-04 03:36:49,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:49,203 INFO:     Epoch: 16
2023-01-04 03:36:50,792 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48453325728575386, 'Total loss': 0.48453325728575386} | train loss {'Reaction outcome loss': 0.3321092380565424, 'Total loss': 0.3321092380565424}
2023-01-04 03:36:50,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:50,793 INFO:     Epoch: 17
2023-01-04 03:36:52,388 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47828806142012276, 'Total loss': 0.47828806142012276} | train loss {'Reaction outcome loss': 0.3260941894037217, 'Total loss': 0.3260941894037217}
2023-01-04 03:36:52,389 INFO:     Found new best model at epoch 17
2023-01-04 03:36:52,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:52,389 INFO:     Epoch: 18
2023-01-04 03:36:53,968 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4854060391585032, 'Total loss': 0.4854060391585032} | train loss {'Reaction outcome loss': 0.31991200899516326, 'Total loss': 0.31991200899516326}
2023-01-04 03:36:53,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:53,968 INFO:     Epoch: 19
2023-01-04 03:36:55,584 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49009669820467633, 'Total loss': 0.49009669820467633} | train loss {'Reaction outcome loss': 0.3158004669049937, 'Total loss': 0.3158004669049937}
2023-01-04 03:36:55,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:55,585 INFO:     Epoch: 20
2023-01-04 03:36:57,207 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49144710302352906, 'Total loss': 0.49144710302352906} | train loss {'Reaction outcome loss': 0.3091034396227611, 'Total loss': 0.3091034396227611}
2023-01-04 03:36:57,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:57,207 INFO:     Epoch: 21
2023-01-04 03:36:58,826 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48950149019559225, 'Total loss': 0.48950149019559225} | train loss {'Reaction outcome loss': 0.30446841668152413, 'Total loss': 0.30446841668152413}
2023-01-04 03:36:58,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:36:58,827 INFO:     Epoch: 22
2023-01-04 03:37:00,419 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4894048810005188, 'Total loss': 0.4894048810005188} | train loss {'Reaction outcome loss': 0.29848681089292833, 'Total loss': 0.29848681089292833}
2023-01-04 03:37:00,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:00,419 INFO:     Epoch: 23
2023-01-04 03:37:02,025 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4900156954924266, 'Total loss': 0.4900156954924266} | train loss {'Reaction outcome loss': 0.29529313736703194, 'Total loss': 0.29529313736703194}
2023-01-04 03:37:02,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:02,025 INFO:     Epoch: 24
2023-01-04 03:37:03,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5032045106093089, 'Total loss': 0.5032045106093089} | train loss {'Reaction outcome loss': 0.2894843578527587, 'Total loss': 0.2894843578527587}
2023-01-04 03:37:03,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:03,607 INFO:     Epoch: 25
2023-01-04 03:37:05,233 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5349441130956014, 'Total loss': 0.5349441130956014} | train loss {'Reaction outcome loss': 0.28299236748421536, 'Total loss': 0.28299236748421536}
2023-01-04 03:37:05,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:05,234 INFO:     Epoch: 26
2023-01-04 03:37:06,833 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5121217548847199, 'Total loss': 0.5121217548847199} | train loss {'Reaction outcome loss': 0.28249932613993145, 'Total loss': 0.28249932613993145}
2023-01-04 03:37:06,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:06,834 INFO:     Epoch: 27
2023-01-04 03:37:08,435 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48619393110275266, 'Total loss': 0.48619393110275266} | train loss {'Reaction outcome loss': 0.2769945892032938, 'Total loss': 0.2769945892032938}
2023-01-04 03:37:08,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:08,435 INFO:     Epoch: 28
2023-01-04 03:37:10,035 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.49627394874890646, 'Total loss': 0.49627394874890646} | train loss {'Reaction outcome loss': 0.2759427515632959, 'Total loss': 0.2759427515632959}
2023-01-04 03:37:10,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:10,036 INFO:     Epoch: 29
2023-01-04 03:37:11,623 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4739038050174713, 'Total loss': 0.4739038050174713} | train loss {'Reaction outcome loss': 0.2677275994946536, 'Total loss': 0.2677275994946536}
2023-01-04 03:37:11,623 INFO:     Found new best model at epoch 29
2023-01-04 03:37:11,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:11,624 INFO:     Epoch: 30
2023-01-04 03:37:13,238 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5022268931070963, 'Total loss': 0.5022268931070963} | train loss {'Reaction outcome loss': 0.2631662482382271, 'Total loss': 0.2631662482382271}
2023-01-04 03:37:13,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:13,239 INFO:     Epoch: 31
2023-01-04 03:37:14,833 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47313348650932313, 'Total loss': 0.47313348650932313} | train loss {'Reaction outcome loss': 0.2604230728067995, 'Total loss': 0.2604230728067995}
2023-01-04 03:37:14,834 INFO:     Found new best model at epoch 31
2023-01-04 03:37:14,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:14,835 INFO:     Epoch: 32
2023-01-04 03:37:16,438 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4918656647205353, 'Total loss': 0.4918656647205353} | train loss {'Reaction outcome loss': 0.2596435008901239, 'Total loss': 0.2596435008901239}
2023-01-04 03:37:16,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:16,438 INFO:     Epoch: 33
2023-01-04 03:37:18,012 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4957222898801168, 'Total loss': 0.4957222898801168} | train loss {'Reaction outcome loss': 0.2556560727129893, 'Total loss': 0.2556560727129893}
2023-01-04 03:37:18,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:18,013 INFO:     Epoch: 34
2023-01-04 03:37:19,610 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5004486223061879, 'Total loss': 0.5004486223061879} | train loss {'Reaction outcome loss': 0.2548928863193462, 'Total loss': 0.2548928863193462}
2023-01-04 03:37:19,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:19,610 INFO:     Epoch: 35
2023-01-04 03:37:21,195 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4808545410633087, 'Total loss': 0.4808545410633087} | train loss {'Reaction outcome loss': 0.2540405962554623, 'Total loss': 0.2540405962554623}
2023-01-04 03:37:21,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:21,195 INFO:     Epoch: 36
2023-01-04 03:37:22,791 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5044081469376882, 'Total loss': 0.5044081469376882} | train loss {'Reaction outcome loss': 0.24538594150921647, 'Total loss': 0.24538594150921647}
2023-01-04 03:37:22,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:22,791 INFO:     Epoch: 37
2023-01-04 03:37:24,387 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48073229839404424, 'Total loss': 0.48073229839404424} | train loss {'Reaction outcome loss': 0.24436739500083934, 'Total loss': 0.24436739500083934}
2023-01-04 03:37:24,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:24,387 INFO:     Epoch: 38
2023-01-04 03:37:25,965 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4930367946624756, 'Total loss': 0.4930367946624756} | train loss {'Reaction outcome loss': 0.2403078356730765, 'Total loss': 0.2403078356730765}
2023-01-04 03:37:25,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:25,965 INFO:     Epoch: 39
2023-01-04 03:37:27,582 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4902198364337285, 'Total loss': 0.4902198364337285} | train loss {'Reaction outcome loss': 0.2435944794434244, 'Total loss': 0.2435944794434244}
2023-01-04 03:37:27,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:27,582 INFO:     Epoch: 40
2023-01-04 03:37:29,190 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4971997340520223, 'Total loss': 0.4971997340520223} | train loss {'Reaction outcome loss': 0.23718095993230354, 'Total loss': 0.23718095993230354}
2023-01-04 03:37:29,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:29,190 INFO:     Epoch: 41
2023-01-04 03:37:30,772 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47674827178319296, 'Total loss': 0.47674827178319296} | train loss {'Reaction outcome loss': 0.23970177325595549, 'Total loss': 0.23970177325595549}
2023-01-04 03:37:30,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:30,773 INFO:     Epoch: 42
2023-01-04 03:37:32,370 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47464626232782997, 'Total loss': 0.47464626232782997} | train loss {'Reaction outcome loss': 0.2409230792757138, 'Total loss': 0.2409230792757138}
2023-01-04 03:37:32,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:32,370 INFO:     Epoch: 43
2023-01-04 03:37:33,965 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.485401850938797, 'Total loss': 0.485401850938797} | train loss {'Reaction outcome loss': 0.22843275927616033, 'Total loss': 0.22843275927616033}
2023-01-04 03:37:33,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:33,966 INFO:     Epoch: 44
2023-01-04 03:37:35,537 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48303937862316765, 'Total loss': 0.48303937862316765} | train loss {'Reaction outcome loss': 0.22573805810964626, 'Total loss': 0.22573805810964626}
2023-01-04 03:37:35,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:35,537 INFO:     Epoch: 45
2023-01-04 03:37:37,165 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48904080589612325, 'Total loss': 0.48904080589612325} | train loss {'Reaction outcome loss': 0.22185338899936946, 'Total loss': 0.22185338899936946}
2023-01-04 03:37:37,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:37,166 INFO:     Epoch: 46
2023-01-04 03:37:38,743 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4991593897342682, 'Total loss': 0.4991593897342682} | train loss {'Reaction outcome loss': 0.2227448672619294, 'Total loss': 0.2227448672619294}
2023-01-04 03:37:38,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:38,743 INFO:     Epoch: 47
2023-01-04 03:37:40,355 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48051680823167164, 'Total loss': 0.48051680823167164} | train loss {'Reaction outcome loss': 0.22312509453180004, 'Total loss': 0.22312509453180004}
2023-01-04 03:37:40,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:40,355 INFO:     Epoch: 48
2023-01-04 03:37:41,950 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4963458021481832, 'Total loss': 0.4963458021481832} | train loss {'Reaction outcome loss': 0.22279694448292686, 'Total loss': 0.22279694448292686}
2023-01-04 03:37:41,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:41,950 INFO:     Epoch: 49
2023-01-04 03:37:43,545 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.485787167151769, 'Total loss': 0.485787167151769} | train loss {'Reaction outcome loss': 0.21743034707058384, 'Total loss': 0.21743034707058384}
2023-01-04 03:37:43,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:43,545 INFO:     Epoch: 50
2023-01-04 03:37:45,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5010407725969951, 'Total loss': 0.5010407725969951} | train loss {'Reaction outcome loss': 0.21451108942678926, 'Total loss': 0.21451108942678926}
2023-01-04 03:37:45,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:45,143 INFO:     Epoch: 51
2023-01-04 03:37:46,776 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5127860258022944, 'Total loss': 0.5127860258022944} | train loss {'Reaction outcome loss': 0.21498134173199776, 'Total loss': 0.21498134173199776}
2023-01-04 03:37:46,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:46,776 INFO:     Epoch: 52
2023-01-04 03:37:48,358 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4838921993970871, 'Total loss': 0.4838921993970871} | train loss {'Reaction outcome loss': 0.21176731238644436, 'Total loss': 0.21176731238644436}
2023-01-04 03:37:48,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:48,359 INFO:     Epoch: 53
2023-01-04 03:37:49,986 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4936883459488551, 'Total loss': 0.4936883459488551} | train loss {'Reaction outcome loss': 0.21926829375772047, 'Total loss': 0.21926829375772047}
2023-01-04 03:37:49,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:49,986 INFO:     Epoch: 54
2023-01-04 03:37:51,601 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49429086844126385, 'Total loss': 0.49429086844126385} | train loss {'Reaction outcome loss': 0.21713215230134875, 'Total loss': 0.21713215230134875}
2023-01-04 03:37:51,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:51,602 INFO:     Epoch: 55
2023-01-04 03:37:53,197 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48997988750537236, 'Total loss': 0.48997988750537236} | train loss {'Reaction outcome loss': 0.21102818345947974, 'Total loss': 0.21102818345947974}
2023-01-04 03:37:53,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:53,198 INFO:     Epoch: 56
2023-01-04 03:37:54,792 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4859555582205454, 'Total loss': 0.4859555582205454} | train loss {'Reaction outcome loss': 0.20583586732443993, 'Total loss': 0.20583586732443993}
2023-01-04 03:37:54,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:54,792 INFO:     Epoch: 57
2023-01-04 03:37:56,382 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5011894325415294, 'Total loss': 0.5011894325415294} | train loss {'Reaction outcome loss': 0.2055695460059643, 'Total loss': 0.2055695460059643}
2023-01-04 03:37:56,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:56,383 INFO:     Epoch: 58
2023-01-04 03:37:57,965 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5139000634352366, 'Total loss': 0.5139000634352366} | train loss {'Reaction outcome loss': 0.20304294738302964, 'Total loss': 0.20304294738302964}
2023-01-04 03:37:57,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:57,965 INFO:     Epoch: 59
2023-01-04 03:37:59,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4915156642595927, 'Total loss': 0.4915156642595927} | train loss {'Reaction outcome loss': 0.20099897187479865, 'Total loss': 0.20099897187479865}
2023-01-04 03:37:59,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:37:59,556 INFO:     Epoch: 60
2023-01-04 03:38:01,145 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4778491407632828, 'Total loss': 0.4778491407632828} | train loss {'Reaction outcome loss': 0.20161537426521545, 'Total loss': 0.20161537426521545}
2023-01-04 03:38:01,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:01,145 INFO:     Epoch: 61
2023-01-04 03:38:02,716 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5028453608353932, 'Total loss': 0.5028453608353932} | train loss {'Reaction outcome loss': 0.19918800980720308, 'Total loss': 0.19918800980720308}
2023-01-04 03:38:02,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:02,717 INFO:     Epoch: 62
2023-01-04 03:38:04,306 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5211959520975749, 'Total loss': 0.5211959520975749} | train loss {'Reaction outcome loss': 0.19784409409745105, 'Total loss': 0.19784409409745105}
2023-01-04 03:38:04,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:04,306 INFO:     Epoch: 63
2023-01-04 03:38:05,876 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5403419872124989, 'Total loss': 0.5403419872124989} | train loss {'Reaction outcome loss': 0.2002248431056522, 'Total loss': 0.2002248431056522}
2023-01-04 03:38:05,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:05,877 INFO:     Epoch: 64
2023-01-04 03:38:07,493 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5379156947135926, 'Total loss': 0.5379156947135926} | train loss {'Reaction outcome loss': 0.20463523834065772, 'Total loss': 0.20463523834065772}
2023-01-04 03:38:07,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:07,493 INFO:     Epoch: 65
2023-01-04 03:38:09,119 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49850531419118244, 'Total loss': 0.49850531419118244} | train loss {'Reaction outcome loss': 0.19471405786116255, 'Total loss': 0.19471405786116255}
2023-01-04 03:38:09,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:09,119 INFO:     Epoch: 66
2023-01-04 03:38:10,724 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5002992143233617, 'Total loss': 0.5002992143233617} | train loss {'Reaction outcome loss': 0.1944985256979134, 'Total loss': 0.1944985256979134}
2023-01-04 03:38:10,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:10,724 INFO:     Epoch: 67
2023-01-04 03:38:12,336 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5075806478659312, 'Total loss': 0.5075806478659312} | train loss {'Reaction outcome loss': 0.1943464813672978, 'Total loss': 0.1943464813672978}
2023-01-04 03:38:12,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:12,337 INFO:     Epoch: 68
2023-01-04 03:38:13,948 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5104802330334981, 'Total loss': 0.5104802330334981} | train loss {'Reaction outcome loss': 0.19734873703429542, 'Total loss': 0.19734873703429542}
2023-01-04 03:38:13,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:13,948 INFO:     Epoch: 69
2023-01-04 03:38:15,548 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4985081116358439, 'Total loss': 0.4985081116358439} | train loss {'Reaction outcome loss': 0.18957825479826526, 'Total loss': 0.18957825479826526}
2023-01-04 03:38:15,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:15,549 INFO:     Epoch: 70
2023-01-04 03:38:17,178 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5132373710473378, 'Total loss': 0.5132373710473378} | train loss {'Reaction outcome loss': 0.18928517923505633, 'Total loss': 0.18928517923505633}
2023-01-04 03:38:17,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:17,178 INFO:     Epoch: 71
2023-01-04 03:38:18,805 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4834428052107493, 'Total loss': 0.4834428052107493} | train loss {'Reaction outcome loss': 0.20577927184142714, 'Total loss': 0.20577927184142714}
2023-01-04 03:38:18,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:18,806 INFO:     Epoch: 72
2023-01-04 03:38:20,407 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4956230858961741, 'Total loss': 0.4956230858961741} | train loss {'Reaction outcome loss': 0.19720653575453637, 'Total loss': 0.19720653575453637}
2023-01-04 03:38:20,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:20,407 INFO:     Epoch: 73
2023-01-04 03:38:22,033 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.52818869749705, 'Total loss': 0.52818869749705} | train loss {'Reaction outcome loss': 0.18723633027305672, 'Total loss': 0.18723633027305672}
2023-01-04 03:38:22,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:22,033 INFO:     Epoch: 74
2023-01-04 03:38:23,619 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.519478032986323, 'Total loss': 0.519478032986323} | train loss {'Reaction outcome loss': 0.1848208583744739, 'Total loss': 0.1848208583744739}
2023-01-04 03:38:23,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:23,620 INFO:     Epoch: 75
2023-01-04 03:38:25,233 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49551113446553546, 'Total loss': 0.49551113446553546} | train loss {'Reaction outcome loss': 0.18586463802995137, 'Total loss': 0.18586463802995137}
2023-01-04 03:38:25,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:25,233 INFO:     Epoch: 76
2023-01-04 03:38:26,825 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5104275683561961, 'Total loss': 0.5104275683561961} | train loss {'Reaction outcome loss': 0.18338602358573183, 'Total loss': 0.18338602358573183}
2023-01-04 03:38:26,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:26,826 INFO:     Epoch: 77
2023-01-04 03:38:28,418 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48621759489178656, 'Total loss': 0.48621759489178656} | train loss {'Reaction outcome loss': 0.18203449011280495, 'Total loss': 0.18203449011280495}
2023-01-04 03:38:28,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:28,418 INFO:     Epoch: 78
2023-01-04 03:38:30,021 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5203518152236939, 'Total loss': 0.5203518152236939} | train loss {'Reaction outcome loss': 0.1822096935920063, 'Total loss': 0.1822096935920063}
2023-01-04 03:38:30,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:30,021 INFO:     Epoch: 79
2023-01-04 03:38:31,628 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5355255246162415, 'Total loss': 0.5355255246162415} | train loss {'Reaction outcome loss': 0.18360466676750692, 'Total loss': 0.18360466676750692}
2023-01-04 03:38:31,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:31,628 INFO:     Epoch: 80
2023-01-04 03:38:33,225 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5485918780167898, 'Total loss': 0.5485918780167898} | train loss {'Reaction outcome loss': 0.18279955600788209, 'Total loss': 0.18279955600788209}
2023-01-04 03:38:33,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:33,226 INFO:     Epoch: 81
2023-01-04 03:38:34,840 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5270199904839198, 'Total loss': 0.5270199904839198} | train loss {'Reaction outcome loss': 0.18203672855963596, 'Total loss': 0.18203672855963596}
2023-01-04 03:38:34,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:34,840 INFO:     Epoch: 82
2023-01-04 03:38:36,445 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5014036536216736, 'Total loss': 0.5014036536216736} | train loss {'Reaction outcome loss': 0.1783447417626279, 'Total loss': 0.1783447417626279}
2023-01-04 03:38:36,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:36,445 INFO:     Epoch: 83
2023-01-04 03:38:38,040 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.544107981522878, 'Total loss': 0.544107981522878} | train loss {'Reaction outcome loss': 0.17782063756525848, 'Total loss': 0.17782063756525848}
2023-01-04 03:38:38,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:38,041 INFO:     Epoch: 84
2023-01-04 03:38:39,655 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.531745524207751, 'Total loss': 0.531745524207751} | train loss {'Reaction outcome loss': 0.1774309441823499, 'Total loss': 0.1774309441823499}
2023-01-04 03:38:39,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:39,655 INFO:     Epoch: 85
2023-01-04 03:38:41,272 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5352383414904277, 'Total loss': 0.5352383414904277} | train loss {'Reaction outcome loss': 0.17642808550290548, 'Total loss': 0.17642808550290548}
2023-01-04 03:38:41,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:41,272 INFO:     Epoch: 86
2023-01-04 03:38:42,873 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5214062194029491, 'Total loss': 0.5214062194029491} | train loss {'Reaction outcome loss': 0.17837164633353983, 'Total loss': 0.17837164633353983}
2023-01-04 03:38:42,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:42,874 INFO:     Epoch: 87
2023-01-04 03:38:44,489 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5008445580800375, 'Total loss': 0.5008445580800375} | train loss {'Reaction outcome loss': 0.17649017979915632, 'Total loss': 0.17649017979915632}
2023-01-04 03:38:44,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:44,490 INFO:     Epoch: 88
2023-01-04 03:38:46,108 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5368950555721919, 'Total loss': 0.5368950555721919} | train loss {'Reaction outcome loss': 0.1769659478922604, 'Total loss': 0.1769659478922604}
2023-01-04 03:38:46,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:46,108 INFO:     Epoch: 89
2023-01-04 03:38:47,709 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5381467531124751, 'Total loss': 0.5381467531124751} | train loss {'Reaction outcome loss': 0.17549539786732302, 'Total loss': 0.17549539786732302}
2023-01-04 03:38:47,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:47,710 INFO:     Epoch: 90
2023-01-04 03:38:49,323 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5479853490988413, 'Total loss': 0.5479853490988413} | train loss {'Reaction outcome loss': 0.17220702058287882, 'Total loss': 0.17220702058287882}
2023-01-04 03:38:49,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:49,323 INFO:     Epoch: 91
2023-01-04 03:38:50,917 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.528550795217355, 'Total loss': 0.528550795217355} | train loss {'Reaction outcome loss': 0.17165959629135719, 'Total loss': 0.17165959629135719}
2023-01-04 03:38:50,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:50,917 INFO:     Epoch: 92
2023-01-04 03:38:52,509 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5479544043540955, 'Total loss': 0.5479544043540955} | train loss {'Reaction outcome loss': 0.19411663890586814, 'Total loss': 0.19411663890586814}
2023-01-04 03:38:52,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:52,509 INFO:     Epoch: 93
2023-01-04 03:38:54,102 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5357877314090729, 'Total loss': 0.5357877314090729} | train loss {'Reaction outcome loss': 0.20467268152962156, 'Total loss': 0.20467268152962156}
2023-01-04 03:38:54,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:54,103 INFO:     Epoch: 94
2023-01-04 03:38:55,684 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.530738765001297, 'Total loss': 0.530738765001297} | train loss {'Reaction outcome loss': 0.17139522715782127, 'Total loss': 0.17139522715782127}
2023-01-04 03:38:55,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:55,684 INFO:     Epoch: 95
2023-01-04 03:38:57,287 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5226061503092448, 'Total loss': 0.5226061503092448} | train loss {'Reaction outcome loss': 0.17334082086217942, 'Total loss': 0.17334082086217942}
2023-01-04 03:38:57,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:57,288 INFO:     Epoch: 96
2023-01-04 03:38:58,902 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5346069554487864, 'Total loss': 0.5346069554487864} | train loss {'Reaction outcome loss': 0.1682257571156842, 'Total loss': 0.1682257571156842}
2023-01-04 03:38:58,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:38:58,903 INFO:     Epoch: 97
2023-01-04 03:39:00,482 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5353500465552012, 'Total loss': 0.5353500465552012} | train loss {'Reaction outcome loss': 0.1660238492025438, 'Total loss': 0.1660238492025438}
2023-01-04 03:39:00,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:00,483 INFO:     Epoch: 98
2023-01-04 03:39:02,075 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5407212282220523, 'Total loss': 0.5407212282220523} | train loss {'Reaction outcome loss': 0.16716749168193082, 'Total loss': 0.16716749168193082}
2023-01-04 03:39:02,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:02,075 INFO:     Epoch: 99
2023-01-04 03:39:03,668 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5241404583056768, 'Total loss': 0.5241404583056768} | train loss {'Reaction outcome loss': 0.1686172160055097, 'Total loss': 0.1686172160055097}
2023-01-04 03:39:03,668 INFO:     Best model found after epoch 32 of 100.
2023-01-04 03:39:03,668 INFO:   Done with stage: TRAINING
2023-01-04 03:39:03,668 INFO:   Starting stage: EVALUATION
2023-01-04 03:39:03,797 INFO:   Done with stage: EVALUATION
2023-01-04 03:39:03,797 INFO:   Leaving out SEQ value Fold_6
2023-01-04 03:39:03,810 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 03:39:03,810 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:39:04,461 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:39:04,461 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:39:04,530 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:39:04,530 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:39:04,530 INFO:     No hyperparam tuning for this model
2023-01-04 03:39:04,530 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:39:04,530 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:39:04,531 INFO:     None feature selector for col prot
2023-01-04 03:39:04,531 INFO:     None feature selector for col prot
2023-01-04 03:39:04,531 INFO:     None feature selector for col prot
2023-01-04 03:39:04,532 INFO:     None feature selector for col chem
2023-01-04 03:39:04,532 INFO:     None feature selector for col chem
2023-01-04 03:39:04,532 INFO:     None feature selector for col chem
2023-01-04 03:39:04,532 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:39:04,532 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:39:04,533 INFO:     Number of params in model 70141
2023-01-04 03:39:04,536 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:39:04,536 INFO:   Starting stage: TRAINING
2023-01-04 03:39:04,576 INFO:     Val loss before train {'Reaction outcome loss': 1.0423721313476562, 'Total loss': 1.0423721313476562}
2023-01-04 03:39:04,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:04,576 INFO:     Epoch: 0
2023-01-04 03:39:06,180 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.692425258954366, 'Total loss': 0.692425258954366} | train loss {'Reaction outcome loss': 0.832718610978729, 'Total loss': 0.832718610978729}
2023-01-04 03:39:06,180 INFO:     Found new best model at epoch 0
2023-01-04 03:39:06,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:06,181 INFO:     Epoch: 1
2023-01-04 03:39:07,790 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5705641984939576, 'Total loss': 0.5705641984939576} | train loss {'Reaction outcome loss': 0.597045567491855, 'Total loss': 0.597045567491855}
2023-01-04 03:39:07,790 INFO:     Found new best model at epoch 1
2023-01-04 03:39:07,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:07,791 INFO:     Epoch: 2
2023-01-04 03:39:09,373 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5283149719238281, 'Total loss': 0.5283149719238281} | train loss {'Reaction outcome loss': 0.5203399019120832, 'Total loss': 0.5203399019120832}
2023-01-04 03:39:09,373 INFO:     Found new best model at epoch 2
2023-01-04 03:39:09,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:09,374 INFO:     Epoch: 3
2023-01-04 03:39:10,981 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.519958374897639, 'Total loss': 0.519958374897639} | train loss {'Reaction outcome loss': 0.480900113386798, 'Total loss': 0.480900113386798}
2023-01-04 03:39:10,981 INFO:     Found new best model at epoch 3
2023-01-04 03:39:10,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:10,982 INFO:     Epoch: 4
2023-01-04 03:39:12,605 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5031450112660726, 'Total loss': 0.5031450112660726} | train loss {'Reaction outcome loss': 0.4523388056440904, 'Total loss': 0.4523388056440904}
2023-01-04 03:39:12,606 INFO:     Found new best model at epoch 4
2023-01-04 03:39:12,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:12,607 INFO:     Epoch: 5
2023-01-04 03:39:14,198 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49905563791592916, 'Total loss': 0.49905563791592916} | train loss {'Reaction outcome loss': 0.43404700486023073, 'Total loss': 0.43404700486023073}
2023-01-04 03:39:14,199 INFO:     Found new best model at epoch 5
2023-01-04 03:39:14,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:14,199 INFO:     Epoch: 6
2023-01-04 03:39:15,793 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5063048829634984, 'Total loss': 0.5063048829634984} | train loss {'Reaction outcome loss': 0.41819898880991263, 'Total loss': 0.41819898880991263}
2023-01-04 03:39:15,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:15,793 INFO:     Epoch: 7
2023-01-04 03:39:17,404 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4767667790253957, 'Total loss': 0.4767667790253957} | train loss {'Reaction outcome loss': 0.4050639728991994, 'Total loss': 0.4050639728991994}
2023-01-04 03:39:17,404 INFO:     Found new best model at epoch 7
2023-01-04 03:39:17,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:17,405 INFO:     Epoch: 8
2023-01-04 03:39:19,005 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47866370975971223, 'Total loss': 0.47866370975971223} | train loss {'Reaction outcome loss': 0.39343190994718874, 'Total loss': 0.39343190994718874}
2023-01-04 03:39:19,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:19,005 INFO:     Epoch: 9
2023-01-04 03:39:20,605 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4812576194604238, 'Total loss': 0.4812576194604238} | train loss {'Reaction outcome loss': 0.3844404940893504, 'Total loss': 0.3844404940893504}
2023-01-04 03:39:20,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:20,605 INFO:     Epoch: 10
2023-01-04 03:39:22,202 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46653276681900024, 'Total loss': 0.46653276681900024} | train loss {'Reaction outcome loss': 0.37623241239829186, 'Total loss': 0.37623241239829186}
2023-01-04 03:39:22,202 INFO:     Found new best model at epoch 10
2023-01-04 03:39:22,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:22,203 INFO:     Epoch: 11
2023-01-04 03:39:23,782 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4773381531238556, 'Total loss': 0.4773381531238556} | train loss {'Reaction outcome loss': 0.36635783965622043, 'Total loss': 0.36635783965622043}
2023-01-04 03:39:23,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:23,782 INFO:     Epoch: 12
2023-01-04 03:39:25,399 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.467363570133845, 'Total loss': 0.467363570133845} | train loss {'Reaction outcome loss': 0.3632635425251744, 'Total loss': 0.3632635425251744}
2023-01-04 03:39:25,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:25,400 INFO:     Epoch: 13
2023-01-04 03:39:27,009 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46321826974550884, 'Total loss': 0.46321826974550884} | train loss {'Reaction outcome loss': 0.35486808276671367, 'Total loss': 0.35486808276671367}
2023-01-04 03:39:27,010 INFO:     Found new best model at epoch 13
2023-01-04 03:39:27,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:27,011 INFO:     Epoch: 14
2023-01-04 03:39:28,601 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47405115962028505, 'Total loss': 0.47405115962028505} | train loss {'Reaction outcome loss': 0.3461881828652392, 'Total loss': 0.3461881828652392}
2023-01-04 03:39:28,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:28,601 INFO:     Epoch: 15
2023-01-04 03:39:30,229 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4733823756376902, 'Total loss': 0.4733823756376902} | train loss {'Reaction outcome loss': 0.3406126397772817, 'Total loss': 0.3406126397772817}
2023-01-04 03:39:30,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:30,229 INFO:     Epoch: 16
2023-01-04 03:39:31,822 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46901704867680866, 'Total loss': 0.46901704867680866} | train loss {'Reaction outcome loss': 0.3344603028108067, 'Total loss': 0.3344603028108067}
2023-01-04 03:39:31,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:31,823 INFO:     Epoch: 17
2023-01-04 03:39:33,432 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4585376719633738, 'Total loss': 0.4585376719633738} | train loss {'Reaction outcome loss': 0.32745614844216336, 'Total loss': 0.32745614844216336}
2023-01-04 03:39:33,432 INFO:     Found new best model at epoch 17
2023-01-04 03:39:33,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:33,433 INFO:     Epoch: 18
2023-01-04 03:39:35,020 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.448556461930275, 'Total loss': 0.448556461930275} | train loss {'Reaction outcome loss': 0.32464530491118826, 'Total loss': 0.32464530491118826}
2023-01-04 03:39:35,020 INFO:     Found new best model at epoch 18
2023-01-04 03:39:35,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:35,021 INFO:     Epoch: 19
2023-01-04 03:39:36,618 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46264840265115104, 'Total loss': 0.46264840265115104} | train loss {'Reaction outcome loss': 0.318199253738572, 'Total loss': 0.318199253738572}
2023-01-04 03:39:36,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:36,619 INFO:     Epoch: 20
2023-01-04 03:39:38,245 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45976035396258036, 'Total loss': 0.45976035396258036} | train loss {'Reaction outcome loss': 0.31178470789740664, 'Total loss': 0.31178470789740664}
2023-01-04 03:39:38,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:38,245 INFO:     Epoch: 21
2023-01-04 03:39:39,860 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46455030838648476, 'Total loss': 0.46455030838648476} | train loss {'Reaction outcome loss': 0.3095179300768711, 'Total loss': 0.3095179300768711}
2023-01-04 03:39:39,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:39,860 INFO:     Epoch: 22
2023-01-04 03:39:41,451 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4703540652990341, 'Total loss': 0.4703540652990341} | train loss {'Reaction outcome loss': 0.30338822719422487, 'Total loss': 0.30338822719422487}
2023-01-04 03:39:41,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:41,451 INFO:     Epoch: 23
2023-01-04 03:39:43,070 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4604054550329844, 'Total loss': 0.4604054550329844} | train loss {'Reaction outcome loss': 0.2999688414083491, 'Total loss': 0.2999688414083491}
2023-01-04 03:39:43,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:43,070 INFO:     Epoch: 24
2023-01-04 03:39:44,656 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4353082666794459, 'Total loss': 0.4353082666794459} | train loss {'Reaction outcome loss': 0.2950179613521491, 'Total loss': 0.2950179613521491}
2023-01-04 03:39:44,656 INFO:     Found new best model at epoch 24
2023-01-04 03:39:44,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:44,657 INFO:     Epoch: 25
2023-01-04 03:39:46,278 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44230185747146605, 'Total loss': 0.44230185747146605} | train loss {'Reaction outcome loss': 0.2915644205111459, 'Total loss': 0.2915644205111459}
2023-01-04 03:39:46,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:46,278 INFO:     Epoch: 26
2023-01-04 03:39:47,900 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4491946076353391, 'Total loss': 0.4491946076353391} | train loss {'Reaction outcome loss': 0.288108526799653, 'Total loss': 0.288108526799653}
2023-01-04 03:39:47,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:47,900 INFO:     Epoch: 27
2023-01-04 03:39:49,500 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4646204590797424, 'Total loss': 0.4646204590797424} | train loss {'Reaction outcome loss': 0.2846206340010846, 'Total loss': 0.2846206340010846}
2023-01-04 03:39:49,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:49,500 INFO:     Epoch: 28
2023-01-04 03:39:51,136 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4578557272752126, 'Total loss': 0.4578557272752126} | train loss {'Reaction outcome loss': 0.2814935783885877, 'Total loss': 0.2814935783885877}
2023-01-04 03:39:51,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:51,136 INFO:     Epoch: 29
2023-01-04 03:39:52,766 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45467086136341095, 'Total loss': 0.45467086136341095} | train loss {'Reaction outcome loss': 0.2766674793853226, 'Total loss': 0.2766674793853226}
2023-01-04 03:39:52,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:52,766 INFO:     Epoch: 30
2023-01-04 03:39:54,370 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4554239183664322, 'Total loss': 0.4554239183664322} | train loss {'Reaction outcome loss': 0.27759202716313974, 'Total loss': 0.27759202716313974}
2023-01-04 03:39:54,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:54,370 INFO:     Epoch: 31
2023-01-04 03:39:55,996 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.443785297870636, 'Total loss': 0.443785297870636} | train loss {'Reaction outcome loss': 0.2698644622756901, 'Total loss': 0.2698644622756901}
2023-01-04 03:39:55,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:55,997 INFO:     Epoch: 32
2023-01-04 03:39:57,608 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4526698182026545, 'Total loss': 0.4526698182026545} | train loss {'Reaction outcome loss': 0.2683619896642568, 'Total loss': 0.2683619896642568}
2023-01-04 03:39:57,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:57,608 INFO:     Epoch: 33
2023-01-04 03:39:58,957 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45894381602605183, 'Total loss': 0.45894381602605183} | train loss {'Reaction outcome loss': 0.2656599704431713, 'Total loss': 0.2656599704431713}
2023-01-04 03:39:58,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:39:58,958 INFO:     Epoch: 34
2023-01-04 03:40:00,036 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43980802794297535, 'Total loss': 0.43980802794297535} | train loss {'Reaction outcome loss': 0.26307421886372223, 'Total loss': 0.26307421886372223}
2023-01-04 03:40:00,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:00,036 INFO:     Epoch: 35
2023-01-04 03:40:01,116 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4428528765837351, 'Total loss': 0.4428528765837351} | train loss {'Reaction outcome loss': 0.26167694191424856, 'Total loss': 0.26167694191424856}
2023-01-04 03:40:01,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:01,116 INFO:     Epoch: 36
2023-01-04 03:40:02,189 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4495954116185506, 'Total loss': 0.4495954116185506} | train loss {'Reaction outcome loss': 0.2566237026280875, 'Total loss': 0.2566237026280875}
2023-01-04 03:40:02,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:02,190 INFO:     Epoch: 37
2023-01-04 03:40:03,476 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4468295633792877, 'Total loss': 0.4468295633792877} | train loss {'Reaction outcome loss': 0.25715899705510276, 'Total loss': 0.25715899705510276}
2023-01-04 03:40:03,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:03,477 INFO:     Epoch: 38
2023-01-04 03:40:05,061 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4541278163592021, 'Total loss': 0.4541278163592021} | train loss {'Reaction outcome loss': 0.253554328146394, 'Total loss': 0.253554328146394}
2023-01-04 03:40:05,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:05,062 INFO:     Epoch: 39
2023-01-04 03:40:06,687 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44183454712231957, 'Total loss': 0.44183454712231957} | train loss {'Reaction outcome loss': 0.2506776707589842, 'Total loss': 0.2506776707589842}
2023-01-04 03:40:06,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:06,688 INFO:     Epoch: 40
2023-01-04 03:40:08,312 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45509386360645293, 'Total loss': 0.45509386360645293} | train loss {'Reaction outcome loss': 0.2470995820386315, 'Total loss': 0.2470995820386315}
2023-01-04 03:40:08,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:08,312 INFO:     Epoch: 41
2023-01-04 03:40:09,900 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4542194535334905, 'Total loss': 0.4542194535334905} | train loss {'Reaction outcome loss': 0.24552942860858104, 'Total loss': 0.24552942860858104}
2023-01-04 03:40:09,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:09,900 INFO:     Epoch: 42
2023-01-04 03:40:11,524 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4509536494811376, 'Total loss': 0.4509536494811376} | train loss {'Reaction outcome loss': 0.24275831642832996, 'Total loss': 0.24275831642832996}
2023-01-04 03:40:11,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:11,524 INFO:     Epoch: 43
2023-01-04 03:40:13,101 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4385529061158498, 'Total loss': 0.4385529061158498} | train loss {'Reaction outcome loss': 0.24143980384303343, 'Total loss': 0.24143980384303343}
2023-01-04 03:40:13,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:13,101 INFO:     Epoch: 44
2023-01-04 03:40:14,702 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4540860116481781, 'Total loss': 0.4540860116481781} | train loss {'Reaction outcome loss': 0.2346723540702882, 'Total loss': 0.2346723540702882}
2023-01-04 03:40:14,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:14,703 INFO:     Epoch: 45
2023-01-04 03:40:16,303 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.475877246260643, 'Total loss': 0.475877246260643} | train loss {'Reaction outcome loss': 0.23866303850113268, 'Total loss': 0.23866303850113268}
2023-01-04 03:40:16,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:16,303 INFO:     Epoch: 46
2023-01-04 03:40:17,886 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46351142326990763, 'Total loss': 0.46351142326990763} | train loss {'Reaction outcome loss': 0.23379863198806233, 'Total loss': 0.23379863198806233}
2023-01-04 03:40:17,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:17,886 INFO:     Epoch: 47
2023-01-04 03:40:19,521 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47320881485939026, 'Total loss': 0.47320881485939026} | train loss {'Reaction outcome loss': 0.23194099118132883, 'Total loss': 0.23194099118132883}
2023-01-04 03:40:19,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:19,521 INFO:     Epoch: 48
2023-01-04 03:40:21,123 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46234801212946575, 'Total loss': 0.46234801212946575} | train loss {'Reaction outcome loss': 0.23166416327230335, 'Total loss': 0.23166416327230335}
2023-01-04 03:40:21,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:21,123 INFO:     Epoch: 49
2023-01-04 03:40:22,752 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.482406493028005, 'Total loss': 0.482406493028005} | train loss {'Reaction outcome loss': 0.22883910380492142, 'Total loss': 0.22883910380492142}
2023-01-04 03:40:22,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:22,753 INFO:     Epoch: 50
2023-01-04 03:40:24,380 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4549184838930766, 'Total loss': 0.4549184838930766} | train loss {'Reaction outcome loss': 0.22763600724914013, 'Total loss': 0.22763600724914013}
2023-01-04 03:40:24,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:24,380 INFO:     Epoch: 51
2023-01-04 03:40:26,002 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4803210645914078, 'Total loss': 0.4803210645914078} | train loss {'Reaction outcome loss': 0.22550811077928715, 'Total loss': 0.22550811077928715}
2023-01-04 03:40:26,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:26,003 INFO:     Epoch: 52
2023-01-04 03:40:27,587 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45021652777989707, 'Total loss': 0.45021652777989707} | train loss {'Reaction outcome loss': 0.2260624500603452, 'Total loss': 0.2260624500603452}
2023-01-04 03:40:27,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:27,587 INFO:     Epoch: 53
2023-01-04 03:40:29,191 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46733681857585907, 'Total loss': 0.46733681857585907} | train loss {'Reaction outcome loss': 0.22127428712720046, 'Total loss': 0.22127428712720046}
2023-01-04 03:40:29,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:29,191 INFO:     Epoch: 54
2023-01-04 03:40:30,779 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49238238433996834, 'Total loss': 0.49238238433996834} | train loss {'Reaction outcome loss': 0.22131198377008904, 'Total loss': 0.22131198377008904}
2023-01-04 03:40:30,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:30,779 INFO:     Epoch: 55
2023-01-04 03:40:32,393 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48276472091674805, 'Total loss': 0.48276472091674805} | train loss {'Reaction outcome loss': 0.2204472875552057, 'Total loss': 0.2204472875552057}
2023-01-04 03:40:32,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:32,394 INFO:     Epoch: 56
2023-01-04 03:40:34,024 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48187832832336425, 'Total loss': 0.48187832832336425} | train loss {'Reaction outcome loss': 0.2171711403109967, 'Total loss': 0.2171711403109967}
2023-01-04 03:40:34,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:34,024 INFO:     Epoch: 57
2023-01-04 03:40:35,656 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4726725906133652, 'Total loss': 0.4726725906133652} | train loss {'Reaction outcome loss': 0.21517565393221938, 'Total loss': 0.21517565393221938}
2023-01-04 03:40:35,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:35,657 INFO:     Epoch: 58
2023-01-04 03:40:37,258 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47632533411184946, 'Total loss': 0.47632533411184946} | train loss {'Reaction outcome loss': 0.21353419221910758, 'Total loss': 0.21353419221910758}
2023-01-04 03:40:37,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:37,258 INFO:     Epoch: 59
2023-01-04 03:40:38,861 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.477650914589564, 'Total loss': 0.477650914589564} | train loss {'Reaction outcome loss': 0.2123786727578416, 'Total loss': 0.2123786727578416}
2023-01-04 03:40:38,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:38,861 INFO:     Epoch: 60
2023-01-04 03:40:40,452 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4771693915128708, 'Total loss': 0.4771693915128708} | train loss {'Reaction outcome loss': 0.21157965814486307, 'Total loss': 0.21157965814486307}
2023-01-04 03:40:40,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:40,452 INFO:     Epoch: 61
2023-01-04 03:40:42,046 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4901866793632507, 'Total loss': 0.4901866793632507} | train loss {'Reaction outcome loss': 0.2088289850589816, 'Total loss': 0.2088289850589816}
2023-01-04 03:40:42,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:42,046 INFO:     Epoch: 62
2023-01-04 03:40:43,672 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47572947641213736, 'Total loss': 0.47572947641213736} | train loss {'Reaction outcome loss': 0.20976185279525145, 'Total loss': 0.20976185279525145}
2023-01-04 03:40:43,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:43,672 INFO:     Epoch: 63
2023-01-04 03:40:45,255 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4848668495814005, 'Total loss': 0.4848668495814005} | train loss {'Reaction outcome loss': 0.20771757970204316, 'Total loss': 0.20771757970204316}
2023-01-04 03:40:45,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:45,256 INFO:     Epoch: 64
2023-01-04 03:40:46,852 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48298511703809105, 'Total loss': 0.48298511703809105} | train loss {'Reaction outcome loss': 0.20698545059518694, 'Total loss': 0.20698545059518694}
2023-01-04 03:40:46,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:46,853 INFO:     Epoch: 65
2023-01-04 03:40:48,434 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47385937968889874, 'Total loss': 0.47385937968889874} | train loss {'Reaction outcome loss': 0.2042106080612013, 'Total loss': 0.2042106080612013}
2023-01-04 03:40:48,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:48,434 INFO:     Epoch: 66
2023-01-04 03:40:50,050 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4903992275396983, 'Total loss': 0.4903992275396983} | train loss {'Reaction outcome loss': 0.20439232536171317, 'Total loss': 0.20439232536171317}
2023-01-04 03:40:50,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:50,051 INFO:     Epoch: 67
2023-01-04 03:40:51,676 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48782220085461936, 'Total loss': 0.48782220085461936} | train loss {'Reaction outcome loss': 0.20103198991220997, 'Total loss': 0.20103198991220997}
2023-01-04 03:40:51,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:51,676 INFO:     Epoch: 68
2023-01-04 03:40:53,292 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49293915430704754, 'Total loss': 0.49293915430704754} | train loss {'Reaction outcome loss': 0.20197227711550594, 'Total loss': 0.20197227711550594}
2023-01-04 03:40:53,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:53,292 INFO:     Epoch: 69
2023-01-04 03:40:54,890 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46857512593269346, 'Total loss': 0.46857512593269346} | train loss {'Reaction outcome loss': 0.19975699400966349, 'Total loss': 0.19975699400966349}
2023-01-04 03:40:54,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:54,890 INFO:     Epoch: 70
2023-01-04 03:40:56,494 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48479345937569934, 'Total loss': 0.48479345937569934} | train loss {'Reaction outcome loss': 0.19830546073534858, 'Total loss': 0.19830546073534858}
2023-01-04 03:40:56,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:56,494 INFO:     Epoch: 71
2023-01-04 03:40:58,096 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4856072356303533, 'Total loss': 0.4856072356303533} | train loss {'Reaction outcome loss': 0.19696665305092878, 'Total loss': 0.19696665305092878}
2023-01-04 03:40:58,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:58,096 INFO:     Epoch: 72
2023-01-04 03:40:59,726 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.517909316221873, 'Total loss': 0.517909316221873} | train loss {'Reaction outcome loss': 0.19781081128314085, 'Total loss': 0.19781081128314085}
2023-01-04 03:40:59,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:40:59,726 INFO:     Epoch: 73
2023-01-04 03:41:01,351 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4816823701063792, 'Total loss': 0.4816823701063792} | train loss {'Reaction outcome loss': 0.1946761314673114, 'Total loss': 0.1946761314673114}
2023-01-04 03:41:01,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:01,351 INFO:     Epoch: 74
2023-01-04 03:41:02,958 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4863369921843211, 'Total loss': 0.4863369921843211} | train loss {'Reaction outcome loss': 0.19484457338652456, 'Total loss': 0.19484457338652456}
2023-01-04 03:41:02,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:02,959 INFO:     Epoch: 75
2023-01-04 03:41:04,559 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46987754801909126, 'Total loss': 0.46987754801909126} | train loss {'Reaction outcome loss': 0.1939820720400621, 'Total loss': 0.1939820720400621}
2023-01-04 03:41:04,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:04,560 INFO:     Epoch: 76
2023-01-04 03:41:06,142 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4877001365025838, 'Total loss': 0.4877001365025838} | train loss {'Reaction outcome loss': 0.19251101466050433, 'Total loss': 0.19251101466050433}
2023-01-04 03:41:06,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:06,143 INFO:     Epoch: 77
2023-01-04 03:41:07,772 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5030298928419749, 'Total loss': 0.5030298928419749} | train loss {'Reaction outcome loss': 0.19122959327773068, 'Total loss': 0.19122959327773068}
2023-01-04 03:41:07,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:07,772 INFO:     Epoch: 78
2023-01-04 03:41:09,401 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49930057922999066, 'Total loss': 0.49930057922999066} | train loss {'Reaction outcome loss': 0.18846414640330666, 'Total loss': 0.18846414640330666}
2023-01-04 03:41:09,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:09,402 INFO:     Epoch: 79
2023-01-04 03:41:11,035 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47736456990242004, 'Total loss': 0.47736456990242004} | train loss {'Reaction outcome loss': 0.18892257321720088, 'Total loss': 0.18892257321720088}
2023-01-04 03:41:11,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:11,036 INFO:     Epoch: 80
2023-01-04 03:41:12,650 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5178438464800517, 'Total loss': 0.5178438464800517} | train loss {'Reaction outcome loss': 0.1879281044167732, 'Total loss': 0.1879281044167732}
2023-01-04 03:41:12,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:12,651 INFO:     Epoch: 81
2023-01-04 03:41:14,290 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5044778317213059, 'Total loss': 0.5044778317213059} | train loss {'Reaction outcome loss': 0.18707322591532438, 'Total loss': 0.18707322591532438}
2023-01-04 03:41:14,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:14,291 INFO:     Epoch: 82
2023-01-04 03:41:15,919 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48352789084116615, 'Total loss': 0.48352789084116615} | train loss {'Reaction outcome loss': 0.18767516111907975, 'Total loss': 0.18767516111907975}
2023-01-04 03:41:15,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:15,920 INFO:     Epoch: 83
2023-01-04 03:41:17,545 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.519737168153127, 'Total loss': 0.519737168153127} | train loss {'Reaction outcome loss': 0.18648583798363322, 'Total loss': 0.18648583798363322}
2023-01-04 03:41:17,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:17,546 INFO:     Epoch: 84
2023-01-04 03:41:19,178 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49555211265881854, 'Total loss': 0.49555211265881854} | train loss {'Reaction outcome loss': 0.18779849979206112, 'Total loss': 0.18779849979206112}
2023-01-04 03:41:19,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:19,178 INFO:     Epoch: 85
2023-01-04 03:41:20,824 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49896004796028137, 'Total loss': 0.49896004796028137} | train loss {'Reaction outcome loss': 0.18420730305277483, 'Total loss': 0.18420730305277483}
2023-01-04 03:41:20,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:20,824 INFO:     Epoch: 86
2023-01-04 03:41:22,426 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5059991111358006, 'Total loss': 0.5059991111358006} | train loss {'Reaction outcome loss': 0.18382298248393011, 'Total loss': 0.18382298248393011}
2023-01-04 03:41:22,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:22,427 INFO:     Epoch: 87
2023-01-04 03:41:24,050 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.515096002817154, 'Total loss': 0.515096002817154} | train loss {'Reaction outcome loss': 0.18344050871766432, 'Total loss': 0.18344050871766432}
2023-01-04 03:41:24,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:24,050 INFO:     Epoch: 88
2023-01-04 03:41:25,678 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5182991862297058, 'Total loss': 0.5182991862297058} | train loss {'Reaction outcome loss': 0.18304284566858722, 'Total loss': 0.18304284566858722}
2023-01-04 03:41:25,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:25,679 INFO:     Epoch: 89
2023-01-04 03:41:27,319 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49948831597963966, 'Total loss': 0.49948831597963966} | train loss {'Reaction outcome loss': 0.1820290287526237, 'Total loss': 0.1820290287526237}
2023-01-04 03:41:27,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:27,319 INFO:     Epoch: 90
2023-01-04 03:41:28,950 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48961900770664213, 'Total loss': 0.48961900770664213} | train loss {'Reaction outcome loss': 0.18104744059729663, 'Total loss': 0.18104744059729663}
2023-01-04 03:41:28,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:28,950 INFO:     Epoch: 91
2023-01-04 03:41:30,558 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5141887416442236, 'Total loss': 0.5141887416442236} | train loss {'Reaction outcome loss': 0.17777393450321705, 'Total loss': 0.17777393450321705}
2023-01-04 03:41:30,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:30,559 INFO:     Epoch: 92
2023-01-04 03:41:32,194 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5040262808402379, 'Total loss': 0.5040262808402379} | train loss {'Reaction outcome loss': 0.180115099471829, 'Total loss': 0.180115099471829}
2023-01-04 03:41:32,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:32,195 INFO:     Epoch: 93
2023-01-04 03:41:33,816 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5023958643277486, 'Total loss': 0.5023958643277486} | train loss {'Reaction outcome loss': 0.1783854188901853, 'Total loss': 0.1783854188901853}
2023-01-04 03:41:33,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:33,816 INFO:     Epoch: 94
2023-01-04 03:41:35,455 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5270602782567342, 'Total loss': 0.5270602782567342} | train loss {'Reaction outcome loss': 0.17625063489315634, 'Total loss': 0.17625063489315634}
2023-01-04 03:41:35,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:35,455 INFO:     Epoch: 95
2023-01-04 03:41:37,091 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5087823212146759, 'Total loss': 0.5087823212146759} | train loss {'Reaction outcome loss': 0.17832679236946553, 'Total loss': 0.17832679236946553}
2023-01-04 03:41:37,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:37,092 INFO:     Epoch: 96
2023-01-04 03:41:38,718 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5147714058558146, 'Total loss': 0.5147714058558146} | train loss {'Reaction outcome loss': 0.17791284725661743, 'Total loss': 0.17791284725661743}
2023-01-04 03:41:38,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:38,719 INFO:     Epoch: 97
2023-01-04 03:41:40,312 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5049130479494731, 'Total loss': 0.5049130479494731} | train loss {'Reaction outcome loss': 0.17480729552597776, 'Total loss': 0.17480729552597776}
2023-01-04 03:41:40,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:40,312 INFO:     Epoch: 98
2023-01-04 03:41:41,942 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5222735285758973, 'Total loss': 0.5222735285758973} | train loss {'Reaction outcome loss': 0.17774548312978625, 'Total loss': 0.17774548312978625}
2023-01-04 03:41:41,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:41,943 INFO:     Epoch: 99
2023-01-04 03:41:43,518 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.533514936765035, 'Total loss': 0.533514936765035} | train loss {'Reaction outcome loss': 0.17487747433329748, 'Total loss': 0.17487747433329748}
2023-01-04 03:41:43,518 INFO:     Best model found after epoch 25 of 100.
2023-01-04 03:41:43,518 INFO:   Done with stage: TRAINING
2023-01-04 03:41:43,518 INFO:   Starting stage: EVALUATION
2023-01-04 03:41:43,641 INFO:   Done with stage: EVALUATION
2023-01-04 03:41:43,641 INFO:   Leaving out SEQ value Fold_7
2023-01-04 03:41:43,654 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 03:41:43,654 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:41:44,298 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:41:44,298 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:41:44,364 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:41:44,365 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:41:44,365 INFO:     No hyperparam tuning for this model
2023-01-04 03:41:44,365 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:41:44,365 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:41:44,365 INFO:     None feature selector for col prot
2023-01-04 03:41:44,366 INFO:     None feature selector for col prot
2023-01-04 03:41:44,366 INFO:     None feature selector for col prot
2023-01-04 03:41:44,366 INFO:     None feature selector for col chem
2023-01-04 03:41:44,366 INFO:     None feature selector for col chem
2023-01-04 03:41:44,366 INFO:     None feature selector for col chem
2023-01-04 03:41:44,366 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:41:44,367 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:41:44,368 INFO:     Number of params in model 70141
2023-01-04 03:41:44,371 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:41:44,371 INFO:   Starting stage: TRAINING
2023-01-04 03:41:44,414 INFO:     Val loss before train {'Reaction outcome loss': 0.988213058312734, 'Total loss': 0.988213058312734}
2023-01-04 03:41:44,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:44,414 INFO:     Epoch: 0
2023-01-04 03:41:46,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6558278799057007, 'Total loss': 0.6558278799057007} | train loss {'Reaction outcome loss': 0.8315231640269791, 'Total loss': 0.8315231640269791}
2023-01-04 03:41:46,024 INFO:     Found new best model at epoch 0
2023-01-04 03:41:46,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:46,025 INFO:     Epoch: 1
2023-01-04 03:41:47,666 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5562728365262349, 'Total loss': 0.5562728365262349} | train loss {'Reaction outcome loss': 0.5738034803037315, 'Total loss': 0.5738034803037315}
2023-01-04 03:41:47,666 INFO:     Found new best model at epoch 1
2023-01-04 03:41:47,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:47,667 INFO:     Epoch: 2
2023-01-04 03:41:49,255 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4870952546596527, 'Total loss': 0.4870952546596527} | train loss {'Reaction outcome loss': 0.5106106577036174, 'Total loss': 0.5106106577036174}
2023-01-04 03:41:49,256 INFO:     Found new best model at epoch 2
2023-01-04 03:41:49,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:49,256 INFO:     Epoch: 3
2023-01-04 03:41:50,835 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47507898410161337, 'Total loss': 0.47507898410161337} | train loss {'Reaction outcome loss': 0.46901092926661175, 'Total loss': 0.46901092926661175}
2023-01-04 03:41:50,835 INFO:     Found new best model at epoch 3
2023-01-04 03:41:50,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:50,836 INFO:     Epoch: 4
2023-01-04 03:41:52,455 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45971466700236, 'Total loss': 0.45971466700236} | train loss {'Reaction outcome loss': 0.44482661583300587, 'Total loss': 0.44482661583300587}
2023-01-04 03:41:52,456 INFO:     Found new best model at epoch 4
2023-01-04 03:41:52,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:52,456 INFO:     Epoch: 5
2023-01-04 03:41:54,085 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44121539493401846, 'Total loss': 0.44121539493401846} | train loss {'Reaction outcome loss': 0.427350498256746, 'Total loss': 0.427350498256746}
2023-01-04 03:41:54,085 INFO:     Found new best model at epoch 5
2023-01-04 03:41:54,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:54,086 INFO:     Epoch: 6
2023-01-04 03:41:55,704 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44575816293557485, 'Total loss': 0.44575816293557485} | train loss {'Reaction outcome loss': 0.41416767800557497, 'Total loss': 0.41416767800557497}
2023-01-04 03:41:55,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:55,704 INFO:     Epoch: 7
2023-01-04 03:41:57,305 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43964059551556905, 'Total loss': 0.43964059551556905} | train loss {'Reaction outcome loss': 0.4029532989142868, 'Total loss': 0.4029532989142868}
2023-01-04 03:41:57,305 INFO:     Found new best model at epoch 7
2023-01-04 03:41:57,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:57,306 INFO:     Epoch: 8
2023-01-04 03:41:58,925 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44282976587613426, 'Total loss': 0.44282976587613426} | train loss {'Reaction outcome loss': 0.39056958949220355, 'Total loss': 0.39056958949220355}
2023-01-04 03:41:58,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:41:58,926 INFO:     Epoch: 9
2023-01-04 03:42:00,509 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.435491810242335, 'Total loss': 0.435491810242335} | train loss {'Reaction outcome loss': 0.3821276176849083, 'Total loss': 0.3821276176849083}
2023-01-04 03:42:00,509 INFO:     Found new best model at epoch 9
2023-01-04 03:42:00,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:00,510 INFO:     Epoch: 10
2023-01-04 03:42:02,097 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4339996447165807, 'Total loss': 0.4339996447165807} | train loss {'Reaction outcome loss': 0.3713838265655373, 'Total loss': 0.3713838265655373}
2023-01-04 03:42:02,097 INFO:     Found new best model at epoch 10
2023-01-04 03:42:02,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:02,098 INFO:     Epoch: 11
2023-01-04 03:42:03,715 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4243514617284139, 'Total loss': 0.4243514617284139} | train loss {'Reaction outcome loss': 0.3653276579680623, 'Total loss': 0.3653276579680623}
2023-01-04 03:42:03,715 INFO:     Found new best model at epoch 11
2023-01-04 03:42:03,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:03,716 INFO:     Epoch: 12
2023-01-04 03:42:05,310 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4279071241617203, 'Total loss': 0.4279071241617203} | train loss {'Reaction outcome loss': 0.35636939028062037, 'Total loss': 0.35636939028062037}
2023-01-04 03:42:05,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:05,310 INFO:     Epoch: 13
2023-01-04 03:42:06,882 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4159440040588379, 'Total loss': 0.4159440040588379} | train loss {'Reaction outcome loss': 0.34969345387408807, 'Total loss': 0.34969345387408807}
2023-01-04 03:42:06,883 INFO:     Found new best model at epoch 13
2023-01-04 03:42:06,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:06,883 INFO:     Epoch: 14
2023-01-04 03:42:08,483 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4218332330385844, 'Total loss': 0.4218332330385844} | train loss {'Reaction outcome loss': 0.35847509007199085, 'Total loss': 0.35847509007199085}
2023-01-04 03:42:08,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:08,483 INFO:     Epoch: 15
2023-01-04 03:42:10,073 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4297874063253403, 'Total loss': 0.4297874063253403} | train loss {'Reaction outcome loss': 0.34785637607632636, 'Total loss': 0.34785637607632636}
2023-01-04 03:42:10,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:10,074 INFO:     Epoch: 16
2023-01-04 03:42:11,680 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4173544337352117, 'Total loss': 0.4173544337352117} | train loss {'Reaction outcome loss': 0.3314072944416219, 'Total loss': 0.3314072944416219}
2023-01-04 03:42:11,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:11,680 INFO:     Epoch: 17
2023-01-04 03:42:13,303 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42639519572257994, 'Total loss': 0.42639519572257994} | train loss {'Reaction outcome loss': 0.32786030964790913, 'Total loss': 0.32786030964790913}
2023-01-04 03:42:13,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:13,304 INFO:     Epoch: 18
2023-01-04 03:42:14,925 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42859330077966057, 'Total loss': 0.42859330077966057} | train loss {'Reaction outcome loss': 0.32482175005302916, 'Total loss': 0.32482175005302916}
2023-01-04 03:42:14,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:14,926 INFO:     Epoch: 19
2023-01-04 03:42:16,505 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4178629944721858, 'Total loss': 0.4178629944721858} | train loss {'Reaction outcome loss': 0.3199190117310787, 'Total loss': 0.3199190117310787}
2023-01-04 03:42:16,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:16,505 INFO:     Epoch: 20
2023-01-04 03:42:18,102 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43079212407271067, 'Total loss': 0.43079212407271067} | train loss {'Reaction outcome loss': 0.31093391010780697, 'Total loss': 0.31093391010780697}
2023-01-04 03:42:18,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:18,102 INFO:     Epoch: 21
2023-01-04 03:42:19,710 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4161353667577108, 'Total loss': 0.4161353667577108} | train loss {'Reaction outcome loss': 0.30769449783058034, 'Total loss': 0.30769449783058034}
2023-01-04 03:42:19,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:19,710 INFO:     Epoch: 22
2023-01-04 03:42:21,300 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4219127635161082, 'Total loss': 0.4219127635161082} | train loss {'Reaction outcome loss': 0.3017531655040448, 'Total loss': 0.3017531655040448}
2023-01-04 03:42:21,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:21,301 INFO:     Epoch: 23
2023-01-04 03:42:22,894 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41843671798706056, 'Total loss': 0.41843671798706056} | train loss {'Reaction outcome loss': 0.29740094357723557, 'Total loss': 0.29740094357723557}
2023-01-04 03:42:22,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:22,894 INFO:     Epoch: 24
2023-01-04 03:42:24,481 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.429657526810964, 'Total loss': 0.429657526810964} | train loss {'Reaction outcome loss': 0.2929570901153742, 'Total loss': 0.2929570901153742}
2023-01-04 03:42:24,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:24,481 INFO:     Epoch: 25
2023-01-04 03:42:26,095 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4508848011493683, 'Total loss': 0.4508848011493683} | train loss {'Reaction outcome loss': 0.28876550297043624, 'Total loss': 0.28876550297043624}
2023-01-04 03:42:26,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:26,096 INFO:     Epoch: 26
2023-01-04 03:42:27,691 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43566892147064207, 'Total loss': 0.43566892147064207} | train loss {'Reaction outcome loss': 0.28595567702491215, 'Total loss': 0.28595567702491215}
2023-01-04 03:42:27,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:27,691 INFO:     Epoch: 27
2023-01-04 03:42:29,286 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43390932281812034, 'Total loss': 0.43390932281812034} | train loss {'Reaction outcome loss': 0.2810103884776649, 'Total loss': 0.2810103884776649}
2023-01-04 03:42:29,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:29,286 INFO:     Epoch: 28
2023-01-04 03:42:30,884 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43279904723167417, 'Total loss': 0.43279904723167417} | train loss {'Reaction outcome loss': 0.27998801659576705, 'Total loss': 0.27998801659576705}
2023-01-04 03:42:30,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:30,884 INFO:     Epoch: 29
2023-01-04 03:42:32,474 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4374568904439608, 'Total loss': 0.4374568904439608} | train loss {'Reaction outcome loss': 0.2751533946332832, 'Total loss': 0.2751533946332832}
2023-01-04 03:42:32,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:32,474 INFO:     Epoch: 30
2023-01-04 03:42:34,061 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4362685243288676, 'Total loss': 0.4362685243288676} | train loss {'Reaction outcome loss': 0.27631855909915076, 'Total loss': 0.27631855909915076}
2023-01-04 03:42:34,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:34,062 INFO:     Epoch: 31
2023-01-04 03:42:35,645 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4542071441809336, 'Total loss': 0.4542071441809336} | train loss {'Reaction outcome loss': 0.27482080276029697, 'Total loss': 0.27482080276029697}
2023-01-04 03:42:35,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:35,645 INFO:     Epoch: 32
2023-01-04 03:42:37,255 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42707187732060753, 'Total loss': 0.42707187732060753} | train loss {'Reaction outcome loss': 0.26563031701674766, 'Total loss': 0.26563031701674766}
2023-01-04 03:42:37,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:37,255 INFO:     Epoch: 33
2023-01-04 03:42:38,900 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.429750848809878, 'Total loss': 0.429750848809878} | train loss {'Reaction outcome loss': 0.26282369168115954, 'Total loss': 0.26282369168115954}
2023-01-04 03:42:38,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:38,900 INFO:     Epoch: 34
2023-01-04 03:42:40,515 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4498030036687851, 'Total loss': 0.4498030036687851} | train loss {'Reaction outcome loss': 0.2608924896415809, 'Total loss': 0.2608924896415809}
2023-01-04 03:42:40,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:40,515 INFO:     Epoch: 35
2023-01-04 03:42:42,122 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43528382033109664, 'Total loss': 0.43528382033109664} | train loss {'Reaction outcome loss': 0.26745314357917843, 'Total loss': 0.26745314357917843}
2023-01-04 03:42:42,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:42,122 INFO:     Epoch: 36
2023-01-04 03:42:43,712 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44421632786591847, 'Total loss': 0.44421632786591847} | train loss {'Reaction outcome loss': 0.25402960708572664, 'Total loss': 0.25402960708572664}
2023-01-04 03:42:43,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:43,713 INFO:     Epoch: 37
2023-01-04 03:42:45,287 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4400681331753731, 'Total loss': 0.4400681331753731} | train loss {'Reaction outcome loss': 0.25024652792405727, 'Total loss': 0.25024652792405727}
2023-01-04 03:42:45,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:45,287 INFO:     Epoch: 38
2023-01-04 03:42:46,878 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4422667572895686, 'Total loss': 0.4422667572895686} | train loss {'Reaction outcome loss': 0.25053622264523007, 'Total loss': 0.25053622264523007}
2023-01-04 03:42:46,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:46,878 INFO:     Epoch: 39
2023-01-04 03:42:48,470 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4440849314133326, 'Total loss': 0.4440849314133326} | train loss {'Reaction outcome loss': 0.2509484110202681, 'Total loss': 0.2509484110202681}
2023-01-04 03:42:48,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:48,471 INFO:     Epoch: 40
2023-01-04 03:42:50,059 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44426019887129464, 'Total loss': 0.44426019887129464} | train loss {'Reaction outcome loss': 0.24112594309870317, 'Total loss': 0.24112594309870317}
2023-01-04 03:42:50,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:50,061 INFO:     Epoch: 41
2023-01-04 03:42:51,633 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46712282399336497, 'Total loss': 0.46712282399336497} | train loss {'Reaction outcome loss': 0.25061765966424043, 'Total loss': 0.25061765966424043}
2023-01-04 03:42:51,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:51,633 INFO:     Epoch: 42
2023-01-04 03:42:53,223 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45753614157438277, 'Total loss': 0.45753614157438277} | train loss {'Reaction outcome loss': 0.23907963008167682, 'Total loss': 0.23907963008167682}
2023-01-04 03:42:53,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:53,223 INFO:     Epoch: 43
2023-01-04 03:42:54,815 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4570469379425049, 'Total loss': 0.4570469379425049} | train loss {'Reaction outcome loss': 0.23452664915005342, 'Total loss': 0.23452664915005342}
2023-01-04 03:42:54,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:54,815 INFO:     Epoch: 44
2023-01-04 03:42:56,432 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4493914852539698, 'Total loss': 0.4493914852539698} | train loss {'Reaction outcome loss': 0.23232659073614015, 'Total loss': 0.23232659073614015}
2023-01-04 03:42:56,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:56,433 INFO:     Epoch: 45
2023-01-04 03:42:58,057 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4529876281817754, 'Total loss': 0.4529876281817754} | train loss {'Reaction outcome loss': 0.2282132956087994, 'Total loss': 0.2282132956087994}
2023-01-04 03:42:58,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:58,057 INFO:     Epoch: 46
2023-01-04 03:42:59,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4462867833673954, 'Total loss': 0.4462867833673954} | train loss {'Reaction outcome loss': 0.2297954639015834, 'Total loss': 0.2297954639015834}
2023-01-04 03:42:59,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:42:59,682 INFO:     Epoch: 47
2023-01-04 03:43:01,281 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44727189242839815, 'Total loss': 0.44727189242839815} | train loss {'Reaction outcome loss': 0.22342907178529497, 'Total loss': 0.22342907178529497}
2023-01-04 03:43:01,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:01,281 INFO:     Epoch: 48
2023-01-04 03:43:02,885 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46593972444534304, 'Total loss': 0.46593972444534304} | train loss {'Reaction outcome loss': 0.22508059878010248, 'Total loss': 0.22508059878010248}
2023-01-04 03:43:02,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:02,885 INFO:     Epoch: 49
2023-01-04 03:43:04,507 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43831833402315773, 'Total loss': 0.43831833402315773} | train loss {'Reaction outcome loss': 0.22075038727000018, 'Total loss': 0.22075038727000018}
2023-01-04 03:43:04,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:04,507 INFO:     Epoch: 50
2023-01-04 03:43:06,127 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46111288766066233, 'Total loss': 0.46111288766066233} | train loss {'Reaction outcome loss': 0.22021699459224509, 'Total loss': 0.22021699459224509}
2023-01-04 03:43:06,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:06,128 INFO:     Epoch: 51
2023-01-04 03:43:07,752 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4678225129842758, 'Total loss': 0.4678225129842758} | train loss {'Reaction outcome loss': 0.22078338683628396, 'Total loss': 0.22078338683628396}
2023-01-04 03:43:07,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:07,752 INFO:     Epoch: 52
2023-01-04 03:43:09,335 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46212259531021116, 'Total loss': 0.46212259531021116} | train loss {'Reaction outcome loss': 0.21448777058495858, 'Total loss': 0.21448777058495858}
2023-01-04 03:43:09,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:09,335 INFO:     Epoch: 53
2023-01-04 03:43:10,921 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4730400929848353, 'Total loss': 0.4730400929848353} | train loss {'Reaction outcome loss': 0.21609546241444955, 'Total loss': 0.21609546241444955}
2023-01-04 03:43:10,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:10,921 INFO:     Epoch: 54
2023-01-04 03:43:12,490 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4591579387585322, 'Total loss': 0.4591579387585322} | train loss {'Reaction outcome loss': 0.2178873797498661, 'Total loss': 0.2178873797498661}
2023-01-04 03:43:12,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:12,490 INFO:     Epoch: 55
2023-01-04 03:43:14,114 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4739075074593226, 'Total loss': 0.4739075074593226} | train loss {'Reaction outcome loss': 0.21417931735745893, 'Total loss': 0.21417931735745893}
2023-01-04 03:43:14,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:14,115 INFO:     Epoch: 56
2023-01-04 03:43:15,739 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45823575953642526, 'Total loss': 0.45823575953642526} | train loss {'Reaction outcome loss': 0.21010377254013135, 'Total loss': 0.21010377254013135}
2023-01-04 03:43:15,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:15,740 INFO:     Epoch: 57
2023-01-04 03:43:17,364 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47672743697961173, 'Total loss': 0.47672743697961173} | train loss {'Reaction outcome loss': 0.21536218073810276, 'Total loss': 0.21536218073810276}
2023-01-04 03:43:17,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:17,364 INFO:     Epoch: 58
2023-01-04 03:43:18,960 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46810777684052784, 'Total loss': 0.46810777684052784} | train loss {'Reaction outcome loss': 0.20574708118278912, 'Total loss': 0.20574708118278912}
2023-01-04 03:43:18,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:18,960 INFO:     Epoch: 59
2023-01-04 03:43:20,578 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46156256000200907, 'Total loss': 0.46156256000200907} | train loss {'Reaction outcome loss': 0.20233759688741976, 'Total loss': 0.20233759688741976}
2023-01-04 03:43:20,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:20,579 INFO:     Epoch: 60
2023-01-04 03:43:22,176 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47865339914957683, 'Total loss': 0.47865339914957683} | train loss {'Reaction outcome loss': 0.20130573724652978, 'Total loss': 0.20130573724652978}
2023-01-04 03:43:22,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:22,176 INFO:     Epoch: 61
2023-01-04 03:43:23,798 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45657360553741455, 'Total loss': 0.45657360553741455} | train loss {'Reaction outcome loss': 0.2055412219243421, 'Total loss': 0.2055412219243421}
2023-01-04 03:43:23,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:23,798 INFO:     Epoch: 62
2023-01-04 03:43:25,421 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4569726859529813, 'Total loss': 0.4569726859529813} | train loss {'Reaction outcome loss': 0.2017421551136067, 'Total loss': 0.2017421551136067}
2023-01-04 03:43:25,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:25,421 INFO:     Epoch: 63
2023-01-04 03:43:27,028 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4756957252820333, 'Total loss': 0.4756957252820333} | train loss {'Reaction outcome loss': 0.1981450706815045, 'Total loss': 0.1981450706815045}
2023-01-04 03:43:27,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:27,029 INFO:     Epoch: 64
2023-01-04 03:43:28,615 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46257469356060027, 'Total loss': 0.46257469356060027} | train loss {'Reaction outcome loss': 0.19869544850054965, 'Total loss': 0.19869544850054965}
2023-01-04 03:43:28,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:28,615 INFO:     Epoch: 65
2023-01-04 03:43:30,191 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48563801248868305, 'Total loss': 0.48563801248868305} | train loss {'Reaction outcome loss': 0.19496039356496456, 'Total loss': 0.19496039356496456}
2023-01-04 03:43:30,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:30,192 INFO:     Epoch: 66
2023-01-04 03:43:31,808 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4891876310110092, 'Total loss': 0.4891876310110092} | train loss {'Reaction outcome loss': 0.21229671296812053, 'Total loss': 0.21229671296812053}
2023-01-04 03:43:31,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:31,808 INFO:     Epoch: 67
2023-01-04 03:43:33,433 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4906174381573995, 'Total loss': 0.4906174381573995} | train loss {'Reaction outcome loss': 0.22237293924449067, 'Total loss': 0.22237293924449067}
2023-01-04 03:43:33,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:33,433 INFO:     Epoch: 68
2023-01-04 03:43:35,058 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5014997472365698, 'Total loss': 0.5014997472365698} | train loss {'Reaction outcome loss': 0.19532929091258047, 'Total loss': 0.19532929091258047}
2023-01-04 03:43:35,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:35,058 INFO:     Epoch: 69
2023-01-04 03:43:36,649 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4729298899571101, 'Total loss': 0.4729298899571101} | train loss {'Reaction outcome loss': 0.19182102628901307, 'Total loss': 0.19182102628901307}
2023-01-04 03:43:36,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:36,649 INFO:     Epoch: 70
2023-01-04 03:43:38,243 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5068029741446177, 'Total loss': 0.5068029741446177} | train loss {'Reaction outcome loss': 0.19193527206738034, 'Total loss': 0.19193527206738034}
2023-01-04 03:43:38,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:38,243 INFO:     Epoch: 71
2023-01-04 03:43:39,826 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47515652477741244, 'Total loss': 0.47515652477741244} | train loss {'Reaction outcome loss': 0.18777324655472868, 'Total loss': 0.18777324655472868}
2023-01-04 03:43:39,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:39,827 INFO:     Epoch: 72
2023-01-04 03:43:41,443 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4695620909333229, 'Total loss': 0.4695620909333229} | train loss {'Reaction outcome loss': 0.18702021622996562, 'Total loss': 0.18702021622996562}
2023-01-04 03:43:41,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:41,443 INFO:     Epoch: 73
2023-01-04 03:43:43,074 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4966578940550486, 'Total loss': 0.4966578940550486} | train loss {'Reaction outcome loss': 0.18836655137399078, 'Total loss': 0.18836655137399078}
2023-01-04 03:43:43,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:43,075 INFO:     Epoch: 74
2023-01-04 03:43:44,699 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4952267090479533, 'Total loss': 0.4952267090479533} | train loss {'Reaction outcome loss': 0.1881706415122186, 'Total loss': 0.1881706415122186}
2023-01-04 03:43:44,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:44,699 INFO:     Epoch: 75
2023-01-04 03:43:46,279 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4824817806482315, 'Total loss': 0.4824817806482315} | train loss {'Reaction outcome loss': 0.19354178849607706, 'Total loss': 0.19354178849607706}
2023-01-04 03:43:46,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:46,279 INFO:     Epoch: 76
2023-01-04 03:43:47,860 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.492610173424085, 'Total loss': 0.492610173424085} | train loss {'Reaction outcome loss': 0.18903005147771235, 'Total loss': 0.18903005147771235}
2023-01-04 03:43:47,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:47,860 INFO:     Epoch: 77
2023-01-04 03:43:49,477 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48124261597792306, 'Total loss': 0.48124261597792306} | train loss {'Reaction outcome loss': 0.18444465107134328, 'Total loss': 0.18444465107134328}
2023-01-04 03:43:49,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:49,478 INFO:     Epoch: 78
2023-01-04 03:43:51,073 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48274802764256797, 'Total loss': 0.48274802764256797} | train loss {'Reaction outcome loss': 0.18050172285892177, 'Total loss': 0.18050172285892177}
2023-01-04 03:43:51,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:51,074 INFO:     Epoch: 79
2023-01-04 03:43:52,692 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4888106962045034, 'Total loss': 0.4888106962045034} | train loss {'Reaction outcome loss': 0.18876415324410883, 'Total loss': 0.18876415324410883}
2023-01-04 03:43:52,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:52,693 INFO:     Epoch: 80
2023-01-04 03:43:54,293 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.504361915588379, 'Total loss': 0.504361915588379} | train loss {'Reaction outcome loss': 0.19654283509969347, 'Total loss': 0.19654283509969347}
2023-01-04 03:43:54,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:54,293 INFO:     Epoch: 81
2023-01-04 03:43:55,909 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4851726373036703, 'Total loss': 0.4851726373036703} | train loss {'Reaction outcome loss': 0.18149586245113902, 'Total loss': 0.18149586245113902}
2023-01-04 03:43:55,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:55,910 INFO:     Epoch: 82
2023-01-04 03:43:57,500 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4921191483736038, 'Total loss': 0.4921191483736038} | train loss {'Reaction outcome loss': 0.18007750749297818, 'Total loss': 0.18007750749297818}
2023-01-04 03:43:57,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:57,501 INFO:     Epoch: 83
2023-01-04 03:43:59,082 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5013001223405202, 'Total loss': 0.5013001223405202} | train loss {'Reaction outcome loss': 0.17659749629545832, 'Total loss': 0.17659749629545832}
2023-01-04 03:43:59,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:43:59,083 INFO:     Epoch: 84
2023-01-04 03:44:00,701 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.50127954185009, 'Total loss': 0.50127954185009} | train loss {'Reaction outcome loss': 0.17682537330867912, 'Total loss': 0.17682537330867912}
2023-01-04 03:44:00,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:00,702 INFO:     Epoch: 85
2023-01-04 03:44:02,332 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4839416265487671, 'Total loss': 0.4839416265487671} | train loss {'Reaction outcome loss': 0.1784924345847685, 'Total loss': 0.1784924345847685}
2023-01-04 03:44:02,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:02,333 INFO:     Epoch: 86
2023-01-04 03:44:03,914 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.508973757425944, 'Total loss': 0.508973757425944} | train loss {'Reaction outcome loss': 0.17697603766709621, 'Total loss': 0.17697603766709621}
2023-01-04 03:44:03,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:03,915 INFO:     Epoch: 87
2023-01-04 03:44:05,532 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49005585511525473, 'Total loss': 0.49005585511525473} | train loss {'Reaction outcome loss': 0.1742190062844505, 'Total loss': 0.1742190062844505}
2023-01-04 03:44:05,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:05,532 INFO:     Epoch: 88
2023-01-04 03:44:07,112 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5062509993712108, 'Total loss': 0.5062509993712108} | train loss {'Reaction outcome loss': 0.18268416451452218, 'Total loss': 0.18268416451452218}
2023-01-04 03:44:07,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:07,112 INFO:     Epoch: 89
2023-01-04 03:44:08,719 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5148412823677063, 'Total loss': 0.5148412823677063} | train loss {'Reaction outcome loss': 0.18355189172691916, 'Total loss': 0.18355189172691916}
2023-01-04 03:44:08,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:08,719 INFO:     Epoch: 90
2023-01-04 03:44:10,347 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5082919041315714, 'Total loss': 0.5082919041315714} | train loss {'Reaction outcome loss': 0.18323576076469128, 'Total loss': 0.18323576076469128}
2023-01-04 03:44:10,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:10,348 INFO:     Epoch: 91
2023-01-04 03:44:11,933 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5158491949240367, 'Total loss': 0.5158491949240367} | train loss {'Reaction outcome loss': 0.19248483066347535, 'Total loss': 0.19248483066347535}
2023-01-04 03:44:11,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:11,933 INFO:     Epoch: 92
2023-01-04 03:44:13,536 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48814738591512047, 'Total loss': 0.48814738591512047} | train loss {'Reaction outcome loss': 0.17326393852451566, 'Total loss': 0.17326393852451566}
2023-01-04 03:44:13,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:13,536 INFO:     Epoch: 93
2023-01-04 03:44:15,133 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5071526825428009, 'Total loss': 0.5071526825428009} | train loss {'Reaction outcome loss': 0.17052622526563832, 'Total loss': 0.17052622526563832}
2023-01-04 03:44:15,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:15,133 INFO:     Epoch: 94
2023-01-04 03:44:16,730 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48085514406363167, 'Total loss': 0.48085514406363167} | train loss {'Reaction outcome loss': 0.1698429247472381, 'Total loss': 0.1698429247472381}
2023-01-04 03:44:16,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:16,730 INFO:     Epoch: 95
2023-01-04 03:44:18,341 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.524989186724027, 'Total loss': 0.524989186724027} | train loss {'Reaction outcome loss': 0.17031105347078943, 'Total loss': 0.17031105347078943}
2023-01-04 03:44:18,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:18,341 INFO:     Epoch: 96
2023-01-04 03:44:19,979 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4806350737810135, 'Total loss': 0.4806350737810135} | train loss {'Reaction outcome loss': 0.16815676704045737, 'Total loss': 0.16815676704045737}
2023-01-04 03:44:19,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:19,980 INFO:     Epoch: 97
2023-01-04 03:44:21,583 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5059970041116079, 'Total loss': 0.5059970041116079} | train loss {'Reaction outcome loss': 0.16948719451096805, 'Total loss': 0.16948719451096805}
2023-01-04 03:44:21,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:21,585 INFO:     Epoch: 98
2023-01-04 03:44:23,207 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49912293553352355, 'Total loss': 0.49912293553352355} | train loss {'Reaction outcome loss': 0.16818935153873943, 'Total loss': 0.16818935153873943}
2023-01-04 03:44:23,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:23,207 INFO:     Epoch: 99
2023-01-04 03:44:24,793 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48318822408715884, 'Total loss': 0.48318822408715884} | train loss {'Reaction outcome loss': 0.16742293316823686, 'Total loss': 0.16742293316823686}
2023-01-04 03:44:24,793 INFO:     Best model found after epoch 14 of 100.
2023-01-04 03:44:24,793 INFO:   Done with stage: TRAINING
2023-01-04 03:44:24,793 INFO:   Starting stage: EVALUATION
2023-01-04 03:44:24,922 INFO:   Done with stage: EVALUATION
2023-01-04 03:44:24,922 INFO:   Leaving out SEQ value Fold_8
2023-01-04 03:44:24,935 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 03:44:24,935 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:44:25,583 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:44:25,583 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:44:25,651 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:44:25,651 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:44:25,652 INFO:     No hyperparam tuning for this model
2023-01-04 03:44:25,652 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:44:25,652 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:44:25,652 INFO:     None feature selector for col prot
2023-01-04 03:44:25,653 INFO:     None feature selector for col prot
2023-01-04 03:44:25,653 INFO:     None feature selector for col prot
2023-01-04 03:44:25,653 INFO:     None feature selector for col chem
2023-01-04 03:44:25,653 INFO:     None feature selector for col chem
2023-01-04 03:44:25,654 INFO:     None feature selector for col chem
2023-01-04 03:44:25,654 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:44:25,654 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:44:25,655 INFO:     Number of params in model 70141
2023-01-04 03:44:25,658 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:44:25,658 INFO:   Starting stage: TRAINING
2023-01-04 03:44:25,701 INFO:     Val loss before train {'Reaction outcome loss': 1.1362130363782248, 'Total loss': 1.1362130363782248}
2023-01-04 03:44:25,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:25,701 INFO:     Epoch: 0
2023-01-04 03:44:27,289 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7636844476064046, 'Total loss': 0.7636844476064046} | train loss {'Reaction outcome loss': 0.8719735749146568, 'Total loss': 0.8719735749146568}
2023-01-04 03:44:27,289 INFO:     Found new best model at epoch 0
2023-01-04 03:44:27,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:27,290 INFO:     Epoch: 1
2023-01-04 03:44:28,912 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.577523946762085, 'Total loss': 0.577523946762085} | train loss {'Reaction outcome loss': 0.6169310212135315, 'Total loss': 0.6169310212135315}
2023-01-04 03:44:28,913 INFO:     Found new best model at epoch 1
2023-01-04 03:44:28,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:28,914 INFO:     Epoch: 2
2023-01-04 03:44:30,507 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5503379146258036, 'Total loss': 0.5503379146258036} | train loss {'Reaction outcome loss': 0.5232576047362834, 'Total loss': 0.5232576047362834}
2023-01-04 03:44:30,507 INFO:     Found new best model at epoch 2
2023-01-04 03:44:30,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:30,508 INFO:     Epoch: 3
2023-01-04 03:44:32,105 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5149694343407949, 'Total loss': 0.5149694343407949} | train loss {'Reaction outcome loss': 0.4835331954788215, 'Total loss': 0.4835331954788215}
2023-01-04 03:44:32,105 INFO:     Found new best model at epoch 3
2023-01-04 03:44:32,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:32,106 INFO:     Epoch: 4
2023-01-04 03:44:33,705 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5067237655321757, 'Total loss': 0.5067237655321757} | train loss {'Reaction outcome loss': 0.45959128315698367, 'Total loss': 0.45959128315698367}
2023-01-04 03:44:33,705 INFO:     Found new best model at epoch 4
2023-01-04 03:44:33,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:33,706 INFO:     Epoch: 5
2023-01-04 03:44:35,296 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5149003426233928, 'Total loss': 0.5149003426233928} | train loss {'Reaction outcome loss': 0.442484112611101, 'Total loss': 0.442484112611101}
2023-01-04 03:44:35,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:35,296 INFO:     Epoch: 6
2023-01-04 03:44:36,925 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5025211671988169, 'Total loss': 0.5025211671988169} | train loss {'Reaction outcome loss': 0.4242343887525345, 'Total loss': 0.4242343887525345}
2023-01-04 03:44:36,925 INFO:     Found new best model at epoch 6
2023-01-04 03:44:36,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:36,926 INFO:     Epoch: 7
2023-01-04 03:44:38,544 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48704409003257754, 'Total loss': 0.48704409003257754} | train loss {'Reaction outcome loss': 0.4115020061442998, 'Total loss': 0.4115020061442998}
2023-01-04 03:44:38,545 INFO:     Found new best model at epoch 7
2023-01-04 03:44:38,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:38,545 INFO:     Epoch: 8
2023-01-04 03:44:40,159 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5005124489466349, 'Total loss': 0.5005124489466349} | train loss {'Reaction outcome loss': 0.3978264957451218, 'Total loss': 0.3978264957451218}
2023-01-04 03:44:40,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:40,159 INFO:     Epoch: 9
2023-01-04 03:44:41,765 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49029880166053774, 'Total loss': 0.49029880166053774} | train loss {'Reaction outcome loss': 0.38888480839746525, 'Total loss': 0.38888480839746525}
2023-01-04 03:44:41,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:41,766 INFO:     Epoch: 10
2023-01-04 03:44:43,395 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47435471415519714, 'Total loss': 0.47435471415519714} | train loss {'Reaction outcome loss': 0.37630991815229614, 'Total loss': 0.37630991815229614}
2023-01-04 03:44:43,395 INFO:     Found new best model at epoch 10
2023-01-04 03:44:43,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:43,396 INFO:     Epoch: 11
2023-01-04 03:44:45,024 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5084887405236562, 'Total loss': 0.5084887405236562} | train loss {'Reaction outcome loss': 0.3698004439526947, 'Total loss': 0.3698004439526947}
2023-01-04 03:44:45,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:45,024 INFO:     Epoch: 12
2023-01-04 03:44:46,651 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5024311065673828, 'Total loss': 0.5024311065673828} | train loss {'Reaction outcome loss': 0.3592138402836417, 'Total loss': 0.3592138402836417}
2023-01-04 03:44:46,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:46,652 INFO:     Epoch: 13
2023-01-04 03:44:48,256 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4907620211442312, 'Total loss': 0.4907620211442312} | train loss {'Reaction outcome loss': 0.35348603635058073, 'Total loss': 0.35348603635058073}
2023-01-04 03:44:48,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:48,256 INFO:     Epoch: 14
2023-01-04 03:44:49,894 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47377456426620485, 'Total loss': 0.47377456426620485} | train loss {'Reaction outcome loss': 0.34604631240617495, 'Total loss': 0.34604631240617495}
2023-01-04 03:44:49,894 INFO:     Found new best model at epoch 14
2023-01-04 03:44:49,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:49,895 INFO:     Epoch: 15
2023-01-04 03:44:51,483 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48740504384040834, 'Total loss': 0.48740504384040834} | train loss {'Reaction outcome loss': 0.33688437155975764, 'Total loss': 0.33688437155975764}
2023-01-04 03:44:51,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:51,483 INFO:     Epoch: 16
2023-01-04 03:44:53,080 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49934723575909934, 'Total loss': 0.49934723575909934} | train loss {'Reaction outcome loss': 0.33057863181894004, 'Total loss': 0.33057863181894004}
2023-01-04 03:44:53,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:53,080 INFO:     Epoch: 17
2023-01-04 03:44:54,708 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48891615867614746, 'Total loss': 0.48891615867614746} | train loss {'Reaction outcome loss': 0.3235809998822126, 'Total loss': 0.3235809998822126}
2023-01-04 03:44:54,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:54,708 INFO:     Epoch: 18
2023-01-04 03:44:56,347 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49713998238245644, 'Total loss': 0.49713998238245644} | train loss {'Reaction outcome loss': 0.3180046419643323, 'Total loss': 0.3180046419643323}
2023-01-04 03:44:56,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:56,347 INFO:     Epoch: 19
2023-01-04 03:44:57,930 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5180344780286154, 'Total loss': 0.5180344780286154} | train loss {'Reaction outcome loss': 0.3136369587066802, 'Total loss': 0.3136369587066802}
2023-01-04 03:44:57,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:57,931 INFO:     Epoch: 20
2023-01-04 03:44:59,551 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5033721446990966, 'Total loss': 0.5033721446990966} | train loss {'Reaction outcome loss': 0.30876087464580465, 'Total loss': 0.30876087464580465}
2023-01-04 03:44:59,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:44:59,551 INFO:     Epoch: 21
2023-01-04 03:45:01,143 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48527966340382894, 'Total loss': 0.48527966340382894} | train loss {'Reaction outcome loss': 0.30253200321744067, 'Total loss': 0.30253200321744067}
2023-01-04 03:45:01,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:01,144 INFO:     Epoch: 22
2023-01-04 03:45:02,745 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4850776751836141, 'Total loss': 0.4850776751836141} | train loss {'Reaction outcome loss': 0.2975521017175289, 'Total loss': 0.2975521017175289}
2023-01-04 03:45:02,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:02,745 INFO:     Epoch: 23
2023-01-04 03:45:04,347 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4903780122598012, 'Total loss': 0.4903780122598012} | train loss {'Reaction outcome loss': 0.2934810773129928, 'Total loss': 0.2934810773129928}
2023-01-04 03:45:04,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:04,348 INFO:     Epoch: 24
2023-01-04 03:45:05,931 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4983435342709223, 'Total loss': 0.4983435342709223} | train loss {'Reaction outcome loss': 0.288867840671152, 'Total loss': 0.288867840671152}
2023-01-04 03:45:05,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:05,932 INFO:     Epoch: 25
2023-01-04 03:45:07,574 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5049666325251262, 'Total loss': 0.5049666325251262} | train loss {'Reaction outcome loss': 0.2819573875745281, 'Total loss': 0.2819573875745281}
2023-01-04 03:45:07,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:07,575 INFO:     Epoch: 26
2023-01-04 03:45:09,163 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49063371419906615, 'Total loss': 0.49063371419906615} | train loss {'Reaction outcome loss': 0.280278041999155, 'Total loss': 0.280278041999155}
2023-01-04 03:45:09,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:09,164 INFO:     Epoch: 27
2023-01-04 03:45:10,765 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4916405528783798, 'Total loss': 0.4916405528783798} | train loss {'Reaction outcome loss': 0.2740421887984775, 'Total loss': 0.2740421887984775}
2023-01-04 03:45:10,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:10,765 INFO:     Epoch: 28
2023-01-04 03:45:12,415 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4994329810142517, 'Total loss': 0.4994329810142517} | train loss {'Reaction outcome loss': 0.2706801063021383, 'Total loss': 0.2706801063021383}
2023-01-04 03:45:12,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:12,415 INFO:     Epoch: 29
2023-01-04 03:45:14,020 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4871998926003774, 'Total loss': 0.4871998926003774} | train loss {'Reaction outcome loss': 0.2683826596728301, 'Total loss': 0.2683826596728301}
2023-01-04 03:45:14,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:14,020 INFO:     Epoch: 30
2023-01-04 03:45:15,614 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4887578586737315, 'Total loss': 0.4887578586737315} | train loss {'Reaction outcome loss': 0.26415953002466624, 'Total loss': 0.26415953002466624}
2023-01-04 03:45:15,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:15,614 INFO:     Epoch: 31
2023-01-04 03:45:17,231 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5033341566721599, 'Total loss': 0.5033341566721599} | train loss {'Reaction outcome loss': 0.26173101372963037, 'Total loss': 0.26173101372963037}
2023-01-04 03:45:17,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:17,232 INFO:     Epoch: 32
2023-01-04 03:45:18,817 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.491705396771431, 'Total loss': 0.491705396771431} | train loss {'Reaction outcome loss': 0.2586051238572985, 'Total loss': 0.2586051238572985}
2023-01-04 03:45:18,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:18,817 INFO:     Epoch: 33
2023-01-04 03:45:20,418 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4937647879123688, 'Total loss': 0.4937647879123688} | train loss {'Reaction outcome loss': 0.2563437400150385, 'Total loss': 0.2563437400150385}
2023-01-04 03:45:20,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:20,419 INFO:     Epoch: 34
2023-01-04 03:45:22,020 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5280206382274628, 'Total loss': 0.5280206382274628} | train loss {'Reaction outcome loss': 0.25035369084199843, 'Total loss': 0.25035369084199843}
2023-01-04 03:45:22,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:22,020 INFO:     Epoch: 35
2023-01-04 03:45:23,606 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5243310838937759, 'Total loss': 0.5243310838937759} | train loss {'Reaction outcome loss': 0.2498101060436736, 'Total loss': 0.2498101060436736}
2023-01-04 03:45:23,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:23,606 INFO:     Epoch: 36
2023-01-04 03:45:25,231 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.504180226723353, 'Total loss': 0.504180226723353} | train loss {'Reaction outcome loss': 0.24891109043725562, 'Total loss': 0.24891109043725562}
2023-01-04 03:45:25,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:25,231 INFO:     Epoch: 37
2023-01-04 03:45:26,837 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4999565064907074, 'Total loss': 0.4999565064907074} | train loss {'Reaction outcome loss': 0.24303718357740325, 'Total loss': 0.24303718357740325}
2023-01-04 03:45:26,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:26,838 INFO:     Epoch: 38
2023-01-04 03:45:28,467 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5024117777744929, 'Total loss': 0.5024117777744929} | train loss {'Reaction outcome loss': 0.24048023115480419, 'Total loss': 0.24048023115480419}
2023-01-04 03:45:28,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:28,468 INFO:     Epoch: 39
2023-01-04 03:45:30,079 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49158539772033694, 'Total loss': 0.49158539772033694} | train loss {'Reaction outcome loss': 0.23753208575588702, 'Total loss': 0.23753208575588702}
2023-01-04 03:45:30,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:30,080 INFO:     Epoch: 40
2023-01-04 03:45:31,706 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5083574016888937, 'Total loss': 0.5083574016888937} | train loss {'Reaction outcome loss': 0.2350587695568047, 'Total loss': 0.2350587695568047}
2023-01-04 03:45:31,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:31,706 INFO:     Epoch: 41
2023-01-04 03:45:33,305 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5278453995784124, 'Total loss': 0.5278453995784124} | train loss {'Reaction outcome loss': 0.23081673252722418, 'Total loss': 0.23081673252722418}
2023-01-04 03:45:33,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:33,305 INFO:     Epoch: 42
2023-01-04 03:45:34,934 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.512676082054774, 'Total loss': 0.512676082054774} | train loss {'Reaction outcome loss': 0.22911132469316037, 'Total loss': 0.22911132469316037}
2023-01-04 03:45:34,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:34,935 INFO:     Epoch: 43
2023-01-04 03:45:36,529 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5221641302108765, 'Total loss': 0.5221641302108765} | train loss {'Reaction outcome loss': 0.22752488682900526, 'Total loss': 0.22752488682900526}
2023-01-04 03:45:36,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:36,529 INFO:     Epoch: 44
2023-01-04 03:45:38,124 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5128952125708263, 'Total loss': 0.5128952125708263} | train loss {'Reaction outcome loss': 0.22208912706923828, 'Total loss': 0.22208912706923828}
2023-01-04 03:45:38,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:38,125 INFO:     Epoch: 45
2023-01-04 03:45:39,753 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5109646156430244, 'Total loss': 0.5109646156430244} | train loss {'Reaction outcome loss': 0.22284704692231405, 'Total loss': 0.22284704692231405}
2023-01-04 03:45:39,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:39,753 INFO:     Epoch: 46
2023-01-04 03:45:41,381 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5211259206136067, 'Total loss': 0.5211259206136067} | train loss {'Reaction outcome loss': 0.21889853515134391, 'Total loss': 0.21889853515134391}
2023-01-04 03:45:41,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:41,381 INFO:     Epoch: 47
2023-01-04 03:45:42,972 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5001920302708943, 'Total loss': 0.5001920302708943} | train loss {'Reaction outcome loss': 0.21713720434194006, 'Total loss': 0.21713720434194006}
2023-01-04 03:45:42,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:42,972 INFO:     Epoch: 48
2023-01-04 03:45:44,550 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4959326754013697, 'Total loss': 0.4959326754013697} | train loss {'Reaction outcome loss': 0.21607518097930437, 'Total loss': 0.21607518097930437}
2023-01-04 03:45:44,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:44,550 INFO:     Epoch: 49
2023-01-04 03:45:46,149 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.513924640417099, 'Total loss': 0.513924640417099} | train loss {'Reaction outcome loss': 0.21360564473949184, 'Total loss': 0.21360564473949184}
2023-01-04 03:45:46,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:46,149 INFO:     Epoch: 50
2023-01-04 03:45:47,748 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4972590744495392, 'Total loss': 0.4972590744495392} | train loss {'Reaction outcome loss': 0.2132344604990973, 'Total loss': 0.2132344604990973}
2023-01-04 03:45:47,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:47,749 INFO:     Epoch: 51
2023-01-04 03:45:49,350 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4832254469394684, 'Total loss': 0.4832254469394684} | train loss {'Reaction outcome loss': 0.21295127833416747, 'Total loss': 0.21295127833416747}
2023-01-04 03:45:49,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:49,350 INFO:     Epoch: 52
2023-01-04 03:45:50,940 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48947499295075736, 'Total loss': 0.48947499295075736} | train loss {'Reaction outcome loss': 0.20876700346381655, 'Total loss': 0.20876700346381655}
2023-01-04 03:45:50,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:50,940 INFO:     Epoch: 53
2023-01-04 03:45:52,567 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5211056649684906, 'Total loss': 0.5211056649684906} | train loss {'Reaction outcome loss': 0.2054382841697884, 'Total loss': 0.2054382841697884}
2023-01-04 03:45:52,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:52,568 INFO:     Epoch: 54
2023-01-04 03:45:54,183 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.508474588394165, 'Total loss': 0.508474588394165} | train loss {'Reaction outcome loss': 0.20664678812564927, 'Total loss': 0.20664678812564927}
2023-01-04 03:45:54,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:54,183 INFO:     Epoch: 55
2023-01-04 03:45:55,815 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5543396025896072, 'Total loss': 0.5543396025896072} | train loss {'Reaction outcome loss': 0.20263727435620252, 'Total loss': 0.20263727435620252}
2023-01-04 03:45:55,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:55,815 INFO:     Epoch: 56
2023-01-04 03:45:57,451 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5211079974969228, 'Total loss': 0.5211079974969228} | train loss {'Reaction outcome loss': 0.20272217106598595, 'Total loss': 0.20272217106598595}
2023-01-04 03:45:57,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:57,452 INFO:     Epoch: 57
2023-01-04 03:45:59,080 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5394680758317312, 'Total loss': 0.5394680758317312} | train loss {'Reaction outcome loss': 0.19954971720999112, 'Total loss': 0.19954971720999112}
2023-01-04 03:45:59,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:45:59,081 INFO:     Epoch: 58
2023-01-04 03:46:00,662 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.520076201359431, 'Total loss': 0.520076201359431} | train loss {'Reaction outcome loss': 0.19919332454404676, 'Total loss': 0.19919332454404676}
2023-01-04 03:46:00,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:00,663 INFO:     Epoch: 59
2023-01-04 03:46:02,294 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4985039879878362, 'Total loss': 0.4985039879878362} | train loss {'Reaction outcome loss': 0.1971336735768869, 'Total loss': 0.1971336735768869}
2023-01-04 03:46:02,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:02,294 INFO:     Epoch: 60
2023-01-04 03:46:03,901 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5268945356210073, 'Total loss': 0.5268945356210073} | train loss {'Reaction outcome loss': 0.19455680732585032, 'Total loss': 0.19455680732585032}
2023-01-04 03:46:03,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:03,902 INFO:     Epoch: 61
2023-01-04 03:46:05,530 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5128877540429433, 'Total loss': 0.5128877540429433} | train loss {'Reaction outcome loss': 0.1935480039580204, 'Total loss': 0.1935480039580204}
2023-01-04 03:46:05,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:05,531 INFO:     Epoch: 62
2023-01-04 03:46:07,121 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5182313034931819, 'Total loss': 0.5182313034931819} | train loss {'Reaction outcome loss': 0.1900230358734673, 'Total loss': 0.1900230358734673}
2023-01-04 03:46:07,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:07,122 INFO:     Epoch: 63
2023-01-04 03:46:08,727 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5078238050142924, 'Total loss': 0.5078238050142924} | train loss {'Reaction outcome loss': 0.192549829495674, 'Total loss': 0.192549829495674}
2023-01-04 03:46:08,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:08,727 INFO:     Epoch: 64
2023-01-04 03:46:10,351 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5143306116263072, 'Total loss': 0.5143306116263072} | train loss {'Reaction outcome loss': 0.19005624130233745, 'Total loss': 0.19005624130233745}
2023-01-04 03:46:10,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:10,351 INFO:     Epoch: 65
2023-01-04 03:46:11,927 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5173833012580872, 'Total loss': 0.5173833012580872} | train loss {'Reaction outcome loss': 0.1875322861428833, 'Total loss': 0.1875322861428833}
2023-01-04 03:46:11,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:11,927 INFO:     Epoch: 66
2023-01-04 03:46:13,573 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.524731558561325, 'Total loss': 0.524731558561325} | train loss {'Reaction outcome loss': 0.18381192664941942, 'Total loss': 0.18381192664941942}
2023-01-04 03:46:13,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:13,573 INFO:     Epoch: 67
2023-01-04 03:46:15,157 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5329433053731918, 'Total loss': 0.5329433053731918} | train loss {'Reaction outcome loss': 0.18644086500152354, 'Total loss': 0.18644086500152354}
2023-01-04 03:46:15,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:15,157 INFO:     Epoch: 68
2023-01-04 03:46:16,785 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.526679340004921, 'Total loss': 0.526679340004921} | train loss {'Reaction outcome loss': 0.18551573098136198, 'Total loss': 0.18551573098136198}
2023-01-04 03:46:16,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:16,785 INFO:     Epoch: 69
2023-01-04 03:46:18,369 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.519005075097084, 'Total loss': 0.519005075097084} | train loss {'Reaction outcome loss': 0.1837653888234808, 'Total loss': 0.1837653888234808}
2023-01-04 03:46:18,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:18,370 INFO:     Epoch: 70
2023-01-04 03:46:19,997 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5286632388830185, 'Total loss': 0.5286632388830185} | train loss {'Reaction outcome loss': 0.18036362616217524, 'Total loss': 0.18036362616217524}
2023-01-04 03:46:19,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:19,997 INFO:     Epoch: 71
2023-01-04 03:46:21,587 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5293711056311925, 'Total loss': 0.5293711056311925} | train loss {'Reaction outcome loss': 0.17948951181495018, 'Total loss': 0.17948951181495018}
2023-01-04 03:46:21,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:21,588 INFO:     Epoch: 72
2023-01-04 03:46:23,186 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5415424486001332, 'Total loss': 0.5415424486001332} | train loss {'Reaction outcome loss': 0.1810296815735984, 'Total loss': 0.1810296815735984}
2023-01-04 03:46:23,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:23,186 INFO:     Epoch: 73
2023-01-04 03:46:24,785 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5372079342603684, 'Total loss': 0.5372079342603684} | train loss {'Reaction outcome loss': 0.17610096536738132, 'Total loss': 0.17610096536738132}
2023-01-04 03:46:24,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:24,786 INFO:     Epoch: 74
2023-01-04 03:46:26,376 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5314706782499949, 'Total loss': 0.5314706782499949} | train loss {'Reaction outcome loss': 0.1789059490637874, 'Total loss': 0.1789059490637874}
2023-01-04 03:46:26,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:26,377 INFO:     Epoch: 75
2023-01-04 03:46:27,961 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5445014059543609, 'Total loss': 0.5445014059543609} | train loss {'Reaction outcome loss': 0.17326718794740065, 'Total loss': 0.17326718794740065}
2023-01-04 03:46:27,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:27,961 INFO:     Epoch: 76
2023-01-04 03:46:29,540 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5577535678942999, 'Total loss': 0.5577535678942999} | train loss {'Reaction outcome loss': 0.174739686153587, 'Total loss': 0.174739686153587}
2023-01-04 03:46:29,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:29,541 INFO:     Epoch: 77
2023-01-04 03:46:31,125 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5657634516557057, 'Total loss': 0.5657634516557057} | train loss {'Reaction outcome loss': 0.17720921024585998, 'Total loss': 0.17720921024585998}
2023-01-04 03:46:31,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:31,125 INFO:     Epoch: 78
2023-01-04 03:46:32,755 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5320721348126729, 'Total loss': 0.5320721348126729} | train loss {'Reaction outcome loss': 0.1724866400153413, 'Total loss': 0.1724866400153413}
2023-01-04 03:46:32,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:32,756 INFO:     Epoch: 79
2023-01-04 03:46:34,389 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5270465016365051, 'Total loss': 0.5270465016365051} | train loss {'Reaction outcome loss': 0.1703928123406447, 'Total loss': 0.1703928123406447}
2023-01-04 03:46:34,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:34,389 INFO:     Epoch: 80
2023-01-04 03:46:35,990 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5487684865792593, 'Total loss': 0.5487684865792593} | train loss {'Reaction outcome loss': 0.1706221141593551, 'Total loss': 0.1706221141593551}
2023-01-04 03:46:35,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:35,991 INFO:     Epoch: 81
2023-01-04 03:46:37,587 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.523225145538648, 'Total loss': 0.523225145538648} | train loss {'Reaction outcome loss': 0.1705617666688314, 'Total loss': 0.1705617666688314}
2023-01-04 03:46:37,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:37,588 INFO:     Epoch: 82
2023-01-04 03:46:39,166 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5630846013625462, 'Total loss': 0.5630846013625462} | train loss {'Reaction outcome loss': 0.17003850706109933, 'Total loss': 0.17003850706109933}
2023-01-04 03:46:39,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:39,166 INFO:     Epoch: 83
2023-01-04 03:46:40,796 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5640798211097717, 'Total loss': 0.5640798211097717} | train loss {'Reaction outcome loss': 0.16968862190573655, 'Total loss': 0.16968862190573655}
2023-01-04 03:46:40,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:40,796 INFO:     Epoch: 84
2023-01-04 03:46:42,426 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.533315114180247, 'Total loss': 0.533315114180247} | train loss {'Reaction outcome loss': 0.16869317246634608, 'Total loss': 0.16869317246634608}
2023-01-04 03:46:42,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:42,427 INFO:     Epoch: 85
2023-01-04 03:46:44,019 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5251772622267405, 'Total loss': 0.5251772622267405} | train loss {'Reaction outcome loss': 0.16635412535889055, 'Total loss': 0.16635412535889055}
2023-01-04 03:46:44,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:44,020 INFO:     Epoch: 86
2023-01-04 03:46:45,634 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5258526692787806, 'Total loss': 0.5258526692787806} | train loss {'Reaction outcome loss': 0.16594646922867437, 'Total loss': 0.16594646922867437}
2023-01-04 03:46:45,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:45,634 INFO:     Epoch: 87
2023-01-04 03:46:47,272 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5405469243725141, 'Total loss': 0.5405469243725141} | train loss {'Reaction outcome loss': 0.1649785812352431, 'Total loss': 0.1649785812352431}
2023-01-04 03:46:47,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:47,273 INFO:     Epoch: 88
2023-01-04 03:46:48,893 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.551920906205972, 'Total loss': 0.551920906205972} | train loss {'Reaction outcome loss': 0.16437040013177084, 'Total loss': 0.16437040013177084}
2023-01-04 03:46:48,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:48,894 INFO:     Epoch: 89
2023-01-04 03:46:50,512 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.541938524444898, 'Total loss': 0.541938524444898} | train loss {'Reaction outcome loss': 0.1635353858397756, 'Total loss': 0.1635353858397756}
2023-01-04 03:46:50,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:50,512 INFO:     Epoch: 90
2023-01-04 03:46:52,143 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5337406593064468, 'Total loss': 0.5337406593064468} | train loss {'Reaction outcome loss': 0.16432757890154523, 'Total loss': 0.16432757890154523}
2023-01-04 03:46:52,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:52,143 INFO:     Epoch: 91
2023-01-04 03:46:53,750 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5269401411215464, 'Total loss': 0.5269401411215464} | train loss {'Reaction outcome loss': 0.16246383888680582, 'Total loss': 0.16246383888680582}
2023-01-04 03:46:53,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:53,751 INFO:     Epoch: 92
2023-01-04 03:46:55,380 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5263425429662069, 'Total loss': 0.5263425429662069} | train loss {'Reaction outcome loss': 0.16098676336129003, 'Total loss': 0.16098676336129003}
2023-01-04 03:46:55,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:55,380 INFO:     Epoch: 93
2023-01-04 03:46:56,980 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5502500593662262, 'Total loss': 0.5502500593662262} | train loss {'Reaction outcome loss': 0.16080284840511394, 'Total loss': 0.16080284840511394}
2023-01-04 03:46:56,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:56,980 INFO:     Epoch: 94
2023-01-04 03:46:58,582 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5671983271837234, 'Total loss': 0.5671983271837234} | train loss {'Reaction outcome loss': 0.16087750124237382, 'Total loss': 0.16087750124237382}
2023-01-04 03:46:58,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:46:58,583 INFO:     Epoch: 95
2023-01-04 03:47:00,184 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5512642165025076, 'Total loss': 0.5512642165025076} | train loss {'Reaction outcome loss': 0.15750567646972863, 'Total loss': 0.15750567646972863}
2023-01-04 03:47:00,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:00,184 INFO:     Epoch: 96
2023-01-04 03:47:01,785 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5278465996185938, 'Total loss': 0.5278465996185938} | train loss {'Reaction outcome loss': 0.1594757700897081, 'Total loss': 0.1594757700897081}
2023-01-04 03:47:01,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:01,785 INFO:     Epoch: 97
2023-01-04 03:47:03,364 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5460054983695348, 'Total loss': 0.5460054983695348} | train loss {'Reaction outcome loss': 0.15660828624983125, 'Total loss': 0.15660828624983125}
2023-01-04 03:47:03,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:03,365 INFO:     Epoch: 98
2023-01-04 03:47:04,993 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5451944410800934, 'Total loss': 0.5451944410800934} | train loss {'Reaction outcome loss': 0.16094833488713964, 'Total loss': 0.16094833488713964}
2023-01-04 03:47:04,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:04,993 INFO:     Epoch: 99
2023-01-04 03:47:06,609 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.550673391421636, 'Total loss': 0.550673391421636} | train loss {'Reaction outcome loss': 0.15745733995730266, 'Total loss': 0.15745733995730266}
2023-01-04 03:47:06,610 INFO:     Best model found after epoch 15 of 100.
2023-01-04 03:47:06,610 INFO:   Done with stage: TRAINING
2023-01-04 03:47:06,610 INFO:   Starting stage: EVALUATION
2023-01-04 03:47:06,734 INFO:   Done with stage: EVALUATION
2023-01-04 03:47:06,734 INFO:   Leaving out SEQ value Fold_9
2023-01-04 03:47:06,747 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 03:47:06,747 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:47:07,394 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:47:07,394 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:47:07,462 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:47:07,462 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:47:07,462 INFO:     No hyperparam tuning for this model
2023-01-04 03:47:07,462 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:47:07,462 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:47:07,463 INFO:     None feature selector for col prot
2023-01-04 03:47:07,463 INFO:     None feature selector for col prot
2023-01-04 03:47:07,463 INFO:     None feature selector for col prot
2023-01-04 03:47:07,463 INFO:     None feature selector for col chem
2023-01-04 03:47:07,463 INFO:     None feature selector for col chem
2023-01-04 03:47:07,464 INFO:     None feature selector for col chem
2023-01-04 03:47:07,464 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:47:07,464 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:47:07,465 INFO:     Number of params in model 70141
2023-01-04 03:47:07,468 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:47:07,468 INFO:   Starting stage: TRAINING
2023-01-04 03:47:07,511 INFO:     Val loss before train {'Reaction outcome loss': 0.9756361047426859, 'Total loss': 0.9756361047426859}
2023-01-04 03:47:07,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:07,511 INFO:     Epoch: 0
2023-01-04 03:47:09,145 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5994816939036052, 'Total loss': 0.5994816939036052} | train loss {'Reaction outcome loss': 0.8504332314759816, 'Total loss': 0.8504332314759816}
2023-01-04 03:47:09,145 INFO:     Found new best model at epoch 0
2023-01-04 03:47:09,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:09,146 INFO:     Epoch: 1
2023-01-04 03:47:10,767 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5005409002304078, 'Total loss': 0.5005409002304078} | train loss {'Reaction outcome loss': 0.5926030010845686, 'Total loss': 0.5926030010845686}
2023-01-04 03:47:10,768 INFO:     Found new best model at epoch 1
2023-01-04 03:47:10,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:10,768 INFO:     Epoch: 2
2023-01-04 03:47:12,350 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45116001963615415, 'Total loss': 0.45116001963615415} | train loss {'Reaction outcome loss': 0.5220855773033218, 'Total loss': 0.5220855773033218}
2023-01-04 03:47:12,350 INFO:     Found new best model at epoch 2
2023-01-04 03:47:12,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:12,351 INFO:     Epoch: 3
2023-01-04 03:47:13,938 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4596280773480733, 'Total loss': 0.4596280773480733} | train loss {'Reaction outcome loss': 0.4831709131221909, 'Total loss': 0.4831709131221909}
2023-01-04 03:47:13,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:13,939 INFO:     Epoch: 4
2023-01-04 03:47:15,534 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43770093023777007, 'Total loss': 0.43770093023777007} | train loss {'Reaction outcome loss': 0.45883643761653764, 'Total loss': 0.45883643761653764}
2023-01-04 03:47:15,534 INFO:     Found new best model at epoch 4
2023-01-04 03:47:15,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:15,535 INFO:     Epoch: 5
2023-01-04 03:47:17,142 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4143046836058299, 'Total loss': 0.4143046836058299} | train loss {'Reaction outcome loss': 0.4354523720508878, 'Total loss': 0.4354523720508878}
2023-01-04 03:47:17,142 INFO:     Found new best model at epoch 5
2023-01-04 03:47:17,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:17,143 INFO:     Epoch: 6
2023-01-04 03:47:18,763 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40491249163945514, 'Total loss': 0.40491249163945514} | train loss {'Reaction outcome loss': 0.42275835627468056, 'Total loss': 0.42275835627468056}
2023-01-04 03:47:18,763 INFO:     Found new best model at epoch 6
2023-01-04 03:47:18,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:18,764 INFO:     Epoch: 7
2023-01-04 03:47:20,349 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3852778971195221, 'Total loss': 0.3852778971195221} | train loss {'Reaction outcome loss': 0.40770085599771044, 'Total loss': 0.40770085599771044}
2023-01-04 03:47:20,349 INFO:     Found new best model at epoch 7
2023-01-04 03:47:20,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:20,350 INFO:     Epoch: 8
2023-01-04 03:47:21,955 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38958671192328137, 'Total loss': 0.38958671192328137} | train loss {'Reaction outcome loss': 0.3962380998777999, 'Total loss': 0.3962380998777999}
2023-01-04 03:47:21,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:21,956 INFO:     Epoch: 9
2023-01-04 03:47:23,540 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39877516478300096, 'Total loss': 0.39877516478300096} | train loss {'Reaction outcome loss': 0.38643760102320235, 'Total loss': 0.38643760102320235}
2023-01-04 03:47:23,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:23,540 INFO:     Epoch: 10
2023-01-04 03:47:25,146 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40360466539859774, 'Total loss': 0.40360466539859774} | train loss {'Reaction outcome loss': 0.37708425053835776, 'Total loss': 0.37708425053835776}
2023-01-04 03:47:25,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:25,146 INFO:     Epoch: 11
2023-01-04 03:47:26,752 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37822173635164896, 'Total loss': 0.37822173635164896} | train loss {'Reaction outcome loss': 0.36809732479846863, 'Total loss': 0.36809732479846863}
2023-01-04 03:47:26,753 INFO:     Found new best model at epoch 11
2023-01-04 03:47:26,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:26,753 INFO:     Epoch: 12
2023-01-04 03:47:28,378 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3759081125259399, 'Total loss': 0.3759081125259399} | train loss {'Reaction outcome loss': 0.3623906131363087, 'Total loss': 0.3623906131363087}
2023-01-04 03:47:28,378 INFO:     Found new best model at epoch 12
2023-01-04 03:47:28,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:28,379 INFO:     Epoch: 13
2023-01-04 03:47:29,964 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.36622395714124045, 'Total loss': 0.36622395714124045} | train loss {'Reaction outcome loss': 0.3501236518905481, 'Total loss': 0.3501236518905481}
2023-01-04 03:47:29,964 INFO:     Found new best model at epoch 13
2023-01-04 03:47:29,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:29,965 INFO:     Epoch: 14
2023-01-04 03:47:31,570 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3780789077281952, 'Total loss': 0.3780789077281952} | train loss {'Reaction outcome loss': 0.34382917608272295, 'Total loss': 0.34382917608272295}
2023-01-04 03:47:31,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:31,571 INFO:     Epoch: 15
2023-01-04 03:47:33,159 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3726240654786428, 'Total loss': 0.3726240654786428} | train loss {'Reaction outcome loss': 0.33816680570371743, 'Total loss': 0.33816680570371743}
2023-01-04 03:47:33,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:33,160 INFO:     Epoch: 16
2023-01-04 03:47:34,761 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38274526993433633, 'Total loss': 0.38274526993433633} | train loss {'Reaction outcome loss': 0.3293922255992459, 'Total loss': 0.3293922255992459}
2023-01-04 03:47:34,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:34,761 INFO:     Epoch: 17
2023-01-04 03:47:36,390 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3686985343694687, 'Total loss': 0.3686985343694687} | train loss {'Reaction outcome loss': 0.3233597484898051, 'Total loss': 0.3233597484898051}
2023-01-04 03:47:36,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:36,390 INFO:     Epoch: 18
2023-01-04 03:47:37,999 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3693829317887624, 'Total loss': 0.3693829317887624} | train loss {'Reaction outcome loss': 0.31863381864254225, 'Total loss': 0.31863381864254225}
2023-01-04 03:47:37,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:37,999 INFO:     Epoch: 19
2023-01-04 03:47:39,647 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37727285822232565, 'Total loss': 0.37727285822232565} | train loss {'Reaction outcome loss': 0.31483853568023723, 'Total loss': 0.31483853568023723}
2023-01-04 03:47:39,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:39,647 INFO:     Epoch: 20
2023-01-04 03:47:41,250 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.36708093285560606, 'Total loss': 0.36708093285560606} | train loss {'Reaction outcome loss': 0.3072824318378841, 'Total loss': 0.3072824318378841}
2023-01-04 03:47:41,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:41,251 INFO:     Epoch: 21
2023-01-04 03:47:42,881 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3684074203173319, 'Total loss': 0.3684074203173319} | train loss {'Reaction outcome loss': 0.30320607408181854, 'Total loss': 0.30320607408181854}
2023-01-04 03:47:42,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:42,881 INFO:     Epoch: 22
2023-01-04 03:47:44,514 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3737357834974925, 'Total loss': 0.3737357834974925} | train loss {'Reaction outcome loss': 0.29644145840772224, 'Total loss': 0.29644145840772224}
2023-01-04 03:47:44,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:44,515 INFO:     Epoch: 23
2023-01-04 03:47:46,146 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.36834839582443235, 'Total loss': 0.36834839582443235} | train loss {'Reaction outcome loss': 0.2943868952053549, 'Total loss': 0.2943868952053549}
2023-01-04 03:47:46,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:46,146 INFO:     Epoch: 24
2023-01-04 03:47:47,747 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38645456631978353, 'Total loss': 0.38645456631978353} | train loss {'Reaction outcome loss': 0.2892434758668772, 'Total loss': 0.2892434758668772}
2023-01-04 03:47:47,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:47,748 INFO:     Epoch: 25
2023-01-04 03:47:49,352 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3802757402261098, 'Total loss': 0.3802757402261098} | train loss {'Reaction outcome loss': 0.28560604483211943, 'Total loss': 0.28560604483211943}
2023-01-04 03:47:49,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:49,352 INFO:     Epoch: 26
2023-01-04 03:47:50,930 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.36853787004947663, 'Total loss': 0.36853787004947663} | train loss {'Reaction outcome loss': 0.28208691349743936, 'Total loss': 0.28208691349743936}
2023-01-04 03:47:50,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:50,930 INFO:     Epoch: 27
2023-01-04 03:47:52,556 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3747628758351008, 'Total loss': 0.3747628758351008} | train loss {'Reaction outcome loss': 0.27757348791302755, 'Total loss': 0.27757348791302755}
2023-01-04 03:47:52,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:52,556 INFO:     Epoch: 28
2023-01-04 03:47:54,186 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35688905815283456, 'Total loss': 0.35688905815283456} | train loss {'Reaction outcome loss': 0.27054610818839675, 'Total loss': 0.27054610818839675}
2023-01-04 03:47:54,186 INFO:     Found new best model at epoch 28
2023-01-04 03:47:54,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:54,187 INFO:     Epoch: 29
2023-01-04 03:47:55,812 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36119119624296825, 'Total loss': 0.36119119624296825} | train loss {'Reaction outcome loss': 0.27017794154073355, 'Total loss': 0.27017794154073355}
2023-01-04 03:47:55,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:55,813 INFO:     Epoch: 30
2023-01-04 03:47:57,422 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3783503810564677, 'Total loss': 0.3783503810564677} | train loss {'Reaction outcome loss': 0.2663589513689172, 'Total loss': 0.2663589513689172}
2023-01-04 03:47:57,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:57,422 INFO:     Epoch: 31
2023-01-04 03:47:59,033 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38768496910731, 'Total loss': 0.38768496910731} | train loss {'Reaction outcome loss': 0.26571208463195, 'Total loss': 0.26571208463195}
2023-01-04 03:47:59,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:47:59,034 INFO:     Epoch: 32
2023-01-04 03:48:00,631 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.383009546995163, 'Total loss': 0.383009546995163} | train loss {'Reaction outcome loss': 0.26066890245955776, 'Total loss': 0.26066890245955776}
2023-01-04 03:48:00,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:00,632 INFO:     Epoch: 33
2023-01-04 03:48:02,237 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35650534331798556, 'Total loss': 0.35650534331798556} | train loss {'Reaction outcome loss': 0.2611278980055871, 'Total loss': 0.2611278980055871}
2023-01-04 03:48:02,237 INFO:     Found new best model at epoch 33
2023-01-04 03:48:02,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:02,238 INFO:     Epoch: 34
2023-01-04 03:48:03,873 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38082773188749947, 'Total loss': 0.38082773188749947} | train loss {'Reaction outcome loss': 0.25571206900617277, 'Total loss': 0.25571206900617277}
2023-01-04 03:48:03,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:03,874 INFO:     Epoch: 35
2023-01-04 03:48:05,473 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3843933016061783, 'Total loss': 0.3843933016061783} | train loss {'Reaction outcome loss': 0.25056442720580185, 'Total loss': 0.25056442720580185}
2023-01-04 03:48:05,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:05,473 INFO:     Epoch: 36
2023-01-04 03:48:07,074 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3871924340724945, 'Total loss': 0.3871924340724945} | train loss {'Reaction outcome loss': 0.2509592459251304, 'Total loss': 0.2509592459251304}
2023-01-04 03:48:07,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:07,074 INFO:     Epoch: 37
2023-01-04 03:48:08,670 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3731873412926992, 'Total loss': 0.3731873412926992} | train loss {'Reaction outcome loss': 0.2467805393282257, 'Total loss': 0.2467805393282257}
2023-01-04 03:48:08,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:08,670 INFO:     Epoch: 38
2023-01-04 03:48:10,257 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3682818591594696, 'Total loss': 0.3682818591594696} | train loss {'Reaction outcome loss': 0.2445605759801417, 'Total loss': 0.2445605759801417}
2023-01-04 03:48:10,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:10,258 INFO:     Epoch: 39
2023-01-04 03:48:11,883 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.387449453274409, 'Total loss': 0.387449453274409} | train loss {'Reaction outcome loss': 0.24453496709734954, 'Total loss': 0.24453496709734954}
2023-01-04 03:48:11,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:11,883 INFO:     Epoch: 40
2023-01-04 03:48:13,511 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36014616588751475, 'Total loss': 0.36014616588751475} | train loss {'Reaction outcome loss': 0.23849269255511596, 'Total loss': 0.23849269255511596}
2023-01-04 03:48:13,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:13,511 INFO:     Epoch: 41
2023-01-04 03:48:15,097 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4001975198586782, 'Total loss': 0.4001975198586782} | train loss {'Reaction outcome loss': 0.2388578546821856, 'Total loss': 0.2388578546821856}
2023-01-04 03:48:15,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:15,097 INFO:     Epoch: 42
2023-01-04 03:48:16,696 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39578347901503247, 'Total loss': 0.39578347901503247} | train loss {'Reaction outcome loss': 0.2345110163603664, 'Total loss': 0.2345110163603664}
2023-01-04 03:48:16,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:16,696 INFO:     Epoch: 43
2023-01-04 03:48:18,300 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3783261398474375, 'Total loss': 0.3783261398474375} | train loss {'Reaction outcome loss': 0.23350204309509118, 'Total loss': 0.23350204309509118}
2023-01-04 03:48:18,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:18,301 INFO:     Epoch: 44
2023-01-04 03:48:19,925 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.383663813273112, 'Total loss': 0.383663813273112} | train loss {'Reaction outcome loss': 0.22818797444151412, 'Total loss': 0.22818797444151412}
2023-01-04 03:48:19,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:19,925 INFO:     Epoch: 45
2023-01-04 03:48:21,567 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.382715106010437, 'Total loss': 0.382715106010437} | train loss {'Reaction outcome loss': 0.23022985044154018, 'Total loss': 0.23022985044154018}
2023-01-04 03:48:21,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:21,567 INFO:     Epoch: 46
2023-01-04 03:48:23,159 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3851414114236832, 'Total loss': 0.3851414114236832} | train loss {'Reaction outcome loss': 0.2272068284290577, 'Total loss': 0.2272068284290577}
2023-01-04 03:48:23,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:23,159 INFO:     Epoch: 47
2023-01-04 03:48:24,759 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39430607060591377, 'Total loss': 0.39430607060591377} | train loss {'Reaction outcome loss': 0.2248785481233459, 'Total loss': 0.2248785481233459}
2023-01-04 03:48:24,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:24,760 INFO:     Epoch: 48
2023-01-04 03:48:26,352 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39326107800006865, 'Total loss': 0.39326107800006865} | train loss {'Reaction outcome loss': 0.2221246647719119, 'Total loss': 0.2221246647719119}
2023-01-04 03:48:26,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:26,352 INFO:     Epoch: 49
2023-01-04 03:48:27,968 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3904662897189458, 'Total loss': 0.3904662897189458} | train loss {'Reaction outcome loss': 0.22266131039668507, 'Total loss': 0.22266131039668507}
2023-01-04 03:48:27,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:27,968 INFO:     Epoch: 50
2023-01-04 03:48:29,596 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37980353037516273, 'Total loss': 0.37980353037516273} | train loss {'Reaction outcome loss': 0.22000759821183416, 'Total loss': 0.22000759821183416}
2023-01-04 03:48:29,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:29,596 INFO:     Epoch: 51
2023-01-04 03:48:31,223 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3890896240870158, 'Total loss': 0.3890896240870158} | train loss {'Reaction outcome loss': 0.21766971083969847, 'Total loss': 0.21766971083969847}
2023-01-04 03:48:31,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:31,223 INFO:     Epoch: 52
2023-01-04 03:48:32,819 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38778850535551707, 'Total loss': 0.38778850535551707} | train loss {'Reaction outcome loss': 0.2177365212987046, 'Total loss': 0.2177365212987046}
2023-01-04 03:48:32,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:32,820 INFO:     Epoch: 53
2023-01-04 03:48:34,420 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3814240296681722, 'Total loss': 0.3814240296681722} | train loss {'Reaction outcome loss': 0.21665375155232014, 'Total loss': 0.21665375155232014}
2023-01-04 03:48:34,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:34,420 INFO:     Epoch: 54
2023-01-04 03:48:36,028 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38295332392056786, 'Total loss': 0.38295332392056786} | train loss {'Reaction outcome loss': 0.21547776283124723, 'Total loss': 0.21547776283124723}
2023-01-04 03:48:36,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:36,028 INFO:     Epoch: 55
2023-01-04 03:48:37,665 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3880143145720164, 'Total loss': 0.3880143145720164} | train loss {'Reaction outcome loss': 0.21064381741175583, 'Total loss': 0.21064381741175583}
2023-01-04 03:48:37,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:37,665 INFO:     Epoch: 56
2023-01-04 03:48:39,280 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3776831199725469, 'Total loss': 0.3776831199725469} | train loss {'Reaction outcome loss': 0.21079509451124642, 'Total loss': 0.21079509451124642}
2023-01-04 03:48:39,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:39,280 INFO:     Epoch: 57
2023-01-04 03:48:40,890 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3768493324518204, 'Total loss': 0.3768493324518204} | train loss {'Reaction outcome loss': 0.20885695954818373, 'Total loss': 0.20885695954818373}
2023-01-04 03:48:40,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:40,890 INFO:     Epoch: 58
2023-01-04 03:48:42,479 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38734883268674214, 'Total loss': 0.38734883268674214} | train loss {'Reaction outcome loss': 0.20735509014463166, 'Total loss': 0.20735509014463166}
2023-01-04 03:48:42,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:42,479 INFO:     Epoch: 59
2023-01-04 03:48:44,062 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.37968745628992717, 'Total loss': 0.37968745628992717} | train loss {'Reaction outcome loss': 0.20504989187209616, 'Total loss': 0.20504989187209616}
2023-01-04 03:48:44,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:44,062 INFO:     Epoch: 60
2023-01-04 03:48:45,696 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4097289055585861, 'Total loss': 0.4097289055585861} | train loss {'Reaction outcome loss': 0.20543177105782265, 'Total loss': 0.20543177105782265}
2023-01-04 03:48:45,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:45,696 INFO:     Epoch: 61
2023-01-04 03:48:47,335 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38423462708791095, 'Total loss': 0.38423462708791095} | train loss {'Reaction outcome loss': 0.2027037823942594, 'Total loss': 0.2027037823942594}
2023-01-04 03:48:47,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:47,336 INFO:     Epoch: 62
2023-01-04 03:48:48,970 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4007449676593145, 'Total loss': 0.4007449676593145} | train loss {'Reaction outcome loss': 0.19988269037449402, 'Total loss': 0.19988269037449402}
2023-01-04 03:48:48,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:48,970 INFO:     Epoch: 63
2023-01-04 03:48:50,577 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41083745857079823, 'Total loss': 0.41083745857079823} | train loss {'Reaction outcome loss': 0.20313825664053325, 'Total loss': 0.20313825664053325}
2023-01-04 03:48:50,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:50,578 INFO:     Epoch: 64
2023-01-04 03:48:52,179 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.407746222615242, 'Total loss': 0.407746222615242} | train loss {'Reaction outcome loss': 0.19887337711259775, 'Total loss': 0.19887337711259775}
2023-01-04 03:48:52,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:52,179 INFO:     Epoch: 65
2023-01-04 03:48:53,777 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4010359058777491, 'Total loss': 0.4010359058777491} | train loss {'Reaction outcome loss': 0.19832925395603, 'Total loss': 0.19832925395603}
2023-01-04 03:48:53,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:53,778 INFO:     Epoch: 66
2023-01-04 03:48:55,378 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3982988695303599, 'Total loss': 0.3982988695303599} | train loss {'Reaction outcome loss': 0.19455720868889606, 'Total loss': 0.19455720868889606}
2023-01-04 03:48:55,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:55,378 INFO:     Epoch: 67
2023-01-04 03:48:56,981 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3911947468916575, 'Total loss': 0.3911947468916575} | train loss {'Reaction outcome loss': 0.19318954840248673, 'Total loss': 0.19318954840248673}
2023-01-04 03:48:56,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:56,981 INFO:     Epoch: 68
2023-01-04 03:48:58,581 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3879905422528585, 'Total loss': 0.3879905422528585} | train loss {'Reaction outcome loss': 0.19287983419555188, 'Total loss': 0.19287983419555188}
2023-01-04 03:48:58,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:48:58,581 INFO:     Epoch: 69
2023-01-04 03:49:00,161 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38779677798350654, 'Total loss': 0.38779677798350654} | train loss {'Reaction outcome loss': 0.19317691880765805, 'Total loss': 0.19317691880765805}
2023-01-04 03:49:00,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:00,162 INFO:     Epoch: 70
2023-01-04 03:49:01,746 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42417172690232596, 'Total loss': 0.42417172690232596} | train loss {'Reaction outcome loss': 0.19161750728580496, 'Total loss': 0.19161750728580496}
2023-01-04 03:49:01,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:01,747 INFO:     Epoch: 71
2023-01-04 03:49:03,366 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42895687619845074, 'Total loss': 0.42895687619845074} | train loss {'Reaction outcome loss': 0.19172297934547658, 'Total loss': 0.19172297934547658}
2023-01-04 03:49:03,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:03,366 INFO:     Epoch: 72
2023-01-04 03:49:04,952 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3992296000321706, 'Total loss': 0.3992296000321706} | train loss {'Reaction outcome loss': 0.19252577869201395, 'Total loss': 0.19252577869201395}
2023-01-04 03:49:04,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:04,952 INFO:     Epoch: 73
2023-01-04 03:49:06,579 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4150220900774002, 'Total loss': 0.4150220900774002} | train loss {'Reaction outcome loss': 0.18943432179894903, 'Total loss': 0.18943432179894903}
2023-01-04 03:49:06,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:06,579 INFO:     Epoch: 74
2023-01-04 03:49:08,186 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.391030869881312, 'Total loss': 0.391030869881312} | train loss {'Reaction outcome loss': 0.18709003855390238, 'Total loss': 0.18709003855390238}
2023-01-04 03:49:08,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:08,187 INFO:     Epoch: 75
2023-01-04 03:49:09,776 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4133353273073832, 'Total loss': 0.4133353273073832} | train loss {'Reaction outcome loss': 0.1851515170818847, 'Total loss': 0.1851515170818847}
2023-01-04 03:49:09,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:09,776 INFO:     Epoch: 76
2023-01-04 03:49:11,374 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4182031025489171, 'Total loss': 0.4182031025489171} | train loss {'Reaction outcome loss': 0.18328042805114161, 'Total loss': 0.18328042805114161}
2023-01-04 03:49:11,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:11,374 INFO:     Epoch: 77
2023-01-04 03:49:13,018 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40362787346045176, 'Total loss': 0.40362787346045176} | train loss {'Reaction outcome loss': 0.18277951863859965, 'Total loss': 0.18277951863859965}
2023-01-04 03:49:13,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:13,019 INFO:     Epoch: 78
2023-01-04 03:49:14,654 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39843717018763225, 'Total loss': 0.39843717018763225} | train loss {'Reaction outcome loss': 0.1848691707470249, 'Total loss': 0.1848691707470249}
2023-01-04 03:49:14,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:14,654 INFO:     Epoch: 79
2023-01-04 03:49:16,290 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3975345293680827, 'Total loss': 0.3975345293680827} | train loss {'Reaction outcome loss': 0.18391996185002774, 'Total loss': 0.18391996185002774}
2023-01-04 03:49:16,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:16,290 INFO:     Epoch: 80
2023-01-04 03:49:17,876 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4031393051147461, 'Total loss': 0.4031393051147461} | train loss {'Reaction outcome loss': 0.18340290332085282, 'Total loss': 0.18340290332085282}
2023-01-04 03:49:17,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:17,876 INFO:     Epoch: 81
2023-01-04 03:49:19,505 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4372763067483902, 'Total loss': 0.4372763067483902} | train loss {'Reaction outcome loss': 0.1787556320401951, 'Total loss': 0.1787556320401951}
2023-01-04 03:49:19,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:19,505 INFO:     Epoch: 82
2023-01-04 03:49:21,117 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44525024592876433, 'Total loss': 0.44525024592876433} | train loss {'Reaction outcome loss': 0.18237174473138063, 'Total loss': 0.18237174473138063}
2023-01-04 03:49:21,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:21,117 INFO:     Epoch: 83
2023-01-04 03:49:22,727 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3965328166882197, 'Total loss': 0.3965328166882197} | train loss {'Reaction outcome loss': 0.17975641434696177, 'Total loss': 0.17975641434696177}
2023-01-04 03:49:22,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:22,727 INFO:     Epoch: 84
2023-01-04 03:49:24,334 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4278900921344757, 'Total loss': 0.4278900921344757} | train loss {'Reaction outcome loss': 0.17792311616726086, 'Total loss': 0.17792311616726086}
2023-01-04 03:49:24,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:24,335 INFO:     Epoch: 85
2023-01-04 03:49:25,961 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4118855039278666, 'Total loss': 0.4118855039278666} | train loss {'Reaction outcome loss': 0.1768416082116671, 'Total loss': 0.1768416082116671}
2023-01-04 03:49:25,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:25,961 INFO:     Epoch: 86
2023-01-04 03:49:27,560 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40368017355600994, 'Total loss': 0.40368017355600994} | train loss {'Reaction outcome loss': 0.17494977824053717, 'Total loss': 0.17494977824053717}
2023-01-04 03:49:27,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:27,561 INFO:     Epoch: 87
2023-01-04 03:49:29,163 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4121010810136795, 'Total loss': 0.4121010810136795} | train loss {'Reaction outcome loss': 0.1775709498835062, 'Total loss': 0.1775709498835062}
2023-01-04 03:49:29,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:29,164 INFO:     Epoch: 88
2023-01-04 03:49:30,789 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4456845720609029, 'Total loss': 0.4456845720609029} | train loss {'Reaction outcome loss': 0.17684565195376692, 'Total loss': 0.17684565195376692}
2023-01-04 03:49:30,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:30,789 INFO:     Epoch: 89
2023-01-04 03:49:32,423 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4329185406366984, 'Total loss': 0.4329185406366984} | train loss {'Reaction outcome loss': 0.1763406802600902, 'Total loss': 0.1763406802600902}
2023-01-04 03:49:32,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:32,424 INFO:     Epoch: 90
2023-01-04 03:49:34,064 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42451629092295967, 'Total loss': 0.42451629092295967} | train loss {'Reaction outcome loss': 0.17487928566492636, 'Total loss': 0.17487928566492636}
2023-01-04 03:49:34,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:34,064 INFO:     Epoch: 91
2023-01-04 03:49:35,453 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3984337836503983, 'Total loss': 0.3984337836503983} | train loss {'Reaction outcome loss': 0.17479919410219907, 'Total loss': 0.17479919410219907}
2023-01-04 03:49:35,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:35,454 INFO:     Epoch: 92
2023-01-04 03:49:36,521 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41074248949686687, 'Total loss': 0.41074248949686687} | train loss {'Reaction outcome loss': 0.17230214988173992, 'Total loss': 0.17230214988173992}
2023-01-04 03:49:36,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:36,521 INFO:     Epoch: 93
2023-01-04 03:49:37,593 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42183778882026673, 'Total loss': 0.42183778882026673} | train loss {'Reaction outcome loss': 0.17327709606300623, 'Total loss': 0.17327709606300623}
2023-01-04 03:49:37,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:37,594 INFO:     Epoch: 94
2023-01-04 03:49:38,655 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41040131747722625, 'Total loss': 0.41040131747722625} | train loss {'Reaction outcome loss': 0.1713013552559627, 'Total loss': 0.1713013552559627}
2023-01-04 03:49:38,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:38,655 INFO:     Epoch: 95
2023-01-04 03:49:39,829 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4210870832204819, 'Total loss': 0.4210870832204819} | train loss {'Reaction outcome loss': 0.17147599604142164, 'Total loss': 0.17147599604142164}
2023-01-04 03:49:39,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:39,830 INFO:     Epoch: 96
2023-01-04 03:49:41,427 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4512161463499069, 'Total loss': 0.4512161463499069} | train loss {'Reaction outcome loss': 0.1703456176465061, 'Total loss': 0.1703456176465061}
2023-01-04 03:49:41,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:41,427 INFO:     Epoch: 97
2023-01-04 03:49:43,024 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4206217885017395, 'Total loss': 0.4206217885017395} | train loss {'Reaction outcome loss': 0.17111545741988432, 'Total loss': 0.17111545741988432}
2023-01-04 03:49:43,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:43,024 INFO:     Epoch: 98
2023-01-04 03:49:44,624 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4004372894763947, 'Total loss': 0.4004372894763947} | train loss {'Reaction outcome loss': 0.16985529737836186, 'Total loss': 0.16985529737836186}
2023-01-04 03:49:44,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:44,625 INFO:     Epoch: 99
2023-01-04 03:49:46,226 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4186286518971125, 'Total loss': 0.4186286518971125} | train loss {'Reaction outcome loss': 0.16961752839171285, 'Total loss': 0.16961752839171285}
2023-01-04 03:49:46,227 INFO:     Best model found after epoch 34 of 100.
2023-01-04 03:49:46,227 INFO:   Done with stage: TRAINING
2023-01-04 03:49:46,227 INFO:   Starting stage: EVALUATION
2023-01-04 03:49:46,350 INFO:   Done with stage: EVALUATION
2023-01-04 03:49:46,358 INFO:   Leaving out SEQ value Fold_0
2023-01-04 03:49:46,371 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 03:49:46,371 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:49:47,021 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:49:47,021 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:49:47,088 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:49:47,089 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:49:47,089 INFO:     No hyperparam tuning for this model
2023-01-04 03:49:47,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:49:47,089 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:49:47,089 INFO:     None feature selector for col prot
2023-01-04 03:49:47,090 INFO:     None feature selector for col prot
2023-01-04 03:49:47,090 INFO:     None feature selector for col prot
2023-01-04 03:49:47,090 INFO:     None feature selector for col chem
2023-01-04 03:49:47,090 INFO:     None feature selector for col chem
2023-01-04 03:49:47,090 INFO:     None feature selector for col chem
2023-01-04 03:49:47,090 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:49:47,090 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:49:47,092 INFO:     Number of params in model 70141
2023-01-04 03:49:47,095 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:49:47,095 INFO:   Starting stage: TRAINING
2023-01-04 03:49:47,139 INFO:     Val loss before train {'Reaction outcome loss': 0.9900381882985433, 'Total loss': 0.9900381882985433}
2023-01-04 03:49:47,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:47,139 INFO:     Epoch: 0
2023-01-04 03:49:48,704 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6870200057824453, 'Total loss': 0.6870200057824453} | train loss {'Reaction outcome loss': 0.8293042885561059, 'Total loss': 0.8293042885561059}
2023-01-04 03:49:48,705 INFO:     Found new best model at epoch 0
2023-01-04 03:49:48,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:48,705 INFO:     Epoch: 1
2023-01-04 03:49:50,292 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5758162875970204, 'Total loss': 0.5758162875970204} | train loss {'Reaction outcome loss': 0.5935527466944535, 'Total loss': 0.5935527466944535}
2023-01-04 03:49:50,293 INFO:     Found new best model at epoch 1
2023-01-04 03:49:50,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:50,293 INFO:     Epoch: 2
2023-01-04 03:49:51,883 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5290425717830658, 'Total loss': 0.5290425717830658} | train loss {'Reaction outcome loss': 0.5208744181551203, 'Total loss': 0.5208744181551203}
2023-01-04 03:49:51,883 INFO:     Found new best model at epoch 2
2023-01-04 03:49:51,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:51,884 INFO:     Epoch: 3
2023-01-04 03:49:53,492 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5053785661856334, 'Total loss': 0.5053785661856334} | train loss {'Reaction outcome loss': 0.48806077388733843, 'Total loss': 0.48806077388733843}
2023-01-04 03:49:53,492 INFO:     Found new best model at epoch 3
2023-01-04 03:49:53,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:53,493 INFO:     Epoch: 4
2023-01-04 03:49:55,110 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5012511948744456, 'Total loss': 0.5012511948744456} | train loss {'Reaction outcome loss': 0.4588518670766893, 'Total loss': 0.4588518670766893}
2023-01-04 03:49:55,110 INFO:     Found new best model at epoch 4
2023-01-04 03:49:55,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:55,111 INFO:     Epoch: 5
2023-01-04 03:49:56,732 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5009245574474335, 'Total loss': 0.5009245574474335} | train loss {'Reaction outcome loss': 0.4403970173023043, 'Total loss': 0.4403970173023043}
2023-01-04 03:49:56,732 INFO:     Found new best model at epoch 5
2023-01-04 03:49:56,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:56,733 INFO:     Epoch: 6
2023-01-04 03:49:58,319 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4657799959182739, 'Total loss': 0.4657799959182739} | train loss {'Reaction outcome loss': 0.42205339050205953, 'Total loss': 0.42205339050205953}
2023-01-04 03:49:58,319 INFO:     Found new best model at epoch 6
2023-01-04 03:49:58,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:58,320 INFO:     Epoch: 7
2023-01-04 03:49:59,910 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4490242044130961, 'Total loss': 0.4490242044130961} | train loss {'Reaction outcome loss': 0.40802166937258993, 'Total loss': 0.40802166937258993}
2023-01-04 03:49:59,912 INFO:     Found new best model at epoch 7
2023-01-04 03:49:59,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:49:59,913 INFO:     Epoch: 8
2023-01-04 03:50:01,502 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4660463492075602, 'Total loss': 0.4660463492075602} | train loss {'Reaction outcome loss': 0.395127559067124, 'Total loss': 0.395127559067124}
2023-01-04 03:50:01,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:01,502 INFO:     Epoch: 9
2023-01-04 03:50:03,076 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4386736293633779, 'Total loss': 0.4386736293633779} | train loss {'Reaction outcome loss': 0.384726949960646, 'Total loss': 0.384726949960646}
2023-01-04 03:50:03,077 INFO:     Found new best model at epoch 9
2023-01-04 03:50:03,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:03,077 INFO:     Epoch: 10
2023-01-04 03:50:04,669 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43604953984419503, 'Total loss': 0.43604953984419503} | train loss {'Reaction outcome loss': 0.37264790946114673, 'Total loss': 0.37264790946114673}
2023-01-04 03:50:04,670 INFO:     Found new best model at epoch 10
2023-01-04 03:50:04,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:04,670 INFO:     Epoch: 11
2023-01-04 03:50:06,261 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43561405936876935, 'Total loss': 0.43561405936876935} | train loss {'Reaction outcome loss': 0.3638655264066519, 'Total loss': 0.3638655264066519}
2023-01-04 03:50:06,261 INFO:     Found new best model at epoch 11
2023-01-04 03:50:06,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:06,262 INFO:     Epoch: 12
2023-01-04 03:50:07,832 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43474345405896503, 'Total loss': 0.43474345405896503} | train loss {'Reaction outcome loss': 0.35672740069945363, 'Total loss': 0.35672740069945363}
2023-01-04 03:50:07,832 INFO:     Found new best model at epoch 12
2023-01-04 03:50:07,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:07,833 INFO:     Epoch: 13
2023-01-04 03:50:09,422 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42663091818491616, 'Total loss': 0.42663091818491616} | train loss {'Reaction outcome loss': 0.3467110084900021, 'Total loss': 0.3467110084900021}
2023-01-04 03:50:09,422 INFO:     Found new best model at epoch 13
2023-01-04 03:50:09,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:09,423 INFO:     Epoch: 14
2023-01-04 03:50:11,013 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.431956418355306, 'Total loss': 0.431956418355306} | train loss {'Reaction outcome loss': 0.34105713159716045, 'Total loss': 0.34105713159716045}
2023-01-04 03:50:11,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:11,014 INFO:     Epoch: 15
2023-01-04 03:50:12,608 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4163820336262385, 'Total loss': 0.4163820336262385} | train loss {'Reaction outcome loss': 0.3344890818978748, 'Total loss': 0.3344890818978748}
2023-01-04 03:50:12,608 INFO:     Found new best model at epoch 15
2023-01-04 03:50:12,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:12,609 INFO:     Epoch: 16
2023-01-04 03:50:14,223 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4385166585445404, 'Total loss': 0.4385166585445404} | train loss {'Reaction outcome loss': 0.3270229800284779, 'Total loss': 0.3270229800284779}
2023-01-04 03:50:14,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:14,223 INFO:     Epoch: 17
2023-01-04 03:50:15,810 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43699027399222057, 'Total loss': 0.43699027399222057} | train loss {'Reaction outcome loss': 0.32126271702947407, 'Total loss': 0.32126271702947407}
2023-01-04 03:50:15,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:15,810 INFO:     Epoch: 18
2023-01-04 03:50:17,419 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4254202485084534, 'Total loss': 0.4254202485084534} | train loss {'Reaction outcome loss': 0.31574180349707603, 'Total loss': 0.31574180349707603}
2023-01-04 03:50:17,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:17,419 INFO:     Epoch: 19
2023-01-04 03:50:19,029 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44632935921351113, 'Total loss': 0.44632935921351113} | train loss {'Reaction outcome loss': 0.31007809580786383, 'Total loss': 0.31007809580786383}
2023-01-04 03:50:19,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:19,030 INFO:     Epoch: 20
2023-01-04 03:50:20,587 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4245992441972097, 'Total loss': 0.4245992441972097} | train loss {'Reaction outcome loss': 0.3053012328208798, 'Total loss': 0.3053012328208798}
2023-01-04 03:50:20,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:20,587 INFO:     Epoch: 21
2023-01-04 03:50:22,171 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4146386444568634, 'Total loss': 0.4146386444568634} | train loss {'Reaction outcome loss': 0.3007412652899749, 'Total loss': 0.3007412652899749}
2023-01-04 03:50:22,171 INFO:     Found new best model at epoch 21
2023-01-04 03:50:22,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:22,172 INFO:     Epoch: 22
2023-01-04 03:50:23,814 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41700148781140645, 'Total loss': 0.41700148781140645} | train loss {'Reaction outcome loss': 0.29625343474267174, 'Total loss': 0.29625343474267174}
2023-01-04 03:50:23,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:23,814 INFO:     Epoch: 23
2023-01-04 03:50:25,392 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41322589417298633, 'Total loss': 0.41322589417298633} | train loss {'Reaction outcome loss': 0.2897903241053985, 'Total loss': 0.2897903241053985}
2023-01-04 03:50:25,392 INFO:     Found new best model at epoch 23
2023-01-04 03:50:25,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:25,393 INFO:     Epoch: 24
2023-01-04 03:50:26,990 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4331192294756571, 'Total loss': 0.4331192294756571} | train loss {'Reaction outcome loss': 0.28934343707115545, 'Total loss': 0.28934343707115545}
2023-01-04 03:50:26,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:26,990 INFO:     Epoch: 25
2023-01-04 03:50:28,602 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41299738983313244, 'Total loss': 0.41299738983313244} | train loss {'Reaction outcome loss': 0.2857323707400882, 'Total loss': 0.2857323707400882}
2023-01-04 03:50:28,602 INFO:     Found new best model at epoch 25
2023-01-04 03:50:28,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:28,603 INFO:     Epoch: 26
2023-01-04 03:50:30,198 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4098576585451762, 'Total loss': 0.4098576585451762} | train loss {'Reaction outcome loss': 0.28050243196478725, 'Total loss': 0.28050243196478725}
2023-01-04 03:50:30,199 INFO:     Found new best model at epoch 26
2023-01-04 03:50:30,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:30,200 INFO:     Epoch: 27
2023-01-04 03:50:31,852 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4318661550680796, 'Total loss': 0.4318661550680796} | train loss {'Reaction outcome loss': 0.27685426749343417, 'Total loss': 0.27685426749343417}
2023-01-04 03:50:31,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:31,852 INFO:     Epoch: 28
2023-01-04 03:50:33,453 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41412054498990375, 'Total loss': 0.41412054498990375} | train loss {'Reaction outcome loss': 0.2705104489450472, 'Total loss': 0.2705104489450472}
2023-01-04 03:50:33,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:33,453 INFO:     Epoch: 29
2023-01-04 03:50:35,010 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4053348273038864, 'Total loss': 0.4053348273038864} | train loss {'Reaction outcome loss': 0.27197810857944243, 'Total loss': 0.27197810857944243}
2023-01-04 03:50:35,011 INFO:     Found new best model at epoch 29
2023-01-04 03:50:35,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:35,011 INFO:     Epoch: 30
2023-01-04 03:50:36,579 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4297233025232951, 'Total loss': 0.4297233025232951} | train loss {'Reaction outcome loss': 0.2652592442277139, 'Total loss': 0.2652592442277139}
2023-01-04 03:50:36,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:36,579 INFO:     Epoch: 31
2023-01-04 03:50:38,170 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3971416920423508, 'Total loss': 0.3971416920423508} | train loss {'Reaction outcome loss': 0.264629306611571, 'Total loss': 0.264629306611571}
2023-01-04 03:50:38,170 INFO:     Found new best model at epoch 31
2023-01-04 03:50:38,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:38,171 INFO:     Epoch: 32
2023-01-04 03:50:39,738 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40588275094827014, 'Total loss': 0.40588275094827014} | train loss {'Reaction outcome loss': 0.2596375061484584, 'Total loss': 0.2596375061484584}
2023-01-04 03:50:39,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:39,738 INFO:     Epoch: 33
2023-01-04 03:50:41,324 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4146112600962321, 'Total loss': 0.4146112600962321} | train loss {'Reaction outcome loss': 0.25701125694887483, 'Total loss': 0.25701125694887483}
2023-01-04 03:50:41,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:41,324 INFO:     Epoch: 34
2023-01-04 03:50:42,895 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4070842117071152, 'Total loss': 0.4070842117071152} | train loss {'Reaction outcome loss': 0.2534785636421973, 'Total loss': 0.2534785636421973}
2023-01-04 03:50:42,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:42,895 INFO:     Epoch: 35
2023-01-04 03:50:44,482 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4216674347718557, 'Total loss': 0.4216674347718557} | train loss {'Reaction outcome loss': 0.2506049189335891, 'Total loss': 0.2506049189335891}
2023-01-04 03:50:44,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:44,482 INFO:     Epoch: 36
2023-01-04 03:50:46,068 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41238576273123423, 'Total loss': 0.41238576273123423} | train loss {'Reaction outcome loss': 0.2476709814619844, 'Total loss': 0.2476709814619844}
2023-01-04 03:50:46,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:46,068 INFO:     Epoch: 37
2023-01-04 03:50:47,635 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3959789047638575, 'Total loss': 0.3959789047638575} | train loss {'Reaction outcome loss': 0.2450531514864551, 'Total loss': 0.2450531514864551}
2023-01-04 03:50:47,635 INFO:     Found new best model at epoch 37
2023-01-04 03:50:47,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:47,636 INFO:     Epoch: 38
2023-01-04 03:50:49,247 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41000189681847893, 'Total loss': 0.41000189681847893} | train loss {'Reaction outcome loss': 0.24296826026300444, 'Total loss': 0.24296826026300444}
2023-01-04 03:50:49,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:49,248 INFO:     Epoch: 39
2023-01-04 03:50:50,854 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4207256575425466, 'Total loss': 0.4207256575425466} | train loss {'Reaction outcome loss': 0.2395477977030686, 'Total loss': 0.2395477977030686}
2023-01-04 03:50:50,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:50,854 INFO:     Epoch: 40
2023-01-04 03:50:52,436 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4171122332413991, 'Total loss': 0.4171122332413991} | train loss {'Reaction outcome loss': 0.23758224676614695, 'Total loss': 0.23758224676614695}
2023-01-04 03:50:52,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:52,437 INFO:     Epoch: 41
2023-01-04 03:50:54,046 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42998492320378623, 'Total loss': 0.42998492320378623} | train loss {'Reaction outcome loss': 0.2354432613228577, 'Total loss': 0.2354432613228577}
2023-01-04 03:50:54,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:54,047 INFO:     Epoch: 42
2023-01-04 03:50:55,657 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4207436790068944, 'Total loss': 0.4207436790068944} | train loss {'Reaction outcome loss': 0.23454628853521642, 'Total loss': 0.23454628853521642}
2023-01-04 03:50:55,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:55,657 INFO:     Epoch: 43
2023-01-04 03:50:57,234 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4072255492210388, 'Total loss': 0.4072255492210388} | train loss {'Reaction outcome loss': 0.22898356117525676, 'Total loss': 0.22898356117525676}
2023-01-04 03:50:57,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:57,234 INFO:     Epoch: 44
2023-01-04 03:50:58,848 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4141377220551173, 'Total loss': 0.4141377220551173} | train loss {'Reaction outcome loss': 0.22919751181654688, 'Total loss': 0.22919751181654688}
2023-01-04 03:50:58,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:50:58,848 INFO:     Epoch: 45
2023-01-04 03:51:00,443 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39750921676556267, 'Total loss': 0.39750921676556267} | train loss {'Reaction outcome loss': 0.2241849972166284, 'Total loss': 0.2241849972166284}
2023-01-04 03:51:00,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:00,444 INFO:     Epoch: 46
2023-01-04 03:51:02,068 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40274101197719575, 'Total loss': 0.40274101197719575} | train loss {'Reaction outcome loss': 0.22364795366370113, 'Total loss': 0.22364795366370113}
2023-01-04 03:51:02,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:02,068 INFO:     Epoch: 47
2023-01-04 03:51:03,672 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4249678413073222, 'Total loss': 0.4249678413073222} | train loss {'Reaction outcome loss': 0.22189089536231799, 'Total loss': 0.22189089536231799}
2023-01-04 03:51:03,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:03,672 INFO:     Epoch: 48
2023-01-04 03:51:05,252 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4232259432474772, 'Total loss': 0.4232259432474772} | train loss {'Reaction outcome loss': 0.21941933655146048, 'Total loss': 0.21941933655146048}
2023-01-04 03:51:05,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:05,252 INFO:     Epoch: 49
2023-01-04 03:51:06,849 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41005164086818696, 'Total loss': 0.41005164086818696} | train loss {'Reaction outcome loss': 0.21870161300647434, 'Total loss': 0.21870161300647434}
2023-01-04 03:51:06,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:06,850 INFO:     Epoch: 50
2023-01-04 03:51:08,458 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43589743276437126, 'Total loss': 0.43589743276437126} | train loss {'Reaction outcome loss': 0.2165931344480954, 'Total loss': 0.2165931344480954}
2023-01-04 03:51:08,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:08,458 INFO:     Epoch: 51
2023-01-04 03:51:10,048 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42111699978510536, 'Total loss': 0.42111699978510536} | train loss {'Reaction outcome loss': 0.21718409018468682, 'Total loss': 0.21718409018468682}
2023-01-04 03:51:10,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:10,048 INFO:     Epoch: 52
2023-01-04 03:51:11,655 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4077310959498088, 'Total loss': 0.4077310959498088} | train loss {'Reaction outcome loss': 0.21324930869613903, 'Total loss': 0.21324930869613903}
2023-01-04 03:51:11,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:11,655 INFO:     Epoch: 53
2023-01-04 03:51:13,266 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4326404382785161, 'Total loss': 0.4326404382785161} | train loss {'Reaction outcome loss': 0.2115208540438083, 'Total loss': 0.2115208540438083}
2023-01-04 03:51:13,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:13,266 INFO:     Epoch: 54
2023-01-04 03:51:14,819 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4334519952535629, 'Total loss': 0.4334519952535629} | train loss {'Reaction outcome loss': 0.2090204398344903, 'Total loss': 0.2090204398344903}
2023-01-04 03:51:14,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:14,819 INFO:     Epoch: 55
2023-01-04 03:51:16,435 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4454810321331024, 'Total loss': 0.4454810321331024} | train loss {'Reaction outcome loss': 0.2074367062725725, 'Total loss': 0.2074367062725725}
2023-01-04 03:51:16,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:16,435 INFO:     Epoch: 56
2023-01-04 03:51:18,047 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42128095030784607, 'Total loss': 0.42128095030784607} | train loss {'Reaction outcome loss': 0.20404197429272816, 'Total loss': 0.20404197429272816}
2023-01-04 03:51:18,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:18,047 INFO:     Epoch: 57
2023-01-04 03:51:19,644 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43074015378952024, 'Total loss': 0.43074015378952024} | train loss {'Reaction outcome loss': 0.20268790793679928, 'Total loss': 0.20268790793679928}
2023-01-04 03:51:19,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:19,644 INFO:     Epoch: 58
2023-01-04 03:51:21,262 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43913881480693817, 'Total loss': 0.43913881480693817} | train loss {'Reaction outcome loss': 0.201129863881608, 'Total loss': 0.201129863881608}
2023-01-04 03:51:21,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:21,262 INFO:     Epoch: 59
2023-01-04 03:51:22,883 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4169432520866394, 'Total loss': 0.4169432520866394} | train loss {'Reaction outcome loss': 0.1992498810409847, 'Total loss': 0.1992498810409847}
2023-01-04 03:51:22,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:22,883 INFO:     Epoch: 60
2023-01-04 03:51:24,466 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4525369226932526, 'Total loss': 0.4525369226932526} | train loss {'Reaction outcome loss': 0.20007682509421215, 'Total loss': 0.20007682509421215}
2023-01-04 03:51:24,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:24,466 INFO:     Epoch: 61
2023-01-04 03:51:26,058 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44777282476425173, 'Total loss': 0.44777282476425173} | train loss {'Reaction outcome loss': 0.1970276482484854, 'Total loss': 0.1970276482484854}
2023-01-04 03:51:26,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:26,059 INFO:     Epoch: 62
2023-01-04 03:51:27,633 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4222513308127721, 'Total loss': 0.4222513308127721} | train loss {'Reaction outcome loss': 0.19696474035889128, 'Total loss': 0.19696474035889128}
2023-01-04 03:51:27,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:27,633 INFO:     Epoch: 63
2023-01-04 03:51:29,200 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43914879163106285, 'Total loss': 0.43914879163106285} | train loss {'Reaction outcome loss': 0.19528828426706094, 'Total loss': 0.19528828426706094}
2023-01-04 03:51:29,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:29,201 INFO:     Epoch: 64
2023-01-04 03:51:30,813 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46264052093029023, 'Total loss': 0.46264052093029023} | train loss {'Reaction outcome loss': 0.1935781672134669, 'Total loss': 0.1935781672134669}
2023-01-04 03:51:30,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:30,814 INFO:     Epoch: 65
2023-01-04 03:51:32,426 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4501303950945536, 'Total loss': 0.4501303950945536} | train loss {'Reaction outcome loss': 0.19182790023186347, 'Total loss': 0.19182790023186347}
2023-01-04 03:51:32,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:32,426 INFO:     Epoch: 66
2023-01-04 03:51:33,975 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45307213366031646, 'Total loss': 0.45307213366031646} | train loss {'Reaction outcome loss': 0.19112880411048006, 'Total loss': 0.19112880411048006}
2023-01-04 03:51:33,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:33,975 INFO:     Epoch: 67
2023-01-04 03:51:35,591 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4236146956682205, 'Total loss': 0.4236146956682205} | train loss {'Reaction outcome loss': 0.18856967640292904, 'Total loss': 0.18856967640292904}
2023-01-04 03:51:35,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:35,591 INFO:     Epoch: 68
2023-01-04 03:51:37,165 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42438370510935786, 'Total loss': 0.42438370510935786} | train loss {'Reaction outcome loss': 0.18916598496020492, 'Total loss': 0.18916598496020492}
2023-01-04 03:51:37,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:37,166 INFO:     Epoch: 69
2023-01-04 03:51:38,779 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46250227888425194, 'Total loss': 0.46250227888425194} | train loss {'Reaction outcome loss': 0.18635731792743623, 'Total loss': 0.18635731792743623}
2023-01-04 03:51:38,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:38,780 INFO:     Epoch: 70
2023-01-04 03:51:40,399 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43588673969109853, 'Total loss': 0.43588673969109853} | train loss {'Reaction outcome loss': 0.1878815605882963, 'Total loss': 0.1878815605882963}
2023-01-04 03:51:40,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:40,399 INFO:     Epoch: 71
2023-01-04 03:51:41,982 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4385609189669291, 'Total loss': 0.4385609189669291} | train loss {'Reaction outcome loss': 0.18517401356277238, 'Total loss': 0.18517401356277238}
2023-01-04 03:51:41,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:41,983 INFO:     Epoch: 72
2023-01-04 03:51:43,588 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4682993272940318, 'Total loss': 0.4682993272940318} | train loss {'Reaction outcome loss': 0.18235546430695232, 'Total loss': 0.18235546430695232}
2023-01-04 03:51:43,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:43,589 INFO:     Epoch: 73
2023-01-04 03:51:45,202 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4784684757391612, 'Total loss': 0.4784684757391612} | train loss {'Reaction outcome loss': 0.184248944948407, 'Total loss': 0.184248944948407}
2023-01-04 03:51:45,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:45,203 INFO:     Epoch: 74
2023-01-04 03:51:46,804 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45426665941874184, 'Total loss': 0.45426665941874184} | train loss {'Reaction outcome loss': 0.18247616712520592, 'Total loss': 0.18247616712520592}
2023-01-04 03:51:46,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:46,804 INFO:     Epoch: 75
2023-01-04 03:51:48,415 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45696194569269816, 'Total loss': 0.45696194569269816} | train loss {'Reaction outcome loss': 0.1817533686403593, 'Total loss': 0.1817533686403593}
2023-01-04 03:51:48,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:48,416 INFO:     Epoch: 76
2023-01-04 03:51:49,981 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4308814316987991, 'Total loss': 0.4308814316987991} | train loss {'Reaction outcome loss': 0.18046109969761684, 'Total loss': 0.18046109969761684}
2023-01-04 03:51:49,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:49,982 INFO:     Epoch: 77
2023-01-04 03:51:51,553 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43488166530927025, 'Total loss': 0.43488166530927025} | train loss {'Reaction outcome loss': 0.18059919434633567, 'Total loss': 0.18059919434633567}
2023-01-04 03:51:51,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:51,553 INFO:     Epoch: 78
2023-01-04 03:51:53,146 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4525392641623815, 'Total loss': 0.4525392641623815} | train loss {'Reaction outcome loss': 0.17779109429867163, 'Total loss': 0.17779109429867163}
2023-01-04 03:51:53,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:53,146 INFO:     Epoch: 79
2023-01-04 03:51:54,724 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4559086710214615, 'Total loss': 0.4559086710214615} | train loss {'Reaction outcome loss': 0.1775685883956506, 'Total loss': 0.1775685883956506}
2023-01-04 03:51:54,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:54,725 INFO:     Epoch: 80
2023-01-04 03:51:56,318 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45076297521591185, 'Total loss': 0.45076297521591185} | train loss {'Reaction outcome loss': 0.1763497670351045, 'Total loss': 0.1763497670351045}
2023-01-04 03:51:56,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:56,318 INFO:     Epoch: 81
2023-01-04 03:51:57,931 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46141958634058633, 'Total loss': 0.46141958634058633} | train loss {'Reaction outcome loss': 0.17772820012059307, 'Total loss': 0.17772820012059307}
2023-01-04 03:51:57,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:57,931 INFO:     Epoch: 82
2023-01-04 03:51:59,522 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.449038361509641, 'Total loss': 0.449038361509641} | train loss {'Reaction outcome loss': 0.1734209898655323, 'Total loss': 0.1734209898655323}
2023-01-04 03:51:59,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:51:59,522 INFO:     Epoch: 83
2023-01-04 03:52:01,100 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.451598780353864, 'Total loss': 0.451598780353864} | train loss {'Reaction outcome loss': 0.1762400549720891, 'Total loss': 0.1762400549720891}
2023-01-04 03:52:01,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:01,101 INFO:     Epoch: 84
2023-01-04 03:52:02,690 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4626755992571513, 'Total loss': 0.4626755992571513} | train loss {'Reaction outcome loss': 0.17323946146579988, 'Total loss': 0.17323946146579988}
2023-01-04 03:52:02,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:02,690 INFO:     Epoch: 85
2023-01-04 03:52:04,251 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46503360867500304, 'Total loss': 0.46503360867500304} | train loss {'Reaction outcome loss': 0.1744391293108572, 'Total loss': 0.1744391293108572}
2023-01-04 03:52:04,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:04,251 INFO:     Epoch: 86
2023-01-04 03:52:05,866 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4609895790616671, 'Total loss': 0.4609895790616671} | train loss {'Reaction outcome loss': 0.17190907192654417, 'Total loss': 0.17190907192654417}
2023-01-04 03:52:05,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:05,866 INFO:     Epoch: 87
2023-01-04 03:52:07,476 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47444159984588624, 'Total loss': 0.47444159984588624} | train loss {'Reaction outcome loss': 0.1705694848494808, 'Total loss': 0.1705694848494808}
2023-01-04 03:52:07,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:07,476 INFO:     Epoch: 88
2023-01-04 03:52:09,069 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44921345909436544, 'Total loss': 0.44921345909436544} | train loss {'Reaction outcome loss': 0.17269922070966584, 'Total loss': 0.17269922070966584}
2023-01-04 03:52:09,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:09,070 INFO:     Epoch: 89
2023-01-04 03:52:10,683 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4574464698632558, 'Total loss': 0.4574464698632558} | train loss {'Reaction outcome loss': 0.17001004778800438, 'Total loss': 0.17001004778800438}
2023-01-04 03:52:10,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:10,683 INFO:     Epoch: 90
2023-01-04 03:52:12,298 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4416135499874751, 'Total loss': 0.4416135499874751} | train loss {'Reaction outcome loss': 0.1708971240904427, 'Total loss': 0.1708971240904427}
2023-01-04 03:52:12,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:12,298 INFO:     Epoch: 91
2023-01-04 03:52:13,871 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4652665505806605, 'Total loss': 0.4652665505806605} | train loss {'Reaction outcome loss': 0.16736735214554047, 'Total loss': 0.16736735214554047}
2023-01-04 03:52:13,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:13,871 INFO:     Epoch: 92
2023-01-04 03:52:15,460 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46782488822937013, 'Total loss': 0.46782488822937013} | train loss {'Reaction outcome loss': 0.16752362981384253, 'Total loss': 0.16752362981384253}
2023-01-04 03:52:15,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:15,461 INFO:     Epoch: 93
2023-01-04 03:52:17,050 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4460746333003044, 'Total loss': 0.4460746333003044} | train loss {'Reaction outcome loss': 0.16681579168695604, 'Total loss': 0.16681579168695604}
2023-01-04 03:52:17,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:17,050 INFO:     Epoch: 94
2023-01-04 03:52:18,635 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4618907555937767, 'Total loss': 0.4618907555937767} | train loss {'Reaction outcome loss': 0.16514476225541455, 'Total loss': 0.16514476225541455}
2023-01-04 03:52:18,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:18,636 INFO:     Epoch: 95
2023-01-04 03:52:20,242 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46662811636924745, 'Total loss': 0.46662811636924745} | train loss {'Reaction outcome loss': 0.16928183755082807, 'Total loss': 0.16928183755082807}
2023-01-04 03:52:20,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:20,242 INFO:     Epoch: 96
2023-01-04 03:52:21,827 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4499654869238536, 'Total loss': 0.4499654869238536} | train loss {'Reaction outcome loss': 0.16266871158740598, 'Total loss': 0.16266871158740598}
2023-01-04 03:52:21,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:21,828 INFO:     Epoch: 97
2023-01-04 03:52:23,439 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.475519206126531, 'Total loss': 0.475519206126531} | train loss {'Reaction outcome loss': 0.1656563993115114, 'Total loss': 0.1656563993115114}
2023-01-04 03:52:23,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:23,439 INFO:     Epoch: 98
2023-01-04 03:52:25,046 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45144809285799664, 'Total loss': 0.45144809285799664} | train loss {'Reaction outcome loss': 0.1635582807820535, 'Total loss': 0.1635582807820535}
2023-01-04 03:52:25,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:25,047 INFO:     Epoch: 99
2023-01-04 03:52:26,633 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4630190511544546, 'Total loss': 0.4630190511544546} | train loss {'Reaction outcome loss': 0.16008763568625398, 'Total loss': 0.16008763568625398}
2023-01-04 03:52:26,633 INFO:     Best model found after epoch 38 of 100.
2023-01-04 03:52:26,634 INFO:   Done with stage: TRAINING
2023-01-04 03:52:26,634 INFO:   Starting stage: EVALUATION
2023-01-04 03:52:26,768 INFO:   Done with stage: EVALUATION
2023-01-04 03:52:26,768 INFO:   Leaving out SEQ value Fold_1
2023-01-04 03:52:26,781 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 03:52:26,781 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:52:27,419 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:52:27,419 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:52:27,486 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:52:27,486 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:52:27,486 INFO:     No hyperparam tuning for this model
2023-01-04 03:52:27,486 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:52:27,486 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:52:27,487 INFO:     None feature selector for col prot
2023-01-04 03:52:27,487 INFO:     None feature selector for col prot
2023-01-04 03:52:27,487 INFO:     None feature selector for col prot
2023-01-04 03:52:27,487 INFO:     None feature selector for col chem
2023-01-04 03:52:27,487 INFO:     None feature selector for col chem
2023-01-04 03:52:27,487 INFO:     None feature selector for col chem
2023-01-04 03:52:27,487 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:52:27,488 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:52:27,489 INFO:     Number of params in model 70141
2023-01-04 03:52:27,492 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:52:27,492 INFO:   Starting stage: TRAINING
2023-01-04 03:52:27,536 INFO:     Val loss before train {'Reaction outcome loss': 1.006937062740326, 'Total loss': 1.006937062740326}
2023-01-04 03:52:27,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:27,536 INFO:     Epoch: 0
2023-01-04 03:52:29,149 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6714064081509908, 'Total loss': 0.6714064081509908} | train loss {'Reaction outcome loss': 0.8350717412294263, 'Total loss': 0.8350717412294263}
2023-01-04 03:52:29,150 INFO:     Found new best model at epoch 0
2023-01-04 03:52:29,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:29,150 INFO:     Epoch: 1
2023-01-04 03:52:30,726 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5755626181761424, 'Total loss': 0.5755626181761424} | train loss {'Reaction outcome loss': 0.5979640010717141, 'Total loss': 0.5979640010717141}
2023-01-04 03:52:30,726 INFO:     Found new best model at epoch 1
2023-01-04 03:52:30,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:30,727 INFO:     Epoch: 2
2023-01-04 03:52:32,315 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5203000207742056, 'Total loss': 0.5203000207742056} | train loss {'Reaction outcome loss': 0.5293923430416706, 'Total loss': 0.5293923430416706}
2023-01-04 03:52:32,315 INFO:     Found new best model at epoch 2
2023-01-04 03:52:32,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:32,316 INFO:     Epoch: 3
2023-01-04 03:52:33,904 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5005172193050385, 'Total loss': 0.5005172193050385} | train loss {'Reaction outcome loss': 0.492285353750208, 'Total loss': 0.492285353750208}
2023-01-04 03:52:33,904 INFO:     Found new best model at epoch 3
2023-01-04 03:52:33,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:33,905 INFO:     Epoch: 4
2023-01-04 03:52:35,468 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47789773245652517, 'Total loss': 0.47789773245652517} | train loss {'Reaction outcome loss': 0.4666473955786141, 'Total loss': 0.4666473955786141}
2023-01-04 03:52:35,468 INFO:     Found new best model at epoch 4
2023-01-04 03:52:35,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:35,469 INFO:     Epoch: 5
2023-01-04 03:52:37,078 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46988584597905475, 'Total loss': 0.46988584597905475} | train loss {'Reaction outcome loss': 0.44634628225199496, 'Total loss': 0.44634628225199496}
2023-01-04 03:52:37,079 INFO:     Found new best model at epoch 5
2023-01-04 03:52:37,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:37,079 INFO:     Epoch: 6
2023-01-04 03:52:38,684 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4619303027788798, 'Total loss': 0.4619303027788798} | train loss {'Reaction outcome loss': 0.4296058234724685, 'Total loss': 0.4296058234724685}
2023-01-04 03:52:38,684 INFO:     Found new best model at epoch 6
2023-01-04 03:52:38,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:38,685 INFO:     Epoch: 7
2023-01-04 03:52:40,249 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47836021780967714, 'Total loss': 0.47836021780967714} | train loss {'Reaction outcome loss': 0.41582076061163503, 'Total loss': 0.41582076061163503}
2023-01-04 03:52:40,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:40,249 INFO:     Epoch: 8
2023-01-04 03:52:41,872 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4529461661974589, 'Total loss': 0.4529461661974589} | train loss {'Reaction outcome loss': 0.4056869313990983, 'Total loss': 0.4056869313990983}
2023-01-04 03:52:41,872 INFO:     Found new best model at epoch 8
2023-01-04 03:52:41,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:41,873 INFO:     Epoch: 9
2023-01-04 03:52:43,490 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4437908887863159, 'Total loss': 0.4437908887863159} | train loss {'Reaction outcome loss': 0.3959116640969785, 'Total loss': 0.3959116640969785}
2023-01-04 03:52:43,490 INFO:     Found new best model at epoch 9
2023-01-04 03:52:43,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:43,491 INFO:     Epoch: 10
2023-01-04 03:52:45,073 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4394378145535787, 'Total loss': 0.4394378145535787} | train loss {'Reaction outcome loss': 0.3858614190869088, 'Total loss': 0.3858614190869088}
2023-01-04 03:52:45,073 INFO:     Found new best model at epoch 10
2023-01-04 03:52:45,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:45,074 INFO:     Epoch: 11
2023-01-04 03:52:46,683 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44478551745414735, 'Total loss': 0.44478551745414735} | train loss {'Reaction outcome loss': 0.3750320573194619, 'Total loss': 0.3750320573194619}
2023-01-04 03:52:46,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:46,683 INFO:     Epoch: 12
2023-01-04 03:52:48,279 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4453896423180898, 'Total loss': 0.4453896423180898} | train loss {'Reaction outcome loss': 0.366977303567594, 'Total loss': 0.366977303567594}
2023-01-04 03:52:48,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:48,279 INFO:     Epoch: 13
2023-01-04 03:52:49,904 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43206299940745035, 'Total loss': 0.43206299940745035} | train loss {'Reaction outcome loss': 0.3589016971633817, 'Total loss': 0.3589016971633817}
2023-01-04 03:52:49,904 INFO:     Found new best model at epoch 13
2023-01-04 03:52:49,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:49,905 INFO:     Epoch: 14
2023-01-04 03:52:51,469 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4305461217959722, 'Total loss': 0.4305461217959722} | train loss {'Reaction outcome loss': 0.35249724579009695, 'Total loss': 0.35249724579009695}
2023-01-04 03:52:51,469 INFO:     Found new best model at epoch 14
2023-01-04 03:52:51,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:51,470 INFO:     Epoch: 15
2023-01-04 03:52:53,038 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4341072996457418, 'Total loss': 0.4341072996457418} | train loss {'Reaction outcome loss': 0.34944581721712203, 'Total loss': 0.34944581721712203}
2023-01-04 03:52:53,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:53,038 INFO:     Epoch: 16
2023-01-04 03:52:54,638 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46370684703191123, 'Total loss': 0.46370684703191123} | train loss {'Reaction outcome loss': 0.34163543867477536, 'Total loss': 0.34163543867477536}
2023-01-04 03:52:54,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:54,639 INFO:     Epoch: 17
2023-01-04 03:52:56,256 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4481821815172831, 'Total loss': 0.4481821815172831} | train loss {'Reaction outcome loss': 0.3347788027005039, 'Total loss': 0.3347788027005039}
2023-01-04 03:52:56,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:56,256 INFO:     Epoch: 18
2023-01-04 03:52:57,846 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4423146883646647, 'Total loss': 0.4423146883646647} | train loss {'Reaction outcome loss': 0.32736677195142655, 'Total loss': 0.32736677195142655}
2023-01-04 03:52:57,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:57,847 INFO:     Epoch: 19
2023-01-04 03:52:59,435 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4363953749338786, 'Total loss': 0.4363953749338786} | train loss {'Reaction outcome loss': 0.3229236111153651, 'Total loss': 0.3229236111153651}
2023-01-04 03:52:59,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:52:59,435 INFO:     Epoch: 20
2023-01-04 03:53:01,024 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42962077260017395, 'Total loss': 0.42962077260017395} | train loss {'Reaction outcome loss': 0.31786124318511816, 'Total loss': 0.31786124318511816}
2023-01-04 03:53:01,025 INFO:     Found new best model at epoch 20
2023-01-04 03:53:01,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:01,026 INFO:     Epoch: 21
2023-01-04 03:53:02,605 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4431797901789347, 'Total loss': 0.4431797901789347} | train loss {'Reaction outcome loss': 0.3099079135615025, 'Total loss': 0.3099079135615025}
2023-01-04 03:53:02,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:02,605 INFO:     Epoch: 22
2023-01-04 03:53:04,192 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4346061607201894, 'Total loss': 0.4346061607201894} | train loss {'Reaction outcome loss': 0.3100160093855684, 'Total loss': 0.3100160093855684}
2023-01-04 03:53:04,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:04,192 INFO:     Epoch: 23
2023-01-04 03:53:05,779 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4504388431708018, 'Total loss': 0.4504388431708018} | train loss {'Reaction outcome loss': 0.3058350848673034, 'Total loss': 0.3058350848673034}
2023-01-04 03:53:05,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:05,780 INFO:     Epoch: 24
2023-01-04 03:53:07,354 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42432498137156166, 'Total loss': 0.42432498137156166} | train loss {'Reaction outcome loss': 0.2980153901081016, 'Total loss': 0.2980153901081016}
2023-01-04 03:53:07,354 INFO:     Found new best model at epoch 24
2023-01-04 03:53:07,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:07,355 INFO:     Epoch: 25
2023-01-04 03:53:08,939 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4590592563152313, 'Total loss': 0.4590592563152313} | train loss {'Reaction outcome loss': 0.29669155082563414, 'Total loss': 0.29669155082563414}
2023-01-04 03:53:08,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:08,939 INFO:     Epoch: 26
2023-01-04 03:53:10,559 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4519750436147054, 'Total loss': 0.4519750436147054} | train loss {'Reaction outcome loss': 0.2920889899433747, 'Total loss': 0.2920889899433747}
2023-01-04 03:53:10,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:10,559 INFO:     Epoch: 27
2023-01-04 03:53:12,125 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43209784825642905, 'Total loss': 0.43209784825642905} | train loss {'Reaction outcome loss': 0.2874588535921852, 'Total loss': 0.2874588535921852}
2023-01-04 03:53:12,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:12,125 INFO:     Epoch: 28
2023-01-04 03:53:13,717 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.442586021622022, 'Total loss': 0.442586021622022} | train loss {'Reaction outcome loss': 0.2823615473334807, 'Total loss': 0.2823615473334807}
2023-01-04 03:53:13,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:13,718 INFO:     Epoch: 29
2023-01-04 03:53:15,294 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4459653377532959, 'Total loss': 0.4459653377532959} | train loss {'Reaction outcome loss': 0.2825743251337405, 'Total loss': 0.2825743251337405}
2023-01-04 03:53:15,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:15,294 INFO:     Epoch: 30
2023-01-04 03:53:16,887 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44579403003056844, 'Total loss': 0.44579403003056844} | train loss {'Reaction outcome loss': 0.2796647008372484, 'Total loss': 0.2796647008372484}
2023-01-04 03:53:16,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:16,887 INFO:     Epoch: 31
2023-01-04 03:53:18,481 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43626959522565206, 'Total loss': 0.43626959522565206} | train loss {'Reaction outcome loss': 0.2768902698953221, 'Total loss': 0.2768902698953221}
2023-01-04 03:53:18,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:18,481 INFO:     Epoch: 32
2023-01-04 03:53:20,067 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4563903858264287, 'Total loss': 0.4563903858264287} | train loss {'Reaction outcome loss': 0.2726829691117045, 'Total loss': 0.2726829691117045}
2023-01-04 03:53:20,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:20,068 INFO:     Epoch: 33
2023-01-04 03:53:21,657 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4693622082471848, 'Total loss': 0.4693622082471848} | train loss {'Reaction outcome loss': 0.26814254525586634, 'Total loss': 0.26814254525586634}
2023-01-04 03:53:21,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:21,657 INFO:     Epoch: 34
2023-01-04 03:53:23,277 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4387683262427648, 'Total loss': 0.4387683262427648} | train loss {'Reaction outcome loss': 0.26793787035628824, 'Total loss': 0.26793787035628824}
2023-01-04 03:53:23,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:23,278 INFO:     Epoch: 35
2023-01-04 03:53:24,869 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46034444371859234, 'Total loss': 0.46034444371859234} | train loss {'Reaction outcome loss': 0.2628786915192639, 'Total loss': 0.2628786915192639}
2023-01-04 03:53:24,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:24,870 INFO:     Epoch: 36
2023-01-04 03:53:26,484 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4388698438803355, 'Total loss': 0.4388698438803355} | train loss {'Reaction outcome loss': 0.26335058994863153, 'Total loss': 0.26335058994863153}
2023-01-04 03:53:26,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:26,484 INFO:     Epoch: 37
2023-01-04 03:53:28,098 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47281895677248637, 'Total loss': 0.47281895677248637} | train loss {'Reaction outcome loss': 0.2552819717811407, 'Total loss': 0.2552819717811407}
2023-01-04 03:53:28,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:28,098 INFO:     Epoch: 38
2023-01-04 03:53:29,672 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42753421564896904, 'Total loss': 0.42753421564896904} | train loss {'Reaction outcome loss': 0.2559069052855246, 'Total loss': 0.2559069052855246}
2023-01-04 03:53:29,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:29,673 INFO:     Epoch: 39
2023-01-04 03:53:31,262 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46656039853890735, 'Total loss': 0.46656039853890735} | train loss {'Reaction outcome loss': 0.2528955545140444, 'Total loss': 0.2528955545140444}
2023-01-04 03:53:31,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:31,262 INFO:     Epoch: 40
2023-01-04 03:53:32,856 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45077664256095884, 'Total loss': 0.45077664256095884} | train loss {'Reaction outcome loss': 0.2524728265312249, 'Total loss': 0.2524728265312249}
2023-01-04 03:53:32,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:32,856 INFO:     Epoch: 41
2023-01-04 03:53:34,429 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4398554821809133, 'Total loss': 0.4398554821809133} | train loss {'Reaction outcome loss': 0.24908265485054384, 'Total loss': 0.24908265485054384}
2023-01-04 03:53:34,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:34,429 INFO:     Epoch: 42
2023-01-04 03:53:36,030 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4503097395102183, 'Total loss': 0.4503097395102183} | train loss {'Reaction outcome loss': 0.24877278593769908, 'Total loss': 0.24877278593769908}
2023-01-04 03:53:36,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:36,031 INFO:     Epoch: 43
2023-01-04 03:53:37,623 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44186928793787955, 'Total loss': 0.44186928793787955} | train loss {'Reaction outcome loss': 0.24302617706575969, 'Total loss': 0.24302617706575969}
2023-01-04 03:53:37,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:37,623 INFO:     Epoch: 44
2023-01-04 03:53:39,187 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45327001611391704, 'Total loss': 0.45327001611391704} | train loss {'Reaction outcome loss': 0.24230149851935187, 'Total loss': 0.24230149851935187}
2023-01-04 03:53:39,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:39,187 INFO:     Epoch: 45
2023-01-04 03:53:40,795 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44414096176624296, 'Total loss': 0.44414096176624296} | train loss {'Reaction outcome loss': 0.24137647469004575, 'Total loss': 0.24137647469004575}
2023-01-04 03:53:40,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:40,796 INFO:     Epoch: 46
2023-01-04 03:53:42,376 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4770515998204549, 'Total loss': 0.4770515998204549} | train loss {'Reaction outcome loss': 0.23956872070085827, 'Total loss': 0.23956872070085827}
2023-01-04 03:53:42,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:42,376 INFO:     Epoch: 47
2023-01-04 03:53:43,988 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4694356769323349, 'Total loss': 0.4694356769323349} | train loss {'Reaction outcome loss': 0.23445294657382218, 'Total loss': 0.23445294657382218}
2023-01-04 03:53:43,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:43,989 INFO:     Epoch: 48
2023-01-04 03:53:45,598 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46420965492725375, 'Total loss': 0.46420965492725375} | train loss {'Reaction outcome loss': 0.23320873549384794, 'Total loss': 0.23320873549384794}
2023-01-04 03:53:45,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:45,598 INFO:     Epoch: 49
2023-01-04 03:53:47,216 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44648441175619763, 'Total loss': 0.44648441175619763} | train loss {'Reaction outcome loss': 0.2335038396128773, 'Total loss': 0.2335038396128773}
2023-01-04 03:53:47,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:47,216 INFO:     Epoch: 50
2023-01-04 03:53:48,821 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4885077655315399, 'Total loss': 0.4885077655315399} | train loss {'Reaction outcome loss': 0.2279532180052169, 'Total loss': 0.2279532180052169}
2023-01-04 03:53:48,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:48,821 INFO:     Epoch: 51
2023-01-04 03:53:50,459 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4944019913673401, 'Total loss': 0.4944019913673401} | train loss {'Reaction outcome loss': 0.2288309811566868, 'Total loss': 0.2288309811566868}
2023-01-04 03:53:50,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:50,460 INFO:     Epoch: 52
2023-01-04 03:53:52,042 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47778067191441853, 'Total loss': 0.47778067191441853} | train loss {'Reaction outcome loss': 0.22573709440329215, 'Total loss': 0.22573709440329215}
2023-01-04 03:53:52,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:52,042 INFO:     Epoch: 53
2023-01-04 03:53:53,634 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4673515329758326, 'Total loss': 0.4673515329758326} | train loss {'Reaction outcome loss': 0.22444493704930926, 'Total loss': 0.22444493704930926}
2023-01-04 03:53:53,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:53,635 INFO:     Epoch: 54
2023-01-04 03:53:55,228 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4893675496180852, 'Total loss': 0.4893675496180852} | train loss {'Reaction outcome loss': 0.2271041460199295, 'Total loss': 0.2271041460199295}
2023-01-04 03:53:55,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:55,228 INFO:     Epoch: 55
2023-01-04 03:53:56,808 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4767641246318817, 'Total loss': 0.4767641246318817} | train loss {'Reaction outcome loss': 0.22055751981254476, 'Total loss': 0.22055751981254476}
2023-01-04 03:53:56,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:56,808 INFO:     Epoch: 56
2023-01-04 03:53:58,413 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48384421368439995, 'Total loss': 0.48384421368439995} | train loss {'Reaction outcome loss': 0.21843990732501023, 'Total loss': 0.21843990732501023}
2023-01-04 03:53:58,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:53:58,413 INFO:     Epoch: 57
2023-01-04 03:54:00,000 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46885454952716826, 'Total loss': 0.46885454952716826} | train loss {'Reaction outcome loss': 0.22003401103463485, 'Total loss': 0.22003401103463485}
2023-01-04 03:54:00,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:00,001 INFO:     Epoch: 58
2023-01-04 03:54:01,581 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4689987321694692, 'Total loss': 0.4689987321694692} | train loss {'Reaction outcome loss': 0.2177697692039239, 'Total loss': 0.2177697692039239}
2023-01-04 03:54:01,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:01,583 INFO:     Epoch: 59
2023-01-04 03:54:03,186 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48352731664975485, 'Total loss': 0.48352731664975485} | train loss {'Reaction outcome loss': 0.21408717642898542, 'Total loss': 0.21408717642898542}
2023-01-04 03:54:03,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:03,187 INFO:     Epoch: 60
2023-01-04 03:54:04,800 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4598067382971446, 'Total loss': 0.4598067382971446} | train loss {'Reaction outcome loss': 0.21420985612556012, 'Total loss': 0.21420985612556012}
2023-01-04 03:54:04,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:04,800 INFO:     Epoch: 61
2023-01-04 03:54:06,378 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.449957341949145, 'Total loss': 0.449957341949145} | train loss {'Reaction outcome loss': 0.2112120235080484, 'Total loss': 0.2112120235080484}
2023-01-04 03:54:06,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:06,378 INFO:     Epoch: 62
2023-01-04 03:54:07,971 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4709056238333384, 'Total loss': 0.4709056238333384} | train loss {'Reaction outcome loss': 0.2104651961937873, 'Total loss': 0.2104651961937873}
2023-01-04 03:54:07,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:07,971 INFO:     Epoch: 63
2023-01-04 03:54:09,548 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46236909180879593, 'Total loss': 0.46236909180879593} | train loss {'Reaction outcome loss': 0.21006452963843833, 'Total loss': 0.21006452963843833}
2023-01-04 03:54:09,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:09,548 INFO:     Epoch: 64
2023-01-04 03:54:11,140 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.500451847910881, 'Total loss': 0.500451847910881} | train loss {'Reaction outcome loss': 0.20886612175046093, 'Total loss': 0.20886612175046093}
2023-01-04 03:54:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:11,140 INFO:     Epoch: 65
2023-01-04 03:54:12,751 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4674492617448171, 'Total loss': 0.4674492617448171} | train loss {'Reaction outcome loss': 0.20712896256986327, 'Total loss': 0.20712896256986327}
2023-01-04 03:54:12,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:12,751 INFO:     Epoch: 66
2023-01-04 03:54:14,344 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47795650859673816, 'Total loss': 0.47795650859673816} | train loss {'Reaction outcome loss': 0.20460600377379978, 'Total loss': 0.20460600377379978}
2023-01-04 03:54:14,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:14,345 INFO:     Epoch: 67
2023-01-04 03:54:15,955 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.468330783645312, 'Total loss': 0.468330783645312} | train loss {'Reaction outcome loss': 0.20549277435090854, 'Total loss': 0.20549277435090854}
2023-01-04 03:54:15,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:15,955 INFO:     Epoch: 68
2023-01-04 03:54:17,555 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5033704777558644, 'Total loss': 0.5033704777558644} | train loss {'Reaction outcome loss': 0.20469233951782875, 'Total loss': 0.20469233951782875}
2023-01-04 03:54:17,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:17,555 INFO:     Epoch: 69
2023-01-04 03:54:19,137 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48092041015625, 'Total loss': 0.48092041015625} | train loss {'Reaction outcome loss': 0.20275664768677992, 'Total loss': 0.20275664768677992}
2023-01-04 03:54:19,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:19,138 INFO:     Epoch: 70
2023-01-04 03:54:20,737 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46030168135960897, 'Total loss': 0.46030168135960897} | train loss {'Reaction outcome loss': 0.2020400376840882, 'Total loss': 0.2020400376840882}
2023-01-04 03:54:20,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:20,738 INFO:     Epoch: 71
2023-01-04 03:54:22,343 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49111263553301493, 'Total loss': 0.49111263553301493} | train loss {'Reaction outcome loss': 0.20050298332841726, 'Total loss': 0.20050298332841726}
2023-01-04 03:54:22,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:22,343 INFO:     Epoch: 72
2023-01-04 03:54:23,936 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4624156395594279, 'Total loss': 0.4624156395594279} | train loss {'Reaction outcome loss': 0.1984872294617069, 'Total loss': 0.1984872294617069}
2023-01-04 03:54:23,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:23,936 INFO:     Epoch: 73
2023-01-04 03:54:25,549 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4993571400642395, 'Total loss': 0.4993571400642395} | train loss {'Reaction outcome loss': 0.19807459997271534, 'Total loss': 0.19807459997271534}
2023-01-04 03:54:25,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:25,549 INFO:     Epoch: 74
2023-01-04 03:54:27,167 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.480197208126386, 'Total loss': 0.480197208126386} | train loss {'Reaction outcome loss': 0.1973277406943758, 'Total loss': 0.1973277406943758}
2023-01-04 03:54:27,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:27,167 INFO:     Epoch: 75
2023-01-04 03:54:28,751 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49307953715324404, 'Total loss': 0.49307953715324404} | train loss {'Reaction outcome loss': 0.19586590417137328, 'Total loss': 0.19586590417137328}
2023-01-04 03:54:28,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:28,751 INFO:     Epoch: 76
2023-01-04 03:54:30,345 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49097996453444165, 'Total loss': 0.49097996453444165} | train loss {'Reaction outcome loss': 0.19758379905328263, 'Total loss': 0.19758379905328263}
2023-01-04 03:54:30,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:30,345 INFO:     Epoch: 77
2023-01-04 03:54:31,936 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48967239360014597, 'Total loss': 0.48967239360014597} | train loss {'Reaction outcome loss': 0.19498381442152454, 'Total loss': 0.19498381442152454}
2023-01-04 03:54:31,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:31,937 INFO:     Epoch: 78
2023-01-04 03:54:33,523 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.502823535601298, 'Total loss': 0.502823535601298} | train loss {'Reaction outcome loss': 0.19331922539829338, 'Total loss': 0.19331922539829338}
2023-01-04 03:54:33,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:33,524 INFO:     Epoch: 79
2023-01-04 03:54:35,140 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4825120598077774, 'Total loss': 0.4825120598077774} | train loss {'Reaction outcome loss': 0.19432190728176685, 'Total loss': 0.19432190728176685}
2023-01-04 03:54:35,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:35,140 INFO:     Epoch: 80
2023-01-04 03:54:36,731 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5113802949587504, 'Total loss': 0.5113802949587504} | train loss {'Reaction outcome loss': 0.19337878429269703, 'Total loss': 0.19337878429269703}
2023-01-04 03:54:36,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:36,732 INFO:     Epoch: 81
2023-01-04 03:54:38,324 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5094724277655284, 'Total loss': 0.5094724277655284} | train loss {'Reaction outcome loss': 0.192395840846274, 'Total loss': 0.192395840846274}
2023-01-04 03:54:38,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:38,324 INFO:     Epoch: 82
2023-01-04 03:54:39,914 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4861219644546509, 'Total loss': 0.4861219644546509} | train loss {'Reaction outcome loss': 0.19221430432296147, 'Total loss': 0.19221430432296147}
2023-01-04 03:54:39,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:39,914 INFO:     Epoch: 83
2023-01-04 03:54:41,499 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5253729184468587, 'Total loss': 0.5253729184468587} | train loss {'Reaction outcome loss': 0.18928828225029212, 'Total loss': 0.18928828225029212}
2023-01-04 03:54:41,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:41,499 INFO:     Epoch: 84
2023-01-04 03:54:43,111 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48279284636179604, 'Total loss': 0.48279284636179604} | train loss {'Reaction outcome loss': 0.18957520262032312, 'Total loss': 0.18957520262032312}
2023-01-04 03:54:43,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:43,112 INFO:     Epoch: 85
2023-01-04 03:54:44,721 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4903082331021627, 'Total loss': 0.4903082331021627} | train loss {'Reaction outcome loss': 0.18663741408228657, 'Total loss': 0.18663741408228657}
2023-01-04 03:54:44,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:44,721 INFO:     Epoch: 86
2023-01-04 03:54:46,308 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4880660831928253, 'Total loss': 0.4880660831928253} | train loss {'Reaction outcome loss': 0.18689669277790907, 'Total loss': 0.18689669277790907}
2023-01-04 03:54:46,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:46,308 INFO:     Epoch: 87
2023-01-04 03:54:47,911 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49435050288836163, 'Total loss': 0.49435050288836163} | train loss {'Reaction outcome loss': 0.1878097286910145, 'Total loss': 0.1878097286910145}
2023-01-04 03:54:47,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:47,912 INFO:     Epoch: 88
2023-01-04 03:54:49,532 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5045384585857391, 'Total loss': 0.5045384585857391} | train loss {'Reaction outcome loss': 0.18538366686416805, 'Total loss': 0.18538366686416805}
2023-01-04 03:54:49,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:49,533 INFO:     Epoch: 89
2023-01-04 03:54:51,117 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.506255571047465, 'Total loss': 0.506255571047465} | train loss {'Reaction outcome loss': 0.18566121170501204, 'Total loss': 0.18566121170501204}
2023-01-04 03:54:51,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:51,118 INFO:     Epoch: 90
2023-01-04 03:54:52,709 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.506997408469518, 'Total loss': 0.506997408469518} | train loss {'Reaction outcome loss': 0.18597702485896703, 'Total loss': 0.18597702485896703}
2023-01-04 03:54:52,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:52,710 INFO:     Epoch: 91
2023-01-04 03:54:54,284 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5181802213191986, 'Total loss': 0.5181802213191986} | train loss {'Reaction outcome loss': 0.18375622402251202, 'Total loss': 0.18375622402251202}
2023-01-04 03:54:54,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:54,284 INFO:     Epoch: 92
2023-01-04 03:54:55,868 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48992594877878826, 'Total loss': 0.48992594877878826} | train loss {'Reaction outcome loss': 0.18312108401127541, 'Total loss': 0.18312108401127541}
2023-01-04 03:54:55,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:55,869 INFO:     Epoch: 93
2023-01-04 03:54:57,460 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.473428471883138, 'Total loss': 0.473428471883138} | train loss {'Reaction outcome loss': 0.18196381990165605, 'Total loss': 0.18196381990165605}
2023-01-04 03:54:57,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:57,460 INFO:     Epoch: 94
2023-01-04 03:54:59,053 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5129363616307576, 'Total loss': 0.5129363616307576} | train loss {'Reaction outcome loss': 0.1824100680010271, 'Total loss': 0.1824100680010271}
2023-01-04 03:54:59,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:54:59,053 INFO:     Epoch: 95
2023-01-04 03:55:00,234 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4897801667451859, 'Total loss': 0.4897801667451859} | train loss {'Reaction outcome loss': 0.1800667594873557, 'Total loss': 0.1800667594873557}
2023-01-04 03:55:00,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:00,234 INFO:     Epoch: 96
2023-01-04 03:55:01,300 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48110392888387044, 'Total loss': 0.48110392888387044} | train loss {'Reaction outcome loss': 0.18082803959557175, 'Total loss': 0.18082803959557175}
2023-01-04 03:55:01,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:01,300 INFO:     Epoch: 97
2023-01-04 03:55:02,374 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5039388249317805, 'Total loss': 0.5039388249317805} | train loss {'Reaction outcome loss': 0.1789430734857808, 'Total loss': 0.1789430734857808}
2023-01-04 03:55:02,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:02,374 INFO:     Epoch: 98
2023-01-04 03:55:03,434 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49925629496574403, 'Total loss': 0.49925629496574403} | train loss {'Reaction outcome loss': 0.1794001224185646, 'Total loss': 0.1794001224185646}
2023-01-04 03:55:03,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:03,434 INFO:     Epoch: 99
2023-01-04 03:55:04,988 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.501532357931137, 'Total loss': 0.501532357931137} | train loss {'Reaction outcome loss': 0.17679326274996474, 'Total loss': 0.17679326274996474}
2023-01-04 03:55:04,988 INFO:     Best model found after epoch 25 of 100.
2023-01-04 03:55:04,988 INFO:   Done with stage: TRAINING
2023-01-04 03:55:04,988 INFO:   Starting stage: EVALUATION
2023-01-04 03:55:05,123 INFO:   Done with stage: EVALUATION
2023-01-04 03:55:05,123 INFO:   Leaving out SEQ value Fold_2
2023-01-04 03:55:05,136 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 03:55:05,136 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:55:05,784 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:55:05,784 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:55:05,850 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:55:05,850 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:55:05,850 INFO:     No hyperparam tuning for this model
2023-01-04 03:55:05,850 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:55:05,850 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:55:05,851 INFO:     None feature selector for col prot
2023-01-04 03:55:05,851 INFO:     None feature selector for col prot
2023-01-04 03:55:05,851 INFO:     None feature selector for col prot
2023-01-04 03:55:05,852 INFO:     None feature selector for col chem
2023-01-04 03:55:05,852 INFO:     None feature selector for col chem
2023-01-04 03:55:05,852 INFO:     None feature selector for col chem
2023-01-04 03:55:05,852 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:55:05,852 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:55:05,853 INFO:     Number of params in model 70141
2023-01-04 03:55:05,856 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:55:05,856 INFO:   Starting stage: TRAINING
2023-01-04 03:55:05,899 INFO:     Val loss before train {'Reaction outcome loss': 0.8377179423967998, 'Total loss': 0.8377179423967998}
2023-01-04 03:55:05,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:05,900 INFO:     Epoch: 0
2023-01-04 03:55:07,521 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5700867344935735, 'Total loss': 0.5700867344935735} | train loss {'Reaction outcome loss': 0.880182649735566, 'Total loss': 0.880182649735566}
2023-01-04 03:55:07,523 INFO:     Found new best model at epoch 0
2023-01-04 03:55:07,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:07,523 INFO:     Epoch: 1
2023-01-04 03:55:09,148 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5161489526430766, 'Total loss': 0.5161489526430766} | train loss {'Reaction outcome loss': 0.6319805545793785, 'Total loss': 0.6319805545793785}
2023-01-04 03:55:09,148 INFO:     Found new best model at epoch 1
2023-01-04 03:55:09,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:09,149 INFO:     Epoch: 2
2023-01-04 03:55:10,708 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5142227868239085, 'Total loss': 0.5142227868239085} | train loss {'Reaction outcome loss': 0.548497640606248, 'Total loss': 0.548497640606248}
2023-01-04 03:55:10,709 INFO:     Found new best model at epoch 2
2023-01-04 03:55:10,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:10,709 INFO:     Epoch: 3
2023-01-04 03:55:12,272 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4707459628582001, 'Total loss': 0.4707459628582001} | train loss {'Reaction outcome loss': 0.5088146576732943, 'Total loss': 0.5088146576732943}
2023-01-04 03:55:12,272 INFO:     Found new best model at epoch 3
2023-01-04 03:55:12,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:12,273 INFO:     Epoch: 4
2023-01-04 03:55:13,869 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4840059916178385, 'Total loss': 0.4840059916178385} | train loss {'Reaction outcome loss': 0.47769683834178983, 'Total loss': 0.47769683834178983}
2023-01-04 03:55:13,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:13,870 INFO:     Epoch: 5
2023-01-04 03:55:15,443 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.462144660949707, 'Total loss': 0.462144660949707} | train loss {'Reaction outcome loss': 0.4601923285986914, 'Total loss': 0.4601923285986914}
2023-01-04 03:55:15,443 INFO:     Found new best model at epoch 5
2023-01-04 03:55:15,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:15,444 INFO:     Epoch: 6
2023-01-04 03:55:17,015 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46937013665835065, 'Total loss': 0.46937013665835065} | train loss {'Reaction outcome loss': 0.437975912522047, 'Total loss': 0.437975912522047}
2023-01-04 03:55:17,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:17,015 INFO:     Epoch: 7
2023-01-04 03:55:18,633 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4601355900367101, 'Total loss': 0.4601355900367101} | train loss {'Reaction outcome loss': 0.42386298176351483, 'Total loss': 0.42386298176351483}
2023-01-04 03:55:18,633 INFO:     Found new best model at epoch 7
2023-01-04 03:55:18,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:18,634 INFO:     Epoch: 8
2023-01-04 03:55:20,221 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4513453314701716, 'Total loss': 0.4513453314701716} | train loss {'Reaction outcome loss': 0.41010933381679293, 'Total loss': 0.41010933381679293}
2023-01-04 03:55:20,222 INFO:     Found new best model at epoch 8
2023-01-04 03:55:20,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:20,222 INFO:     Epoch: 9
2023-01-04 03:55:21,800 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4523944199085236, 'Total loss': 0.4523944199085236} | train loss {'Reaction outcome loss': 0.4027498558491141, 'Total loss': 0.4027498558491141}
2023-01-04 03:55:21,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:21,800 INFO:     Epoch: 10
2023-01-04 03:55:23,400 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46127829353014627, 'Total loss': 0.46127829353014627} | train loss {'Reaction outcome loss': 0.3914381726866677, 'Total loss': 0.3914381726866677}
2023-01-04 03:55:23,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:23,400 INFO:     Epoch: 11
2023-01-04 03:55:25,007 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45318618019421897, 'Total loss': 0.45318618019421897} | train loss {'Reaction outcome loss': 0.38196390517902024, 'Total loss': 0.38196390517902024}
2023-01-04 03:55:25,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:25,007 INFO:     Epoch: 12
2023-01-04 03:55:26,611 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43809982637564343, 'Total loss': 0.43809982637564343} | train loss {'Reaction outcome loss': 0.37526865480911165, 'Total loss': 0.37526865480911165}
2023-01-04 03:55:26,611 INFO:     Found new best model at epoch 12
2023-01-04 03:55:26,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:26,612 INFO:     Epoch: 13
2023-01-04 03:55:28,184 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44514068265755974, 'Total loss': 0.44514068265755974} | train loss {'Reaction outcome loss': 0.36762147489594016, 'Total loss': 0.36762147489594016}
2023-01-04 03:55:28,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:28,184 INFO:     Epoch: 14
2023-01-04 03:55:29,768 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4316796710093816, 'Total loss': 0.4316796710093816} | train loss {'Reaction outcome loss': 0.3623131280253222, 'Total loss': 0.3623131280253222}
2023-01-04 03:55:29,768 INFO:     Found new best model at epoch 14
2023-01-04 03:55:29,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:29,769 INFO:     Epoch: 15
2023-01-04 03:55:31,348 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45307946602503457, 'Total loss': 0.45307946602503457} | train loss {'Reaction outcome loss': 0.3562646565529016, 'Total loss': 0.3562646565529016}
2023-01-04 03:55:31,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:31,348 INFO:     Epoch: 16
2023-01-04 03:55:32,917 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44806147813797, 'Total loss': 0.44806147813797} | train loss {'Reaction outcome loss': 0.3486947700545028, 'Total loss': 0.3486947700545028}
2023-01-04 03:55:32,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:32,917 INFO:     Epoch: 17
2023-01-04 03:55:34,523 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4583740492661794, 'Total loss': 0.4583740492661794} | train loss {'Reaction outcome loss': 0.33961241498534933, 'Total loss': 0.33961241498534933}
2023-01-04 03:55:34,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:34,523 INFO:     Epoch: 18
2023-01-04 03:55:36,129 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4454259713490804, 'Total loss': 0.4454259713490804} | train loss {'Reaction outcome loss': 0.33801851530760635, 'Total loss': 0.33801851530760635}
2023-01-04 03:55:36,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:36,129 INFO:     Epoch: 19
2023-01-04 03:55:37,707 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4401791433493296, 'Total loss': 0.4401791433493296} | train loss {'Reaction outcome loss': 0.3303974970438323, 'Total loss': 0.3303974970438323}
2023-01-04 03:55:37,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:37,707 INFO:     Epoch: 20
2023-01-04 03:55:39,282 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4587589919567108, 'Total loss': 0.4587589919567108} | train loss {'Reaction outcome loss': 0.3276872830294864, 'Total loss': 0.3276872830294864}
2023-01-04 03:55:39,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:39,283 INFO:     Epoch: 21
2023-01-04 03:55:40,853 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4628803670406342, 'Total loss': 0.4628803670406342} | train loss {'Reaction outcome loss': 0.3205384402484684, 'Total loss': 0.3205384402484684}
2023-01-04 03:55:40,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:40,853 INFO:     Epoch: 22
2023-01-04 03:55:42,437 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4505575120449066, 'Total loss': 0.4505575120449066} | train loss {'Reaction outcome loss': 0.31836541379109407, 'Total loss': 0.31836541379109407}
2023-01-04 03:55:42,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:42,438 INFO:     Epoch: 23
2023-01-04 03:55:44,022 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4761250714461009, 'Total loss': 0.4761250714461009} | train loss {'Reaction outcome loss': 0.3121525438932272, 'Total loss': 0.3121525438932272}
2023-01-04 03:55:44,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:44,022 INFO:     Epoch: 24
2023-01-04 03:55:45,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4336881707111994, 'Total loss': 0.4336881707111994} | train loss {'Reaction outcome loss': 0.31037002408897485, 'Total loss': 0.31037002408897485}
2023-01-04 03:55:45,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:45,607 INFO:     Epoch: 25
2023-01-04 03:55:47,195 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44654875894387563, 'Total loss': 0.44654875894387563} | train loss {'Reaction outcome loss': 0.30660366509860254, 'Total loss': 0.30660366509860254}
2023-01-04 03:55:47,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:47,195 INFO:     Epoch: 26
2023-01-04 03:55:48,773 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43229322334130604, 'Total loss': 0.43229322334130604} | train loss {'Reaction outcome loss': 0.30185326647299987, 'Total loss': 0.30185326647299987}
2023-01-04 03:55:48,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:48,774 INFO:     Epoch: 27
2023-01-04 03:55:50,354 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4414659425616264, 'Total loss': 0.4414659425616264} | train loss {'Reaction outcome loss': 0.2957332004612182, 'Total loss': 0.2957332004612182}
2023-01-04 03:55:50,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:50,354 INFO:     Epoch: 28
2023-01-04 03:55:51,932 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4507724533478419, 'Total loss': 0.4507724533478419} | train loss {'Reaction outcome loss': 0.2931564143507472, 'Total loss': 0.2931564143507472}
2023-01-04 03:55:51,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:51,933 INFO:     Epoch: 29
2023-01-04 03:55:53,498 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4371219307184219, 'Total loss': 0.4371219307184219} | train loss {'Reaction outcome loss': 0.2881807865568133, 'Total loss': 0.2881807865568133}
2023-01-04 03:55:53,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:53,498 INFO:     Epoch: 30
2023-01-04 03:55:55,080 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4345383445421855, 'Total loss': 0.4345383445421855} | train loss {'Reaction outcome loss': 0.287976244444048, 'Total loss': 0.287976244444048}
2023-01-04 03:55:55,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:55,080 INFO:     Epoch: 31
2023-01-04 03:55:56,656 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.445185919602712, 'Total loss': 0.445185919602712} | train loss {'Reaction outcome loss': 0.2821911917282985, 'Total loss': 0.2821911917282985}
2023-01-04 03:55:56,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:56,656 INFO:     Epoch: 32
2023-01-04 03:55:58,217 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45007338325182594, 'Total loss': 0.45007338325182594} | train loss {'Reaction outcome loss': 0.27891436846919987, 'Total loss': 0.27891436846919987}
2023-01-04 03:55:58,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:58,217 INFO:     Epoch: 33
2023-01-04 03:55:59,791 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4734439621369044, 'Total loss': 0.4734439621369044} | train loss {'Reaction outcome loss': 0.2777680001688964, 'Total loss': 0.2777680001688964}
2023-01-04 03:55:59,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:55:59,791 INFO:     Epoch: 34
2023-01-04 03:56:01,366 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4457508916656176, 'Total loss': 0.4457508916656176} | train loss {'Reaction outcome loss': 0.2742679753364661, 'Total loss': 0.2742679753364661}
2023-01-04 03:56:01,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:01,367 INFO:     Epoch: 35
2023-01-04 03:56:02,939 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45504100918769835, 'Total loss': 0.45504100918769835} | train loss {'Reaction outcome loss': 0.2699762791831851, 'Total loss': 0.2699762791831851}
2023-01-04 03:56:02,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:02,939 INFO:     Epoch: 36
2023-01-04 03:56:04,501 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4537049065033595, 'Total loss': 0.4537049065033595} | train loss {'Reaction outcome loss': 0.2671891078625843, 'Total loss': 0.2671891078625843}
2023-01-04 03:56:04,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:04,502 INFO:     Epoch: 37
2023-01-04 03:56:06,073 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4556181520223618, 'Total loss': 0.4556181520223618} | train loss {'Reaction outcome loss': 0.26528079658337345, 'Total loss': 0.26528079658337345}
2023-01-04 03:56:06,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:06,073 INFO:     Epoch: 38
2023-01-04 03:56:07,679 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4641009380420049, 'Total loss': 0.4641009380420049} | train loss {'Reaction outcome loss': 0.26502488051360346, 'Total loss': 0.26502488051360346}
2023-01-04 03:56:07,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:07,679 INFO:     Epoch: 39
2023-01-04 03:56:09,304 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4196685204903285, 'Total loss': 0.4196685204903285} | train loss {'Reaction outcome loss': 0.261280351014801, 'Total loss': 0.261280351014801}
2023-01-04 03:56:09,304 INFO:     Found new best model at epoch 39
2023-01-04 03:56:09,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:09,305 INFO:     Epoch: 40
2023-01-04 03:56:10,885 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44023259182771046, 'Total loss': 0.44023259182771046} | train loss {'Reaction outcome loss': 0.25757278519726934, 'Total loss': 0.25757278519726934}
2023-01-04 03:56:10,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:10,885 INFO:     Epoch: 41
2023-01-04 03:56:12,503 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4374883641799291, 'Total loss': 0.4374883641799291} | train loss {'Reaction outcome loss': 0.25310618330762064, 'Total loss': 0.25310618330762064}
2023-01-04 03:56:12,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:12,503 INFO:     Epoch: 42
2023-01-04 03:56:14,088 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44492242534955345, 'Total loss': 0.44492242534955345} | train loss {'Reaction outcome loss': 0.2538298597839071, 'Total loss': 0.2538298597839071}
2023-01-04 03:56:14,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:14,088 INFO:     Epoch: 43
2023-01-04 03:56:15,673 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4529832045237223, 'Total loss': 0.4529832045237223} | train loss {'Reaction outcome loss': 0.24760806904389307, 'Total loss': 0.24760806904389307}
2023-01-04 03:56:15,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:15,674 INFO:     Epoch: 44
2023-01-04 03:56:17,288 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43788859446843464, 'Total loss': 0.43788859446843464} | train loss {'Reaction outcome loss': 0.2463766202610327, 'Total loss': 0.2463766202610327}
2023-01-04 03:56:17,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:17,289 INFO:     Epoch: 45
2023-01-04 03:56:18,849 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42364596426486967, 'Total loss': 0.42364596426486967} | train loss {'Reaction outcome loss': 0.2483596290042112, 'Total loss': 0.2483596290042112}
2023-01-04 03:56:18,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:18,850 INFO:     Epoch: 46
2023-01-04 03:56:20,414 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45401792228221893, 'Total loss': 0.45401792228221893} | train loss {'Reaction outcome loss': 0.24317781365179753, 'Total loss': 0.24317781365179753}
2023-01-04 03:56:20,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:20,414 INFO:     Epoch: 47
2023-01-04 03:56:21,997 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4412655035654704, 'Total loss': 0.4412655035654704} | train loss {'Reaction outcome loss': 0.24212918793543792, 'Total loss': 0.24212918793543792}
2023-01-04 03:56:21,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:21,998 INFO:     Epoch: 48
2023-01-04 03:56:23,575 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43531028032302854, 'Total loss': 0.43531028032302854} | train loss {'Reaction outcome loss': 0.2389546848335491, 'Total loss': 0.2389546848335491}
2023-01-04 03:56:23,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:23,576 INFO:     Epoch: 49
2023-01-04 03:56:25,155 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4308111021916072, 'Total loss': 0.4308111021916072} | train loss {'Reaction outcome loss': 0.2393168241549761, 'Total loss': 0.2393168241549761}
2023-01-04 03:56:25,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:25,156 INFO:     Epoch: 50
2023-01-04 03:56:26,769 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4524836818377177, 'Total loss': 0.4524836818377177} | train loss {'Reaction outcome loss': 0.2362688526702233, 'Total loss': 0.2362688526702233}
2023-01-04 03:56:26,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:26,770 INFO:     Epoch: 51
2023-01-04 03:56:28,339 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43004881143569945, 'Total loss': 0.43004881143569945} | train loss {'Reaction outcome loss': 0.23606089151877185, 'Total loss': 0.23606089151877185}
2023-01-04 03:56:28,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:28,340 INFO:     Epoch: 52
2023-01-04 03:56:29,941 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4400455040236314, 'Total loss': 0.4400455040236314} | train loss {'Reaction outcome loss': 0.2326549658681447, 'Total loss': 0.2326549658681447}
2023-01-04 03:56:29,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:29,941 INFO:     Epoch: 53
2023-01-04 03:56:31,518 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4542448461055756, 'Total loss': 0.4542448461055756} | train loss {'Reaction outcome loss': 0.2342154001168934, 'Total loss': 0.2342154001168934}
2023-01-04 03:56:31,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:31,518 INFO:     Epoch: 54
2023-01-04 03:56:33,091 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44895630876223247, 'Total loss': 0.44895630876223247} | train loss {'Reaction outcome loss': 0.23108926823451406, 'Total loss': 0.23108926823451406}
2023-01-04 03:56:33,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:33,092 INFO:     Epoch: 55
2023-01-04 03:56:34,654 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4366028293967247, 'Total loss': 0.4366028293967247} | train loss {'Reaction outcome loss': 0.2303008707615482, 'Total loss': 0.2303008707615482}
2023-01-04 03:56:34,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:34,654 INFO:     Epoch: 56
2023-01-04 03:56:36,235 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44568244367837906, 'Total loss': 0.44568244367837906} | train loss {'Reaction outcome loss': 0.2269694499889791, 'Total loss': 0.2269694499889791}
2023-01-04 03:56:36,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:36,235 INFO:     Epoch: 57
2023-01-04 03:56:37,817 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4329798777898153, 'Total loss': 0.4329798777898153} | train loss {'Reaction outcome loss': 0.2271970520444187, 'Total loss': 0.2271970520444187}
2023-01-04 03:56:37,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:37,818 INFO:     Epoch: 58
2023-01-04 03:56:39,395 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47840206027030946, 'Total loss': 0.47840206027030946} | train loss {'Reaction outcome loss': 0.22382973996929198, 'Total loss': 0.22382973996929198}
2023-01-04 03:56:39,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:39,395 INFO:     Epoch: 59
2023-01-04 03:56:40,962 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4971239020427068, 'Total loss': 0.4971239020427068} | train loss {'Reaction outcome loss': 0.22269997816710246, 'Total loss': 0.22269997816710246}
2023-01-04 03:56:40,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:40,962 INFO:     Epoch: 60
2023-01-04 03:56:42,555 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45749476651350657, 'Total loss': 0.45749476651350657} | train loss {'Reaction outcome loss': 0.21966253658722498, 'Total loss': 0.21966253658722498}
2023-01-04 03:56:42,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:42,555 INFO:     Epoch: 61
2023-01-04 03:56:44,162 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44249752163887024, 'Total loss': 0.44249752163887024} | train loss {'Reaction outcome loss': 0.21729912589075584, 'Total loss': 0.21729912589075584}
2023-01-04 03:56:44,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:44,163 INFO:     Epoch: 62
2023-01-04 03:56:45,756 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4283991679549217, 'Total loss': 0.4283991679549217} | train loss {'Reaction outcome loss': 0.21878076984031952, 'Total loss': 0.21878076984031952}
2023-01-04 03:56:45,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:45,757 INFO:     Epoch: 63
2023-01-04 03:56:47,365 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48884373108545937, 'Total loss': 0.48884373108545937} | train loss {'Reaction outcome loss': 0.2158266145585876, 'Total loss': 0.2158266145585876}
2023-01-04 03:56:47,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:47,365 INFO:     Epoch: 64
2023-01-04 03:56:48,949 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44283881584803264, 'Total loss': 0.44283881584803264} | train loss {'Reaction outcome loss': 0.21389894412605318, 'Total loss': 0.21389894412605318}
2023-01-04 03:56:48,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:48,949 INFO:     Epoch: 65
2023-01-04 03:56:50,551 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4437391365567843, 'Total loss': 0.4437391365567843} | train loss {'Reaction outcome loss': 0.21037694694467515, 'Total loss': 0.21037694694467515}
2023-01-04 03:56:50,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:50,552 INFO:     Epoch: 66
2023-01-04 03:56:52,137 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4659302582343419, 'Total loss': 0.4659302582343419} | train loss {'Reaction outcome loss': 0.209018079857359, 'Total loss': 0.209018079857359}
2023-01-04 03:56:52,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:52,137 INFO:     Epoch: 67
2023-01-04 03:56:53,745 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4671601901451747, 'Total loss': 0.4671601901451747} | train loss {'Reaction outcome loss': 0.21319110860072432, 'Total loss': 0.21319110860072432}
2023-01-04 03:56:53,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:53,745 INFO:     Epoch: 68
2023-01-04 03:56:55,354 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5037991414467494, 'Total loss': 0.5037991414467494} | train loss {'Reaction outcome loss': 0.2105940427399162, 'Total loss': 0.2105940427399162}
2023-01-04 03:56:55,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:55,354 INFO:     Epoch: 69
2023-01-04 03:56:56,962 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46192958056926725, 'Total loss': 0.46192958056926725} | train loss {'Reaction outcome loss': 0.2109277965876209, 'Total loss': 0.2109277965876209}
2023-01-04 03:56:56,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:56,963 INFO:     Epoch: 70
2023-01-04 03:56:58,544 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45438842872778573, 'Total loss': 0.45438842872778573} | train loss {'Reaction outcome loss': 0.2076012563683611, 'Total loss': 0.2076012563683611}
2023-01-04 03:56:58,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:56:58,544 INFO:     Epoch: 71
2023-01-04 03:57:00,160 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4637092148264249, 'Total loss': 0.4637092148264249} | train loss {'Reaction outcome loss': 0.20363750251439902, 'Total loss': 0.20363750251439902}
2023-01-04 03:57:00,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:00,160 INFO:     Epoch: 72
2023-01-04 03:57:01,722 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4887645880381266, 'Total loss': 0.4887645880381266} | train loss {'Reaction outcome loss': 0.20405699709778305, 'Total loss': 0.20405699709778305}
2023-01-04 03:57:01,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:01,722 INFO:     Epoch: 73
2023-01-04 03:57:03,306 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4597776105006536, 'Total loss': 0.4597776105006536} | train loss {'Reaction outcome loss': 0.20315820520450345, 'Total loss': 0.20315820520450345}
2023-01-04 03:57:03,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:03,307 INFO:     Epoch: 74
2023-01-04 03:57:04,890 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.493350425362587, 'Total loss': 0.493350425362587} | train loss {'Reaction outcome loss': 0.20099708143171374, 'Total loss': 0.20099708143171374}
2023-01-04 03:57:04,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:04,890 INFO:     Epoch: 75
2023-01-04 03:57:06,475 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47582794626553854, 'Total loss': 0.47582794626553854} | train loss {'Reaction outcome loss': 0.19941015747604351, 'Total loss': 0.19941015747604351}
2023-01-04 03:57:06,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:06,476 INFO:     Epoch: 76
2023-01-04 03:57:08,042 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46428309082984925, 'Total loss': 0.46428309082984925} | train loss {'Reaction outcome loss': 0.19890963646409276, 'Total loss': 0.19890963646409276}
2023-01-04 03:57:08,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:08,043 INFO:     Epoch: 77
2023-01-04 03:57:09,607 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4701620737711589, 'Total loss': 0.4701620737711589} | train loss {'Reaction outcome loss': 0.1995390476078996, 'Total loss': 0.1995390476078996}
2023-01-04 03:57:09,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:09,608 INFO:     Epoch: 78
2023-01-04 03:57:11,185 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4621601978937785, 'Total loss': 0.4621601978937785} | train loss {'Reaction outcome loss': 0.19566780115876878, 'Total loss': 0.19566780115876878}
2023-01-04 03:57:11,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:11,185 INFO:     Epoch: 79
2023-01-04 03:57:12,759 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48128801782925923, 'Total loss': 0.48128801782925923} | train loss {'Reaction outcome loss': 0.19534822946393882, 'Total loss': 0.19534822946393882}
2023-01-04 03:57:12,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:12,759 INFO:     Epoch: 80
2023-01-04 03:57:14,367 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5012900655468305, 'Total loss': 0.5012900655468305} | train loss {'Reaction outcome loss': 0.1944361700243129, 'Total loss': 0.1944361700243129}
2023-01-04 03:57:14,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:14,367 INFO:     Epoch: 81
2023-01-04 03:57:15,951 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5020522524913152, 'Total loss': 0.5020522524913152} | train loss {'Reaction outcome loss': 0.19331828547102628, 'Total loss': 0.19331828547102628}
2023-01-04 03:57:15,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:15,951 INFO:     Epoch: 82
2023-01-04 03:57:17,537 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4494447032610575, 'Total loss': 0.4494447032610575} | train loss {'Reaction outcome loss': 0.1937521712056228, 'Total loss': 0.1937521712056228}
2023-01-04 03:57:17,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:17,537 INFO:     Epoch: 83
2023-01-04 03:57:19,112 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4658931334813436, 'Total loss': 0.4658931334813436} | train loss {'Reaction outcome loss': 0.19337844682154637, 'Total loss': 0.19337844682154637}
2023-01-04 03:57:19,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:19,112 INFO:     Epoch: 84
2023-01-04 03:57:20,713 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4529920091231664, 'Total loss': 0.4529920091231664} | train loss {'Reaction outcome loss': 0.19229290193635903, 'Total loss': 0.19229290193635903}
2023-01-04 03:57:20,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:20,713 INFO:     Epoch: 85
2023-01-04 03:57:22,340 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45561159749825797, 'Total loss': 0.45561159749825797} | train loss {'Reaction outcome loss': 0.18877228256656137, 'Total loss': 0.18877228256656137}
2023-01-04 03:57:22,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:22,340 INFO:     Epoch: 86
2023-01-04 03:57:23,947 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46085651516914367, 'Total loss': 0.46085651516914367} | train loss {'Reaction outcome loss': 0.18998993470609843, 'Total loss': 0.18998993470609843}
2023-01-04 03:57:23,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:23,947 INFO:     Epoch: 87
2023-01-04 03:57:25,520 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4620185434818268, 'Total loss': 0.4620185434818268} | train loss {'Reaction outcome loss': 0.1859944101982501, 'Total loss': 0.1859944101982501}
2023-01-04 03:57:25,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:25,521 INFO:     Epoch: 88
2023-01-04 03:57:27,104 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4522686431805293, 'Total loss': 0.4522686431805293} | train loss {'Reaction outcome loss': 0.1859231702232863, 'Total loss': 0.1859231702232863}
2023-01-04 03:57:27,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:27,104 INFO:     Epoch: 89
2023-01-04 03:57:28,653 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46041412353515626, 'Total loss': 0.46041412353515626} | train loss {'Reaction outcome loss': 0.18691140810375687, 'Total loss': 0.18691140810375687}
2023-01-04 03:57:28,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:28,653 INFO:     Epoch: 90
2023-01-04 03:57:30,259 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4874400198459625, 'Total loss': 0.4874400198459625} | train loss {'Reaction outcome loss': 0.18487018369984276, 'Total loss': 0.18487018369984276}
2023-01-04 03:57:30,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:30,260 INFO:     Epoch: 91
2023-01-04 03:57:31,831 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4575971345106761, 'Total loss': 0.4575971345106761} | train loss {'Reaction outcome loss': 0.18817689333916146, 'Total loss': 0.18817689333916146}
2023-01-04 03:57:31,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:31,832 INFO:     Epoch: 92
2023-01-04 03:57:33,433 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4716804981231689, 'Total loss': 0.4716804981231689} | train loss {'Reaction outcome loss': 0.18317028111863487, 'Total loss': 0.18317028111863487}
2023-01-04 03:57:33,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:33,433 INFO:     Epoch: 93
2023-01-04 03:57:34,998 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46102274060249326, 'Total loss': 0.46102274060249326} | train loss {'Reaction outcome loss': 0.18233540590729688, 'Total loss': 0.18233540590729688}
2023-01-04 03:57:34,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:34,999 INFO:     Epoch: 94
2023-01-04 03:57:36,564 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46019595563411714, 'Total loss': 0.46019595563411714} | train loss {'Reaction outcome loss': 0.1818551224257265, 'Total loss': 0.1818551224257265}
2023-01-04 03:57:36,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:36,564 INFO:     Epoch: 95
2023-01-04 03:57:38,148 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4680967370669047, 'Total loss': 0.4680967370669047} | train loss {'Reaction outcome loss': 0.17997912511966385, 'Total loss': 0.17997912511966385}
2023-01-04 03:57:38,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:38,148 INFO:     Epoch: 96
2023-01-04 03:57:39,731 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4631645083427429, 'Total loss': 0.4631645083427429} | train loss {'Reaction outcome loss': 0.18120150430462298, 'Total loss': 0.18120150430462298}
2023-01-04 03:57:39,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:39,731 INFO:     Epoch: 97
2023-01-04 03:57:41,314 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4588655690352122, 'Total loss': 0.4588655690352122} | train loss {'Reaction outcome loss': 0.18420507144114692, 'Total loss': 0.18420507144114692}
2023-01-04 03:57:41,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:41,314 INFO:     Epoch: 98
2023-01-04 03:57:42,879 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45229126463333763, 'Total loss': 0.45229126463333763} | train loss {'Reaction outcome loss': 0.17619611915446573, 'Total loss': 0.17619611915446573}
2023-01-04 03:57:42,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:42,879 INFO:     Epoch: 99
2023-01-04 03:57:44,463 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4449267226116111, 'Total loss': 0.4449267226116111} | train loss {'Reaction outcome loss': 0.17878626583096308, 'Total loss': 0.17878626583096308}
2023-01-04 03:57:44,464 INFO:     Best model found after epoch 40 of 100.
2023-01-04 03:57:44,464 INFO:   Done with stage: TRAINING
2023-01-04 03:57:44,464 INFO:   Starting stage: EVALUATION
2023-01-04 03:57:44,605 INFO:   Done with stage: EVALUATION
2023-01-04 03:57:44,605 INFO:   Leaving out SEQ value Fold_3
2023-01-04 03:57:44,617 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 03:57:44,618 INFO:   Starting stage: FEATURE SCALING
2023-01-04 03:57:45,253 INFO:   Done with stage: FEATURE SCALING
2023-01-04 03:57:45,253 INFO:   Starting stage: SCALING TARGETS
2023-01-04 03:57:45,320 INFO:   Done with stage: SCALING TARGETS
2023-01-04 03:57:45,320 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:57:45,320 INFO:     No hyperparam tuning for this model
2023-01-04 03:57:45,320 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 03:57:45,320 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 03:57:45,321 INFO:     None feature selector for col prot
2023-01-04 03:57:45,321 INFO:     None feature selector for col prot
2023-01-04 03:57:45,321 INFO:     None feature selector for col prot
2023-01-04 03:57:45,322 INFO:     None feature selector for col chem
2023-01-04 03:57:45,322 INFO:     None feature selector for col chem
2023-01-04 03:57:45,322 INFO:     None feature selector for col chem
2023-01-04 03:57:45,322 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 03:57:45,322 INFO:   Starting stage: BUILD MODEL
2023-01-04 03:57:45,323 INFO:     Number of params in model 70141
2023-01-04 03:57:45,326 INFO:   Done with stage: BUILD MODEL
2023-01-04 03:57:45,326 INFO:   Starting stage: TRAINING
2023-01-04 03:57:45,371 INFO:     Val loss before train {'Reaction outcome loss': 1.065228005250295, 'Total loss': 1.065228005250295}
2023-01-04 03:57:45,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:45,371 INFO:     Epoch: 0
2023-01-04 03:57:46,960 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7112384041150411, 'Total loss': 0.7112384041150411} | train loss {'Reaction outcome loss': 0.8556709102876894, 'Total loss': 0.8556709102876894}
2023-01-04 03:57:46,960 INFO:     Found new best model at epoch 0
2023-01-04 03:57:46,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:46,961 INFO:     Epoch: 1
2023-01-04 03:57:48,563 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5644146243731181, 'Total loss': 0.5644146243731181} | train loss {'Reaction outcome loss': 0.6242580976023342, 'Total loss': 0.6242580976023342}
2023-01-04 03:57:48,563 INFO:     Found new best model at epoch 1
2023-01-04 03:57:48,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:48,564 INFO:     Epoch: 2
2023-01-04 03:57:50,151 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5172850529352824, 'Total loss': 0.5172850529352824} | train loss {'Reaction outcome loss': 0.5333615714486265, 'Total loss': 0.5333615714486265}
2023-01-04 03:57:50,151 INFO:     Found new best model at epoch 2
2023-01-04 03:57:50,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:50,152 INFO:     Epoch: 3
2023-01-04 03:57:51,740 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49796971877415974, 'Total loss': 0.49796971877415974} | train loss {'Reaction outcome loss': 0.4864216773282914, 'Total loss': 0.4864216773282914}
2023-01-04 03:57:51,741 INFO:     Found new best model at epoch 3
2023-01-04 03:57:51,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:51,741 INFO:     Epoch: 4
2023-01-04 03:57:53,328 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46020523011684417, 'Total loss': 0.46020523011684417} | train loss {'Reaction outcome loss': 0.46054455234017566, 'Total loss': 0.46054455234017566}
2023-01-04 03:57:53,328 INFO:     Found new best model at epoch 4
2023-01-04 03:57:53,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:53,329 INFO:     Epoch: 5
2023-01-04 03:57:54,908 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44998841881752016, 'Total loss': 0.44998841881752016} | train loss {'Reaction outcome loss': 0.4367120399689063, 'Total loss': 0.4367120399689063}
2023-01-04 03:57:54,908 INFO:     Found new best model at epoch 5
2023-01-04 03:57:54,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:54,909 INFO:     Epoch: 6
2023-01-04 03:57:56,512 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44303902983665466, 'Total loss': 0.44303902983665466} | train loss {'Reaction outcome loss': 0.4204721396222656, 'Total loss': 0.4204721396222656}
2023-01-04 03:57:56,513 INFO:     Found new best model at epoch 6
2023-01-04 03:57:56,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:56,514 INFO:     Epoch: 7
2023-01-04 03:57:58,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4459729214509328, 'Total loss': 0.4459729214509328} | train loss {'Reaction outcome loss': 0.405215737201792, 'Total loss': 0.405215737201792}
2023-01-04 03:57:58,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:58,114 INFO:     Epoch: 8
2023-01-04 03:57:59,720 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42504942715168, 'Total loss': 0.42504942715168} | train loss {'Reaction outcome loss': 0.3938742885331968, 'Total loss': 0.3938742885331968}
2023-01-04 03:57:59,721 INFO:     Found new best model at epoch 8
2023-01-04 03:57:59,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:57:59,721 INFO:     Epoch: 9
2023-01-04 03:58:01,299 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4093595614035924, 'Total loss': 0.4093595614035924} | train loss {'Reaction outcome loss': 0.38422642882927, 'Total loss': 0.38422642882927}
2023-01-04 03:58:01,299 INFO:     Found new best model at epoch 9
2023-01-04 03:58:01,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:01,300 INFO:     Epoch: 10
2023-01-04 03:58:02,917 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39945712486902873, 'Total loss': 0.39945712486902873} | train loss {'Reaction outcome loss': 0.3748351875624377, 'Total loss': 0.3748351875624377}
2023-01-04 03:58:02,918 INFO:     Found new best model at epoch 10
2023-01-04 03:58:02,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:02,919 INFO:     Epoch: 11
2023-01-04 03:58:04,513 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4058759172757467, 'Total loss': 0.4058759172757467} | train loss {'Reaction outcome loss': 0.3625320084802397, 'Total loss': 0.3625320084802397}
2023-01-04 03:58:04,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:04,513 INFO:     Epoch: 12
2023-01-04 03:58:06,136 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4101139763991038, 'Total loss': 0.4101139763991038} | train loss {'Reaction outcome loss': 0.35803038553222194, 'Total loss': 0.35803038553222194}
2023-01-04 03:58:06,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:06,136 INFO:     Epoch: 13
2023-01-04 03:58:07,759 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3851650595664978, 'Total loss': 0.3851650595664978} | train loss {'Reaction outcome loss': 0.34821303287050226, 'Total loss': 0.34821303287050226}
2023-01-04 03:58:07,759 INFO:     Found new best model at epoch 13
2023-01-04 03:58:07,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:07,760 INFO:     Epoch: 14
2023-01-04 03:58:09,327 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38535638054211935, 'Total loss': 0.38535638054211935} | train loss {'Reaction outcome loss': 0.34128166082905326, 'Total loss': 0.34128166082905326}
2023-01-04 03:58:09,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:09,327 INFO:     Epoch: 15
2023-01-04 03:58:10,880 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.37834061682224274, 'Total loss': 0.37834061682224274} | train loss {'Reaction outcome loss': 0.33573836399303686, 'Total loss': 0.33573836399303686}
2023-01-04 03:58:10,880 INFO:     Found new best model at epoch 15
2023-01-04 03:58:10,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:10,881 INFO:     Epoch: 16
2023-01-04 03:58:12,448 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39203488230705263, 'Total loss': 0.39203488230705263} | train loss {'Reaction outcome loss': 0.3291139938346632, 'Total loss': 0.3291139938346632}
2023-01-04 03:58:12,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:12,449 INFO:     Epoch: 17
2023-01-04 03:58:14,072 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.400388640165329, 'Total loss': 0.400388640165329} | train loss {'Reaction outcome loss': 0.32325731911065375, 'Total loss': 0.32325731911065375}
2023-01-04 03:58:14,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:14,073 INFO:     Epoch: 18
2023-01-04 03:58:15,692 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39015854597091676, 'Total loss': 0.39015854597091676} | train loss {'Reaction outcome loss': 0.3171556066899073, 'Total loss': 0.3171556066899073}
2023-01-04 03:58:15,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:15,693 INFO:     Epoch: 19
2023-01-04 03:58:17,271 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3868467688560486, 'Total loss': 0.3868467688560486} | train loss {'Reaction outcome loss': 0.31277900099099337, 'Total loss': 0.31277900099099337}
2023-01-04 03:58:17,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:17,271 INFO:     Epoch: 20
2023-01-04 03:58:18,862 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.37824899951616925, 'Total loss': 0.37824899951616925} | train loss {'Reaction outcome loss': 0.3072415930679539, 'Total loss': 0.3072415930679539}
2023-01-04 03:58:18,862 INFO:     Found new best model at epoch 20
2023-01-04 03:58:18,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:18,863 INFO:     Epoch: 21
2023-01-04 03:58:20,448 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3575987696647644, 'Total loss': 0.3575987696647644} | train loss {'Reaction outcome loss': 0.3010454697759597, 'Total loss': 0.3010454697759597}
2023-01-04 03:58:20,448 INFO:     Found new best model at epoch 21
2023-01-04 03:58:20,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:20,449 INFO:     Epoch: 22
2023-01-04 03:58:22,020 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.367548468708992, 'Total loss': 0.367548468708992} | train loss {'Reaction outcome loss': 0.2957085621826378, 'Total loss': 0.2957085621826378}
2023-01-04 03:58:22,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:22,020 INFO:     Epoch: 23
2023-01-04 03:58:23,632 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37015433187286056, 'Total loss': 0.37015433187286056} | train loss {'Reaction outcome loss': 0.29182413627048986, 'Total loss': 0.29182413627048986}
2023-01-04 03:58:23,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:23,633 INFO:     Epoch: 24
2023-01-04 03:58:25,244 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3873698522647222, 'Total loss': 0.3873698522647222} | train loss {'Reaction outcome loss': 0.2891232918252002, 'Total loss': 0.2891232918252002}
2023-01-04 03:58:25,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:25,244 INFO:     Epoch: 25
2023-01-04 03:58:26,854 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3787398060162862, 'Total loss': 0.3787398060162862} | train loss {'Reaction outcome loss': 0.2839748191036584, 'Total loss': 0.2839748191036584}
2023-01-04 03:58:26,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:26,855 INFO:     Epoch: 26
2023-01-04 03:58:28,433 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3844978868961334, 'Total loss': 0.3844978868961334} | train loss {'Reaction outcome loss': 0.28123984726029877, 'Total loss': 0.28123984726029877}
2023-01-04 03:58:28,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:28,433 INFO:     Epoch: 27
2023-01-04 03:58:30,018 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3902168333530426, 'Total loss': 0.3902168333530426} | train loss {'Reaction outcome loss': 0.27525991720621623, 'Total loss': 0.27525991720621623}
2023-01-04 03:58:30,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:30,018 INFO:     Epoch: 28
2023-01-04 03:58:31,599 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38592627545197805, 'Total loss': 0.38592627545197805} | train loss {'Reaction outcome loss': 0.27200832235671224, 'Total loss': 0.27200832235671224}
2023-01-04 03:58:31,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:31,601 INFO:     Epoch: 29
2023-01-04 03:58:33,184 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.369131996234258, 'Total loss': 0.369131996234258} | train loss {'Reaction outcome loss': 0.26865410586416505, 'Total loss': 0.26865410586416505}
2023-01-04 03:58:33,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:33,184 INFO:     Epoch: 30
2023-01-04 03:58:34,789 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3745642522970835, 'Total loss': 0.3745642522970835} | train loss {'Reaction outcome loss': 0.2652715496418677, 'Total loss': 0.2652715496418677}
2023-01-04 03:58:34,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:34,789 INFO:     Epoch: 31
2023-01-04 03:58:36,403 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3970759123563766, 'Total loss': 0.3970759123563766} | train loss {'Reaction outcome loss': 0.2601677439424581, 'Total loss': 0.2601677439424581}
2023-01-04 03:58:36,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:36,403 INFO:     Epoch: 32
2023-01-04 03:58:37,953 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3944588760534922, 'Total loss': 0.3944588760534922} | train loss {'Reaction outcome loss': 0.2589840754975766, 'Total loss': 0.2589840754975766}
2023-01-04 03:58:37,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:37,954 INFO:     Epoch: 33
2023-01-04 03:58:39,527 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38757735093434653, 'Total loss': 0.38757735093434653} | train loss {'Reaction outcome loss': 0.2570789572492842, 'Total loss': 0.2570789572492842}
2023-01-04 03:58:39,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:39,527 INFO:     Epoch: 34
2023-01-04 03:58:41,132 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42216945191224414, 'Total loss': 0.42216945191224414} | train loss {'Reaction outcome loss': 0.25231171339313624, 'Total loss': 0.25231171339313624}
2023-01-04 03:58:41,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:41,133 INFO:     Epoch: 35
2023-01-04 03:58:42,753 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3779661744832993, 'Total loss': 0.3779661744832993} | train loss {'Reaction outcome loss': 0.25170680984254284, 'Total loss': 0.25170680984254284}
2023-01-04 03:58:42,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:42,753 INFO:     Epoch: 36
2023-01-04 03:58:44,364 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4100402096907298, 'Total loss': 0.4100402096907298} | train loss {'Reaction outcome loss': 0.24558411448538958, 'Total loss': 0.24558411448538958}
2023-01-04 03:58:44,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:44,364 INFO:     Epoch: 37
2023-01-04 03:58:45,948 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39665543536345166, 'Total loss': 0.39665543536345166} | train loss {'Reaction outcome loss': 0.241878259121935, 'Total loss': 0.241878259121935}
2023-01-04 03:58:45,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:45,948 INFO:     Epoch: 38
2023-01-04 03:58:47,536 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4181074142456055, 'Total loss': 0.4181074142456055} | train loss {'Reaction outcome loss': 0.24115837065182327, 'Total loss': 0.24115837065182327}
2023-01-04 03:58:47,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:47,536 INFO:     Epoch: 39
2023-01-04 03:58:49,117 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41424023161331813, 'Total loss': 0.41424023161331813} | train loss {'Reaction outcome loss': 0.23647712015516156, 'Total loss': 0.23647712015516156}
2023-01-04 03:58:49,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:49,117 INFO:     Epoch: 40
2023-01-04 03:58:50,690 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4226148804028829, 'Total loss': 0.4226148804028829} | train loss {'Reaction outcome loss': 0.23613543476186175, 'Total loss': 0.23613543476186175}
2023-01-04 03:58:50,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:50,691 INFO:     Epoch: 41
2023-01-04 03:58:52,260 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40422927935918174, 'Total loss': 0.40422927935918174} | train loss {'Reaction outcome loss': 0.23409298878340495, 'Total loss': 0.23409298878340495}
2023-01-04 03:58:52,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:52,260 INFO:     Epoch: 42
2023-01-04 03:58:53,865 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38507032791773477, 'Total loss': 0.38507032791773477} | train loss {'Reaction outcome loss': 0.23173778566903683, 'Total loss': 0.23173778566903683}
2023-01-04 03:58:53,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:53,866 INFO:     Epoch: 43
2023-01-04 03:58:55,447 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4038633853197098, 'Total loss': 0.4038633853197098} | train loss {'Reaction outcome loss': 0.22735168967709873, 'Total loss': 0.22735168967709873}
2023-01-04 03:58:55,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:55,447 INFO:     Epoch: 44
2023-01-04 03:58:57,047 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4107924342155457, 'Total loss': 0.4107924342155457} | train loss {'Reaction outcome loss': 0.23027360981036893, 'Total loss': 0.23027360981036893}
2023-01-04 03:58:57,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:57,047 INFO:     Epoch: 45
2023-01-04 03:58:58,642 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39350197712580365, 'Total loss': 0.39350197712580365} | train loss {'Reaction outcome loss': 0.22567790271816673, 'Total loss': 0.22567790271816673}
2023-01-04 03:58:58,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:58:58,642 INFO:     Epoch: 46
2023-01-04 03:59:00,253 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42488942941029867, 'Total loss': 0.42488942941029867} | train loss {'Reaction outcome loss': 0.22303973531330024, 'Total loss': 0.22303973531330024}
2023-01-04 03:59:00,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:00,253 INFO:     Epoch: 47
2023-01-04 03:59:01,862 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39528494079907733, 'Total loss': 0.39528494079907733} | train loss {'Reaction outcome loss': 0.22240413558897953, 'Total loss': 0.22240413558897953}
2023-01-04 03:59:01,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:01,862 INFO:     Epoch: 48
2023-01-04 03:59:03,476 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4025954415400823, 'Total loss': 0.4025954415400823} | train loss {'Reaction outcome loss': 0.21933276060245413, 'Total loss': 0.21933276060245413}
2023-01-04 03:59:03,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:03,477 INFO:     Epoch: 49
2023-01-04 03:59:05,042 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3967802096779148, 'Total loss': 0.3967802096779148} | train loss {'Reaction outcome loss': 0.2220568036721958, 'Total loss': 0.2220568036721958}
2023-01-04 03:59:05,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:05,042 INFO:     Epoch: 50
2023-01-04 03:59:06,609 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4307812700668971, 'Total loss': 0.4307812700668971} | train loss {'Reaction outcome loss': 0.21687049327261282, 'Total loss': 0.21687049327261282}
2023-01-04 03:59:06,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:06,609 INFO:     Epoch: 51
2023-01-04 03:59:08,226 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4142116169134776, 'Total loss': 0.4142116169134776} | train loss {'Reaction outcome loss': 0.21703568096835535, 'Total loss': 0.21703568096835535}
2023-01-04 03:59:08,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:08,226 INFO:     Epoch: 52
2023-01-04 03:59:09,840 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4121168355147044, 'Total loss': 0.4121168355147044} | train loss {'Reaction outcome loss': 0.21199035055034762, 'Total loss': 0.21199035055034762}
2023-01-04 03:59:09,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:09,841 INFO:     Epoch: 53
2023-01-04 03:59:11,416 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4043884654839834, 'Total loss': 0.4043884654839834} | train loss {'Reaction outcome loss': 0.2128327969093244, 'Total loss': 0.2128327969093244}
2023-01-04 03:59:11,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:11,416 INFO:     Epoch: 54
2023-01-04 03:59:13,003 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4187543953458468, 'Total loss': 0.4187543953458468} | train loss {'Reaction outcome loss': 0.20845200514400397, 'Total loss': 0.20845200514400397}
2023-01-04 03:59:13,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:13,003 INFO:     Epoch: 55
2023-01-04 03:59:14,578 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42712769905726117, 'Total loss': 0.42712769905726117} | train loss {'Reaction outcome loss': 0.20790773510059593, 'Total loss': 0.20790773510059593}
2023-01-04 03:59:14,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:14,578 INFO:     Epoch: 56
2023-01-04 03:59:16,174 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41815498620271685, 'Total loss': 0.41815498620271685} | train loss {'Reaction outcome loss': 0.2075560244871474, 'Total loss': 0.2075560244871474}
2023-01-04 03:59:16,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:16,174 INFO:     Epoch: 57
2023-01-04 03:59:17,801 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4544962853193283, 'Total loss': 0.4544962853193283} | train loss {'Reaction outcome loss': 0.2062098850588222, 'Total loss': 0.2062098850588222}
2023-01-04 03:59:17,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:17,801 INFO:     Epoch: 58
2023-01-04 03:59:19,398 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4317506661017736, 'Total loss': 0.4317506661017736} | train loss {'Reaction outcome loss': 0.20366362558725554, 'Total loss': 0.20366362558725554}
2023-01-04 03:59:19,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:19,398 INFO:     Epoch: 59
2023-01-04 03:59:21,004 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42909642308950424, 'Total loss': 0.42909642308950424} | train loss {'Reaction outcome loss': 0.1996326296429931, 'Total loss': 0.1996326296429931}
2023-01-04 03:59:21,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:21,004 INFO:     Epoch: 60
2023-01-04 03:59:22,585 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41613729298114777, 'Total loss': 0.41613729298114777} | train loss {'Reaction outcome loss': 0.20118474067383252, 'Total loss': 0.20118474067383252}
2023-01-04 03:59:22,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:22,586 INFO:     Epoch: 61
2023-01-04 03:59:24,163 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4294298400481542, 'Total loss': 0.4294298400481542} | train loss {'Reaction outcome loss': 0.20066758106725338, 'Total loss': 0.20066758106725338}
2023-01-04 03:59:24,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:24,163 INFO:     Epoch: 62
2023-01-04 03:59:25,723 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41478013917803763, 'Total loss': 0.41478013917803763} | train loss {'Reaction outcome loss': 0.19823884212108323, 'Total loss': 0.19823884212108323}
2023-01-04 03:59:25,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:25,723 INFO:     Epoch: 63
2023-01-04 03:59:27,305 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4457842350006104, 'Total loss': 0.4457842350006104} | train loss {'Reaction outcome loss': 0.1973250764712091, 'Total loss': 0.1973250764712091}
2023-01-04 03:59:27,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:27,305 INFO:     Epoch: 64
2023-01-04 03:59:28,887 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4336720089117686, 'Total loss': 0.4336720089117686} | train loss {'Reaction outcome loss': 0.19608738246090682, 'Total loss': 0.19608738246090682}
2023-01-04 03:59:28,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:28,888 INFO:     Epoch: 65
2023-01-04 03:59:30,469 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4389519155025482, 'Total loss': 0.4389519155025482} | train loss {'Reaction outcome loss': 0.19528797741010512, 'Total loss': 0.19528797741010512}
2023-01-04 03:59:30,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:30,469 INFO:     Epoch: 66
2023-01-04 03:59:32,031 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4538114249706268, 'Total loss': 0.4538114249706268} | train loss {'Reaction outcome loss': 0.195238883112431, 'Total loss': 0.195238883112431}
2023-01-04 03:59:32,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:32,031 INFO:     Epoch: 67
2023-01-04 03:59:33,594 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4419981355468432, 'Total loss': 0.4419981355468432} | train loss {'Reaction outcome loss': 0.19455265765497973, 'Total loss': 0.19455265765497973}
2023-01-04 03:59:33,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:33,594 INFO:     Epoch: 68
2023-01-04 03:59:35,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4464781641960144, 'Total loss': 0.4464781641960144} | train loss {'Reaction outcome loss': 0.19028969734716109, 'Total loss': 0.19028969734716109}
2023-01-04 03:59:35,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:35,198 INFO:     Epoch: 69
2023-01-04 03:59:36,803 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43183195690313975, 'Total loss': 0.43183195690313975} | train loss {'Reaction outcome loss': 0.18997746635051, 'Total loss': 0.18997746635051}
2023-01-04 03:59:36,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:36,803 INFO:     Epoch: 70
2023-01-04 03:59:38,408 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4590487043062846, 'Total loss': 0.4590487043062846} | train loss {'Reaction outcome loss': 0.1896060419579347, 'Total loss': 0.1896060419579347}
2023-01-04 03:59:38,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:38,409 INFO:     Epoch: 71
2023-01-04 03:59:40,002 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41844283367196716, 'Total loss': 0.41844283367196716} | train loss {'Reaction outcome loss': 0.18834381869861058, 'Total loss': 0.18834381869861058}
2023-01-04 03:59:40,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:40,002 INFO:     Epoch: 72
2023-01-04 03:59:41,584 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45831376512845357, 'Total loss': 0.45831376512845357} | train loss {'Reaction outcome loss': 0.1867872618084207, 'Total loss': 0.1867872618084207}
2023-01-04 03:59:41,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:41,585 INFO:     Epoch: 73
2023-01-04 03:59:43,148 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43515161871910096, 'Total loss': 0.43515161871910096} | train loss {'Reaction outcome loss': 0.18933362210844898, 'Total loss': 0.18933362210844898}
2023-01-04 03:59:43,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:43,149 INFO:     Epoch: 74
2023-01-04 03:59:44,730 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41415469720959663, 'Total loss': 0.41415469720959663} | train loss {'Reaction outcome loss': 0.1855281593462268, 'Total loss': 0.1855281593462268}
2023-01-04 03:59:44,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:44,731 INFO:     Epoch: 75
2023-01-04 03:59:46,317 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44583069582780205, 'Total loss': 0.44583069582780205} | train loss {'Reaction outcome loss': 0.18473763791196077, 'Total loss': 0.18473763791196077}
2023-01-04 03:59:46,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:46,318 INFO:     Epoch: 76
2023-01-04 03:59:47,900 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4669756094614665, 'Total loss': 0.4669756094614665} | train loss {'Reaction outcome loss': 0.18258906399401334, 'Total loss': 0.18258906399401334}
2023-01-04 03:59:47,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:47,900 INFO:     Epoch: 77
2023-01-04 03:59:49,464 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4315209945042928, 'Total loss': 0.4315209945042928} | train loss {'Reaction outcome loss': 0.18179700042602126, 'Total loss': 0.18179700042602126}
2023-01-04 03:59:49,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:49,465 INFO:     Epoch: 78
2023-01-04 03:59:51,047 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4231588751077652, 'Total loss': 0.4231588751077652} | train loss {'Reaction outcome loss': 0.18169509947654747, 'Total loss': 0.18169509947654747}
2023-01-04 03:59:51,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:51,047 INFO:     Epoch: 79
2023-01-04 03:59:52,642 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41980991661548617, 'Total loss': 0.41980991661548617} | train loss {'Reaction outcome loss': 0.18104241115651726, 'Total loss': 0.18104241115651726}
2023-01-04 03:59:52,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:52,642 INFO:     Epoch: 80
2023-01-04 03:59:54,244 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41855955123901367, 'Total loss': 0.41855955123901367} | train loss {'Reaction outcome loss': 0.18198371063849647, 'Total loss': 0.18198371063849647}
2023-01-04 03:59:54,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:54,244 INFO:     Epoch: 81
2023-01-04 03:59:55,849 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4243908435106277, 'Total loss': 0.4243908435106277} | train loss {'Reaction outcome loss': 0.17975078071484635, 'Total loss': 0.17975078071484635}
2023-01-04 03:59:55,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:55,849 INFO:     Epoch: 82
2023-01-04 03:59:57,407 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4236843377351761, 'Total loss': 0.4236843377351761} | train loss {'Reaction outcome loss': 0.17897572580915996, 'Total loss': 0.17897572580915996}
2023-01-04 03:59:57,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:57,408 INFO:     Epoch: 83
2023-01-04 03:59:58,989 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4309167981147766, 'Total loss': 0.4309167981147766} | train loss {'Reaction outcome loss': 0.17786774084299475, 'Total loss': 0.17786774084299475}
2023-01-04 03:59:58,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 03:59:58,990 INFO:     Epoch: 84
2023-01-04 04:00:00,563 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48037229577700297, 'Total loss': 0.48037229577700297} | train loss {'Reaction outcome loss': 0.1778097993049484, 'Total loss': 0.1778097993049484}
2023-01-04 04:00:00,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:00,563 INFO:     Epoch: 85
2023-01-04 04:00:02,166 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4459236671527227, 'Total loss': 0.4459236671527227} | train loss {'Reaction outcome loss': 0.17727088828608667, 'Total loss': 0.17727088828608667}
2023-01-04 04:00:02,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:02,166 INFO:     Epoch: 86
2023-01-04 04:00:03,722 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4566599855820338, 'Total loss': 0.4566599855820338} | train loss {'Reaction outcome loss': 0.1780750425157202, 'Total loss': 0.1780750425157202}
2023-01-04 04:00:03,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:03,723 INFO:     Epoch: 87
2023-01-04 04:00:05,324 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4226505766312281, 'Total loss': 0.4226505766312281} | train loss {'Reaction outcome loss': 0.17286132535327486, 'Total loss': 0.17286132535327486}
2023-01-04 04:00:05,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:05,324 INFO:     Epoch: 88
2023-01-04 04:00:06,900 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42317917893330254, 'Total loss': 0.42317917893330254} | train loss {'Reaction outcome loss': 0.17330872702954725, 'Total loss': 0.17330872702954725}
2023-01-04 04:00:06,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:06,900 INFO:     Epoch: 89
2023-01-04 04:00:08,479 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45530704259872434, 'Total loss': 0.45530704259872434} | train loss {'Reaction outcome loss': 0.17543791146478155, 'Total loss': 0.17543791146478155}
2023-01-04 04:00:08,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:08,480 INFO:     Epoch: 90
2023-01-04 04:00:10,042 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4217796812454859, 'Total loss': 0.4217796812454859} | train loss {'Reaction outcome loss': 0.17388876900076866, 'Total loss': 0.17388876900076866}
2023-01-04 04:00:10,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:10,043 INFO:     Epoch: 91
2023-01-04 04:00:11,626 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4220875839392344, 'Total loss': 0.4220875839392344} | train loss {'Reaction outcome loss': 0.1723438113400774, 'Total loss': 0.1723438113400774}
2023-01-04 04:00:11,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:11,626 INFO:     Epoch: 92
2023-01-04 04:00:13,212 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42467355728149414, 'Total loss': 0.42467355728149414} | train loss {'Reaction outcome loss': 0.17161408501366773, 'Total loss': 0.17161408501366773}
2023-01-04 04:00:13,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:13,212 INFO:     Epoch: 93
2023-01-04 04:00:14,798 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45362078001101813, 'Total loss': 0.45362078001101813} | train loss {'Reaction outcome loss': 0.1720934158170616, 'Total loss': 0.1720934158170616}
2023-01-04 04:00:14,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:14,798 INFO:     Epoch: 94
2023-01-04 04:00:16,370 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42643469870090484, 'Total loss': 0.42643469870090484} | train loss {'Reaction outcome loss': 0.17213767223169296, 'Total loss': 0.17213767223169296}
2023-01-04 04:00:16,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:16,371 INFO:     Epoch: 95
2023-01-04 04:00:17,955 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43955032924811044, 'Total loss': 0.43955032924811044} | train loss {'Reaction outcome loss': 0.16952780257542055, 'Total loss': 0.16952780257542055}
2023-01-04 04:00:17,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:17,956 INFO:     Epoch: 96
2023-01-04 04:00:19,548 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4439410308996836, 'Total loss': 0.4439410308996836} | train loss {'Reaction outcome loss': 0.17062284760586507, 'Total loss': 0.17062284760586507}
2023-01-04 04:00:19,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:19,548 INFO:     Epoch: 97
2023-01-04 04:00:21,162 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45524834593137103, 'Total loss': 0.45524834593137103} | train loss {'Reaction outcome loss': 0.17286279592867737, 'Total loss': 0.17286279592867737}
2023-01-04 04:00:21,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:21,162 INFO:     Epoch: 98
2023-01-04 04:00:22,740 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44699867169062296, 'Total loss': 0.44699867169062296} | train loss {'Reaction outcome loss': 0.1672484754753596, 'Total loss': 0.1672484754753596}
2023-01-04 04:00:22,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:22,741 INFO:     Epoch: 99
2023-01-04 04:00:24,343 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4343245171010494, 'Total loss': 0.4343245171010494} | train loss {'Reaction outcome loss': 0.1671087218878361, 'Total loss': 0.1671087218878361}
2023-01-04 04:00:24,343 INFO:     Best model found after epoch 22 of 100.
2023-01-04 04:00:24,343 INFO:   Done with stage: TRAINING
2023-01-04 04:00:24,343 INFO:   Starting stage: EVALUATION
2023-01-04 04:00:24,484 INFO:   Done with stage: EVALUATION
2023-01-04 04:00:24,484 INFO:   Leaving out SEQ value Fold_4
2023-01-04 04:00:24,496 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:00:24,496 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:00:25,142 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:00:25,142 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:00:25,209 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:00:25,209 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:00:25,209 INFO:     No hyperparam tuning for this model
2023-01-04 04:00:25,209 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:00:25,209 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:00:25,210 INFO:     None feature selector for col prot
2023-01-04 04:00:25,210 INFO:     None feature selector for col prot
2023-01-04 04:00:25,210 INFO:     None feature selector for col prot
2023-01-04 04:00:25,210 INFO:     None feature selector for col chem
2023-01-04 04:00:25,211 INFO:     None feature selector for col chem
2023-01-04 04:00:25,211 INFO:     None feature selector for col chem
2023-01-04 04:00:25,211 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:00:25,211 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:00:25,212 INFO:     Number of params in model 70141
2023-01-04 04:00:25,215 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:00:25,215 INFO:   Starting stage: TRAINING
2023-01-04 04:00:25,258 INFO:     Val loss before train {'Reaction outcome loss': 0.9561444858709971, 'Total loss': 0.9561444858709971}
2023-01-04 04:00:25,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:25,258 INFO:     Epoch: 0
2023-01-04 04:00:26,873 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6971611579259237, 'Total loss': 0.6971611579259237} | train loss {'Reaction outcome loss': 0.8538847882030667, 'Total loss': 0.8538847882030667}
2023-01-04 04:00:26,873 INFO:     Found new best model at epoch 0
2023-01-04 04:00:26,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:26,874 INFO:     Epoch: 1
2023-01-04 04:00:28,461 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6282490412394206, 'Total loss': 0.6282490412394206} | train loss {'Reaction outcome loss': 0.6167212797031887, 'Total loss': 0.6167212797031887}
2023-01-04 04:00:28,462 INFO:     Found new best model at epoch 1
2023-01-04 04:00:28,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:28,463 INFO:     Epoch: 2
2023-01-04 04:00:30,054 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5851988911628723, 'Total loss': 0.5851988911628723} | train loss {'Reaction outcome loss': 0.5370646850948316, 'Total loss': 0.5370646850948316}
2023-01-04 04:00:30,054 INFO:     Found new best model at epoch 2
2023-01-04 04:00:30,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:30,055 INFO:     Epoch: 3
2023-01-04 04:00:31,650 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5677636762460073, 'Total loss': 0.5677636762460073} | train loss {'Reaction outcome loss': 0.4993493993213211, 'Total loss': 0.4993493993213211}
2023-01-04 04:00:31,651 INFO:     Found new best model at epoch 3
2023-01-04 04:00:31,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:31,651 INFO:     Epoch: 4
2023-01-04 04:00:33,230 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.54592058857282, 'Total loss': 0.54592058857282} | train loss {'Reaction outcome loss': 0.46212484946717386, 'Total loss': 0.46212484946717386}
2023-01-04 04:00:33,230 INFO:     Found new best model at epoch 4
2023-01-04 04:00:33,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:33,231 INFO:     Epoch: 5
2023-01-04 04:00:34,841 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5336178104082744, 'Total loss': 0.5336178104082744} | train loss {'Reaction outcome loss': 0.43739545113150624, 'Total loss': 0.43739545113150624}
2023-01-04 04:00:34,842 INFO:     Found new best model at epoch 5
2023-01-04 04:00:34,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:34,843 INFO:     Epoch: 6
2023-01-04 04:00:36,434 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5233863254388174, 'Total loss': 0.5233863254388174} | train loss {'Reaction outcome loss': 0.4211231601168064, 'Total loss': 0.4211231601168064}
2023-01-04 04:00:36,434 INFO:     Found new best model at epoch 6
2023-01-04 04:00:36,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:36,435 INFO:     Epoch: 7
2023-01-04 04:00:38,063 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5267915983994802, 'Total loss': 0.5267915983994802} | train loss {'Reaction outcome loss': 0.40295040362136625, 'Total loss': 0.40295040362136625}
2023-01-04 04:00:38,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:38,064 INFO:     Epoch: 8
2023-01-04 04:00:39,688 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5144062399864197, 'Total loss': 0.5144062399864197} | train loss {'Reaction outcome loss': 0.39202222336029663, 'Total loss': 0.39202222336029663}
2023-01-04 04:00:39,688 INFO:     Found new best model at epoch 8
2023-01-04 04:00:39,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:39,689 INFO:     Epoch: 9
2023-01-04 04:00:41,317 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5008548468351364, 'Total loss': 0.5008548468351364} | train loss {'Reaction outcome loss': 0.3807430796534417, 'Total loss': 0.3807430796534417}
2023-01-04 04:00:41,317 INFO:     Found new best model at epoch 9
2023-01-04 04:00:41,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:41,318 INFO:     Epoch: 10
2023-01-04 04:00:42,902 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.520624448855718, 'Total loss': 0.520624448855718} | train loss {'Reaction outcome loss': 0.3707599453746166, 'Total loss': 0.3707599453746166}
2023-01-04 04:00:42,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:42,902 INFO:     Epoch: 11
2023-01-04 04:00:44,500 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5003023783365885, 'Total loss': 0.5003023783365885} | train loss {'Reaction outcome loss': 0.3633345035893886, 'Total loss': 0.3633345035893886}
2023-01-04 04:00:44,500 INFO:     Found new best model at epoch 11
2023-01-04 04:00:44,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:44,501 INFO:     Epoch: 12
2023-01-04 04:00:46,076 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5183219850063324, 'Total loss': 0.5183219850063324} | train loss {'Reaction outcome loss': 0.3555275758836364, 'Total loss': 0.3555275758836364}
2023-01-04 04:00:46,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:46,077 INFO:     Epoch: 13
2023-01-04 04:00:47,708 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5003827969233196, 'Total loss': 0.5003827969233196} | train loss {'Reaction outcome loss': 0.37048295577583107, 'Total loss': 0.37048295577583107}
2023-01-04 04:00:47,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:47,708 INFO:     Epoch: 14
2023-01-04 04:00:49,287 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.518173756202062, 'Total loss': 0.518173756202062} | train loss {'Reaction outcome loss': 0.34691835205624066, 'Total loss': 0.34691835205624066}
2023-01-04 04:00:49,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:49,287 INFO:     Epoch: 15
2023-01-04 04:00:50,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5093071679274241, 'Total loss': 0.5093071679274241} | train loss {'Reaction outcome loss': 0.34104773569582164, 'Total loss': 0.34104773569582164}
2023-01-04 04:00:50,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:50,908 INFO:     Epoch: 16
2023-01-04 04:00:52,491 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5120650192101797, 'Total loss': 0.5120650192101797} | train loss {'Reaction outcome loss': 0.32789189811202063, 'Total loss': 0.32789189811202063}
2023-01-04 04:00:52,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:52,491 INFO:     Epoch: 17
2023-01-04 04:00:54,069 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5027550051609675, 'Total loss': 0.5027550051609675} | train loss {'Reaction outcome loss': 0.32399526344980534, 'Total loss': 0.32399526344980534}
2023-01-04 04:00:54,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:54,069 INFO:     Epoch: 18
2023-01-04 04:00:55,705 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4912702391544978, 'Total loss': 0.4912702391544978} | train loss {'Reaction outcome loss': 0.321252794045469, 'Total loss': 0.321252794045469}
2023-01-04 04:00:55,705 INFO:     Found new best model at epoch 18
2023-01-04 04:00:55,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:55,706 INFO:     Epoch: 19
2023-01-04 04:00:57,291 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48480620483557385, 'Total loss': 0.48480620483557385} | train loss {'Reaction outcome loss': 0.31523558666863805, 'Total loss': 0.31523558666863805}
2023-01-04 04:00:57,291 INFO:     Found new best model at epoch 19
2023-01-04 04:00:57,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:57,291 INFO:     Epoch: 20
2023-01-04 04:00:58,900 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5046825776497523, 'Total loss': 0.5046825776497523} | train loss {'Reaction outcome loss': 0.3090580601947031, 'Total loss': 0.3090580601947031}
2023-01-04 04:00:58,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:00:58,900 INFO:     Epoch: 21
2023-01-04 04:01:00,464 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4841294308503469, 'Total loss': 0.4841294308503469} | train loss {'Reaction outcome loss': 0.30409393197223306, 'Total loss': 0.30409393197223306}
2023-01-04 04:01:00,464 INFO:     Found new best model at epoch 21
2023-01-04 04:01:00,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:00,465 INFO:     Epoch: 22
2023-01-04 04:01:02,099 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.501688634355863, 'Total loss': 0.501688634355863} | train loss {'Reaction outcome loss': 0.30009324971478485, 'Total loss': 0.30009324971478485}
2023-01-04 04:01:02,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:02,099 INFO:     Epoch: 23
2023-01-04 04:01:03,714 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5039085507392883, 'Total loss': 0.5039085507392883} | train loss {'Reaction outcome loss': 0.2960454574878921, 'Total loss': 0.2960454574878921}
2023-01-04 04:01:03,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:03,714 INFO:     Epoch: 24
2023-01-04 04:01:05,328 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4895950158437093, 'Total loss': 0.4895950158437093} | train loss {'Reaction outcome loss': 0.29011482580851106, 'Total loss': 0.29011482580851106}
2023-01-04 04:01:05,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:05,329 INFO:     Epoch: 25
2023-01-04 04:01:06,965 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4888021558523178, 'Total loss': 0.4888021558523178} | train loss {'Reaction outcome loss': 0.28896782523277553, 'Total loss': 0.28896782523277553}
2023-01-04 04:01:06,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:06,965 INFO:     Epoch: 26
2023-01-04 04:01:08,585 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5015023092428843, 'Total loss': 0.5015023092428843} | train loss {'Reaction outcome loss': 0.2835137935147203, 'Total loss': 0.2835137935147203}
2023-01-04 04:01:08,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:08,585 INFO:     Epoch: 27
2023-01-04 04:01:10,179 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4971515993277232, 'Total loss': 0.4971515993277232} | train loss {'Reaction outcome loss': 0.2794245524838924, 'Total loss': 0.2794245524838924}
2023-01-04 04:01:10,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:10,179 INFO:     Epoch: 28
2023-01-04 04:01:11,816 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4852805495262146, 'Total loss': 0.4852805495262146} | train loss {'Reaction outcome loss': 0.2756707659614337, 'Total loss': 0.2756707659614337}
2023-01-04 04:01:11,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:11,816 INFO:     Epoch: 29
2023-01-04 04:01:13,399 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4781671941280365, 'Total loss': 0.4781671941280365} | train loss {'Reaction outcome loss': 0.2753584068167307, 'Total loss': 0.2753584068167307}
2023-01-04 04:01:13,399 INFO:     Found new best model at epoch 29
2023-01-04 04:01:13,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:13,400 INFO:     Epoch: 30
2023-01-04 04:01:14,991 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.477659206589063, 'Total loss': 0.477659206589063} | train loss {'Reaction outcome loss': 0.2682725664791455, 'Total loss': 0.2682725664791455}
2023-01-04 04:01:14,991 INFO:     Found new best model at epoch 30
2023-01-04 04:01:14,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:14,992 INFO:     Epoch: 31
2023-01-04 04:01:16,582 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4970247824986776, 'Total loss': 0.4970247824986776} | train loss {'Reaction outcome loss': 0.26684370279764297, 'Total loss': 0.26684370279764297}
2023-01-04 04:01:16,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:16,583 INFO:     Epoch: 32
2023-01-04 04:01:18,162 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4813649088144302, 'Total loss': 0.4813649088144302} | train loss {'Reaction outcome loss': 0.26259714522970223, 'Total loss': 0.26259714522970223}
2023-01-04 04:01:18,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:18,162 INFO:     Epoch: 33
2023-01-04 04:01:19,760 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5131177206834158, 'Total loss': 0.5131177206834158} | train loss {'Reaction outcome loss': 0.2660759361055882, 'Total loss': 0.2660759361055882}
2023-01-04 04:01:19,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:19,761 INFO:     Epoch: 34
2023-01-04 04:01:21,345 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5007859816153845, 'Total loss': 0.5007859816153845} | train loss {'Reaction outcome loss': 0.26483868143449124, 'Total loss': 0.26483868143449124}
2023-01-04 04:01:21,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:21,346 INFO:     Epoch: 35
2023-01-04 04:01:22,986 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49751375516255697, 'Total loss': 0.49751375516255697} | train loss {'Reaction outcome loss': 0.2526428648540615, 'Total loss': 0.2526428648540615}
2023-01-04 04:01:22,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:22,986 INFO:     Epoch: 36
2023-01-04 04:01:24,601 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4775104214747747, 'Total loss': 0.4775104214747747} | train loss {'Reaction outcome loss': 0.2532687283296516, 'Total loss': 0.2532687283296516}
2023-01-04 04:01:24,601 INFO:     Found new best model at epoch 36
2023-01-04 04:01:24,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:24,602 INFO:     Epoch: 37
2023-01-04 04:01:26,226 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49874531030654906, 'Total loss': 0.49874531030654906} | train loss {'Reaction outcome loss': 0.2510754381800707, 'Total loss': 0.2510754381800707}
2023-01-04 04:01:26,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:26,227 INFO:     Epoch: 38
2023-01-04 04:01:27,821 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49785642623901366, 'Total loss': 0.49785642623901366} | train loss {'Reaction outcome loss': 0.24418247059203577, 'Total loss': 0.24418247059203577}
2023-01-04 04:01:27,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:27,822 INFO:     Epoch: 39
2023-01-04 04:01:29,417 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.489336833357811, 'Total loss': 0.489336833357811} | train loss {'Reaction outcome loss': 0.2432934171722635, 'Total loss': 0.2432934171722635}
2023-01-04 04:01:29,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:29,417 INFO:     Epoch: 40
2023-01-04 04:01:30,994 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.485450878739357, 'Total loss': 0.485450878739357} | train loss {'Reaction outcome loss': 0.24461491584129955, 'Total loss': 0.24461491584129955}
2023-01-04 04:01:30,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:30,994 INFO:     Epoch: 41
2023-01-04 04:01:32,588 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4895343859990438, 'Total loss': 0.4895343859990438} | train loss {'Reaction outcome loss': 0.23965928681950638, 'Total loss': 0.23965928681950638}
2023-01-04 04:01:32,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:32,588 INFO:     Epoch: 42
2023-01-04 04:01:34,179 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4881221781174342, 'Total loss': 0.4881221781174342} | train loss {'Reaction outcome loss': 0.23805097578964907, 'Total loss': 0.23805097578964907}
2023-01-04 04:01:34,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:34,179 INFO:     Epoch: 43
2023-01-04 04:01:35,784 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5030368586381276, 'Total loss': 0.5030368586381276} | train loss {'Reaction outcome loss': 0.2316674573154634, 'Total loss': 0.2316674573154634}
2023-01-04 04:01:35,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:35,784 INFO:     Epoch: 44
2023-01-04 04:01:37,353 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48949870268503826, 'Total loss': 0.48949870268503826} | train loss {'Reaction outcome loss': 0.23048605187057916, 'Total loss': 0.23048605187057916}
2023-01-04 04:01:37,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:37,353 INFO:     Epoch: 45
2023-01-04 04:01:38,953 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49591689904530845, 'Total loss': 0.49591689904530845} | train loss {'Reaction outcome loss': 0.22572200560766825, 'Total loss': 0.22572200560766825}
2023-01-04 04:01:38,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:38,954 INFO:     Epoch: 46
2023-01-04 04:01:40,598 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5009178022543589, 'Total loss': 0.5009178022543589} | train loss {'Reaction outcome loss': 0.22632526705527437, 'Total loss': 0.22632526705527437}
2023-01-04 04:01:40,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:40,599 INFO:     Epoch: 47
2023-01-04 04:01:42,235 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48912404576937357, 'Total loss': 0.48912404576937357} | train loss {'Reaction outcome loss': 0.21952331529093394, 'Total loss': 0.21952331529093394}
2023-01-04 04:01:42,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:42,235 INFO:     Epoch: 48
2023-01-04 04:01:43,820 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49930751423041025, 'Total loss': 0.49930751423041025} | train loss {'Reaction outcome loss': 0.22136436401447956, 'Total loss': 0.22136436401447956}
2023-01-04 04:01:43,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:43,820 INFO:     Epoch: 49
2023-01-04 04:01:45,402 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5075363218784332, 'Total loss': 0.5075363218784332} | train loss {'Reaction outcome loss': 0.21875649357072846, 'Total loss': 0.21875649357072846}
2023-01-04 04:01:45,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:45,402 INFO:     Epoch: 50
2023-01-04 04:01:47,028 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5007582952578863, 'Total loss': 0.5007582952578863} | train loss {'Reaction outcome loss': 0.21622119281981714, 'Total loss': 0.21622119281981714}
2023-01-04 04:01:47,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:47,028 INFO:     Epoch: 51
2023-01-04 04:01:48,629 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49659619430700935, 'Total loss': 0.49659619430700935} | train loss {'Reaction outcome loss': 0.2143154791457177, 'Total loss': 0.2143154791457177}
2023-01-04 04:01:48,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:48,629 INFO:     Epoch: 52
2023-01-04 04:01:50,217 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4962283233801524, 'Total loss': 0.4962283233801524} | train loss {'Reaction outcome loss': 0.21197871990042969, 'Total loss': 0.21197871990042969}
2023-01-04 04:01:50,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:50,218 INFO:     Epoch: 53
2023-01-04 04:01:51,802 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49583049217859904, 'Total loss': 0.49583049217859904} | train loss {'Reaction outcome loss': 0.21149210954435926, 'Total loss': 0.21149210954435926}
2023-01-04 04:01:51,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:51,802 INFO:     Epoch: 54
2023-01-04 04:01:53,390 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49787795742352803, 'Total loss': 0.49787795742352803} | train loss {'Reaction outcome loss': 0.2151254086714724, 'Total loss': 0.2151254086714724}
2023-01-04 04:01:53,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:53,390 INFO:     Epoch: 55
2023-01-04 04:01:54,982 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5019028693437576, 'Total loss': 0.5019028693437576} | train loss {'Reaction outcome loss': 0.20833475451133604, 'Total loss': 0.20833475451133604}
2023-01-04 04:01:54,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:54,982 INFO:     Epoch: 56
2023-01-04 04:01:56,609 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5018053449690342, 'Total loss': 0.5018053449690342} | train loss {'Reaction outcome loss': 0.2071989929553493, 'Total loss': 0.2071989929553493}
2023-01-04 04:01:56,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:56,611 INFO:     Epoch: 57
2023-01-04 04:01:58,209 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5234933018684387, 'Total loss': 0.5234933018684387} | train loss {'Reaction outcome loss': 0.2018821115780156, 'Total loss': 0.2018821115780156}
2023-01-04 04:01:58,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:58,210 INFO:     Epoch: 58
2023-01-04 04:01:59,807 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5292135576407114, 'Total loss': 0.5292135576407114} | train loss {'Reaction outcome loss': 0.20132254998737853, 'Total loss': 0.20132254998737853}
2023-01-04 04:01:59,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:01:59,808 INFO:     Epoch: 59
2023-01-04 04:02:01,430 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5395504673322041, 'Total loss': 0.5395504673322041} | train loss {'Reaction outcome loss': 0.20331434912277738, 'Total loss': 0.20331434912277738}
2023-01-04 04:02:01,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:01,430 INFO:     Epoch: 60
2023-01-04 04:02:03,065 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5161747435728709, 'Total loss': 0.5161747435728709} | train loss {'Reaction outcome loss': 0.2138696767396523, 'Total loss': 0.2138696767396523}
2023-01-04 04:02:03,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:03,066 INFO:     Epoch: 61
2023-01-04 04:02:04,702 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5121564626693725, 'Total loss': 0.5121564626693725} | train loss {'Reaction outcome loss': 0.20157470936090618, 'Total loss': 0.20157470936090618}
2023-01-04 04:02:04,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:04,702 INFO:     Epoch: 62
2023-01-04 04:02:06,280 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.51172736287117, 'Total loss': 0.51172736287117} | train loss {'Reaction outcome loss': 0.20067437219583645, 'Total loss': 0.20067437219583645}
2023-01-04 04:02:06,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:06,280 INFO:     Epoch: 63
2023-01-04 04:02:07,903 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.512120145559311, 'Total loss': 0.512120145559311} | train loss {'Reaction outcome loss': 0.19747900484345746, 'Total loss': 0.19747900484345746}
2023-01-04 04:02:07,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:07,904 INFO:     Epoch: 64
2023-01-04 04:02:09,515 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5034292002518972, 'Total loss': 0.5034292002518972} | train loss {'Reaction outcome loss': 0.19338646666585482, 'Total loss': 0.19338646666585482}
2023-01-04 04:02:09,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:09,515 INFO:     Epoch: 65
2023-01-04 04:02:11,141 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4715189258257548, 'Total loss': 0.4715189258257548} | train loss {'Reaction outcome loss': 0.19141377250467695, 'Total loss': 0.19141377250467695}
2023-01-04 04:02:11,141 INFO:     Found new best model at epoch 65
2023-01-04 04:02:11,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:11,142 INFO:     Epoch: 66
2023-01-04 04:02:12,741 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5156134764353434, 'Total loss': 0.5156134764353434} | train loss {'Reaction outcome loss': 0.190961182522385, 'Total loss': 0.190961182522385}
2023-01-04 04:02:12,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:12,741 INFO:     Epoch: 67
2023-01-04 04:02:14,364 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5196047166983286, 'Total loss': 0.5196047166983286} | train loss {'Reaction outcome loss': 0.19141659149022747, 'Total loss': 0.19141659149022747}
2023-01-04 04:02:14,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:14,364 INFO:     Epoch: 68
2023-01-04 04:02:15,986 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5172822952270508, 'Total loss': 0.5172822952270508} | train loss {'Reaction outcome loss': 0.1883679591304879, 'Total loss': 0.1883679591304879}
2023-01-04 04:02:15,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:15,987 INFO:     Epoch: 69
2023-01-04 04:02:17,605 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5013641496499379, 'Total loss': 0.5013641496499379} | train loss {'Reaction outcome loss': 0.1916967466527569, 'Total loss': 0.1916967466527569}
2023-01-04 04:02:17,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:17,606 INFO:     Epoch: 70
2023-01-04 04:02:19,230 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5090811401605606, 'Total loss': 0.5090811401605606} | train loss {'Reaction outcome loss': 0.20708792894214822, 'Total loss': 0.20708792894214822}
2023-01-04 04:02:19,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:19,230 INFO:     Epoch: 71
2023-01-04 04:02:20,876 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49568196932474773, 'Total loss': 0.49568196932474773} | train loss {'Reaction outcome loss': 0.20020613025585393, 'Total loss': 0.20020613025585393}
2023-01-04 04:02:20,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:20,876 INFO:     Epoch: 72
2023-01-04 04:02:22,469 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4826907594998678, 'Total loss': 0.4826907594998678} | train loss {'Reaction outcome loss': 0.1826553651050705, 'Total loss': 0.1826553651050705}
2023-01-04 04:02:22,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:22,469 INFO:     Epoch: 73
2023-01-04 04:02:24,095 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.501030957698822, 'Total loss': 0.501030957698822} | train loss {'Reaction outcome loss': 0.18219720710782195, 'Total loss': 0.18219720710782195}
2023-01-04 04:02:24,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:24,095 INFO:     Epoch: 74
2023-01-04 04:02:25,703 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4989437411228816, 'Total loss': 0.4989437411228816} | train loss {'Reaction outcome loss': 0.18157326451340772, 'Total loss': 0.18157326451340772}
2023-01-04 04:02:25,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:25,703 INFO:     Epoch: 75
2023-01-04 04:02:27,346 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4933912734190623, 'Total loss': 0.4933912734190623} | train loss {'Reaction outcome loss': 0.1799290620357446, 'Total loss': 0.1799290620357446}
2023-01-04 04:02:27,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:27,348 INFO:     Epoch: 76
2023-01-04 04:02:28,989 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5234295566876729, 'Total loss': 0.5234295566876729} | train loss {'Reaction outcome loss': 0.1811844458790037, 'Total loss': 0.1811844458790037}
2023-01-04 04:02:28,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:28,989 INFO:     Epoch: 77
2023-01-04 04:02:30,588 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.495135643084844, 'Total loss': 0.495135643084844} | train loss {'Reaction outcome loss': 0.1780912179324398, 'Total loss': 0.1780912179324398}
2023-01-04 04:02:30,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:30,588 INFO:     Epoch: 78
2023-01-04 04:02:32,187 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.530987161397934, 'Total loss': 0.530987161397934} | train loss {'Reaction outcome loss': 0.17933096087633033, 'Total loss': 0.17933096087633033}
2023-01-04 04:02:32,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:32,187 INFO:     Epoch: 79
2023-01-04 04:02:33,784 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5046207368373871, 'Total loss': 0.5046207368373871} | train loss {'Reaction outcome loss': 0.17905832671195918, 'Total loss': 0.17905832671195918}
2023-01-04 04:02:33,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:33,785 INFO:     Epoch: 80
2023-01-04 04:02:35,377 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5095267593860626, 'Total loss': 0.5095267593860626} | train loss {'Reaction outcome loss': 0.17771066640557695, 'Total loss': 0.17771066640557695}
2023-01-04 04:02:35,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:35,377 INFO:     Epoch: 81
2023-01-04 04:02:37,014 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5422454158465068, 'Total loss': 0.5422454158465068} | train loss {'Reaction outcome loss': 0.1782965341420925, 'Total loss': 0.1782965341420925}
2023-01-04 04:02:37,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:37,014 INFO:     Epoch: 82
2023-01-04 04:02:38,643 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5382645686467489, 'Total loss': 0.5382645686467489} | train loss {'Reaction outcome loss': 0.1807380328807968, 'Total loss': 0.1807380328807968}
2023-01-04 04:02:38,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:38,644 INFO:     Epoch: 83
2023-01-04 04:02:40,247 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5077623983224233, 'Total loss': 0.5077623983224233} | train loss {'Reaction outcome loss': 0.17348966867459661, 'Total loss': 0.17348966867459661}
2023-01-04 04:02:40,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:40,247 INFO:     Epoch: 84
2023-01-04 04:02:41,877 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4978146274884542, 'Total loss': 0.4978146274884542} | train loss {'Reaction outcome loss': 0.17305429205357475, 'Total loss': 0.17305429205357475}
2023-01-04 04:02:41,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:41,878 INFO:     Epoch: 85
2023-01-04 04:02:43,499 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5293805261452993, 'Total loss': 0.5293805261452993} | train loss {'Reaction outcome loss': 0.1733873208915769, 'Total loss': 0.1733873208915769}
2023-01-04 04:02:43,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:43,500 INFO:     Epoch: 86
2023-01-04 04:02:45,140 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5345360318819682, 'Total loss': 0.5345360318819682} | train loss {'Reaction outcome loss': 0.17333457193318821, 'Total loss': 0.17333457193318821}
2023-01-04 04:02:45,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:45,140 INFO:     Epoch: 87
2023-01-04 04:02:46,720 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5240620414415995, 'Total loss': 0.5240620414415995} | train loss {'Reaction outcome loss': 0.17262901140349932, 'Total loss': 0.17262901140349932}
2023-01-04 04:02:46,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:46,721 INFO:     Epoch: 88
2023-01-04 04:02:48,325 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5242689003547033, 'Total loss': 0.5242689003547033} | train loss {'Reaction outcome loss': 0.18901993361288222, 'Total loss': 0.18901993361288222}
2023-01-04 04:02:48,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:48,325 INFO:     Epoch: 89
2023-01-04 04:02:49,910 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5406826615333558, 'Total loss': 0.5406826615333558} | train loss {'Reaction outcome loss': 0.18609898515801498, 'Total loss': 0.18609898515801498}
2023-01-04 04:02:49,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:49,910 INFO:     Epoch: 90
2023-01-04 04:02:51,485 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5334474047025045, 'Total loss': 0.5334474047025045} | train loss {'Reaction outcome loss': 0.18165675394129063, 'Total loss': 0.18165675394129063}
2023-01-04 04:02:51,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:51,485 INFO:     Epoch: 91
2023-01-04 04:02:53,088 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5372880617777507, 'Total loss': 0.5372880617777507} | train loss {'Reaction outcome loss': 0.18467888512985656, 'Total loss': 0.18467888512985656}
2023-01-04 04:02:53,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:53,089 INFO:     Epoch: 92
2023-01-04 04:02:54,730 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4902731478214264, 'Total loss': 0.4902731478214264} | train loss {'Reaction outcome loss': 0.16811472345211043, 'Total loss': 0.16811472345211043}
2023-01-04 04:02:54,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:54,731 INFO:     Epoch: 93
2023-01-04 04:02:56,313 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5140266577402751, 'Total loss': 0.5140266577402751} | train loss {'Reaction outcome loss': 0.1670326286402733, 'Total loss': 0.1670326286402733}
2023-01-04 04:02:56,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:56,313 INFO:     Epoch: 94
2023-01-04 04:02:57,915 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5109467963377635, 'Total loss': 0.5109467963377635} | train loss {'Reaction outcome loss': 0.16552023899660434, 'Total loss': 0.16552023899660434}
2023-01-04 04:02:57,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:57,916 INFO:     Epoch: 95
2023-01-04 04:02:59,515 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5409670213858286, 'Total loss': 0.5409670213858286} | train loss {'Reaction outcome loss': 0.1638129000095195, 'Total loss': 0.1638129000095195}
2023-01-04 04:02:59,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:02:59,516 INFO:     Epoch: 96
2023-01-04 04:03:01,121 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5209725300470988, 'Total loss': 0.5209725300470988} | train loss {'Reaction outcome loss': 0.166445353801217, 'Total loss': 0.166445353801217}
2023-01-04 04:03:01,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:01,121 INFO:     Epoch: 97
2023-01-04 04:03:02,750 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5442079583803813, 'Total loss': 0.5442079583803813} | train loss {'Reaction outcome loss': 0.16492496042147928, 'Total loss': 0.16492496042147928}
2023-01-04 04:03:02,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:02,750 INFO:     Epoch: 98
2023-01-04 04:03:04,371 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5241634567578634, 'Total loss': 0.5241634567578634} | train loss {'Reaction outcome loss': 0.16630658000982637, 'Total loss': 0.16630658000982637}
2023-01-04 04:03:04,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:04,372 INFO:     Epoch: 99
2023-01-04 04:03:05,963 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5177266677220662, 'Total loss': 0.5177266677220662} | train loss {'Reaction outcome loss': 0.16498892877480367, 'Total loss': 0.16498892877480367}
2023-01-04 04:03:05,963 INFO:     Best model found after epoch 66 of 100.
2023-01-04 04:03:05,964 INFO:   Done with stage: TRAINING
2023-01-04 04:03:05,964 INFO:   Starting stage: EVALUATION
2023-01-04 04:03:06,093 INFO:   Done with stage: EVALUATION
2023-01-04 04:03:06,093 INFO:   Leaving out SEQ value Fold_5
2023-01-04 04:03:06,106 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:03:06,106 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:03:06,752 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:03:06,753 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:03:06,820 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:03:06,820 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:03:06,820 INFO:     No hyperparam tuning for this model
2023-01-04 04:03:06,820 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:03:06,820 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:03:06,821 INFO:     None feature selector for col prot
2023-01-04 04:03:06,821 INFO:     None feature selector for col prot
2023-01-04 04:03:06,821 INFO:     None feature selector for col prot
2023-01-04 04:03:06,821 INFO:     None feature selector for col chem
2023-01-04 04:03:06,822 INFO:     None feature selector for col chem
2023-01-04 04:03:06,822 INFO:     None feature selector for col chem
2023-01-04 04:03:06,822 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:03:06,822 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:03:06,823 INFO:     Number of params in model 70141
2023-01-04 04:03:06,826 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:03:06,826 INFO:   Starting stage: TRAINING
2023-01-04 04:03:06,872 INFO:     Val loss before train {'Reaction outcome loss': 1.0026718457539876, 'Total loss': 1.0026718457539876}
2023-01-04 04:03:06,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:06,872 INFO:     Epoch: 0
2023-01-04 04:03:08,467 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6401076356569926, 'Total loss': 0.6401076356569926} | train loss {'Reaction outcome loss': 0.8780131775183954, 'Total loss': 0.8780131775183954}
2023-01-04 04:03:08,467 INFO:     Found new best model at epoch 0
2023-01-04 04:03:08,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:08,468 INFO:     Epoch: 1
2023-01-04 04:03:10,067 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5225116829077403, 'Total loss': 0.5225116829077403} | train loss {'Reaction outcome loss': 0.6118906685758544, 'Total loss': 0.6118906685758544}
2023-01-04 04:03:10,068 INFO:     Found new best model at epoch 1
2023-01-04 04:03:10,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:10,068 INFO:     Epoch: 2
2023-01-04 04:03:11,653 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4654817332824071, 'Total loss': 0.4654817332824071} | train loss {'Reaction outcome loss': 0.5312429267265226, 'Total loss': 0.5312429267265226}
2023-01-04 04:03:11,654 INFO:     Found new best model at epoch 2
2023-01-04 04:03:11,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:11,654 INFO:     Epoch: 3
2023-01-04 04:03:13,248 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45005579590797423, 'Total loss': 0.45005579590797423} | train loss {'Reaction outcome loss': 0.4930849044610733, 'Total loss': 0.4930849044610733}
2023-01-04 04:03:13,248 INFO:     Found new best model at epoch 3
2023-01-04 04:03:13,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:13,249 INFO:     Epoch: 4
2023-01-04 04:03:14,858 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43985793987909955, 'Total loss': 0.43985793987909955} | train loss {'Reaction outcome loss': 0.46431772046439024, 'Total loss': 0.46431772046439024}
2023-01-04 04:03:14,858 INFO:     Found new best model at epoch 4
2023-01-04 04:03:14,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:14,859 INFO:     Epoch: 5
2023-01-04 04:03:16,444 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4412793904542923, 'Total loss': 0.4412793904542923} | train loss {'Reaction outcome loss': 0.44400612989599153, 'Total loss': 0.44400612989599153}
2023-01-04 04:03:16,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:16,445 INFO:     Epoch: 6
2023-01-04 04:03:18,022 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4134031981229782, 'Total loss': 0.4134031981229782} | train loss {'Reaction outcome loss': 0.43523137724917865, 'Total loss': 0.43523137724917865}
2023-01-04 04:03:18,022 INFO:     Found new best model at epoch 6
2023-01-04 04:03:18,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:18,023 INFO:     Epoch: 7
2023-01-04 04:03:19,653 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4153431395689646, 'Total loss': 0.4153431395689646} | train loss {'Reaction outcome loss': 0.4167477123952214, 'Total loss': 0.4167477123952214}
2023-01-04 04:03:19,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:19,653 INFO:     Epoch: 8
2023-01-04 04:03:21,251 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4264475921789805, 'Total loss': 0.4264475921789805} | train loss {'Reaction outcome loss': 0.40663696868696075, 'Total loss': 0.40663696868696075}
2023-01-04 04:03:21,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:21,251 INFO:     Epoch: 9
2023-01-04 04:03:22,876 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.415119676788648, 'Total loss': 0.415119676788648} | train loss {'Reaction outcome loss': 0.39500982140231394, 'Total loss': 0.39500982140231394}
2023-01-04 04:03:22,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:22,876 INFO:     Epoch: 10
2023-01-04 04:03:24,485 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4174037496248881, 'Total loss': 0.4174037496248881} | train loss {'Reaction outcome loss': 0.3826172908388601, 'Total loss': 0.3826172908388601}
2023-01-04 04:03:24,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:24,485 INFO:     Epoch: 11
2023-01-04 04:03:26,103 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4176146000623703, 'Total loss': 0.4176146000623703} | train loss {'Reaction outcome loss': 0.3739372126798591, 'Total loss': 0.3739372126798591}
2023-01-04 04:03:26,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:26,104 INFO:     Epoch: 12
2023-01-04 04:03:27,697 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40572431484858196, 'Total loss': 0.40572431484858196} | train loss {'Reaction outcome loss': 0.36738107322404784, 'Total loss': 0.36738107322404784}
2023-01-04 04:03:27,697 INFO:     Found new best model at epoch 12
2023-01-04 04:03:27,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:27,698 INFO:     Epoch: 13
2023-01-04 04:03:29,290 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4073616355657578, 'Total loss': 0.4073616355657578} | train loss {'Reaction outcome loss': 0.3676805207370848, 'Total loss': 0.3676805207370848}
2023-01-04 04:03:29,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:29,292 INFO:     Epoch: 14
2023-01-04 04:03:30,908 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39756489197413125, 'Total loss': 0.39756489197413125} | train loss {'Reaction outcome loss': 0.3655623270323554, 'Total loss': 0.3655623270323554}
2023-01-04 04:03:30,908 INFO:     Found new best model at epoch 14
2023-01-04 04:03:30,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:30,909 INFO:     Epoch: 15
2023-01-04 04:03:32,505 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42025303741296133, 'Total loss': 0.42025303741296133} | train loss {'Reaction outcome loss': 0.3475217588407838, 'Total loss': 0.3475217588407838}
2023-01-04 04:03:32,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:32,505 INFO:     Epoch: 16
2023-01-04 04:03:34,088 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3940458486477534, 'Total loss': 0.3940458486477534} | train loss {'Reaction outcome loss': 0.34045475879616605, 'Total loss': 0.34045475879616605}
2023-01-04 04:03:34,088 INFO:     Found new best model at epoch 16
2023-01-04 04:03:34,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:34,089 INFO:     Epoch: 17
2023-01-04 04:03:35,684 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.420685750246048, 'Total loss': 0.420685750246048} | train loss {'Reaction outcome loss': 0.3388542281868665, 'Total loss': 0.3388542281868665}
2023-01-04 04:03:35,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:35,685 INFO:     Epoch: 18
2023-01-04 04:03:37,290 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41429211596647897, 'Total loss': 0.41429211596647897} | train loss {'Reaction outcome loss': 0.34403908158234064, 'Total loss': 0.34403908158234064}
2023-01-04 04:03:37,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:37,290 INFO:     Epoch: 19
2023-01-04 04:03:38,895 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4178457140922546, 'Total loss': 0.4178457140922546} | train loss {'Reaction outcome loss': 0.3357974251903479, 'Total loss': 0.3357974251903479}
2023-01-04 04:03:38,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:38,895 INFO:     Epoch: 20
2023-01-04 04:03:40,502 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39486909508705137, 'Total loss': 0.39486909508705137} | train loss {'Reaction outcome loss': 0.31876828928901546, 'Total loss': 0.31876828928901546}
2023-01-04 04:03:40,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:40,502 INFO:     Epoch: 21
2023-01-04 04:03:42,123 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41871989369392393, 'Total loss': 0.41871989369392393} | train loss {'Reaction outcome loss': 0.31408957144299493, 'Total loss': 0.31408957144299493}
2023-01-04 04:03:42,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:42,124 INFO:     Epoch: 22
2023-01-04 04:03:43,710 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41203504701455435, 'Total loss': 0.41203504701455435} | train loss {'Reaction outcome loss': 0.30941402671885665, 'Total loss': 0.30941402671885665}
2023-01-04 04:03:43,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:43,710 INFO:     Epoch: 23
2023-01-04 04:03:45,295 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4167500793933868, 'Total loss': 0.4167500793933868} | train loss {'Reaction outcome loss': 0.3084737743694754, 'Total loss': 0.3084737743694754}
2023-01-04 04:03:45,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:45,295 INFO:     Epoch: 24
2023-01-04 04:03:46,892 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40864530007044475, 'Total loss': 0.40864530007044475} | train loss {'Reaction outcome loss': 0.2997611569115153, 'Total loss': 0.2997611569115153}
2023-01-04 04:03:46,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:46,892 INFO:     Epoch: 25
2023-01-04 04:03:48,487 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4038076529900233, 'Total loss': 0.4038076529900233} | train loss {'Reaction outcome loss': 0.2944194676955163, 'Total loss': 0.2944194676955163}
2023-01-04 04:03:48,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:48,488 INFO:     Epoch: 26
2023-01-04 04:03:50,098 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44765891631444293, 'Total loss': 0.44765891631444293} | train loss {'Reaction outcome loss': 0.2995142044256563, 'Total loss': 0.2995142044256563}
2023-01-04 04:03:50,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:50,098 INFO:     Epoch: 27
2023-01-04 04:03:51,694 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4294783314069112, 'Total loss': 0.4294783314069112} | train loss {'Reaction outcome loss': 0.2955094899010399, 'Total loss': 0.2955094899010399}
2023-01-04 04:03:51,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:51,694 INFO:     Epoch: 28
2023-01-04 04:03:53,292 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4158601542313894, 'Total loss': 0.4158601542313894} | train loss {'Reaction outcome loss': 0.28460551564838144, 'Total loss': 0.28460551564838144}
2023-01-04 04:03:53,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:53,292 INFO:     Epoch: 29
2023-01-04 04:03:54,871 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4051818251609802, 'Total loss': 0.4051818251609802} | train loss {'Reaction outcome loss': 0.2789490777945173, 'Total loss': 0.2789490777945173}
2023-01-04 04:03:54,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:54,871 INFO:     Epoch: 30
2023-01-04 04:03:56,470 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4095688283443451, 'Total loss': 0.4095688283443451} | train loss {'Reaction outcome loss': 0.28218282122110977, 'Total loss': 0.28218282122110977}
2023-01-04 04:03:56,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:56,471 INFO:     Epoch: 31
2023-01-04 04:03:58,101 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4115441222985586, 'Total loss': 0.4115441222985586} | train loss {'Reaction outcome loss': 0.27736859382602613, 'Total loss': 0.27736859382602613}
2023-01-04 04:03:58,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:58,101 INFO:     Epoch: 32
2023-01-04 04:03:59,699 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3993740926186244, 'Total loss': 0.3993740926186244} | train loss {'Reaction outcome loss': 0.2715654995543815, 'Total loss': 0.2715654995543815}
2023-01-04 04:03:59,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:03:59,700 INFO:     Epoch: 33
2023-01-04 04:04:01,307 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41686031719048816, 'Total loss': 0.41686031719048816} | train loss {'Reaction outcome loss': 0.2643051603640281, 'Total loss': 0.2643051603640281}
2023-01-04 04:04:01,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:01,308 INFO:     Epoch: 34
2023-01-04 04:04:02,876 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42201266884803773, 'Total loss': 0.42201266884803773} | train loss {'Reaction outcome loss': 0.26225864277153776, 'Total loss': 0.26225864277153776}
2023-01-04 04:04:02,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:02,876 INFO:     Epoch: 35
2023-01-04 04:04:04,472 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4135165840387344, 'Total loss': 0.4135165840387344} | train loss {'Reaction outcome loss': 0.2592444391014304, 'Total loss': 0.2592444391014304}
2023-01-04 04:04:04,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:04,473 INFO:     Epoch: 36
2023-01-04 04:04:06,057 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4212464431921641, 'Total loss': 0.4212464431921641} | train loss {'Reaction outcome loss': 0.27373416570649634, 'Total loss': 0.27373416570649634}
2023-01-04 04:04:06,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:06,058 INFO:     Epoch: 37
2023-01-04 04:04:07,682 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42102649609247844, 'Total loss': 0.42102649609247844} | train loss {'Reaction outcome loss': 0.26699789887182607, 'Total loss': 0.26699789887182607}
2023-01-04 04:04:07,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:07,682 INFO:     Epoch: 38
2023-01-04 04:04:09,284 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4177292386690776, 'Total loss': 0.4177292386690776} | train loss {'Reaction outcome loss': 0.25005591992774734, 'Total loss': 0.25005591992774734}
2023-01-04 04:04:09,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:09,284 INFO:     Epoch: 39
2023-01-04 04:04:10,886 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4403230309486389, 'Total loss': 0.4403230309486389} | train loss {'Reaction outcome loss': 0.24861033189285925, 'Total loss': 0.24861033189285925}
2023-01-04 04:04:10,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:10,886 INFO:     Epoch: 40
2023-01-04 04:04:12,478 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4013479173183441, 'Total loss': 0.4013479173183441} | train loss {'Reaction outcome loss': 0.24563744507284593, 'Total loss': 0.24563744507284593}
2023-01-04 04:04:12,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:12,478 INFO:     Epoch: 41
2023-01-04 04:04:14,068 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4110138754049937, 'Total loss': 0.4110138754049937} | train loss {'Reaction outcome loss': 0.24254002899397165, 'Total loss': 0.24254002899397165}
2023-01-04 04:04:14,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:14,069 INFO:     Epoch: 42
2023-01-04 04:04:15,692 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4259740004936854, 'Total loss': 0.4259740004936854} | train loss {'Reaction outcome loss': 0.2412560520005291, 'Total loss': 0.2412560520005291}
2023-01-04 04:04:15,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:15,692 INFO:     Epoch: 43
2023-01-04 04:04:17,319 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4330013463894526, 'Total loss': 0.4330013463894526} | train loss {'Reaction outcome loss': 0.23983156619605311, 'Total loss': 0.23983156619605311}
2023-01-04 04:04:17,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:17,319 INFO:     Epoch: 44
2023-01-04 04:04:18,915 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41661481857299804, 'Total loss': 0.41661481857299804} | train loss {'Reaction outcome loss': 0.23811940898767847, 'Total loss': 0.23811940898767847}
2023-01-04 04:04:18,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:18,915 INFO:     Epoch: 45
2023-01-04 04:04:20,519 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4130057543516159, 'Total loss': 0.4130057543516159} | train loss {'Reaction outcome loss': 0.23648631929055505, 'Total loss': 0.23648631929055505}
2023-01-04 04:04:20,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:20,519 INFO:     Epoch: 46
2023-01-04 04:04:22,120 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43692315618197125, 'Total loss': 0.43692315618197125} | train loss {'Reaction outcome loss': 0.2328363422344884, 'Total loss': 0.2328363422344884}
2023-01-04 04:04:22,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:22,120 INFO:     Epoch: 47
2023-01-04 04:04:23,748 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42457945346832277, 'Total loss': 0.42457945346832277} | train loss {'Reaction outcome loss': 0.22989827603400362, 'Total loss': 0.22989827603400362}
2023-01-04 04:04:23,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:23,749 INFO:     Epoch: 48
2023-01-04 04:04:25,329 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4138100668787956, 'Total loss': 0.4138100668787956} | train loss {'Reaction outcome loss': 0.2283150975362978, 'Total loss': 0.2283150975362978}
2023-01-04 04:04:25,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:25,330 INFO:     Epoch: 49
2023-01-04 04:04:26,949 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39700645903746284, 'Total loss': 0.39700645903746284} | train loss {'Reaction outcome loss': 0.22764854558298123, 'Total loss': 0.22764854558298123}
2023-01-04 04:04:26,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:26,949 INFO:     Epoch: 50
2023-01-04 04:04:28,536 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4200635552406311, 'Total loss': 0.4200635552406311} | train loss {'Reaction outcome loss': 0.23073799823127364, 'Total loss': 0.23073799823127364}
2023-01-04 04:04:28,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:28,536 INFO:     Epoch: 51
2023-01-04 04:04:30,109 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41580693821112313, 'Total loss': 0.41580693821112313} | train loss {'Reaction outcome loss': 0.23444904526020738, 'Total loss': 0.23444904526020738}
2023-01-04 04:04:30,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:30,110 INFO:     Epoch: 52
2023-01-04 04:04:31,731 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.430984103679657, 'Total loss': 0.430984103679657} | train loss {'Reaction outcome loss': 0.22323720516235393, 'Total loss': 0.22323720516235393}
2023-01-04 04:04:31,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:31,731 INFO:     Epoch: 53
2023-01-04 04:04:33,351 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4275286058584849, 'Total loss': 0.4275286058584849} | train loss {'Reaction outcome loss': 0.21777098273615475, 'Total loss': 0.21777098273615475}
2023-01-04 04:04:33,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:33,352 INFO:     Epoch: 54
2023-01-04 04:04:34,973 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4344733546177546, 'Total loss': 0.4344733546177546} | train loss {'Reaction outcome loss': 0.22204741793752147, 'Total loss': 0.22204741793752147}
2023-01-04 04:04:34,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:34,974 INFO:     Epoch: 55
2023-01-04 04:04:36,420 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4361826876799266, 'Total loss': 0.4361826876799266} | train loss {'Reaction outcome loss': 0.22155840704689964, 'Total loss': 0.22155840704689964}
2023-01-04 04:04:36,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:36,420 INFO:     Epoch: 56
2023-01-04 04:04:37,496 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4372681776682536, 'Total loss': 0.4372681776682536} | train loss {'Reaction outcome loss': 0.21578061648819974, 'Total loss': 0.21578061648819974}
2023-01-04 04:04:37,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:37,496 INFO:     Epoch: 57
2023-01-04 04:04:38,582 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46431007583936057, 'Total loss': 0.46431007583936057} | train loss {'Reaction outcome loss': 0.21266549144723063, 'Total loss': 0.21266549144723063}
2023-01-04 04:04:38,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:38,582 INFO:     Epoch: 58
2023-01-04 04:04:39,657 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45048407167196275, 'Total loss': 0.45048407167196275} | train loss {'Reaction outcome loss': 0.21466460489312075, 'Total loss': 0.21466460489312075}
2023-01-04 04:04:39,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:39,657 INFO:     Epoch: 59
2023-01-04 04:04:40,783 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43825535277525585, 'Total loss': 0.43825535277525585} | train loss {'Reaction outcome loss': 0.21197704777148538, 'Total loss': 0.21197704777148538}
2023-01-04 04:04:40,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:40,783 INFO:     Epoch: 60
2023-01-04 04:04:42,398 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4468942527969678, 'Total loss': 0.4468942527969678} | train loss {'Reaction outcome loss': 0.2120673174394524, 'Total loss': 0.2120673174394524}
2023-01-04 04:04:42,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:42,399 INFO:     Epoch: 61
2023-01-04 04:04:44,018 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4551425377527873, 'Total loss': 0.4551425377527873} | train loss {'Reaction outcome loss': 0.20795515309715562, 'Total loss': 0.20795515309715562}
2023-01-04 04:04:44,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:44,019 INFO:     Epoch: 62
2023-01-04 04:04:45,632 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4443782061338425, 'Total loss': 0.4443782061338425} | train loss {'Reaction outcome loss': 0.20955261398658098, 'Total loss': 0.20955261398658098}
2023-01-04 04:04:45,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:45,632 INFO:     Epoch: 63
2023-01-04 04:04:47,222 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4242913434902827, 'Total loss': 0.4242913434902827} | train loss {'Reaction outcome loss': 0.20900992192732898, 'Total loss': 0.20900992192732898}
2023-01-04 04:04:47,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:47,222 INFO:     Epoch: 64
2023-01-04 04:04:48,820 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41773141622543336, 'Total loss': 0.41773141622543336} | train loss {'Reaction outcome loss': 0.20757139853853057, 'Total loss': 0.20757139853853057}
2023-01-04 04:04:48,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:48,821 INFO:     Epoch: 65
2023-01-04 04:04:50,403 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42752299110094705, 'Total loss': 0.42752299110094705} | train loss {'Reaction outcome loss': 0.20382337108637422, 'Total loss': 0.20382337108637422}
2023-01-04 04:04:50,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:50,403 INFO:     Epoch: 66
2023-01-04 04:04:51,998 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46041375199953716, 'Total loss': 0.46041375199953716} | train loss {'Reaction outcome loss': 0.20301810956047173, 'Total loss': 0.20301810956047173}
2023-01-04 04:04:51,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:51,998 INFO:     Epoch: 67
2023-01-04 04:04:53,593 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44934235513210297, 'Total loss': 0.44934235513210297} | train loss {'Reaction outcome loss': 0.20031993431241615, 'Total loss': 0.20031993431241615}
2023-01-04 04:04:53,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:53,593 INFO:     Epoch: 68
2023-01-04 04:04:55,164 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45937104771534604, 'Total loss': 0.45937104771534604} | train loss {'Reaction outcome loss': 0.1996193791307725, 'Total loss': 0.1996193791307725}
2023-01-04 04:04:55,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:55,165 INFO:     Epoch: 69
2023-01-04 04:04:56,805 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43921637733777363, 'Total loss': 0.43921637733777363} | train loss {'Reaction outcome loss': 0.2005960396819991, 'Total loss': 0.2005960396819991}
2023-01-04 04:04:56,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:56,805 INFO:     Epoch: 70
2023-01-04 04:04:58,409 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4346576571464539, 'Total loss': 0.4346576571464539} | train loss {'Reaction outcome loss': 0.1985923669980254, 'Total loss': 0.1985923669980254}
2023-01-04 04:04:58,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:04:58,410 INFO:     Epoch: 71
2023-01-04 04:05:00,003 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4270392765601476, 'Total loss': 0.4270392765601476} | train loss {'Reaction outcome loss': 0.19692081054212843, 'Total loss': 0.19692081054212843}
2023-01-04 04:05:00,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:00,003 INFO:     Epoch: 72
2023-01-04 04:05:01,636 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4363095680872599, 'Total loss': 0.4363095680872599} | train loss {'Reaction outcome loss': 0.19416657271136975, 'Total loss': 0.19416657271136975}
2023-01-04 04:05:01,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:01,636 INFO:     Epoch: 73
2023-01-04 04:05:03,272 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44150898257891336, 'Total loss': 0.44150898257891336} | train loss {'Reaction outcome loss': 0.1945723734654324, 'Total loss': 0.1945723734654324}
2023-01-04 04:05:03,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:03,272 INFO:     Epoch: 74
2023-01-04 04:05:04,851 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44440305332342783, 'Total loss': 0.44440305332342783} | train loss {'Reaction outcome loss': 0.19597390552105248, 'Total loss': 0.19597390552105248}
2023-01-04 04:05:04,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:04,851 INFO:     Epoch: 75
2023-01-04 04:05:06,451 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4343965212504069, 'Total loss': 0.4343965212504069} | train loss {'Reaction outcome loss': 0.19331292270098988, 'Total loss': 0.19331292270098988}
2023-01-04 04:05:06,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:06,452 INFO:     Epoch: 76
2023-01-04 04:05:08,035 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43383102416992186, 'Total loss': 0.43383102416992186} | train loss {'Reaction outcome loss': 0.2107395140076245, 'Total loss': 0.2107395140076245}
2023-01-04 04:05:08,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:08,035 INFO:     Epoch: 77
2023-01-04 04:05:09,636 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44009393254915874, 'Total loss': 0.44009393254915874} | train loss {'Reaction outcome loss': 0.2101277456605348, 'Total loss': 0.2101277456605348}
2023-01-04 04:05:09,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:09,636 INFO:     Epoch: 78
2023-01-04 04:05:11,236 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43238863348960876, 'Total loss': 0.43238863348960876} | train loss {'Reaction outcome loss': 0.1971707229482833, 'Total loss': 0.1971707229482833}
2023-01-04 04:05:11,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:11,237 INFO:     Epoch: 79
2023-01-04 04:05:12,817 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43673748672008517, 'Total loss': 0.43673748672008517} | train loss {'Reaction outcome loss': 0.19313337666023037, 'Total loss': 0.19313337666023037}
2023-01-04 04:05:12,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:12,817 INFO:     Epoch: 80
2023-01-04 04:05:14,424 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4557717313369115, 'Total loss': 0.4557717313369115} | train loss {'Reaction outcome loss': 0.18754224965496047, 'Total loss': 0.18754224965496047}
2023-01-04 04:05:14,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:14,425 INFO:     Epoch: 81
2023-01-04 04:05:16,023 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4400431046883265, 'Total loss': 0.4400431046883265} | train loss {'Reaction outcome loss': 0.19063355278858976, 'Total loss': 0.19063355278858976}
2023-01-04 04:05:16,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:16,024 INFO:     Epoch: 82
2023-01-04 04:05:17,609 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44787602722644804, 'Total loss': 0.44787602722644804} | train loss {'Reaction outcome loss': 0.18752655071928503, 'Total loss': 0.18752655071928503}
2023-01-04 04:05:17,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:17,610 INFO:     Epoch: 83
2023-01-04 04:05:19,209 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4744073549906413, 'Total loss': 0.4744073549906413} | train loss {'Reaction outcome loss': 0.18685501977207436, 'Total loss': 0.18685501977207436}
2023-01-04 04:05:19,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:19,209 INFO:     Epoch: 84
2023-01-04 04:05:20,808 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4326696033279101, 'Total loss': 0.4326696033279101} | train loss {'Reaction outcome loss': 0.192788257387503, 'Total loss': 0.192788257387503}
2023-01-04 04:05:20,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:20,808 INFO:     Epoch: 85
2023-01-04 04:05:22,400 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4286690255006154, 'Total loss': 0.4286690255006154} | train loss {'Reaction outcome loss': 0.1834705142925183, 'Total loss': 0.1834705142925183}
2023-01-04 04:05:22,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:22,400 INFO:     Epoch: 86
2023-01-04 04:05:24,027 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4580426514148712, 'Total loss': 0.4580426514148712} | train loss {'Reaction outcome loss': 0.185482834459053, 'Total loss': 0.185482834459053}
2023-01-04 04:05:24,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:24,027 INFO:     Epoch: 87
2023-01-04 04:05:25,644 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43453736901283263, 'Total loss': 0.43453736901283263} | train loss {'Reaction outcome loss': 0.1823933435118069, 'Total loss': 0.1823933435118069}
2023-01-04 04:05:25,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:25,644 INFO:     Epoch: 88
2023-01-04 04:05:27,252 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4502155721187592, 'Total loss': 0.4502155721187592} | train loss {'Reaction outcome loss': 0.18296046570553764, 'Total loss': 0.18296046570553764}
2023-01-04 04:05:27,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:27,253 INFO:     Epoch: 89
2023-01-04 04:05:28,867 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4409127692381541, 'Total loss': 0.4409127692381541} | train loss {'Reaction outcome loss': 0.18048390944845186, 'Total loss': 0.18048390944845186}
2023-01-04 04:05:28,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:28,867 INFO:     Epoch: 90
2023-01-04 04:05:30,459 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4204861084620158, 'Total loss': 0.4204861084620158} | train loss {'Reaction outcome loss': 0.18082180277754864, 'Total loss': 0.18082180277754864}
2023-01-04 04:05:30,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:30,460 INFO:     Epoch: 91
2023-01-04 04:05:32,072 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48301616311073303, 'Total loss': 0.48301616311073303} | train loss {'Reaction outcome loss': 0.1946749550398385, 'Total loss': 0.1946749550398385}
2023-01-04 04:05:32,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:32,072 INFO:     Epoch: 92
2023-01-04 04:05:33,699 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4490691045920054, 'Total loss': 0.4490691045920054} | train loss {'Reaction outcome loss': 0.2008939432790098, 'Total loss': 0.2008939432790098}
2023-01-04 04:05:33,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:33,700 INFO:     Epoch: 93
2023-01-04 04:05:35,297 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4310356179873149, 'Total loss': 0.4310356179873149} | train loss {'Reaction outcome loss': 0.17851965782482285, 'Total loss': 0.17851965782482285}
2023-01-04 04:05:35,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:35,297 INFO:     Epoch: 94
2023-01-04 04:05:36,921 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44646105766296384, 'Total loss': 0.44646105766296384} | train loss {'Reaction outcome loss': 0.17624455553502322, 'Total loss': 0.17624455553502322}
2023-01-04 04:05:36,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:36,921 INFO:     Epoch: 95
2023-01-04 04:05:38,540 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44125039378801983, 'Total loss': 0.44125039378801983} | train loss {'Reaction outcome loss': 0.17829638059154843, 'Total loss': 0.17829638059154843}
2023-01-04 04:05:38,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:38,540 INFO:     Epoch: 96
2023-01-04 04:05:40,134 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4573509722948074, 'Total loss': 0.4573509722948074} | train loss {'Reaction outcome loss': 0.1759123572364958, 'Total loss': 0.1759123572364958}
2023-01-04 04:05:40,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:40,134 INFO:     Epoch: 97
2023-01-04 04:05:41,736 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43921639720598854, 'Total loss': 0.43921639720598854} | train loss {'Reaction outcome loss': 0.1749548613476783, 'Total loss': 0.1749548613476783}
2023-01-04 04:05:41,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:41,738 INFO:     Epoch: 98
2023-01-04 04:05:43,336 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4326493988434474, 'Total loss': 0.4326493988434474} | train loss {'Reaction outcome loss': 0.17445143024636217, 'Total loss': 0.17445143024636217}
2023-01-04 04:05:43,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:43,337 INFO:     Epoch: 99
2023-01-04 04:05:44,920 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44208553036053977, 'Total loss': 0.44208553036053977} | train loss {'Reaction outcome loss': 0.17391657119072118, 'Total loss': 0.17391657119072118}
2023-01-04 04:05:44,920 INFO:     Best model found after epoch 17 of 100.
2023-01-04 04:05:44,921 INFO:   Done with stage: TRAINING
2023-01-04 04:05:44,921 INFO:   Starting stage: EVALUATION
2023-01-04 04:05:45,052 INFO:   Done with stage: EVALUATION
2023-01-04 04:05:45,052 INFO:   Leaving out SEQ value Fold_6
2023-01-04 04:05:45,064 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:05:45,064 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:05:45,720 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:05:45,720 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:05:45,788 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:05:45,788 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:05:45,788 INFO:     No hyperparam tuning for this model
2023-01-04 04:05:45,788 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:05:45,789 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:05:45,789 INFO:     None feature selector for col prot
2023-01-04 04:05:45,789 INFO:     None feature selector for col prot
2023-01-04 04:05:45,790 INFO:     None feature selector for col prot
2023-01-04 04:05:45,790 INFO:     None feature selector for col chem
2023-01-04 04:05:45,790 INFO:     None feature selector for col chem
2023-01-04 04:05:45,790 INFO:     None feature selector for col chem
2023-01-04 04:05:45,790 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:05:45,790 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:05:45,791 INFO:     Number of params in model 70141
2023-01-04 04:05:45,795 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:05:45,795 INFO:   Starting stage: TRAINING
2023-01-04 04:05:45,839 INFO:     Val loss before train {'Reaction outcome loss': 1.0076735774676004, 'Total loss': 1.0076735774676004}
2023-01-04 04:05:45,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:45,839 INFO:     Epoch: 0
2023-01-04 04:05:47,441 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.699911481142044, 'Total loss': 0.699911481142044} | train loss {'Reaction outcome loss': 0.8626697763854416, 'Total loss': 0.8626697763854416}
2023-01-04 04:05:47,441 INFO:     Found new best model at epoch 0
2023-01-04 04:05:47,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:47,442 INFO:     Epoch: 1
2023-01-04 04:05:49,042 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5872339844703675, 'Total loss': 0.5872339844703675} | train loss {'Reaction outcome loss': 0.6071131324079493, 'Total loss': 0.6071131324079493}
2023-01-04 04:05:49,042 INFO:     Found new best model at epoch 1
2023-01-04 04:05:49,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:49,043 INFO:     Epoch: 2
2023-01-04 04:05:50,631 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5577997247378031, 'Total loss': 0.5577997247378031} | train loss {'Reaction outcome loss': 0.5306363064889873, 'Total loss': 0.5306363064889873}
2023-01-04 04:05:50,631 INFO:     Found new best model at epoch 2
2023-01-04 04:05:50,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:50,632 INFO:     Epoch: 3
2023-01-04 04:05:52,244 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5060495257377624, 'Total loss': 0.5060495257377624} | train loss {'Reaction outcome loss': 0.49637200320240393, 'Total loss': 0.49637200320240393}
2023-01-04 04:05:52,244 INFO:     Found new best model at epoch 3
2023-01-04 04:05:52,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:52,245 INFO:     Epoch: 4
2023-01-04 04:05:53,866 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5149324675401051, 'Total loss': 0.5149324675401051} | train loss {'Reaction outcome loss': 0.46965504542584885, 'Total loss': 0.46965504542584885}
2023-01-04 04:05:53,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:53,867 INFO:     Epoch: 5
2023-01-04 04:05:55,496 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5034265796343486, 'Total loss': 0.5034265796343486} | train loss {'Reaction outcome loss': 0.449706047827156, 'Total loss': 0.449706047827156}
2023-01-04 04:05:55,496 INFO:     Found new best model at epoch 5
2023-01-04 04:05:55,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:55,497 INFO:     Epoch: 6
2023-01-04 04:05:57,116 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4863645414511363, 'Total loss': 0.4863645414511363} | train loss {'Reaction outcome loss': 0.4316766912971593, 'Total loss': 0.4316766912971593}
2023-01-04 04:05:57,116 INFO:     Found new best model at epoch 6
2023-01-04 04:05:57,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:57,117 INFO:     Epoch: 7
2023-01-04 04:05:58,733 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.482500163714091, 'Total loss': 0.482500163714091} | train loss {'Reaction outcome loss': 0.4208582392238107, 'Total loss': 0.4208582392238107}
2023-01-04 04:05:58,733 INFO:     Found new best model at epoch 7
2023-01-04 04:05:58,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:05:58,734 INFO:     Epoch: 8
2023-01-04 04:06:00,329 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4774080117543538, 'Total loss': 0.4774080117543538} | train loss {'Reaction outcome loss': 0.4092857902768717, 'Total loss': 0.4092857902768717}
2023-01-04 04:06:00,329 INFO:     Found new best model at epoch 8
2023-01-04 04:06:00,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:00,330 INFO:     Epoch: 9
2023-01-04 04:06:01,925 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45965483983357747, 'Total loss': 0.45965483983357747} | train loss {'Reaction outcome loss': 0.39665608699786536, 'Total loss': 0.39665608699786536}
2023-01-04 04:06:01,926 INFO:     Found new best model at epoch 9
2023-01-04 04:06:01,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:01,927 INFO:     Epoch: 10
2023-01-04 04:06:03,534 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46000030140082043, 'Total loss': 0.46000030140082043} | train loss {'Reaction outcome loss': 0.3906214660578256, 'Total loss': 0.3906214660578256}
2023-01-04 04:06:03,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:03,535 INFO:     Epoch: 11
2023-01-04 04:06:05,132 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45841887791951497, 'Total loss': 0.45841887791951497} | train loss {'Reaction outcome loss': 0.38054934267748136, 'Total loss': 0.38054934267748136}
2023-01-04 04:06:05,132 INFO:     Found new best model at epoch 11
2023-01-04 04:06:05,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:05,133 INFO:     Epoch: 12
2023-01-04 04:06:06,713 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4494844973087311, 'Total loss': 0.4494844973087311} | train loss {'Reaction outcome loss': 0.37409504607911576, 'Total loss': 0.37409504607911576}
2023-01-04 04:06:06,713 INFO:     Found new best model at epoch 12
2023-01-04 04:06:06,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:06,714 INFO:     Epoch: 13
2023-01-04 04:06:08,332 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45016510287920636, 'Total loss': 0.45016510287920636} | train loss {'Reaction outcome loss': 0.3677725966226323, 'Total loss': 0.3677725966226323}
2023-01-04 04:06:08,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:08,333 INFO:     Epoch: 14
2023-01-04 04:06:09,966 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4496675928433736, 'Total loss': 0.4496675928433736} | train loss {'Reaction outcome loss': 0.3574093209061812, 'Total loss': 0.3574093209061812}
2023-01-04 04:06:09,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:09,966 INFO:     Epoch: 15
2023-01-04 04:06:11,570 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44394628604253134, 'Total loss': 0.44394628604253134} | train loss {'Reaction outcome loss': 0.35418759910423403, 'Total loss': 0.35418759910423403}
2023-01-04 04:06:11,570 INFO:     Found new best model at epoch 15
2023-01-04 04:06:11,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:11,571 INFO:     Epoch: 16
2023-01-04 04:06:13,165 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44374231100082395, 'Total loss': 0.44374231100082395} | train loss {'Reaction outcome loss': 0.34683116807834335, 'Total loss': 0.34683116807834335}
2023-01-04 04:06:13,166 INFO:     Found new best model at epoch 16
2023-01-04 04:06:13,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:13,167 INFO:     Epoch: 17
2023-01-04 04:06:14,760 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43706905444463096, 'Total loss': 0.43706905444463096} | train loss {'Reaction outcome loss': 0.3393774391404128, 'Total loss': 0.3393774391404128}
2023-01-04 04:06:14,761 INFO:     Found new best model at epoch 17
2023-01-04 04:06:14,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:14,761 INFO:     Epoch: 18
2023-01-04 04:06:16,368 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42488404413064323, 'Total loss': 0.42488404413064323} | train loss {'Reaction outcome loss': 0.33579521168978205, 'Total loss': 0.33579521168978205}
2023-01-04 04:06:16,368 INFO:     Found new best model at epoch 18
2023-01-04 04:06:16,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:16,369 INFO:     Epoch: 19
2023-01-04 04:06:17,997 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43205488721529645, 'Total loss': 0.43205488721529645} | train loss {'Reaction outcome loss': 0.32910274474844603, 'Total loss': 0.32910274474844603}
2023-01-04 04:06:17,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:17,997 INFO:     Epoch: 20
2023-01-04 04:06:19,606 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4209143280982971, 'Total loss': 0.4209143280982971} | train loss {'Reaction outcome loss': 0.3236765844834841, 'Total loss': 0.3236765844834841}
2023-01-04 04:06:19,607 INFO:     Found new best model at epoch 20
2023-01-04 04:06:19,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:19,608 INFO:     Epoch: 21
2023-01-04 04:06:21,219 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41695114771525066, 'Total loss': 0.41695114771525066} | train loss {'Reaction outcome loss': 0.3167616550672786, 'Total loss': 0.3167616550672786}
2023-01-04 04:06:21,219 INFO:     Found new best model at epoch 21
2023-01-04 04:06:21,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:21,220 INFO:     Epoch: 22
2023-01-04 04:06:22,838 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4184666891892751, 'Total loss': 0.4184666891892751} | train loss {'Reaction outcome loss': 0.315310610922235, 'Total loss': 0.315310610922235}
2023-01-04 04:06:22,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:22,838 INFO:     Epoch: 23
2023-01-04 04:06:24,447 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4148772835731506, 'Total loss': 0.4148772835731506} | train loss {'Reaction outcome loss': 0.30624565022194, 'Total loss': 0.30624565022194}
2023-01-04 04:06:24,447 INFO:     Found new best model at epoch 23
2023-01-04 04:06:24,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:24,448 INFO:     Epoch: 24
2023-01-04 04:06:26,050 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4177954812844594, 'Total loss': 0.4177954812844594} | train loss {'Reaction outcome loss': 0.3024128971870195, 'Total loss': 0.3024128971870195}
2023-01-04 04:06:26,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:26,050 INFO:     Epoch: 25
2023-01-04 04:06:27,653 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41765026648839315, 'Total loss': 0.41765026648839315} | train loss {'Reaction outcome loss': 0.29902559806616297, 'Total loss': 0.29902559806616297}
2023-01-04 04:06:27,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:27,653 INFO:     Epoch: 26
2023-01-04 04:06:29,248 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43274007737636566, 'Total loss': 0.43274007737636566} | train loss {'Reaction outcome loss': 0.29422436076273556, 'Total loss': 0.29422436076273556}
2023-01-04 04:06:29,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:29,248 INFO:     Epoch: 27
2023-01-04 04:06:30,875 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4155903458595276, 'Total loss': 0.4155903458595276} | train loss {'Reaction outcome loss': 0.2890355377474847, 'Total loss': 0.2890355377474847}
2023-01-04 04:06:30,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:30,875 INFO:     Epoch: 28
2023-01-04 04:06:32,506 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41954272588094077, 'Total loss': 0.41954272588094077} | train loss {'Reaction outcome loss': 0.28674682740807966, 'Total loss': 0.28674682740807966}
2023-01-04 04:06:32,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:32,507 INFO:     Epoch: 29
2023-01-04 04:06:34,100 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40425842702388765, 'Total loss': 0.40425842702388765} | train loss {'Reaction outcome loss': 0.28495074910807694, 'Total loss': 0.28495074910807694}
2023-01-04 04:06:34,100 INFO:     Found new best model at epoch 29
2023-01-04 04:06:34,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:34,101 INFO:     Epoch: 30
2023-01-04 04:06:35,707 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.409526002407074, 'Total loss': 0.409526002407074} | train loss {'Reaction outcome loss': 0.2806027883710844, 'Total loss': 0.2806027883710844}
2023-01-04 04:06:35,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:35,707 INFO:     Epoch: 31
2023-01-04 04:06:37,317 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41630505124727885, 'Total loss': 0.41630505124727885} | train loss {'Reaction outcome loss': 0.2738611917095494, 'Total loss': 0.2738611917095494}
2023-01-04 04:06:37,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:37,317 INFO:     Epoch: 32
2023-01-04 04:06:38,949 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4316980704665184, 'Total loss': 0.4316980704665184} | train loss {'Reaction outcome loss': 0.2725194261177352, 'Total loss': 0.2725194261177352}
2023-01-04 04:06:38,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:38,949 INFO:     Epoch: 33
2023-01-04 04:06:40,569 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4167991707722346, 'Total loss': 0.4167991707722346} | train loss {'Reaction outcome loss': 0.269102380890063, 'Total loss': 0.269102380890063}
2023-01-04 04:06:40,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:40,570 INFO:     Epoch: 34
2023-01-04 04:06:42,182 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4128198881944021, 'Total loss': 0.4128198881944021} | train loss {'Reaction outcome loss': 0.26624020909897256, 'Total loss': 0.26624020909897256}
2023-01-04 04:06:42,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:42,183 INFO:     Epoch: 35
2023-01-04 04:06:43,806 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40898689528306326, 'Total loss': 0.40898689528306326} | train loss {'Reaction outcome loss': 0.26346091027724616, 'Total loss': 0.26346091027724616}
2023-01-04 04:06:43,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:43,806 INFO:     Epoch: 36
2023-01-04 04:06:45,393 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41083094278971355, 'Total loss': 0.41083094278971355} | train loss {'Reaction outcome loss': 0.26047312731884875, 'Total loss': 0.26047312731884875}
2023-01-04 04:06:45,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:45,393 INFO:     Epoch: 37
2023-01-04 04:06:46,993 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4154193287094434, 'Total loss': 0.4154193287094434} | train loss {'Reaction outcome loss': 0.25816800004200813, 'Total loss': 0.25816800004200813}
2023-01-04 04:06:46,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:46,993 INFO:     Epoch: 38
2023-01-04 04:06:48,596 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40763094623883567, 'Total loss': 0.40763094623883567} | train loss {'Reaction outcome loss': 0.25383160582034164, 'Total loss': 0.25383160582034164}
2023-01-04 04:06:48,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:48,597 INFO:     Epoch: 39
2023-01-04 04:06:50,199 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4029433528582255, 'Total loss': 0.4029433528582255} | train loss {'Reaction outcome loss': 0.25214530610973657, 'Total loss': 0.25214530610973657}
2023-01-04 04:06:50,199 INFO:     Found new best model at epoch 39
2023-01-04 04:06:50,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:50,200 INFO:     Epoch: 40
2023-01-04 04:06:51,783 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40550759534041086, 'Total loss': 0.40550759534041086} | train loss {'Reaction outcome loss': 0.2495179723827202, 'Total loss': 0.2495179723827202}
2023-01-04 04:06:51,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:51,783 INFO:     Epoch: 41
2023-01-04 04:06:53,415 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4006446719169617, 'Total loss': 0.4006446719169617} | train loss {'Reaction outcome loss': 0.24417729269619023, 'Total loss': 0.24417729269619023}
2023-01-04 04:06:53,415 INFO:     Found new best model at epoch 41
2023-01-04 04:06:53,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:53,416 INFO:     Epoch: 42
2023-01-04 04:06:55,043 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41076806783676145, 'Total loss': 0.41076806783676145} | train loss {'Reaction outcome loss': 0.24450825226059458, 'Total loss': 0.24450825226059458}
2023-01-04 04:06:55,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:55,044 INFO:     Epoch: 43
2023-01-04 04:06:56,650 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.411061883966128, 'Total loss': 0.411061883966128} | train loss {'Reaction outcome loss': 0.2405473862905795, 'Total loss': 0.2405473862905795}
2023-01-04 04:06:56,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:56,651 INFO:     Epoch: 44
2023-01-04 04:06:58,279 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41022806862990063, 'Total loss': 0.41022806862990063} | train loss {'Reaction outcome loss': 0.24256284253853322, 'Total loss': 0.24256284253853322}
2023-01-04 04:06:58,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:58,279 INFO:     Epoch: 45
2023-01-04 04:06:59,881 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40526585082213085, 'Total loss': 0.40526585082213085} | train loss {'Reaction outcome loss': 0.23594527507355498, 'Total loss': 0.23594527507355498}
2023-01-04 04:06:59,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:06:59,881 INFO:     Epoch: 46
2023-01-04 04:07:01,467 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42500669360160825, 'Total loss': 0.42500669360160825} | train loss {'Reaction outcome loss': 0.23557886773121917, 'Total loss': 0.23557886773121917}
2023-01-04 04:07:01,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:01,467 INFO:     Epoch: 47
2023-01-04 04:07:03,073 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4313889036575953, 'Total loss': 0.4313889036575953} | train loss {'Reaction outcome loss': 0.23039931896737767, 'Total loss': 0.23039931896737767}
2023-01-04 04:07:03,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:03,074 INFO:     Epoch: 48
2023-01-04 04:07:04,652 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41121739745140073, 'Total loss': 0.41121739745140073} | train loss {'Reaction outcome loss': 0.23200207713332416, 'Total loss': 0.23200207713332416}
2023-01-04 04:07:04,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:04,653 INFO:     Epoch: 49
2023-01-04 04:07:06,280 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4158930112918218, 'Total loss': 0.4158930112918218} | train loss {'Reaction outcome loss': 0.22988044787937983, 'Total loss': 0.22988044787937983}
2023-01-04 04:07:06,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:06,280 INFO:     Epoch: 50
2023-01-04 04:07:07,907 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4004961892962456, 'Total loss': 0.4004961892962456} | train loss {'Reaction outcome loss': 0.22680361563548285, 'Total loss': 0.22680361563548285}
2023-01-04 04:07:07,908 INFO:     Found new best model at epoch 50
2023-01-04 04:07:07,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:07,909 INFO:     Epoch: 51
2023-01-04 04:07:09,478 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4295404672622681, 'Total loss': 0.4295404672622681} | train loss {'Reaction outcome loss': 0.2252995954685263, 'Total loss': 0.2252995954685263}
2023-01-04 04:07:09,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:09,479 INFO:     Epoch: 52
2023-01-04 04:07:11,098 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4264070610205332, 'Total loss': 0.4264070610205332} | train loss {'Reaction outcome loss': 0.22357297283916697, 'Total loss': 0.22357297283916697}
2023-01-04 04:07:11,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:11,098 INFO:     Epoch: 53
2023-01-04 04:07:12,712 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41275693078835807, 'Total loss': 0.41275693078835807} | train loss {'Reaction outcome loss': 0.2242370169569439, 'Total loss': 0.2242370169569439}
2023-01-04 04:07:12,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:12,712 INFO:     Epoch: 54
2023-01-04 04:07:14,299 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4221470504999161, 'Total loss': 0.4221470504999161} | train loss {'Reaction outcome loss': 0.21930067018615856, 'Total loss': 0.21930067018615856}
2023-01-04 04:07:14,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:14,300 INFO:     Epoch: 55
2023-01-04 04:07:15,903 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41993322869141897, 'Total loss': 0.41993322869141897} | train loss {'Reaction outcome loss': 0.21784526176938943, 'Total loss': 0.21784526176938943}
2023-01-04 04:07:15,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:15,903 INFO:     Epoch: 56
2023-01-04 04:07:17,506 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4152465403079987, 'Total loss': 0.4152465403079987} | train loss {'Reaction outcome loss': 0.21717422160350244, 'Total loss': 0.21717422160350244}
2023-01-04 04:07:17,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:17,506 INFO:     Epoch: 57
2023-01-04 04:07:19,090 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42684411207834877, 'Total loss': 0.42684411207834877} | train loss {'Reaction outcome loss': 0.2144630488263786, 'Total loss': 0.2144630488263786}
2023-01-04 04:07:19,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:19,091 INFO:     Epoch: 58
2023-01-04 04:07:20,700 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4341194212436676, 'Total loss': 0.4341194212436676} | train loss {'Reaction outcome loss': 0.2128112150578077, 'Total loss': 0.2128112150578077}
2023-01-04 04:07:20,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:20,700 INFO:     Epoch: 59
2023-01-04 04:07:22,304 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4233128940065702, 'Total loss': 0.4233128940065702} | train loss {'Reaction outcome loss': 0.212695274771013, 'Total loss': 0.212695274771013}
2023-01-04 04:07:22,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:22,304 INFO:     Epoch: 60
2023-01-04 04:07:23,907 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42991820673147835, 'Total loss': 0.42991820673147835} | train loss {'Reaction outcome loss': 0.21032794465441995, 'Total loss': 0.21032794465441995}
2023-01-04 04:07:23,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:23,907 INFO:     Epoch: 61
2023-01-04 04:07:25,510 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42050650467475253, 'Total loss': 0.42050650467475253} | train loss {'Reaction outcome loss': 0.21046672527432872, 'Total loss': 0.21046672527432872}
2023-01-04 04:07:25,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:25,511 INFO:     Epoch: 62
2023-01-04 04:07:27,093 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42358562449614207, 'Total loss': 0.42358562449614207} | train loss {'Reaction outcome loss': 0.20767266935389825, 'Total loss': 0.20767266935389825}
2023-01-04 04:07:27,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:27,094 INFO:     Epoch: 63
2023-01-04 04:07:28,720 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44057640035947165, 'Total loss': 0.44057640035947165} | train loss {'Reaction outcome loss': 0.2056535135026658, 'Total loss': 0.2056535135026658}
2023-01-04 04:07:28,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:28,720 INFO:     Epoch: 64
2023-01-04 04:07:30,347 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40624345242977145, 'Total loss': 0.40624345242977145} | train loss {'Reaction outcome loss': 0.2028403626855745, 'Total loss': 0.2028403626855745}
2023-01-04 04:07:30,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:30,347 INFO:     Epoch: 65
2023-01-04 04:07:31,941 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4146039019028346, 'Total loss': 0.4146039019028346} | train loss {'Reaction outcome loss': 0.2037632472692091, 'Total loss': 0.2037632472692091}
2023-01-04 04:07:31,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:31,941 INFO:     Epoch: 66
2023-01-04 04:07:33,545 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.423744235932827, 'Total loss': 0.423744235932827} | train loss {'Reaction outcome loss': 0.20222662058440358, 'Total loss': 0.20222662058440358}
2023-01-04 04:07:33,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:33,545 INFO:     Epoch: 67
2023-01-04 04:07:35,151 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4264247059822083, 'Total loss': 0.4264247059822083} | train loss {'Reaction outcome loss': 0.20297119455808768, 'Total loss': 0.20297119455808768}
2023-01-04 04:07:35,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:35,151 INFO:     Epoch: 68
2023-01-04 04:07:36,747 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4291124234596888, 'Total loss': 0.4291124234596888} | train loss {'Reaction outcome loss': 0.1988225748580931, 'Total loss': 0.1988225748580931}
2023-01-04 04:07:36,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:36,747 INFO:     Epoch: 69
2023-01-04 04:07:38,356 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42636466920375826, 'Total loss': 0.42636466920375826} | train loss {'Reaction outcome loss': 0.1980075523633819, 'Total loss': 0.1980075523633819}
2023-01-04 04:07:38,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:38,356 INFO:     Epoch: 70
2023-01-04 04:07:39,954 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4230945686499278, 'Total loss': 0.4230945686499278} | train loss {'Reaction outcome loss': 0.19506968099233907, 'Total loss': 0.19506968099233907}
2023-01-04 04:07:39,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:39,955 INFO:     Epoch: 71
2023-01-04 04:07:41,546 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44983455538749695, 'Total loss': 0.44983455538749695} | train loss {'Reaction outcome loss': 0.19399508254246162, 'Total loss': 0.19399508254246162}
2023-01-04 04:07:41,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:41,547 INFO:     Epoch: 72
2023-01-04 04:07:43,178 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4557567030191422, 'Total loss': 0.4557567030191422} | train loss {'Reaction outcome loss': 0.19632995614129714, 'Total loss': 0.19632995614129714}
2023-01-04 04:07:43,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:43,178 INFO:     Epoch: 73
2023-01-04 04:07:44,812 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.425919301311175, 'Total loss': 0.425919301311175} | train loss {'Reaction outcome loss': 0.19277865985670675, 'Total loss': 0.19277865985670675}
2023-01-04 04:07:44,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:44,812 INFO:     Epoch: 74
2023-01-04 04:07:46,417 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4358580579360326, 'Total loss': 0.4358580579360326} | train loss {'Reaction outcome loss': 0.19185145351269184, 'Total loss': 0.19185145351269184}
2023-01-04 04:07:46,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:46,417 INFO:     Epoch: 75
2023-01-04 04:07:48,025 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41647183100382484, 'Total loss': 0.41647183100382484} | train loss {'Reaction outcome loss': 0.19238674813471332, 'Total loss': 0.19238674813471332}
2023-01-04 04:07:48,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:48,026 INFO:     Epoch: 76
2023-01-04 04:07:49,624 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4362077275911967, 'Total loss': 0.4362077275911967} | train loss {'Reaction outcome loss': 0.19223750507734744, 'Total loss': 0.19223750507734744}
2023-01-04 04:07:49,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:49,626 INFO:     Epoch: 77
2023-01-04 04:07:51,229 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43665858705838523, 'Total loss': 0.43665858705838523} | train loss {'Reaction outcome loss': 0.1896253729622394, 'Total loss': 0.1896253729622394}
2023-01-04 04:07:51,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:51,229 INFO:     Epoch: 78
2023-01-04 04:07:52,832 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4142563949028651, 'Total loss': 0.4142563949028651} | train loss {'Reaction outcome loss': 0.1883364599198103, 'Total loss': 0.1883364599198103}
2023-01-04 04:07:52,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:52,832 INFO:     Epoch: 79
2023-01-04 04:07:54,419 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4265073666969935, 'Total loss': 0.4265073666969935} | train loss {'Reaction outcome loss': 0.189221025938807, 'Total loss': 0.189221025938807}
2023-01-04 04:07:54,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:54,419 INFO:     Epoch: 80
2023-01-04 04:07:56,053 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4439659655094147, 'Total loss': 0.4439659655094147} | train loss {'Reaction outcome loss': 0.18664976716418127, 'Total loss': 0.18664976716418127}
2023-01-04 04:07:56,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:56,054 INFO:     Epoch: 81
2023-01-04 04:07:57,666 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4219409306844076, 'Total loss': 0.4219409306844076} | train loss {'Reaction outcome loss': 0.1851788647136641, 'Total loss': 0.1851788647136641}
2023-01-04 04:07:57,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:57,666 INFO:     Epoch: 82
2023-01-04 04:07:59,250 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43377384841442107, 'Total loss': 0.43377384841442107} | train loss {'Reaction outcome loss': 0.18109066778329952, 'Total loss': 0.18109066778329952}
2023-01-04 04:07:59,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:07:59,250 INFO:     Epoch: 83
2023-01-04 04:08:00,855 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45452045400937396, 'Total loss': 0.45452045400937396} | train loss {'Reaction outcome loss': 0.18155533952524192, 'Total loss': 0.18155533952524192}
2023-01-04 04:08:00,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:00,855 INFO:     Epoch: 84
2023-01-04 04:08:02,461 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4380286047856013, 'Total loss': 0.4380286047856013} | train loss {'Reaction outcome loss': 0.17960329883688195, 'Total loss': 0.17960329883688195}
2023-01-04 04:08:02,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:02,461 INFO:     Epoch: 85
2023-01-04 04:08:04,061 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4315959334373474, 'Total loss': 0.4315959334373474} | train loss {'Reaction outcome loss': 0.18180274017935194, 'Total loss': 0.18180274017935194}
2023-01-04 04:08:04,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:04,062 INFO:     Epoch: 86
2023-01-04 04:08:05,679 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4293331483999888, 'Total loss': 0.4293331483999888} | train loss {'Reaction outcome loss': 0.18101765749310328, 'Total loss': 0.18101765749310328}
2023-01-04 04:08:05,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:05,679 INFO:     Epoch: 87
2023-01-04 04:08:07,293 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4402619957923889, 'Total loss': 0.4402619957923889} | train loss {'Reaction outcome loss': 0.17915618496304814, 'Total loss': 0.17915618496304814}
2023-01-04 04:08:07,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:07,293 INFO:     Epoch: 88
2023-01-04 04:08:08,935 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.432245342930158, 'Total loss': 0.432245342930158} | train loss {'Reaction outcome loss': 0.1785460288169044, 'Total loss': 0.1785460288169044}
2023-01-04 04:08:08,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:08,936 INFO:     Epoch: 89
2023-01-04 04:08:10,571 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43189854025840757, 'Total loss': 0.43189854025840757} | train loss {'Reaction outcome loss': 0.18001204090939316, 'Total loss': 0.18001204090939316}
2023-01-04 04:08:10,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:10,571 INFO:     Epoch: 90
2023-01-04 04:08:12,182 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4180978407462438, 'Total loss': 0.4180978407462438} | train loss {'Reaction outcome loss': 0.18109762049969352, 'Total loss': 0.18109762049969352}
2023-01-04 04:08:12,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:12,182 INFO:     Epoch: 91
2023-01-04 04:08:13,808 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45452534755071006, 'Total loss': 0.45452534755071006} | train loss {'Reaction outcome loss': 0.17494455666452755, 'Total loss': 0.17494455666452755}
2023-01-04 04:08:13,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:13,808 INFO:     Epoch: 92
2023-01-04 04:08:15,432 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4351525475581487, 'Total loss': 0.4351525475581487} | train loss {'Reaction outcome loss': 0.17527332037875584, 'Total loss': 0.17527332037875584}
2023-01-04 04:08:15,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:15,432 INFO:     Epoch: 93
2023-01-04 04:08:17,020 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43333866198857623, 'Total loss': 0.43333866198857623} | train loss {'Reaction outcome loss': 0.17487547067851367, 'Total loss': 0.17487547067851367}
2023-01-04 04:08:17,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:17,020 INFO:     Epoch: 94
2023-01-04 04:08:18,624 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42716902097066245, 'Total loss': 0.42716902097066245} | train loss {'Reaction outcome loss': 0.17266356966555765, 'Total loss': 0.17266356966555765}
2023-01-04 04:08:18,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:18,625 INFO:     Epoch: 95
2023-01-04 04:08:20,228 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4339191978176435, 'Total loss': 0.4339191978176435} | train loss {'Reaction outcome loss': 0.1729911745724265, 'Total loss': 0.1729911745724265}
2023-01-04 04:08:20,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:20,229 INFO:     Epoch: 96
2023-01-04 04:08:21,824 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4384111156066259, 'Total loss': 0.4384111156066259} | train loss {'Reaction outcome loss': 0.17408745399666176, 'Total loss': 0.17408745399666176}
2023-01-04 04:08:21,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:21,824 INFO:     Epoch: 97
2023-01-04 04:08:23,431 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43551178673903146, 'Total loss': 0.43551178673903146} | train loss {'Reaction outcome loss': 0.17532289090031752, 'Total loss': 0.17532289090031752}
2023-01-04 04:08:23,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:23,431 INFO:     Epoch: 98
2023-01-04 04:08:25,052 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4315486033757528, 'Total loss': 0.4315486033757528} | train loss {'Reaction outcome loss': 0.17159882337123908, 'Total loss': 0.17159882337123908}
2023-01-04 04:08:25,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:25,052 INFO:     Epoch: 99
2023-01-04 04:08:26,664 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42563987473646797, 'Total loss': 0.42563987473646797} | train loss {'Reaction outcome loss': 0.171907244243454, 'Total loss': 0.171907244243454}
2023-01-04 04:08:26,665 INFO:     Best model found after epoch 51 of 100.
2023-01-04 04:08:26,665 INFO:   Done with stage: TRAINING
2023-01-04 04:08:26,665 INFO:   Starting stage: EVALUATION
2023-01-04 04:08:26,788 INFO:   Done with stage: EVALUATION
2023-01-04 04:08:26,789 INFO:   Leaving out SEQ value Fold_7
2023-01-04 04:08:26,801 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:08:26,801 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:08:27,448 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:08:27,448 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:08:27,515 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:08:27,515 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:08:27,515 INFO:     No hyperparam tuning for this model
2023-01-04 04:08:27,516 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:08:27,516 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:08:27,516 INFO:     None feature selector for col prot
2023-01-04 04:08:27,516 INFO:     None feature selector for col prot
2023-01-04 04:08:27,516 INFO:     None feature selector for col prot
2023-01-04 04:08:27,517 INFO:     None feature selector for col chem
2023-01-04 04:08:27,517 INFO:     None feature selector for col chem
2023-01-04 04:08:27,517 INFO:     None feature selector for col chem
2023-01-04 04:08:27,517 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:08:27,517 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:08:27,518 INFO:     Number of params in model 70141
2023-01-04 04:08:27,522 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:08:27,522 INFO:   Starting stage: TRAINING
2023-01-04 04:08:27,564 INFO:     Val loss before train {'Reaction outcome loss': 1.0239126404126486, 'Total loss': 1.0239126404126486}
2023-01-04 04:08:27,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:27,564 INFO:     Epoch: 0
2023-01-04 04:08:29,197 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7153631508350372, 'Total loss': 0.7153631508350372} | train loss {'Reaction outcome loss': 0.8367333961953325, 'Total loss': 0.8367333961953325}
2023-01-04 04:08:29,197 INFO:     Found new best model at epoch 0
2023-01-04 04:08:29,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:29,198 INFO:     Epoch: 1
2023-01-04 04:08:30,796 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.612288639942805, 'Total loss': 0.612288639942805} | train loss {'Reaction outcome loss': 0.5975564137262558, 'Total loss': 0.5975564137262558}
2023-01-04 04:08:30,796 INFO:     Found new best model at epoch 1
2023-01-04 04:08:30,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:30,797 INFO:     Epoch: 2
2023-01-04 04:08:32,429 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5774985949198405, 'Total loss': 0.5774985949198405} | train loss {'Reaction outcome loss': 0.529820861799192, 'Total loss': 0.529820861799192}
2023-01-04 04:08:32,429 INFO:     Found new best model at epoch 2
2023-01-04 04:08:32,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:32,430 INFO:     Epoch: 3
2023-01-04 04:08:34,034 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5699337303638459, 'Total loss': 0.5699337303638459} | train loss {'Reaction outcome loss': 0.49363577306700956, 'Total loss': 0.49363577306700956}
2023-01-04 04:08:34,035 INFO:     Found new best model at epoch 3
2023-01-04 04:08:34,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:34,036 INFO:     Epoch: 4
2023-01-04 04:08:35,640 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5351286431153616, 'Total loss': 0.5351286431153616} | train loss {'Reaction outcome loss': 0.46790473787147646, 'Total loss': 0.46790473787147646}
2023-01-04 04:08:35,640 INFO:     Found new best model at epoch 4
2023-01-04 04:08:35,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:35,641 INFO:     Epoch: 5
2023-01-04 04:08:37,243 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5240193208058676, 'Total loss': 0.5240193208058676} | train loss {'Reaction outcome loss': 0.44614567067003424, 'Total loss': 0.44614567067003424}
2023-01-04 04:08:37,244 INFO:     Found new best model at epoch 5
2023-01-04 04:08:37,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:37,244 INFO:     Epoch: 6
2023-01-04 04:08:38,824 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5237371782461803, 'Total loss': 0.5237371782461803} | train loss {'Reaction outcome loss': 0.4301842789464909, 'Total loss': 0.4301842789464909}
2023-01-04 04:08:38,825 INFO:     Found new best model at epoch 6
2023-01-04 04:08:38,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:38,825 INFO:     Epoch: 7
2023-01-04 04:08:40,435 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5067813952763875, 'Total loss': 0.5067813952763875} | train loss {'Reaction outcome loss': 0.4157490304230783, 'Total loss': 0.4157490304230783}
2023-01-04 04:08:40,435 INFO:     Found new best model at epoch 7
2023-01-04 04:08:40,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:40,436 INFO:     Epoch: 8
2023-01-04 04:08:42,032 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49405212004979454, 'Total loss': 0.49405212004979454} | train loss {'Reaction outcome loss': 0.4040158779935286, 'Total loss': 0.4040158779935286}
2023-01-04 04:08:42,032 INFO:     Found new best model at epoch 8
2023-01-04 04:08:42,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:42,033 INFO:     Epoch: 9
2023-01-04 04:08:43,626 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4847593426704407, 'Total loss': 0.4847593426704407} | train loss {'Reaction outcome loss': 0.3933750768646006, 'Total loss': 0.3933750768646006}
2023-01-04 04:08:43,626 INFO:     Found new best model at epoch 9
2023-01-04 04:08:43,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:43,627 INFO:     Epoch: 10
2023-01-04 04:08:45,226 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.497294012705485, 'Total loss': 0.497294012705485} | train loss {'Reaction outcome loss': 0.3869377540606024, 'Total loss': 0.3869377540606024}
2023-01-04 04:08:45,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:45,226 INFO:     Epoch: 11
2023-01-04 04:08:46,826 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47065829038619994, 'Total loss': 0.47065829038619994} | train loss {'Reaction outcome loss': 0.37502267601687983, 'Total loss': 0.37502267601687983}
2023-01-04 04:08:46,826 INFO:     Found new best model at epoch 11
2023-01-04 04:08:46,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:46,827 INFO:     Epoch: 12
2023-01-04 04:08:48,428 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4652060965696971, 'Total loss': 0.4652060965696971} | train loss {'Reaction outcome loss': 0.36730529523928673, 'Total loss': 0.36730529523928673}
2023-01-04 04:08:48,428 INFO:     Found new best model at epoch 12
2023-01-04 04:08:48,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:48,429 INFO:     Epoch: 13
2023-01-04 04:08:50,063 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47889883518218995, 'Total loss': 0.47889883518218995} | train loss {'Reaction outcome loss': 0.3596300950226801, 'Total loss': 0.3596300950226801}
2023-01-04 04:08:50,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:50,063 INFO:     Epoch: 14
2023-01-04 04:08:51,683 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4481476038694382, 'Total loss': 0.4481476038694382} | train loss {'Reaction outcome loss': 0.35251509704852363, 'Total loss': 0.35251509704852363}
2023-01-04 04:08:51,683 INFO:     Found new best model at epoch 14
2023-01-04 04:08:51,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:51,684 INFO:     Epoch: 15
2023-01-04 04:08:53,275 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4614539702733358, 'Total loss': 0.4614539702733358} | train loss {'Reaction outcome loss': 0.348073457364356, 'Total loss': 0.348073457364356}
2023-01-04 04:08:53,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:53,275 INFO:     Epoch: 16
2023-01-04 04:08:54,912 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4552151660124461, 'Total loss': 0.4552151660124461} | train loss {'Reaction outcome loss': 0.33999485530577844, 'Total loss': 0.33999485530577844}
2023-01-04 04:08:54,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:54,912 INFO:     Epoch: 17
2023-01-04 04:08:56,538 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4609739750623703, 'Total loss': 0.4609739750623703} | train loss {'Reaction outcome loss': 0.33278886215351117, 'Total loss': 0.33278886215351117}
2023-01-04 04:08:56,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:56,539 INFO:     Epoch: 18
2023-01-04 04:08:58,129 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4697625130414963, 'Total loss': 0.4697625130414963} | train loss {'Reaction outcome loss': 0.3245898605953055, 'Total loss': 0.3245898605953055}
2023-01-04 04:08:58,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:58,129 INFO:     Epoch: 19
2023-01-04 04:08:59,765 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44539405902226764, 'Total loss': 0.44539405902226764} | train loss {'Reaction outcome loss': 0.32119634142313624, 'Total loss': 0.32119634142313624}
2023-01-04 04:08:59,765 INFO:     Found new best model at epoch 19
2023-01-04 04:08:59,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:08:59,766 INFO:     Epoch: 20
2023-01-04 04:09:01,348 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45216075976689657, 'Total loss': 0.45216075976689657} | train loss {'Reaction outcome loss': 0.3162611619391166, 'Total loss': 0.3162611619391166}
2023-01-04 04:09:01,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:01,349 INFO:     Epoch: 21
2023-01-04 04:09:02,942 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.446668367087841, 'Total loss': 0.446668367087841} | train loss {'Reaction outcome loss': 0.31198261783118714, 'Total loss': 0.31198261783118714}
2023-01-04 04:09:02,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:02,943 INFO:     Epoch: 22
2023-01-04 04:09:04,571 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4739321360985438, 'Total loss': 0.4739321360985438} | train loss {'Reaction outcome loss': 0.30606193923885644, 'Total loss': 0.30606193923885644}
2023-01-04 04:09:04,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:04,571 INFO:     Epoch: 23
2023-01-04 04:09:06,181 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4593786795934041, 'Total loss': 0.4593786795934041} | train loss {'Reaction outcome loss': 0.3002683800588016, 'Total loss': 0.3002683800588016}
2023-01-04 04:09:06,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:06,182 INFO:     Epoch: 24
2023-01-04 04:09:07,784 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47591779232025144, 'Total loss': 0.47591779232025144} | train loss {'Reaction outcome loss': 0.296024436366472, 'Total loss': 0.296024436366472}
2023-01-04 04:09:07,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:07,785 INFO:     Epoch: 25
2023-01-04 04:09:09,388 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4541950603326162, 'Total loss': 0.4541950603326162} | train loss {'Reaction outcome loss': 0.2906814277010704, 'Total loss': 0.2906814277010704}
2023-01-04 04:09:09,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:09,388 INFO:     Epoch: 26
2023-01-04 04:09:10,975 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4448111206293106, 'Total loss': 0.4448111206293106} | train loss {'Reaction outcome loss': 0.28544005670917594, 'Total loss': 0.28544005670917594}
2023-01-04 04:09:10,976 INFO:     Found new best model at epoch 26
2023-01-04 04:09:10,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:10,976 INFO:     Epoch: 27
2023-01-04 04:09:12,579 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4698809117078781, 'Total loss': 0.4698809117078781} | train loss {'Reaction outcome loss': 0.2844947809185362, 'Total loss': 0.2844947809185362}
2023-01-04 04:09:12,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:12,579 INFO:     Epoch: 28
2023-01-04 04:09:14,198 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47570035060246785, 'Total loss': 0.47570035060246785} | train loss {'Reaction outcome loss': 0.2792467092725344, 'Total loss': 0.2792467092725344}
2023-01-04 04:09:14,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:14,198 INFO:     Epoch: 29
2023-01-04 04:09:15,775 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4513227542241414, 'Total loss': 0.4513227542241414} | train loss {'Reaction outcome loss': 0.27228058460387083, 'Total loss': 0.27228058460387083}
2023-01-04 04:09:15,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:15,776 INFO:     Epoch: 30
2023-01-04 04:09:17,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.458848496278127, 'Total loss': 0.458848496278127} | train loss {'Reaction outcome loss': 0.27210440377735057, 'Total loss': 0.27210440377735057}
2023-01-04 04:09:17,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:17,414 INFO:     Epoch: 31
2023-01-04 04:09:19,022 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46074428061644235, 'Total loss': 0.46074428061644235} | train loss {'Reaction outcome loss': 0.26702545112543585, 'Total loss': 0.26702545112543585}
2023-01-04 04:09:19,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:19,022 INFO:     Epoch: 32
2023-01-04 04:09:20,652 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4656974673271179, 'Total loss': 0.4656974673271179} | train loss {'Reaction outcome loss': 0.2654609650992099, 'Total loss': 0.2654609650992099}
2023-01-04 04:09:20,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:20,653 INFO:     Epoch: 33
2023-01-04 04:09:22,258 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4662512749433517, 'Total loss': 0.4662512749433517} | train loss {'Reaction outcome loss': 0.2582073119142856, 'Total loss': 0.2582073119142856}
2023-01-04 04:09:22,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:22,258 INFO:     Epoch: 34
2023-01-04 04:09:23,850 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4493757426738739, 'Total loss': 0.4493757426738739} | train loss {'Reaction outcome loss': 0.25568517179157757, 'Total loss': 0.25568517179157757}
2023-01-04 04:09:23,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:23,850 INFO:     Epoch: 35
2023-01-04 04:09:25,453 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46862675348917643, 'Total loss': 0.46862675348917643} | train loss {'Reaction outcome loss': 0.2530606882882032, 'Total loss': 0.2530606882882032}
2023-01-04 04:09:25,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:25,453 INFO:     Epoch: 36
2023-01-04 04:09:27,057 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4767957925796509, 'Total loss': 0.4767957925796509} | train loss {'Reaction outcome loss': 0.2504659283247235, 'Total loss': 0.2504659283247235}
2023-01-04 04:09:27,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:27,057 INFO:     Epoch: 37
2023-01-04 04:09:28,638 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46022957265377046, 'Total loss': 0.46022957265377046} | train loss {'Reaction outcome loss': 0.24593512169236742, 'Total loss': 0.24593512169236742}
2023-01-04 04:09:28,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:28,638 INFO:     Epoch: 38
2023-01-04 04:09:30,264 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46309325893719994, 'Total loss': 0.46309325893719994} | train loss {'Reaction outcome loss': 0.24458019935697425, 'Total loss': 0.24458019935697425}
2023-01-04 04:09:30,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:30,265 INFO:     Epoch: 39
2023-01-04 04:09:31,891 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47323158383369446, 'Total loss': 0.47323158383369446} | train loss {'Reaction outcome loss': 0.24338042329902684, 'Total loss': 0.24338042329902684}
2023-01-04 04:09:31,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:31,891 INFO:     Epoch: 40
2023-01-04 04:09:33,505 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4610219419002533, 'Total loss': 0.4610219419002533} | train loss {'Reaction outcome loss': 0.23959610981039622, 'Total loss': 0.23959610981039622}
2023-01-04 04:09:33,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:33,505 INFO:     Epoch: 41
2023-01-04 04:09:35,143 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4720291296641032, 'Total loss': 0.4720291296641032} | train loss {'Reaction outcome loss': 0.2377335864929516, 'Total loss': 0.2377335864929516}
2023-01-04 04:09:35,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:35,144 INFO:     Epoch: 42
2023-01-04 04:09:36,760 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4715863972902298, 'Total loss': 0.4715863972902298} | train loss {'Reaction outcome loss': 0.23560492660756147, 'Total loss': 0.23560492660756147}
2023-01-04 04:09:36,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:36,760 INFO:     Epoch: 43
2023-01-04 04:09:38,364 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4595092495282491, 'Total loss': 0.4595092495282491} | train loss {'Reaction outcome loss': 0.23047009123899445, 'Total loss': 0.23047009123899445}
2023-01-04 04:09:38,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:38,365 INFO:     Epoch: 44
2023-01-04 04:09:39,968 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46618178486824036, 'Total loss': 0.46618178486824036} | train loss {'Reaction outcome loss': 0.23036834203540632, 'Total loss': 0.23036834203540632}
2023-01-04 04:09:39,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:39,969 INFO:     Epoch: 45
2023-01-04 04:09:41,559 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4470770925283432, 'Total loss': 0.4470770925283432} | train loss {'Reaction outcome loss': 0.2285806100398625, 'Total loss': 0.2285806100398625}
2023-01-04 04:09:41,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:41,559 INFO:     Epoch: 46
2023-01-04 04:09:43,186 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46455274522304535, 'Total loss': 0.46455274522304535} | train loss {'Reaction outcome loss': 0.22654429562255363, 'Total loss': 0.22654429562255363}
2023-01-04 04:09:43,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:43,186 INFO:     Epoch: 47
2023-01-04 04:09:44,821 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4970729649066925, 'Total loss': 0.4970729649066925} | train loss {'Reaction outcome loss': 0.22312559512870836, 'Total loss': 0.22312559512870836}
2023-01-04 04:09:44,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:44,822 INFO:     Epoch: 48
2023-01-04 04:09:46,400 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4796685934066772, 'Total loss': 0.4796685934066772} | train loss {'Reaction outcome loss': 0.2206080327153421, 'Total loss': 0.2206080327153421}
2023-01-04 04:09:46,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:46,400 INFO:     Epoch: 49
2023-01-04 04:09:48,030 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47563894192377726, 'Total loss': 0.47563894192377726} | train loss {'Reaction outcome loss': 0.2190605470312201, 'Total loss': 0.2190605470312201}
2023-01-04 04:09:48,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:48,031 INFO:     Epoch: 50
2023-01-04 04:09:49,660 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4835579261183739, 'Total loss': 0.4835579261183739} | train loss {'Reaction outcome loss': 0.21672661649567557, 'Total loss': 0.21672661649567557}
2023-01-04 04:09:49,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:49,660 INFO:     Epoch: 51
2023-01-04 04:09:51,258 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.478836985429128, 'Total loss': 0.478836985429128} | train loss {'Reaction outcome loss': 0.21368447736927748, 'Total loss': 0.21368447736927748}
2023-01-04 04:09:51,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:51,258 INFO:     Epoch: 52
2023-01-04 04:09:52,888 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49630730152130126, 'Total loss': 0.49630730152130126} | train loss {'Reaction outcome loss': 0.21107633430712489, 'Total loss': 0.21107633430712489}
2023-01-04 04:09:52,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:52,889 INFO:     Epoch: 53
2023-01-04 04:09:54,498 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4838458379109701, 'Total loss': 0.4838458379109701} | train loss {'Reaction outcome loss': 0.2138558941210758, 'Total loss': 0.2138558941210758}
2023-01-04 04:09:54,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:54,498 INFO:     Epoch: 54
2023-01-04 04:09:56,068 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45593104561169945, 'Total loss': 0.45593104561169945} | train loss {'Reaction outcome loss': 0.2100334568050041, 'Total loss': 0.2100334568050041}
2023-01-04 04:09:56,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:56,068 INFO:     Epoch: 55
2023-01-04 04:09:57,695 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4768377015988032, 'Total loss': 0.4768377015988032} | train loss {'Reaction outcome loss': 0.2078978390927134, 'Total loss': 0.2078978390927134}
2023-01-04 04:09:57,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:57,696 INFO:     Epoch: 56
2023-01-04 04:09:59,276 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46514024436473844, 'Total loss': 0.46514024436473844} | train loss {'Reaction outcome loss': 0.2070887988493761, 'Total loss': 0.2070887988493761}
2023-01-04 04:09:59,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:09:59,277 INFO:     Epoch: 57
2023-01-04 04:10:00,420 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45986628929773965, 'Total loss': 0.45986628929773965} | train loss {'Reaction outcome loss': 0.20709075153358147, 'Total loss': 0.20709075153358147}
2023-01-04 04:10:00,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:00,420 INFO:     Epoch: 58
2023-01-04 04:10:01,486 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48168767293294273, 'Total loss': 0.48168767293294273} | train loss {'Reaction outcome loss': 0.20383333022090933, 'Total loss': 0.20383333022090933}
2023-01-04 04:10:01,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:01,486 INFO:     Epoch: 59
2023-01-04 04:10:02,561 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4927197555700938, 'Total loss': 0.4927197555700938} | train loss {'Reaction outcome loss': 0.2007298873138987, 'Total loss': 0.2007298873138987}
2023-01-04 04:10:02,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:02,561 INFO:     Epoch: 60
2023-01-04 04:10:03,629 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4693837990363439, 'Total loss': 0.4693837990363439} | train loss {'Reaction outcome loss': 0.20266352424445136, 'Total loss': 0.20266352424445136}
2023-01-04 04:10:03,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:03,630 INFO:     Epoch: 61
2023-01-04 04:10:05,223 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48112485905488334, 'Total loss': 0.48112485905488334} | train loss {'Reaction outcome loss': 0.20015295440943018, 'Total loss': 0.20015295440943018}
2023-01-04 04:10:05,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:05,223 INFO:     Epoch: 62
2023-01-04 04:10:06,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4877925137678782, 'Total loss': 0.4877925137678782} | train loss {'Reaction outcome loss': 0.19849943513528104, 'Total loss': 0.19849943513528104}
2023-01-04 04:10:06,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:06,856 INFO:     Epoch: 63
2023-01-04 04:10:08,484 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4855753521124522, 'Total loss': 0.4855753521124522} | train loss {'Reaction outcome loss': 0.1957200436654504, 'Total loss': 0.1957200436654504}
2023-01-04 04:10:08,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:08,484 INFO:     Epoch: 64
2023-01-04 04:10:10,062 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49020623912413913, 'Total loss': 0.49020623912413913} | train loss {'Reaction outcome loss': 0.1971504386070618, 'Total loss': 0.1971504386070618}
2023-01-04 04:10:10,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:10,063 INFO:     Epoch: 65
2023-01-04 04:10:11,628 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4990866939226786, 'Total loss': 0.4990866939226786} | train loss {'Reaction outcome loss': 0.19512888635861744, 'Total loss': 0.19512888635861744}
2023-01-04 04:10:11,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:11,628 INFO:     Epoch: 66
2023-01-04 04:10:13,220 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44948503077030183, 'Total loss': 0.44948503077030183} | train loss {'Reaction outcome loss': 0.19399596941707797, 'Total loss': 0.19399596941707797}
2023-01-04 04:10:13,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:13,222 INFO:     Epoch: 67
2023-01-04 04:10:14,843 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4742459893226624, 'Total loss': 0.4742459893226624} | train loss {'Reaction outcome loss': 0.1932101134977401, 'Total loss': 0.1932101134977401}
2023-01-04 04:10:14,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:14,843 INFO:     Epoch: 68
2023-01-04 04:10:16,473 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47651262283325196, 'Total loss': 0.47651262283325196} | train loss {'Reaction outcome loss': 0.1928916820778851, 'Total loss': 0.1928916820778851}
2023-01-04 04:10:16,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:16,474 INFO:     Epoch: 69
2023-01-04 04:10:18,103 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48100287318229673, 'Total loss': 0.48100287318229673} | train loss {'Reaction outcome loss': 0.19122870698140848, 'Total loss': 0.19122870698140848}
2023-01-04 04:10:18,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:18,103 INFO:     Epoch: 70
2023-01-04 04:10:19,705 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4817880421876907, 'Total loss': 0.4817880421876907} | train loss {'Reaction outcome loss': 0.1885784843580172, 'Total loss': 0.1885784843580172}
2023-01-04 04:10:19,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:19,706 INFO:     Epoch: 71
2023-01-04 04:10:21,303 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4961804707845052, 'Total loss': 0.4961804707845052} | train loss {'Reaction outcome loss': 0.18695362354712797, 'Total loss': 0.18695362354712797}
2023-01-04 04:10:21,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:21,303 INFO:     Epoch: 72
2023-01-04 04:10:22,904 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4913222759962082, 'Total loss': 0.4913222759962082} | train loss {'Reaction outcome loss': 0.19151642912534816, 'Total loss': 0.19151642912534816}
2023-01-04 04:10:22,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:22,904 INFO:     Epoch: 73
2023-01-04 04:10:24,532 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4946789632240931, 'Total loss': 0.4946789632240931} | train loss {'Reaction outcome loss': 0.18539280027473876, 'Total loss': 0.18539280027473876}
2023-01-04 04:10:24,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:24,532 INFO:     Epoch: 74
2023-01-04 04:10:26,163 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4688310851653417, 'Total loss': 0.4688310851653417} | train loss {'Reaction outcome loss': 0.1844864825681121, 'Total loss': 0.1844864825681121}
2023-01-04 04:10:26,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:26,164 INFO:     Epoch: 75
2023-01-04 04:10:27,797 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5221682091554006, 'Total loss': 0.5221682091554006} | train loss {'Reaction outcome loss': 0.1851359272530363, 'Total loss': 0.1851359272530363}
2023-01-04 04:10:27,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:27,797 INFO:     Epoch: 76
2023-01-04 04:10:29,398 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4857844273249308, 'Total loss': 0.4857844273249308} | train loss {'Reaction outcome loss': 0.18786359451953255, 'Total loss': 0.18786359451953255}
2023-01-04 04:10:29,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:29,398 INFO:     Epoch: 77
2023-01-04 04:10:30,981 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49263253609339397, 'Total loss': 0.49263253609339397} | train loss {'Reaction outcome loss': 0.18314031655446286, 'Total loss': 0.18314031655446286}
2023-01-04 04:10:30,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:30,981 INFO:     Epoch: 78
2023-01-04 04:10:32,611 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4828625003496806, 'Total loss': 0.4828625003496806} | train loss {'Reaction outcome loss': 0.1834897414280189, 'Total loss': 0.1834897414280189}
2023-01-04 04:10:32,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:32,612 INFO:     Epoch: 79
2023-01-04 04:10:34,200 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5034328162670135, 'Total loss': 0.5034328162670135} | train loss {'Reaction outcome loss': 0.18288742009859654, 'Total loss': 0.18288742009859654}
2023-01-04 04:10:34,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:34,200 INFO:     Epoch: 80
2023-01-04 04:10:35,830 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5060759802659353, 'Total loss': 0.5060759802659353} | train loss {'Reaction outcome loss': 0.1822463857473987, 'Total loss': 0.1822463857473987}
2023-01-04 04:10:35,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:35,831 INFO:     Epoch: 81
2023-01-04 04:10:37,447 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4910318717360497, 'Total loss': 0.4910318717360497} | train loss {'Reaction outcome loss': 0.17958057638836036, 'Total loss': 0.17958057638836036}
2023-01-04 04:10:37,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:37,447 INFO:     Epoch: 82
2023-01-04 04:10:39,047 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4997773617506027, 'Total loss': 0.4997773617506027} | train loss {'Reaction outcome loss': 0.17704757347380212, 'Total loss': 0.17704757347380212}
2023-01-04 04:10:39,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:39,048 INFO:     Epoch: 83
2023-01-04 04:10:40,659 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5173548450072606, 'Total loss': 0.5173548450072606} | train loss {'Reaction outcome loss': 0.1800621766260815, 'Total loss': 0.1800621766260815}
2023-01-04 04:10:40,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:40,660 INFO:     Epoch: 84
2023-01-04 04:10:42,293 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49227717717488606, 'Total loss': 0.49227717717488606} | train loss {'Reaction outcome loss': 0.17993975875879023, 'Total loss': 0.17993975875879023}
2023-01-04 04:10:42,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:42,293 INFO:     Epoch: 85
2023-01-04 04:10:43,906 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47791207234064736, 'Total loss': 0.47791207234064736} | train loss {'Reaction outcome loss': 0.17752032126518577, 'Total loss': 0.17752032126518577}
2023-01-04 04:10:43,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:43,907 INFO:     Epoch: 86
2023-01-04 04:10:45,489 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49782628417015073, 'Total loss': 0.49782628417015073} | train loss {'Reaction outcome loss': 0.17762100005300466, 'Total loss': 0.17762100005300466}
2023-01-04 04:10:45,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:45,489 INFO:     Epoch: 87
2023-01-04 04:10:47,094 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4992760439713796, 'Total loss': 0.4992760439713796} | train loss {'Reaction outcome loss': 0.17677531357760465, 'Total loss': 0.17677531357760465}
2023-01-04 04:10:47,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:47,094 INFO:     Epoch: 88
2023-01-04 04:10:48,688 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4906251241763433, 'Total loss': 0.4906251241763433} | train loss {'Reaction outcome loss': 0.17742174890040274, 'Total loss': 0.17742174890040274}
2023-01-04 04:10:48,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:48,689 INFO:     Epoch: 89
2023-01-04 04:10:50,301 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49120986759662627, 'Total loss': 0.49120986759662627} | train loss {'Reaction outcome loss': 0.175912216406598, 'Total loss': 0.175912216406598}
2023-01-04 04:10:50,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:50,302 INFO:     Epoch: 90
2023-01-04 04:10:51,886 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5107396225134532, 'Total loss': 0.5107396225134532} | train loss {'Reaction outcome loss': 0.17316977053019975, 'Total loss': 0.17316977053019975}
2023-01-04 04:10:51,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:51,886 INFO:     Epoch: 91
2023-01-04 04:10:53,511 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4931262989838918, 'Total loss': 0.4931262989838918} | train loss {'Reaction outcome loss': 0.17466233646503854, 'Total loss': 0.17466233646503854}
2023-01-04 04:10:53,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:53,511 INFO:     Epoch: 92
2023-01-04 04:10:55,134 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4813240776459376, 'Total loss': 0.4813240776459376} | train loss {'Reaction outcome loss': 0.17396345614902808, 'Total loss': 0.17396345614902808}
2023-01-04 04:10:55,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:55,134 INFO:     Epoch: 93
2023-01-04 04:10:56,707 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.492701115210851, 'Total loss': 0.492701115210851} | train loss {'Reaction outcome loss': 0.1731069437648415, 'Total loss': 0.1731069437648415}
2023-01-04 04:10:56,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:56,707 INFO:     Epoch: 94
2023-01-04 04:10:58,312 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4886820531139771, 'Total loss': 0.4886820531139771} | train loss {'Reaction outcome loss': 0.17114220877658803, 'Total loss': 0.17114220877658803}
2023-01-04 04:10:58,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:58,312 INFO:     Epoch: 95
2023-01-04 04:10:59,956 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5099176049232483, 'Total loss': 0.5099176049232483} | train loss {'Reaction outcome loss': 0.17034060708398424, 'Total loss': 0.17034060708398424}
2023-01-04 04:10:59,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:10:59,956 INFO:     Epoch: 96
2023-01-04 04:11:01,596 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4832208181420962, 'Total loss': 0.4832208181420962} | train loss {'Reaction outcome loss': 0.1734891191851146, 'Total loss': 0.1734891191851146}
2023-01-04 04:11:01,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:01,597 INFO:     Epoch: 97
2023-01-04 04:11:03,184 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5270376880963643, 'Total loss': 0.5270376880963643} | train loss {'Reaction outcome loss': 0.17252264693648375, 'Total loss': 0.17252264693648375}
2023-01-04 04:11:03,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:03,185 INFO:     Epoch: 98
2023-01-04 04:11:04,791 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49771561423937477, 'Total loss': 0.49771561423937477} | train loss {'Reaction outcome loss': 0.17095105614956965, 'Total loss': 0.17095105614956965}
2023-01-04 04:11:04,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:04,792 INFO:     Epoch: 99
2023-01-04 04:11:06,394 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5268311371405919, 'Total loss': 0.5268311371405919} | train loss {'Reaction outcome loss': 0.17211930874721668, 'Total loss': 0.17211930874721668}
2023-01-04 04:11:06,395 INFO:     Best model found after epoch 27 of 100.
2023-01-04 04:11:06,395 INFO:   Done with stage: TRAINING
2023-01-04 04:11:06,395 INFO:   Starting stage: EVALUATION
2023-01-04 04:11:06,518 INFO:   Done with stage: EVALUATION
2023-01-04 04:11:06,518 INFO:   Leaving out SEQ value Fold_8
2023-01-04 04:11:06,530 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:11:06,530 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:11:07,179 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:11:07,179 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:11:07,246 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:11:07,246 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:11:07,246 INFO:     No hyperparam tuning for this model
2023-01-04 04:11:07,246 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:11:07,246 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:11:07,247 INFO:     None feature selector for col prot
2023-01-04 04:11:07,247 INFO:     None feature selector for col prot
2023-01-04 04:11:07,247 INFO:     None feature selector for col prot
2023-01-04 04:11:07,248 INFO:     None feature selector for col chem
2023-01-04 04:11:07,248 INFO:     None feature selector for col chem
2023-01-04 04:11:07,248 INFO:     None feature selector for col chem
2023-01-04 04:11:07,248 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:11:07,248 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:11:07,249 INFO:     Number of params in model 70141
2023-01-04 04:11:07,252 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:11:07,253 INFO:   Starting stage: TRAINING
2023-01-04 04:11:07,297 INFO:     Val loss before train {'Reaction outcome loss': 0.9667797327041626, 'Total loss': 0.9667797327041626}
2023-01-04 04:11:07,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:07,297 INFO:     Epoch: 0
2023-01-04 04:11:08,884 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6601151804129283, 'Total loss': 0.6601151804129283} | train loss {'Reaction outcome loss': 0.8413445301076813, 'Total loss': 0.8413445301076813}
2023-01-04 04:11:08,884 INFO:     Found new best model at epoch 0
2023-01-04 04:11:08,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:08,885 INFO:     Epoch: 1
2023-01-04 04:11:10,463 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5450106124083202, 'Total loss': 0.5450106124083202} | train loss {'Reaction outcome loss': 0.6050002580724548, 'Total loss': 0.6050002580724548}
2023-01-04 04:11:10,463 INFO:     Found new best model at epoch 1
2023-01-04 04:11:10,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:10,464 INFO:     Epoch: 2
2023-01-04 04:11:12,040 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5094712595144908, 'Total loss': 0.5094712595144908} | train loss {'Reaction outcome loss': 0.518383454227739, 'Total loss': 0.518383454227739}
2023-01-04 04:11:12,040 INFO:     Found new best model at epoch 2
2023-01-04 04:11:12,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:12,041 INFO:     Epoch: 3
2023-01-04 04:11:13,617 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4880637149016062, 'Total loss': 0.4880637149016062} | train loss {'Reaction outcome loss': 0.4792191134090873, 'Total loss': 0.4792191134090873}
2023-01-04 04:11:13,617 INFO:     Found new best model at epoch 3
2023-01-04 04:11:13,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:13,618 INFO:     Epoch: 4
2023-01-04 04:11:15,234 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47430324256420137, 'Total loss': 0.47430324256420137} | train loss {'Reaction outcome loss': 0.45115922708604217, 'Total loss': 0.45115922708604217}
2023-01-04 04:11:15,235 INFO:     Found new best model at epoch 4
2023-01-04 04:11:15,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:15,236 INFO:     Epoch: 5
2023-01-04 04:11:16,798 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4871522655089696, 'Total loss': 0.4871522655089696} | train loss {'Reaction outcome loss': 0.4309194515378255, 'Total loss': 0.4309194515378255}
2023-01-04 04:11:16,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:16,798 INFO:     Epoch: 6
2023-01-04 04:11:18,420 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4730992515881856, 'Total loss': 0.4730992515881856} | train loss {'Reaction outcome loss': 0.41778351814634557, 'Total loss': 0.41778351814634557}
2023-01-04 04:11:18,420 INFO:     Found new best model at epoch 6
2023-01-04 04:11:18,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:18,421 INFO:     Epoch: 7
2023-01-04 04:11:20,037 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45990347464879355, 'Total loss': 0.45990347464879355} | train loss {'Reaction outcome loss': 0.4066257377465566, 'Total loss': 0.4066257377465566}
2023-01-04 04:11:20,037 INFO:     Found new best model at epoch 7
2023-01-04 04:11:20,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:20,038 INFO:     Epoch: 8
2023-01-04 04:11:21,651 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4630573183298111, 'Total loss': 0.4630573183298111} | train loss {'Reaction outcome loss': 0.3956916837318652, 'Total loss': 0.3956916837318652}
2023-01-04 04:11:21,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:21,652 INFO:     Epoch: 9
2023-01-04 04:11:23,249 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4687644004821777, 'Total loss': 0.4687644004821777} | train loss {'Reaction outcome loss': 0.3868256159450697, 'Total loss': 0.3868256159450697}
2023-01-04 04:11:23,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:23,249 INFO:     Epoch: 10
2023-01-04 04:11:24,840 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4564370930194855, 'Total loss': 0.4564370930194855} | train loss {'Reaction outcome loss': 0.37682649194924295, 'Total loss': 0.37682649194924295}
2023-01-04 04:11:24,841 INFO:     Found new best model at epoch 10
2023-01-04 04:11:24,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:24,841 INFO:     Epoch: 11
2023-01-04 04:11:26,433 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4460920512676239, 'Total loss': 0.4460920512676239} | train loss {'Reaction outcome loss': 0.36782266836751765, 'Total loss': 0.36782266836751765}
2023-01-04 04:11:26,433 INFO:     Found new best model at epoch 11
2023-01-04 04:11:26,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:26,434 INFO:     Epoch: 12
2023-01-04 04:11:28,027 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45557538866996766, 'Total loss': 0.45557538866996766} | train loss {'Reaction outcome loss': 0.3589337666829427, 'Total loss': 0.3589337666829427}
2023-01-04 04:11:28,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:28,027 INFO:     Epoch: 13
2023-01-04 04:11:29,620 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4527760982513428, 'Total loss': 0.4527760982513428} | train loss {'Reaction outcome loss': 0.35341431427261105, 'Total loss': 0.35341431427261105}
2023-01-04 04:11:29,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:29,621 INFO:     Epoch: 14
2023-01-04 04:11:31,198 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4622957229614258, 'Total loss': 0.4622957229614258} | train loss {'Reaction outcome loss': 0.3501565495271411, 'Total loss': 0.3501565495271411}
2023-01-04 04:11:31,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:31,198 INFO:     Epoch: 15
2023-01-04 04:11:32,791 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42573050322631995, 'Total loss': 0.42573050322631995} | train loss {'Reaction outcome loss': 0.33812374343489593, 'Total loss': 0.33812374343489593}
2023-01-04 04:11:32,792 INFO:     Found new best model at epoch 15
2023-01-04 04:11:32,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:32,792 INFO:     Epoch: 16
2023-01-04 04:11:34,391 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43376509050528206, 'Total loss': 0.43376509050528206} | train loss {'Reaction outcome loss': 0.33292774495920097, 'Total loss': 0.33292774495920097}
2023-01-04 04:11:34,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:34,392 INFO:     Epoch: 17
2023-01-04 04:11:35,989 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4613067666689555, 'Total loss': 0.4613067666689555} | train loss {'Reaction outcome loss': 0.3262322197087865, 'Total loss': 0.3262322197087865}
2023-01-04 04:11:35,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:35,989 INFO:     Epoch: 18
2023-01-04 04:11:37,569 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43754603266716, 'Total loss': 0.43754603266716} | train loss {'Reaction outcome loss': 0.3217779020981296, 'Total loss': 0.3217779020981296}
2023-01-04 04:11:37,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:37,569 INFO:     Epoch: 19
2023-01-04 04:11:39,144 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43641863465309144, 'Total loss': 0.43641863465309144} | train loss {'Reaction outcome loss': 0.31553747041312896, 'Total loss': 0.31553747041312896}
2023-01-04 04:11:39,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:39,145 INFO:     Epoch: 20
2023-01-04 04:11:40,745 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43097241322199503, 'Total loss': 0.43097241322199503} | train loss {'Reaction outcome loss': 0.3100856135504833, 'Total loss': 0.3100856135504833}
2023-01-04 04:11:40,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:40,745 INFO:     Epoch: 21
2023-01-04 04:11:42,350 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4385116895039876, 'Total loss': 0.4385116895039876} | train loss {'Reaction outcome loss': 0.3080445429229218, 'Total loss': 0.3080445429229218}
2023-01-04 04:11:42,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:42,350 INFO:     Epoch: 22
2023-01-04 04:11:43,941 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42848378519217173, 'Total loss': 0.42848378519217173} | train loss {'Reaction outcome loss': 0.30143643339313025, 'Total loss': 0.30143643339313025}
2023-01-04 04:11:43,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:43,941 INFO:     Epoch: 23
2023-01-04 04:11:45,534 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43320683638254803, 'Total loss': 0.43320683638254803} | train loss {'Reaction outcome loss': 0.29730880627127354, 'Total loss': 0.29730880627127354}
2023-01-04 04:11:45,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:45,534 INFO:     Epoch: 24
2023-01-04 04:11:47,126 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45339813033739723, 'Total loss': 0.45339813033739723} | train loss {'Reaction outcome loss': 0.2939382569621439, 'Total loss': 0.2939382569621439}
2023-01-04 04:11:47,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:47,126 INFO:     Epoch: 25
2023-01-04 04:11:48,706 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45605635941028594, 'Total loss': 0.45605635941028594} | train loss {'Reaction outcome loss': 0.28979988433285686, 'Total loss': 0.28979988433285686}
2023-01-04 04:11:48,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:48,706 INFO:     Epoch: 26
2023-01-04 04:11:50,296 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43376023272673286, 'Total loss': 0.43376023272673286} | train loss {'Reaction outcome loss': 0.2868226019428761, 'Total loss': 0.2868226019428761}
2023-01-04 04:11:50,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:50,297 INFO:     Epoch: 27
2023-01-04 04:11:51,869 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4298020700613658, 'Total loss': 0.4298020700613658} | train loss {'Reaction outcome loss': 0.28016369787814177, 'Total loss': 0.28016369787814177}
2023-01-04 04:11:51,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:51,869 INFO:     Epoch: 28
2023-01-04 04:11:53,494 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44268926680088044, 'Total loss': 0.44268926680088044} | train loss {'Reaction outcome loss': 0.28344938048310037, 'Total loss': 0.28344938048310037}
2023-01-04 04:11:53,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:53,494 INFO:     Epoch: 29
2023-01-04 04:11:55,115 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4499292433261871, 'Total loss': 0.4499292433261871} | train loss {'Reaction outcome loss': 0.2861776471009775, 'Total loss': 0.2861776471009775}
2023-01-04 04:11:55,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:55,115 INFO:     Epoch: 30
2023-01-04 04:11:56,735 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43928917944431306, 'Total loss': 0.43928917944431306} | train loss {'Reaction outcome loss': 0.27034018368230783, 'Total loss': 0.27034018368230783}
2023-01-04 04:11:56,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:56,736 INFO:     Epoch: 31
2023-01-04 04:11:58,350 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45674158036708834, 'Total loss': 0.45674158036708834} | train loss {'Reaction outcome loss': 0.27099232181258825, 'Total loss': 0.27099232181258825}
2023-01-04 04:11:58,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:58,351 INFO:     Epoch: 32
2023-01-04 04:11:59,949 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45012913246949515, 'Total loss': 0.45012913246949515} | train loss {'Reaction outcome loss': 0.26980503057121247, 'Total loss': 0.26980503057121247}
2023-01-04 04:11:59,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:11:59,949 INFO:     Epoch: 33
2023-01-04 04:12:01,563 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4248162309328715, 'Total loss': 0.4248162309328715} | train loss {'Reaction outcome loss': 0.26089753865169873, 'Total loss': 0.26089753865169873}
2023-01-04 04:12:01,564 INFO:     Found new best model at epoch 33
2023-01-04 04:12:01,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:01,565 INFO:     Epoch: 34
2023-01-04 04:12:03,217 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43359609246253966, 'Total loss': 0.43359609246253966} | train loss {'Reaction outcome loss': 0.25988656840712315, 'Total loss': 0.25988656840712315}
2023-01-04 04:12:03,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:03,217 INFO:     Epoch: 35
2023-01-04 04:12:04,808 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4247193209826946, 'Total loss': 0.4247193209826946} | train loss {'Reaction outcome loss': 0.2562116715765813, 'Total loss': 0.2562116715765813}
2023-01-04 04:12:04,808 INFO:     Found new best model at epoch 35
2023-01-04 04:12:04,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:04,809 INFO:     Epoch: 36
2023-01-04 04:12:06,397 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4337076445420583, 'Total loss': 0.4337076445420583} | train loss {'Reaction outcome loss': 0.2576983907543447, 'Total loss': 0.2576983907543447}
2023-01-04 04:12:06,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:06,397 INFO:     Epoch: 37
2023-01-04 04:12:07,961 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4518703411022822, 'Total loss': 0.4518703411022822} | train loss {'Reaction outcome loss': 0.2544086184749123, 'Total loss': 0.2544086184749123}
2023-01-04 04:12:07,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:07,961 INFO:     Epoch: 38
2023-01-04 04:12:09,537 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44502910375595095, 'Total loss': 0.44502910375595095} | train loss {'Reaction outcome loss': 0.25178196996305324, 'Total loss': 0.25178196996305324}
2023-01-04 04:12:09,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:09,538 INFO:     Epoch: 39
2023-01-04 04:12:11,130 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44121382633845013, 'Total loss': 0.44121382633845013} | train loss {'Reaction outcome loss': 0.2503342393083849, 'Total loss': 0.2503342393083849}
2023-01-04 04:12:11,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:11,130 INFO:     Epoch: 40
2023-01-04 04:12:12,722 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4534266074498495, 'Total loss': 0.4534266074498495} | train loss {'Reaction outcome loss': 0.24395140335832696, 'Total loss': 0.24395140335832696}
2023-01-04 04:12:12,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:12,722 INFO:     Epoch: 41
2023-01-04 04:12:14,314 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4609324793020884, 'Total loss': 0.4609324793020884} | train loss {'Reaction outcome loss': 0.2572068042270299, 'Total loss': 0.2572068042270299}
2023-01-04 04:12:14,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:14,314 INFO:     Epoch: 42
2023-01-04 04:12:15,890 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43180608650048574, 'Total loss': 0.43180608650048574} | train loss {'Reaction outcome loss': 0.2464390726004174, 'Total loss': 0.2464390726004174}
2023-01-04 04:12:15,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:15,890 INFO:     Epoch: 43
2023-01-04 04:12:17,511 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4388384997844696, 'Total loss': 0.4388384997844696} | train loss {'Reaction outcome loss': 0.23599882329733152, 'Total loss': 0.23599882329733152}
2023-01-04 04:12:17,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:17,511 INFO:     Epoch: 44
2023-01-04 04:12:19,091 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43470981319745383, 'Total loss': 0.43470981319745383} | train loss {'Reaction outcome loss': 0.23901332360084937, 'Total loss': 0.23901332360084937}
2023-01-04 04:12:19,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:19,092 INFO:     Epoch: 45
2023-01-04 04:12:20,682 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45647947986920673, 'Total loss': 0.45647947986920673} | train loss {'Reaction outcome loss': 0.23876428725518475, 'Total loss': 0.23876428725518475}
2023-01-04 04:12:20,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:20,682 INFO:     Epoch: 46
2023-01-04 04:12:22,273 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4277493546406428, 'Total loss': 0.4277493546406428} | train loss {'Reaction outcome loss': 0.23475758379082318, 'Total loss': 0.23475758379082318}
2023-01-04 04:12:22,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:22,274 INFO:     Epoch: 47
2023-01-04 04:12:23,864 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43176395297050474, 'Total loss': 0.43176395297050474} | train loss {'Reaction outcome loss': 0.23356599152084792, 'Total loss': 0.23356599152084792}
2023-01-04 04:12:23,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:23,865 INFO:     Epoch: 48
2023-01-04 04:12:25,440 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43880788584550223, 'Total loss': 0.43880788584550223} | train loss {'Reaction outcome loss': 0.2296223556538504, 'Total loss': 0.2296223556538504}
2023-01-04 04:12:25,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:25,441 INFO:     Epoch: 49
2023-01-04 04:12:27,021 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43838411569595337, 'Total loss': 0.43838411569595337} | train loss {'Reaction outcome loss': 0.22626641873216283, 'Total loss': 0.22626641873216283}
2023-01-04 04:12:27,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:27,021 INFO:     Epoch: 50
2023-01-04 04:12:28,638 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43623362183570863, 'Total loss': 0.43623362183570863} | train loss {'Reaction outcome loss': 0.22847754522429212, 'Total loss': 0.22847754522429212}
2023-01-04 04:12:28,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:28,638 INFO:     Epoch: 51
2023-01-04 04:12:30,247 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4357420116662979, 'Total loss': 0.4357420116662979} | train loss {'Reaction outcome loss': 0.2238000459637724, 'Total loss': 0.2238000459637724}
2023-01-04 04:12:30,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:30,247 INFO:     Epoch: 52
2023-01-04 04:12:31,828 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4341459770997365, 'Total loss': 0.4341459770997365} | train loss {'Reaction outcome loss': 0.2230258448491467, 'Total loss': 0.2230258448491467}
2023-01-04 04:12:31,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:31,828 INFO:     Epoch: 53
2023-01-04 04:12:33,446 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46229724486668905, 'Total loss': 0.46229724486668905} | train loss {'Reaction outcome loss': 0.22092022313112122, 'Total loss': 0.22092022313112122}
2023-01-04 04:12:33,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:33,446 INFO:     Epoch: 54
2023-01-04 04:12:35,027 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4636115670204163, 'Total loss': 0.4636115670204163} | train loss {'Reaction outcome loss': 0.21809424760294202, 'Total loss': 0.21809424760294202}
2023-01-04 04:12:35,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:35,028 INFO:     Epoch: 55
2023-01-04 04:12:36,596 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4395579735438029, 'Total loss': 0.4395579735438029} | train loss {'Reaction outcome loss': 0.21697372078478624, 'Total loss': 0.21697372078478624}
2023-01-04 04:12:36,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:36,596 INFO:     Epoch: 56
2023-01-04 04:12:38,218 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4783027191956838, 'Total loss': 0.4783027191956838} | train loss {'Reaction outcome loss': 0.21627415114662785, 'Total loss': 0.21627415114662785}
2023-01-04 04:12:38,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:38,218 INFO:     Epoch: 57
2023-01-04 04:12:39,804 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47402727901935576, 'Total loss': 0.47402727901935576} | train loss {'Reaction outcome loss': 0.21235866029409395, 'Total loss': 0.21235866029409395}
2023-01-04 04:12:39,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:39,804 INFO:     Epoch: 58
2023-01-04 04:12:41,424 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4583726386229197, 'Total loss': 0.4583726386229197} | train loss {'Reaction outcome loss': 0.21625379752114657, 'Total loss': 0.21625379752114657}
2023-01-04 04:12:41,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:41,425 INFO:     Epoch: 59
2023-01-04 04:12:43,000 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4595200538635254, 'Total loss': 0.4595200538635254} | train loss {'Reaction outcome loss': 0.21560797798514797, 'Total loss': 0.21560797798514797}
2023-01-04 04:12:43,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:43,000 INFO:     Epoch: 60
2023-01-04 04:12:44,589 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4660805404186249, 'Total loss': 0.4660805404186249} | train loss {'Reaction outcome loss': 0.20932826138269392, 'Total loss': 0.20932826138269392}
2023-01-04 04:12:44,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:44,590 INFO:     Epoch: 61
2023-01-04 04:12:46,162 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.452438364426295, 'Total loss': 0.452438364426295} | train loss {'Reaction outcome loss': 0.20970034731241563, 'Total loss': 0.20970034731241563}
2023-01-04 04:12:46,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:46,162 INFO:     Epoch: 62
2023-01-04 04:12:47,780 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4397227476040522, 'Total loss': 0.4397227476040522} | train loss {'Reaction outcome loss': 0.20660866337382924, 'Total loss': 0.20660866337382924}
2023-01-04 04:12:47,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:47,781 INFO:     Epoch: 63
2023-01-04 04:12:49,396 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45362340013186137, 'Total loss': 0.45362340013186137} | train loss {'Reaction outcome loss': 0.20757958990946898, 'Total loss': 0.20757958990946898}
2023-01-04 04:12:49,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:49,396 INFO:     Epoch: 64
2023-01-04 04:12:51,024 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45448935429255166, 'Total loss': 0.45448935429255166} | train loss {'Reaction outcome loss': 0.2041375051991528, 'Total loss': 0.2041375051991528}
2023-01-04 04:12:51,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:51,024 INFO:     Epoch: 65
2023-01-04 04:12:52,618 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4472626248995463, 'Total loss': 0.4472626248995463} | train loss {'Reaction outcome loss': 0.20649321320588174, 'Total loss': 0.20649321320588174}
2023-01-04 04:12:52,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:52,618 INFO:     Epoch: 66
2023-01-04 04:12:54,209 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46911155978838603, 'Total loss': 0.46911155978838603} | train loss {'Reaction outcome loss': 0.2171957661546227, 'Total loss': 0.2171957661546227}
2023-01-04 04:12:54,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:54,209 INFO:     Epoch: 67
2023-01-04 04:12:55,804 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4531342774629593, 'Total loss': 0.4531342774629593} | train loss {'Reaction outcome loss': 0.20944620601738384, 'Total loss': 0.20944620601738384}
2023-01-04 04:12:55,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:55,805 INFO:     Epoch: 68
2023-01-04 04:12:57,399 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44782137622435886, 'Total loss': 0.44782137622435886} | train loss {'Reaction outcome loss': 0.19871727712587386, 'Total loss': 0.19871727712587386}
2023-01-04 04:12:57,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:57,400 INFO:     Epoch: 69
2023-01-04 04:12:58,993 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4429029693206151, 'Total loss': 0.4429029693206151} | train loss {'Reaction outcome loss': 0.19690411418222525, 'Total loss': 0.19690411418222525}
2023-01-04 04:12:58,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:12:58,993 INFO:     Epoch: 70
2023-01-04 04:13:00,570 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44440796673297883, 'Total loss': 0.44440796673297883} | train loss {'Reaction outcome loss': 0.1951781653130994, 'Total loss': 0.1951781653130994}
2023-01-04 04:13:00,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:00,570 INFO:     Epoch: 71
2023-01-04 04:13:02,165 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4642947897315025, 'Total loss': 0.4642947897315025} | train loss {'Reaction outcome loss': 0.19513225447440494, 'Total loss': 0.19513225447440494}
2023-01-04 04:13:02,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:02,166 INFO:     Epoch: 72
2023-01-04 04:13:03,745 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4625427484512329, 'Total loss': 0.4625427484512329} | train loss {'Reaction outcome loss': 0.19565985138541547, 'Total loss': 0.19565985138541547}
2023-01-04 04:13:03,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:03,746 INFO:     Epoch: 73
2023-01-04 04:13:05,339 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44197686612606046, 'Total loss': 0.44197686612606046} | train loss {'Reaction outcome loss': 0.19372824394520358, 'Total loss': 0.19372824394520358}
2023-01-04 04:13:05,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:05,339 INFO:     Epoch: 74
2023-01-04 04:13:06,930 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.479054061571757, 'Total loss': 0.479054061571757} | train loss {'Reaction outcome loss': 0.1910675633918035, 'Total loss': 0.1910675633918035}
2023-01-04 04:13:06,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:06,931 INFO:     Epoch: 75
2023-01-04 04:13:08,524 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.452830179532369, 'Total loss': 0.452830179532369} | train loss {'Reaction outcome loss': 0.19156644128763245, 'Total loss': 0.19156644128763245}
2023-01-04 04:13:08,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:08,524 INFO:     Epoch: 76
2023-01-04 04:13:10,121 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48430877923965454, 'Total loss': 0.48430877923965454} | train loss {'Reaction outcome loss': 0.18727453836902935, 'Total loss': 0.18727453836902935}
2023-01-04 04:13:10,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:10,121 INFO:     Epoch: 77
2023-01-04 04:13:11,695 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4568541318178177, 'Total loss': 0.4568541318178177} | train loss {'Reaction outcome loss': 0.18834971776232123, 'Total loss': 0.18834971776232123}
2023-01-04 04:13:11,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:11,696 INFO:     Epoch: 78
2023-01-04 04:13:13,283 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.490198810895284, 'Total loss': 0.490198810895284} | train loss {'Reaction outcome loss': 0.18914856334922134, 'Total loss': 0.18914856334922134}
2023-01-04 04:13:13,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:13,283 INFO:     Epoch: 79
2023-01-04 04:13:14,881 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.461883216102918, 'Total loss': 0.461883216102918} | train loss {'Reaction outcome loss': 0.18789686506416742, 'Total loss': 0.18789686506416742}
2023-01-04 04:13:14,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:14,881 INFO:     Epoch: 80
2023-01-04 04:13:16,477 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4494623184204102, 'Total loss': 0.4494623184204102} | train loss {'Reaction outcome loss': 0.18623606855154334, 'Total loss': 0.18623606855154334}
2023-01-04 04:13:16,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:16,478 INFO:     Epoch: 81
2023-01-04 04:13:18,080 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4721190591653188, 'Total loss': 0.4721190591653188} | train loss {'Reaction outcome loss': 0.18517227542411158, 'Total loss': 0.18517227542411158}
2023-01-04 04:13:18,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:18,080 INFO:     Epoch: 82
2023-01-04 04:13:19,649 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4761511246363322, 'Total loss': 0.4761511246363322} | train loss {'Reaction outcome loss': 0.1827677057649387, 'Total loss': 0.1827677057649387}
2023-01-04 04:13:19,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:19,650 INFO:     Epoch: 83
2023-01-04 04:13:21,244 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4831729531288147, 'Total loss': 0.4831729531288147} | train loss {'Reaction outcome loss': 0.1820198067242914, 'Total loss': 0.1820198067242914}
2023-01-04 04:13:21,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:21,244 INFO:     Epoch: 84
2023-01-04 04:13:22,861 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.462888115644455, 'Total loss': 0.462888115644455} | train loss {'Reaction outcome loss': 0.18164769881843604, 'Total loss': 0.18164769881843604}
2023-01-04 04:13:22,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:22,861 INFO:     Epoch: 85
2023-01-04 04:13:24,463 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.471144425868988, 'Total loss': 0.471144425868988} | train loss {'Reaction outcome loss': 0.1807811969639801, 'Total loss': 0.1807811969639801}
2023-01-04 04:13:24,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:24,463 INFO:     Epoch: 86
2023-01-04 04:13:26,059 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4636706352233887, 'Total loss': 0.4636706352233887} | train loss {'Reaction outcome loss': 0.18154330724709708, 'Total loss': 0.18154330724709708}
2023-01-04 04:13:26,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:26,060 INFO:     Epoch: 87
2023-01-04 04:13:27,643 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4357462298125029, 'Total loss': 0.4357462298125029} | train loss {'Reaction outcome loss': 0.17811110276915498, 'Total loss': 0.17811110276915498}
2023-01-04 04:13:27,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:27,644 INFO:     Epoch: 88
2023-01-04 04:13:29,223 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4704111933708191, 'Total loss': 0.4704111933708191} | train loss {'Reaction outcome loss': 0.1793191658022503, 'Total loss': 0.1793191658022503}
2023-01-04 04:13:29,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:29,223 INFO:     Epoch: 89
2023-01-04 04:13:30,807 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45868862569332125, 'Total loss': 0.45868862569332125} | train loss {'Reaction outcome loss': 0.18567502355031995, 'Total loss': 0.18567502355031995}
2023-01-04 04:13:30,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:30,807 INFO:     Epoch: 90
2023-01-04 04:13:32,401 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4820658892393112, 'Total loss': 0.4820658892393112} | train loss {'Reaction outcome loss': 0.17596741827540993, 'Total loss': 0.17596741827540993}
2023-01-04 04:13:32,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:32,402 INFO:     Epoch: 91
2023-01-04 04:13:33,997 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43840025862058, 'Total loss': 0.43840025862058} | train loss {'Reaction outcome loss': 0.17698914219373904, 'Total loss': 0.17698914219373904}
2023-01-04 04:13:33,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:33,998 INFO:     Epoch: 92
2023-01-04 04:13:35,593 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4639240503311157, 'Total loss': 0.4639240503311157} | train loss {'Reaction outcome loss': 0.17370298678097373, 'Total loss': 0.17370298678097373}
2023-01-04 04:13:35,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:35,593 INFO:     Epoch: 93
2023-01-04 04:13:37,173 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4854597936073939, 'Total loss': 0.4854597936073939} | train loss {'Reaction outcome loss': 0.1709147086147678, 'Total loss': 0.1709147086147678}
2023-01-04 04:13:37,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:37,173 INFO:     Epoch: 94
2023-01-04 04:13:38,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47713468472162884, 'Total loss': 0.47713468472162884} | train loss {'Reaction outcome loss': 0.17084526981225412, 'Total loss': 0.17084526981225412}
2023-01-04 04:13:38,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:38,754 INFO:     Epoch: 95
2023-01-04 04:13:40,371 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4542983869711558, 'Total loss': 0.4542983869711558} | train loss {'Reaction outcome loss': 0.1726592031673531, 'Total loss': 0.1726592031673531}
2023-01-04 04:13:40,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:40,371 INFO:     Epoch: 96
2023-01-04 04:13:41,995 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4819404900074005, 'Total loss': 0.4819404900074005} | train loss {'Reaction outcome loss': 0.17148048766041749, 'Total loss': 0.17148048766041749}
2023-01-04 04:13:41,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:41,996 INFO:     Epoch: 97
2023-01-04 04:13:43,611 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4784363885720571, 'Total loss': 0.4784363885720571} | train loss {'Reaction outcome loss': 0.17324475536419862, 'Total loss': 0.17324475536419862}
2023-01-04 04:13:43,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:43,611 INFO:     Epoch: 98
2023-01-04 04:13:45,211 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4647787610689799, 'Total loss': 0.4647787610689799} | train loss {'Reaction outcome loss': 0.1709380443627803, 'Total loss': 0.1709380443627803}
2023-01-04 04:13:45,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:45,211 INFO:     Epoch: 99
2023-01-04 04:13:46,830 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46777475078900654, 'Total loss': 0.46777475078900654} | train loss {'Reaction outcome loss': 0.16671852880972438, 'Total loss': 0.16671852880972438}
2023-01-04 04:13:46,830 INFO:     Best model found after epoch 36 of 100.
2023-01-04 04:13:46,831 INFO:   Done with stage: TRAINING
2023-01-04 04:13:46,831 INFO:   Starting stage: EVALUATION
2023-01-04 04:13:46,961 INFO:   Done with stage: EVALUATION
2023-01-04 04:13:46,961 INFO:   Leaving out SEQ value Fold_9
2023-01-04 04:13:46,973 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:13:46,974 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:13:47,613 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:13:47,613 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:13:47,680 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:13:47,680 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:13:47,680 INFO:     No hyperparam tuning for this model
2023-01-04 04:13:47,680 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:13:47,680 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:13:47,681 INFO:     None feature selector for col prot
2023-01-04 04:13:47,681 INFO:     None feature selector for col prot
2023-01-04 04:13:47,681 INFO:     None feature selector for col prot
2023-01-04 04:13:47,682 INFO:     None feature selector for col chem
2023-01-04 04:13:47,682 INFO:     None feature selector for col chem
2023-01-04 04:13:47,682 INFO:     None feature selector for col chem
2023-01-04 04:13:47,682 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:13:47,682 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:13:47,683 INFO:     Number of params in model 70141
2023-01-04 04:13:47,686 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:13:47,686 INFO:   Starting stage: TRAINING
2023-01-04 04:13:47,730 INFO:     Val loss before train {'Reaction outcome loss': 1.0000516653060914, 'Total loss': 1.0000516653060914}
2023-01-04 04:13:47,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:47,730 INFO:     Epoch: 0
2023-01-04 04:13:49,350 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6862362662951151, 'Total loss': 0.6862362662951151} | train loss {'Reaction outcome loss': 0.8656770147356219, 'Total loss': 0.8656770147356219}
2023-01-04 04:13:49,351 INFO:     Found new best model at epoch 0
2023-01-04 04:13:49,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:49,351 INFO:     Epoch: 1
2023-01-04 04:13:50,961 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5298340201377869, 'Total loss': 0.5298340201377869} | train loss {'Reaction outcome loss': 0.6429858909029028, 'Total loss': 0.6429858909029028}
2023-01-04 04:13:50,961 INFO:     Found new best model at epoch 1
2023-01-04 04:13:50,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:50,962 INFO:     Epoch: 2
2023-01-04 04:13:52,556 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48977784713109335, 'Total loss': 0.48977784713109335} | train loss {'Reaction outcome loss': 0.5539572971562544, 'Total loss': 0.5539572971562544}
2023-01-04 04:13:52,556 INFO:     Found new best model at epoch 2
2023-01-04 04:13:52,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:52,557 INFO:     Epoch: 3
2023-01-04 04:13:54,140 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45843111475308734, 'Total loss': 0.45843111475308734} | train loss {'Reaction outcome loss': 0.5178977977214516, 'Total loss': 0.5178977977214516}
2023-01-04 04:13:54,140 INFO:     Found new best model at epoch 3
2023-01-04 04:13:54,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:54,141 INFO:     Epoch: 4
2023-01-04 04:13:55,760 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4320140947898229, 'Total loss': 0.4320140947898229} | train loss {'Reaction outcome loss': 0.47817010185415554, 'Total loss': 0.47817010185415554}
2023-01-04 04:13:55,760 INFO:     Found new best model at epoch 4
2023-01-04 04:13:55,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:55,761 INFO:     Epoch: 5
2023-01-04 04:13:57,337 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4218066543340683, 'Total loss': 0.4218066543340683} | train loss {'Reaction outcome loss': 0.4555911339306529, 'Total loss': 0.4555911339306529}
2023-01-04 04:13:57,337 INFO:     Found new best model at epoch 5
2023-01-04 04:13:57,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:57,338 INFO:     Epoch: 6
2023-01-04 04:13:58,932 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4267676363388697, 'Total loss': 0.4267676363388697} | train loss {'Reaction outcome loss': 0.43779760446615407, 'Total loss': 0.43779760446615407}
2023-01-04 04:13:58,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:13:58,933 INFO:     Epoch: 7
2023-01-04 04:14:00,527 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4086457004149755, 'Total loss': 0.4086457004149755} | train loss {'Reaction outcome loss': 0.42453361039329995, 'Total loss': 0.42453361039329995}
2023-01-04 04:14:00,527 INFO:     Found new best model at epoch 7
2023-01-04 04:14:00,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:00,528 INFO:     Epoch: 8
2023-01-04 04:14:02,123 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41570628583431246, 'Total loss': 0.41570628583431246} | train loss {'Reaction outcome loss': 0.411282231214088, 'Total loss': 0.411282231214088}
2023-01-04 04:14:02,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:02,123 INFO:     Epoch: 9
2023-01-04 04:14:03,709 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38482939898967744, 'Total loss': 0.38482939898967744} | train loss {'Reaction outcome loss': 0.40147862189832784, 'Total loss': 0.40147862189832784}
2023-01-04 04:14:03,709 INFO:     Found new best model at epoch 9
2023-01-04 04:14:03,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:03,710 INFO:     Epoch: 10
2023-01-04 04:14:05,296 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.37300601104895276, 'Total loss': 0.37300601104895276} | train loss {'Reaction outcome loss': 0.3991878726992054, 'Total loss': 0.3991878726992054}
2023-01-04 04:14:05,297 INFO:     Found new best model at epoch 10
2023-01-04 04:14:05,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:05,298 INFO:     Epoch: 11
2023-01-04 04:14:06,908 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3893349587917328, 'Total loss': 0.3893349587917328} | train loss {'Reaction outcome loss': 0.387014620105628, 'Total loss': 0.387014620105628}
2023-01-04 04:14:06,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:06,908 INFO:     Epoch: 12
2023-01-04 04:14:08,527 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.37212422788143157, 'Total loss': 0.37212422788143157} | train loss {'Reaction outcome loss': 0.3777937040178348, 'Total loss': 0.3777937040178348}
2023-01-04 04:14:08,527 INFO:     Found new best model at epoch 12
2023-01-04 04:14:08,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:08,528 INFO:     Epoch: 13
2023-01-04 04:14:10,136 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3843438575665156, 'Total loss': 0.3843438575665156} | train loss {'Reaction outcome loss': 0.3690651561575604, 'Total loss': 0.3690651561575604}
2023-01-04 04:14:10,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:10,136 INFO:     Epoch: 14
2023-01-04 04:14:11,718 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37330984473228457, 'Total loss': 0.37330984473228457} | train loss {'Reaction outcome loss': 0.3632597209298578, 'Total loss': 0.3632597209298578}
2023-01-04 04:14:11,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:11,718 INFO:     Epoch: 15
2023-01-04 04:14:13,333 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3820341189702352, 'Total loss': 0.3820341189702352} | train loss {'Reaction outcome loss': 0.380717350035042, 'Total loss': 0.380717350035042}
2023-01-04 04:14:13,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:13,333 INFO:     Epoch: 16
2023-01-04 04:14:14,921 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.36059925655523933, 'Total loss': 0.36059925655523933} | train loss {'Reaction outcome loss': 0.35315661245714064, 'Total loss': 0.35315661245714064}
2023-01-04 04:14:14,921 INFO:     Found new best model at epoch 16
2023-01-04 04:14:14,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:14,922 INFO:     Epoch: 17
2023-01-04 04:14:16,538 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3557252615690231, 'Total loss': 0.3557252615690231} | train loss {'Reaction outcome loss': 0.34816147602986597, 'Total loss': 0.34816147602986597}
2023-01-04 04:14:16,538 INFO:     Found new best model at epoch 17
2023-01-04 04:14:16,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:16,539 INFO:     Epoch: 18
2023-01-04 04:14:18,154 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3671944205959638, 'Total loss': 0.3671944205959638} | train loss {'Reaction outcome loss': 0.3421439089866328, 'Total loss': 0.3421439089866328}
2023-01-04 04:14:18,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:18,155 INFO:     Epoch: 19
2023-01-04 04:14:19,775 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3542774806420008, 'Total loss': 0.3542774806420008} | train loss {'Reaction outcome loss': 0.33624819083058316, 'Total loss': 0.33624819083058316}
2023-01-04 04:14:19,775 INFO:     Found new best model at epoch 19
2023-01-04 04:14:19,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:19,776 INFO:     Epoch: 20
2023-01-04 04:14:21,357 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3516090522209803, 'Total loss': 0.3516090522209803} | train loss {'Reaction outcome loss': 0.32976549662534904, 'Total loss': 0.32976549662534904}
2023-01-04 04:14:21,357 INFO:     Found new best model at epoch 20
2023-01-04 04:14:21,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:21,358 INFO:     Epoch: 21
2023-01-04 04:14:22,944 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35630987385908763, 'Total loss': 0.35630987385908763} | train loss {'Reaction outcome loss': 0.32310484374023, 'Total loss': 0.32310484374023}
2023-01-04 04:14:22,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:22,944 INFO:     Epoch: 22
2023-01-04 04:14:24,544 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3632896343866984, 'Total loss': 0.3632896343866984} | train loss {'Reaction outcome loss': 0.3168738623990857, 'Total loss': 0.3168738623990857}
2023-01-04 04:14:24,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:24,544 INFO:     Epoch: 23
2023-01-04 04:14:26,168 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3612828930219015, 'Total loss': 0.3612828930219015} | train loss {'Reaction outcome loss': 0.3172715247973152, 'Total loss': 0.3172715247973152}
2023-01-04 04:14:26,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:26,168 INFO:     Epoch: 24
2023-01-04 04:14:27,789 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3407663981119792, 'Total loss': 0.3407663981119792} | train loss {'Reaction outcome loss': 0.3305179427607336, 'Total loss': 0.3305179427607336}
2023-01-04 04:14:27,790 INFO:     Found new best model at epoch 24
2023-01-04 04:14:27,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:27,790 INFO:     Epoch: 25
2023-01-04 04:14:29,378 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3508168488740921, 'Total loss': 0.3508168488740921} | train loss {'Reaction outcome loss': 0.32851611783026136, 'Total loss': 0.32851611783026136}
2023-01-04 04:14:29,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:29,379 INFO:     Epoch: 26
2023-01-04 04:14:30,955 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3584577371676763, 'Total loss': 0.3584577371676763} | train loss {'Reaction outcome loss': 0.30514178490135446, 'Total loss': 0.30514178490135446}
2023-01-04 04:14:30,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:30,955 INFO:     Epoch: 27
2023-01-04 04:14:32,542 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3440235455830892, 'Total loss': 0.3440235455830892} | train loss {'Reaction outcome loss': 0.2995580876797802, 'Total loss': 0.2995580876797802}
2023-01-04 04:14:32,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:32,542 INFO:     Epoch: 28
2023-01-04 04:14:34,164 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.35563693245251976, 'Total loss': 0.35563693245251976} | train loss {'Reaction outcome loss': 0.29282444377072947, 'Total loss': 0.29282444377072947}
2023-01-04 04:14:34,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:34,165 INFO:     Epoch: 29
2023-01-04 04:14:35,753 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3708273142576218, 'Total loss': 0.3708273142576218} | train loss {'Reaction outcome loss': 0.28980826968462137, 'Total loss': 0.28980826968462137}
2023-01-04 04:14:35,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:35,754 INFO:     Epoch: 30
2023-01-04 04:14:37,343 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.35018950899442036, 'Total loss': 0.35018950899442036} | train loss {'Reaction outcome loss': 0.29741829108662793, 'Total loss': 0.29741829108662793}
2023-01-04 04:14:37,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:37,343 INFO:     Epoch: 31
2023-01-04 04:14:38,941 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3559357752402624, 'Total loss': 0.3559357752402624} | train loss {'Reaction outcome loss': 0.2936199143178005, 'Total loss': 0.2936199143178005}
2023-01-04 04:14:38,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:38,941 INFO:     Epoch: 32
2023-01-04 04:14:40,563 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3495919942855835, 'Total loss': 0.3495919942855835} | train loss {'Reaction outcome loss': 0.2862535529580993, 'Total loss': 0.2862535529580993}
2023-01-04 04:14:40,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:40,563 INFO:     Epoch: 33
2023-01-04 04:14:42,170 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3499472270409266, 'Total loss': 0.3499472270409266} | train loss {'Reaction outcome loss': 0.27735213770221523, 'Total loss': 0.27735213770221523}
2023-01-04 04:14:42,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:42,170 INFO:     Epoch: 34
2023-01-04 04:14:43,784 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.34911084175109863, 'Total loss': 0.34911084175109863} | train loss {'Reaction outcome loss': 0.29822951182723045, 'Total loss': 0.29822951182723045}
2023-01-04 04:14:43,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:43,784 INFO:     Epoch: 35
2023-01-04 04:14:45,408 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3489038825035095, 'Total loss': 0.3489038825035095} | train loss {'Reaction outcome loss': 0.27180094977307634, 'Total loss': 0.27180094977307634}
2023-01-04 04:14:45,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:45,408 INFO:     Epoch: 36
2023-01-04 04:14:47,015 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36977669497330984, 'Total loss': 0.36977669497330984} | train loss {'Reaction outcome loss': 0.2673538690190374, 'Total loss': 0.2673538690190374}
2023-01-04 04:14:47,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:47,016 INFO:     Epoch: 37
2023-01-04 04:14:48,597 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3614262024561564, 'Total loss': 0.3614262024561564} | train loss {'Reaction outcome loss': 0.27012121129403077, 'Total loss': 0.27012121129403077}
2023-01-04 04:14:48,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:48,598 INFO:     Epoch: 38
2023-01-04 04:14:50,196 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3557677060365677, 'Total loss': 0.3557677060365677} | train loss {'Reaction outcome loss': 0.27041884287651896, 'Total loss': 0.27041884287651896}
2023-01-04 04:14:50,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:50,196 INFO:     Epoch: 39
2023-01-04 04:14:51,784 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36295226713021594, 'Total loss': 0.36295226713021594} | train loss {'Reaction outcome loss': 0.2596596990822919, 'Total loss': 0.2596596990822919}
2023-01-04 04:14:51,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:51,785 INFO:     Epoch: 40
2023-01-04 04:14:53,373 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3463380128145218, 'Total loss': 0.3463380128145218} | train loss {'Reaction outcome loss': 0.2587627794012972, 'Total loss': 0.2587627794012972}
2023-01-04 04:14:53,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:53,374 INFO:     Epoch: 41
2023-01-04 04:14:54,994 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.34973952968915306, 'Total loss': 0.34973952968915306} | train loss {'Reaction outcome loss': 0.2573370068887438, 'Total loss': 0.2573370068887438}
2023-01-04 04:14:54,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:54,994 INFO:     Epoch: 42
2023-01-04 04:14:56,601 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.34728777408599854, 'Total loss': 0.34728777408599854} | train loss {'Reaction outcome loss': 0.2505315963090929, 'Total loss': 0.2505315963090929}
2023-01-04 04:14:56,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:56,602 INFO:     Epoch: 43
2023-01-04 04:14:58,217 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.356714008251826, 'Total loss': 0.356714008251826} | train loss {'Reaction outcome loss': 0.24950587955316988, 'Total loss': 0.24950587955316988}
2023-01-04 04:14:58,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:58,217 INFO:     Epoch: 44
2023-01-04 04:14:59,829 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3713359435399373, 'Total loss': 0.3713359435399373} | train loss {'Reaction outcome loss': 0.24712365865707397, 'Total loss': 0.24712365865707397}
2023-01-04 04:14:59,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:14:59,830 INFO:     Epoch: 45
2023-01-04 04:15:01,446 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3695786555608114, 'Total loss': 0.3695786555608114} | train loss {'Reaction outcome loss': 0.24487654797300912, 'Total loss': 0.24487654797300912}
2023-01-04 04:15:01,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:01,446 INFO:     Epoch: 46
2023-01-04 04:15:03,065 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3603452910979589, 'Total loss': 0.3603452910979589} | train loss {'Reaction outcome loss': 0.2477260825993574, 'Total loss': 0.2477260825993574}
2023-01-04 04:15:03,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:03,065 INFO:     Epoch: 47
2023-01-04 04:15:04,679 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3722471753756205, 'Total loss': 0.3722471753756205} | train loss {'Reaction outcome loss': 0.2470079889401635, 'Total loss': 0.2470079889401635}
2023-01-04 04:15:04,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:04,679 INFO:     Epoch: 48
2023-01-04 04:15:06,271 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3660290017724037, 'Total loss': 0.3660290017724037} | train loss {'Reaction outcome loss': 0.23711103488861135, 'Total loss': 0.23711103488861135}
2023-01-04 04:15:06,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:06,272 INFO:     Epoch: 49
2023-01-04 04:15:07,862 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3616458048423131, 'Total loss': 0.3616458048423131} | train loss {'Reaction outcome loss': 0.23674979559207027, 'Total loss': 0.23674979559207027}
2023-01-04 04:15:07,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:07,862 INFO:     Epoch: 50
2023-01-04 04:15:09,459 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3727435717980067, 'Total loss': 0.3727435717980067} | train loss {'Reaction outcome loss': 0.23329755807376848, 'Total loss': 0.23329755807376848}
2023-01-04 04:15:09,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:09,459 INFO:     Epoch: 51
2023-01-04 04:15:11,079 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3691317141056061, 'Total loss': 0.3691317141056061} | train loss {'Reaction outcome loss': 0.23385199053766395, 'Total loss': 0.23385199053766395}
2023-01-04 04:15:11,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:11,079 INFO:     Epoch: 52
2023-01-04 04:15:12,665 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3725963781277339, 'Total loss': 0.3725963781277339} | train loss {'Reaction outcome loss': 0.23030185335791548, 'Total loss': 0.23030185335791548}
2023-01-04 04:15:12,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:12,666 INFO:     Epoch: 53
2023-01-04 04:15:14,285 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37071402569611867, 'Total loss': 0.37071402569611867} | train loss {'Reaction outcome loss': 0.22751572199901432, 'Total loss': 0.22751572199901432}
2023-01-04 04:15:14,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:14,285 INFO:     Epoch: 54
2023-01-04 04:15:15,879 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3493320167064667, 'Total loss': 0.3493320167064667} | train loss {'Reaction outcome loss': 0.227074608940988, 'Total loss': 0.227074608940988}
2023-01-04 04:15:15,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:15,880 INFO:     Epoch: 55
2023-01-04 04:15:17,476 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35390850255886713, 'Total loss': 0.35390850255886713} | train loss {'Reaction outcome loss': 0.22343279818997488, 'Total loss': 0.22343279818997488}
2023-01-04 04:15:17,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:17,477 INFO:     Epoch: 56
2023-01-04 04:15:19,129 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3521174321571986, 'Total loss': 0.3521174321571986} | train loss {'Reaction outcome loss': 0.22221189225345608, 'Total loss': 0.22221189225345608}
2023-01-04 04:15:19,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:19,130 INFO:     Epoch: 57
2023-01-04 04:15:20,775 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37784492870171865, 'Total loss': 0.37784492870171865} | train loss {'Reaction outcome loss': 0.2229098416708808, 'Total loss': 0.2229098416708808}
2023-01-04 04:15:20,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:20,776 INFO:     Epoch: 58
2023-01-04 04:15:22,422 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3999238257606824, 'Total loss': 0.3999238257606824} | train loss {'Reaction outcome loss': 0.22206285582575694, 'Total loss': 0.22206285582575694}
2023-01-04 04:15:22,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:22,423 INFO:     Epoch: 59
2023-01-04 04:15:24,057 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.370458322763443, 'Total loss': 0.370458322763443} | train loss {'Reaction outcome loss': 0.21808704370767742, 'Total loss': 0.21808704370767742}
2023-01-04 04:15:24,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:24,057 INFO:     Epoch: 60
2023-01-04 04:15:25,697 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.372105577091376, 'Total loss': 0.372105577091376} | train loss {'Reaction outcome loss': 0.22851996649515585, 'Total loss': 0.22851996649515585}
2023-01-04 04:15:25,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:25,698 INFO:     Epoch: 61
2023-01-04 04:15:27,324 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37761253913243614, 'Total loss': 0.37761253913243614} | train loss {'Reaction outcome loss': 0.2334827569809378, 'Total loss': 0.2334827569809378}
2023-01-04 04:15:27,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:27,324 INFO:     Epoch: 62
2023-01-04 04:15:28,957 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3640672485033671, 'Total loss': 0.3640672485033671} | train loss {'Reaction outcome loss': 0.21590769988656772, 'Total loss': 0.21590769988656772}
2023-01-04 04:15:28,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:28,957 INFO:     Epoch: 63
2023-01-04 04:15:30,581 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38640955090522766, 'Total loss': 0.38640955090522766} | train loss {'Reaction outcome loss': 0.2147091646230378, 'Total loss': 0.2147091646230378}
2023-01-04 04:15:30,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:30,582 INFO:     Epoch: 64
2023-01-04 04:15:32,162 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3613679617643356, 'Total loss': 0.3613679617643356} | train loss {'Reaction outcome loss': 0.21109701196774436, 'Total loss': 0.21109701196774436}
2023-01-04 04:15:32,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:32,162 INFO:     Epoch: 65
2023-01-04 04:15:33,752 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37512081464131675, 'Total loss': 0.37512081464131675} | train loss {'Reaction outcome loss': 0.2100385590625144, 'Total loss': 0.2100385590625144}
2023-01-04 04:15:33,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:33,752 INFO:     Epoch: 66
2023-01-04 04:15:35,331 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36418103277683256, 'Total loss': 0.36418103277683256} | train loss {'Reaction outcome loss': 0.20827039164289643, 'Total loss': 0.20827039164289643}
2023-01-04 04:15:35,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:35,331 INFO:     Epoch: 67
2023-01-04 04:15:36,928 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3789599557717641, 'Total loss': 0.3789599557717641} | train loss {'Reaction outcome loss': 0.20922685703060226, 'Total loss': 0.20922685703060226}
2023-01-04 04:15:36,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:36,929 INFO:     Epoch: 68
2023-01-04 04:15:38,526 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3699816445509593, 'Total loss': 0.3699816445509593} | train loss {'Reaction outcome loss': 0.20722084720467177, 'Total loss': 0.20722084720467177}
2023-01-04 04:15:38,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:38,526 INFO:     Epoch: 69
2023-01-04 04:15:40,124 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3911829133828481, 'Total loss': 0.3911829133828481} | train loss {'Reaction outcome loss': 0.20656195165943442, 'Total loss': 0.20656195165943442}
2023-01-04 04:15:40,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:40,125 INFO:     Epoch: 70
2023-01-04 04:15:41,709 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3873649393518766, 'Total loss': 0.3873649393518766} | train loss {'Reaction outcome loss': 0.20357829880979977, 'Total loss': 0.20357829880979977}
2023-01-04 04:15:41,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:41,709 INFO:     Epoch: 71
2023-01-04 04:15:43,318 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3759480198224386, 'Total loss': 0.3759480198224386} | train loss {'Reaction outcome loss': 0.20638654538956674, 'Total loss': 0.20638654538956674}
2023-01-04 04:15:43,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:43,318 INFO:     Epoch: 72
2023-01-04 04:15:44,906 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3723199635744095, 'Total loss': 0.3723199635744095} | train loss {'Reaction outcome loss': 0.20838396488937735, 'Total loss': 0.20838396488937735}
2023-01-04 04:15:44,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:44,907 INFO:     Epoch: 73
2023-01-04 04:15:46,529 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3789799302816391, 'Total loss': 0.3789799302816391} | train loss {'Reaction outcome loss': 0.20424661628490154, 'Total loss': 0.20424661628490154}
2023-01-04 04:15:46,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:46,529 INFO:     Epoch: 74
2023-01-04 04:15:48,144 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38416108091672263, 'Total loss': 0.38416108091672263} | train loss {'Reaction outcome loss': 0.20000185944482454, 'Total loss': 0.20000185944482454}
2023-01-04 04:15:48,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:48,144 INFO:     Epoch: 75
2023-01-04 04:15:49,746 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38900638520717623, 'Total loss': 0.38900638520717623} | train loss {'Reaction outcome loss': 0.20069839606277537, 'Total loss': 0.20069839606277537}
2023-01-04 04:15:49,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:49,747 INFO:     Epoch: 76
2023-01-04 04:15:51,319 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.399193008740743, 'Total loss': 0.399193008740743} | train loss {'Reaction outcome loss': 0.1993179925872288, 'Total loss': 0.1993179925872288}
2023-01-04 04:15:51,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:51,319 INFO:     Epoch: 77
2023-01-04 04:15:52,916 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3881336361169815, 'Total loss': 0.3881336361169815} | train loss {'Reaction outcome loss': 0.19527429666156448, 'Total loss': 0.19527429666156448}
2023-01-04 04:15:52,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:52,916 INFO:     Epoch: 78
2023-01-04 04:15:54,494 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3892335812250773, 'Total loss': 0.3892335812250773} | train loss {'Reaction outcome loss': 0.19820640289812666, 'Total loss': 0.19820640289812666}
2023-01-04 04:15:54,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:54,494 INFO:     Epoch: 79
2023-01-04 04:15:56,091 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41145671904087067, 'Total loss': 0.41145671904087067} | train loss {'Reaction outcome loss': 0.2093769152905198, 'Total loss': 0.2093769152905198}
2023-01-04 04:15:56,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:56,091 INFO:     Epoch: 80
2023-01-04 04:15:57,686 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3785224397977193, 'Total loss': 0.3785224397977193} | train loss {'Reaction outcome loss': 0.2124343334094785, 'Total loss': 0.2124343334094785}
2023-01-04 04:15:57,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:57,687 INFO:     Epoch: 81
2023-01-04 04:15:59,282 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3870764493942261, 'Total loss': 0.3870764493942261} | train loss {'Reaction outcome loss': 0.19458114711991406, 'Total loss': 0.19458114711991406}
2023-01-04 04:15:59,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:15:59,282 INFO:     Epoch: 82
2023-01-04 04:16:00,858 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3812313844760259, 'Total loss': 0.3812313844760259} | train loss {'Reaction outcome loss': 0.19089994510516367, 'Total loss': 0.19089994510516367}
2023-01-04 04:16:00,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:00,859 INFO:     Epoch: 83
2023-01-04 04:16:02,435 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37315658827622733, 'Total loss': 0.37315658827622733} | train loss {'Reaction outcome loss': 0.19212874544757433, 'Total loss': 0.19212874544757433}
2023-01-04 04:16:02,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:02,436 INFO:     Epoch: 84
2023-01-04 04:16:04,031 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37912081281344095, 'Total loss': 0.37912081281344095} | train loss {'Reaction outcome loss': 0.19090364286524203, 'Total loss': 0.19090364286524203}
2023-01-04 04:16:04,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:04,032 INFO:     Epoch: 85
2023-01-04 04:16:05,628 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.382855952779452, 'Total loss': 0.382855952779452} | train loss {'Reaction outcome loss': 0.19083629090311952, 'Total loss': 0.19083629090311952}
2023-01-04 04:16:05,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:05,628 INFO:     Epoch: 86
2023-01-04 04:16:07,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3804977963368098, 'Total loss': 0.3804977963368098} | train loss {'Reaction outcome loss': 0.18942811340093613, 'Total loss': 0.18942811340093613}
2023-01-04 04:16:07,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:07,226 INFO:     Epoch: 87
2023-01-04 04:16:08,806 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38924799064795174, 'Total loss': 0.38924799064795174} | train loss {'Reaction outcome loss': 0.19070914341811684, 'Total loss': 0.19070914341811684}
2023-01-04 04:16:08,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:08,807 INFO:     Epoch: 88
2023-01-04 04:16:10,422 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38932976027329763, 'Total loss': 0.38932976027329763} | train loss {'Reaction outcome loss': 0.19161657019183465, 'Total loss': 0.19161657019183465}
2023-01-04 04:16:10,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:10,422 INFO:     Epoch: 89
2023-01-04 04:16:12,002 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39282420873641966, 'Total loss': 0.39282420873641966} | train loss {'Reaction outcome loss': 0.18486335127702172, 'Total loss': 0.18486335127702172}
2023-01-04 04:16:12,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:12,002 INFO:     Epoch: 90
2023-01-04 04:16:13,598 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38995390832424165, 'Total loss': 0.38995390832424165} | train loss {'Reaction outcome loss': 0.18892778605357677, 'Total loss': 0.18892778605357677}
2023-01-04 04:16:13,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:13,598 INFO:     Epoch: 91
2023-01-04 04:16:15,193 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38877449532349906, 'Total loss': 0.38877449532349906} | train loss {'Reaction outcome loss': 0.19217735634647662, 'Total loss': 0.19217735634647662}
2023-01-04 04:16:15,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:15,193 INFO:     Epoch: 92
2023-01-04 04:16:16,790 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.398465363184611, 'Total loss': 0.398465363184611} | train loss {'Reaction outcome loss': 0.18925245982203362, 'Total loss': 0.18925245982203362}
2023-01-04 04:16:16,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:16,791 INFO:     Epoch: 93
2023-01-04 04:16:18,372 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40218353072802226, 'Total loss': 0.40218353072802226} | train loss {'Reaction outcome loss': 0.1863264238151411, 'Total loss': 0.1863264238151411}
2023-01-04 04:16:18,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:18,372 INFO:     Epoch: 94
2023-01-04 04:16:19,951 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4119798441727956, 'Total loss': 0.4119798441727956} | train loss {'Reaction outcome loss': 0.18776430028315255, 'Total loss': 0.18776430028315255}
2023-01-04 04:16:19,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:19,951 INFO:     Epoch: 95
2023-01-04 04:16:21,566 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3857752487063408, 'Total loss': 0.3857752487063408} | train loss {'Reaction outcome loss': 0.19050333094175742, 'Total loss': 0.19050333094175742}
2023-01-04 04:16:21,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:21,567 INFO:     Epoch: 96
2023-01-04 04:16:23,168 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39059624870618187, 'Total loss': 0.39059624870618187} | train loss {'Reaction outcome loss': 0.181364675611477, 'Total loss': 0.181364675611477}
2023-01-04 04:16:23,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:23,168 INFO:     Epoch: 97
2023-01-04 04:16:24,772 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.384332745273908, 'Total loss': 0.384332745273908} | train loss {'Reaction outcome loss': 0.18172824263414097, 'Total loss': 0.18172824263414097}
2023-01-04 04:16:24,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:24,772 INFO:     Epoch: 98
2023-01-04 04:16:26,371 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40340625246365863, 'Total loss': 0.40340625246365863} | train loss {'Reaction outcome loss': 0.18230410955510562, 'Total loss': 0.18230410955510562}
2023-01-04 04:16:26,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:26,372 INFO:     Epoch: 99
2023-01-04 04:16:27,970 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40578150550524394, 'Total loss': 0.40578150550524394} | train loss {'Reaction outcome loss': 0.17943309719413408, 'Total loss': 0.17943309719413408}
2023-01-04 04:16:27,970 INFO:     Best model found after epoch 25 of 100.
2023-01-04 04:16:27,970 INFO:   Done with stage: TRAINING
2023-01-04 04:16:27,970 INFO:   Starting stage: EVALUATION
2023-01-04 04:16:28,100 INFO:   Done with stage: EVALUATION
2023-01-04 04:16:28,108 INFO:   Leaving out SEQ value Fold_0
2023-01-04 04:16:28,121 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 04:16:28,121 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:16:28,768 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:16:28,768 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:16:28,835 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:16:28,835 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:16:28,835 INFO:     No hyperparam tuning for this model
2023-01-04 04:16:28,835 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:16:28,835 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:16:28,836 INFO:     None feature selector for col prot
2023-01-04 04:16:28,836 INFO:     None feature selector for col prot
2023-01-04 04:16:28,836 INFO:     None feature selector for col prot
2023-01-04 04:16:28,836 INFO:     None feature selector for col chem
2023-01-04 04:16:28,837 INFO:     None feature selector for col chem
2023-01-04 04:16:28,837 INFO:     None feature selector for col chem
2023-01-04 04:16:28,837 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:16:28,837 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:16:28,838 INFO:     Number of params in model 70141
2023-01-04 04:16:28,841 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:16:28,841 INFO:   Starting stage: TRAINING
2023-01-04 04:16:28,887 INFO:     Val loss before train {'Reaction outcome loss': 1.0168507019678752, 'Total loss': 1.0168507019678752}
2023-01-04 04:16:28,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:28,887 INFO:     Epoch: 0
2023-01-04 04:16:30,475 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6965130666891733, 'Total loss': 0.6965130666891733} | train loss {'Reaction outcome loss': 0.8511722897091051, 'Total loss': 0.8511722897091051}
2023-01-04 04:16:30,476 INFO:     Found new best model at epoch 0
2023-01-04 04:16:30,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:30,476 INFO:     Epoch: 1
2023-01-04 04:16:32,052 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5560841302076975, 'Total loss': 0.5560841302076975} | train loss {'Reaction outcome loss': 0.5995558579690266, 'Total loss': 0.5995558579690266}
2023-01-04 04:16:32,053 INFO:     Found new best model at epoch 1
2023-01-04 04:16:32,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:32,054 INFO:     Epoch: 2
2023-01-04 04:16:33,630 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5187484284241994, 'Total loss': 0.5187484284241994} | train loss {'Reaction outcome loss': 0.5283192049195297, 'Total loss': 0.5283192049195297}
2023-01-04 04:16:33,631 INFO:     Found new best model at epoch 2
2023-01-04 04:16:33,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:33,631 INFO:     Epoch: 3
2023-01-04 04:16:35,194 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48515764325857164, 'Total loss': 0.48515764325857164} | train loss {'Reaction outcome loss': 0.49143189170064716, 'Total loss': 0.49143189170064716}
2023-01-04 04:16:35,194 INFO:     Found new best model at epoch 3
2023-01-04 04:16:35,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:35,195 INFO:     Epoch: 4
2023-01-04 04:16:36,800 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46776132583618163, 'Total loss': 0.46776132583618163} | train loss {'Reaction outcome loss': 0.467245898814532, 'Total loss': 0.467245898814532}
2023-01-04 04:16:36,800 INFO:     Found new best model at epoch 4
2023-01-04 04:16:36,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:36,801 INFO:     Epoch: 5
2023-01-04 04:16:38,364 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48010500371456144, 'Total loss': 0.48010500371456144} | train loss {'Reaction outcome loss': 0.4486731280484339, 'Total loss': 0.4486731280484339}
2023-01-04 04:16:38,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:38,365 INFO:     Epoch: 6
2023-01-04 04:16:39,952 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4547060916821162, 'Total loss': 0.4547060916821162} | train loss {'Reaction outcome loss': 0.4316674915217135, 'Total loss': 0.4316674915217135}
2023-01-04 04:16:39,952 INFO:     Found new best model at epoch 6
2023-01-04 04:16:39,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:39,953 INFO:     Epoch: 7
2023-01-04 04:16:41,540 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45402276118596396, 'Total loss': 0.45402276118596396} | train loss {'Reaction outcome loss': 0.4203244531459182, 'Total loss': 0.4203244531459182}
2023-01-04 04:16:41,540 INFO:     Found new best model at epoch 7
2023-01-04 04:16:41,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:41,541 INFO:     Epoch: 8
2023-01-04 04:16:43,136 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4565031498670578, 'Total loss': 0.4565031498670578} | train loss {'Reaction outcome loss': 0.40514912940289854, 'Total loss': 0.40514912940289854}
2023-01-04 04:16:43,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:43,136 INFO:     Epoch: 9
2023-01-04 04:16:44,724 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44065459370613097, 'Total loss': 0.44065459370613097} | train loss {'Reaction outcome loss': 0.39376605900317213, 'Total loss': 0.39376605900317213}
2023-01-04 04:16:44,725 INFO:     Found new best model at epoch 9
2023-01-04 04:16:44,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:44,726 INFO:     Epoch: 10
2023-01-04 04:16:46,309 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42818108598391214, 'Total loss': 0.42818108598391214} | train loss {'Reaction outcome loss': 0.3842383504566485, 'Total loss': 0.3842383504566485}
2023-01-04 04:16:46,309 INFO:     Found new best model at epoch 10
2023-01-04 04:16:46,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:46,310 INFO:     Epoch: 11
2023-01-04 04:16:47,910 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4358241687218348, 'Total loss': 0.4358241687218348} | train loss {'Reaction outcome loss': 0.3745957213814241, 'Total loss': 0.3745957213814241}
2023-01-04 04:16:47,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:47,910 INFO:     Epoch: 12
2023-01-04 04:16:49,522 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4282738228638967, 'Total loss': 0.4282738228638967} | train loss {'Reaction outcome loss': 0.36585718371572284, 'Total loss': 0.36585718371572284}
2023-01-04 04:16:49,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:49,522 INFO:     Epoch: 13
2023-01-04 04:16:51,143 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4216699739297231, 'Total loss': 0.4216699739297231} | train loss {'Reaction outcome loss': 0.35796064592517207, 'Total loss': 0.35796064592517207}
2023-01-04 04:16:51,143 INFO:     Found new best model at epoch 13
2023-01-04 04:16:51,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:51,144 INFO:     Epoch: 14
2023-01-04 04:16:52,741 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4389662563800812, 'Total loss': 0.4389662563800812} | train loss {'Reaction outcome loss': 0.3477565756298765, 'Total loss': 0.3477565756298765}
2023-01-04 04:16:52,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:52,741 INFO:     Epoch: 15
2023-01-04 04:16:54,306 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4203746497631073, 'Total loss': 0.4203746497631073} | train loss {'Reaction outcome loss': 0.343022432966824, 'Total loss': 0.343022432966824}
2023-01-04 04:16:54,306 INFO:     Found new best model at epoch 15
2023-01-04 04:16:54,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:54,307 INFO:     Epoch: 16
2023-01-04 04:16:55,874 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42624025940895083, 'Total loss': 0.42624025940895083} | train loss {'Reaction outcome loss': 0.33463864860525966, 'Total loss': 0.33463864860525966}
2023-01-04 04:16:55,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:55,874 INFO:     Epoch: 17
2023-01-04 04:16:57,487 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4110187937815984, 'Total loss': 0.4110187937815984} | train loss {'Reaction outcome loss': 0.32870111997871504, 'Total loss': 0.32870111997871504}
2023-01-04 04:16:57,488 INFO:     Found new best model at epoch 17
2023-01-04 04:16:57,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:57,488 INFO:     Epoch: 18
2023-01-04 04:16:59,079 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4074650496244431, 'Total loss': 0.4074650496244431} | train loss {'Reaction outcome loss': 0.3218749754511527, 'Total loss': 0.3218749754511527}
2023-01-04 04:16:59,079 INFO:     Found new best model at epoch 18
2023-01-04 04:16:59,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:16:59,080 INFO:     Epoch: 19
2023-01-04 04:17:00,688 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41333251098791757, 'Total loss': 0.41333251098791757} | train loss {'Reaction outcome loss': 0.3172620250741496, 'Total loss': 0.3172620250741496}
2023-01-04 04:17:00,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:00,688 INFO:     Epoch: 20
2023-01-04 04:17:02,294 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42611248393853507, 'Total loss': 0.42611248393853507} | train loss {'Reaction outcome loss': 0.3105490244109265, 'Total loss': 0.3105490244109265}
2023-01-04 04:17:02,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:02,294 INFO:     Epoch: 21
2023-01-04 04:17:03,880 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4281517247358958, 'Total loss': 0.4281517247358958} | train loss {'Reaction outcome loss': 0.30653539571883903, 'Total loss': 0.30653539571883903}
2023-01-04 04:17:03,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:03,881 INFO:     Epoch: 22
2023-01-04 04:17:05,453 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4200096994638443, 'Total loss': 0.4200096994638443} | train loss {'Reaction outcome loss': 0.3019944943052574, 'Total loss': 0.3019944943052574}
2023-01-04 04:17:05,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:05,454 INFO:     Epoch: 23
2023-01-04 04:17:07,041 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4235043605168661, 'Total loss': 0.4235043605168661} | train loss {'Reaction outcome loss': 0.29877132579793025, 'Total loss': 0.29877132579793025}
2023-01-04 04:17:07,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:07,041 INFO:     Epoch: 24
2023-01-04 04:17:08,645 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4280924260616302, 'Total loss': 0.4280924260616302} | train loss {'Reaction outcome loss': 0.29450774258070617, 'Total loss': 0.29450774258070617}
2023-01-04 04:17:08,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:08,645 INFO:     Epoch: 25
2023-01-04 04:17:10,241 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42067796488602954, 'Total loss': 0.42067796488602954} | train loss {'Reaction outcome loss': 0.2873311201178462, 'Total loss': 0.2873311201178462}
2023-01-04 04:17:10,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:10,241 INFO:     Epoch: 26
2023-01-04 04:17:11,818 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4240697314341863, 'Total loss': 0.4240697314341863} | train loss {'Reaction outcome loss': 0.28516048274553607, 'Total loss': 0.28516048274553607}
2023-01-04 04:17:11,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:11,818 INFO:     Epoch: 27
2023-01-04 04:17:13,413 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4239510416984558, 'Total loss': 0.4239510416984558} | train loss {'Reaction outcome loss': 0.28262863930885807, 'Total loss': 0.28262863930885807}
2023-01-04 04:17:13,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:13,414 INFO:     Epoch: 28
2023-01-04 04:17:15,004 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3973895390828451, 'Total loss': 0.3973895390828451} | train loss {'Reaction outcome loss': 0.2817874117380511, 'Total loss': 0.2817874117380511}
2023-01-04 04:17:15,004 INFO:     Found new best model at epoch 28
2023-01-04 04:17:15,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:15,005 INFO:     Epoch: 29
2023-01-04 04:17:16,595 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4047814279794693, 'Total loss': 0.4047814279794693} | train loss {'Reaction outcome loss': 0.27699615210838563, 'Total loss': 0.27699615210838563}
2023-01-04 04:17:16,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:16,596 INFO:     Epoch: 30
2023-01-04 04:17:18,209 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4146314720312754, 'Total loss': 0.4146314720312754} | train loss {'Reaction outcome loss': 0.2731877154242383, 'Total loss': 0.2731877154242383}
2023-01-04 04:17:18,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:18,210 INFO:     Epoch: 31
2023-01-04 04:17:19,816 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42789017856121064, 'Total loss': 0.42789017856121064} | train loss {'Reaction outcome loss': 0.2684570826916364, 'Total loss': 0.2684570826916364}
2023-01-04 04:17:19,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:19,817 INFO:     Epoch: 32
2023-01-04 04:17:21,413 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4386417220036189, 'Total loss': 0.4386417220036189} | train loss {'Reaction outcome loss': 0.2645307875843379, 'Total loss': 0.2645307875843379}
2023-01-04 04:17:21,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:21,414 INFO:     Epoch: 33
2023-01-04 04:17:23,021 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4343170702457428, 'Total loss': 0.4343170702457428} | train loss {'Reaction outcome loss': 0.26266693833698757, 'Total loss': 0.26266693833698757}
2023-01-04 04:17:23,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:23,022 INFO:     Epoch: 34
2023-01-04 04:17:24,657 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44402345816294353, 'Total loss': 0.44402345816294353} | train loss {'Reaction outcome loss': 0.2599303944267496, 'Total loss': 0.2599303944267496}
2023-01-04 04:17:24,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:24,657 INFO:     Epoch: 35
2023-01-04 04:17:26,294 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42976127862930297, 'Total loss': 0.42976127862930297} | train loss {'Reaction outcome loss': 0.25664128569790917, 'Total loss': 0.25664128569790917}
2023-01-04 04:17:26,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:26,295 INFO:     Epoch: 36
2023-01-04 04:17:27,919 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43737558722496034, 'Total loss': 0.43737558722496034} | train loss {'Reaction outcome loss': 0.2544928855758949, 'Total loss': 0.2544928855758949}
2023-01-04 04:17:27,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:27,919 INFO:     Epoch: 37
2023-01-04 04:17:29,519 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40499534755945205, 'Total loss': 0.40499534755945205} | train loss {'Reaction outcome loss': 0.25230570102151295, 'Total loss': 0.25230570102151295}
2023-01-04 04:17:29,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:29,519 INFO:     Epoch: 38
2023-01-04 04:17:31,134 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4170378237962723, 'Total loss': 0.4170378237962723} | train loss {'Reaction outcome loss': 0.2496022675050436, 'Total loss': 0.2496022675050436}
2023-01-04 04:17:31,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:31,135 INFO:     Epoch: 39
2023-01-04 04:17:32,709 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4345056613286336, 'Total loss': 0.4345056613286336} | train loss {'Reaction outcome loss': 0.24429002939893382, 'Total loss': 0.24429002939893382}
2023-01-04 04:17:32,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:32,710 INFO:     Epoch: 40
2023-01-04 04:17:34,296 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40817295213540394, 'Total loss': 0.40817295213540394} | train loss {'Reaction outcome loss': 0.243080745811445, 'Total loss': 0.243080745811445}
2023-01-04 04:17:34,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:34,296 INFO:     Epoch: 41
2023-01-04 04:17:35,944 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41674511035283407, 'Total loss': 0.41674511035283407} | train loss {'Reaction outcome loss': 0.24249722479577482, 'Total loss': 0.24249722479577482}
2023-01-04 04:17:35,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:35,944 INFO:     Epoch: 42
2023-01-04 04:17:37,546 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4203070809443792, 'Total loss': 0.4203070809443792} | train loss {'Reaction outcome loss': 0.2396954161516071, 'Total loss': 0.2396954161516071}
2023-01-04 04:17:37,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:37,547 INFO:     Epoch: 43
2023-01-04 04:17:39,113 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4184137572844823, 'Total loss': 0.4184137572844823} | train loss {'Reaction outcome loss': 0.23806943282158705, 'Total loss': 0.23806943282158705}
2023-01-04 04:17:39,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:39,113 INFO:     Epoch: 44
2023-01-04 04:17:40,742 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4164302428563436, 'Total loss': 0.4164302428563436} | train loss {'Reaction outcome loss': 0.23688244033795203, 'Total loss': 0.23688244033795203}
2023-01-04 04:17:40,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:40,743 INFO:     Epoch: 45
2023-01-04 04:17:42,324 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4183294057846069, 'Total loss': 0.4183294057846069} | train loss {'Reaction outcome loss': 0.23545564058488302, 'Total loss': 0.23545564058488302}
2023-01-04 04:17:42,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:42,324 INFO:     Epoch: 46
2023-01-04 04:17:43,915 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42852828005949656, 'Total loss': 0.42852828005949656} | train loss {'Reaction outcome loss': 0.23424446890062658, 'Total loss': 0.23424446890062658}
2023-01-04 04:17:43,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:43,917 INFO:     Epoch: 47
2023-01-04 04:17:45,486 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41857165296872456, 'Total loss': 0.41857165296872456} | train loss {'Reaction outcome loss': 0.23054238605945215, 'Total loss': 0.23054238605945215}
2023-01-04 04:17:45,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:45,486 INFO:     Epoch: 48
2023-01-04 04:17:47,093 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4278432567914327, 'Total loss': 0.4278432567914327} | train loss {'Reaction outcome loss': 0.22929882198354623, 'Total loss': 0.22929882198354623}
2023-01-04 04:17:47,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:47,094 INFO:     Epoch: 49
2023-01-04 04:17:48,664 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4012166996796926, 'Total loss': 0.4012166996796926} | train loss {'Reaction outcome loss': 0.2276676963389355, 'Total loss': 0.2276676963389355}
2023-01-04 04:17:48,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:48,664 INFO:     Epoch: 50
2023-01-04 04:17:50,232 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44326203167438505, 'Total loss': 0.44326203167438505} | train loss {'Reaction outcome loss': 0.22465629369890602, 'Total loss': 0.22465629369890602}
2023-01-04 04:17:50,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:50,233 INFO:     Epoch: 51
2023-01-04 04:17:51,806 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.419804522395134, 'Total loss': 0.419804522395134} | train loss {'Reaction outcome loss': 0.22344321949257903, 'Total loss': 0.22344321949257903}
2023-01-04 04:17:51,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:51,806 INFO:     Epoch: 52
2023-01-04 04:17:53,421 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4372752611835798, 'Total loss': 0.4372752611835798} | train loss {'Reaction outcome loss': 0.2228794814270996, 'Total loss': 0.2228794814270996}
2023-01-04 04:17:53,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:53,422 INFO:     Epoch: 53
2023-01-04 04:17:55,009 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42394400214155514, 'Total loss': 0.42394400214155514} | train loss {'Reaction outcome loss': 0.2197036720458826, 'Total loss': 0.2197036720458826}
2023-01-04 04:17:55,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:55,009 INFO:     Epoch: 54
2023-01-04 04:17:56,582 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4406244734923045, 'Total loss': 0.4406244734923045} | train loss {'Reaction outcome loss': 0.21935661460687644, 'Total loss': 0.21935661460687644}
2023-01-04 04:17:56,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:56,583 INFO:     Epoch: 55
2023-01-04 04:17:58,164 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41830290655295055, 'Total loss': 0.41830290655295055} | train loss {'Reaction outcome loss': 0.21568994603398509, 'Total loss': 0.21568994603398509}
2023-01-04 04:17:58,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:58,165 INFO:     Epoch: 56
2023-01-04 04:17:59,773 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.440164045492808, 'Total loss': 0.440164045492808} | train loss {'Reaction outcome loss': 0.2154416915124459, 'Total loss': 0.2154416915124459}
2023-01-04 04:17:59,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:17:59,773 INFO:     Epoch: 57
2023-01-04 04:18:01,383 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.432671116789182, 'Total loss': 0.432671116789182} | train loss {'Reaction outcome loss': 0.2125812532774506, 'Total loss': 0.2125812532774506}
2023-01-04 04:18:01,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:01,383 INFO:     Epoch: 58
2023-01-04 04:18:02,960 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40896472285191215, 'Total loss': 0.40896472285191215} | train loss {'Reaction outcome loss': 0.21404731050677542, 'Total loss': 0.21404731050677542}
2023-01-04 04:18:02,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:02,962 INFO:     Epoch: 59
2023-01-04 04:18:04,542 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42124478419621786, 'Total loss': 0.42124478419621786} | train loss {'Reaction outcome loss': 0.21061882138741714, 'Total loss': 0.21061882138741714}
2023-01-04 04:18:04,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:04,542 INFO:     Epoch: 60
2023-01-04 04:18:06,133 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4188003957271576, 'Total loss': 0.4188003957271576} | train loss {'Reaction outcome loss': 0.20795769088079025, 'Total loss': 0.20795769088079025}
2023-01-04 04:18:06,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:06,133 INFO:     Epoch: 61
2023-01-04 04:18:07,691 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43502534329891207, 'Total loss': 0.43502534329891207} | train loss {'Reaction outcome loss': 0.20794217442128346, 'Total loss': 0.20794217442128346}
2023-01-04 04:18:07,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:07,692 INFO:     Epoch: 62
2023-01-04 04:18:09,305 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43414991796016694, 'Total loss': 0.43414991796016694} | train loss {'Reaction outcome loss': 0.2074638733191647, 'Total loss': 0.2074638733191647}
2023-01-04 04:18:09,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:09,306 INFO:     Epoch: 63
2023-01-04 04:18:10,923 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4152380466461182, 'Total loss': 0.4152380466461182} | train loss {'Reaction outcome loss': 0.20501223550497616, 'Total loss': 0.20501223550497616}
2023-01-04 04:18:10,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:10,924 INFO:     Epoch: 64
2023-01-04 04:18:12,498 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43814576864242555, 'Total loss': 0.43814576864242555} | train loss {'Reaction outcome loss': 0.2049611681514848, 'Total loss': 0.2049611681514848}
2023-01-04 04:18:12,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:12,498 INFO:     Epoch: 65
2023-01-04 04:18:14,112 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4147322336832682, 'Total loss': 0.4147322336832682} | train loss {'Reaction outcome loss': 0.20293275695158183, 'Total loss': 0.20293275695158183}
2023-01-04 04:18:14,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:14,113 INFO:     Epoch: 66
2023-01-04 04:18:15,691 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.413703882197539, 'Total loss': 0.413703882197539} | train loss {'Reaction outcome loss': 0.1996263116938028, 'Total loss': 0.1996263116938028}
2023-01-04 04:18:15,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:15,691 INFO:     Epoch: 67
2023-01-04 04:18:17,262 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4328015406926473, 'Total loss': 0.4328015406926473} | train loss {'Reaction outcome loss': 0.20048913201929008, 'Total loss': 0.20048913201929008}
2023-01-04 04:18:17,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:17,262 INFO:     Epoch: 68
2023-01-04 04:18:18,855 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43952178756395976, 'Total loss': 0.43952178756395976} | train loss {'Reaction outcome loss': 0.19938278369551157, 'Total loss': 0.19938278369551157}
2023-01-04 04:18:18,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:18,855 INFO:     Epoch: 69
2023-01-04 04:18:20,449 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4426825801531474, 'Total loss': 0.4426825801531474} | train loss {'Reaction outcome loss': 0.1996792056971658, 'Total loss': 0.1996792056971658}
2023-01-04 04:18:20,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:20,450 INFO:     Epoch: 70
2023-01-04 04:18:22,044 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43333600958188373, 'Total loss': 0.43333600958188373} | train loss {'Reaction outcome loss': 0.1958670362313516, 'Total loss': 0.1958670362313516}
2023-01-04 04:18:22,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:22,044 INFO:     Epoch: 71
2023-01-04 04:18:23,612 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.437712820370992, 'Total loss': 0.437712820370992} | train loss {'Reaction outcome loss': 0.19375752259290566, 'Total loss': 0.19375752259290566}
2023-01-04 04:18:23,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:23,613 INFO:     Epoch: 72
2023-01-04 04:18:25,199 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45844358106454214, 'Total loss': 0.45844358106454214} | train loss {'Reaction outcome loss': 0.1948066684587376, 'Total loss': 0.1948066684587376}
2023-01-04 04:18:25,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:25,199 INFO:     Epoch: 73
2023-01-04 04:18:26,783 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4263109395901362, 'Total loss': 0.4263109395901362} | train loss {'Reaction outcome loss': 0.19316879131008674, 'Total loss': 0.19316879131008674}
2023-01-04 04:18:26,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:26,783 INFO:     Epoch: 74
2023-01-04 04:18:28,396 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4326515148083369, 'Total loss': 0.4326515148083369} | train loss {'Reaction outcome loss': 0.19340750543115132, 'Total loss': 0.19340750543115132}
2023-01-04 04:18:28,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:28,396 INFO:     Epoch: 75
2023-01-04 04:18:29,998 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44074344212810196, 'Total loss': 0.44074344212810196} | train loss {'Reaction outcome loss': 0.1919913856774895, 'Total loss': 0.1919913856774895}
2023-01-04 04:18:29,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:29,998 INFO:     Epoch: 76
2023-01-04 04:18:31,610 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4294184669852257, 'Total loss': 0.4294184669852257} | train loss {'Reaction outcome loss': 0.1901018351833098, 'Total loss': 0.1901018351833098}
2023-01-04 04:18:31,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:31,611 INFO:     Epoch: 77
2023-01-04 04:18:33,201 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4349854389826457, 'Total loss': 0.4349854389826457} | train loss {'Reaction outcome loss': 0.18885617654253967, 'Total loss': 0.18885617654253967}
2023-01-04 04:18:33,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:33,202 INFO:     Epoch: 78
2023-01-04 04:18:34,779 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42648307979106903, 'Total loss': 0.42648307979106903} | train loss {'Reaction outcome loss': 0.18743316468911886, 'Total loss': 0.18743316468911886}
2023-01-04 04:18:34,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:34,779 INFO:     Epoch: 79
2023-01-04 04:18:36,386 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4340369353691737, 'Total loss': 0.4340369353691737} | train loss {'Reaction outcome loss': 0.18844506181232687, 'Total loss': 0.18844506181232687}
2023-01-04 04:18:36,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:36,386 INFO:     Epoch: 80
2023-01-04 04:18:37,957 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45400533874829613, 'Total loss': 0.45400533874829613} | train loss {'Reaction outcome loss': 0.18502330307570033, 'Total loss': 0.18502330307570033}
2023-01-04 04:18:37,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:37,957 INFO:     Epoch: 81
2023-01-04 04:18:39,570 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4529717077811559, 'Total loss': 0.4529717077811559} | train loss {'Reaction outcome loss': 0.18529294367988397, 'Total loss': 0.18529294367988397}
2023-01-04 04:18:39,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:39,570 INFO:     Epoch: 82
2023-01-04 04:18:41,168 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43559396664301553, 'Total loss': 0.43559396664301553} | train loss {'Reaction outcome loss': 0.18607872116794116, 'Total loss': 0.18607872116794116}
2023-01-04 04:18:41,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:41,169 INFO:     Epoch: 83
2023-01-04 04:18:42,755 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4347441087166468, 'Total loss': 0.4347441087166468} | train loss {'Reaction outcome loss': 0.1837016322996712, 'Total loss': 0.1837016322996712}
2023-01-04 04:18:42,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:42,755 INFO:     Epoch: 84
2023-01-04 04:18:44,343 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4709942415356636, 'Total loss': 0.4709942415356636} | train loss {'Reaction outcome loss': 0.18549546039234982, 'Total loss': 0.18549546039234982}
2023-01-04 04:18:44,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:44,344 INFO:     Epoch: 85
2023-01-04 04:18:45,957 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4581803441047668, 'Total loss': 0.4581803441047668} | train loss {'Reaction outcome loss': 0.18298536244045643, 'Total loss': 0.18298536244045643}
2023-01-04 04:18:45,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:45,958 INFO:     Epoch: 86
2023-01-04 04:18:47,571 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4405809462070465, 'Total loss': 0.4405809462070465} | train loss {'Reaction outcome loss': 0.1810714201185934, 'Total loss': 0.1810714201185934}
2023-01-04 04:18:47,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:47,571 INFO:     Epoch: 87
2023-01-04 04:18:49,187 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.437868665655454, 'Total loss': 0.437868665655454} | train loss {'Reaction outcome loss': 0.17998576937175362, 'Total loss': 0.17998576937175362}
2023-01-04 04:18:49,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:49,187 INFO:     Epoch: 88
2023-01-04 04:18:50,794 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4597618480523427, 'Total loss': 0.4597618480523427} | train loss {'Reaction outcome loss': 0.1810114939363986, 'Total loss': 0.1810114939363986}
2023-01-04 04:18:50,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:50,795 INFO:     Epoch: 89
2023-01-04 04:18:52,397 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4330856074889501, 'Total loss': 0.4330856074889501} | train loss {'Reaction outcome loss': 0.17888979418679093, 'Total loss': 0.17888979418679093}
2023-01-04 04:18:52,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:52,398 INFO:     Epoch: 90
2023-01-04 04:18:53,970 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45493818720181783, 'Total loss': 0.45493818720181783} | train loss {'Reaction outcome loss': 0.1782792687320905, 'Total loss': 0.1782792687320905}
2023-01-04 04:18:53,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:53,970 INFO:     Epoch: 91
2023-01-04 04:18:55,555 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4346950650215149, 'Total loss': 0.4346950650215149} | train loss {'Reaction outcome loss': 0.17860094960235115, 'Total loss': 0.17860094960235115}
2023-01-04 04:18:55,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:55,555 INFO:     Epoch: 92
2023-01-04 04:18:57,159 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4434882422288259, 'Total loss': 0.4434882422288259} | train loss {'Reaction outcome loss': 0.17802009473208094, 'Total loss': 0.17802009473208094}
2023-01-04 04:18:57,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:57,159 INFO:     Epoch: 93
2023-01-04 04:18:58,739 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4432918091615041, 'Total loss': 0.4432918091615041} | train loss {'Reaction outcome loss': 0.17569819543456291, 'Total loss': 0.17569819543456291}
2023-01-04 04:18:58,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:18:58,739 INFO:     Epoch: 94
2023-01-04 04:19:00,310 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4733013172944387, 'Total loss': 0.4733013172944387} | train loss {'Reaction outcome loss': 0.17365362448957714, 'Total loss': 0.17365362448957714}
2023-01-04 04:19:00,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:00,310 INFO:     Epoch: 95
2023-01-04 04:19:01,880 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44465467631816863, 'Total loss': 0.44465467631816863} | train loss {'Reaction outcome loss': 0.17512191571023342, 'Total loss': 0.17512191571023342}
2023-01-04 04:19:01,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:01,880 INFO:     Epoch: 96
2023-01-04 04:19:03,477 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4427180121342341, 'Total loss': 0.4427180121342341} | train loss {'Reaction outcome loss': 0.17568545677719544, 'Total loss': 0.17568545677719544}
2023-01-04 04:19:03,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:03,477 INFO:     Epoch: 97
2023-01-04 04:19:05,095 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44792471726735433, 'Total loss': 0.44792471726735433} | train loss {'Reaction outcome loss': 0.17348933141732956, 'Total loss': 0.17348933141732956}
2023-01-04 04:19:05,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:05,096 INFO:     Epoch: 98
2023-01-04 04:19:06,712 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45528558393319446, 'Total loss': 0.45528558393319446} | train loss {'Reaction outcome loss': 0.17299539894613364, 'Total loss': 0.17299539894613364}
2023-01-04 04:19:06,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:06,712 INFO:     Epoch: 99
2023-01-04 04:19:08,306 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4592731277147929, 'Total loss': 0.4592731277147929} | train loss {'Reaction outcome loss': 0.17194648580557673, 'Total loss': 0.17194648580557673}
2023-01-04 04:19:08,306 INFO:     Best model found after epoch 29 of 100.
2023-01-04 04:19:08,306 INFO:   Done with stage: TRAINING
2023-01-04 04:19:08,306 INFO:   Starting stage: EVALUATION
2023-01-04 04:19:08,443 INFO:   Done with stage: EVALUATION
2023-01-04 04:19:08,443 INFO:   Leaving out SEQ value Fold_1
2023-01-04 04:19:08,456 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 04:19:08,456 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:19:09,105 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:19:09,106 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:19:09,173 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:19:09,174 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:19:09,174 INFO:     No hyperparam tuning for this model
2023-01-04 04:19:09,174 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:19:09,174 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:19:09,175 INFO:     None feature selector for col prot
2023-01-04 04:19:09,175 INFO:     None feature selector for col prot
2023-01-04 04:19:09,175 INFO:     None feature selector for col prot
2023-01-04 04:19:09,176 INFO:     None feature selector for col chem
2023-01-04 04:19:09,176 INFO:     None feature selector for col chem
2023-01-04 04:19:09,176 INFO:     None feature selector for col chem
2023-01-04 04:19:09,176 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:19:09,176 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:19:09,177 INFO:     Number of params in model 70141
2023-01-04 04:19:09,180 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:19:09,180 INFO:   Starting stage: TRAINING
2023-01-04 04:19:09,224 INFO:     Val loss before train {'Reaction outcome loss': 0.906163215637207, 'Total loss': 0.906163215637207}
2023-01-04 04:19:09,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:09,224 INFO:     Epoch: 0
2023-01-04 04:19:10,781 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.55829043785731, 'Total loss': 0.55829043785731} | train loss {'Reaction outcome loss': 0.8520844418268937, 'Total loss': 0.8520844418268937}
2023-01-04 04:19:10,781 INFO:     Found new best model at epoch 0
2023-01-04 04:19:10,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:10,782 INFO:     Epoch: 1
2023-01-04 04:19:12,352 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4527982095877329, 'Total loss': 0.4527982095877329} | train loss {'Reaction outcome loss': 0.6144410617403931, 'Total loss': 0.6144410617403931}
2023-01-04 04:19:12,352 INFO:     Found new best model at epoch 1
2023-01-04 04:19:12,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:12,353 INFO:     Epoch: 2
2023-01-04 04:19:13,919 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4408385952313741, 'Total loss': 0.4408385952313741} | train loss {'Reaction outcome loss': 0.5317273530767951, 'Total loss': 0.5317273530767951}
2023-01-04 04:19:13,919 INFO:     Found new best model at epoch 2
2023-01-04 04:19:13,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:13,920 INFO:     Epoch: 3
2023-01-04 04:19:15,499 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4220306138197581, 'Total loss': 0.4220306138197581} | train loss {'Reaction outcome loss': 0.49553088974821696, 'Total loss': 0.49553088974821696}
2023-01-04 04:19:15,500 INFO:     Found new best model at epoch 3
2023-01-04 04:19:15,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:15,500 INFO:     Epoch: 4
2023-01-04 04:19:17,063 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.40288231074810027, 'Total loss': 0.40288231074810027} | train loss {'Reaction outcome loss': 0.46309292240020555, 'Total loss': 0.46309292240020555}
2023-01-04 04:19:17,063 INFO:     Found new best model at epoch 4
2023-01-04 04:19:17,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:17,064 INFO:     Epoch: 5
2023-01-04 04:19:18,637 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40118663807710014, 'Total loss': 0.40118663807710014} | train loss {'Reaction outcome loss': 0.44577207893897325, 'Total loss': 0.44577207893897325}
2023-01-04 04:19:18,637 INFO:     Found new best model at epoch 5
2023-01-04 04:19:18,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:18,638 INFO:     Epoch: 6
2023-01-04 04:19:20,188 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3707753578821818, 'Total loss': 0.3707753578821818} | train loss {'Reaction outcome loss': 0.4301479445436062, 'Total loss': 0.4301479445436062}
2023-01-04 04:19:20,188 INFO:     Found new best model at epoch 6
2023-01-04 04:19:20,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:20,189 INFO:     Epoch: 7
2023-01-04 04:19:21,759 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3721241980791092, 'Total loss': 0.3721241980791092} | train loss {'Reaction outcome loss': 0.4184732808298244, 'Total loss': 0.4184732808298244}
2023-01-04 04:19:21,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:21,760 INFO:     Epoch: 8
2023-01-04 04:19:23,367 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3572302753726641, 'Total loss': 0.3572302753726641} | train loss {'Reaction outcome loss': 0.40608930249353903, 'Total loss': 0.40608930249353903}
2023-01-04 04:19:23,367 INFO:     Found new best model at epoch 8
2023-01-04 04:19:23,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:23,368 INFO:     Epoch: 9
2023-01-04 04:19:24,951 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3802073915799459, 'Total loss': 0.3802073915799459} | train loss {'Reaction outcome loss': 0.39569288191996216, 'Total loss': 0.39569288191996216}
2023-01-04 04:19:24,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:24,952 INFO:     Epoch: 10
2023-01-04 04:19:26,527 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3574997474749883, 'Total loss': 0.3574997474749883} | train loss {'Reaction outcome loss': 0.3865192815825179, 'Total loss': 0.3865192815825179}
2023-01-04 04:19:26,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:26,527 INFO:     Epoch: 11
2023-01-04 04:19:28,090 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3796787699063619, 'Total loss': 0.3796787699063619} | train loss {'Reaction outcome loss': 0.3780715155241254, 'Total loss': 0.3780715155241254}
2023-01-04 04:19:28,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:28,090 INFO:     Epoch: 12
2023-01-04 04:19:29,665 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38727450370788574, 'Total loss': 0.38727450370788574} | train loss {'Reaction outcome loss': 0.37288327012961603, 'Total loss': 0.37288327012961603}
2023-01-04 04:19:29,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:29,665 INFO:     Epoch: 13
2023-01-04 04:19:31,240 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35927285452683766, 'Total loss': 0.35927285452683766} | train loss {'Reaction outcome loss': 0.3634155377090632, 'Total loss': 0.3634155377090632}
2023-01-04 04:19:31,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:31,240 INFO:     Epoch: 14
2023-01-04 04:19:32,816 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37305633425712587, 'Total loss': 0.37305633425712587} | train loss {'Reaction outcome loss': 0.3578400866780089, 'Total loss': 0.3578400866780089}
2023-01-04 04:19:32,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:32,817 INFO:     Epoch: 15
2023-01-04 04:19:34,390 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3699647804101308, 'Total loss': 0.3699647804101308} | train loss {'Reaction outcome loss': 0.34846035505716616, 'Total loss': 0.34846035505716616}
2023-01-04 04:19:34,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:34,391 INFO:     Epoch: 16
2023-01-04 04:19:35,549 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35721374998490013, 'Total loss': 0.35721374998490013} | train loss {'Reaction outcome loss': 0.34239598165092233, 'Total loss': 0.34239598165092233}
2023-01-04 04:19:35,549 INFO:     Found new best model at epoch 16
2023-01-04 04:19:35,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:35,550 INFO:     Epoch: 17
2023-01-04 04:19:36,646 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.35261364579200744, 'Total loss': 0.35261364579200744} | train loss {'Reaction outcome loss': 0.33579306653786056, 'Total loss': 0.33579306653786056}
2023-01-04 04:19:36,646 INFO:     Found new best model at epoch 17
2023-01-04 04:19:36,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:36,647 INFO:     Epoch: 18
2023-01-04 04:19:37,737 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3549588640530904, 'Total loss': 0.3549588640530904} | train loss {'Reaction outcome loss': 0.3310945321679552, 'Total loss': 0.3310945321679552}
2023-01-04 04:19:37,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:37,738 INFO:     Epoch: 19
2023-01-04 04:19:38,827 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.35267312626043956, 'Total loss': 0.35267312626043956} | train loss {'Reaction outcome loss': 0.3266588697830836, 'Total loss': 0.3266588697830836}
2023-01-04 04:19:38,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:38,827 INFO:     Epoch: 20
2023-01-04 04:19:40,268 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34038294131557145, 'Total loss': 0.34038294131557145} | train loss {'Reaction outcome loss': 0.32041851452964565, 'Total loss': 0.32041851452964565}
2023-01-04 04:19:40,269 INFO:     Found new best model at epoch 20
2023-01-04 04:19:40,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:40,270 INFO:     Epoch: 21
2023-01-04 04:19:41,843 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3416342775026957, 'Total loss': 0.3416342775026957} | train loss {'Reaction outcome loss': 0.317387431150391, 'Total loss': 0.317387431150391}
2023-01-04 04:19:41,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:41,843 INFO:     Epoch: 22
2023-01-04 04:19:43,454 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35098010500272114, 'Total loss': 0.35098010500272114} | train loss {'Reaction outcome loss': 0.3142129415339166, 'Total loss': 0.3142129415339166}
2023-01-04 04:19:43,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:43,454 INFO:     Epoch: 23
2023-01-04 04:19:45,040 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3438911934693654, 'Total loss': 0.3438911934693654} | train loss {'Reaction outcome loss': 0.3085864182193201, 'Total loss': 0.3085864182193201}
2023-01-04 04:19:45,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:45,041 INFO:     Epoch: 24
2023-01-04 04:19:46,651 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3519638001918793, 'Total loss': 0.3519638001918793} | train loss {'Reaction outcome loss': 0.3052998871266187, 'Total loss': 0.3052998871266187}
2023-01-04 04:19:46,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:46,651 INFO:     Epoch: 25
2023-01-04 04:19:48,264 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.33930726945400236, 'Total loss': 0.33930726945400236} | train loss {'Reaction outcome loss': 0.29856554104949967, 'Total loss': 0.29856554104949967}
2023-01-04 04:19:48,264 INFO:     Found new best model at epoch 25
2023-01-04 04:19:48,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:48,265 INFO:     Epoch: 26
2023-01-04 04:19:49,827 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3426029841105143, 'Total loss': 0.3426029841105143} | train loss {'Reaction outcome loss': 0.29401713294478565, 'Total loss': 0.29401713294478565}
2023-01-04 04:19:49,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:49,827 INFO:     Epoch: 27
2023-01-04 04:19:51,438 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34888652761777245, 'Total loss': 0.34888652761777245} | train loss {'Reaction outcome loss': 0.2906167105440692, 'Total loss': 0.2906167105440692}
2023-01-04 04:19:51,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:51,438 INFO:     Epoch: 28
2023-01-04 04:19:53,029 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.360100049773852, 'Total loss': 0.360100049773852} | train loss {'Reaction outcome loss': 0.28638777031730384, 'Total loss': 0.28638777031730384}
2023-01-04 04:19:53,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:53,029 INFO:     Epoch: 29
2023-01-04 04:19:54,637 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.33326022525628407, 'Total loss': 0.33326022525628407} | train loss {'Reaction outcome loss': 0.2834391712651148, 'Total loss': 0.2834391712651148}
2023-01-04 04:19:54,637 INFO:     Found new best model at epoch 29
2023-01-04 04:19:54,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:54,638 INFO:     Epoch: 30
2023-01-04 04:19:56,208 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3441160529851913, 'Total loss': 0.3441160529851913} | train loss {'Reaction outcome loss': 0.28095266214766346, 'Total loss': 0.28095266214766346}
2023-01-04 04:19:56,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:56,208 INFO:     Epoch: 31
2023-01-04 04:19:57,803 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3824838320414225, 'Total loss': 0.3824838320414225} | train loss {'Reaction outcome loss': 0.2779945467527096, 'Total loss': 0.2779945467527096}
2023-01-04 04:19:57,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:57,805 INFO:     Epoch: 32
2023-01-04 04:19:59,380 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3380127787590027, 'Total loss': 0.3380127787590027} | train loss {'Reaction outcome loss': 0.2754341353536089, 'Total loss': 0.2754341353536089}
2023-01-04 04:19:59,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:19:59,380 INFO:     Epoch: 33
2023-01-04 04:20:00,989 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35197658886512123, 'Total loss': 0.35197658886512123} | train loss {'Reaction outcome loss': 0.27084173136578377, 'Total loss': 0.27084173136578377}
2023-01-04 04:20:00,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:00,989 INFO:     Epoch: 34
2023-01-04 04:20:02,551 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3463102991382281, 'Total loss': 0.3463102991382281} | train loss {'Reaction outcome loss': 0.2658835467865397, 'Total loss': 0.2658835467865397}
2023-01-04 04:20:02,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:02,552 INFO:     Epoch: 35
2023-01-04 04:20:04,131 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3357983941833178, 'Total loss': 0.3357983941833178} | train loss {'Reaction outcome loss': 0.26431969782480824, 'Total loss': 0.26431969782480824}
2023-01-04 04:20:04,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:04,132 INFO:     Epoch: 36
2023-01-04 04:20:05,709 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.37136250336964927, 'Total loss': 0.37136250336964927} | train loss {'Reaction outcome loss': 0.26029632674468745, 'Total loss': 0.26029632674468745}
2023-01-04 04:20:05,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:05,710 INFO:     Epoch: 37
2023-01-04 04:20:07,277 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3446550408999125, 'Total loss': 0.3446550408999125} | train loss {'Reaction outcome loss': 0.25925119041086553, 'Total loss': 0.25925119041086553}
2023-01-04 04:20:07,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:07,278 INFO:     Epoch: 38
2023-01-04 04:20:08,856 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3478707432746887, 'Total loss': 0.3478707432746887} | train loss {'Reaction outcome loss': 0.25485716491337224, 'Total loss': 0.25485716491337224}
2023-01-04 04:20:08,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:08,856 INFO:     Epoch: 39
2023-01-04 04:20:10,432 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.32888162235418955, 'Total loss': 0.32888162235418955} | train loss {'Reaction outcome loss': 0.2534264470604095, 'Total loss': 0.2534264470604095}
2023-01-04 04:20:10,432 INFO:     Found new best model at epoch 39
2023-01-04 04:20:10,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:10,433 INFO:     Epoch: 40
2023-01-04 04:20:11,991 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36038402020931243, 'Total loss': 0.36038402020931243} | train loss {'Reaction outcome loss': 0.2519931455616986, 'Total loss': 0.2519931455616986}
2023-01-04 04:20:11,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:11,991 INFO:     Epoch: 41
2023-01-04 04:20:13,567 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3403247093160947, 'Total loss': 0.3403247093160947} | train loss {'Reaction outcome loss': 0.2477284589639077, 'Total loss': 0.2477284589639077}
2023-01-04 04:20:13,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:13,568 INFO:     Epoch: 42
2023-01-04 04:20:15,136 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3762150168418884, 'Total loss': 0.3762150168418884} | train loss {'Reaction outcome loss': 0.24743744923354505, 'Total loss': 0.24743744923354505}
2023-01-04 04:20:15,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:15,136 INFO:     Epoch: 43
2023-01-04 04:20:16,701 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35765656431516013, 'Total loss': 0.35765656431516013} | train loss {'Reaction outcome loss': 0.24364588277298452, 'Total loss': 0.24364588277298452}
2023-01-04 04:20:16,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:16,702 INFO:     Epoch: 44
2023-01-04 04:20:18,276 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.34331761598587035, 'Total loss': 0.34331761598587035} | train loss {'Reaction outcome loss': 0.2417908747554262, 'Total loss': 0.2417908747554262}
2023-01-04 04:20:18,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:18,276 INFO:     Epoch: 45
2023-01-04 04:20:19,858 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3220383400718371, 'Total loss': 0.3220383400718371} | train loss {'Reaction outcome loss': 0.23663403912559972, 'Total loss': 0.23663403912559972}
2023-01-04 04:20:19,858 INFO:     Found new best model at epoch 45
2023-01-04 04:20:19,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:19,860 INFO:     Epoch: 46
2023-01-04 04:20:21,505 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3422530045111974, 'Total loss': 0.3422530045111974} | train loss {'Reaction outcome loss': 0.2356301418099648, 'Total loss': 0.2356301418099648}
2023-01-04 04:20:21,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:21,506 INFO:     Epoch: 47
2023-01-04 04:20:23,158 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.32876153935988744, 'Total loss': 0.32876153935988744} | train loss {'Reaction outcome loss': 0.23396599555776998, 'Total loss': 0.23396599555776998}
2023-01-04 04:20:23,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:23,158 INFO:     Epoch: 48
2023-01-04 04:20:24,789 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3317618042230606, 'Total loss': 0.3317618042230606} | train loss {'Reaction outcome loss': 0.23096706030460504, 'Total loss': 0.23096706030460504}
2023-01-04 04:20:24,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:24,789 INFO:     Epoch: 49
2023-01-04 04:20:26,437 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.32745845913887023, 'Total loss': 0.32745845913887023} | train loss {'Reaction outcome loss': 0.23236305987114433, 'Total loss': 0.23236305987114433}
2023-01-04 04:20:26,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:26,437 INFO:     Epoch: 50
2023-01-04 04:20:28,079 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34045654932657876, 'Total loss': 0.34045654932657876} | train loss {'Reaction outcome loss': 0.22808079362502356, 'Total loss': 0.22808079362502356}
2023-01-04 04:20:28,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:28,079 INFO:     Epoch: 51
2023-01-04 04:20:29,696 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36062651574611665, 'Total loss': 0.36062651574611665} | train loss {'Reaction outcome loss': 0.22581280545491875, 'Total loss': 0.22581280545491875}
2023-01-04 04:20:29,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:29,697 INFO:     Epoch: 52
2023-01-04 04:20:31,317 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3475020855665207, 'Total loss': 0.3475020855665207} | train loss {'Reaction outcome loss': 0.22289735256206422, 'Total loss': 0.22289735256206422}
2023-01-04 04:20:31,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:31,317 INFO:     Epoch: 53
2023-01-04 04:20:32,891 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.33678579529126484, 'Total loss': 0.33678579529126484} | train loss {'Reaction outcome loss': 0.22245982369824208, 'Total loss': 0.22245982369824208}
2023-01-04 04:20:32,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:32,892 INFO:     Epoch: 54
2023-01-04 04:20:34,474 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37879950602849327, 'Total loss': 0.37879950602849327} | train loss {'Reaction outcome loss': 0.22096682282594535, 'Total loss': 0.22096682282594535}
2023-01-04 04:20:34,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:34,474 INFO:     Epoch: 55
2023-01-04 04:20:36,089 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.31235965391000114, 'Total loss': 0.31235965391000114} | train loss {'Reaction outcome loss': 0.21941990403956546, 'Total loss': 0.21941990403956546}
2023-01-04 04:20:36,089 INFO:     Found new best model at epoch 55
2023-01-04 04:20:36,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:36,090 INFO:     Epoch: 56
2023-01-04 04:20:37,689 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.339711985985438, 'Total loss': 0.339711985985438} | train loss {'Reaction outcome loss': 0.21867451722641568, 'Total loss': 0.21867451722641568}
2023-01-04 04:20:37,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:37,689 INFO:     Epoch: 57
2023-01-04 04:20:39,271 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3539253681898117, 'Total loss': 0.3539253681898117} | train loss {'Reaction outcome loss': 0.21611287740431043, 'Total loss': 0.21611287740431043}
2023-01-04 04:20:39,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:39,271 INFO:     Epoch: 58
2023-01-04 04:20:40,877 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.32264658249914646, 'Total loss': 0.32264658249914646} | train loss {'Reaction outcome loss': 0.2145111966373283, 'Total loss': 0.2145111966373283}
2023-01-04 04:20:40,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:40,877 INFO:     Epoch: 59
2023-01-04 04:20:42,453 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33463380734125775, 'Total loss': 0.33463380734125775} | train loss {'Reaction outcome loss': 0.21431092170814237, 'Total loss': 0.21431092170814237}
2023-01-04 04:20:42,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:42,453 INFO:     Epoch: 60
2023-01-04 04:20:44,029 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38679467837015785, 'Total loss': 0.38679467837015785} | train loss {'Reaction outcome loss': 0.21273633870449696, 'Total loss': 0.21273633870449696}
2023-01-04 04:20:44,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:44,029 INFO:     Epoch: 61
2023-01-04 04:20:45,612 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38319758176803587, 'Total loss': 0.38319758176803587} | train loss {'Reaction outcome loss': 0.21085302697515096, 'Total loss': 0.21085302697515096}
2023-01-04 04:20:45,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:45,612 INFO:     Epoch: 62
2023-01-04 04:20:47,175 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3370246887207031, 'Total loss': 0.3370246887207031} | train loss {'Reaction outcome loss': 0.207851611268826, 'Total loss': 0.207851611268826}
2023-01-04 04:20:47,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:47,175 INFO:     Epoch: 63
2023-01-04 04:20:48,784 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.33715992073218026, 'Total loss': 0.33715992073218026} | train loss {'Reaction outcome loss': 0.2049767456184595, 'Total loss': 0.2049767456184595}
2023-01-04 04:20:48,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:48,785 INFO:     Epoch: 64
2023-01-04 04:20:50,392 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3472662031650543, 'Total loss': 0.3472662031650543} | train loss {'Reaction outcome loss': 0.20548070978796307, 'Total loss': 0.20548070978796307}
2023-01-04 04:20:50,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:50,392 INFO:     Epoch: 65
2023-01-04 04:20:51,991 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3140239842236042, 'Total loss': 0.3140239842236042} | train loss {'Reaction outcome loss': 0.20605714587774468, 'Total loss': 0.20605714587774468}
2023-01-04 04:20:51,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:51,992 INFO:     Epoch: 66
2023-01-04 04:20:53,592 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3523421108722687, 'Total loss': 0.3523421108722687} | train loss {'Reaction outcome loss': 0.20399029072606084, 'Total loss': 0.20399029072606084}
2023-01-04 04:20:53,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:53,592 INFO:     Epoch: 67
2023-01-04 04:20:55,200 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.34629139105478923, 'Total loss': 0.34629139105478923} | train loss {'Reaction outcome loss': 0.20077960103095233, 'Total loss': 0.20077960103095233}
2023-01-04 04:20:55,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:55,200 INFO:     Epoch: 68
2023-01-04 04:20:56,787 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3513804316520691, 'Total loss': 0.3513804316520691} | train loss {'Reaction outcome loss': 0.2010575018604815, 'Total loss': 0.2010575018604815}
2023-01-04 04:20:56,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:56,787 INFO:     Epoch: 69
2023-01-04 04:20:58,394 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3528224403659503, 'Total loss': 0.3528224403659503} | train loss {'Reaction outcome loss': 0.20162476533716853, 'Total loss': 0.20162476533716853}
2023-01-04 04:20:58,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:58,394 INFO:     Epoch: 70
2023-01-04 04:20:59,984 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3201367884874344, 'Total loss': 0.3201367884874344} | train loss {'Reaction outcome loss': 0.19808912653844435, 'Total loss': 0.19808912653844435}
2023-01-04 04:20:59,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:20:59,985 INFO:     Epoch: 71
2023-01-04 04:21:01,546 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.31759432752927147, 'Total loss': 0.31759432752927147} | train loss {'Reaction outcome loss': 0.19960118916172248, 'Total loss': 0.19960118916172248}
2023-01-04 04:21:01,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:01,546 INFO:     Epoch: 72
2023-01-04 04:21:03,127 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3395650071402391, 'Total loss': 0.3395650071402391} | train loss {'Reaction outcome loss': 0.19520643959333608, 'Total loss': 0.19520643959333608}
2023-01-04 04:21:03,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:03,128 INFO:     Epoch: 73
2023-01-04 04:21:04,704 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3331640362739563, 'Total loss': 0.3331640362739563} | train loss {'Reaction outcome loss': 0.1944748944510798, 'Total loss': 0.1944748944510798}
2023-01-04 04:21:04,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:04,704 INFO:     Epoch: 74
2023-01-04 04:21:06,264 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3521137361725171, 'Total loss': 0.3521137361725171} | train loss {'Reaction outcome loss': 0.1952219322978795, 'Total loss': 0.1952219322978795}
2023-01-04 04:21:06,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:06,264 INFO:     Epoch: 75
2023-01-04 04:21:07,872 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.33164135068655015, 'Total loss': 0.33164135068655015} | train loss {'Reaction outcome loss': 0.19462237148221595, 'Total loss': 0.19462237148221595}
2023-01-04 04:21:07,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:07,873 INFO:     Epoch: 76
2023-01-04 04:21:09,512 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3419821262359619, 'Total loss': 0.3419821262359619} | train loss {'Reaction outcome loss': 0.19478527961414813, 'Total loss': 0.19478527961414813}
2023-01-04 04:21:09,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:09,513 INFO:     Epoch: 77
2023-01-04 04:21:11,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3326089839140574, 'Total loss': 0.3326089839140574} | train loss {'Reaction outcome loss': 0.1936910487029142, 'Total loss': 0.1936910487029142}
2023-01-04 04:21:11,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:11,140 INFO:     Epoch: 78
2023-01-04 04:21:12,726 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.340622279047966, 'Total loss': 0.340622279047966} | train loss {'Reaction outcome loss': 0.1906328530702399, 'Total loss': 0.1906328530702399}
2023-01-04 04:21:12,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:12,726 INFO:     Epoch: 79
2023-01-04 04:21:14,316 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35331445634365083, 'Total loss': 0.35331445634365083} | train loss {'Reaction outcome loss': 0.19023172040521116, 'Total loss': 0.19023172040521116}
2023-01-04 04:21:14,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:14,317 INFO:     Epoch: 80
2023-01-04 04:21:15,919 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3453433329860369, 'Total loss': 0.3453433329860369} | train loss {'Reaction outcome loss': 0.18722945562949328, 'Total loss': 0.18722945562949328}
2023-01-04 04:21:15,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:15,919 INFO:     Epoch: 81
2023-01-04 04:21:17,508 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3311103343963623, 'Total loss': 0.3311103343963623} | train loss {'Reaction outcome loss': 0.18796326268477972, 'Total loss': 0.18796326268477972}
2023-01-04 04:21:17,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:17,508 INFO:     Epoch: 82
2023-01-04 04:21:19,098 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34135353763898213, 'Total loss': 0.34135353763898213} | train loss {'Reaction outcome loss': 0.18973604311327358, 'Total loss': 0.18973604311327358}
2023-01-04 04:21:19,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:19,098 INFO:     Epoch: 83
2023-01-04 04:21:20,677 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3799014647801717, 'Total loss': 0.3799014647801717} | train loss {'Reaction outcome loss': 0.1851258481897059, 'Total loss': 0.1851258481897059}
2023-01-04 04:21:20,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:20,678 INFO:     Epoch: 84
2023-01-04 04:21:22,256 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33951331774393717, 'Total loss': 0.33951331774393717} | train loss {'Reaction outcome loss': 0.18425036094837136, 'Total loss': 0.18425036094837136}
2023-01-04 04:21:22,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:22,257 INFO:     Epoch: 85
2023-01-04 04:21:23,825 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3378945216536522, 'Total loss': 0.3378945216536522} | train loss {'Reaction outcome loss': 0.18334207036993005, 'Total loss': 0.18334207036993005}
2023-01-04 04:21:23,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:23,825 INFO:     Epoch: 86
2023-01-04 04:21:25,432 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33607349724819263, 'Total loss': 0.33607349724819263} | train loss {'Reaction outcome loss': 0.18239056325821212, 'Total loss': 0.18239056325821212}
2023-01-04 04:21:25,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:25,432 INFO:     Epoch: 87
2023-01-04 04:21:27,004 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3680198907852173, 'Total loss': 0.3680198907852173} | train loss {'Reaction outcome loss': 0.17966621861735108, 'Total loss': 0.17966621861735108}
2023-01-04 04:21:27,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:27,005 INFO:     Epoch: 88
2023-01-04 04:21:28,581 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.33641465405623117, 'Total loss': 0.33641465405623117} | train loss {'Reaction outcome loss': 0.1791045805609925, 'Total loss': 0.1791045805609925}
2023-01-04 04:21:28,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:28,581 INFO:     Epoch: 89
2023-01-04 04:21:30,184 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.356356281042099, 'Total loss': 0.356356281042099} | train loss {'Reaction outcome loss': 0.17998269699759536, 'Total loss': 0.17998269699759536}
2023-01-04 04:21:30,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:30,184 INFO:     Epoch: 90
2023-01-04 04:21:31,758 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3190394063790639, 'Total loss': 0.3190394063790639} | train loss {'Reaction outcome loss': 0.1779608817023972, 'Total loss': 0.1779608817023972}
2023-01-04 04:21:31,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:31,758 INFO:     Epoch: 91
2023-01-04 04:21:33,340 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3216055194536845, 'Total loss': 0.3216055194536845} | train loss {'Reaction outcome loss': 0.17920957032877666, 'Total loss': 0.17920957032877666}
2023-01-04 04:21:33,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:33,341 INFO:     Epoch: 92
2023-01-04 04:21:34,948 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3467222740252813, 'Total loss': 0.3467222740252813} | train loss {'Reaction outcome loss': 0.1763333986741883, 'Total loss': 0.1763333986741883}
2023-01-04 04:21:34,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:34,948 INFO:     Epoch: 93
2023-01-04 04:21:36,555 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3567072590192159, 'Total loss': 0.3567072590192159} | train loss {'Reaction outcome loss': 0.17808016136820828, 'Total loss': 0.17808016136820828}
2023-01-04 04:21:36,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:36,555 INFO:     Epoch: 94
2023-01-04 04:21:38,121 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3392774557073911, 'Total loss': 0.3392774557073911} | train loss {'Reaction outcome loss': 0.1755839903555783, 'Total loss': 0.1755839903555783}
2023-01-04 04:21:38,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:38,121 INFO:     Epoch: 95
2023-01-04 04:21:39,698 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35121824145317077, 'Total loss': 0.35121824145317077} | train loss {'Reaction outcome loss': 0.1760734515503431, 'Total loss': 0.1760734515503431}
2023-01-04 04:21:39,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:39,699 INFO:     Epoch: 96
2023-01-04 04:21:41,259 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3777760590116183, 'Total loss': 0.3777760590116183} | train loss {'Reaction outcome loss': 0.1759188700153496, 'Total loss': 0.1759188700153496}
2023-01-04 04:21:41,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:41,259 INFO:     Epoch: 97
2023-01-04 04:21:42,831 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3395577867825826, 'Total loss': 0.3395577867825826} | train loss {'Reaction outcome loss': 0.1750483335415413, 'Total loss': 0.1750483335415413}
2023-01-04 04:21:42,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:42,831 INFO:     Epoch: 98
2023-01-04 04:21:44,443 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3387843151887258, 'Total loss': 0.3387843151887258} | train loss {'Reaction outcome loss': 0.17281585737325988, 'Total loss': 0.17281585737325988}
2023-01-04 04:21:44,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:44,443 INFO:     Epoch: 99
2023-01-04 04:21:46,030 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.34545114239056907, 'Total loss': 0.34545114239056907} | train loss {'Reaction outcome loss': 0.17190874872845172, 'Total loss': 0.17190874872845172}
2023-01-04 04:21:46,031 INFO:     Best model found after epoch 56 of 100.
2023-01-04 04:21:46,031 INFO:   Done with stage: TRAINING
2023-01-04 04:21:46,031 INFO:   Starting stage: EVALUATION
2023-01-04 04:21:46,173 INFO:   Done with stage: EVALUATION
2023-01-04 04:21:46,173 INFO:   Leaving out SEQ value Fold_2
2023-01-04 04:21:46,186 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 04:21:46,186 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:21:46,836 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:21:46,836 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:21:46,904 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:21:46,904 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:21:46,904 INFO:     No hyperparam tuning for this model
2023-01-04 04:21:46,904 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:21:46,904 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:21:46,905 INFO:     None feature selector for col prot
2023-01-04 04:21:46,905 INFO:     None feature selector for col prot
2023-01-04 04:21:46,905 INFO:     None feature selector for col prot
2023-01-04 04:21:46,906 INFO:     None feature selector for col chem
2023-01-04 04:21:46,906 INFO:     None feature selector for col chem
2023-01-04 04:21:46,906 INFO:     None feature selector for col chem
2023-01-04 04:21:46,906 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:21:46,906 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:21:46,907 INFO:     Number of params in model 70141
2023-01-04 04:21:46,910 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:21:46,910 INFO:   Starting stage: TRAINING
2023-01-04 04:21:46,955 INFO:     Val loss before train {'Reaction outcome loss': 0.9783585568269094, 'Total loss': 0.9783585568269094}
2023-01-04 04:21:46,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:46,955 INFO:     Epoch: 0
2023-01-04 04:21:48,541 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6580122987429301, 'Total loss': 0.6580122987429301} | train loss {'Reaction outcome loss': 0.8500133124884645, 'Total loss': 0.8500133124884645}
2023-01-04 04:21:48,541 INFO:     Found new best model at epoch 0
2023-01-04 04:21:48,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:48,542 INFO:     Epoch: 1
2023-01-04 04:21:50,119 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5733676671981811, 'Total loss': 0.5733676671981811} | train loss {'Reaction outcome loss': 0.6105841810083037, 'Total loss': 0.6105841810083037}
2023-01-04 04:21:50,119 INFO:     Found new best model at epoch 1
2023-01-04 04:21:50,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:50,120 INFO:     Epoch: 2
2023-01-04 04:21:51,682 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4897227704524994, 'Total loss': 0.4897227704524994} | train loss {'Reaction outcome loss': 0.5308785137215224, 'Total loss': 0.5308785137215224}
2023-01-04 04:21:51,682 INFO:     Found new best model at epoch 2
2023-01-04 04:21:51,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:51,683 INFO:     Epoch: 3
2023-01-04 04:21:53,246 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4644714295864105, 'Total loss': 0.4644714295864105} | train loss {'Reaction outcome loss': 0.48645770472794003, 'Total loss': 0.48645770472794003}
2023-01-04 04:21:53,247 INFO:     Found new best model at epoch 3
2023-01-04 04:21:53,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:53,247 INFO:     Epoch: 4
2023-01-04 04:21:54,796 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4359651173154513, 'Total loss': 0.4359651173154513} | train loss {'Reaction outcome loss': 0.4560651410219854, 'Total loss': 0.4560651410219854}
2023-01-04 04:21:54,796 INFO:     Found new best model at epoch 4
2023-01-04 04:21:54,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:54,797 INFO:     Epoch: 5
2023-01-04 04:21:56,393 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4341703116893768, 'Total loss': 0.4341703116893768} | train loss {'Reaction outcome loss': 0.4367535715283503, 'Total loss': 0.4367535715283503}
2023-01-04 04:21:56,393 INFO:     Found new best model at epoch 5
2023-01-04 04:21:56,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:56,394 INFO:     Epoch: 6
2023-01-04 04:21:57,985 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41874725023905435, 'Total loss': 0.41874725023905435} | train loss {'Reaction outcome loss': 0.4182886711125884, 'Total loss': 0.4182886711125884}
2023-01-04 04:21:57,986 INFO:     Found new best model at epoch 6
2023-01-04 04:21:57,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:57,986 INFO:     Epoch: 7
2023-01-04 04:21:59,559 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43062484860420225, 'Total loss': 0.43062484860420225} | train loss {'Reaction outcome loss': 0.4025045810370428, 'Total loss': 0.4025045810370428}
2023-01-04 04:21:59,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:21:59,560 INFO:     Epoch: 8
2023-01-04 04:22:01,159 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39686791946490607, 'Total loss': 0.39686791946490607} | train loss {'Reaction outcome loss': 0.3931829699785947, 'Total loss': 0.3931829699785947}
2023-01-04 04:22:01,159 INFO:     Found new best model at epoch 8
2023-01-04 04:22:01,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:01,160 INFO:     Epoch: 9
2023-01-04 04:22:02,757 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.393343922495842, 'Total loss': 0.393343922495842} | train loss {'Reaction outcome loss': 0.38235293917110486, 'Total loss': 0.38235293917110486}
2023-01-04 04:22:02,757 INFO:     Found new best model at epoch 9
2023-01-04 04:22:02,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:02,758 INFO:     Epoch: 10
2023-01-04 04:22:04,312 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40752229988574984, 'Total loss': 0.40752229988574984} | train loss {'Reaction outcome loss': 0.3715264959418906, 'Total loss': 0.3715264959418906}
2023-01-04 04:22:04,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:04,312 INFO:     Epoch: 11
2023-01-04 04:22:05,880 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4064631114403407, 'Total loss': 0.4064631114403407} | train loss {'Reaction outcome loss': 0.3615695203197398, 'Total loss': 0.3615695203197398}
2023-01-04 04:22:05,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:05,881 INFO:     Epoch: 12
2023-01-04 04:22:07,459 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4163042426109314, 'Total loss': 0.4163042426109314} | train loss {'Reaction outcome loss': 0.35263602067183747, 'Total loss': 0.35263602067183747}
2023-01-04 04:22:07,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:07,459 INFO:     Epoch: 13
2023-01-04 04:22:09,032 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44038758079210916, 'Total loss': 0.44038758079210916} | train loss {'Reaction outcome loss': 0.34936335754350545, 'Total loss': 0.34936335754350545}
2023-01-04 04:22:09,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:09,032 INFO:     Epoch: 14
2023-01-04 04:22:10,635 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4134531855583191, 'Total loss': 0.4134531855583191} | train loss {'Reaction outcome loss': 0.3412445695637777, 'Total loss': 0.3412445695637777}
2023-01-04 04:22:10,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:10,636 INFO:     Epoch: 15
2023-01-04 04:22:12,193 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40308334728082024, 'Total loss': 0.40308334728082024} | train loss {'Reaction outcome loss': 0.33052483569432006, 'Total loss': 0.33052483569432006}
2023-01-04 04:22:12,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:12,194 INFO:     Epoch: 16
2023-01-04 04:22:13,759 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38851009706656137, 'Total loss': 0.38851009706656137} | train loss {'Reaction outcome loss': 0.3259849096631212, 'Total loss': 0.3259849096631212}
2023-01-04 04:22:13,759 INFO:     Found new best model at epoch 16
2023-01-04 04:22:13,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:13,760 INFO:     Epoch: 17
2023-01-04 04:22:15,332 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3932337462902069, 'Total loss': 0.3932337462902069} | train loss {'Reaction outcome loss': 0.3219131179896228, 'Total loss': 0.3219131179896228}
2023-01-04 04:22:15,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:15,332 INFO:     Epoch: 18
2023-01-04 04:22:16,887 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4212796211242676, 'Total loss': 0.4212796211242676} | train loss {'Reaction outcome loss': 0.3160063556199584, 'Total loss': 0.3160063556199584}
2023-01-04 04:22:16,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:16,888 INFO:     Epoch: 19
2023-01-04 04:22:18,482 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42961657444636026, 'Total loss': 0.42961657444636026} | train loss {'Reaction outcome loss': 0.30999131212045344, 'Total loss': 0.30999131212045344}
2023-01-04 04:22:18,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:18,483 INFO:     Epoch: 20
2023-01-04 04:22:20,080 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40900774002075196, 'Total loss': 0.40900774002075196} | train loss {'Reaction outcome loss': 0.3037280057354167, 'Total loss': 0.3037280057354167}
2023-01-04 04:22:20,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:20,081 INFO:     Epoch: 21
2023-01-04 04:22:21,656 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4223429640134176, 'Total loss': 0.4223429640134176} | train loss {'Reaction outcome loss': 0.3008194913008556, 'Total loss': 0.3008194913008556}
2023-01-04 04:22:21,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:21,656 INFO:     Epoch: 22
2023-01-04 04:22:23,246 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41930099328358966, 'Total loss': 0.41930099328358966} | train loss {'Reaction outcome loss': 0.29578177410957995, 'Total loss': 0.29578177410957995}
2023-01-04 04:22:23,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:23,246 INFO:     Epoch: 23
2023-01-04 04:22:24,834 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4028212547302246, 'Total loss': 0.4028212547302246} | train loss {'Reaction outcome loss': 0.28948913367526996, 'Total loss': 0.28948913367526996}
2023-01-04 04:22:24,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:24,834 INFO:     Epoch: 24
2023-01-04 04:22:26,400 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4004688133796056, 'Total loss': 0.4004688133796056} | train loss {'Reaction outcome loss': 0.28680467194571707, 'Total loss': 0.28680467194571707}
2023-01-04 04:22:26,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:26,400 INFO:     Epoch: 25
2023-01-04 04:22:27,974 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.401353594660759, 'Total loss': 0.401353594660759} | train loss {'Reaction outcome loss': 0.28161458701335196, 'Total loss': 0.28161458701335196}
2023-01-04 04:22:27,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:27,974 INFO:     Epoch: 26
2023-01-04 04:22:29,547 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41779982348283135, 'Total loss': 0.41779982348283135} | train loss {'Reaction outcome loss': 0.2786715144765773, 'Total loss': 0.2786715144765773}
2023-01-04 04:22:29,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:29,548 INFO:     Epoch: 27
2023-01-04 04:22:31,105 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40413080851236977, 'Total loss': 0.40413080851236977} | train loss {'Reaction outcome loss': 0.2735636117713478, 'Total loss': 0.2735636117713478}
2023-01-04 04:22:31,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:31,105 INFO:     Epoch: 28
2023-01-04 04:22:32,682 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40426590144634245, 'Total loss': 0.40426590144634245} | train loss {'Reaction outcome loss': 0.26842462495519226, 'Total loss': 0.26842462495519226}
2023-01-04 04:22:32,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:32,682 INFO:     Epoch: 29
2023-01-04 04:22:34,254 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41335116426150004, 'Total loss': 0.41335116426150004} | train loss {'Reaction outcome loss': 0.26843927089963454, 'Total loss': 0.26843927089963454}
2023-01-04 04:22:34,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:34,254 INFO:     Epoch: 30
2023-01-04 04:22:35,826 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.386100048571825, 'Total loss': 0.386100048571825} | train loss {'Reaction outcome loss': 0.2635750440103981, 'Total loss': 0.2635750440103981}
2023-01-04 04:22:35,827 INFO:     Found new best model at epoch 30
2023-01-04 04:22:35,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:35,827 INFO:     Epoch: 31
2023-01-04 04:22:37,402 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41100581685702003, 'Total loss': 0.41100581685702003} | train loss {'Reaction outcome loss': 0.26011627923518527, 'Total loss': 0.26011627923518527}
2023-01-04 04:22:37,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:37,403 INFO:     Epoch: 32
2023-01-04 04:22:38,984 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3957000265518824, 'Total loss': 0.3957000265518824} | train loss {'Reaction outcome loss': 0.25680441478081734, 'Total loss': 0.25680441478081734}
2023-01-04 04:22:38,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:38,984 INFO:     Epoch: 33
2023-01-04 04:22:40,540 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.402110293880105, 'Total loss': 0.402110293880105} | train loss {'Reaction outcome loss': 0.2526859298788314, 'Total loss': 0.2526859298788314}
2023-01-04 04:22:40,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:40,540 INFO:     Epoch: 34
2023-01-04 04:22:42,126 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4025892361998558, 'Total loss': 0.4025892361998558} | train loss {'Reaction outcome loss': 0.25031157151359473, 'Total loss': 0.25031157151359473}
2023-01-04 04:22:42,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:42,126 INFO:     Epoch: 35
2023-01-04 04:22:43,692 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49677871267000834, 'Total loss': 0.49677871267000834} | train loss {'Reaction outcome loss': 0.24714347845238954, 'Total loss': 0.24714347845238954}
2023-01-04 04:22:43,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:43,692 INFO:     Epoch: 36
2023-01-04 04:22:45,277 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46344665785630546, 'Total loss': 0.46344665785630546} | train loss {'Reaction outcome loss': 0.24495431494888784, 'Total loss': 0.24495431494888784}
2023-01-04 04:22:45,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:45,277 INFO:     Epoch: 37
2023-01-04 04:22:46,851 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40672063728173574, 'Total loss': 0.40672063728173574} | train loss {'Reaction outcome loss': 0.242051883459751, 'Total loss': 0.242051883459751}
2023-01-04 04:22:46,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:46,853 INFO:     Epoch: 38
2023-01-04 04:22:48,405 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39420351982116697, 'Total loss': 0.39420351982116697} | train loss {'Reaction outcome loss': 0.24036257276208417, 'Total loss': 0.24036257276208417}
2023-01-04 04:22:48,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:48,405 INFO:     Epoch: 39
2023-01-04 04:22:50,002 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41067962249120077, 'Total loss': 0.41067962249120077} | train loss {'Reaction outcome loss': 0.23580757164262317, 'Total loss': 0.23580757164262317}
2023-01-04 04:22:50,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:50,002 INFO:     Epoch: 40
2023-01-04 04:22:51,608 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.400733494758606, 'Total loss': 0.400733494758606} | train loss {'Reaction outcome loss': 0.2333040718277882, 'Total loss': 0.2333040718277882}
2023-01-04 04:22:51,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:51,609 INFO:     Epoch: 41
2023-01-04 04:22:53,163 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40058420797189076, 'Total loss': 0.40058420797189076} | train loss {'Reaction outcome loss': 0.2317726056871599, 'Total loss': 0.2317726056871599}
2023-01-04 04:22:53,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:53,164 INFO:     Epoch: 42
2023-01-04 04:22:54,736 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42670408288637796, 'Total loss': 0.42670408288637796} | train loss {'Reaction outcome loss': 0.23136692880429466, 'Total loss': 0.23136692880429466}
2023-01-04 04:22:54,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:54,736 INFO:     Epoch: 43
2023-01-04 04:22:56,310 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39158307512601215, 'Total loss': 0.39158307512601215} | train loss {'Reaction outcome loss': 0.22566424563142207, 'Total loss': 0.22566424563142207}
2023-01-04 04:22:56,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:56,310 INFO:     Epoch: 44
2023-01-04 04:22:57,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47039680878321327, 'Total loss': 0.47039680878321327} | train loss {'Reaction outcome loss': 0.2250281788848643, 'Total loss': 0.2250281788848643}
2023-01-04 04:22:57,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:57,869 INFO:     Epoch: 45
2023-01-04 04:22:59,444 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4213942110538483, 'Total loss': 0.4213942110538483} | train loss {'Reaction outcome loss': 0.2203746814954325, 'Total loss': 0.2203746814954325}
2023-01-04 04:22:59,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:22:59,444 INFO:     Epoch: 46
2023-01-04 04:23:01,017 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41342144707838696, 'Total loss': 0.41342144707838696} | train loss {'Reaction outcome loss': 0.22089093377834318, 'Total loss': 0.22089093377834318}
2023-01-04 04:23:01,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:01,017 INFO:     Epoch: 47
2023-01-04 04:23:02,584 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42165936330954235, 'Total loss': 0.42165936330954235} | train loss {'Reaction outcome loss': 0.21876274133135473, 'Total loss': 0.21876274133135473}
2023-01-04 04:23:02,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:02,585 INFO:     Epoch: 48
2023-01-04 04:23:04,182 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4573738435904185, 'Total loss': 0.4573738435904185} | train loss {'Reaction outcome loss': 0.2180585883062924, 'Total loss': 0.2180585883062924}
2023-01-04 04:23:04,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:04,182 INFO:     Epoch: 49
2023-01-04 04:23:05,779 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43497026761372887, 'Total loss': 0.43497026761372887} | train loss {'Reaction outcome loss': 0.21411097988596262, 'Total loss': 0.21411097988596262}
2023-01-04 04:23:05,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:05,780 INFO:     Epoch: 50
2023-01-04 04:23:07,341 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4202794293562571, 'Total loss': 0.4202794293562571} | train loss {'Reaction outcome loss': 0.2119978943021755, 'Total loss': 0.2119978943021755}
2023-01-04 04:23:07,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:07,341 INFO:     Epoch: 51
2023-01-04 04:23:08,933 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4560305635134379, 'Total loss': 0.4560305635134379} | train loss {'Reaction outcome loss': 0.2103709268256527, 'Total loss': 0.2103709268256527}
2023-01-04 04:23:08,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:08,933 INFO:     Epoch: 52
2023-01-04 04:23:10,488 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4228870391845703, 'Total loss': 0.4228870391845703} | train loss {'Reaction outcome loss': 0.20716889201220112, 'Total loss': 0.20716889201220112}
2023-01-04 04:23:10,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:10,488 INFO:     Epoch: 53
2023-01-04 04:23:12,045 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4392539143562317, 'Total loss': 0.4392539143562317} | train loss {'Reaction outcome loss': 0.20709384581919527, 'Total loss': 0.20709384581919527}
2023-01-04 04:23:12,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:12,046 INFO:     Epoch: 54
2023-01-04 04:23:13,617 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4372500697771708, 'Total loss': 0.4372500697771708} | train loss {'Reaction outcome loss': 0.2040204928287501, 'Total loss': 0.2040204928287501}
2023-01-04 04:23:13,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:13,617 INFO:     Epoch: 55
2023-01-04 04:23:15,171 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44701831887165705, 'Total loss': 0.44701831887165705} | train loss {'Reaction outcome loss': 0.2059988004200133, 'Total loss': 0.2059988004200133}
2023-01-04 04:23:15,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:15,172 INFO:     Epoch: 56
2023-01-04 04:23:16,723 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45637586116790774, 'Total loss': 0.45637586116790774} | train loss {'Reaction outcome loss': 0.20115586195649696, 'Total loss': 0.20115586195649696}
2023-01-04 04:23:16,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:16,723 INFO:     Epoch: 57
2023-01-04 04:23:18,316 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4248969932397207, 'Total loss': 0.4248969932397207} | train loss {'Reaction outcome loss': 0.20214409808666065, 'Total loss': 0.20214409808666065}
2023-01-04 04:23:18,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:18,317 INFO:     Epoch: 58
2023-01-04 04:23:19,887 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43081793884436287, 'Total loss': 0.43081793884436287} | train loss {'Reaction outcome loss': 0.19867009971964403, 'Total loss': 0.19867009971964403}
2023-01-04 04:23:19,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:19,887 INFO:     Epoch: 59
2023-01-04 04:23:21,481 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4088742564121882, 'Total loss': 0.4088742564121882} | train loss {'Reaction outcome loss': 0.19956651286005533, 'Total loss': 0.19956651286005533}
2023-01-04 04:23:21,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:21,482 INFO:     Epoch: 60
2023-01-04 04:23:23,048 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4729755123456319, 'Total loss': 0.4729755123456319} | train loss {'Reaction outcome loss': 0.196464784099717, 'Total loss': 0.196464784099717}
2023-01-04 04:23:23,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:23,049 INFO:     Epoch: 61
2023-01-04 04:23:24,618 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4106289237737656, 'Total loss': 0.4106289237737656} | train loss {'Reaction outcome loss': 0.1931309621244999, 'Total loss': 0.1931309621244999}
2023-01-04 04:23:24,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:24,618 INFO:     Epoch: 62
2023-01-04 04:23:26,190 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44111179411411283, 'Total loss': 0.44111179411411283} | train loss {'Reaction outcome loss': 0.1951902580492171, 'Total loss': 0.1951902580492171}
2023-01-04 04:23:26,190 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:26,190 INFO:     Epoch: 63
2023-01-04 04:23:27,763 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.432428510983785, 'Total loss': 0.432428510983785} | train loss {'Reaction outcome loss': 0.19299161284337185, 'Total loss': 0.19299161284337185}
2023-01-04 04:23:27,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:27,764 INFO:     Epoch: 64
2023-01-04 04:23:29,318 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4376530349254608, 'Total loss': 0.4376530349254608} | train loss {'Reaction outcome loss': 0.1909329416470884, 'Total loss': 0.1909329416470884}
2023-01-04 04:23:29,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:29,318 INFO:     Epoch: 65
2023-01-04 04:23:30,886 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42768117090066277, 'Total loss': 0.42768117090066277} | train loss {'Reaction outcome loss': 0.19024391290886375, 'Total loss': 0.19024391290886375}
2023-01-04 04:23:30,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:30,887 INFO:     Epoch: 66
2023-01-04 04:23:32,454 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44266432225704194, 'Total loss': 0.44266432225704194} | train loss {'Reaction outcome loss': 0.19040957592578941, 'Total loss': 0.19040957592578941}
2023-01-04 04:23:32,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:32,454 INFO:     Epoch: 67
2023-01-04 04:23:34,005 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4234084576368332, 'Total loss': 0.4234084576368332} | train loss {'Reaction outcome loss': 0.18801587809055934, 'Total loss': 0.18801587809055934}
2023-01-04 04:23:34,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:34,005 INFO:     Epoch: 68
2023-01-04 04:23:35,574 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4817448357741038, 'Total loss': 0.4817448357741038} | train loss {'Reaction outcome loss': 0.18427424758975136, 'Total loss': 0.18427424758975136}
2023-01-04 04:23:35,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:35,574 INFO:     Epoch: 69
2023-01-04 04:23:37,143 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4249879904091358, 'Total loss': 0.4249879904091358} | train loss {'Reaction outcome loss': 0.18495614574431712, 'Total loss': 0.18495614574431712}
2023-01-04 04:23:37,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:37,143 INFO:     Epoch: 70
2023-01-04 04:23:38,719 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5038856367270151, 'Total loss': 0.5038856367270151} | train loss {'Reaction outcome loss': 0.18547880664687755, 'Total loss': 0.18547880664687755}
2023-01-04 04:23:38,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:38,719 INFO:     Epoch: 71
2023-01-04 04:23:40,282 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4877500951290131, 'Total loss': 0.4877500951290131} | train loss {'Reaction outcome loss': 0.18287844944924006, 'Total loss': 0.18287844944924006}
2023-01-04 04:23:40,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:40,283 INFO:     Epoch: 72
2023-01-04 04:23:41,865 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4389832536379496, 'Total loss': 0.4389832536379496} | train loss {'Reaction outcome loss': 0.18176162444275024, 'Total loss': 0.18176162444275024}
2023-01-04 04:23:41,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:41,865 INFO:     Epoch: 73
2023-01-04 04:23:43,448 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43074666873241463, 'Total loss': 0.43074666873241463} | train loss {'Reaction outcome loss': 0.18226823486332744, 'Total loss': 0.18226823486332744}
2023-01-04 04:23:43,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:43,448 INFO:     Epoch: 74
2023-01-04 04:23:45,053 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.448537802696228, 'Total loss': 0.448537802696228} | train loss {'Reaction outcome loss': 0.17991232393632517, 'Total loss': 0.17991232393632517}
2023-01-04 04:23:45,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:45,053 INFO:     Epoch: 75
2023-01-04 04:23:46,638 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45279321372509, 'Total loss': 0.45279321372509} | train loss {'Reaction outcome loss': 0.1766912525732799, 'Total loss': 0.1766912525732799}
2023-01-04 04:23:46,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:46,638 INFO:     Epoch: 76
2023-01-04 04:23:48,202 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4655584911505381, 'Total loss': 0.4655584911505381} | train loss {'Reaction outcome loss': 0.1772738647753737, 'Total loss': 0.1772738647753737}
2023-01-04 04:23:48,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:48,202 INFO:     Epoch: 77
2023-01-04 04:23:49,771 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4716778506835302, 'Total loss': 0.4716778506835302} | train loss {'Reaction outcome loss': 0.17839528343939254, 'Total loss': 0.17839528343939254}
2023-01-04 04:23:49,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:49,772 INFO:     Epoch: 78
2023-01-04 04:23:51,322 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4950723866621653, 'Total loss': 0.4950723866621653} | train loss {'Reaction outcome loss': 0.17802705024661172, 'Total loss': 0.17802705024661172}
2023-01-04 04:23:51,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:51,322 INFO:     Epoch: 79
2023-01-04 04:23:52,915 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4397147446870804, 'Total loss': 0.4397147446870804} | train loss {'Reaction outcome loss': 0.174555088073785, 'Total loss': 0.174555088073785}
2023-01-04 04:23:52,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:52,917 INFO:     Epoch: 80
2023-01-04 04:23:54,469 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45573418736457827, 'Total loss': 0.45573418736457827} | train loss {'Reaction outcome loss': 0.17330205349794614, 'Total loss': 0.17330205349794614}
2023-01-04 04:23:54,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:54,469 INFO:     Epoch: 81
2023-01-04 04:23:56,051 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46578515569369, 'Total loss': 0.46578515569369} | train loss {'Reaction outcome loss': 0.17395093108482687, 'Total loss': 0.17395093108482687}
2023-01-04 04:23:56,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:56,051 INFO:     Epoch: 82
2023-01-04 04:23:57,641 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46672896047433216, 'Total loss': 0.46672896047433216} | train loss {'Reaction outcome loss': 0.17149010655294925, 'Total loss': 0.17149010655294925}
2023-01-04 04:23:57,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:57,641 INFO:     Epoch: 83
2023-01-04 04:23:59,243 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46524471739927925, 'Total loss': 0.46524471739927925} | train loss {'Reaction outcome loss': 0.17328943694319673, 'Total loss': 0.17328943694319673}
2023-01-04 04:23:59,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:23:59,244 INFO:     Epoch: 84
2023-01-04 04:24:00,791 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4783020089070002, 'Total loss': 0.4783020089070002} | train loss {'Reaction outcome loss': 0.1747239156045377, 'Total loss': 0.1747239156045377}
2023-01-04 04:24:00,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:00,792 INFO:     Epoch: 85
2023-01-04 04:24:02,359 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48271756768226626, 'Total loss': 0.48271756768226626} | train loss {'Reaction outcome loss': 0.17137575827236545, 'Total loss': 0.17137575827236545}
2023-01-04 04:24:02,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:02,359 INFO:     Epoch: 86
2023-01-04 04:24:03,928 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4605421225229899, 'Total loss': 0.4605421225229899} | train loss {'Reaction outcome loss': 0.1697565247356287, 'Total loss': 0.1697565247356287}
2023-01-04 04:24:03,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:03,928 INFO:     Epoch: 87
2023-01-04 04:24:05,490 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47022453347841897, 'Total loss': 0.47022453347841897} | train loss {'Reaction outcome loss': 0.16884095831413332, 'Total loss': 0.16884095831413332}
2023-01-04 04:24:05,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:05,490 INFO:     Epoch: 88
2023-01-04 04:24:07,059 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4783653904994329, 'Total loss': 0.4783653904994329} | train loss {'Reaction outcome loss': 0.1681226307175696, 'Total loss': 0.1681226307175696}
2023-01-04 04:24:07,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:07,060 INFO:     Epoch: 89
2023-01-04 04:24:08,627 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46030239562193553, 'Total loss': 0.46030239562193553} | train loss {'Reaction outcome loss': 0.16767571841768672, 'Total loss': 0.16767571841768672}
2023-01-04 04:24:08,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:08,628 INFO:     Epoch: 90
2023-01-04 04:24:10,210 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4684865931669871, 'Total loss': 0.4684865931669871} | train loss {'Reaction outcome loss': 0.16836021490037661, 'Total loss': 0.16836021490037661}
2023-01-04 04:24:10,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:10,210 INFO:     Epoch: 91
2023-01-04 04:24:11,841 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45527036587397257, 'Total loss': 0.45527036587397257} | train loss {'Reaction outcome loss': 0.16731336136173278, 'Total loss': 0.16731336136173278}
2023-01-04 04:24:11,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:11,842 INFO:     Epoch: 92
2023-01-04 04:24:13,410 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4577912936607997, 'Total loss': 0.4577912936607997} | train loss {'Reaction outcome loss': 0.1652156116227822, 'Total loss': 0.1652156116227822}
2023-01-04 04:24:13,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:13,410 INFO:     Epoch: 93
2023-01-04 04:24:14,993 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46819704373677573, 'Total loss': 0.46819704373677573} | train loss {'Reaction outcome loss': 0.1627571728644116, 'Total loss': 0.1627571728644116}
2023-01-04 04:24:14,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:14,993 INFO:     Epoch: 94
2023-01-04 04:24:16,574 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4812051693598429, 'Total loss': 0.4812051693598429} | train loss {'Reaction outcome loss': 0.16314336755467626, 'Total loss': 0.16314336755467626}
2023-01-04 04:24:16,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:16,574 INFO:     Epoch: 95
2023-01-04 04:24:18,145 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4805839329957962, 'Total loss': 0.4805839329957962} | train loss {'Reaction outcome loss': 0.1641648648292981, 'Total loss': 0.1641648648292981}
2023-01-04 04:24:18,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:18,145 INFO:     Epoch: 96
2023-01-04 04:24:19,730 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4668991506099701, 'Total loss': 0.4668991506099701} | train loss {'Reaction outcome loss': 0.1608730215696116, 'Total loss': 0.1608730215696116}
2023-01-04 04:24:19,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:19,731 INFO:     Epoch: 97
2023-01-04 04:24:21,298 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4527026524146398, 'Total loss': 0.4527026524146398} | train loss {'Reaction outcome loss': 0.16241691385935372, 'Total loss': 0.16241691385935372}
2023-01-04 04:24:21,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:21,298 INFO:     Epoch: 98
2023-01-04 04:24:22,876 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44403426349163055, 'Total loss': 0.44403426349163055} | train loss {'Reaction outcome loss': 0.16031144154550184, 'Total loss': 0.16031144154550184}
2023-01-04 04:24:22,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:22,876 INFO:     Epoch: 99
2023-01-04 04:24:24,470 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47076750099658965, 'Total loss': 0.47076750099658965} | train loss {'Reaction outcome loss': 0.16149735621200717, 'Total loss': 0.16149735621200717}
2023-01-04 04:24:24,470 INFO:     Best model found after epoch 31 of 100.
2023-01-04 04:24:24,471 INFO:   Done with stage: TRAINING
2023-01-04 04:24:24,471 INFO:   Starting stage: EVALUATION
2023-01-04 04:24:24,618 INFO:   Done with stage: EVALUATION
2023-01-04 04:24:24,618 INFO:   Leaving out SEQ value Fold_3
2023-01-04 04:24:24,631 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 04:24:24,632 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:24:25,282 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:24:25,283 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:24:25,350 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:24:25,350 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:24:25,350 INFO:     No hyperparam tuning for this model
2023-01-04 04:24:25,350 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:24:25,351 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:24:25,351 INFO:     None feature selector for col prot
2023-01-04 04:24:25,351 INFO:     None feature selector for col prot
2023-01-04 04:24:25,352 INFO:     None feature selector for col prot
2023-01-04 04:24:25,352 INFO:     None feature selector for col chem
2023-01-04 04:24:25,352 INFO:     None feature selector for col chem
2023-01-04 04:24:25,352 INFO:     None feature selector for col chem
2023-01-04 04:24:25,352 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:24:25,352 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:24:25,353 INFO:     Number of params in model 70141
2023-01-04 04:24:25,357 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:24:25,357 INFO:   Starting stage: TRAINING
2023-01-04 04:24:25,400 INFO:     Val loss before train {'Reaction outcome loss': 1.0156493306159973, 'Total loss': 1.0156493306159973}
2023-01-04 04:24:25,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:25,400 INFO:     Epoch: 0
2023-01-04 04:24:26,961 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6720334847768148, 'Total loss': 0.6720334847768148} | train loss {'Reaction outcome loss': 0.8642749339342117, 'Total loss': 0.8642749339342117}
2023-01-04 04:24:26,961 INFO:     Found new best model at epoch 0
2023-01-04 04:24:26,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:26,962 INFO:     Epoch: 1
2023-01-04 04:24:28,538 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5429598569869996, 'Total loss': 0.5429598569869996} | train loss {'Reaction outcome loss': 0.6039628061282374, 'Total loss': 0.6039628061282374}
2023-01-04 04:24:28,539 INFO:     Found new best model at epoch 1
2023-01-04 04:24:28,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:28,540 INFO:     Epoch: 2
2023-01-04 04:24:30,117 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5020284593105316, 'Total loss': 0.5020284593105316} | train loss {'Reaction outcome loss': 0.5264464752191175, 'Total loss': 0.5264464752191175}
2023-01-04 04:24:30,117 INFO:     Found new best model at epoch 2
2023-01-04 04:24:30,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:30,118 INFO:     Epoch: 3
2023-01-04 04:24:31,686 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46998300949732463, 'Total loss': 0.46998300949732463} | train loss {'Reaction outcome loss': 0.4879627483387063, 'Total loss': 0.4879627483387063}
2023-01-04 04:24:31,687 INFO:     Found new best model at epoch 3
2023-01-04 04:24:31,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:31,687 INFO:     Epoch: 4
2023-01-04 04:24:33,278 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46202048659324646, 'Total loss': 0.46202048659324646} | train loss {'Reaction outcome loss': 0.4600043185871013, 'Total loss': 0.4600043185871013}
2023-01-04 04:24:33,278 INFO:     Found new best model at epoch 4
2023-01-04 04:24:33,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:33,279 INFO:     Epoch: 5
2023-01-04 04:24:34,879 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46209461291631065, 'Total loss': 0.46209461291631065} | train loss {'Reaction outcome loss': 0.43973444429409764, 'Total loss': 0.43973444429409764}
2023-01-04 04:24:34,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:34,880 INFO:     Epoch: 6
2023-01-04 04:24:36,441 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4633655468622843, 'Total loss': 0.4633655468622843} | train loss {'Reaction outcome loss': 0.4258798019294321, 'Total loss': 0.4258798019294321}
2023-01-04 04:24:36,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:36,442 INFO:     Epoch: 7
2023-01-04 04:24:38,048 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4363691329956055, 'Total loss': 0.4363691329956055} | train loss {'Reaction outcome loss': 0.4118582477697926, 'Total loss': 0.4118582477697926}
2023-01-04 04:24:38,048 INFO:     Found new best model at epoch 7
2023-01-04 04:24:38,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:38,049 INFO:     Epoch: 8
2023-01-04 04:24:39,657 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4461807052294413, 'Total loss': 0.4461807052294413} | train loss {'Reaction outcome loss': 0.40288905951663523, 'Total loss': 0.40288905951663523}
2023-01-04 04:24:39,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:39,657 INFO:     Epoch: 9
2023-01-04 04:24:41,228 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4339507043361664, 'Total loss': 0.4339507043361664} | train loss {'Reaction outcome loss': 0.3915941469425703, 'Total loss': 0.3915941469425703}
2023-01-04 04:24:41,229 INFO:     Found new best model at epoch 9
2023-01-04 04:24:41,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:41,230 INFO:     Epoch: 10
2023-01-04 04:24:42,832 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4181526730457942, 'Total loss': 0.4181526730457942} | train loss {'Reaction outcome loss': 0.38210838339733383, 'Total loss': 0.38210838339733383}
2023-01-04 04:24:42,832 INFO:     Found new best model at epoch 10
2023-01-04 04:24:42,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:42,833 INFO:     Epoch: 11
2023-01-04 04:24:44,445 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42023470004399616, 'Total loss': 0.42023470004399616} | train loss {'Reaction outcome loss': 0.37206221766171665, 'Total loss': 0.37206221766171665}
2023-01-04 04:24:44,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:44,445 INFO:     Epoch: 12
2023-01-04 04:24:46,028 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41988777816295625, 'Total loss': 0.41988777816295625} | train loss {'Reaction outcome loss': 0.3631326536083744, 'Total loss': 0.3631326536083744}
2023-01-04 04:24:46,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:46,029 INFO:     Epoch: 13
2023-01-04 04:24:47,613 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4059031029542287, 'Total loss': 0.4059031029542287} | train loss {'Reaction outcome loss': 0.35936685050599765, 'Total loss': 0.35936685050599765}
2023-01-04 04:24:47,614 INFO:     Found new best model at epoch 13
2023-01-04 04:24:47,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:47,614 INFO:     Epoch: 14
2023-01-04 04:24:49,177 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39276613891124723, 'Total loss': 0.39276613891124723} | train loss {'Reaction outcome loss': 0.3495409195821216, 'Total loss': 0.3495409195821216}
2023-01-04 04:24:49,177 INFO:     Found new best model at epoch 14
2023-01-04 04:24:49,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:49,178 INFO:     Epoch: 15
2023-01-04 04:24:50,785 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4043247878551483, 'Total loss': 0.4043247878551483} | train loss {'Reaction outcome loss': 0.34108223959150974, 'Total loss': 0.34108223959150974}
2023-01-04 04:24:50,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:50,786 INFO:     Epoch: 16
2023-01-04 04:24:52,370 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38651002049446104, 'Total loss': 0.38651002049446104} | train loss {'Reaction outcome loss': 0.33583763010636736, 'Total loss': 0.33583763010636736}
2023-01-04 04:24:52,370 INFO:     Found new best model at epoch 16
2023-01-04 04:24:52,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:52,371 INFO:     Epoch: 17
2023-01-04 04:24:53,951 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3933927208185196, 'Total loss': 0.3933927208185196} | train loss {'Reaction outcome loss': 0.32945461848573965, 'Total loss': 0.32945461848573965}
2023-01-04 04:24:53,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:53,951 INFO:     Epoch: 18
2023-01-04 04:24:55,533 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3898252027730147, 'Total loss': 0.3898252027730147} | train loss {'Reaction outcome loss': 0.3245123434730255, 'Total loss': 0.3245123434730255}
2023-01-04 04:24:55,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:55,533 INFO:     Epoch: 19
2023-01-04 04:24:57,134 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39589871764183043, 'Total loss': 0.39589871764183043} | train loss {'Reaction outcome loss': 0.3153368782551184, 'Total loss': 0.3153368782551184}
2023-01-04 04:24:57,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:57,134 INFO:     Epoch: 20
2023-01-04 04:24:58,513 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3987473686536153, 'Total loss': 0.3987473686536153} | train loss {'Reaction outcome loss': 0.31164325306015295, 'Total loss': 0.31164325306015295}
2023-01-04 04:24:58,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:58,514 INFO:     Epoch: 21
2023-01-04 04:24:59,584 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39274564385414124, 'Total loss': 0.39274564385414124} | train loss {'Reaction outcome loss': 0.30536120159238794, 'Total loss': 0.30536120159238794}
2023-01-04 04:24:59,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:24:59,586 INFO:     Epoch: 22
2023-01-04 04:25:00,651 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38602005541324613, 'Total loss': 0.38602005541324613} | train loss {'Reaction outcome loss': 0.29963581130778705, 'Total loss': 0.29963581130778705}
2023-01-04 04:25:00,651 INFO:     Found new best model at epoch 22
2023-01-04 04:25:00,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:00,652 INFO:     Epoch: 23
2023-01-04 04:25:01,735 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38596555093924206, 'Total loss': 0.38596555093924206} | train loss {'Reaction outcome loss': 0.29470493992532254, 'Total loss': 0.29470493992532254}
2023-01-04 04:25:01,735 INFO:     Found new best model at epoch 23
2023-01-04 04:25:01,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:01,736 INFO:     Epoch: 24
2023-01-04 04:25:03,043 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40766065418720243, 'Total loss': 0.40766065418720243} | train loss {'Reaction outcome loss': 0.2916476406619279, 'Total loss': 0.2916476406619279}
2023-01-04 04:25:03,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:03,044 INFO:     Epoch: 25
2023-01-04 04:25:04,623 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.398970220486323, 'Total loss': 0.398970220486323} | train loss {'Reaction outcome loss': 0.28689129830059346, 'Total loss': 0.28689129830059346}
2023-01-04 04:25:04,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:04,624 INFO:     Epoch: 26
2023-01-04 04:25:06,235 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39950784544150036, 'Total loss': 0.39950784544150036} | train loss {'Reaction outcome loss': 0.28522758139637266, 'Total loss': 0.28522758139637266}
2023-01-04 04:25:06,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:06,236 INFO:     Epoch: 27
2023-01-04 04:25:07,802 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4056065594156583, 'Total loss': 0.4056065594156583} | train loss {'Reaction outcome loss': 0.27767357888230443, 'Total loss': 0.27767357888230443}
2023-01-04 04:25:07,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:07,802 INFO:     Epoch: 28
2023-01-04 04:25:09,411 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.394763586918513, 'Total loss': 0.394763586918513} | train loss {'Reaction outcome loss': 0.275895411243839, 'Total loss': 0.275895411243839}
2023-01-04 04:25:09,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:09,411 INFO:     Epoch: 29
2023-01-04 04:25:10,976 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39718407293160757, 'Total loss': 0.39718407293160757} | train loss {'Reaction outcome loss': 0.2724291678436481, 'Total loss': 0.2724291678436481}
2023-01-04 04:25:10,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:10,977 INFO:     Epoch: 30
2023-01-04 04:25:12,539 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.402833499511083, 'Total loss': 0.402833499511083} | train loss {'Reaction outcome loss': 0.2699200420157753, 'Total loss': 0.2699200420157753}
2023-01-04 04:25:12,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:12,539 INFO:     Epoch: 31
2023-01-04 04:25:14,143 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3798046847184499, 'Total loss': 0.3798046847184499} | train loss {'Reaction outcome loss': 0.26465513684997594, 'Total loss': 0.26465513684997594}
2023-01-04 04:25:14,143 INFO:     Found new best model at epoch 31
2023-01-04 04:25:14,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:14,144 INFO:     Epoch: 32
2023-01-04 04:25:15,749 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3912282884120941, 'Total loss': 0.3912282884120941} | train loss {'Reaction outcome loss': 0.26209184715021266, 'Total loss': 0.26209184715021266}
2023-01-04 04:25:15,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:15,750 INFO:     Epoch: 33
2023-01-04 04:25:17,362 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37590397397677106, 'Total loss': 0.37590397397677106} | train loss {'Reaction outcome loss': 0.2596459027896397, 'Total loss': 0.2596459027896397}
2023-01-04 04:25:17,363 INFO:     Found new best model at epoch 33
2023-01-04 04:25:17,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:17,363 INFO:     Epoch: 34
2023-01-04 04:25:18,945 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38150110840797424, 'Total loss': 0.38150110840797424} | train loss {'Reaction outcome loss': 0.2532510810198575, 'Total loss': 0.2532510810198575}
2023-01-04 04:25:18,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:18,946 INFO:     Epoch: 35
2023-01-04 04:25:20,511 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3894601598381996, 'Total loss': 0.3894601598381996} | train loss {'Reaction outcome loss': 0.2515845382246223, 'Total loss': 0.2515845382246223}
2023-01-04 04:25:20,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:20,511 INFO:     Epoch: 36
2023-01-04 04:25:22,131 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40399137884378433, 'Total loss': 0.40399137884378433} | train loss {'Reaction outcome loss': 0.25277693409227975, 'Total loss': 0.25277693409227975}
2023-01-04 04:25:22,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:22,131 INFO:     Epoch: 37
2023-01-04 04:25:23,744 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3647810980677605, 'Total loss': 0.3647810980677605} | train loss {'Reaction outcome loss': 0.24739882543030448, 'Total loss': 0.24739882543030448}
2023-01-04 04:25:23,744 INFO:     Found new best model at epoch 37
2023-01-04 04:25:23,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:23,745 INFO:     Epoch: 38
2023-01-04 04:25:25,309 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4100926627715429, 'Total loss': 0.4100926627715429} | train loss {'Reaction outcome loss': 0.2446952556824162, 'Total loss': 0.2446952556824162}
2023-01-04 04:25:25,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:25,310 INFO:     Epoch: 39
2023-01-04 04:25:26,919 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3732792099316915, 'Total loss': 0.3732792099316915} | train loss {'Reaction outcome loss': 0.24398883840028388, 'Total loss': 0.24398883840028388}
2023-01-04 04:25:26,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:26,919 INFO:     Epoch: 40
2023-01-04 04:25:28,492 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38119556605815885, 'Total loss': 0.38119556605815885} | train loss {'Reaction outcome loss': 0.23816922334206364, 'Total loss': 0.23816922334206364}
2023-01-04 04:25:28,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:28,492 INFO:     Epoch: 41
2023-01-04 04:25:30,057 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40226657191912335, 'Total loss': 0.40226657191912335} | train loss {'Reaction outcome loss': 0.2381545929850018, 'Total loss': 0.2381545929850018}
2023-01-04 04:25:30,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:30,058 INFO:     Epoch: 42
2023-01-04 04:25:31,639 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3996734877427419, 'Total loss': 0.3996734877427419} | train loss {'Reaction outcome loss': 0.23484498518009256, 'Total loss': 0.23484498518009256}
2023-01-04 04:25:31,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:31,639 INFO:     Epoch: 43
2023-01-04 04:25:33,220 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3953312238057454, 'Total loss': 0.3953312238057454} | train loss {'Reaction outcome loss': 0.23129296521690204, 'Total loss': 0.23129296521690204}
2023-01-04 04:25:33,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:33,220 INFO:     Epoch: 44
2023-01-04 04:25:34,801 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3857869500915209, 'Total loss': 0.3857869500915209} | train loss {'Reaction outcome loss': 0.2307288632830129, 'Total loss': 0.2307288632830129}
2023-01-04 04:25:34,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:34,802 INFO:     Epoch: 45
2023-01-04 04:25:36,372 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39071650207042696, 'Total loss': 0.39071650207042696} | train loss {'Reaction outcome loss': 0.22744020244555316, 'Total loss': 0.22744020244555316}
2023-01-04 04:25:36,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:36,373 INFO:     Epoch: 46
2023-01-04 04:25:37,936 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3734404265880585, 'Total loss': 0.3734404265880585} | train loss {'Reaction outcome loss': 0.2267838316786028, 'Total loss': 0.2267838316786028}
2023-01-04 04:25:37,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:37,936 INFO:     Epoch: 47
2023-01-04 04:25:39,502 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37625758548577626, 'Total loss': 0.37625758548577626} | train loss {'Reaction outcome loss': 0.22712726676224793, 'Total loss': 0.22712726676224793}
2023-01-04 04:25:39,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:39,502 INFO:     Epoch: 48
2023-01-04 04:25:41,112 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40358025431632993, 'Total loss': 0.40358025431632993} | train loss {'Reaction outcome loss': 0.2248229970407747, 'Total loss': 0.2248229970407747}
2023-01-04 04:25:41,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:41,113 INFO:     Epoch: 49
2023-01-04 04:25:42,686 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41296958923339844, 'Total loss': 0.41296958923339844} | train loss {'Reaction outcome loss': 0.22165919549382515, 'Total loss': 0.22165919549382515}
2023-01-04 04:25:42,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:42,686 INFO:     Epoch: 50
2023-01-04 04:25:44,265 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3922783921162287, 'Total loss': 0.3922783921162287} | train loss {'Reaction outcome loss': 0.22117466073020967, 'Total loss': 0.22117466073020967}
2023-01-04 04:25:44,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:44,265 INFO:     Epoch: 51
2023-01-04 04:25:45,847 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3657221684853236, 'Total loss': 0.3657221684853236} | train loss {'Reaction outcome loss': 0.22007331102542635, 'Total loss': 0.22007331102542635}
2023-01-04 04:25:45,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:45,848 INFO:     Epoch: 52
2023-01-04 04:25:47,414 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40301853120326997, 'Total loss': 0.40301853120326997} | train loss {'Reaction outcome loss': 0.21751693550524484, 'Total loss': 0.21751693550524484}
2023-01-04 04:25:47,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:47,414 INFO:     Epoch: 53
2023-01-04 04:25:49,030 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39459307193756105, 'Total loss': 0.39459307193756105} | train loss {'Reaction outcome loss': 0.21412840983184583, 'Total loss': 0.21412840983184583}
2023-01-04 04:25:49,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:49,030 INFO:     Epoch: 54
2023-01-04 04:25:50,646 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41612985034783684, 'Total loss': 0.41612985034783684} | train loss {'Reaction outcome loss': 0.21194560891085298, 'Total loss': 0.21194560891085298}
2023-01-04 04:25:50,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:50,646 INFO:     Epoch: 55
2023-01-04 04:25:52,259 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38148896396160126, 'Total loss': 0.38148896396160126} | train loss {'Reaction outcome loss': 0.21221480384659375, 'Total loss': 0.21221480384659375}
2023-01-04 04:25:52,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:52,260 INFO:     Epoch: 56
2023-01-04 04:25:53,845 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41510871847470604, 'Total loss': 0.41510871847470604} | train loss {'Reaction outcome loss': 0.21170914884194406, 'Total loss': 0.21170914884194406}
2023-01-04 04:25:53,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:53,846 INFO:     Epoch: 57
2023-01-04 04:25:55,412 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38837384482224785, 'Total loss': 0.38837384482224785} | train loss {'Reaction outcome loss': 0.20990893178123193, 'Total loss': 0.20990893178123193}
2023-01-04 04:25:55,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:55,413 INFO:     Epoch: 58
2023-01-04 04:25:56,978 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40208884278933205, 'Total loss': 0.40208884278933205} | train loss {'Reaction outcome loss': 0.21014420802358294, 'Total loss': 0.21014420802358294}
2023-01-04 04:25:56,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:56,978 INFO:     Epoch: 59
2023-01-04 04:25:58,570 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3940019078552723, 'Total loss': 0.3940019078552723} | train loss {'Reaction outcome loss': 0.20740404576539015, 'Total loss': 0.20740404576539015}
2023-01-04 04:25:58,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:25:58,570 INFO:     Epoch: 60
2023-01-04 04:26:00,165 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4193685511747996, 'Total loss': 0.4193685511747996} | train loss {'Reaction outcome loss': 0.20632975468289677, 'Total loss': 0.20632975468289677}
2023-01-04 04:26:00,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:00,165 INFO:     Epoch: 61
2023-01-04 04:26:01,786 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3915438065926234, 'Total loss': 0.3915438065926234} | train loss {'Reaction outcome loss': 0.20652710967255336, 'Total loss': 0.20652710967255336}
2023-01-04 04:26:01,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:01,786 INFO:     Epoch: 62
2023-01-04 04:26:03,383 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4097023377815882, 'Total loss': 0.4097023377815882} | train loss {'Reaction outcome loss': 0.20306793790664115, 'Total loss': 0.20306793790664115}
2023-01-04 04:26:03,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:03,383 INFO:     Epoch: 63
2023-01-04 04:26:05,003 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37727964520454405, 'Total loss': 0.37727964520454405} | train loss {'Reaction outcome loss': 0.2008604368630008, 'Total loss': 0.2008604368630008}
2023-01-04 04:26:05,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:05,004 INFO:     Epoch: 64
2023-01-04 04:26:06,597 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40463576167821885, 'Total loss': 0.40463576167821885} | train loss {'Reaction outcome loss': 0.19949948379810709, 'Total loss': 0.19949948379810709}
2023-01-04 04:26:06,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:06,599 INFO:     Epoch: 65
2023-01-04 04:26:08,174 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40083882908026375, 'Total loss': 0.40083882908026375} | train loss {'Reaction outcome loss': 0.19916321395685638, 'Total loss': 0.19916321395685638}
2023-01-04 04:26:08,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:08,174 INFO:     Epoch: 66
2023-01-04 04:26:09,790 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3955647756656011, 'Total loss': 0.3955647756656011} | train loss {'Reaction outcome loss': 0.19969193829073958, 'Total loss': 0.19969193829073958}
2023-01-04 04:26:09,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:09,790 INFO:     Epoch: 67
2023-01-04 04:26:11,403 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44249295790990195, 'Total loss': 0.44249295790990195} | train loss {'Reaction outcome loss': 0.19931857047235443, 'Total loss': 0.19931857047235443}
2023-01-04 04:26:11,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:11,404 INFO:     Epoch: 68
2023-01-04 04:26:12,971 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3983501136302948, 'Total loss': 0.3983501136302948} | train loss {'Reaction outcome loss': 0.1953801962336267, 'Total loss': 0.1953801962336267}
2023-01-04 04:26:12,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:12,972 INFO:     Epoch: 69
2023-01-04 04:26:14,538 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3926738788684209, 'Total loss': 0.3926738788684209} | train loss {'Reaction outcome loss': 0.19698931408678963, 'Total loss': 0.19698931408678963}
2023-01-04 04:26:14,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:14,538 INFO:     Epoch: 70
2023-01-04 04:26:16,152 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3953101893266042, 'Total loss': 0.3953101893266042} | train loss {'Reaction outcome loss': 0.19211066890181633, 'Total loss': 0.19211066890181633}
2023-01-04 04:26:16,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:16,153 INFO:     Epoch: 71
2023-01-04 04:26:17,726 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42356329957644145, 'Total loss': 0.42356329957644145} | train loss {'Reaction outcome loss': 0.19543110870205574, 'Total loss': 0.19543110870205574}
2023-01-04 04:26:17,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:17,726 INFO:     Epoch: 72
2023-01-04 04:26:19,331 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4077166159947713, 'Total loss': 0.4077166159947713} | train loss {'Reaction outcome loss': 0.19218664417845488, 'Total loss': 0.19218664417845488}
2023-01-04 04:26:19,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:19,332 INFO:     Epoch: 73
2023-01-04 04:26:20,947 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40618287374575934, 'Total loss': 0.40618287374575934} | train loss {'Reaction outcome loss': 0.19238346173380413, 'Total loss': 0.19238346173380413}
2023-01-04 04:26:20,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:20,947 INFO:     Epoch: 74
2023-01-04 04:26:22,510 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39787789483865105, 'Total loss': 0.39787789483865105} | train loss {'Reaction outcome loss': 0.1894691905659372, 'Total loss': 0.1894691905659372}
2023-01-04 04:26:22,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:22,510 INFO:     Epoch: 75
2023-01-04 04:26:24,075 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4059564600388209, 'Total loss': 0.4059564600388209} | train loss {'Reaction outcome loss': 0.18796979542141848, 'Total loss': 0.18796979542141848}
2023-01-04 04:26:24,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:24,075 INFO:     Epoch: 76
2023-01-04 04:26:25,655 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4314683924118678, 'Total loss': 0.4314683924118678} | train loss {'Reaction outcome loss': 0.1880432640331505, 'Total loss': 0.1880432640331505}
2023-01-04 04:26:25,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:25,656 INFO:     Epoch: 77
2023-01-04 04:26:27,231 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3943738723794619, 'Total loss': 0.3943738723794619} | train loss {'Reaction outcome loss': 0.1882111105496866, 'Total loss': 0.1882111105496866}
2023-01-04 04:26:27,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:27,231 INFO:     Epoch: 78
2023-01-04 04:26:28,827 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38510904014110564, 'Total loss': 0.38510904014110564} | train loss {'Reaction outcome loss': 0.18644716079435208, 'Total loss': 0.18644716079435208}
2023-01-04 04:26:28,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:28,828 INFO:     Epoch: 79
2023-01-04 04:26:30,394 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.406792097290357, 'Total loss': 0.406792097290357} | train loss {'Reaction outcome loss': 0.18392548339618167, 'Total loss': 0.18392548339618167}
2023-01-04 04:26:30,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:30,394 INFO:     Epoch: 80
2023-01-04 04:26:31,982 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38359251419703166, 'Total loss': 0.38359251419703166} | train loss {'Reaction outcome loss': 0.18519686468380647, 'Total loss': 0.18519686468380647}
2023-01-04 04:26:31,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:31,982 INFO:     Epoch: 81
2023-01-04 04:26:33,564 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3816204140583674, 'Total loss': 0.3816204140583674} | train loss {'Reaction outcome loss': 0.18366093831612681, 'Total loss': 0.18366093831612681}
2023-01-04 04:26:33,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:33,565 INFO:     Epoch: 82
2023-01-04 04:26:35,176 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3967511514822642, 'Total loss': 0.3967511514822642} | train loss {'Reaction outcome loss': 0.1840593374477033, 'Total loss': 0.1840593374477033}
2023-01-04 04:26:35,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:35,176 INFO:     Epoch: 83
2023-01-04 04:26:36,749 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40970985690752665, 'Total loss': 0.40970985690752665} | train loss {'Reaction outcome loss': 0.18276597938779063, 'Total loss': 0.18276597938779063}
2023-01-04 04:26:36,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:36,749 INFO:     Epoch: 84
2023-01-04 04:26:38,364 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4243670731782913, 'Total loss': 0.4243670731782913} | train loss {'Reaction outcome loss': 0.1825613331212832, 'Total loss': 0.1825613331212832}
2023-01-04 04:26:38,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:38,365 INFO:     Epoch: 85
2023-01-04 04:26:39,936 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3979486495256424, 'Total loss': 0.3979486495256424} | train loss {'Reaction outcome loss': 0.18077267641133635, 'Total loss': 0.18077267641133635}
2023-01-04 04:26:39,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:39,937 INFO:     Epoch: 86
2023-01-04 04:26:41,502 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3941984236240387, 'Total loss': 0.3941984236240387} | train loss {'Reaction outcome loss': 0.17919079404677787, 'Total loss': 0.17919079404677787}
2023-01-04 04:26:41,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:41,503 INFO:     Epoch: 87
2023-01-04 04:26:43,116 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.408720874786377, 'Total loss': 0.408720874786377} | train loss {'Reaction outcome loss': 0.17883615980917303, 'Total loss': 0.17883615980917303}
2023-01-04 04:26:43,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:43,116 INFO:     Epoch: 88
2023-01-04 04:26:44,726 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4010440409183502, 'Total loss': 0.4010440409183502} | train loss {'Reaction outcome loss': 0.17796162953668268, 'Total loss': 0.17796162953668268}
2023-01-04 04:26:44,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:44,727 INFO:     Epoch: 89
2023-01-04 04:26:46,303 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4027035420139631, 'Total loss': 0.4027035420139631} | train loss {'Reaction outcome loss': 0.17484666584535455, 'Total loss': 0.17484666584535455}
2023-01-04 04:26:46,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:46,304 INFO:     Epoch: 90
2023-01-04 04:26:47,871 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4112824230144421, 'Total loss': 0.4112824230144421} | train loss {'Reaction outcome loss': 0.17700992428772425, 'Total loss': 0.17700992428772425}
2023-01-04 04:26:47,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:47,871 INFO:     Epoch: 91
2023-01-04 04:26:49,464 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4082959403594335, 'Total loss': 0.4082959403594335} | train loss {'Reaction outcome loss': 0.174801154313677, 'Total loss': 0.174801154313677}
2023-01-04 04:26:49,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:49,464 INFO:     Epoch: 92
2023-01-04 04:26:51,047 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4006315439939499, 'Total loss': 0.4006315439939499} | train loss {'Reaction outcome loss': 0.17591128766835823, 'Total loss': 0.17591128766835823}
2023-01-04 04:26:51,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:51,047 INFO:     Epoch: 93
2023-01-04 04:26:52,665 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40490799844264985, 'Total loss': 0.40490799844264985} | train loss {'Reaction outcome loss': 0.1751534192190662, 'Total loss': 0.1751534192190662}
2023-01-04 04:26:52,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:52,665 INFO:     Epoch: 94
2023-01-04 04:26:54,281 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4204271321495374, 'Total loss': 0.4204271321495374} | train loss {'Reaction outcome loss': 0.17391335617506157, 'Total loss': 0.17391335617506157}
2023-01-04 04:26:54,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:54,282 INFO:     Epoch: 95
2023-01-04 04:26:55,896 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4378129571676254, 'Total loss': 0.4378129571676254} | train loss {'Reaction outcome loss': 0.17340101014115733, 'Total loss': 0.17340101014115733}
2023-01-04 04:26:55,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:55,896 INFO:     Epoch: 96
2023-01-04 04:26:57,490 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41793374915917714, 'Total loss': 0.41793374915917714} | train loss {'Reaction outcome loss': 0.1727466738857601, 'Total loss': 0.1727466738857601}
2023-01-04 04:26:57,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:57,491 INFO:     Epoch: 97
2023-01-04 04:26:59,090 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43321221868197124, 'Total loss': 0.43321221868197124} | train loss {'Reaction outcome loss': 0.17137640824772582, 'Total loss': 0.17137640824772582}
2023-01-04 04:26:59,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:26:59,090 INFO:     Epoch: 98
2023-01-04 04:27:00,667 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40275271049079797, 'Total loss': 0.40275271049079797} | train loss {'Reaction outcome loss': 0.17175731187971838, 'Total loss': 0.17175731187971838}
2023-01-04 04:27:00,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:00,667 INFO:     Epoch: 99
2023-01-04 04:27:02,284 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42063390264908473, 'Total loss': 0.42063390264908473} | train loss {'Reaction outcome loss': 0.17094165544929732, 'Total loss': 0.17094165544929732}
2023-01-04 04:27:02,284 INFO:     Best model found after epoch 38 of 100.
2023-01-04 04:27:02,285 INFO:   Done with stage: TRAINING
2023-01-04 04:27:02,285 INFO:   Starting stage: EVALUATION
2023-01-04 04:27:02,419 INFO:   Done with stage: EVALUATION
2023-01-04 04:27:02,419 INFO:   Leaving out SEQ value Fold_4
2023-01-04 04:27:02,432 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:27:02,432 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:27:03,092 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:27:03,092 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:27:03,159 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:27:03,159 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:27:03,159 INFO:     No hyperparam tuning for this model
2023-01-04 04:27:03,159 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:27:03,159 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:27:03,160 INFO:     None feature selector for col prot
2023-01-04 04:27:03,160 INFO:     None feature selector for col prot
2023-01-04 04:27:03,160 INFO:     None feature selector for col prot
2023-01-04 04:27:03,161 INFO:     None feature selector for col chem
2023-01-04 04:27:03,161 INFO:     None feature selector for col chem
2023-01-04 04:27:03,161 INFO:     None feature selector for col chem
2023-01-04 04:27:03,161 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:27:03,161 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:27:03,162 INFO:     Number of params in model 70141
2023-01-04 04:27:03,165 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:27:03,165 INFO:   Starting stage: TRAINING
2023-01-04 04:27:03,209 INFO:     Val loss before train {'Reaction outcome loss': 1.0016877055168152, 'Total loss': 1.0016877055168152}
2023-01-04 04:27:03,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:03,209 INFO:     Epoch: 0
2023-01-04 04:27:04,844 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6867471476395924, 'Total loss': 0.6867471476395924} | train loss {'Reaction outcome loss': 0.8609482961226026, 'Total loss': 0.8609482961226026}
2023-01-04 04:27:04,844 INFO:     Found new best model at epoch 0
2023-01-04 04:27:04,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:04,845 INFO:     Epoch: 1
2023-01-04 04:27:06,442 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6276981910069783, 'Total loss': 0.6276981910069783} | train loss {'Reaction outcome loss': 0.6002228991649642, 'Total loss': 0.6002228991649642}
2023-01-04 04:27:06,442 INFO:     Found new best model at epoch 1
2023-01-04 04:27:06,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:06,443 INFO:     Epoch: 2
2023-01-04 04:27:08,024 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5760039210319519, 'Total loss': 0.5760039210319519} | train loss {'Reaction outcome loss': 0.5259432702826249, 'Total loss': 0.5259432702826249}
2023-01-04 04:27:08,025 INFO:     Found new best model at epoch 2
2023-01-04 04:27:08,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:08,026 INFO:     Epoch: 3
2023-01-04 04:27:09,623 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5552492141723633, 'Total loss': 0.5552492141723633} | train loss {'Reaction outcome loss': 0.490731483762445, 'Total loss': 0.490731483762445}
2023-01-04 04:27:09,623 INFO:     Found new best model at epoch 3
2023-01-04 04:27:09,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:09,624 INFO:     Epoch: 4
2023-01-04 04:27:11,232 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5545248409112294, 'Total loss': 0.5545248409112294} | train loss {'Reaction outcome loss': 0.46168458402587187, 'Total loss': 0.46168458402587187}
2023-01-04 04:27:11,232 INFO:     Found new best model at epoch 4
2023-01-04 04:27:11,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:11,233 INFO:     Epoch: 5
2023-01-04 04:27:12,855 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5273135125637054, 'Total loss': 0.5273135125637054} | train loss {'Reaction outcome loss': 0.436343583873463, 'Total loss': 0.436343583873463}
2023-01-04 04:27:12,856 INFO:     Found new best model at epoch 5
2023-01-04 04:27:12,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:12,857 INFO:     Epoch: 6
2023-01-04 04:27:14,474 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5192405601342519, 'Total loss': 0.5192405601342519} | train loss {'Reaction outcome loss': 0.4209385279713985, 'Total loss': 0.4209385279713985}
2023-01-04 04:27:14,475 INFO:     Found new best model at epoch 6
2023-01-04 04:27:14,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:14,476 INFO:     Epoch: 7
2023-01-04 04:27:16,055 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5174978623787562, 'Total loss': 0.5174978623787562} | train loss {'Reaction outcome loss': 0.4042698032481576, 'Total loss': 0.4042698032481576}
2023-01-04 04:27:16,055 INFO:     Found new best model at epoch 7
2023-01-04 04:27:16,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:16,056 INFO:     Epoch: 8
2023-01-04 04:27:17,656 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5217938224474589, 'Total loss': 0.5217938224474589} | train loss {'Reaction outcome loss': 0.39315017907197725, 'Total loss': 0.39315017907197725}
2023-01-04 04:27:17,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:17,656 INFO:     Epoch: 9
2023-01-04 04:27:19,290 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4977083464463552, 'Total loss': 0.4977083464463552} | train loss {'Reaction outcome loss': 0.38386464648836355, 'Total loss': 0.38386464648836355}
2023-01-04 04:27:19,290 INFO:     Found new best model at epoch 9
2023-01-04 04:27:19,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:19,291 INFO:     Epoch: 10
2023-01-04 04:27:20,915 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.492688512802124, 'Total loss': 0.492688512802124} | train loss {'Reaction outcome loss': 0.37345230119430634, 'Total loss': 0.37345230119430634}
2023-01-04 04:27:20,915 INFO:     Found new best model at epoch 10
2023-01-04 04:27:20,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:20,916 INFO:     Epoch: 11
2023-01-04 04:27:22,526 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4968001584211985, 'Total loss': 0.4968001584211985} | train loss {'Reaction outcome loss': 0.36368343145300763, 'Total loss': 0.36368343145300763}
2023-01-04 04:27:22,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:22,526 INFO:     Epoch: 12
2023-01-04 04:27:24,139 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48180167774359384, 'Total loss': 0.48180167774359384} | train loss {'Reaction outcome loss': 0.3563264459640541, 'Total loss': 0.3563264459640541}
2023-01-04 04:27:24,139 INFO:     Found new best model at epoch 12
2023-01-04 04:27:24,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:24,140 INFO:     Epoch: 13
2023-01-04 04:27:25,722 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5206099430720011, 'Total loss': 0.5206099430720011} | train loss {'Reaction outcome loss': 0.3495994896664947, 'Total loss': 0.3495994896664947}
2023-01-04 04:27:25,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:25,723 INFO:     Epoch: 14
2023-01-04 04:27:27,357 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5002202868461609, 'Total loss': 0.5002202868461609} | train loss {'Reaction outcome loss': 0.34247042383958287, 'Total loss': 0.34247042383958287}
2023-01-04 04:27:27,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:27,357 INFO:     Epoch: 15
2023-01-04 04:27:28,989 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4852370858192444, 'Total loss': 0.4852370858192444} | train loss {'Reaction outcome loss': 0.33286290556622755, 'Total loss': 0.33286290556622755}
2023-01-04 04:27:28,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:28,990 INFO:     Epoch: 16
2023-01-04 04:27:30,619 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49449417491753894, 'Total loss': 0.49449417491753894} | train loss {'Reaction outcome loss': 0.32837899614273425, 'Total loss': 0.32837899614273425}
2023-01-04 04:27:30,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:30,620 INFO:     Epoch: 17
2023-01-04 04:27:32,262 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4819467047850291, 'Total loss': 0.4819467047850291} | train loss {'Reaction outcome loss': 0.32256000217332736, 'Total loss': 0.32256000217332736}
2023-01-04 04:27:32,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:32,263 INFO:     Epoch: 18
2023-01-04 04:27:33,855 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4684260944525401, 'Total loss': 0.4684260944525401} | train loss {'Reaction outcome loss': 0.3168299453541475, 'Total loss': 0.3168299453541475}
2023-01-04 04:27:33,856 INFO:     Found new best model at epoch 18
2023-01-04 04:27:33,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:33,856 INFO:     Epoch: 19
2023-01-04 04:27:35,454 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48738591074943544, 'Total loss': 0.48738591074943544} | train loss {'Reaction outcome loss': 0.310120045842892, 'Total loss': 0.310120045842892}
2023-01-04 04:27:35,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:35,454 INFO:     Epoch: 20
2023-01-04 04:27:37,091 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47181471685568493, 'Total loss': 0.47181471685568493} | train loss {'Reaction outcome loss': 0.30322951212901933, 'Total loss': 0.30322951212901933}
2023-01-04 04:27:37,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:37,092 INFO:     Epoch: 21
2023-01-04 04:27:38,728 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4716218948364258, 'Total loss': 0.4716218948364258} | train loss {'Reaction outcome loss': 0.30062708619054046, 'Total loss': 0.30062708619054046}
2023-01-04 04:27:38,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:38,728 INFO:     Epoch: 22
2023-01-04 04:27:40,351 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45304652750492097, 'Total loss': 0.45304652750492097} | train loss {'Reaction outcome loss': 0.29673734826409, 'Total loss': 0.29673734826409}
2023-01-04 04:27:40,351 INFO:     Found new best model at epoch 22
2023-01-04 04:27:40,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:40,352 INFO:     Epoch: 23
2023-01-04 04:27:41,933 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4671982725461324, 'Total loss': 0.4671982725461324} | train loss {'Reaction outcome loss': 0.2883987196785018, 'Total loss': 0.2883987196785018}
2023-01-04 04:27:41,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:41,933 INFO:     Epoch: 24
2023-01-04 04:27:43,591 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45777721007665, 'Total loss': 0.45777721007665} | train loss {'Reaction outcome loss': 0.28574410439990056, 'Total loss': 0.28574410439990056}
2023-01-04 04:27:43,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:43,591 INFO:     Epoch: 25
2023-01-04 04:27:45,225 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4549445897340775, 'Total loss': 0.4549445897340775} | train loss {'Reaction outcome loss': 0.2821487386573093, 'Total loss': 0.2821487386573093}
2023-01-04 04:27:45,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:45,226 INFO:     Epoch: 26
2023-01-04 04:27:46,876 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4607370058695475, 'Total loss': 0.4607370058695475} | train loss {'Reaction outcome loss': 0.27618213209057974, 'Total loss': 0.27618213209057974}
2023-01-04 04:27:46,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:46,876 INFO:     Epoch: 27
2023-01-04 04:27:48,527 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.458231025437514, 'Total loss': 0.458231025437514} | train loss {'Reaction outcome loss': 0.27457874467334165, 'Total loss': 0.27457874467334165}
2023-01-04 04:27:48,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:48,527 INFO:     Epoch: 28
2023-01-04 04:27:50,176 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4773765464623769, 'Total loss': 0.4773765464623769} | train loss {'Reaction outcome loss': 0.2704944855496556, 'Total loss': 0.2704944855496556}
2023-01-04 04:27:50,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:50,177 INFO:     Epoch: 29
2023-01-04 04:27:51,769 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49309348265329994, 'Total loss': 0.49309348265329994} | train loss {'Reaction outcome loss': 0.2656299258155298, 'Total loss': 0.2656299258155298}
2023-01-04 04:27:51,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:51,769 INFO:     Epoch: 30
2023-01-04 04:27:53,372 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46939799586931863, 'Total loss': 0.46939799586931863} | train loss {'Reaction outcome loss': 0.2650053737019374, 'Total loss': 0.2650053737019374}
2023-01-04 04:27:53,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:53,373 INFO:     Epoch: 31
2023-01-04 04:27:54,993 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4779773116111755, 'Total loss': 0.4779773116111755} | train loss {'Reaction outcome loss': 0.25961058073095467, 'Total loss': 0.25961058073095467}
2023-01-04 04:27:54,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:54,993 INFO:     Epoch: 32
2023-01-04 04:27:56,610 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45110582013924916, 'Total loss': 0.45110582013924916} | train loss {'Reaction outcome loss': 0.2578913235653609, 'Total loss': 0.2578913235653609}
2023-01-04 04:27:56,611 INFO:     Found new best model at epoch 32
2023-01-04 04:27:56,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:56,612 INFO:     Epoch: 33
2023-01-04 04:27:58,244 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4620174080133438, 'Total loss': 0.4620174080133438} | train loss {'Reaction outcome loss': 0.2519902409683066, 'Total loss': 0.2519902409683066}
2023-01-04 04:27:58,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:58,244 INFO:     Epoch: 34
2023-01-04 04:27:59,834 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44967678785324094, 'Total loss': 0.44967678785324094} | train loss {'Reaction outcome loss': 0.2511009523503832, 'Total loss': 0.2511009523503832}
2023-01-04 04:27:59,834 INFO:     Found new best model at epoch 34
2023-01-04 04:27:59,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:27:59,835 INFO:     Epoch: 35
2023-01-04 04:28:01,443 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4523738940556844, 'Total loss': 0.4523738940556844} | train loss {'Reaction outcome loss': 0.24631265837309163, 'Total loss': 0.24631265837309163}
2023-01-04 04:28:01,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:01,443 INFO:     Epoch: 36
2023-01-04 04:28:03,033 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4570370018482208, 'Total loss': 0.4570370018482208} | train loss {'Reaction outcome loss': 0.24490512720568086, 'Total loss': 0.24490512720568086}
2023-01-04 04:28:03,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:03,033 INFO:     Epoch: 37
2023-01-04 04:28:04,631 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4681619932254156, 'Total loss': 0.4681619932254156} | train loss {'Reaction outcome loss': 0.2410700098083553, 'Total loss': 0.2410700098083553}
2023-01-04 04:28:04,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:04,631 INFO:     Epoch: 38
2023-01-04 04:28:06,230 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.456181263923645, 'Total loss': 0.456181263923645} | train loss {'Reaction outcome loss': 0.2385336272418499, 'Total loss': 0.2385336272418499}
2023-01-04 04:28:06,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:06,230 INFO:     Epoch: 39
2023-01-04 04:28:07,828 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43390629688898724, 'Total loss': 0.43390629688898724} | train loss {'Reaction outcome loss': 0.2379113557187013, 'Total loss': 0.2379113557187013}
2023-01-04 04:28:07,829 INFO:     Found new best model at epoch 39
2023-01-04 04:28:07,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:07,829 INFO:     Epoch: 40
2023-01-04 04:28:09,415 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46646706759929657, 'Total loss': 0.46646706759929657} | train loss {'Reaction outcome loss': 0.235874734025462, 'Total loss': 0.235874734025462}
2023-01-04 04:28:09,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:09,416 INFO:     Epoch: 41
2023-01-04 04:28:11,000 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4694752405087153, 'Total loss': 0.4694752405087153} | train loss {'Reaction outcome loss': 0.23176551474399515, 'Total loss': 0.23176551474399515}
2023-01-04 04:28:11,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:11,001 INFO:     Epoch: 42
2023-01-04 04:28:12,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4652814646561941, 'Total loss': 0.4652814646561941} | train loss {'Reaction outcome loss': 0.22893536733698758, 'Total loss': 0.22893536733698758}
2023-01-04 04:28:12,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:12,633 INFO:     Epoch: 43
2023-01-04 04:28:14,263 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4785828153292338, 'Total loss': 0.4785828153292338} | train loss {'Reaction outcome loss': 0.2268733422974602, 'Total loss': 0.2268733422974602}
2023-01-04 04:28:14,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:14,263 INFO:     Epoch: 44
2023-01-04 04:28:15,889 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4602230370044708, 'Total loss': 0.4602230370044708} | train loss {'Reaction outcome loss': 0.2255774606220989, 'Total loss': 0.2255774606220989}
2023-01-04 04:28:15,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:15,889 INFO:     Epoch: 45
2023-01-04 04:28:17,491 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45221133828163146, 'Total loss': 0.45221133828163146} | train loss {'Reaction outcome loss': 0.22192679506992175, 'Total loss': 0.22192679506992175}
2023-01-04 04:28:17,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:17,491 INFO:     Epoch: 46
2023-01-04 04:28:19,096 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46850456595420836, 'Total loss': 0.46850456595420836} | train loss {'Reaction outcome loss': 0.21993686043613656, 'Total loss': 0.21993686043613656}
2023-01-04 04:28:19,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:19,096 INFO:     Epoch: 47
2023-01-04 04:28:20,692 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.454643855492274, 'Total loss': 0.454643855492274} | train loss {'Reaction outcome loss': 0.22002536371780645, 'Total loss': 0.22002536371780645}
2023-01-04 04:28:20,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:20,692 INFO:     Epoch: 48
2023-01-04 04:28:22,304 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4684794376293818, 'Total loss': 0.4684794376293818} | train loss {'Reaction outcome loss': 0.21681413293853133, 'Total loss': 0.21681413293853133}
2023-01-04 04:28:22,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:22,304 INFO:     Epoch: 49
2023-01-04 04:28:23,936 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4714883009592692, 'Total loss': 0.4714883009592692} | train loss {'Reaction outcome loss': 0.21632417275264376, 'Total loss': 0.21632417275264376}
2023-01-04 04:28:23,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:23,936 INFO:     Epoch: 50
2023-01-04 04:28:25,558 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47897557020187376, 'Total loss': 0.47897557020187376} | train loss {'Reaction outcome loss': 0.21287298431815008, 'Total loss': 0.21287298431815008}
2023-01-04 04:28:25,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:25,560 INFO:     Epoch: 51
2023-01-04 04:28:27,140 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4877541164557139, 'Total loss': 0.4877541164557139} | train loss {'Reaction outcome loss': 0.2131572661497748, 'Total loss': 0.2131572661497748}
2023-01-04 04:28:27,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:27,141 INFO:     Epoch: 52
2023-01-04 04:28:28,741 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46136623322963716, 'Total loss': 0.46136623322963716} | train loss {'Reaction outcome loss': 0.21034042749701853, 'Total loss': 0.21034042749701853}
2023-01-04 04:28:28,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:28,741 INFO:     Epoch: 53
2023-01-04 04:28:30,358 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45215437809626263, 'Total loss': 0.45215437809626263} | train loss {'Reaction outcome loss': 0.2087062920985024, 'Total loss': 0.2087062920985024}
2023-01-04 04:28:30,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:30,358 INFO:     Epoch: 54
2023-01-04 04:28:31,984 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4933738946914673, 'Total loss': 0.4933738946914673} | train loss {'Reaction outcome loss': 0.20752563609973618, 'Total loss': 0.20752563609973618}
2023-01-04 04:28:31,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:31,985 INFO:     Epoch: 55
2023-01-04 04:28:33,616 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48720075090726217, 'Total loss': 0.48720075090726217} | train loss {'Reaction outcome loss': 0.20392801823760198, 'Total loss': 0.20392801823760198}
2023-01-04 04:28:33,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:33,617 INFO:     Epoch: 56
2023-01-04 04:28:35,212 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4915710916121801, 'Total loss': 0.4915710916121801} | train loss {'Reaction outcome loss': 0.20359921791600838, 'Total loss': 0.20359921791600838}
2023-01-04 04:28:35,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:35,212 INFO:     Epoch: 57
2023-01-04 04:28:36,808 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4566769043604533, 'Total loss': 0.4566769043604533} | train loss {'Reaction outcome loss': 0.20356379657822396, 'Total loss': 0.20356379657822396}
2023-01-04 04:28:36,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:36,808 INFO:     Epoch: 58
2023-01-04 04:28:38,412 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4843611180782318, 'Total loss': 0.4843611180782318} | train loss {'Reaction outcome loss': 0.2024458555491231, 'Total loss': 0.2024458555491231}
2023-01-04 04:28:38,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:38,412 INFO:     Epoch: 59
2023-01-04 04:28:40,032 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47264711459477743, 'Total loss': 0.47264711459477743} | train loss {'Reaction outcome loss': 0.20000786729668021, 'Total loss': 0.20000786729668021}
2023-01-04 04:28:40,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:40,032 INFO:     Epoch: 60
2023-01-04 04:28:41,655 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4655798132220904, 'Total loss': 0.4655798132220904} | train loss {'Reaction outcome loss': 0.19843082380101137, 'Total loss': 0.19843082380101137}
2023-01-04 04:28:41,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:41,655 INFO:     Epoch: 61
2023-01-04 04:28:43,276 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46508418818314873, 'Total loss': 0.46508418818314873} | train loss {'Reaction outcome loss': 0.1966876219689093, 'Total loss': 0.1966876219689093}
2023-01-04 04:28:43,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:43,277 INFO:     Epoch: 62
2023-01-04 04:28:44,883 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4642991185188293, 'Total loss': 0.4642991185188293} | train loss {'Reaction outcome loss': 0.19509574060835994, 'Total loss': 0.19509574060835994}
2023-01-04 04:28:44,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:44,884 INFO:     Epoch: 63
2023-01-04 04:28:46,505 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4913758585850398, 'Total loss': 0.4913758585850398} | train loss {'Reaction outcome loss': 0.19248513933203926, 'Total loss': 0.19248513933203926}
2023-01-04 04:28:46,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:46,506 INFO:     Epoch: 64
2023-01-04 04:28:48,102 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4585726936658224, 'Total loss': 0.4585726936658224} | train loss {'Reaction outcome loss': 0.19409585016567785, 'Total loss': 0.19409585016567785}
2023-01-04 04:28:48,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:48,102 INFO:     Epoch: 65
2023-01-04 04:28:49,734 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4668092946211497, 'Total loss': 0.4668092946211497} | train loss {'Reaction outcome loss': 0.1917327860040785, 'Total loss': 0.1917327860040785}
2023-01-04 04:28:49,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:49,734 INFO:     Epoch: 66
2023-01-04 04:28:51,361 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4608907332022985, 'Total loss': 0.4608907332022985} | train loss {'Reaction outcome loss': 0.18692904429691792, 'Total loss': 0.18692904429691792}
2023-01-04 04:28:51,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:51,361 INFO:     Epoch: 67
2023-01-04 04:28:52,989 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.470091571410497, 'Total loss': 0.470091571410497} | train loss {'Reaction outcome loss': 0.18948837397922677, 'Total loss': 0.18948837397922677}
2023-01-04 04:28:52,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:52,989 INFO:     Epoch: 68
2023-01-04 04:28:54,573 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4577193240324656, 'Total loss': 0.4577193240324656} | train loss {'Reaction outcome loss': 0.1858114707233243, 'Total loss': 0.1858114707233243}
2023-01-04 04:28:54,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:54,573 INFO:     Epoch: 69
2023-01-04 04:28:56,156 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48513361215591433, 'Total loss': 0.48513361215591433} | train loss {'Reaction outcome loss': 0.18629871721006258, 'Total loss': 0.18629871721006258}
2023-01-04 04:28:56,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:56,157 INFO:     Epoch: 70
2023-01-04 04:28:57,779 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.477471790711085, 'Total loss': 0.477471790711085} | train loss {'Reaction outcome loss': 0.1828002722980959, 'Total loss': 0.1828002722980959}
2023-01-04 04:28:57,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:57,779 INFO:     Epoch: 71
2023-01-04 04:28:59,396 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4695379227399826, 'Total loss': 0.4695379227399826} | train loss {'Reaction outcome loss': 0.18645912291825034, 'Total loss': 0.18645912291825034}
2023-01-04 04:28:59,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:28:59,396 INFO:     Epoch: 72
2023-01-04 04:29:00,992 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49624776740868887, 'Total loss': 0.49624776740868887} | train loss {'Reaction outcome loss': 0.18059961132651417, 'Total loss': 0.18059961132651417}
2023-01-04 04:29:00,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:00,992 INFO:     Epoch: 73
2023-01-04 04:29:02,613 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46634247303009035, 'Total loss': 0.46634247303009035} | train loss {'Reaction outcome loss': 0.18213357044794068, 'Total loss': 0.18213357044794068}
2023-01-04 04:29:02,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:02,614 INFO:     Epoch: 74
2023-01-04 04:29:04,212 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46634838779767357, 'Total loss': 0.46634838779767357} | train loss {'Reaction outcome loss': 0.1797514577070083, 'Total loss': 0.1797514577070083}
2023-01-04 04:29:04,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:04,212 INFO:     Epoch: 75
2023-01-04 04:29:05,807 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46112651030222573, 'Total loss': 0.46112651030222573} | train loss {'Reaction outcome loss': 0.17806880758396124, 'Total loss': 0.17806880758396124}
2023-01-04 04:29:05,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:05,807 INFO:     Epoch: 76
2023-01-04 04:29:07,431 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4823164562384287, 'Total loss': 0.4823164562384287} | train loss {'Reaction outcome loss': 0.17952857388432275, 'Total loss': 0.17952857388432275}
2023-01-04 04:29:07,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:07,431 INFO:     Epoch: 77
2023-01-04 04:29:09,050 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47964329024155933, 'Total loss': 0.47964329024155933} | train loss {'Reaction outcome loss': 0.1782323533151339, 'Total loss': 0.1782323533151339}
2023-01-04 04:29:09,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:09,050 INFO:     Epoch: 78
2023-01-04 04:29:10,674 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48138275543848674, 'Total loss': 0.48138275543848674} | train loss {'Reaction outcome loss': 0.17635908761878735, 'Total loss': 0.17635908761878735}
2023-01-04 04:29:10,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:10,674 INFO:     Epoch: 79
2023-01-04 04:29:12,281 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49211990237236025, 'Total loss': 0.49211990237236025} | train loss {'Reaction outcome loss': 0.17276658418013408, 'Total loss': 0.17276658418013408}
2023-01-04 04:29:12,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:12,281 INFO:     Epoch: 80
2023-01-04 04:29:13,898 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49216279288132986, 'Total loss': 0.49216279288132986} | train loss {'Reaction outcome loss': 0.17463934430953398, 'Total loss': 0.17463934430953398}
2023-01-04 04:29:13,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:13,898 INFO:     Epoch: 81
2023-01-04 04:29:15,487 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4620037486155828, 'Total loss': 0.4620037486155828} | train loss {'Reaction outcome loss': 0.17440469620164337, 'Total loss': 0.17440469620164337}
2023-01-04 04:29:15,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:15,488 INFO:     Epoch: 82
2023-01-04 04:29:17,100 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49611495931943256, 'Total loss': 0.49611495931943256} | train loss {'Reaction outcome loss': 0.17181392576854798, 'Total loss': 0.17181392576854798}
2023-01-04 04:29:17,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:17,101 INFO:     Epoch: 83
2023-01-04 04:29:18,728 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48084821502367653, 'Total loss': 0.48084821502367653} | train loss {'Reaction outcome loss': 0.17222673765346677, 'Total loss': 0.17222673765346677}
2023-01-04 04:29:18,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:18,728 INFO:     Epoch: 84
2023-01-04 04:29:20,357 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.455217045545578, 'Total loss': 0.455217045545578} | train loss {'Reaction outcome loss': 0.17173884594510394, 'Total loss': 0.17173884594510394}
2023-01-04 04:29:20,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:20,357 INFO:     Epoch: 85
2023-01-04 04:29:21,945 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4788729578256607, 'Total loss': 0.4788729578256607} | train loss {'Reaction outcome loss': 0.17219138758707564, 'Total loss': 0.17219138758707564}
2023-01-04 04:29:21,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:21,945 INFO:     Epoch: 86
2023-01-04 04:29:23,539 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5080299397309621, 'Total loss': 0.5080299397309621} | train loss {'Reaction outcome loss': 0.17051325307399143, 'Total loss': 0.17051325307399143}
2023-01-04 04:29:23,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:23,539 INFO:     Epoch: 87
2023-01-04 04:29:25,168 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4814025600751241, 'Total loss': 0.4814025600751241} | train loss {'Reaction outcome loss': 0.16961032756022598, 'Total loss': 0.16961032756022598}
2023-01-04 04:29:25,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:25,168 INFO:     Epoch: 88
2023-01-04 04:29:26,796 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4918972929318746, 'Total loss': 0.4918972929318746} | train loss {'Reaction outcome loss': 0.16797436887418535, 'Total loss': 0.16797436887418535}
2023-01-04 04:29:26,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:26,797 INFO:     Epoch: 89
2023-01-04 04:29:28,387 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5165800074736278, 'Total loss': 0.5165800074736278} | train loss {'Reaction outcome loss': 0.16794204054272563, 'Total loss': 0.16794204054272563}
2023-01-04 04:29:28,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:28,387 INFO:     Epoch: 90
2023-01-04 04:29:30,010 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4888375798861186, 'Total loss': 0.4888375798861186} | train loss {'Reaction outcome loss': 0.16651112055372352, 'Total loss': 0.16651112055372352}
2023-01-04 04:29:30,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:30,010 INFO:     Epoch: 91
2023-01-04 04:29:31,602 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47074684699376423, 'Total loss': 0.47074684699376423} | train loss {'Reaction outcome loss': 0.1680561839283481, 'Total loss': 0.1680561839283481}
2023-01-04 04:29:31,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:31,602 INFO:     Epoch: 92
2023-01-04 04:29:33,208 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4758945862452189, 'Total loss': 0.4758945862452189} | train loss {'Reaction outcome loss': 0.1661812029711714, 'Total loss': 0.1661812029711714}
2023-01-04 04:29:33,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:33,209 INFO:     Epoch: 93
2023-01-04 04:29:34,798 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48419196108977, 'Total loss': 0.48419196108977} | train loss {'Reaction outcome loss': 0.16410444694023163, 'Total loss': 0.16410444694023163}
2023-01-04 04:29:34,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:34,798 INFO:     Epoch: 94
2023-01-04 04:29:36,425 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4925410732626915, 'Total loss': 0.4925410732626915} | train loss {'Reaction outcome loss': 0.1657252147834116, 'Total loss': 0.1657252147834116}
2023-01-04 04:29:36,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:36,426 INFO:     Epoch: 95
2023-01-04 04:29:38,029 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49489514032999676, 'Total loss': 0.49489514032999676} | train loss {'Reaction outcome loss': 0.16057912094202498, 'Total loss': 0.16057912094202498}
2023-01-04 04:29:38,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:38,029 INFO:     Epoch: 96
2023-01-04 04:29:39,628 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49643008212248485, 'Total loss': 0.49643008212248485} | train loss {'Reaction outcome loss': 0.1639809771592221, 'Total loss': 0.1639809771592221}
2023-01-04 04:29:39,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:39,628 INFO:     Epoch: 97
2023-01-04 04:29:41,226 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49423945347468057, 'Total loss': 0.49423945347468057} | train loss {'Reaction outcome loss': 0.16150628289187643, 'Total loss': 0.16150628289187643}
2023-01-04 04:29:41,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:41,227 INFO:     Epoch: 98
2023-01-04 04:29:42,841 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4953921298185984, 'Total loss': 0.4953921298185984} | train loss {'Reaction outcome loss': 0.1629575059248222, 'Total loss': 0.1629575059248222}
2023-01-04 04:29:42,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:42,841 INFO:     Epoch: 99
2023-01-04 04:29:44,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.519588577747345, 'Total loss': 0.519588577747345} | train loss {'Reaction outcome loss': 0.1617197741616504, 'Total loss': 0.1617197741616504}
2023-01-04 04:29:44,455 INFO:     Best model found after epoch 40 of 100.
2023-01-04 04:29:44,455 INFO:   Done with stage: TRAINING
2023-01-04 04:29:44,455 INFO:   Starting stage: EVALUATION
2023-01-04 04:29:44,577 INFO:   Done with stage: EVALUATION
2023-01-04 04:29:44,577 INFO:   Leaving out SEQ value Fold_5
2023-01-04 04:29:44,589 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:29:44,589 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:29:45,249 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:29:45,250 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:29:45,319 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:29:45,319 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:29:45,319 INFO:     No hyperparam tuning for this model
2023-01-04 04:29:45,319 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:29:45,319 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:29:45,320 INFO:     None feature selector for col prot
2023-01-04 04:29:45,320 INFO:     None feature selector for col prot
2023-01-04 04:29:45,320 INFO:     None feature selector for col prot
2023-01-04 04:29:45,320 INFO:     None feature selector for col chem
2023-01-04 04:29:45,321 INFO:     None feature selector for col chem
2023-01-04 04:29:45,321 INFO:     None feature selector for col chem
2023-01-04 04:29:45,321 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:29:45,321 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:29:45,322 INFO:     Number of params in model 70141
2023-01-04 04:29:45,325 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:29:45,325 INFO:   Starting stage: TRAINING
2023-01-04 04:29:45,368 INFO:     Val loss before train {'Reaction outcome loss': 0.8887433131535848, 'Total loss': 0.8887433131535848}
2023-01-04 04:29:45,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:45,368 INFO:     Epoch: 0
2023-01-04 04:29:46,981 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6493841310342153, 'Total loss': 0.6493841310342153} | train loss {'Reaction outcome loss': 0.8685759674986347, 'Total loss': 0.8685759674986347}
2023-01-04 04:29:46,981 INFO:     Found new best model at epoch 0
2023-01-04 04:29:46,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:46,982 INFO:     Epoch: 1
2023-01-04 04:29:48,574 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5185827811559042, 'Total loss': 0.5185827811559042} | train loss {'Reaction outcome loss': 0.6158915419763606, 'Total loss': 0.6158915419763606}
2023-01-04 04:29:48,574 INFO:     Found new best model at epoch 1
2023-01-04 04:29:48,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:48,575 INFO:     Epoch: 2
2023-01-04 04:29:50,159 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49078706999619803, 'Total loss': 0.49078706999619803} | train loss {'Reaction outcome loss': 0.5255050975493145, 'Total loss': 0.5255050975493145}
2023-01-04 04:29:50,159 INFO:     Found new best model at epoch 2
2023-01-04 04:29:50,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:50,160 INFO:     Epoch: 3
2023-01-04 04:29:51,752 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4717430382966995, 'Total loss': 0.4717430382966995} | train loss {'Reaction outcome loss': 0.4834440925061057, 'Total loss': 0.4834440925061057}
2023-01-04 04:29:51,752 INFO:     Found new best model at epoch 3
2023-01-04 04:29:51,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:51,753 INFO:     Epoch: 4
2023-01-04 04:29:53,350 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48955079515775046, 'Total loss': 0.48955079515775046} | train loss {'Reaction outcome loss': 0.45391504326667165, 'Total loss': 0.45391504326667165}
2023-01-04 04:29:53,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:53,350 INFO:     Epoch: 5
2023-01-04 04:29:54,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44520135124524435, 'Total loss': 0.44520135124524435} | train loss {'Reaction outcome loss': 0.4352892325242934, 'Total loss': 0.4352892325242934}
2023-01-04 04:29:54,952 INFO:     Found new best model at epoch 5
2023-01-04 04:29:54,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:54,953 INFO:     Epoch: 6
2023-01-04 04:29:56,555 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43951616088549295, 'Total loss': 0.43951616088549295} | train loss {'Reaction outcome loss': 0.41742220714634504, 'Total loss': 0.41742220714634504}
2023-01-04 04:29:56,555 INFO:     Found new best model at epoch 6
2023-01-04 04:29:56,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:56,556 INFO:     Epoch: 7
2023-01-04 04:29:58,160 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43089934090773263, 'Total loss': 0.43089934090773263} | train loss {'Reaction outcome loss': 0.40523963332821744, 'Total loss': 0.40523963332821744}
2023-01-04 04:29:58,161 INFO:     Found new best model at epoch 7
2023-01-04 04:29:58,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:58,162 INFO:     Epoch: 8
2023-01-04 04:29:59,770 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42707066535949706, 'Total loss': 0.42707066535949706} | train loss {'Reaction outcome loss': 0.39270863179050197, 'Total loss': 0.39270863179050197}
2023-01-04 04:29:59,770 INFO:     Found new best model at epoch 8
2023-01-04 04:29:59,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:29:59,771 INFO:     Epoch: 9
2023-01-04 04:30:01,382 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4326480080684026, 'Total loss': 0.4326480080684026} | train loss {'Reaction outcome loss': 0.38487166281964375, 'Total loss': 0.38487166281964375}
2023-01-04 04:30:01,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:01,382 INFO:     Epoch: 10
2023-01-04 04:30:03,009 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4237473318974177, 'Total loss': 0.4237473318974177} | train loss {'Reaction outcome loss': 0.37634401728099864, 'Total loss': 0.37634401728099864}
2023-01-04 04:30:03,010 INFO:     Found new best model at epoch 10
2023-01-04 04:30:03,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:03,010 INFO:     Epoch: 11
2023-01-04 04:30:04,626 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41139744718869525, 'Total loss': 0.41139744718869525} | train loss {'Reaction outcome loss': 0.3675782463180459, 'Total loss': 0.3675782463180459}
2023-01-04 04:30:04,627 INFO:     Found new best model at epoch 11
2023-01-04 04:30:04,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:04,628 INFO:     Epoch: 12
2023-01-04 04:30:06,217 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4147040863831838, 'Total loss': 0.4147040863831838} | train loss {'Reaction outcome loss': 0.3593655130708261, 'Total loss': 0.3593655130708261}
2023-01-04 04:30:06,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:06,217 INFO:     Epoch: 13
2023-01-04 04:30:07,826 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42717560728391013, 'Total loss': 0.42717560728391013} | train loss {'Reaction outcome loss': 0.35425040047844397, 'Total loss': 0.35425040047844397}
2023-01-04 04:30:07,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:07,826 INFO:     Epoch: 14
2023-01-04 04:30:09,463 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42039438088734943, 'Total loss': 0.42039438088734943} | train loss {'Reaction outcome loss': 0.34750958252361963, 'Total loss': 0.34750958252361963}
2023-01-04 04:30:09,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:09,463 INFO:     Epoch: 15
2023-01-04 04:30:11,080 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40300859908262887, 'Total loss': 0.40300859908262887} | train loss {'Reaction outcome loss': 0.34069341071461084, 'Total loss': 0.34069341071461084}
2023-01-04 04:30:11,080 INFO:     Found new best model at epoch 15
2023-01-04 04:30:11,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:11,081 INFO:     Epoch: 16
2023-01-04 04:30:12,673 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3990511953830719, 'Total loss': 0.3990511953830719} | train loss {'Reaction outcome loss': 0.33177209583645695, 'Total loss': 0.33177209583645695}
2023-01-04 04:30:12,673 INFO:     Found new best model at epoch 16
2023-01-04 04:30:12,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:12,674 INFO:     Epoch: 17
2023-01-04 04:30:14,282 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4170024484395981, 'Total loss': 0.4170024484395981} | train loss {'Reaction outcome loss': 0.3294254709505863, 'Total loss': 0.3294254709505863}
2023-01-04 04:30:14,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:14,282 INFO:     Epoch: 18
2023-01-04 04:30:15,880 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3841882278521856, 'Total loss': 0.3841882278521856} | train loss {'Reaction outcome loss': 0.32344814844510184, 'Total loss': 0.32344814844510184}
2023-01-04 04:30:15,880 INFO:     Found new best model at epoch 18
2023-01-04 04:30:15,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:15,881 INFO:     Epoch: 19
2023-01-04 04:30:17,469 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.385232537984848, 'Total loss': 0.385232537984848} | train loss {'Reaction outcome loss': 0.31887307585576813, 'Total loss': 0.31887307585576813}
2023-01-04 04:30:17,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:17,470 INFO:     Epoch: 20
2023-01-04 04:30:19,084 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.392704838514328, 'Total loss': 0.392704838514328} | train loss {'Reaction outcome loss': 0.31401068133567644, 'Total loss': 0.31401068133567644}
2023-01-04 04:30:19,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:19,084 INFO:     Epoch: 21
2023-01-04 04:30:20,699 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39193165898323057, 'Total loss': 0.39193165898323057} | train loss {'Reaction outcome loss': 0.3100761027488898, 'Total loss': 0.3100761027488898}
2023-01-04 04:30:20,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:20,699 INFO:     Epoch: 22
2023-01-04 04:30:22,324 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38723814239104587, 'Total loss': 0.38723814239104587} | train loss {'Reaction outcome loss': 0.30554737844622093, 'Total loss': 0.30554737844622093}
2023-01-04 04:30:22,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:22,325 INFO:     Epoch: 23
2023-01-04 04:30:23,916 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3887856165568034, 'Total loss': 0.3887856165568034} | train loss {'Reaction outcome loss': 0.299667277248973, 'Total loss': 0.299667277248973}
2023-01-04 04:30:23,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:23,916 INFO:     Epoch: 24
2023-01-04 04:30:25,501 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3975748171408971, 'Total loss': 0.3975748171408971} | train loss {'Reaction outcome loss': 0.2938099806650881, 'Total loss': 0.2938099806650881}
2023-01-04 04:30:25,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:25,501 INFO:     Epoch: 25
2023-01-04 04:30:27,110 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4002236783504486, 'Total loss': 0.4002236783504486} | train loss {'Reaction outcome loss': 0.29054360791018724, 'Total loss': 0.29054360791018724}
2023-01-04 04:30:27,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:27,111 INFO:     Epoch: 26
2023-01-04 04:30:28,745 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3932737231254578, 'Total loss': 0.3932737231254578} | train loss {'Reaction outcome loss': 0.2849727890013788, 'Total loss': 0.2849727890013788}
2023-01-04 04:30:28,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:28,745 INFO:     Epoch: 27
2023-01-04 04:30:30,362 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37391402224699655, 'Total loss': 0.37391402224699655} | train loss {'Reaction outcome loss': 0.2836033200260104, 'Total loss': 0.2836033200260104}
2023-01-04 04:30:30,362 INFO:     Found new best model at epoch 27
2023-01-04 04:30:30,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:30,363 INFO:     Epoch: 28
2023-01-04 04:30:31,956 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3941371743877729, 'Total loss': 0.3941371743877729} | train loss {'Reaction outcome loss': 0.27840629004829626, 'Total loss': 0.27840629004829626}
2023-01-04 04:30:31,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:31,957 INFO:     Epoch: 29
2023-01-04 04:30:33,544 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38816801508267723, 'Total loss': 0.38816801508267723} | train loss {'Reaction outcome loss': 0.2766497981085674, 'Total loss': 0.2766497981085674}
2023-01-04 04:30:33,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:33,545 INFO:     Epoch: 30
2023-01-04 04:30:35,140 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3724608908096949, 'Total loss': 0.3724608908096949} | train loss {'Reaction outcome loss': 0.27282957598190444, 'Total loss': 0.27282957598190444}
2023-01-04 04:30:35,141 INFO:     Found new best model at epoch 30
2023-01-04 04:30:35,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:35,141 INFO:     Epoch: 31
2023-01-04 04:30:36,776 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3688969264427821, 'Total loss': 0.3688969264427821} | train loss {'Reaction outcome loss': 0.26544213834275837, 'Total loss': 0.26544213834275837}
2023-01-04 04:30:36,776 INFO:     Found new best model at epoch 31
2023-01-04 04:30:36,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:36,777 INFO:     Epoch: 32
2023-01-04 04:30:38,409 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3594497819741567, 'Total loss': 0.3594497819741567} | train loss {'Reaction outcome loss': 0.2643367968876224, 'Total loss': 0.2643367968876224}
2023-01-04 04:30:38,409 INFO:     Found new best model at epoch 32
2023-01-04 04:30:38,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:38,410 INFO:     Epoch: 33
2023-01-04 04:30:40,020 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3588050643603007, 'Total loss': 0.3588050643603007} | train loss {'Reaction outcome loss': 0.2625994581177777, 'Total loss': 0.2625994581177777}
2023-01-04 04:30:40,021 INFO:     Found new best model at epoch 33
2023-01-04 04:30:40,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:40,022 INFO:     Epoch: 34
2023-01-04 04:30:41,640 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37607799073060355, 'Total loss': 0.37607799073060355} | train loss {'Reaction outcome loss': 0.2559867373092725, 'Total loss': 0.2559867373092725}
2023-01-04 04:30:41,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:41,641 INFO:     Epoch: 35
2023-01-04 04:30:43,281 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4003555397192637, 'Total loss': 0.4003555397192637} | train loss {'Reaction outcome loss': 0.25450718297962677, 'Total loss': 0.25450718297962677}
2023-01-04 04:30:43,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:43,281 INFO:     Epoch: 36
2023-01-04 04:30:44,896 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38685119648774463, 'Total loss': 0.38685119648774463} | train loss {'Reaction outcome loss': 0.2537475972560769, 'Total loss': 0.2537475972560769}
2023-01-04 04:30:44,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:44,896 INFO:     Epoch: 37
2023-01-04 04:30:46,536 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.372930716474851, 'Total loss': 0.372930716474851} | train loss {'Reaction outcome loss': 0.25034384918987534, 'Total loss': 0.25034384918987534}
2023-01-04 04:30:46,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:46,537 INFO:     Epoch: 38
2023-01-04 04:30:48,168 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.370213520526886, 'Total loss': 0.370213520526886} | train loss {'Reaction outcome loss': 0.24715809343846695, 'Total loss': 0.24715809343846695}
2023-01-04 04:30:48,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:48,169 INFO:     Epoch: 39
2023-01-04 04:30:49,794 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36298762957255043, 'Total loss': 0.36298762957255043} | train loss {'Reaction outcome loss': 0.2443183228938373, 'Total loss': 0.2443183228938373}
2023-01-04 04:30:49,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:49,794 INFO:     Epoch: 40
2023-01-04 04:30:51,415 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3617449780305227, 'Total loss': 0.3617449780305227} | train loss {'Reaction outcome loss': 0.24424237199800108, 'Total loss': 0.24424237199800108}
2023-01-04 04:30:51,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:51,415 INFO:     Epoch: 41
2023-01-04 04:30:53,017 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3604967842499415, 'Total loss': 0.3604967842499415} | train loss {'Reaction outcome loss': 0.23890561835053595, 'Total loss': 0.23890561835053595}
2023-01-04 04:30:53,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:53,018 INFO:     Epoch: 42
2023-01-04 04:30:54,637 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3673726707696915, 'Total loss': 0.3673726707696915} | train loss {'Reaction outcome loss': 0.23801312839027347, 'Total loss': 0.23801312839027347}
2023-01-04 04:30:54,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:54,637 INFO:     Epoch: 43
2023-01-04 04:30:56,257 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3535509000221888, 'Total loss': 0.3535509000221888} | train loss {'Reaction outcome loss': 0.23548438086675394, 'Total loss': 0.23548438086675394}
2023-01-04 04:30:56,258 INFO:     Found new best model at epoch 43
2023-01-04 04:30:56,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:56,259 INFO:     Epoch: 44
2023-01-04 04:30:57,853 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3759507795174917, 'Total loss': 0.3759507795174917} | train loss {'Reaction outcome loss': 0.23331479958194687, 'Total loss': 0.23331479958194687}
2023-01-04 04:30:57,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:57,853 INFO:     Epoch: 45
2023-01-04 04:30:59,468 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39274005095163983, 'Total loss': 0.39274005095163983} | train loss {'Reaction outcome loss': 0.23171763603545267, 'Total loss': 0.23171763603545267}
2023-01-04 04:30:59,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:30:59,468 INFO:     Epoch: 46
2023-01-04 04:31:01,084 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39678451120853425, 'Total loss': 0.39678451120853425} | train loss {'Reaction outcome loss': 0.22898146225011737, 'Total loss': 0.22898146225011737}
2023-01-04 04:31:01,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:01,084 INFO:     Epoch: 47
2023-01-04 04:31:02,673 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38863410453001657, 'Total loss': 0.38863410453001657} | train loss {'Reaction outcome loss': 0.22827509064429072, 'Total loss': 0.22827509064429072}
2023-01-04 04:31:02,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:02,673 INFO:     Epoch: 48
2023-01-04 04:31:04,316 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39974599579970044, 'Total loss': 0.39974599579970044} | train loss {'Reaction outcome loss': 0.22424027372138164, 'Total loss': 0.22424027372138164}
2023-01-04 04:31:04,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:04,317 INFO:     Epoch: 49
2023-01-04 04:31:05,917 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.362445409099261, 'Total loss': 0.362445409099261} | train loss {'Reaction outcome loss': 0.22399976261847718, 'Total loss': 0.22399976261847718}
2023-01-04 04:31:05,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:05,918 INFO:     Epoch: 50
2023-01-04 04:31:07,560 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3703953355550766, 'Total loss': 0.3703953355550766} | train loss {'Reaction outcome loss': 0.21995188193631085, 'Total loss': 0.21995188193631085}
2023-01-04 04:31:07,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:07,560 INFO:     Epoch: 51
2023-01-04 04:31:09,164 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3768237749735514, 'Total loss': 0.3768237749735514} | train loss {'Reaction outcome loss': 0.21763471031178205, 'Total loss': 0.21763471031178205}
2023-01-04 04:31:09,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:09,164 INFO:     Epoch: 52
2023-01-04 04:31:10,764 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38082679410775505, 'Total loss': 0.38082679410775505} | train loss {'Reaction outcome loss': 0.22054774454031612, 'Total loss': 0.22054774454031612}
2023-01-04 04:31:10,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:10,765 INFO:     Epoch: 53
2023-01-04 04:31:12,391 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3596264580885569, 'Total loss': 0.3596264580885569} | train loss {'Reaction outcome loss': 0.21749066117653348, 'Total loss': 0.21749066117653348}
2023-01-04 04:31:12,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:12,391 INFO:     Epoch: 54
2023-01-04 04:31:14,002 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37060244381427765, 'Total loss': 0.37060244381427765} | train loss {'Reaction outcome loss': 0.2150457894785955, 'Total loss': 0.2150457894785955}
2023-01-04 04:31:14,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:14,002 INFO:     Epoch: 55
2023-01-04 04:31:15,657 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35230476160844165, 'Total loss': 0.35230476160844165} | train loss {'Reaction outcome loss': 0.21336668576466908, 'Total loss': 0.21336668576466908}
2023-01-04 04:31:15,657 INFO:     Found new best model at epoch 55
2023-01-04 04:31:15,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:15,659 INFO:     Epoch: 56
2023-01-04 04:31:17,313 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3483424186706543, 'Total loss': 0.3483424186706543} | train loss {'Reaction outcome loss': 0.21152980440037344, 'Total loss': 0.21152980440037344}
2023-01-04 04:31:17,314 INFO:     Found new best model at epoch 56
2023-01-04 04:31:17,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:17,314 INFO:     Epoch: 57
2023-01-04 04:31:18,910 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36797276039918264, 'Total loss': 0.36797276039918264} | train loss {'Reaction outcome loss': 0.20945956033489765, 'Total loss': 0.20945956033489765}
2023-01-04 04:31:18,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:18,911 INFO:     Epoch: 58
2023-01-04 04:31:20,523 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38706257541974387, 'Total loss': 0.38706257541974387} | train loss {'Reaction outcome loss': 0.20767617509414574, 'Total loss': 0.20767617509414574}
2023-01-04 04:31:20,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:20,523 INFO:     Epoch: 59
2023-01-04 04:31:22,125 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3802977134784063, 'Total loss': 0.3802977134784063} | train loss {'Reaction outcome loss': 0.2065594804738833, 'Total loss': 0.2065594804738833}
2023-01-04 04:31:22,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:22,125 INFO:     Epoch: 60
2023-01-04 04:31:23,730 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.389363506436348, 'Total loss': 0.389363506436348} | train loss {'Reaction outcome loss': 0.20661441212526727, 'Total loss': 0.20661441212526727}
2023-01-04 04:31:23,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:23,731 INFO:     Epoch: 61
2023-01-04 04:31:25,356 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3568751007318497, 'Total loss': 0.3568751007318497} | train loss {'Reaction outcome loss': 0.20360378564641363, 'Total loss': 0.20360378564641363}
2023-01-04 04:31:25,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:25,357 INFO:     Epoch: 62
2023-01-04 04:31:26,953 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3723852475484212, 'Total loss': 0.3723852475484212} | train loss {'Reaction outcome loss': 0.2033093170084678, 'Total loss': 0.2033093170084678}
2023-01-04 04:31:26,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:26,953 INFO:     Epoch: 63
2023-01-04 04:31:28,564 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38127206365267435, 'Total loss': 0.38127206365267435} | train loss {'Reaction outcome loss': 0.20259315649632512, 'Total loss': 0.20259315649632512}
2023-01-04 04:31:28,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:28,564 INFO:     Epoch: 64
2023-01-04 04:31:30,150 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3517097761233648, 'Total loss': 0.3517097761233648} | train loss {'Reaction outcome loss': 0.20179717429654692, 'Total loss': 0.20179717429654692}
2023-01-04 04:31:30,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:30,150 INFO:     Epoch: 65
2023-01-04 04:31:31,788 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36507406185070673, 'Total loss': 0.36507406185070673} | train loss {'Reaction outcome loss': 0.19999964642153534, 'Total loss': 0.19999964642153534}
2023-01-04 04:31:31,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:31,788 INFO:     Epoch: 66
2023-01-04 04:31:33,394 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3752368986606598, 'Total loss': 0.3752368986606598} | train loss {'Reaction outcome loss': 0.19877131932855513, 'Total loss': 0.19877131932855513}
2023-01-04 04:31:33,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:33,394 INFO:     Epoch: 67
2023-01-04 04:31:35,019 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37339852849642435, 'Total loss': 0.37339852849642435} | train loss {'Reaction outcome loss': 0.19676609721962726, 'Total loss': 0.19676609721962726}
2023-01-04 04:31:35,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:35,020 INFO:     Epoch: 68
2023-01-04 04:31:36,614 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36647126376628875, 'Total loss': 0.36647126376628875} | train loss {'Reaction outcome loss': 0.1939059184453978, 'Total loss': 0.1939059184453978}
2023-01-04 04:31:36,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:36,614 INFO:     Epoch: 69
2023-01-04 04:31:38,216 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35519428650538126, 'Total loss': 0.35519428650538126} | train loss {'Reaction outcome loss': 0.19620798717148683, 'Total loss': 0.19620798717148683}
2023-01-04 04:31:38,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:38,216 INFO:     Epoch: 70
2023-01-04 04:31:39,850 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37211146354675295, 'Total loss': 0.37211146354675295} | train loss {'Reaction outcome loss': 0.19317661132999706, 'Total loss': 0.19317661132999706}
2023-01-04 04:31:39,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:39,850 INFO:     Epoch: 71
2023-01-04 04:31:41,484 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36457561353842416, 'Total loss': 0.36457561353842416} | train loss {'Reaction outcome loss': 0.19196825687662575, 'Total loss': 0.19196825687662575}
2023-01-04 04:31:41,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:41,485 INFO:     Epoch: 72
2023-01-04 04:31:43,088 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36794447104136146, 'Total loss': 0.36794447104136146} | train loss {'Reaction outcome loss': 0.19320033876635537, 'Total loss': 0.19320033876635537}
2023-01-04 04:31:43,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:43,088 INFO:     Epoch: 73
2023-01-04 04:31:44,722 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3922097206115723, 'Total loss': 0.3922097206115723} | train loss {'Reaction outcome loss': 0.19250353310082363, 'Total loss': 0.19250353310082363}
2023-01-04 04:31:44,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:44,722 INFO:     Epoch: 74
2023-01-04 04:31:46,316 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3633281032244364, 'Total loss': 0.3633281032244364} | train loss {'Reaction outcome loss': 0.1885217312010617, 'Total loss': 0.1885217312010617}
2023-01-04 04:31:46,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:46,316 INFO:     Epoch: 75
2023-01-04 04:31:47,905 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3609881887833277, 'Total loss': 0.3609881887833277} | train loss {'Reaction outcome loss': 0.18928148795847213, 'Total loss': 0.18928148795847213}
2023-01-04 04:31:47,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:47,906 INFO:     Epoch: 76
2023-01-04 04:31:49,539 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37831436494986215, 'Total loss': 0.37831436494986215} | train loss {'Reaction outcome loss': 0.18842934308714815, 'Total loss': 0.18842934308714815}
2023-01-04 04:31:49,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:49,539 INFO:     Epoch: 77
2023-01-04 04:31:51,132 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3588165273269018, 'Total loss': 0.3588165273269018} | train loss {'Reaction outcome loss': 0.1869285485777829, 'Total loss': 0.1869285485777829}
2023-01-04 04:31:51,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:51,132 INFO:     Epoch: 78
2023-01-04 04:31:52,750 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3706978350877762, 'Total loss': 0.3706978350877762} | train loss {'Reaction outcome loss': 0.1854140316455588, 'Total loss': 0.1854140316455588}
2023-01-04 04:31:52,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:52,751 INFO:     Epoch: 79
2023-01-04 04:31:54,358 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3517804965376854, 'Total loss': 0.3517804965376854} | train loss {'Reaction outcome loss': 0.18584746891625953, 'Total loss': 0.18584746891625953}
2023-01-04 04:31:54,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:54,359 INFO:     Epoch: 80
2023-01-04 04:31:55,940 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36276969412962595, 'Total loss': 0.36276969412962595} | train loss {'Reaction outcome loss': 0.18722294488861244, 'Total loss': 0.18722294488861244}
2023-01-04 04:31:55,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:55,940 INFO:     Epoch: 81
2023-01-04 04:31:57,564 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37392260928948723, 'Total loss': 0.37392260928948723} | train loss {'Reaction outcome loss': 0.1852224307396997, 'Total loss': 0.1852224307396997}
2023-01-04 04:31:57,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:57,564 INFO:     Epoch: 82
2023-01-04 04:31:59,198 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37954694827397667, 'Total loss': 0.37954694827397667} | train loss {'Reaction outcome loss': 0.18255588494994365, 'Total loss': 0.18255588494994365}
2023-01-04 04:31:59,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:31:59,198 INFO:     Epoch: 83
2023-01-04 04:32:00,794 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3828166753053665, 'Total loss': 0.3828166753053665} | train loss {'Reaction outcome loss': 0.1837091535356716, 'Total loss': 0.1837091535356716}
2023-01-04 04:32:00,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:00,795 INFO:     Epoch: 84
2023-01-04 04:32:02,398 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35042108794053395, 'Total loss': 0.35042108794053395} | train loss {'Reaction outcome loss': 0.18184506224085062, 'Total loss': 0.18184506224085062}
2023-01-04 04:32:02,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:02,398 INFO:     Epoch: 85
2023-01-04 04:32:03,994 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37090382327636084, 'Total loss': 0.37090382327636084} | train loss {'Reaction outcome loss': 0.183777622945795, 'Total loss': 0.183777622945795}
2023-01-04 04:32:03,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:03,994 INFO:     Epoch: 86
2023-01-04 04:32:05,591 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3654252310593923, 'Total loss': 0.3654252310593923} | train loss {'Reaction outcome loss': 0.18192434555679451, 'Total loss': 0.18192434555679451}
2023-01-04 04:32:05,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:05,592 INFO:     Epoch: 87
2023-01-04 04:32:07,194 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3672351251045863, 'Total loss': 0.3672351251045863} | train loss {'Reaction outcome loss': 0.18028531269933556, 'Total loss': 0.18028531269933556}
2023-01-04 04:32:07,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:07,194 INFO:     Epoch: 88
2023-01-04 04:32:08,828 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38220944106578825, 'Total loss': 0.38220944106578825} | train loss {'Reaction outcome loss': 0.17912638001816367, 'Total loss': 0.17912638001816367}
2023-01-04 04:32:08,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:08,828 INFO:     Epoch: 89
2023-01-04 04:32:10,430 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4089125216007233, 'Total loss': 0.4089125216007233} | train loss {'Reaction outcome loss': 0.1783282765547076, 'Total loss': 0.1783282765547076}
2023-01-04 04:32:10,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:10,431 INFO:     Epoch: 90
2023-01-04 04:32:12,026 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3700376436114311, 'Total loss': 0.3700376436114311} | train loss {'Reaction outcome loss': 0.17743865716597235, 'Total loss': 0.17743865716597235}
2023-01-04 04:32:12,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:12,027 INFO:     Epoch: 91
2023-01-04 04:32:13,654 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38124081790447234, 'Total loss': 0.38124081790447234} | train loss {'Reaction outcome loss': 0.1732270995134804, 'Total loss': 0.1732270995134804}
2023-01-04 04:32:13,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:13,654 INFO:     Epoch: 92
2023-01-04 04:32:15,279 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39734253386656443, 'Total loss': 0.39734253386656443} | train loss {'Reaction outcome loss': 0.1774900753441055, 'Total loss': 0.1774900753441055}
2023-01-04 04:32:15,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:15,280 INFO:     Epoch: 93
2023-01-04 04:32:16,907 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4003845492998759, 'Total loss': 0.4003845492998759} | train loss {'Reaction outcome loss': 0.17776797763626714, 'Total loss': 0.17776797763626714}
2023-01-04 04:32:16,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:16,908 INFO:     Epoch: 94
2023-01-04 04:32:18,514 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38145112097263334, 'Total loss': 0.38145112097263334} | train loss {'Reaction outcome loss': 0.1732097891317378, 'Total loss': 0.1732097891317378}
2023-01-04 04:32:18,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:18,515 INFO:     Epoch: 95
2023-01-04 04:32:20,120 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37499965329964957, 'Total loss': 0.37499965329964957} | train loss {'Reaction outcome loss': 0.17432647649642577, 'Total loss': 0.17432647649642577}
2023-01-04 04:32:20,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:20,121 INFO:     Epoch: 96
2023-01-04 04:32:21,715 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37458766599496207, 'Total loss': 0.37458766599496207} | train loss {'Reaction outcome loss': 0.17602667343611106, 'Total loss': 0.17602667343611106}
2023-01-04 04:32:21,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:21,715 INFO:     Epoch: 97
2023-01-04 04:32:23,309 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.397285125652949, 'Total loss': 0.397285125652949} | train loss {'Reaction outcome loss': 0.17521066587108997, 'Total loss': 0.17521066587108997}
2023-01-04 04:32:23,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:23,310 INFO:     Epoch: 98
2023-01-04 04:32:24,944 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3758811816573143, 'Total loss': 0.3758811816573143} | train loss {'Reaction outcome loss': 0.172927664801317, 'Total loss': 0.172927664801317}
2023-01-04 04:32:24,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:24,944 INFO:     Epoch: 99
2023-01-04 04:32:26,540 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3688329497973124, 'Total loss': 0.3688329497973124} | train loss {'Reaction outcome loss': 0.17195424553854155, 'Total loss': 0.17195424553854155}
2023-01-04 04:32:26,540 INFO:     Best model found after epoch 57 of 100.
2023-01-04 04:32:26,541 INFO:   Done with stage: TRAINING
2023-01-04 04:32:26,541 INFO:   Starting stage: EVALUATION
2023-01-04 04:32:26,665 INFO:   Done with stage: EVALUATION
2023-01-04 04:32:26,665 INFO:   Leaving out SEQ value Fold_6
2023-01-04 04:32:26,678 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:32:26,678 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:32:27,341 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:32:27,342 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:32:27,411 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:32:27,411 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:32:27,411 INFO:     No hyperparam tuning for this model
2023-01-04 04:32:27,411 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:32:27,411 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:32:27,412 INFO:     None feature selector for col prot
2023-01-04 04:32:27,412 INFO:     None feature selector for col prot
2023-01-04 04:32:27,412 INFO:     None feature selector for col prot
2023-01-04 04:32:27,413 INFO:     None feature selector for col chem
2023-01-04 04:32:27,413 INFO:     None feature selector for col chem
2023-01-04 04:32:27,413 INFO:     None feature selector for col chem
2023-01-04 04:32:27,413 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:32:27,413 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:32:27,414 INFO:     Number of params in model 70141
2023-01-04 04:32:27,418 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:32:27,418 INFO:   Starting stage: TRAINING
2023-01-04 04:32:27,463 INFO:     Val loss before train {'Reaction outcome loss': 0.9079720457394918, 'Total loss': 0.9079720457394918}
2023-01-04 04:32:27,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:27,463 INFO:     Epoch: 0
2023-01-04 04:32:29,095 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5679696202278137, 'Total loss': 0.5679696202278137} | train loss {'Reaction outcome loss': 0.8462556486525691, 'Total loss': 0.8462556486525691}
2023-01-04 04:32:29,096 INFO:     Found new best model at epoch 0
2023-01-04 04:32:29,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:29,096 INFO:     Epoch: 1
2023-01-04 04:32:30,682 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4777382969856262, 'Total loss': 0.4777382969856262} | train loss {'Reaction outcome loss': 0.5777376782054936, 'Total loss': 0.5777376782054936}
2023-01-04 04:32:30,682 INFO:     Found new best model at epoch 1
2023-01-04 04:32:30,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:30,683 INFO:     Epoch: 2
2023-01-04 04:32:32,271 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45256932576497394, 'Total loss': 0.45256932576497394} | train loss {'Reaction outcome loss': 0.5098069515684451, 'Total loss': 0.5098069515684451}
2023-01-04 04:32:32,271 INFO:     Found new best model at epoch 2
2023-01-04 04:32:32,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:32,272 INFO:     Epoch: 3
2023-01-04 04:32:33,868 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42914822498957317, 'Total loss': 0.42914822498957317} | train loss {'Reaction outcome loss': 0.4728567794987441, 'Total loss': 0.4728567794987441}
2023-01-04 04:32:33,868 INFO:     Found new best model at epoch 3
2023-01-04 04:32:33,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:33,869 INFO:     Epoch: 4
2023-01-04 04:32:35,463 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4195341388384501, 'Total loss': 0.4195341388384501} | train loss {'Reaction outcome loss': 0.44943060825447745, 'Total loss': 0.44943060825447745}
2023-01-04 04:32:35,463 INFO:     Found new best model at epoch 4
2023-01-04 04:32:35,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:35,464 INFO:     Epoch: 5
2023-01-04 04:32:37,064 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41474240124225614, 'Total loss': 0.41474240124225614} | train loss {'Reaction outcome loss': 0.4291983473279416, 'Total loss': 0.4291983473279416}
2023-01-04 04:32:37,065 INFO:     Found new best model at epoch 5
2023-01-04 04:32:37,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:37,066 INFO:     Epoch: 6
2023-01-04 04:32:38,683 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.394746998945872, 'Total loss': 0.394746998945872} | train loss {'Reaction outcome loss': 0.41252425651903185, 'Total loss': 0.41252425651903185}
2023-01-04 04:32:38,683 INFO:     Found new best model at epoch 6
2023-01-04 04:32:38,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:38,684 INFO:     Epoch: 7
2023-01-04 04:32:40,272 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38410252928733823, 'Total loss': 0.38410252928733823} | train loss {'Reaction outcome loss': 0.39996373556581216, 'Total loss': 0.39996373556581216}
2023-01-04 04:32:40,272 INFO:     Found new best model at epoch 7
2023-01-04 04:32:40,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:40,273 INFO:     Epoch: 8
2023-01-04 04:32:41,864 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37982576886812847, 'Total loss': 0.37982576886812847} | train loss {'Reaction outcome loss': 0.38933934959909117, 'Total loss': 0.38933934959909117}
2023-01-04 04:32:41,865 INFO:     Found new best model at epoch 8
2023-01-04 04:32:41,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:41,865 INFO:     Epoch: 9
2023-01-04 04:32:43,462 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37878695627053577, 'Total loss': 0.37878695627053577} | train loss {'Reaction outcome loss': 0.38126635626765365, 'Total loss': 0.38126635626765365}
2023-01-04 04:32:43,463 INFO:     Found new best model at epoch 9
2023-01-04 04:32:43,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:43,464 INFO:     Epoch: 10
2023-01-04 04:32:45,089 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3693012903134028, 'Total loss': 0.3693012903134028} | train loss {'Reaction outcome loss': 0.3715298860350671, 'Total loss': 0.3715298860350671}
2023-01-04 04:32:45,089 INFO:     Found new best model at epoch 10
2023-01-04 04:32:45,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:45,090 INFO:     Epoch: 11
2023-01-04 04:32:46,706 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3545260007182757, 'Total loss': 0.3545260007182757} | train loss {'Reaction outcome loss': 0.3641662154924999, 'Total loss': 0.3641662154924999}
2023-01-04 04:32:46,706 INFO:     Found new best model at epoch 11
2023-01-04 04:32:46,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:46,707 INFO:     Epoch: 12
2023-01-04 04:32:48,299 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3649130016565323, 'Total loss': 0.3649130016565323} | train loss {'Reaction outcome loss': 0.3577374743586843, 'Total loss': 0.3577374743586843}
2023-01-04 04:32:48,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:48,300 INFO:     Epoch: 13
2023-01-04 04:32:49,898 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35687798659006753, 'Total loss': 0.35687798659006753} | train loss {'Reaction outcome loss': 0.3470118488000188, 'Total loss': 0.3470118488000188}
2023-01-04 04:32:49,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:49,898 INFO:     Epoch: 14
2023-01-04 04:32:51,508 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3492201934258143, 'Total loss': 0.3492201934258143} | train loss {'Reaction outcome loss': 0.3403840098355221, 'Total loss': 0.3403840098355221}
2023-01-04 04:32:51,508 INFO:     Found new best model at epoch 14
2023-01-04 04:32:51,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:51,509 INFO:     Epoch: 15
2023-01-04 04:32:53,118 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3602551698684692, 'Total loss': 0.3602551698684692} | train loss {'Reaction outcome loss': 0.3336243707995983, 'Total loss': 0.3336243707995983}
2023-01-04 04:32:53,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:53,119 INFO:     Epoch: 16
2023-01-04 04:32:54,722 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3612247983614604, 'Total loss': 0.3612247983614604} | train loss {'Reaction outcome loss': 0.328699695477632, 'Total loss': 0.328699695477632}
2023-01-04 04:32:54,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:54,722 INFO:     Epoch: 17
2023-01-04 04:32:56,346 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.36056904097398124, 'Total loss': 0.36056904097398124} | train loss {'Reaction outcome loss': 0.3192152760734627, 'Total loss': 0.3192152760734627}
2023-01-04 04:32:56,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:56,347 INFO:     Epoch: 18
2023-01-04 04:32:57,965 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.34275646408398946, 'Total loss': 0.34275646408398946} | train loss {'Reaction outcome loss': 0.3190186187248368, 'Total loss': 0.3190186187248368}
2023-01-04 04:32:57,965 INFO:     Found new best model at epoch 18
2023-01-04 04:32:57,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:57,966 INFO:     Epoch: 19
2023-01-04 04:32:59,569 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3441284835338593, 'Total loss': 0.3441284835338593} | train loss {'Reaction outcome loss': 0.3101687737965842, 'Total loss': 0.3101687737965842}
2023-01-04 04:32:59,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:32:59,569 INFO:     Epoch: 20
2023-01-04 04:33:01,184 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34861590365568795, 'Total loss': 0.34861590365568795} | train loss {'Reaction outcome loss': 0.307899016685219, 'Total loss': 0.307899016685219}
2023-01-04 04:33:01,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:01,184 INFO:     Epoch: 21
2023-01-04 04:33:02,796 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.34412521322568257, 'Total loss': 0.34412521322568257} | train loss {'Reaction outcome loss': 0.30261926761818275, 'Total loss': 0.30261926761818275}
2023-01-04 04:33:02,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:02,796 INFO:     Epoch: 22
2023-01-04 04:33:04,423 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3423045963048935, 'Total loss': 0.3423045963048935} | train loss {'Reaction outcome loss': 0.2975924051087686, 'Total loss': 0.2975924051087686}
2023-01-04 04:33:04,424 INFO:     Found new best model at epoch 22
2023-01-04 04:33:04,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:04,424 INFO:     Epoch: 23
2023-01-04 04:33:06,018 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3353632003068924, 'Total loss': 0.3353632003068924} | train loss {'Reaction outcome loss': 0.2932814323084449, 'Total loss': 0.2932814323084449}
2023-01-04 04:33:06,019 INFO:     Found new best model at epoch 23
2023-01-04 04:33:06,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:06,019 INFO:     Epoch: 24
2023-01-04 04:33:07,640 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.34779207507769266, 'Total loss': 0.34779207507769266} | train loss {'Reaction outcome loss': 0.28913915972309423, 'Total loss': 0.28913915972309423}
2023-01-04 04:33:07,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:07,640 INFO:     Epoch: 25
2023-01-04 04:33:09,264 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3536838799715042, 'Total loss': 0.3536838799715042} | train loss {'Reaction outcome loss': 0.28477773992916305, 'Total loss': 0.28477773992916305}
2023-01-04 04:33:09,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:09,265 INFO:     Epoch: 26
2023-01-04 04:33:10,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3534641812245051, 'Total loss': 0.3534641812245051} | train loss {'Reaction outcome loss': 0.280126087125458, 'Total loss': 0.280126087125458}
2023-01-04 04:33:10,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:10,898 INFO:     Epoch: 27
2023-01-04 04:33:12,517 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3328768665591876, 'Total loss': 0.3328768665591876} | train loss {'Reaction outcome loss': 0.27902123111464916, 'Total loss': 0.27902123111464916}
2023-01-04 04:33:12,518 INFO:     Found new best model at epoch 27
2023-01-04 04:33:12,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:12,519 INFO:     Epoch: 28
2023-01-04 04:33:14,120 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3302146444718043, 'Total loss': 0.3302146444718043} | train loss {'Reaction outcome loss': 0.27506776480844736, 'Total loss': 0.27506776480844736}
2023-01-04 04:33:14,120 INFO:     Found new best model at epoch 28
2023-01-04 04:33:14,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:14,121 INFO:     Epoch: 29
2023-01-04 04:33:15,719 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.32748038371404015, 'Total loss': 0.32748038371404015} | train loss {'Reaction outcome loss': 0.27196540484467135, 'Total loss': 0.27196540484467135}
2023-01-04 04:33:15,719 INFO:     Found new best model at epoch 29
2023-01-04 04:33:15,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:15,720 INFO:     Epoch: 30
2023-01-04 04:33:17,319 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.32684633980194727, 'Total loss': 0.32684633980194727} | train loss {'Reaction outcome loss': 0.2668198745442211, 'Total loss': 0.2668198745442211}
2023-01-04 04:33:17,320 INFO:     Found new best model at epoch 30
2023-01-04 04:33:17,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:17,321 INFO:     Epoch: 31
2023-01-04 04:33:18,917 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.32380242546399435, 'Total loss': 0.32380242546399435} | train loss {'Reaction outcome loss': 0.2648703193406336, 'Total loss': 0.2648703193406336}
2023-01-04 04:33:18,918 INFO:     Found new best model at epoch 31
2023-01-04 04:33:18,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:18,919 INFO:     Epoch: 32
2023-01-04 04:33:20,526 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.33918538292249045, 'Total loss': 0.33918538292249045} | train loss {'Reaction outcome loss': 0.26359147053978504, 'Total loss': 0.26359147053978504}
2023-01-04 04:33:20,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:20,527 INFO:     Epoch: 33
2023-01-04 04:33:22,143 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.32680179476737975, 'Total loss': 0.32680179476737975} | train loss {'Reaction outcome loss': 0.2590145160467616, 'Total loss': 0.2590145160467616}
2023-01-04 04:33:22,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:22,143 INFO:     Epoch: 34
2023-01-04 04:33:23,732 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3212301025787989, 'Total loss': 0.3212301025787989} | train loss {'Reaction outcome loss': 0.25602681702170993, 'Total loss': 0.25602681702170993}
2023-01-04 04:33:23,733 INFO:     Found new best model at epoch 34
2023-01-04 04:33:23,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:23,733 INFO:     Epoch: 35
2023-01-04 04:33:25,330 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3406849056482315, 'Total loss': 0.3406849056482315} | train loss {'Reaction outcome loss': 0.25408877425621995, 'Total loss': 0.25408877425621995}
2023-01-04 04:33:25,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:25,330 INFO:     Epoch: 36
2023-01-04 04:33:26,946 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3127228337029616, 'Total loss': 0.3127228337029616} | train loss {'Reaction outcome loss': 0.2532923699823958, 'Total loss': 0.2532923699823958}
2023-01-04 04:33:26,946 INFO:     Found new best model at epoch 36
2023-01-04 04:33:26,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:26,947 INFO:     Epoch: 37
2023-01-04 04:33:28,572 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.33082138498624164, 'Total loss': 0.33082138498624164} | train loss {'Reaction outcome loss': 0.25112306898197545, 'Total loss': 0.25112306898197545}
2023-01-04 04:33:28,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:28,572 INFO:     Epoch: 38
2023-01-04 04:33:30,194 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3281831572453181, 'Total loss': 0.3281831572453181} | train loss {'Reaction outcome loss': 0.2438054787337995, 'Total loss': 0.2438054787337995}
2023-01-04 04:33:30,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:30,195 INFO:     Epoch: 39
2023-01-04 04:33:31,825 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.32266534169514977, 'Total loss': 0.32266534169514977} | train loss {'Reaction outcome loss': 0.24340973161026458, 'Total loss': 0.24340973161026458}
2023-01-04 04:33:31,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:31,826 INFO:     Epoch: 40
2023-01-04 04:33:33,416 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35939554969469706, 'Total loss': 0.35939554969469706} | train loss {'Reaction outcome loss': 0.24171225210174327, 'Total loss': 0.24171225210174327}
2023-01-04 04:33:33,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:33,416 INFO:     Epoch: 41
2023-01-04 04:33:35,006 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.33539989292621614, 'Total loss': 0.33539989292621614} | train loss {'Reaction outcome loss': 0.24118266327286456, 'Total loss': 0.24118266327286456}
2023-01-04 04:33:35,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:35,006 INFO:     Epoch: 42
2023-01-04 04:33:36,614 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3213231484095255, 'Total loss': 0.3213231484095255} | train loss {'Reaction outcome loss': 0.24148979387666344, 'Total loss': 0.24148979387666344}
2023-01-04 04:33:36,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:36,614 INFO:     Epoch: 43
2023-01-04 04:33:38,231 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.34771895557641985, 'Total loss': 0.34771895557641985} | train loss {'Reaction outcome loss': 0.24033556103921538, 'Total loss': 0.24033556103921538}
2023-01-04 04:33:38,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:38,231 INFO:     Epoch: 44
2023-01-04 04:33:39,838 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3323569764693578, 'Total loss': 0.3323569764693578} | train loss {'Reaction outcome loss': 0.23176897149062328, 'Total loss': 0.23176897149062328}
2023-01-04 04:33:39,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:39,839 INFO:     Epoch: 45
2023-01-04 04:33:41,435 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.31815225730339686, 'Total loss': 0.31815225730339686} | train loss {'Reaction outcome loss': 0.23253420357077992, 'Total loss': 0.23253420357077992}
2023-01-04 04:33:41,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:41,436 INFO:     Epoch: 46
2023-01-04 04:33:43,062 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.32346868216991426, 'Total loss': 0.32346868216991426} | train loss {'Reaction outcome loss': 0.23110593137220356, 'Total loss': 0.23110593137220356}
2023-01-04 04:33:43,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:43,063 INFO:     Epoch: 47
2023-01-04 04:33:44,652 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.33468330403168994, 'Total loss': 0.33468330403168994} | train loss {'Reaction outcome loss': 0.22670519880493195, 'Total loss': 0.22670519880493195}
2023-01-04 04:33:44,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:44,652 INFO:     Epoch: 48
2023-01-04 04:33:46,282 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.34565143336852394, 'Total loss': 0.34565143336852394} | train loss {'Reaction outcome loss': 0.22491863503083856, 'Total loss': 0.22491863503083856}
2023-01-04 04:33:46,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:46,282 INFO:     Epoch: 49
2023-01-04 04:33:47,911 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3327691222230593, 'Total loss': 0.3327691222230593} | train loss {'Reaction outcome loss': 0.2239691501597635, 'Total loss': 0.2239691501597635}
2023-01-04 04:33:47,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:47,911 INFO:     Epoch: 50
2023-01-04 04:33:49,522 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3296811687449614, 'Total loss': 0.3296811687449614} | train loss {'Reaction outcome loss': 0.22268895213139187, 'Total loss': 0.22268895213139187}
2023-01-04 04:33:49,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:49,523 INFO:     Epoch: 51
2023-01-04 04:33:51,109 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3342158009608587, 'Total loss': 0.3342158009608587} | train loss {'Reaction outcome loss': 0.22252831804408063, 'Total loss': 0.22252831804408063}
2023-01-04 04:33:51,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:51,109 INFO:     Epoch: 52
2023-01-04 04:33:52,701 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3443414067228635, 'Total loss': 0.3443414067228635} | train loss {'Reaction outcome loss': 0.21916892082306022, 'Total loss': 0.21916892082306022}
2023-01-04 04:33:52,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:52,701 INFO:     Epoch: 53
2023-01-04 04:33:54,336 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3520659824212392, 'Total loss': 0.3520659824212392} | train loss {'Reaction outcome loss': 0.2178833000294676, 'Total loss': 0.2178833000294676}
2023-01-04 04:33:54,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:54,336 INFO:     Epoch: 54
2023-01-04 04:33:55,937 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.34509514570236205, 'Total loss': 0.34509514570236205} | train loss {'Reaction outcome loss': 0.21902925570223092, 'Total loss': 0.21902925570223092}
2023-01-04 04:33:55,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:55,938 INFO:     Epoch: 55
2023-01-04 04:33:57,531 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.34687757889429727, 'Total loss': 0.34687757889429727} | train loss {'Reaction outcome loss': 0.2169304850514615, 'Total loss': 0.2169304850514615}
2023-01-04 04:33:57,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:57,532 INFO:     Epoch: 56
2023-01-04 04:33:59,129 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.343286835650603, 'Total loss': 0.343286835650603} | train loss {'Reaction outcome loss': 0.21495766714484252, 'Total loss': 0.21495766714484252}
2023-01-04 04:33:59,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:33:59,129 INFO:     Epoch: 57
2023-01-04 04:34:00,730 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3398842866222064, 'Total loss': 0.3398842866222064} | train loss {'Reaction outcome loss': 0.21174160259295027, 'Total loss': 0.21174160259295027}
2023-01-04 04:34:00,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:00,730 INFO:     Epoch: 58
2023-01-04 04:34:02,319 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3403484582901001, 'Total loss': 0.3403484582901001} | train loss {'Reaction outcome loss': 0.211277020832907, 'Total loss': 0.211277020832907}
2023-01-04 04:34:02,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:02,320 INFO:     Epoch: 59
2023-01-04 04:34:03,933 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3338418463865916, 'Total loss': 0.3338418463865916} | train loss {'Reaction outcome loss': 0.2084745858604297, 'Total loss': 0.2084745858604297}
2023-01-04 04:34:03,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:03,933 INFO:     Epoch: 60
2023-01-04 04:34:05,548 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.33704793552557627, 'Total loss': 0.33704793552557627} | train loss {'Reaction outcome loss': 0.20787991416583423, 'Total loss': 0.20787991416583423}
2023-01-04 04:34:05,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:05,548 INFO:     Epoch: 61
2023-01-04 04:34:07,174 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.34070900082588196, 'Total loss': 0.34070900082588196} | train loss {'Reaction outcome loss': 0.20577940312533602, 'Total loss': 0.20577940312533602}
2023-01-04 04:34:07,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:07,174 INFO:     Epoch: 62
2023-01-04 04:34:08,788 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3340429609020551, 'Total loss': 0.3340429609020551} | train loss {'Reaction outcome loss': 0.20490960351826912, 'Total loss': 0.20490960351826912}
2023-01-04 04:34:08,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:08,788 INFO:     Epoch: 63
2023-01-04 04:34:10,383 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.33870302538077035, 'Total loss': 0.33870302538077035} | train loss {'Reaction outcome loss': 0.20484934345102912, 'Total loss': 0.20484934345102912}
2023-01-04 04:34:10,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:10,383 INFO:     Epoch: 64
2023-01-04 04:34:11,995 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3404551804065704, 'Total loss': 0.3404551804065704} | train loss {'Reaction outcome loss': 0.20377088266858556, 'Total loss': 0.20377088266858556}
2023-01-04 04:34:11,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:11,995 INFO:     Epoch: 65
2023-01-04 04:34:13,630 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3333586941162745, 'Total loss': 0.3333586941162745} | train loss {'Reaction outcome loss': 0.20364858661963192, 'Total loss': 0.20364858661963192}
2023-01-04 04:34:13,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:13,631 INFO:     Epoch: 66
2023-01-04 04:34:15,228 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35868723889191945, 'Total loss': 0.35868723889191945} | train loss {'Reaction outcome loss': 0.20013462475060556, 'Total loss': 0.20013462475060556}
2023-01-04 04:34:15,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:15,228 INFO:     Epoch: 67
2023-01-04 04:34:16,861 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3303650210301081, 'Total loss': 0.3303650210301081} | train loss {'Reaction outcome loss': 0.19935424214343303, 'Total loss': 0.19935424214343303}
2023-01-04 04:34:16,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:16,861 INFO:     Epoch: 68
2023-01-04 04:34:18,449 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35186757942040764, 'Total loss': 0.35186757942040764} | train loss {'Reaction outcome loss': 0.19748676131186932, 'Total loss': 0.19748676131186932}
2023-01-04 04:34:18,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:18,449 INFO:     Epoch: 69
2023-01-04 04:34:20,037 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3476279397805532, 'Total loss': 0.3476279397805532} | train loss {'Reaction outcome loss': 0.1985396016456375, 'Total loss': 0.1985396016456375}
2023-01-04 04:34:20,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:20,038 INFO:     Epoch: 70
2023-01-04 04:34:21,640 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3512582908074061, 'Total loss': 0.3512582908074061} | train loss {'Reaction outcome loss': 0.19419341909594914, 'Total loss': 0.19419341909594914}
2023-01-04 04:34:21,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:21,640 INFO:     Epoch: 71
2023-01-04 04:34:23,245 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3617006947596868, 'Total loss': 0.3617006947596868} | train loss {'Reaction outcome loss': 0.19459313538181008, 'Total loss': 0.19459313538181008}
2023-01-04 04:34:23,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:23,245 INFO:     Epoch: 72
2023-01-04 04:34:24,849 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3579583133260409, 'Total loss': 0.3579583133260409} | train loss {'Reaction outcome loss': 0.1910156385858782, 'Total loss': 0.1910156385858782}
2023-01-04 04:34:24,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:24,849 INFO:     Epoch: 73
2023-01-04 04:34:26,445 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36752837598323823, 'Total loss': 0.36752837598323823} | train loss {'Reaction outcome loss': 0.1923270062795615, 'Total loss': 0.1923270062795615}
2023-01-04 04:34:26,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:26,445 INFO:     Epoch: 74
2023-01-04 04:34:28,050 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36715419789155324, 'Total loss': 0.36715419789155324} | train loss {'Reaction outcome loss': 0.19074876919146694, 'Total loss': 0.19074876919146694}
2023-01-04 04:34:28,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:28,051 INFO:     Epoch: 75
2023-01-04 04:34:29,684 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35093268553415935, 'Total loss': 0.35093268553415935} | train loss {'Reaction outcome loss': 0.1919844810941697, 'Total loss': 0.1919844810941697}
2023-01-04 04:34:29,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:29,684 INFO:     Epoch: 76
2023-01-04 04:34:31,294 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35147143254677454, 'Total loss': 0.35147143254677454} | train loss {'Reaction outcome loss': 0.19236256663657267, 'Total loss': 0.19236256663657267}
2023-01-04 04:34:31,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:31,294 INFO:     Epoch: 77
2023-01-04 04:34:32,928 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3603094597657522, 'Total loss': 0.3603094597657522} | train loss {'Reaction outcome loss': 0.1885552684968129, 'Total loss': 0.1885552684968129}
2023-01-04 04:34:32,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:32,929 INFO:     Epoch: 78
2023-01-04 04:34:34,557 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35436685184637706, 'Total loss': 0.35436685184637706} | train loss {'Reaction outcome loss': 0.18877742797243896, 'Total loss': 0.18877742797243896}
2023-01-04 04:34:34,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:34,557 INFO:     Epoch: 79
2023-01-04 04:34:35,897 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3514076627790928, 'Total loss': 0.3514076627790928} | train loss {'Reaction outcome loss': 0.18573136502601179, 'Total loss': 0.18573136502601179}
2023-01-04 04:34:35,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:35,897 INFO:     Epoch: 80
2023-01-04 04:34:36,986 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37173865934213, 'Total loss': 0.37173865934213} | train loss {'Reaction outcome loss': 0.18650639172818256, 'Total loss': 0.18650639172818256}
2023-01-04 04:34:36,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:36,986 INFO:     Epoch: 81
2023-01-04 04:34:38,052 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3641025801499685, 'Total loss': 0.3641025801499685} | train loss {'Reaction outcome loss': 0.1849042594244549, 'Total loss': 0.1849042594244549}
2023-01-04 04:34:38,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:38,052 INFO:     Epoch: 82
2023-01-04 04:34:39,125 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36524742444356284, 'Total loss': 0.36524742444356284} | train loss {'Reaction outcome loss': 0.18478243274863015, 'Total loss': 0.18478243274863015}
2023-01-04 04:34:39,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:39,125 INFO:     Epoch: 83
2023-01-04 04:34:40,347 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.373832905292511, 'Total loss': 0.373832905292511} | train loss {'Reaction outcome loss': 0.1832428484321286, 'Total loss': 0.1832428484321286}
2023-01-04 04:34:40,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:40,347 INFO:     Epoch: 84
2023-01-04 04:34:41,938 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3877018908659617, 'Total loss': 0.3877018908659617} | train loss {'Reaction outcome loss': 0.181124531122644, 'Total loss': 0.181124531122644}
2023-01-04 04:34:41,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:41,938 INFO:     Epoch: 85
2023-01-04 04:34:43,569 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.36900700132052106, 'Total loss': 0.36900700132052106} | train loss {'Reaction outcome loss': 0.18210121056582737, 'Total loss': 0.18210121056582737}
2023-01-04 04:34:43,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:43,569 INFO:     Epoch: 86
2023-01-04 04:34:45,160 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3641394863526026, 'Total loss': 0.3641394863526026} | train loss {'Reaction outcome loss': 0.1796219501012284, 'Total loss': 0.1796219501012284}
2023-01-04 04:34:45,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:45,161 INFO:     Epoch: 87
2023-01-04 04:34:46,771 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37920109132925667, 'Total loss': 0.37920109132925667} | train loss {'Reaction outcome loss': 0.17969455452978828, 'Total loss': 0.17969455452978828}
2023-01-04 04:34:46,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:46,771 INFO:     Epoch: 88
2023-01-04 04:34:48,374 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37674551606178286, 'Total loss': 0.37674551606178286} | train loss {'Reaction outcome loss': 0.17914587923658454, 'Total loss': 0.17914587923658454}
2023-01-04 04:34:48,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:48,375 INFO:     Epoch: 89
2023-01-04 04:34:49,984 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37970289861162504, 'Total loss': 0.37970289861162504} | train loss {'Reaction outcome loss': 0.17941062658056886, 'Total loss': 0.17941062658056886}
2023-01-04 04:34:49,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:49,985 INFO:     Epoch: 90
2023-01-04 04:34:51,611 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3710468113422394, 'Total loss': 0.3710468113422394} | train loss {'Reaction outcome loss': 0.18031765460053506, 'Total loss': 0.18031765460053506}
2023-01-04 04:34:51,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:51,612 INFO:     Epoch: 91
2023-01-04 04:34:53,199 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3684439887603124, 'Total loss': 0.3684439887603124} | train loss {'Reaction outcome loss': 0.17949316807978852, 'Total loss': 0.17949316807978852}
2023-01-04 04:34:53,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:53,200 INFO:     Epoch: 92
2023-01-04 04:34:54,832 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3731567750374476, 'Total loss': 0.3731567750374476} | train loss {'Reaction outcome loss': 0.1776562203864974, 'Total loss': 0.1776562203864974}
2023-01-04 04:34:54,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:54,832 INFO:     Epoch: 93
2023-01-04 04:34:56,452 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35888763070106505, 'Total loss': 0.35888763070106505} | train loss {'Reaction outcome loss': 0.17485336430828063, 'Total loss': 0.17485336430828063}
2023-01-04 04:34:56,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:56,452 INFO:     Epoch: 94
2023-01-04 04:34:58,067 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3592064107457797, 'Total loss': 0.3592064107457797} | train loss {'Reaction outcome loss': 0.17609876121935647, 'Total loss': 0.17609876121935647}
2023-01-04 04:34:58,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:58,067 INFO:     Epoch: 95
2023-01-04 04:34:59,700 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3710722555716833, 'Total loss': 0.3710722555716833} | train loss {'Reaction outcome loss': 0.17334813814247127, 'Total loss': 0.17334813814247127}
2023-01-04 04:34:59,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:34:59,700 INFO:     Epoch: 96
2023-01-04 04:35:01,334 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3691166669130325, 'Total loss': 0.3691166669130325} | train loss {'Reaction outcome loss': 0.17643285387394014, 'Total loss': 0.17643285387394014}
2023-01-04 04:35:01,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:01,335 INFO:     Epoch: 97
2023-01-04 04:35:02,961 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3684309353431066, 'Total loss': 0.3684309353431066} | train loss {'Reaction outcome loss': 0.17318625627791623, 'Total loss': 0.17318625627791623}
2023-01-04 04:35:02,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:02,961 INFO:     Epoch: 98
2023-01-04 04:35:04,561 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3636433539291223, 'Total loss': 0.3636433539291223} | train loss {'Reaction outcome loss': 0.17408694041765124, 'Total loss': 0.17408694041765124}
2023-01-04 04:35:04,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:04,561 INFO:     Epoch: 99
2023-01-04 04:35:06,156 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3892742723226547, 'Total loss': 0.3892742723226547} | train loss {'Reaction outcome loss': 0.17302282884152143, 'Total loss': 0.17302282884152143}
2023-01-04 04:35:06,156 INFO:     Best model found after epoch 37 of 100.
2023-01-04 04:35:06,156 INFO:   Done with stage: TRAINING
2023-01-04 04:35:06,156 INFO:   Starting stage: EVALUATION
2023-01-04 04:35:06,280 INFO:   Done with stage: EVALUATION
2023-01-04 04:35:06,280 INFO:   Leaving out SEQ value Fold_7
2023-01-04 04:35:06,293 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:35:06,293 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:35:06,952 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:35:06,952 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:35:07,022 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:35:07,022 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:35:07,022 INFO:     No hyperparam tuning for this model
2023-01-04 04:35:07,022 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:35:07,022 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:35:07,023 INFO:     None feature selector for col prot
2023-01-04 04:35:07,023 INFO:     None feature selector for col prot
2023-01-04 04:35:07,023 INFO:     None feature selector for col prot
2023-01-04 04:35:07,024 INFO:     None feature selector for col chem
2023-01-04 04:35:07,024 INFO:     None feature selector for col chem
2023-01-04 04:35:07,024 INFO:     None feature selector for col chem
2023-01-04 04:35:07,024 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:35:07,024 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:35:07,025 INFO:     Number of params in model 70141
2023-01-04 04:35:07,029 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:35:07,029 INFO:   Starting stage: TRAINING
2023-01-04 04:35:07,073 INFO:     Val loss before train {'Reaction outcome loss': 0.9821993470191955, 'Total loss': 0.9821993470191955}
2023-01-04 04:35:07,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:07,073 INFO:     Epoch: 0
2023-01-04 04:35:08,665 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.648867130279541, 'Total loss': 0.648867130279541} | train loss {'Reaction outcome loss': 0.8528318675201292, 'Total loss': 0.8528318675201292}
2023-01-04 04:35:08,665 INFO:     Found new best model at epoch 0
2023-01-04 04:35:08,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:08,666 INFO:     Epoch: 1
2023-01-04 04:35:10,278 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5187685867150624, 'Total loss': 0.5187685867150624} | train loss {'Reaction outcome loss': 0.610409073020577, 'Total loss': 0.610409073020577}
2023-01-04 04:35:10,278 INFO:     Found new best model at epoch 1
2023-01-04 04:35:10,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:10,279 INFO:     Epoch: 2
2023-01-04 04:35:11,873 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48911327322324116, 'Total loss': 0.48911327322324116} | train loss {'Reaction outcome loss': 0.5240438777939938, 'Total loss': 0.5240438777939938}
2023-01-04 04:35:11,874 INFO:     Found new best model at epoch 2
2023-01-04 04:35:11,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:11,875 INFO:     Epoch: 3
2023-01-04 04:35:13,479 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45834493935108184, 'Total loss': 0.45834493935108184} | train loss {'Reaction outcome loss': 0.48320973817837365, 'Total loss': 0.48320973817837365}
2023-01-04 04:35:13,479 INFO:     Found new best model at epoch 3
2023-01-04 04:35:13,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:13,480 INFO:     Epoch: 4
2023-01-04 04:35:15,131 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4638406276702881, 'Total loss': 0.4638406276702881} | train loss {'Reaction outcome loss': 0.4535978317583511, 'Total loss': 0.4535978317583511}
2023-01-04 04:35:15,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:15,131 INFO:     Epoch: 5
2023-01-04 04:35:16,732 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43768035372098285, 'Total loss': 0.43768035372098285} | train loss {'Reaction outcome loss': 0.43453738771190714, 'Total loss': 0.43453738771190714}
2023-01-04 04:35:16,732 INFO:     Found new best model at epoch 5
2023-01-04 04:35:16,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:16,733 INFO:     Epoch: 6
2023-01-04 04:35:18,335 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45311649243036906, 'Total loss': 0.45311649243036906} | train loss {'Reaction outcome loss': 0.4184752443422049, 'Total loss': 0.4184752443422049}
2023-01-04 04:35:18,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:18,335 INFO:     Epoch: 7
2023-01-04 04:35:19,942 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4333882490793864, 'Total loss': 0.4333882490793864} | train loss {'Reaction outcome loss': 0.40316310931091276, 'Total loss': 0.40316310931091276}
2023-01-04 04:35:19,943 INFO:     Found new best model at epoch 7
2023-01-04 04:35:19,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:19,944 INFO:     Epoch: 8
2023-01-04 04:35:21,546 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4244185050328573, 'Total loss': 0.4244185050328573} | train loss {'Reaction outcome loss': 0.3940738863463006, 'Total loss': 0.3940738863463006}
2023-01-04 04:35:21,546 INFO:     Found new best model at epoch 8
2023-01-04 04:35:21,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:21,547 INFO:     Epoch: 9
2023-01-04 04:35:23,149 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43821557561556496, 'Total loss': 0.43821557561556496} | train loss {'Reaction outcome loss': 0.38108205886739255, 'Total loss': 0.38108205886739255}
2023-01-04 04:35:23,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:23,150 INFO:     Epoch: 10
2023-01-04 04:35:24,759 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44522273937861123, 'Total loss': 0.44522273937861123} | train loss {'Reaction outcome loss': 0.37099357944533284, 'Total loss': 0.37099357944533284}
2023-01-04 04:35:24,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:24,759 INFO:     Epoch: 11
2023-01-04 04:35:26,368 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4292833069960276, 'Total loss': 0.4292833069960276} | train loss {'Reaction outcome loss': 0.36307079202431636, 'Total loss': 0.36307079202431636}
2023-01-04 04:35:26,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:26,369 INFO:     Epoch: 12
2023-01-04 04:35:27,969 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4298117806514104, 'Total loss': 0.4298117806514104} | train loss {'Reaction outcome loss': 0.3567779703260759, 'Total loss': 0.3567779703260759}
2023-01-04 04:35:27,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:27,970 INFO:     Epoch: 13
2023-01-04 04:35:29,556 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42175463438034055, 'Total loss': 0.42175463438034055} | train loss {'Reaction outcome loss': 0.3474358775609237, 'Total loss': 0.3474358775609237}
2023-01-04 04:35:29,556 INFO:     Found new best model at epoch 13
2023-01-04 04:35:29,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:29,557 INFO:     Epoch: 14
2023-01-04 04:35:31,152 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4353214085102081, 'Total loss': 0.4353214085102081} | train loss {'Reaction outcome loss': 0.3393339449371672, 'Total loss': 0.3393339449371672}
2023-01-04 04:35:31,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:31,152 INFO:     Epoch: 15
2023-01-04 04:35:32,784 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41643006503582003, 'Total loss': 0.41643006503582003} | train loss {'Reaction outcome loss': 0.3313122074849339, 'Total loss': 0.3313122074849339}
2023-01-04 04:35:32,784 INFO:     Found new best model at epoch 15
2023-01-04 04:35:32,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:32,785 INFO:     Epoch: 16
2023-01-04 04:35:34,370 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42523909707864127, 'Total loss': 0.42523909707864127} | train loss {'Reaction outcome loss': 0.32915738795208155, 'Total loss': 0.32915738795208155}
2023-01-04 04:35:34,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:34,370 INFO:     Epoch: 17
2023-01-04 04:35:35,972 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43204190135002135, 'Total loss': 0.43204190135002135} | train loss {'Reaction outcome loss': 0.31896359759924214, 'Total loss': 0.31896359759924214}
2023-01-04 04:35:35,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:35,972 INFO:     Epoch: 18
2023-01-04 04:35:37,562 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43839388291041054, 'Total loss': 0.43839388291041054} | train loss {'Reaction outcome loss': 0.3140472007195872, 'Total loss': 0.3140472007195872}
2023-01-04 04:35:37,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:37,562 INFO:     Epoch: 19
2023-01-04 04:35:39,165 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4255268037319183, 'Total loss': 0.4255268037319183} | train loss {'Reaction outcome loss': 0.3079440794374108, 'Total loss': 0.3079440794374108}
2023-01-04 04:35:39,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:39,166 INFO:     Epoch: 20
2023-01-04 04:35:40,769 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40118277569611865, 'Total loss': 0.40118277569611865} | train loss {'Reaction outcome loss': 0.3031072118706221, 'Total loss': 0.3031072118706221}
2023-01-04 04:35:40,769 INFO:     Found new best model at epoch 20
2023-01-04 04:35:40,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:40,770 INFO:     Epoch: 21
2023-01-04 04:35:42,368 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.444341234366099, 'Total loss': 0.444341234366099} | train loss {'Reaction outcome loss': 0.2975857112597042, 'Total loss': 0.2975857112597042}
2023-01-04 04:35:42,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:42,368 INFO:     Epoch: 22
2023-01-04 04:35:43,955 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4143516848484675, 'Total loss': 0.4143516848484675} | train loss {'Reaction outcome loss': 0.2925337747223541, 'Total loss': 0.2925337747223541}
2023-01-04 04:35:43,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:43,956 INFO:     Epoch: 23
2023-01-04 04:35:45,585 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42043591241041817, 'Total loss': 0.42043591241041817} | train loss {'Reaction outcome loss': 0.28784663259767884, 'Total loss': 0.28784663259767884}
2023-01-04 04:35:45,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:45,585 INFO:     Epoch: 24
2023-01-04 04:35:47,178 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4287771999835968, 'Total loss': 0.4287771999835968} | train loss {'Reaction outcome loss': 0.28331102223710464, 'Total loss': 0.28331102223710464}
2023-01-04 04:35:47,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:47,178 INFO:     Epoch: 25
2023-01-04 04:35:48,805 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43584402799606325, 'Total loss': 0.43584402799606325} | train loss {'Reaction outcome loss': 0.2784343010305498, 'Total loss': 0.2784343010305498}
2023-01-04 04:35:48,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:48,805 INFO:     Epoch: 26
2023-01-04 04:35:50,436 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.426158614953359, 'Total loss': 0.426158614953359} | train loss {'Reaction outcome loss': 0.2748936926239987, 'Total loss': 0.2748936926239987}
2023-01-04 04:35:50,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:50,437 INFO:     Epoch: 27
2023-01-04 04:35:52,028 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43398653268814086, 'Total loss': 0.43398653268814086} | train loss {'Reaction outcome loss': 0.27264186445395006, 'Total loss': 0.27264186445395006}
2023-01-04 04:35:52,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:52,028 INFO:     Epoch: 28
2023-01-04 04:35:53,618 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.445217689871788, 'Total loss': 0.445217689871788} | train loss {'Reaction outcome loss': 0.2668435069789525, 'Total loss': 0.2668435069789525}
2023-01-04 04:35:53,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:53,619 INFO:     Epoch: 29
2023-01-04 04:35:55,239 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4499387969573339, 'Total loss': 0.4499387969573339} | train loss {'Reaction outcome loss': 0.26484943103273856, 'Total loss': 0.26484943103273856}
2023-01-04 04:35:55,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:55,239 INFO:     Epoch: 30
2023-01-04 04:35:56,861 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43695190946261087, 'Total loss': 0.43695190946261087} | train loss {'Reaction outcome loss': 0.26061297116619586, 'Total loss': 0.26061297116619586}
2023-01-04 04:35:56,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:56,862 INFO:     Epoch: 31
2023-01-04 04:35:58,460 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43843228220939634, 'Total loss': 0.43843228220939634} | train loss {'Reaction outcome loss': 0.2568947127095629, 'Total loss': 0.2568947127095629}
2023-01-04 04:35:58,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:35:58,460 INFO:     Epoch: 32
2023-01-04 04:36:00,092 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4280233760674795, 'Total loss': 0.4280233760674795} | train loss {'Reaction outcome loss': 0.2534890954486945, 'Total loss': 0.2534890954486945}
2023-01-04 04:36:00,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:00,092 INFO:     Epoch: 33
2023-01-04 04:36:01,678 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43131757179896035, 'Total loss': 0.43131757179896035} | train loss {'Reaction outcome loss': 0.25172785056304414, 'Total loss': 0.25172785056304414}
2023-01-04 04:36:01,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:01,678 INFO:     Epoch: 34
2023-01-04 04:36:03,310 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42533817887306213, 'Total loss': 0.42533817887306213} | train loss {'Reaction outcome loss': 0.2467245023818653, 'Total loss': 0.2467245023818653}
2023-01-04 04:36:03,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:03,311 INFO:     Epoch: 35
2023-01-04 04:36:04,900 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4197513610124588, 'Total loss': 0.4197513610124588} | train loss {'Reaction outcome loss': 0.24422613395519205, 'Total loss': 0.24422613395519205}
2023-01-04 04:36:04,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:04,901 INFO:     Epoch: 36
2023-01-04 04:36:06,496 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4348496824502945, 'Total loss': 0.4348496824502945} | train loss {'Reaction outcome loss': 0.2440234665970725, 'Total loss': 0.2440234665970725}
2023-01-04 04:36:06,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:06,496 INFO:     Epoch: 37
2023-01-04 04:36:08,131 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43593710164229077, 'Total loss': 0.43593710164229077} | train loss {'Reaction outcome loss': 0.24132174038284523, 'Total loss': 0.24132174038284523}
2023-01-04 04:36:08,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:08,131 INFO:     Epoch: 38
2023-01-04 04:36:09,707 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42188320060571033, 'Total loss': 0.42188320060571033} | train loss {'Reaction outcome loss': 0.23786036055602322, 'Total loss': 0.23786036055602322}
2023-01-04 04:36:09,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:09,708 INFO:     Epoch: 39
2023-01-04 04:36:11,346 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4337731043497721, 'Total loss': 0.4337731043497721} | train loss {'Reaction outcome loss': 0.23567874834533203, 'Total loss': 0.23567874834533203}
2023-01-04 04:36:11,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:11,346 INFO:     Epoch: 40
2023-01-04 04:36:12,946 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42871673504511515, 'Total loss': 0.42871673504511515} | train loss {'Reaction outcome loss': 0.23411402742408674, 'Total loss': 0.23411402742408674}
2023-01-04 04:36:12,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:12,946 INFO:     Epoch: 41
2023-01-04 04:36:14,524 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4625697761774063, 'Total loss': 0.4625697761774063} | train loss {'Reaction outcome loss': 0.22895989152821392, 'Total loss': 0.22895989152821392}
2023-01-04 04:36:14,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:14,524 INFO:     Epoch: 42
2023-01-04 04:36:16,149 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.490243465701739, 'Total loss': 0.490243465701739} | train loss {'Reaction outcome loss': 0.2275088310295494, 'Total loss': 0.2275088310295494}
2023-01-04 04:36:16,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:16,150 INFO:     Epoch: 43
2023-01-04 04:36:17,738 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4410808285077413, 'Total loss': 0.4410808285077413} | train loss {'Reaction outcome loss': 0.22993032741847882, 'Total loss': 0.22993032741847882}
2023-01-04 04:36:17,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:17,739 INFO:     Epoch: 44
2023-01-04 04:36:19,353 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45238087872664134, 'Total loss': 0.45238087872664134} | train loss {'Reaction outcome loss': 0.22476259308332572, 'Total loss': 0.22476259308332572}
2023-01-04 04:36:19,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:19,353 INFO:     Epoch: 45
2023-01-04 04:36:20,988 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4566075474023819, 'Total loss': 0.4566075474023819} | train loss {'Reaction outcome loss': 0.22259253533792409, 'Total loss': 0.22259253533792409}
2023-01-04 04:36:20,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:20,988 INFO:     Epoch: 46
2023-01-04 04:36:22,600 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4557814210653305, 'Total loss': 0.4557814210653305} | train loss {'Reaction outcome loss': 0.22103832629828676, 'Total loss': 0.22103832629828676}
2023-01-04 04:36:22,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:22,600 INFO:     Epoch: 47
2023-01-04 04:36:24,232 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45498986840248107, 'Total loss': 0.45498986840248107} | train loss {'Reaction outcome loss': 0.21675712488833748, 'Total loss': 0.21675712488833748}
2023-01-04 04:36:24,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:24,232 INFO:     Epoch: 48
2023-01-04 04:36:25,865 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.417918711155653, 'Total loss': 0.417918711155653} | train loss {'Reaction outcome loss': 0.21728560136167152, 'Total loss': 0.21728560136167152}
2023-01-04 04:36:25,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:25,865 INFO:     Epoch: 49
2023-01-04 04:36:27,444 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4189833551645279, 'Total loss': 0.4189833551645279} | train loss {'Reaction outcome loss': 0.2179348145877196, 'Total loss': 0.2179348145877196}
2023-01-04 04:36:27,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:27,444 INFO:     Epoch: 50
2023-01-04 04:36:29,036 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42336918115615846, 'Total loss': 0.42336918115615846} | train loss {'Reaction outcome loss': 0.213310180695909, 'Total loss': 0.213310180695909}
2023-01-04 04:36:29,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:29,037 INFO:     Epoch: 51
2023-01-04 04:36:30,669 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4430703577895959, 'Total loss': 0.4430703577895959} | train loss {'Reaction outcome loss': 0.21268805850714123, 'Total loss': 0.21268805850714123}
2023-01-04 04:36:30,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:30,669 INFO:     Epoch: 52
2023-01-04 04:36:32,244 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4568926533063253, 'Total loss': 0.4568926533063253} | train loss {'Reaction outcome loss': 0.21174010786392627, 'Total loss': 0.21174010786392627}
2023-01-04 04:36:32,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:32,245 INFO:     Epoch: 53
2023-01-04 04:36:33,847 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47062466144561765, 'Total loss': 0.47062466144561765} | train loss {'Reaction outcome loss': 0.20999997366044926, 'Total loss': 0.20999997366044926}
2023-01-04 04:36:33,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:33,847 INFO:     Epoch: 54
2023-01-04 04:36:35,448 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47345634798208874, 'Total loss': 0.47345634798208874} | train loss {'Reaction outcome loss': 0.2083285229704225, 'Total loss': 0.2083285229704225}
2023-01-04 04:36:35,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:35,448 INFO:     Epoch: 55
2023-01-04 04:36:37,029 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4326306243737539, 'Total loss': 0.4326306243737539} | train loss {'Reaction outcome loss': 0.20768332535179082, 'Total loss': 0.20768332535179082}
2023-01-04 04:36:37,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:37,030 INFO:     Epoch: 56
2023-01-04 04:36:38,636 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48951587875684105, 'Total loss': 0.48951587875684105} | train loss {'Reaction outcome loss': 0.20442875789391005, 'Total loss': 0.20442875789391005}
2023-01-04 04:36:38,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:38,637 INFO:     Epoch: 57
2023-01-04 04:36:40,229 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45842712024847665, 'Total loss': 0.45842712024847665} | train loss {'Reaction outcome loss': 0.20260099138701435, 'Total loss': 0.20260099138701435}
2023-01-04 04:36:40,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:40,229 INFO:     Epoch: 58
2023-01-04 04:36:41,854 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4488022228082021, 'Total loss': 0.4488022228082021} | train loss {'Reaction outcome loss': 0.2029699853517196, 'Total loss': 0.2029699853517196}
2023-01-04 04:36:41,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:41,854 INFO:     Epoch: 59
2023-01-04 04:36:43,456 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4536082377036413, 'Total loss': 0.4536082377036413} | train loss {'Reaction outcome loss': 0.19971977121159704, 'Total loss': 0.19971977121159704}
2023-01-04 04:36:43,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:43,456 INFO:     Epoch: 60
2023-01-04 04:36:45,096 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4467592974503835, 'Total loss': 0.4467592974503835} | train loss {'Reaction outcome loss': 0.19948499829975708, 'Total loss': 0.19948499829975708}
2023-01-04 04:36:45,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:45,096 INFO:     Epoch: 61
2023-01-04 04:36:46,672 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.440891832113266, 'Total loss': 0.440891832113266} | train loss {'Reaction outcome loss': 0.19934660991122577, 'Total loss': 0.19934660991122577}
2023-01-04 04:36:46,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:46,672 INFO:     Epoch: 62
2023-01-04 04:36:48,299 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45791940987110136, 'Total loss': 0.45791940987110136} | train loss {'Reaction outcome loss': 0.1966635769818126, 'Total loss': 0.1966635769818126}
2023-01-04 04:36:48,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:48,300 INFO:     Epoch: 63
2023-01-04 04:36:49,897 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4475101391474406, 'Total loss': 0.4475101391474406} | train loss {'Reaction outcome loss': 0.19580518615697695, 'Total loss': 0.19580518615697695}
2023-01-04 04:36:49,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:49,897 INFO:     Epoch: 64
2023-01-04 04:36:51,504 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46999513705571494, 'Total loss': 0.46999513705571494} | train loss {'Reaction outcome loss': 0.19506640513074527, 'Total loss': 0.19506640513074527}
2023-01-04 04:36:51,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:51,505 INFO:     Epoch: 65
2023-01-04 04:36:53,110 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44665067791938784, 'Total loss': 0.44665067791938784} | train loss {'Reaction outcome loss': 0.1938951810694128, 'Total loss': 0.1938951810694128}
2023-01-04 04:36:53,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:53,110 INFO:     Epoch: 66
2023-01-04 04:36:54,698 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45510637362798056, 'Total loss': 0.45510637362798056} | train loss {'Reaction outcome loss': 0.19231802668920062, 'Total loss': 0.19231802668920062}
2023-01-04 04:36:54,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:54,698 INFO:     Epoch: 67
2023-01-04 04:36:56,301 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47041722933451335, 'Total loss': 0.47041722933451335} | train loss {'Reaction outcome loss': 0.1924920313813411, 'Total loss': 0.1924920313813411}
2023-01-04 04:36:56,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:56,301 INFO:     Epoch: 68
2023-01-04 04:36:57,930 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4527236302693685, 'Total loss': 0.4527236302693685} | train loss {'Reaction outcome loss': 0.19201201952940075, 'Total loss': 0.19201201952940075}
2023-01-04 04:36:57,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:57,931 INFO:     Epoch: 69
2023-01-04 04:36:59,519 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.477876212199529, 'Total loss': 0.477876212199529} | train loss {'Reaction outcome loss': 0.18844600218862617, 'Total loss': 0.18844600218862617}
2023-01-04 04:36:59,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:36:59,519 INFO:     Epoch: 70
2023-01-04 04:37:01,124 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4472745547691981, 'Total loss': 0.4472745547691981} | train loss {'Reaction outcome loss': 0.18901575918877597, 'Total loss': 0.18901575918877597}
2023-01-04 04:37:01,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:01,124 INFO:     Epoch: 71
2023-01-04 04:37:02,728 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4561990400155385, 'Total loss': 0.4561990400155385} | train loss {'Reaction outcome loss': 0.18593960297747855, 'Total loss': 0.18593960297747855}
2023-01-04 04:37:02,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:02,730 INFO:     Epoch: 72
2023-01-04 04:37:04,316 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44590610067049663, 'Total loss': 0.44590610067049663} | train loss {'Reaction outcome loss': 0.18350314174775398, 'Total loss': 0.18350314174775398}
2023-01-04 04:37:04,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:04,316 INFO:     Epoch: 73
2023-01-04 04:37:05,922 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47410147786140444, 'Total loss': 0.47410147786140444} | train loss {'Reaction outcome loss': 0.1842986357125995, 'Total loss': 0.1842986357125995}
2023-01-04 04:37:05,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:05,922 INFO:     Epoch: 74
2023-01-04 04:37:07,506 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46944758892059324, 'Total loss': 0.46944758892059324} | train loss {'Reaction outcome loss': 0.18439345890891465, 'Total loss': 0.18439345890891465}
2023-01-04 04:37:07,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:07,506 INFO:     Epoch: 75
2023-01-04 04:37:09,111 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45404990514119464, 'Total loss': 0.45404990514119464} | train loss {'Reaction outcome loss': 0.18193314266172558, 'Total loss': 0.18193314266172558}
2023-01-04 04:37:09,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:09,112 INFO:     Epoch: 76
2023-01-04 04:37:10,715 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4656302442153295, 'Total loss': 0.4656302442153295} | train loss {'Reaction outcome loss': 0.1821095159795095, 'Total loss': 0.1821095159795095}
2023-01-04 04:37:10,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:10,716 INFO:     Epoch: 77
2023-01-04 04:37:12,310 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4781255841255188, 'Total loss': 0.4781255841255188} | train loss {'Reaction outcome loss': 0.18083243991924106, 'Total loss': 0.18083243991924106}
2023-01-04 04:37:12,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:12,311 INFO:     Epoch: 78
2023-01-04 04:37:13,915 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4717163493235906, 'Total loss': 0.4717163493235906} | train loss {'Reaction outcome loss': 0.18044277002517176, 'Total loss': 0.18044277002517176}
2023-01-04 04:37:13,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:13,915 INFO:     Epoch: 79
2023-01-04 04:37:15,518 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47861717641353607, 'Total loss': 0.47861717641353607} | train loss {'Reaction outcome loss': 0.18122130365780006, 'Total loss': 0.18122130365780006}
2023-01-04 04:37:15,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:15,519 INFO:     Epoch: 80
2023-01-04 04:37:17,126 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47303043603897094, 'Total loss': 0.47303043603897094} | train loss {'Reaction outcome loss': 0.18004407893718366, 'Total loss': 0.18004407893718366}
2023-01-04 04:37:17,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:17,126 INFO:     Epoch: 81
2023-01-04 04:37:18,760 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46159000396728517, 'Total loss': 0.46159000396728517} | train loss {'Reaction outcome loss': 0.17706640890466607, 'Total loss': 0.17706640890466607}
2023-01-04 04:37:18,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:18,760 INFO:     Epoch: 82
2023-01-04 04:37:20,397 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4857448856035868, 'Total loss': 0.4857448856035868} | train loss {'Reaction outcome loss': 0.17729412155757096, 'Total loss': 0.17729412155757096}
2023-01-04 04:37:20,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:20,397 INFO:     Epoch: 83
2023-01-04 04:37:22,008 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.465986301501592, 'Total loss': 0.465986301501592} | train loss {'Reaction outcome loss': 0.17663038203270856, 'Total loss': 0.17663038203270856}
2023-01-04 04:37:22,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:22,009 INFO:     Epoch: 84
2023-01-04 04:37:23,596 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48206252853075665, 'Total loss': 0.48206252853075665} | train loss {'Reaction outcome loss': 0.17695073036994743, 'Total loss': 0.17695073036994743}
2023-01-04 04:37:23,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:23,596 INFO:     Epoch: 85
2023-01-04 04:37:25,200 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4492944985628128, 'Total loss': 0.4492944985628128} | train loss {'Reaction outcome loss': 0.173757798209894, 'Total loss': 0.173757798209894}
2023-01-04 04:37:25,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:25,201 INFO:     Epoch: 86
2023-01-04 04:37:26,833 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5067672987778982, 'Total loss': 0.5067672987778982} | train loss {'Reaction outcome loss': 0.17729549256526606, 'Total loss': 0.17729549256526606}
2023-01-04 04:37:26,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:26,833 INFO:     Epoch: 87
2023-01-04 04:37:28,424 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.478305850426356, 'Total loss': 0.478305850426356} | train loss {'Reaction outcome loss': 0.17374812890960423, 'Total loss': 0.17374812890960423}
2023-01-04 04:37:28,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:28,424 INFO:     Epoch: 88
2023-01-04 04:37:30,049 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4848246266444524, 'Total loss': 0.4848246266444524} | train loss {'Reaction outcome loss': 0.171008536632472, 'Total loss': 0.171008536632472}
2023-01-04 04:37:30,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:30,049 INFO:     Epoch: 89
2023-01-04 04:37:31,634 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49634413520495096, 'Total loss': 0.49634413520495096} | train loss {'Reaction outcome loss': 0.17101135818348248, 'Total loss': 0.17101135818348248}
2023-01-04 04:37:31,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:31,634 INFO:     Epoch: 90
2023-01-04 04:37:33,265 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4793117423852285, 'Total loss': 0.4793117423852285} | train loss {'Reaction outcome loss': 0.1734290810819675, 'Total loss': 0.1734290810819675}
2023-01-04 04:37:33,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:33,266 INFO:     Epoch: 91
2023-01-04 04:37:34,851 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4539038429657618, 'Total loss': 0.4539038429657618} | train loss {'Reaction outcome loss': 0.17102487834459607, 'Total loss': 0.17102487834459607}
2023-01-04 04:37:34,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:34,851 INFO:     Epoch: 92
2023-01-04 04:37:36,455 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4858243385950724, 'Total loss': 0.4858243385950724} | train loss {'Reaction outcome loss': 0.17373906536572462, 'Total loss': 0.17373906536572462}
2023-01-04 04:37:36,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:36,455 INFO:     Epoch: 93
2023-01-04 04:37:38,068 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4784658372402191, 'Total loss': 0.4784658372402191} | train loss {'Reaction outcome loss': 0.16865746936481782, 'Total loss': 0.16865746936481782}
2023-01-04 04:37:38,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:38,069 INFO:     Epoch: 94
2023-01-04 04:37:39,652 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46645587583382925, 'Total loss': 0.46645587583382925} | train loss {'Reaction outcome loss': 0.1689805747799925, 'Total loss': 0.1689805747799925}
2023-01-04 04:37:39,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:39,653 INFO:     Epoch: 95
2023-01-04 04:37:41,285 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4886810451745987, 'Total loss': 0.4886810451745987} | train loss {'Reaction outcome loss': 0.1683579006666042, 'Total loss': 0.1683579006666042}
2023-01-04 04:37:41,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:41,285 INFO:     Epoch: 96
2023-01-04 04:37:42,886 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4871537486712138, 'Total loss': 0.4871537486712138} | train loss {'Reaction outcome loss': 0.16604725820170413, 'Total loss': 0.16604725820170413}
2023-01-04 04:37:42,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:42,887 INFO:     Epoch: 97
2023-01-04 04:37:44,484 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4817529688278834, 'Total loss': 0.4817529688278834} | train loss {'Reaction outcome loss': 0.16753175166781845, 'Total loss': 0.16753175166781845}
2023-01-04 04:37:44,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:44,484 INFO:     Epoch: 98
2023-01-04 04:37:46,096 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48884092768033344, 'Total loss': 0.48884092768033344} | train loss {'Reaction outcome loss': 0.16527999135991728, 'Total loss': 0.16527999135991728}
2023-01-04 04:37:46,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:46,096 INFO:     Epoch: 99
2023-01-04 04:37:47,702 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4912407179673513, 'Total loss': 0.4912407179673513} | train loss {'Reaction outcome loss': 0.16498525069508743, 'Total loss': 0.16498525069508743}
2023-01-04 04:37:47,702 INFO:     Best model found after epoch 21 of 100.
2023-01-04 04:37:47,702 INFO:   Done with stage: TRAINING
2023-01-04 04:37:47,702 INFO:   Starting stage: EVALUATION
2023-01-04 04:37:47,825 INFO:   Done with stage: EVALUATION
2023-01-04 04:37:47,825 INFO:   Leaving out SEQ value Fold_8
2023-01-04 04:37:47,838 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 04:37:47,838 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:37:48,492 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:37:48,492 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:37:48,559 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:37:48,559 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:37:48,560 INFO:     No hyperparam tuning for this model
2023-01-04 04:37:48,560 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:37:48,560 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:37:48,560 INFO:     None feature selector for col prot
2023-01-04 04:37:48,560 INFO:     None feature selector for col prot
2023-01-04 04:37:48,561 INFO:     None feature selector for col prot
2023-01-04 04:37:48,561 INFO:     None feature selector for col chem
2023-01-04 04:37:48,561 INFO:     None feature selector for col chem
2023-01-04 04:37:48,561 INFO:     None feature selector for col chem
2023-01-04 04:37:48,561 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:37:48,561 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:37:48,562 INFO:     Number of params in model 70141
2023-01-04 04:37:48,566 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:37:48,566 INFO:   Starting stage: TRAINING
2023-01-04 04:37:48,611 INFO:     Val loss before train {'Reaction outcome loss': 1.060991628964742, 'Total loss': 1.060991628964742}
2023-01-04 04:37:48,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:48,611 INFO:     Epoch: 0
2023-01-04 04:37:50,215 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7086038450400035, 'Total loss': 0.7086038450400035} | train loss {'Reaction outcome loss': 0.833253368844081, 'Total loss': 0.833253368844081}
2023-01-04 04:37:50,215 INFO:     Found new best model at epoch 0
2023-01-04 04:37:50,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:50,216 INFO:     Epoch: 1
2023-01-04 04:37:51,802 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5846438825130462, 'Total loss': 0.5846438825130462} | train loss {'Reaction outcome loss': 0.6032392832375791, 'Total loss': 0.6032392832375791}
2023-01-04 04:37:51,803 INFO:     Found new best model at epoch 1
2023-01-04 04:37:51,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:51,804 INFO:     Epoch: 2
2023-01-04 04:37:53,384 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5210010349750519, 'Total loss': 0.5210010349750519} | train loss {'Reaction outcome loss': 0.5370796164565713, 'Total loss': 0.5370796164565713}
2023-01-04 04:37:53,384 INFO:     Found new best model at epoch 2
2023-01-04 04:37:53,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:53,385 INFO:     Epoch: 3
2023-01-04 04:37:54,974 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5003510733445485, 'Total loss': 0.5003510733445485} | train loss {'Reaction outcome loss': 0.5006205942617715, 'Total loss': 0.5006205942617715}
2023-01-04 04:37:54,974 INFO:     Found new best model at epoch 3
2023-01-04 04:37:54,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:54,975 INFO:     Epoch: 4
2023-01-04 04:37:56,560 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4812803109486898, 'Total loss': 0.4812803109486898} | train loss {'Reaction outcome loss': 0.47470899649562626, 'Total loss': 0.47470899649562626}
2023-01-04 04:37:56,560 INFO:     Found new best model at epoch 4
2023-01-04 04:37:56,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:56,561 INFO:     Epoch: 5
2023-01-04 04:37:58,142 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4638941069444021, 'Total loss': 0.4638941069444021} | train loss {'Reaction outcome loss': 0.4556411323919348, 'Total loss': 0.4556411323919348}
2023-01-04 04:37:58,142 INFO:     Found new best model at epoch 5
2023-01-04 04:37:58,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:58,143 INFO:     Epoch: 6
2023-01-04 04:37:59,734 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45154428482055664, 'Total loss': 0.45154428482055664} | train loss {'Reaction outcome loss': 0.4390464930312477, 'Total loss': 0.4390464930312477}
2023-01-04 04:37:59,734 INFO:     Found new best model at epoch 6
2023-01-04 04:37:59,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:37:59,735 INFO:     Epoch: 7
2023-01-04 04:38:01,311 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4462804734706879, 'Total loss': 0.4462804734706879} | train loss {'Reaction outcome loss': 0.42530954650936337, 'Total loss': 0.42530954650936337}
2023-01-04 04:38:01,311 INFO:     Found new best model at epoch 7
2023-01-04 04:38:01,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:01,312 INFO:     Epoch: 8
2023-01-04 04:38:02,908 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46305812100569405, 'Total loss': 0.46305812100569405} | train loss {'Reaction outcome loss': 0.4134318020983334, 'Total loss': 0.4134318020983334}
2023-01-04 04:38:02,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:02,909 INFO:     Epoch: 9
2023-01-04 04:38:04,520 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4337133953968684, 'Total loss': 0.4337133953968684} | train loss {'Reaction outcome loss': 0.4021698023824796, 'Total loss': 0.4021698023824796}
2023-01-04 04:38:04,521 INFO:     Found new best model at epoch 9
2023-01-04 04:38:04,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:04,522 INFO:     Epoch: 10
2023-01-04 04:38:06,104 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4486611207326253, 'Total loss': 0.4486611207326253} | train loss {'Reaction outcome loss': 0.3941275522547917, 'Total loss': 0.3941275522547917}
2023-01-04 04:38:06,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:06,104 INFO:     Epoch: 11
2023-01-04 04:38:07,692 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4192574620246887, 'Total loss': 0.4192574620246887} | train loss {'Reaction outcome loss': 0.3842620284017855, 'Total loss': 0.3842620284017855}
2023-01-04 04:38:07,693 INFO:     Found new best model at epoch 11
2023-01-04 04:38:07,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:07,694 INFO:     Epoch: 12
2023-01-04 04:38:09,295 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4367654820283254, 'Total loss': 0.4367654820283254} | train loss {'Reaction outcome loss': 0.37646735508511536, 'Total loss': 0.37646735508511536}
2023-01-04 04:38:09,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:09,296 INFO:     Epoch: 13
2023-01-04 04:38:10,882 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41373183329900104, 'Total loss': 0.41373183329900104} | train loss {'Reaction outcome loss': 0.36791397892210603, 'Total loss': 0.36791397892210603}
2023-01-04 04:38:10,883 INFO:     Found new best model at epoch 13
2023-01-04 04:38:10,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:10,884 INFO:     Epoch: 14
2023-01-04 04:38:12,493 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4341590424378713, 'Total loss': 0.4341590424378713} | train loss {'Reaction outcome loss': 0.360831409502421, 'Total loss': 0.360831409502421}
2023-01-04 04:38:12,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:12,493 INFO:     Epoch: 15
2023-01-04 04:38:14,080 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4077744310100873, 'Total loss': 0.4077744310100873} | train loss {'Reaction outcome loss': 0.35620000564160137, 'Total loss': 0.35620000564160137}
2023-01-04 04:38:14,081 INFO:     Found new best model at epoch 15
2023-01-04 04:38:14,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:14,081 INFO:     Epoch: 16
2023-01-04 04:38:15,661 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4063795785109202, 'Total loss': 0.4063795785109202} | train loss {'Reaction outcome loss': 0.35036975341121646, 'Total loss': 0.35036975341121646}
2023-01-04 04:38:15,661 INFO:     Found new best model at epoch 16
2023-01-04 04:38:15,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:15,662 INFO:     Epoch: 17
2023-01-04 04:38:17,271 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42603756189346315, 'Total loss': 0.42603756189346315} | train loss {'Reaction outcome loss': 0.34229082812684297, 'Total loss': 0.34229082812684297}
2023-01-04 04:38:17,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:17,272 INFO:     Epoch: 18
2023-01-04 04:38:18,869 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40326690872510274, 'Total loss': 0.40326690872510274} | train loss {'Reaction outcome loss': 0.34077895291312765, 'Total loss': 0.34077895291312765}
2023-01-04 04:38:18,869 INFO:     Found new best model at epoch 18
2023-01-04 04:38:18,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:18,870 INFO:     Epoch: 19
2023-01-04 04:38:20,478 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4287884632746379, 'Total loss': 0.4287884632746379} | train loss {'Reaction outcome loss': 0.3327766793107029, 'Total loss': 0.3327766793107029}
2023-01-04 04:38:20,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:20,478 INFO:     Epoch: 20
2023-01-04 04:38:22,071 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.419391671816508, 'Total loss': 0.419391671816508} | train loss {'Reaction outcome loss': 0.32867374711663183, 'Total loss': 0.32867374711663183}
2023-01-04 04:38:22,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:22,071 INFO:     Epoch: 21
2023-01-04 04:38:23,671 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41231428980827334, 'Total loss': 0.41231428980827334} | train loss {'Reaction outcome loss': 0.3246061102262814, 'Total loss': 0.3246061102262814}
2023-01-04 04:38:23,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:23,672 INFO:     Epoch: 22
2023-01-04 04:38:25,273 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3937655508518219, 'Total loss': 0.3937655508518219} | train loss {'Reaction outcome loss': 0.31851645140317236, 'Total loss': 0.31851645140317236}
2023-01-04 04:38:25,273 INFO:     Found new best model at epoch 22
2023-01-04 04:38:25,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:25,274 INFO:     Epoch: 23
2023-01-04 04:38:26,882 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41158828834692635, 'Total loss': 0.41158828834692635} | train loss {'Reaction outcome loss': 0.31645437020019895, 'Total loss': 0.31645437020019895}
2023-01-04 04:38:26,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:26,882 INFO:     Epoch: 24
2023-01-04 04:38:28,454 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4073019484678904, 'Total loss': 0.4073019484678904} | train loss {'Reaction outcome loss': 0.311791471402793, 'Total loss': 0.311791471402793}
2023-01-04 04:38:28,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:28,454 INFO:     Epoch: 25
2023-01-04 04:38:30,052 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4042140871286392, 'Total loss': 0.4042140871286392} | train loss {'Reaction outcome loss': 0.3072194935359659, 'Total loss': 0.3072194935359659}
2023-01-04 04:38:30,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:30,052 INFO:     Epoch: 26
2023-01-04 04:38:31,660 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3783414115508397, 'Total loss': 0.3783414115508397} | train loss {'Reaction outcome loss': 0.3046079017493847, 'Total loss': 0.3046079017493847}
2023-01-04 04:38:31,660 INFO:     Found new best model at epoch 26
2023-01-04 04:38:31,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:31,661 INFO:     Epoch: 27
2023-01-04 04:38:33,236 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39186319212118786, 'Total loss': 0.39186319212118786} | train loss {'Reaction outcome loss': 0.2998749819876504, 'Total loss': 0.2998749819876504}
2023-01-04 04:38:33,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:33,236 INFO:     Epoch: 28
2023-01-04 04:38:34,818 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3983365456263224, 'Total loss': 0.3983365456263224} | train loss {'Reaction outcome loss': 0.29677524836394037, 'Total loss': 0.29677524836394037}
2023-01-04 04:38:34,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:34,819 INFO:     Epoch: 29
2023-01-04 04:38:36,409 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3993317186832428, 'Total loss': 0.3993317186832428} | train loss {'Reaction outcome loss': 0.29377881886206403, 'Total loss': 0.29377881886206403}
2023-01-04 04:38:36,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:36,409 INFO:     Epoch: 30
2023-01-04 04:38:38,004 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4050910542408625, 'Total loss': 0.4050910542408625} | train loss {'Reaction outcome loss': 0.2889576923972281, 'Total loss': 0.2889576923972281}
2023-01-04 04:38:38,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:38,004 INFO:     Epoch: 31
2023-01-04 04:38:39,615 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4210389306147893, 'Total loss': 0.4210389306147893} | train loss {'Reaction outcome loss': 0.2843383020401871, 'Total loss': 0.2843383020401871}
2023-01-04 04:38:39,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:39,615 INFO:     Epoch: 32
2023-01-04 04:38:41,226 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40004121164480844, 'Total loss': 0.40004121164480844} | train loss {'Reaction outcome loss': 0.2852368787692411, 'Total loss': 0.2852368787692411}
2023-01-04 04:38:41,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:41,227 INFO:     Epoch: 33
2023-01-04 04:38:42,789 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4196305880943934, 'Total loss': 0.4196305880943934} | train loss {'Reaction outcome loss': 0.2803356743750781, 'Total loss': 0.2803356743750781}
2023-01-04 04:38:42,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:42,789 INFO:     Epoch: 34
2023-01-04 04:38:44,401 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4330410232146581, 'Total loss': 0.4330410232146581} | train loss {'Reaction outcome loss': 0.27607311194177964, 'Total loss': 0.27607311194177964}
2023-01-04 04:38:44,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:44,401 INFO:     Epoch: 35
2023-01-04 04:38:45,992 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41961854000886284, 'Total loss': 0.41961854000886284} | train loss {'Reaction outcome loss': 0.2746167744435098, 'Total loss': 0.2746167744435098}
2023-01-04 04:38:45,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:45,992 INFO:     Epoch: 36
2023-01-04 04:38:47,600 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39739841818809507, 'Total loss': 0.39739841818809507} | train loss {'Reaction outcome loss': 0.2705096891625737, 'Total loss': 0.2705096891625737}
2023-01-04 04:38:47,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:47,600 INFO:     Epoch: 37
2023-01-04 04:38:49,180 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40867076218128207, 'Total loss': 0.40867076218128207} | train loss {'Reaction outcome loss': 0.26811446573068626, 'Total loss': 0.26811446573068626}
2023-01-04 04:38:49,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:49,180 INFO:     Epoch: 38
2023-01-04 04:38:50,777 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39946522216002145, 'Total loss': 0.39946522216002145} | train loss {'Reaction outcome loss': 0.26457170773651045, 'Total loss': 0.26457170773651045}
2023-01-04 04:38:50,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:50,777 INFO:     Epoch: 39
2023-01-04 04:38:52,350 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40631588399410246, 'Total loss': 0.40631588399410246} | train loss {'Reaction outcome loss': 0.2630017599920287, 'Total loss': 0.2630017599920287}
2023-01-04 04:38:52,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:52,351 INFO:     Epoch: 40
2023-01-04 04:38:53,935 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37977513869603474, 'Total loss': 0.37977513869603474} | train loss {'Reaction outcome loss': 0.2606190826172811, 'Total loss': 0.2606190826172811}
2023-01-04 04:38:53,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:53,936 INFO:     Epoch: 41
2023-01-04 04:38:55,530 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4027320702870687, 'Total loss': 0.4027320702870687} | train loss {'Reaction outcome loss': 0.2584592176152624, 'Total loss': 0.2584592176152624}
2023-01-04 04:38:55,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:55,530 INFO:     Epoch: 42
2023-01-04 04:38:57,119 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40197882453600564, 'Total loss': 0.40197882453600564} | train loss {'Reaction outcome loss': 0.25356219945489056, 'Total loss': 0.25356219945489056}
2023-01-04 04:38:57,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:57,119 INFO:     Epoch: 43
2023-01-04 04:38:58,697 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40688599745432535, 'Total loss': 0.40688599745432535} | train loss {'Reaction outcome loss': 0.2510804526072784, 'Total loss': 0.2510804526072784}
2023-01-04 04:38:58,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:38:58,697 INFO:     Epoch: 44
2023-01-04 04:39:00,268 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4247346887985865, 'Total loss': 0.4247346887985865} | train loss {'Reaction outcome loss': 0.2527020249760499, 'Total loss': 0.2527020249760499}
2023-01-04 04:39:00,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:00,269 INFO:     Epoch: 45
2023-01-04 04:39:01,884 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40475526452064514, 'Total loss': 0.40475526452064514} | train loss {'Reaction outcome loss': 0.24914955948717402, 'Total loss': 0.24914955948717402}
2023-01-04 04:39:01,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:01,884 INFO:     Epoch: 46
2023-01-04 04:39:03,495 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37967681139707565, 'Total loss': 0.37967681139707565} | train loss {'Reaction outcome loss': 0.24557483574225955, 'Total loss': 0.24557483574225955}
2023-01-04 04:39:03,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:03,495 INFO:     Epoch: 47
2023-01-04 04:39:05,074 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4150334417819977, 'Total loss': 0.4150334417819977} | train loss {'Reaction outcome loss': 0.24176682478809444, 'Total loss': 0.24176682478809444}
2023-01-04 04:39:05,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:05,075 INFO:     Epoch: 48
2023-01-04 04:39:06,656 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4307448585828145, 'Total loss': 0.4307448585828145} | train loss {'Reaction outcome loss': 0.2421075285949411, 'Total loss': 0.2421075285949411}
2023-01-04 04:39:06,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:06,657 INFO:     Epoch: 49
2023-01-04 04:39:08,243 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3924241721630096, 'Total loss': 0.3924241721630096} | train loss {'Reaction outcome loss': 0.242877307980165, 'Total loss': 0.242877307980165}
2023-01-04 04:39:08,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:08,244 INFO:     Epoch: 50
2023-01-04 04:39:09,816 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40446816285451254, 'Total loss': 0.40446816285451254} | train loss {'Reaction outcome loss': 0.23927025964660367, 'Total loss': 0.23927025964660367}
2023-01-04 04:39:09,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:09,816 INFO:     Epoch: 51
2023-01-04 04:39:11,401 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42854859431584674, 'Total loss': 0.42854859431584674} | train loss {'Reaction outcome loss': 0.23548008137158233, 'Total loss': 0.23548008137158233}
2023-01-04 04:39:11,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:11,401 INFO:     Epoch: 52
2023-01-04 04:39:12,968 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40411762793858846, 'Total loss': 0.40411762793858846} | train loss {'Reaction outcome loss': 0.23460219206329244, 'Total loss': 0.23460219206329244}
2023-01-04 04:39:12,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:12,969 INFO:     Epoch: 53
2023-01-04 04:39:14,537 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3974670221408208, 'Total loss': 0.3974670221408208} | train loss {'Reaction outcome loss': 0.2331548108291017, 'Total loss': 0.2331548108291017}
2023-01-04 04:39:14,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:14,537 INFO:     Epoch: 54
2023-01-04 04:39:16,151 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40052195886770886, 'Total loss': 0.40052195886770886} | train loss {'Reaction outcome loss': 0.23218363335859166, 'Total loss': 0.23218363335859166}
2023-01-04 04:39:16,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:16,151 INFO:     Epoch: 55
2023-01-04 04:39:17,749 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41235829492410025, 'Total loss': 0.41235829492410025} | train loss {'Reaction outcome loss': 0.23063012818894246, 'Total loss': 0.23063012818894246}
2023-01-04 04:39:17,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:17,749 INFO:     Epoch: 56
2023-01-04 04:39:19,363 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41987574100494385, 'Total loss': 0.41987574100494385} | train loss {'Reaction outcome loss': 0.226903401383192, 'Total loss': 0.226903401383192}
2023-01-04 04:39:19,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:19,363 INFO:     Epoch: 57
2023-01-04 04:39:20,977 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43376847306887306, 'Total loss': 0.43376847306887306} | train loss {'Reaction outcome loss': 0.22632953661908634, 'Total loss': 0.22632953661908634}
2023-01-04 04:39:20,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:20,977 INFO:     Epoch: 58
2023-01-04 04:39:22,555 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40789983173211414, 'Total loss': 0.40789983173211414} | train loss {'Reaction outcome loss': 0.2229111352731494, 'Total loss': 0.2229111352731494}
2023-01-04 04:39:22,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:22,556 INFO:     Epoch: 59
2023-01-04 04:39:24,142 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39856017430623375, 'Total loss': 0.39856017430623375} | train loss {'Reaction outcome loss': 0.2214512327468417, 'Total loss': 0.2214512327468417}
2023-01-04 04:39:24,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:24,143 INFO:     Epoch: 60
2023-01-04 04:39:25,729 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3911673237880071, 'Total loss': 0.3911673237880071} | train loss {'Reaction outcome loss': 0.21991144882066407, 'Total loss': 0.21991144882066407}
2023-01-04 04:39:25,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:25,730 INFO:     Epoch: 61
2023-01-04 04:39:27,293 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41958045413096745, 'Total loss': 0.41958045413096745} | train loss {'Reaction outcome loss': 0.21855813660488946, 'Total loss': 0.21855813660488946}
2023-01-04 04:39:27,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:27,293 INFO:     Epoch: 62
2023-01-04 04:39:28,907 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38078714633981386, 'Total loss': 0.38078714633981386} | train loss {'Reaction outcome loss': 0.22055726385519017, 'Total loss': 0.22055726385519017}
2023-01-04 04:39:28,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:28,908 INFO:     Epoch: 63
2023-01-04 04:39:30,502 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43294524153073627, 'Total loss': 0.43294524153073627} | train loss {'Reaction outcome loss': 0.21579641644863318, 'Total loss': 0.21579641644863318}
2023-01-04 04:39:30,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:30,502 INFO:     Epoch: 64
2023-01-04 04:39:32,094 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42908785343170164, 'Total loss': 0.42908785343170164} | train loss {'Reaction outcome loss': 0.2133328930413636, 'Total loss': 0.2133328930413636}
2023-01-04 04:39:32,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:32,094 INFO:     Epoch: 65
2023-01-04 04:39:33,685 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40634778936704, 'Total loss': 0.40634778936704} | train loss {'Reaction outcome loss': 0.21573169131076683, 'Total loss': 0.21573169131076683}
2023-01-04 04:39:33,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:33,685 INFO:     Epoch: 66
2023-01-04 04:39:35,272 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4192042961716652, 'Total loss': 0.4192042961716652} | train loss {'Reaction outcome loss': 0.21123113298285617, 'Total loss': 0.21123113298285617}
2023-01-04 04:39:35,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:35,272 INFO:     Epoch: 67
2023-01-04 04:39:36,842 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3984157880147298, 'Total loss': 0.3984157880147298} | train loss {'Reaction outcome loss': 0.2091657871747539, 'Total loss': 0.2091657871747539}
2023-01-04 04:39:36,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:36,842 INFO:     Epoch: 68
2023-01-04 04:39:38,428 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38326200395822524, 'Total loss': 0.38326200395822524} | train loss {'Reaction outcome loss': 0.20879796952226737, 'Total loss': 0.20879796952226737}
2023-01-04 04:39:38,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:38,428 INFO:     Epoch: 69
2023-01-04 04:39:40,002 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41996386349201204, 'Total loss': 0.41996386349201204} | train loss {'Reaction outcome loss': 0.2100316666501717, 'Total loss': 0.2100316666501717}
2023-01-04 04:39:40,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:40,002 INFO:     Epoch: 70
2023-01-04 04:39:41,588 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4254382501045863, 'Total loss': 0.4254382501045863} | train loss {'Reaction outcome loss': 0.20767766407208285, 'Total loss': 0.20767766407208285}
2023-01-04 04:39:41,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:41,589 INFO:     Epoch: 71
2023-01-04 04:39:43,193 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40164599816004437, 'Total loss': 0.40164599816004437} | train loss {'Reaction outcome loss': 0.20545262403541456, 'Total loss': 0.20545262403541456}
2023-01-04 04:39:43,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:43,193 INFO:     Epoch: 72
2023-01-04 04:39:44,762 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3978300521771113, 'Total loss': 0.3978300521771113} | train loss {'Reaction outcome loss': 0.2049749302439881, 'Total loss': 0.2049749302439881}
2023-01-04 04:39:44,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:44,763 INFO:     Epoch: 73
2023-01-04 04:39:46,352 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4204348345597585, 'Total loss': 0.4204348345597585} | train loss {'Reaction outcome loss': 0.2041071595719261, 'Total loss': 0.2041071595719261}
2023-01-04 04:39:46,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:46,352 INFO:     Epoch: 74
2023-01-04 04:39:47,938 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4089832584063212, 'Total loss': 0.4089832584063212} | train loss {'Reaction outcome loss': 0.20096742152406352, 'Total loss': 0.20096742152406352}
2023-01-04 04:39:47,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:47,939 INFO:     Epoch: 75
2023-01-04 04:39:49,535 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.394859446088473, 'Total loss': 0.394859446088473} | train loss {'Reaction outcome loss': 0.20020291105891666, 'Total loss': 0.20020291105891666}
2023-01-04 04:39:49,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:49,535 INFO:     Epoch: 76
2023-01-04 04:39:51,162 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3929601391156515, 'Total loss': 0.3929601391156515} | train loss {'Reaction outcome loss': 0.19880404848143132, 'Total loss': 0.19880404848143132}
2023-01-04 04:39:51,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:51,163 INFO:     Epoch: 77
2023-01-04 04:39:52,781 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4040063718954722, 'Total loss': 0.4040063718954722} | train loss {'Reaction outcome loss': 0.19841783828217618, 'Total loss': 0.19841783828217618}
2023-01-04 04:39:52,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:52,781 INFO:     Epoch: 78
2023-01-04 04:39:54,358 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41346394618352256, 'Total loss': 0.41346394618352256} | train loss {'Reaction outcome loss': 0.1988157768373507, 'Total loss': 0.1988157768373507}
2023-01-04 04:39:54,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:54,358 INFO:     Epoch: 79
2023-01-04 04:39:55,974 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4207359790802002, 'Total loss': 0.4207359790802002} | train loss {'Reaction outcome loss': 0.19686097398835378, 'Total loss': 0.19686097398835378}
2023-01-04 04:39:55,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:55,975 INFO:     Epoch: 80
2023-01-04 04:39:57,565 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3906970426440239, 'Total loss': 0.3906970426440239} | train loss {'Reaction outcome loss': 0.19597332451465357, 'Total loss': 0.19597332451465357}
2023-01-04 04:39:57,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:57,566 INFO:     Epoch: 81
2023-01-04 04:39:58,626 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41019120812416077, 'Total loss': 0.41019120812416077} | train loss {'Reaction outcome loss': 0.1945889285853962, 'Total loss': 0.1945889285853962}
2023-01-04 04:39:58,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:58,627 INFO:     Epoch: 82
2023-01-04 04:39:59,685 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40907051314910253, 'Total loss': 0.40907051314910253} | train loss {'Reaction outcome loss': 0.19257481170505503, 'Total loss': 0.19257481170505503}
2023-01-04 04:39:59,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:39:59,685 INFO:     Epoch: 83
2023-01-04 04:40:00,737 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4086839278539022, 'Total loss': 0.4086839278539022} | train loss {'Reaction outcome loss': 0.19088674188475974, 'Total loss': 0.19088674188475974}
2023-01-04 04:40:00,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:00,738 INFO:     Epoch: 84
2023-01-04 04:40:01,878 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4219933787981669, 'Total loss': 0.4219933787981669} | train loss {'Reaction outcome loss': 0.1888776399827406, 'Total loss': 0.1888776399827406}
2023-01-04 04:40:01,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:01,879 INFO:     Epoch: 85
2023-01-04 04:40:03,505 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41733382840951283, 'Total loss': 0.41733382840951283} | train loss {'Reaction outcome loss': 0.18995753171969287, 'Total loss': 0.18995753171969287}
2023-01-04 04:40:03,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:03,505 INFO:     Epoch: 86
2023-01-04 04:40:05,110 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43886390725771585, 'Total loss': 0.43886390725771585} | train loss {'Reaction outcome loss': 0.1881552323236735, 'Total loss': 0.1881552323236735}
2023-01-04 04:40:05,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:05,110 INFO:     Epoch: 87
2023-01-04 04:40:06,717 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4180124153693517, 'Total loss': 0.4180124153693517} | train loss {'Reaction outcome loss': 0.18897913446663506, 'Total loss': 0.18897913446663506}
2023-01-04 04:40:06,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:06,718 INFO:     Epoch: 88
2023-01-04 04:40:08,318 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4073047618071238, 'Total loss': 0.4073047618071238} | train loss {'Reaction outcome loss': 0.18792340550979558, 'Total loss': 0.18792340550979558}
2023-01-04 04:40:08,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:08,318 INFO:     Epoch: 89
2023-01-04 04:40:09,886 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39137449910243355, 'Total loss': 0.39137449910243355} | train loss {'Reaction outcome loss': 0.19005690997697577, 'Total loss': 0.19005690997697577}
2023-01-04 04:40:09,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:09,887 INFO:     Epoch: 90
2023-01-04 04:40:11,444 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3877775957187017, 'Total loss': 0.3877775957187017} | train loss {'Reaction outcome loss': 0.18520178442589774, 'Total loss': 0.18520178442589774}
2023-01-04 04:40:11,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:11,444 INFO:     Epoch: 91
2023-01-04 04:40:13,030 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39781515498956044, 'Total loss': 0.39781515498956044} | train loss {'Reaction outcome loss': 0.1865842706952108, 'Total loss': 0.1865842706952108}
2023-01-04 04:40:13,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:13,031 INFO:     Epoch: 92
2023-01-04 04:40:14,607 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4364444077014923, 'Total loss': 0.4364444077014923} | train loss {'Reaction outcome loss': 0.1841407467332417, 'Total loss': 0.1841407467332417}
2023-01-04 04:40:14,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:14,607 INFO:     Epoch: 93
2023-01-04 04:40:16,195 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39768901765346526, 'Total loss': 0.39768901765346526} | train loss {'Reaction outcome loss': 0.18264742264945577, 'Total loss': 0.18264742264945577}
2023-01-04 04:40:16,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:16,195 INFO:     Epoch: 94
2023-01-04 04:40:17,786 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4343167195717494, 'Total loss': 0.4343167195717494} | train loss {'Reaction outcome loss': 0.18426449804899903, 'Total loss': 0.18426449804899903}
2023-01-04 04:40:17,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:17,787 INFO:     Epoch: 95
2023-01-04 04:40:19,359 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42638550798098246, 'Total loss': 0.42638550798098246} | train loss {'Reaction outcome loss': 0.18148546794388634, 'Total loss': 0.18148546794388634}
2023-01-04 04:40:19,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:19,360 INFO:     Epoch: 96
2023-01-04 04:40:20,946 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3962992653250694, 'Total loss': 0.3962992653250694} | train loss {'Reaction outcome loss': 0.17943621575696408, 'Total loss': 0.17943621575696408}
2023-01-04 04:40:20,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:20,947 INFO:     Epoch: 97
2023-01-04 04:40:22,562 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39949062863985696, 'Total loss': 0.39949062863985696} | train loss {'Reaction outcome loss': 0.18116200558270198, 'Total loss': 0.18116200558270198}
2023-01-04 04:40:22,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:22,562 INFO:     Epoch: 98
2023-01-04 04:40:24,173 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42462919702132546, 'Total loss': 0.42462919702132546} | train loss {'Reaction outcome loss': 0.18023107166871102, 'Total loss': 0.18023107166871102}
2023-01-04 04:40:24,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:24,174 INFO:     Epoch: 99
2023-01-04 04:40:25,774 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42030157446861266, 'Total loss': 0.42030157446861266} | train loss {'Reaction outcome loss': 0.17887527978958656, 'Total loss': 0.17887527978958656}
2023-01-04 04:40:25,774 INFO:     Best model found after epoch 27 of 100.
2023-01-04 04:40:25,774 INFO:   Done with stage: TRAINING
2023-01-04 04:40:25,774 INFO:   Starting stage: EVALUATION
2023-01-04 04:40:25,909 INFO:   Done with stage: EVALUATION
2023-01-04 04:40:25,910 INFO:   Leaving out SEQ value Fold_9
2023-01-04 04:40:25,922 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:40:25,922 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:40:26,568 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:40:26,569 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:40:26,637 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:40:26,637 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:40:26,637 INFO:     No hyperparam tuning for this model
2023-01-04 04:40:26,637 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:40:26,637 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:40:26,638 INFO:     None feature selector for col prot
2023-01-04 04:40:26,638 INFO:     None feature selector for col prot
2023-01-04 04:40:26,638 INFO:     None feature selector for col prot
2023-01-04 04:40:26,638 INFO:     None feature selector for col chem
2023-01-04 04:40:26,639 INFO:     None feature selector for col chem
2023-01-04 04:40:26,639 INFO:     None feature selector for col chem
2023-01-04 04:40:26,639 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:40:26,639 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:40:26,640 INFO:     Number of params in model 70141
2023-01-04 04:40:26,643 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:40:26,643 INFO:   Starting stage: TRAINING
2023-01-04 04:40:26,686 INFO:     Val loss before train {'Reaction outcome loss': 0.995823343594869, 'Total loss': 0.995823343594869}
2023-01-04 04:40:26,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:26,687 INFO:     Epoch: 0
2023-01-04 04:40:28,286 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6848694046338399, 'Total loss': 0.6848694046338399} | train loss {'Reaction outcome loss': 0.8382939837765002, 'Total loss': 0.8382939837765002}
2023-01-04 04:40:28,286 INFO:     Found new best model at epoch 0
2023-01-04 04:40:28,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:28,287 INFO:     Epoch: 1
2023-01-04 04:40:29,881 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5816495478153229, 'Total loss': 0.5816495478153229} | train loss {'Reaction outcome loss': 0.6043805549110192, 'Total loss': 0.6043805549110192}
2023-01-04 04:40:29,881 INFO:     Found new best model at epoch 1
2023-01-04 04:40:29,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:29,882 INFO:     Epoch: 2
2023-01-04 04:40:31,505 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5358296950658162, 'Total loss': 0.5358296950658162} | train loss {'Reaction outcome loss': 0.5428183847579403, 'Total loss': 0.5428183847579403}
2023-01-04 04:40:31,506 INFO:     Found new best model at epoch 2
2023-01-04 04:40:31,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:31,507 INFO:     Epoch: 3
2023-01-04 04:40:33,124 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5300324459870657, 'Total loss': 0.5300324459870657} | train loss {'Reaction outcome loss': 0.48620043371034705, 'Total loss': 0.48620043371034705}
2023-01-04 04:40:33,124 INFO:     Found new best model at epoch 3
2023-01-04 04:40:33,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:33,125 INFO:     Epoch: 4
2023-01-04 04:40:34,715 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5187078257401784, 'Total loss': 0.5187078257401784} | train loss {'Reaction outcome loss': 0.46074548976047075, 'Total loss': 0.46074548976047075}
2023-01-04 04:40:34,715 INFO:     Found new best model at epoch 4
2023-01-04 04:40:34,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:34,716 INFO:     Epoch: 5
2023-01-04 04:40:36,302 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5001403371493022, 'Total loss': 0.5001403371493022} | train loss {'Reaction outcome loss': 0.4367817657041377, 'Total loss': 0.4367817657041377}
2023-01-04 04:40:36,303 INFO:     Found new best model at epoch 5
2023-01-04 04:40:36,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:36,303 INFO:     Epoch: 6
2023-01-04 04:40:37,875 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4908898949623108, 'Total loss': 0.4908898949623108} | train loss {'Reaction outcome loss': 0.421509493412315, 'Total loss': 0.421509493412315}
2023-01-04 04:40:37,875 INFO:     Found new best model at epoch 6
2023-01-04 04:40:37,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:37,876 INFO:     Epoch: 7
2023-01-04 04:40:39,475 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47148546973864236, 'Total loss': 0.47148546973864236} | train loss {'Reaction outcome loss': 0.40954826340295264, 'Total loss': 0.40954826340295264}
2023-01-04 04:40:39,475 INFO:     Found new best model at epoch 7
2023-01-04 04:40:39,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:39,476 INFO:     Epoch: 8
2023-01-04 04:40:41,081 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4960805873076121, 'Total loss': 0.4960805873076121} | train loss {'Reaction outcome loss': 0.39849386596377345, 'Total loss': 0.39849386596377345}
2023-01-04 04:40:41,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:41,081 INFO:     Epoch: 9
2023-01-04 04:40:42,684 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48556243181228637, 'Total loss': 0.48556243181228637} | train loss {'Reaction outcome loss': 0.3904067655465147, 'Total loss': 0.3904067655465147}
2023-01-04 04:40:42,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:42,684 INFO:     Epoch: 10
2023-01-04 04:40:44,305 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4754337767759959, 'Total loss': 0.4754337767759959} | train loss {'Reaction outcome loss': 0.37732148891676764, 'Total loss': 0.37732148891676764}
2023-01-04 04:40:44,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:44,305 INFO:     Epoch: 11
2023-01-04 04:40:45,900 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47375938296318054, 'Total loss': 0.47375938296318054} | train loss {'Reaction outcome loss': 0.3684043315259497, 'Total loss': 0.3684043315259497}
2023-01-04 04:40:45,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:45,901 INFO:     Epoch: 12
2023-01-04 04:40:47,499 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47013594607512155, 'Total loss': 0.47013594607512155} | train loss {'Reaction outcome loss': 0.3597978583380556, 'Total loss': 0.3597978583380556}
2023-01-04 04:40:47,499 INFO:     Found new best model at epoch 12
2023-01-04 04:40:47,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:47,500 INFO:     Epoch: 13
2023-01-04 04:40:49,096 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46832702358563744, 'Total loss': 0.46832702358563744} | train loss {'Reaction outcome loss': 0.35486646203756117, 'Total loss': 0.35486646203756117}
2023-01-04 04:40:49,097 INFO:     Found new best model at epoch 13
2023-01-04 04:40:49,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:49,098 INFO:     Epoch: 14
2023-01-04 04:40:50,705 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44886619548002876, 'Total loss': 0.44886619548002876} | train loss {'Reaction outcome loss': 0.3483938075925993, 'Total loss': 0.3483938075925993}
2023-01-04 04:40:50,705 INFO:     Found new best model at epoch 14
2023-01-04 04:40:50,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:50,706 INFO:     Epoch: 15
2023-01-04 04:40:52,296 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45982418656349183, 'Total loss': 0.45982418656349183} | train loss {'Reaction outcome loss': 0.341878977175667, 'Total loss': 0.341878977175667}
2023-01-04 04:40:52,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:52,297 INFO:     Epoch: 16
2023-01-04 04:40:53,883 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46228923201560973, 'Total loss': 0.46228923201560973} | train loss {'Reaction outcome loss': 0.34081556264689006, 'Total loss': 0.34081556264689006}
2023-01-04 04:40:53,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:53,883 INFO:     Epoch: 17
2023-01-04 04:40:55,467 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4730061252911886, 'Total loss': 0.4730061252911886} | train loss {'Reaction outcome loss': 0.3342498849699463, 'Total loss': 0.3342498849699463}
2023-01-04 04:40:55,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:55,468 INFO:     Epoch: 18
2023-01-04 04:40:57,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4456875930229823, 'Total loss': 0.4456875930229823} | train loss {'Reaction outcome loss': 0.331779175127546, 'Total loss': 0.331779175127546}
2023-01-04 04:40:57,066 INFO:     Found new best model at epoch 18
2023-01-04 04:40:57,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:57,067 INFO:     Epoch: 19
2023-01-04 04:40:58,654 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45380330582459766, 'Total loss': 0.45380330582459766} | train loss {'Reaction outcome loss': 0.32946555821252044, 'Total loss': 0.32946555821252044}
2023-01-04 04:40:58,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:40:58,655 INFO:     Epoch: 20
2023-01-04 04:41:00,282 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4456612447897593, 'Total loss': 0.4456612447897593} | train loss {'Reaction outcome loss': 0.31745621813815494, 'Total loss': 0.31745621813815494}
2023-01-04 04:41:00,283 INFO:     Found new best model at epoch 20
2023-01-04 04:41:00,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:00,283 INFO:     Epoch: 21
2023-01-04 04:41:01,902 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4895335892836253, 'Total loss': 0.4895335892836253} | train loss {'Reaction outcome loss': 0.3092170827920832, 'Total loss': 0.3092170827920832}
2023-01-04 04:41:01,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:01,902 INFO:     Epoch: 22
2023-01-04 04:41:03,484 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48179413576920826, 'Total loss': 0.48179413576920826} | train loss {'Reaction outcome loss': 0.30519329923022864, 'Total loss': 0.30519329923022864}
2023-01-04 04:41:03,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:03,484 INFO:     Epoch: 23
2023-01-04 04:41:05,082 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4564969539642334, 'Total loss': 0.4564969539642334} | train loss {'Reaction outcome loss': 0.30140663856181543, 'Total loss': 0.30140663856181543}
2023-01-04 04:41:05,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:05,082 INFO:     Epoch: 24
2023-01-04 04:41:06,704 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4615406314531962, 'Total loss': 0.4615406314531962} | train loss {'Reaction outcome loss': 0.30228323268069734, 'Total loss': 0.30228323268069734}
2023-01-04 04:41:06,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:06,704 INFO:     Epoch: 25
2023-01-04 04:41:08,314 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49589544037977856, 'Total loss': 0.49589544037977856} | train loss {'Reaction outcome loss': 0.2981110784508612, 'Total loss': 0.2981110784508612}
2023-01-04 04:41:08,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:08,315 INFO:     Epoch: 26
2023-01-04 04:41:09,917 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4683557311693827, 'Total loss': 0.4683557311693827} | train loss {'Reaction outcome loss': 0.2925177126991279, 'Total loss': 0.2925177126991279}
2023-01-04 04:41:09,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:09,917 INFO:     Epoch: 27
2023-01-04 04:41:11,522 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4773397276798884, 'Total loss': 0.4773397276798884} | train loss {'Reaction outcome loss': 0.285564247775229, 'Total loss': 0.285564247775229}
2023-01-04 04:41:11,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:11,522 INFO:     Epoch: 28
2023-01-04 04:41:13,113 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46809443334738415, 'Total loss': 0.46809443334738415} | train loss {'Reaction outcome loss': 0.28398941967896174, 'Total loss': 0.28398941967896174}
2023-01-04 04:41:13,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:13,113 INFO:     Epoch: 29
2023-01-04 04:41:14,696 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4793195088704427, 'Total loss': 0.4793195088704427} | train loss {'Reaction outcome loss': 0.2806654986502574, 'Total loss': 0.2806654986502574}
2023-01-04 04:41:14,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:14,696 INFO:     Epoch: 30
2023-01-04 04:41:16,291 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46951179107030233, 'Total loss': 0.46951179107030233} | train loss {'Reaction outcome loss': 0.27772924879673816, 'Total loss': 0.27772924879673816}
2023-01-04 04:41:16,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:16,291 INFO:     Epoch: 31
2023-01-04 04:41:17,886 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47676676015059155, 'Total loss': 0.47676676015059155} | train loss {'Reaction outcome loss': 0.27529236399847, 'Total loss': 0.27529236399847}
2023-01-04 04:41:17,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:17,887 INFO:     Epoch: 32
2023-01-04 04:41:19,482 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4767694433530172, 'Total loss': 0.4767694433530172} | train loss {'Reaction outcome loss': 0.2732067054232597, 'Total loss': 0.2732067054232597}
2023-01-04 04:41:19,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:19,482 INFO:     Epoch: 33
2023-01-04 04:41:21,061 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45521502047777174, 'Total loss': 0.45521502047777174} | train loss {'Reaction outcome loss': 0.2691408974874387, 'Total loss': 0.2691408974874387}
2023-01-04 04:41:21,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:21,061 INFO:     Epoch: 34
2023-01-04 04:41:22,650 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46720433632532754, 'Total loss': 0.46720433632532754} | train loss {'Reaction outcome loss': 0.2650210520297296, 'Total loss': 0.2650210520297296}
2023-01-04 04:41:22,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:22,650 INFO:     Epoch: 35
2023-01-04 04:41:24,276 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4833559234937032, 'Total loss': 0.4833559234937032} | train loss {'Reaction outcome loss': 0.2618238069952223, 'Total loss': 0.2618238069952223}
2023-01-04 04:41:24,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:24,277 INFO:     Epoch: 36
2023-01-04 04:41:25,884 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4670651495456696, 'Total loss': 0.4670651495456696} | train loss {'Reaction outcome loss': 0.2699278279653062, 'Total loss': 0.2699278279653062}
2023-01-04 04:41:25,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:25,884 INFO:     Epoch: 37
2023-01-04 04:41:27,511 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4723153869311015, 'Total loss': 0.4723153869311015} | train loss {'Reaction outcome loss': 0.26495607575550134, 'Total loss': 0.26495607575550134}
2023-01-04 04:41:27,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:27,512 INFO:     Epoch: 38
2023-01-04 04:41:29,130 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.467460032304128, 'Total loss': 0.467460032304128} | train loss {'Reaction outcome loss': 0.25551955871607945, 'Total loss': 0.25551955871607945}
2023-01-04 04:41:29,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:29,130 INFO:     Epoch: 39
2023-01-04 04:41:30,725 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45329599479834237, 'Total loss': 0.45329599479834237} | train loss {'Reaction outcome loss': 0.2534003557283707, 'Total loss': 0.2534003557283707}
2023-01-04 04:41:30,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:30,726 INFO:     Epoch: 40
2023-01-04 04:41:32,322 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4509058882792791, 'Total loss': 0.4509058882792791} | train loss {'Reaction outcome loss': 0.24949378441163825, 'Total loss': 0.24949378441163825}
2023-01-04 04:41:32,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:32,322 INFO:     Epoch: 41
2023-01-04 04:41:33,948 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45928123394648235, 'Total loss': 0.45928123394648235} | train loss {'Reaction outcome loss': 0.24585259119993536, 'Total loss': 0.24585259119993536}
2023-01-04 04:41:33,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:33,948 INFO:     Epoch: 42
2023-01-04 04:41:35,543 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4438895801703135, 'Total loss': 0.4438895801703135} | train loss {'Reaction outcome loss': 0.24849620666709202, 'Total loss': 0.24849620666709202}
2023-01-04 04:41:35,543 INFO:     Found new best model at epoch 42
2023-01-04 04:41:35,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:35,544 INFO:     Epoch: 43
2023-01-04 04:41:37,162 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4842264294624329, 'Total loss': 0.4842264294624329} | train loss {'Reaction outcome loss': 0.2424277126505647, 'Total loss': 0.2424277126505647}
2023-01-04 04:41:37,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:37,162 INFO:     Epoch: 44
2023-01-04 04:41:38,753 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4688322007656097, 'Total loss': 0.4688322007656097} | train loss {'Reaction outcome loss': 0.24471053446957713, 'Total loss': 0.24471053446957713}
2023-01-04 04:41:38,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:38,753 INFO:     Epoch: 45
2023-01-04 04:41:40,322 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45627673467000324, 'Total loss': 0.45627673467000324} | train loss {'Reaction outcome loss': 0.2399341450532581, 'Total loss': 0.2399341450532581}
2023-01-04 04:41:40,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:40,323 INFO:     Epoch: 46
2023-01-04 04:41:41,926 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4451038708289464, 'Total loss': 0.4451038708289464} | train loss {'Reaction outcome loss': 0.236086332579388, 'Total loss': 0.236086332579388}
2023-01-04 04:41:41,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:41,926 INFO:     Epoch: 47
2023-01-04 04:41:43,537 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4595879058043162, 'Total loss': 0.4595879058043162} | train loss {'Reaction outcome loss': 0.2366698256869247, 'Total loss': 0.2366698256869247}
2023-01-04 04:41:43,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:43,538 INFO:     Epoch: 48
2023-01-04 04:41:45,141 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4533746639887492, 'Total loss': 0.4533746639887492} | train loss {'Reaction outcome loss': 0.23612046143890716, 'Total loss': 0.23612046143890716}
2023-01-04 04:41:45,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:45,141 INFO:     Epoch: 49
2023-01-04 04:41:46,764 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46348903576533, 'Total loss': 0.46348903576533} | train loss {'Reaction outcome loss': 0.23165537318066304, 'Total loss': 0.23165537318066304}
2023-01-04 04:41:46,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:46,764 INFO:     Epoch: 50
2023-01-04 04:41:48,350 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4629391411940257, 'Total loss': 0.4629391411940257} | train loss {'Reaction outcome loss': 0.23099640638068103, 'Total loss': 0.23099640638068103}
2023-01-04 04:41:48,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:48,351 INFO:     Epoch: 51
2023-01-04 04:41:49,954 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4524215131998062, 'Total loss': 0.4524215131998062} | train loss {'Reaction outcome loss': 0.24104447630436523, 'Total loss': 0.24104447630436523}
2023-01-04 04:41:49,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:49,954 INFO:     Epoch: 52
2023-01-04 04:41:51,581 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.442232221364975, 'Total loss': 0.442232221364975} | train loss {'Reaction outcome loss': 0.24782591821976763, 'Total loss': 0.24782591821976763}
2023-01-04 04:41:51,582 INFO:     Found new best model at epoch 52
2023-01-04 04:41:51,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:51,582 INFO:     Epoch: 53
2023-01-04 04:41:53,186 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46355500221252444, 'Total loss': 0.46355500221252444} | train loss {'Reaction outcome loss': 0.22886868030375002, 'Total loss': 0.22886868030375002}
2023-01-04 04:41:53,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:53,186 INFO:     Epoch: 54
2023-01-04 04:41:54,814 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4342516303062439, 'Total loss': 0.4342516303062439} | train loss {'Reaction outcome loss': 0.22044410205104953, 'Total loss': 0.22044410205104953}
2023-01-04 04:41:54,815 INFO:     Found new best model at epoch 54
2023-01-04 04:41:54,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:54,816 INFO:     Epoch: 55
2023-01-04 04:41:56,432 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46000692049662273, 'Total loss': 0.46000692049662273} | train loss {'Reaction outcome loss': 0.2292330883429858, 'Total loss': 0.2292330883429858}
2023-01-04 04:41:56,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:56,433 INFO:     Epoch: 56
2023-01-04 04:41:58,011 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4524991055329641, 'Total loss': 0.4524991055329641} | train loss {'Reaction outcome loss': 0.23362605396212768, 'Total loss': 0.23362605396212768}
2023-01-04 04:41:58,011 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:58,011 INFO:     Epoch: 57
2023-01-04 04:41:59,608 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4862004746993383, 'Total loss': 0.4862004746993383} | train loss {'Reaction outcome loss': 0.2150447760057801, 'Total loss': 0.2150447760057801}
2023-01-04 04:41:59,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:41:59,609 INFO:     Epoch: 58
2023-01-04 04:42:01,236 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4629703541596731, 'Total loss': 0.4629703541596731} | train loss {'Reaction outcome loss': 0.2138041876276712, 'Total loss': 0.2138041876276712}
2023-01-04 04:42:01,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:01,237 INFO:     Epoch: 59
2023-01-04 04:42:02,864 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47114647428194684, 'Total loss': 0.47114647428194684} | train loss {'Reaction outcome loss': 0.21113907769124152, 'Total loss': 0.21113907769124152}
2023-01-04 04:42:02,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:02,864 INFO:     Epoch: 60
2023-01-04 04:42:04,482 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46620737661918005, 'Total loss': 0.46620737661918005} | train loss {'Reaction outcome loss': 0.209754518678233, 'Total loss': 0.209754518678233}
2023-01-04 04:42:04,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:04,482 INFO:     Epoch: 61
2023-01-04 04:42:06,088 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47019129792849224, 'Total loss': 0.47019129792849224} | train loss {'Reaction outcome loss': 0.21189901709178652, 'Total loss': 0.21189901709178652}
2023-01-04 04:42:06,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:06,089 INFO:     Epoch: 62
2023-01-04 04:42:07,675 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4889034926891327, 'Total loss': 0.4889034926891327} | train loss {'Reaction outcome loss': 0.21026300351418878, 'Total loss': 0.21026300351418878}
2023-01-04 04:42:07,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:07,675 INFO:     Epoch: 63
2023-01-04 04:42:09,285 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4626576582590739, 'Total loss': 0.4626576582590739} | train loss {'Reaction outcome loss': 0.21740576225346414, 'Total loss': 0.21740576225346414}
2023-01-04 04:42:09,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:09,285 INFO:     Epoch: 64
2023-01-04 04:42:10,885 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4642095774412155, 'Total loss': 0.4642095774412155} | train loss {'Reaction outcome loss': 0.21674367721003573, 'Total loss': 0.21674367721003573}
2023-01-04 04:42:10,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:10,885 INFO:     Epoch: 65
2023-01-04 04:42:12,483 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46701637506484983, 'Total loss': 0.46701637506484983} | train loss {'Reaction outcome loss': 0.20685835175925973, 'Total loss': 0.20685835175925973}
2023-01-04 04:42:12,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:12,483 INFO:     Epoch: 66
2023-01-04 04:42:14,080 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4596683780352275, 'Total loss': 0.4596683780352275} | train loss {'Reaction outcome loss': 0.20263621763609516, 'Total loss': 0.20263621763609516}
2023-01-04 04:42:14,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:14,081 INFO:     Epoch: 67
2023-01-04 04:42:15,674 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.515543532371521, 'Total loss': 0.515543532371521} | train loss {'Reaction outcome loss': 0.2035538326683994, 'Total loss': 0.2035538326683994}
2023-01-04 04:42:15,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:15,674 INFO:     Epoch: 68
2023-01-04 04:42:17,280 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4792394777139028, 'Total loss': 0.4792394777139028} | train loss {'Reaction outcome loss': 0.2033660100109494, 'Total loss': 0.2033660100109494}
2023-01-04 04:42:17,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:17,280 INFO:     Epoch: 69
2023-01-04 04:42:18,945 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44688320557276406, 'Total loss': 0.44688320557276406} | train loss {'Reaction outcome loss': 0.20042601145088565, 'Total loss': 0.20042601145088565}
2023-01-04 04:42:18,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:18,946 INFO:     Epoch: 70
2023-01-04 04:42:20,616 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4759407142798106, 'Total loss': 0.4759407142798106} | train loss {'Reaction outcome loss': 0.201879667158684, 'Total loss': 0.201879667158684}
2023-01-04 04:42:20,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:20,616 INFO:     Epoch: 71
2023-01-04 04:42:22,282 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46663139561812084, 'Total loss': 0.46663139561812084} | train loss {'Reaction outcome loss': 0.20456461103606052, 'Total loss': 0.20456461103606052}
2023-01-04 04:42:22,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:22,283 INFO:     Epoch: 72
2023-01-04 04:42:23,922 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4730763892332713, 'Total loss': 0.4730763892332713} | train loss {'Reaction outcome loss': 0.19703186448094895, 'Total loss': 0.19703186448094895}
2023-01-04 04:42:23,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:23,922 INFO:     Epoch: 73
2023-01-04 04:42:25,509 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4818663775920868, 'Total loss': 0.4818663775920868} | train loss {'Reaction outcome loss': 0.196234506303512, 'Total loss': 0.196234506303512}
2023-01-04 04:42:25,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:25,510 INFO:     Epoch: 74
2023-01-04 04:42:27,137 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47434107065200803, 'Total loss': 0.47434107065200803} | train loss {'Reaction outcome loss': 0.19877342702955872, 'Total loss': 0.19877342702955872}
2023-01-04 04:42:27,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:27,138 INFO:     Epoch: 75
2023-01-04 04:42:28,736 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47086115876833595, 'Total loss': 0.47086115876833595} | train loss {'Reaction outcome loss': 0.19730186061528715, 'Total loss': 0.19730186061528715}
2023-01-04 04:42:28,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:28,736 INFO:     Epoch: 76
2023-01-04 04:42:30,368 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4814196914434433, 'Total loss': 0.4814196914434433} | train loss {'Reaction outcome loss': 0.20155048248884472, 'Total loss': 0.20155048248884472}
2023-01-04 04:42:30,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:30,368 INFO:     Epoch: 77
2023-01-04 04:42:31,970 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49115545948346456, 'Total loss': 0.49115545948346456} | train loss {'Reaction outcome loss': 0.19256609144951284, 'Total loss': 0.19256609144951284}
2023-01-04 04:42:31,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:31,971 INFO:     Epoch: 78
2023-01-04 04:42:33,571 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5002646724383036, 'Total loss': 0.5002646724383036} | train loss {'Reaction outcome loss': 0.1920186196516295, 'Total loss': 0.1920186196516295}
2023-01-04 04:42:33,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:33,571 INFO:     Epoch: 79
2023-01-04 04:42:35,156 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4570106695095698, 'Total loss': 0.4570106695095698} | train loss {'Reaction outcome loss': 0.1884354281451585, 'Total loss': 0.1884354281451585}
2023-01-04 04:42:35,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:35,156 INFO:     Epoch: 80
2023-01-04 04:42:36,752 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.461679482460022, 'Total loss': 0.461679482460022} | train loss {'Reaction outcome loss': 0.19525245971221855, 'Total loss': 0.19525245971221855}
2023-01-04 04:42:36,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:36,752 INFO:     Epoch: 81
2023-01-04 04:42:38,348 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5015968183676401, 'Total loss': 0.5015968183676401} | train loss {'Reaction outcome loss': 0.19645373138558606, 'Total loss': 0.19645373138558606}
2023-01-04 04:42:38,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:38,348 INFO:     Epoch: 82
2023-01-04 04:42:39,945 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46241762588421503, 'Total loss': 0.46241762588421503} | train loss {'Reaction outcome loss': 0.18927504447545263, 'Total loss': 0.18927504447545263}
2023-01-04 04:42:39,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:39,945 INFO:     Epoch: 83
2023-01-04 04:42:41,542 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4928394556045532, 'Total loss': 0.4928394556045532} | train loss {'Reaction outcome loss': 0.18922246137525942, 'Total loss': 0.18922246137525942}
2023-01-04 04:42:41,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:41,542 INFO:     Epoch: 84
2023-01-04 04:42:43,130 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47370651761690774, 'Total loss': 0.47370651761690774} | train loss {'Reaction outcome loss': 0.1958999190196071, 'Total loss': 0.1958999190196071}
2023-01-04 04:42:43,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:43,130 INFO:     Epoch: 85
2023-01-04 04:42:44,759 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47929622530937194, 'Total loss': 0.47929622530937194} | train loss {'Reaction outcome loss': 0.18363536034978123, 'Total loss': 0.18363536034978123}
2023-01-04 04:42:44,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:44,760 INFO:     Epoch: 86
2023-01-04 04:42:46,355 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45218844413757325, 'Total loss': 0.45218844413757325} | train loss {'Reaction outcome loss': 0.18498533327183922, 'Total loss': 0.18498533327183922}
2023-01-04 04:42:46,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:46,355 INFO:     Epoch: 87
2023-01-04 04:42:47,951 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44659947156906127, 'Total loss': 0.44659947156906127} | train loss {'Reaction outcome loss': 0.1832574625108121, 'Total loss': 0.1832574625108121}
2023-01-04 04:42:47,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:47,951 INFO:     Epoch: 88
2023-01-04 04:42:49,577 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47234843373298646, 'Total loss': 0.47234843373298646} | train loss {'Reaction outcome loss': 0.1853034967606473, 'Total loss': 0.1853034967606473}
2023-01-04 04:42:49,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:49,577 INFO:     Epoch: 89
2023-01-04 04:42:51,169 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4740923225879669, 'Total loss': 0.4740923225879669} | train loss {'Reaction outcome loss': 0.1795859559923343, 'Total loss': 0.1795859559923343}
2023-01-04 04:42:51,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:51,169 INFO:     Epoch: 90
2023-01-04 04:42:52,776 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4785820404688517, 'Total loss': 0.4785820404688517} | train loss {'Reaction outcome loss': 0.181180229523781, 'Total loss': 0.181180229523781}
2023-01-04 04:42:52,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:52,776 INFO:     Epoch: 91
2023-01-04 04:42:54,410 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4739529460668564, 'Total loss': 0.4739529460668564} | train loss {'Reaction outcome loss': 0.18291506105763972, 'Total loss': 0.18291506105763972}
2023-01-04 04:42:54,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:54,410 INFO:     Epoch: 92
2023-01-04 04:42:56,033 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48414302269617715, 'Total loss': 0.48414302269617715} | train loss {'Reaction outcome loss': 0.18043536499844512, 'Total loss': 0.18043536499844512}
2023-01-04 04:42:56,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:56,035 INFO:     Epoch: 93
2023-01-04 04:42:57,631 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46640002727508545, 'Total loss': 0.46640002727508545} | train loss {'Reaction outcome loss': 0.1754888234477814, 'Total loss': 0.1754888234477814}
2023-01-04 04:42:57,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:57,631 INFO:     Epoch: 94
2023-01-04 04:42:59,252 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44908386121193566, 'Total loss': 0.44908386121193566} | train loss {'Reaction outcome loss': 0.17875481850553668, 'Total loss': 0.17875481850553668}
2023-01-04 04:42:59,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:42:59,253 INFO:     Epoch: 95
2023-01-04 04:43:00,856 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47788206934928895, 'Total loss': 0.47788206934928895} | train loss {'Reaction outcome loss': 0.17786952948243698, 'Total loss': 0.17786952948243698}
2023-01-04 04:43:00,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:00,856 INFO:     Epoch: 96
2023-01-04 04:43:02,458 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47599840760231016, 'Total loss': 0.47599840760231016} | train loss {'Reaction outcome loss': 0.17672046783137257, 'Total loss': 0.17672046783137257}
2023-01-04 04:43:02,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:02,459 INFO:     Epoch: 97
2023-01-04 04:43:04,092 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49727123181025185, 'Total loss': 0.49727123181025185} | train loss {'Reaction outcome loss': 0.1766110605478415, 'Total loss': 0.1766110605478415}
2023-01-04 04:43:04,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:04,092 INFO:     Epoch: 98
2023-01-04 04:43:05,717 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48878448208173114, 'Total loss': 0.48878448208173114} | train loss {'Reaction outcome loss': 0.17273580916962997, 'Total loss': 0.17273580916962997}
2023-01-04 04:43:05,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:05,718 INFO:     Epoch: 99
2023-01-04 04:43:07,314 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5210428953170776, 'Total loss': 0.5210428953170776} | train loss {'Reaction outcome loss': 0.17326384811135737, 'Total loss': 0.17326384811135737}
2023-01-04 04:43:07,314 INFO:     Best model found after epoch 55 of 100.
2023-01-04 04:43:07,314 INFO:   Done with stage: TRAINING
2023-01-04 04:43:07,314 INFO:   Starting stage: EVALUATION
2023-01-04 04:43:07,444 INFO:   Done with stage: EVALUATION
2023-01-04 04:43:07,452 INFO:   Leaving out SEQ value Fold_0
2023-01-04 04:43:07,465 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 04:43:07,465 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:43:08,104 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:43:08,104 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:43:08,170 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:43:08,170 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:43:08,170 INFO:     No hyperparam tuning for this model
2023-01-04 04:43:08,170 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:43:08,170 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:43:08,171 INFO:     None feature selector for col prot
2023-01-04 04:43:08,171 INFO:     None feature selector for col prot
2023-01-04 04:43:08,171 INFO:     None feature selector for col prot
2023-01-04 04:43:08,172 INFO:     None feature selector for col chem
2023-01-04 04:43:08,172 INFO:     None feature selector for col chem
2023-01-04 04:43:08,172 INFO:     None feature selector for col chem
2023-01-04 04:43:08,172 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:43:08,172 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:43:08,173 INFO:     Number of params in model 70141
2023-01-04 04:43:08,176 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:43:08,176 INFO:   Starting stage: TRAINING
2023-01-04 04:43:08,219 INFO:     Val loss before train {'Reaction outcome loss': 0.9550002257029215, 'Total loss': 0.9550002257029215}
2023-01-04 04:43:08,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:08,220 INFO:     Epoch: 0
2023-01-04 04:43:09,802 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5949782848358154, 'Total loss': 0.5949782848358154} | train loss {'Reaction outcome loss': 0.8454045356419694, 'Total loss': 0.8454045356419694}
2023-01-04 04:43:09,802 INFO:     Found new best model at epoch 0
2023-01-04 04:43:09,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:09,803 INFO:     Epoch: 1
2023-01-04 04:43:11,371 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4847494582335154, 'Total loss': 0.4847494582335154} | train loss {'Reaction outcome loss': 0.5881734095046441, 'Total loss': 0.5881734095046441}
2023-01-04 04:43:11,372 INFO:     Found new best model at epoch 1
2023-01-04 04:43:11,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:11,372 INFO:     Epoch: 2
2023-01-04 04:43:12,928 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46680641869703926, 'Total loss': 0.46680641869703926} | train loss {'Reaction outcome loss': 0.5162668545967538, 'Total loss': 0.5162668545967538}
2023-01-04 04:43:12,928 INFO:     Found new best model at epoch 2
2023-01-04 04:43:12,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:12,929 INFO:     Epoch: 3
2023-01-04 04:43:14,483 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4607882638772329, 'Total loss': 0.4607882638772329} | train loss {'Reaction outcome loss': 0.47737190209851493, 'Total loss': 0.47737190209851493}
2023-01-04 04:43:14,483 INFO:     Found new best model at epoch 3
2023-01-04 04:43:14,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:14,484 INFO:     Epoch: 4
2023-01-04 04:43:16,073 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4034044076999029, 'Total loss': 0.4034044076999029} | train loss {'Reaction outcome loss': 0.4510723376626018, 'Total loss': 0.4510723376626018}
2023-01-04 04:43:16,073 INFO:     Found new best model at epoch 4
2023-01-04 04:43:16,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:16,074 INFO:     Epoch: 5
2023-01-04 04:43:17,649 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3817150364319483, 'Total loss': 0.3817150364319483} | train loss {'Reaction outcome loss': 0.42792920988204297, 'Total loss': 0.42792920988204297}
2023-01-04 04:43:17,649 INFO:     Found new best model at epoch 5
2023-01-04 04:43:17,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:17,650 INFO:     Epoch: 6
2023-01-04 04:43:19,225 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3840504671136538, 'Total loss': 0.3840504671136538} | train loss {'Reaction outcome loss': 0.41341217192116697, 'Total loss': 0.41341217192116697}
2023-01-04 04:43:19,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:19,225 INFO:     Epoch: 7
2023-01-04 04:43:20,827 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41860974033673604, 'Total loss': 0.41860974033673604} | train loss {'Reaction outcome loss': 0.39997901135155195, 'Total loss': 0.39997901135155195}
2023-01-04 04:43:20,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:20,827 INFO:     Epoch: 8
2023-01-04 04:43:22,412 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38364962140719094, 'Total loss': 0.38364962140719094} | train loss {'Reaction outcome loss': 0.38994231597413875, 'Total loss': 0.38994231597413875}
2023-01-04 04:43:22,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:22,413 INFO:     Epoch: 9
2023-01-04 04:43:24,009 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.38953816294670107, 'Total loss': 0.38953816294670107} | train loss {'Reaction outcome loss': 0.3748495193040239, 'Total loss': 0.3748495193040239}
2023-01-04 04:43:24,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:24,010 INFO:     Epoch: 10
2023-01-04 04:43:25,604 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3614968667427699, 'Total loss': 0.3614968667427699} | train loss {'Reaction outcome loss': 0.3687774939565641, 'Total loss': 0.3687774939565641}
2023-01-04 04:43:25,604 INFO:     Found new best model at epoch 10
2023-01-04 04:43:25,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:25,605 INFO:     Epoch: 11
2023-01-04 04:43:27,182 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38665608167648313, 'Total loss': 0.38665608167648313} | train loss {'Reaction outcome loss': 0.35788240091277224, 'Total loss': 0.35788240091277224}
2023-01-04 04:43:27,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:27,182 INFO:     Epoch: 12
2023-01-04 04:43:28,735 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41698810656865437, 'Total loss': 0.41698810656865437} | train loss {'Reaction outcome loss': 0.3522392610892159, 'Total loss': 0.3522392610892159}
2023-01-04 04:43:28,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:28,735 INFO:     Epoch: 13
2023-01-04 04:43:30,309 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3581544478734334, 'Total loss': 0.3581544478734334} | train loss {'Reaction outcome loss': 0.3416609115266272, 'Total loss': 0.3416609115266272}
2023-01-04 04:43:30,310 INFO:     Found new best model at epoch 13
2023-01-04 04:43:30,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:30,310 INFO:     Epoch: 14
2023-01-04 04:43:31,881 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.34456765552361807, 'Total loss': 0.34456765552361807} | train loss {'Reaction outcome loss': 0.334385968002446, 'Total loss': 0.334385968002446}
2023-01-04 04:43:31,882 INFO:     Found new best model at epoch 14
2023-01-04 04:43:31,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:31,883 INFO:     Epoch: 15
2023-01-04 04:43:33,456 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3611979494492213, 'Total loss': 0.3611979494492213} | train loss {'Reaction outcome loss': 0.32535463750252425, 'Total loss': 0.32535463750252425}
2023-01-04 04:43:33,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:33,456 INFO:     Epoch: 16
2023-01-04 04:43:35,030 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.34055991321802137, 'Total loss': 0.34055991321802137} | train loss {'Reaction outcome loss': 0.31960171348384386, 'Total loss': 0.31960171348384386}
2023-01-04 04:43:35,030 INFO:     Found new best model at epoch 16
2023-01-04 04:43:35,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:35,031 INFO:     Epoch: 17
2023-01-04 04:43:36,575 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.34199866726994516, 'Total loss': 0.34199866726994516} | train loss {'Reaction outcome loss': 0.3151027184680819, 'Total loss': 0.3151027184680819}
2023-01-04 04:43:36,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:36,575 INFO:     Epoch: 18
2023-01-04 04:43:38,149 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3414842495073875, 'Total loss': 0.3414842495073875} | train loss {'Reaction outcome loss': 0.30870545377810504, 'Total loss': 0.30870545377810504}
2023-01-04 04:43:38,150 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:38,150 INFO:     Epoch: 19
2023-01-04 04:43:39,752 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3374772349993388, 'Total loss': 0.3374772349993388} | train loss {'Reaction outcome loss': 0.30079749693949726, 'Total loss': 0.30079749693949726}
2023-01-04 04:43:39,752 INFO:     Found new best model at epoch 19
2023-01-04 04:43:39,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:39,753 INFO:     Epoch: 20
2023-01-04 04:43:41,358 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.34998529553413393, 'Total loss': 0.34998529553413393} | train loss {'Reaction outcome loss': 0.29769623188844907, 'Total loss': 0.29769623188844907}
2023-01-04 04:43:41,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:41,359 INFO:     Epoch: 21
2023-01-04 04:43:42,967 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3490343411763509, 'Total loss': 0.3490343411763509} | train loss {'Reaction outcome loss': 0.29227544034649083, 'Total loss': 0.29227544034649083}
2023-01-04 04:43:42,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:42,967 INFO:     Epoch: 22
2023-01-04 04:43:44,523 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.347094789147377, 'Total loss': 0.347094789147377} | train loss {'Reaction outcome loss': 0.28764221558821595, 'Total loss': 0.28764221558821595}
2023-01-04 04:43:44,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:44,523 INFO:     Epoch: 23
2023-01-04 04:43:46,067 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3293016349275907, 'Total loss': 0.3293016349275907} | train loss {'Reaction outcome loss': 0.28241771126915166, 'Total loss': 0.28241771126915166}
2023-01-04 04:43:46,068 INFO:     Found new best model at epoch 23
2023-01-04 04:43:46,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:46,068 INFO:     Epoch: 24
2023-01-04 04:43:47,630 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3454479783773422, 'Total loss': 0.3454479783773422} | train loss {'Reaction outcome loss': 0.2786775066128956, 'Total loss': 0.2786775066128956}
2023-01-04 04:43:47,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:47,630 INFO:     Epoch: 25
2023-01-04 04:43:49,205 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3446994464844465, 'Total loss': 0.3446994464844465} | train loss {'Reaction outcome loss': 0.2722487376102442, 'Total loss': 0.2722487376102442}
2023-01-04 04:43:49,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:49,205 INFO:     Epoch: 26
2023-01-04 04:43:50,776 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3509218543767929, 'Total loss': 0.3509218543767929} | train loss {'Reaction outcome loss': 0.2677821269004547, 'Total loss': 0.2677821269004547}
2023-01-04 04:43:50,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:50,777 INFO:     Epoch: 27
2023-01-04 04:43:52,351 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3420956869920095, 'Total loss': 0.3420956869920095} | train loss {'Reaction outcome loss': 0.26534133803140636, 'Total loss': 0.26534133803140636}
2023-01-04 04:43:52,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:52,351 INFO:     Epoch: 28
2023-01-04 04:43:53,901 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3212758739789327, 'Total loss': 0.3212758739789327} | train loss {'Reaction outcome loss': 0.26360104483212055, 'Total loss': 0.26360104483212055}
2023-01-04 04:43:53,902 INFO:     Found new best model at epoch 28
2023-01-04 04:43:53,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:53,902 INFO:     Epoch: 29
2023-01-04 04:43:55,434 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3534397860368093, 'Total loss': 0.3534397860368093} | train loss {'Reaction outcome loss': 0.25816525446037963, 'Total loss': 0.25816525446037963}
2023-01-04 04:43:55,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:55,434 INFO:     Epoch: 30
2023-01-04 04:43:57,018 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.33981147557497027, 'Total loss': 0.33981147557497027} | train loss {'Reaction outcome loss': 0.2527579210176239, 'Total loss': 0.2527579210176239}
2023-01-04 04:43:57,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:57,018 INFO:     Epoch: 31
2023-01-04 04:43:58,612 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.32469855348269144, 'Total loss': 0.32469855348269144} | train loss {'Reaction outcome loss': 0.24982725118194118, 'Total loss': 0.24982725118194118}
2023-01-04 04:43:58,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:43:58,612 INFO:     Epoch: 32
2023-01-04 04:44:00,203 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.32881198078393936, 'Total loss': 0.32881198078393936} | train loss {'Reaction outcome loss': 0.24856152324988834, 'Total loss': 0.24856152324988834}
2023-01-04 04:44:00,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:00,203 INFO:     Epoch: 33
2023-01-04 04:44:01,801 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3427671492099762, 'Total loss': 0.3427671492099762} | train loss {'Reaction outcome loss': 0.24561093887829694, 'Total loss': 0.24561093887829694}
2023-01-04 04:44:01,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:01,801 INFO:     Epoch: 34
2023-01-04 04:44:03,356 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.34688755770524343, 'Total loss': 0.34688755770524343} | train loss {'Reaction outcome loss': 0.2408936227022282, 'Total loss': 0.2408936227022282}
2023-01-04 04:44:03,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:03,357 INFO:     Epoch: 35
2023-01-04 04:44:04,925 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.32342456007997195, 'Total loss': 0.32342456007997195} | train loss {'Reaction outcome loss': 0.23904705990614486, 'Total loss': 0.23904705990614486}
2023-01-04 04:44:04,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:04,925 INFO:     Epoch: 36
2023-01-04 04:44:06,525 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3341787119706472, 'Total loss': 0.3341787119706472} | train loss {'Reaction outcome loss': 0.23774344732510647, 'Total loss': 0.23774344732510647}
2023-01-04 04:44:06,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:06,526 INFO:     Epoch: 37
2023-01-04 04:44:08,123 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.35868071516354877, 'Total loss': 0.35868071516354877} | train loss {'Reaction outcome loss': 0.23307769396428252, 'Total loss': 0.23307769396428252}
2023-01-04 04:44:08,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:08,124 INFO:     Epoch: 38
2023-01-04 04:44:09,684 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.32855309049288434, 'Total loss': 0.32855309049288434} | train loss {'Reaction outcome loss': 0.23068497056395806, 'Total loss': 0.23068497056395806}
2023-01-04 04:44:09,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:09,685 INFO:     Epoch: 39
2023-01-04 04:44:11,263 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.31476432681083677, 'Total loss': 0.31476432681083677} | train loss {'Reaction outcome loss': 0.2271769474298312, 'Total loss': 0.2271769474298312}
2023-01-04 04:44:11,263 INFO:     Found new best model at epoch 39
2023-01-04 04:44:11,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:11,264 INFO:     Epoch: 40
2023-01-04 04:44:12,821 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3646368304888407, 'Total loss': 0.3646368304888407} | train loss {'Reaction outcome loss': 0.22783578554257697, 'Total loss': 0.22783578554257697}
2023-01-04 04:44:12,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:12,821 INFO:     Epoch: 41
2023-01-04 04:44:14,378 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3270426243543625, 'Total loss': 0.3270426243543625} | train loss {'Reaction outcome loss': 0.2249035788528154, 'Total loss': 0.2249035788528154}
2023-01-04 04:44:14,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:14,379 INFO:     Epoch: 42
2023-01-04 04:44:15,951 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33314573764801025, 'Total loss': 0.33314573764801025} | train loss {'Reaction outcome loss': 0.21997939472213882, 'Total loss': 0.21997939472213882}
2023-01-04 04:44:15,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:15,952 INFO:     Epoch: 43
2023-01-04 04:44:17,524 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.32363453606764475, 'Total loss': 0.32363453606764475} | train loss {'Reaction outcome loss': 0.2173811055142501, 'Total loss': 0.2173811055142501}
2023-01-04 04:44:17,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:17,524 INFO:     Epoch: 44
2023-01-04 04:44:19,096 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3626703768968582, 'Total loss': 0.3626703768968582} | train loss {'Reaction outcome loss': 0.21601590345101604, 'Total loss': 0.21601590345101604}
2023-01-04 04:44:19,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:19,096 INFO:     Epoch: 45
2023-01-04 04:44:20,652 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.34542686144510903, 'Total loss': 0.34542686144510903} | train loss {'Reaction outcome loss': 0.21396578440092145, 'Total loss': 0.21396578440092145}
2023-01-04 04:44:20,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:20,652 INFO:     Epoch: 46
2023-01-04 04:44:22,222 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34958912382523216, 'Total loss': 0.34958912382523216} | train loss {'Reaction outcome loss': 0.21079053790256985, 'Total loss': 0.21079053790256985}
2023-01-04 04:44:22,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:22,223 INFO:     Epoch: 47
2023-01-04 04:44:23,816 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3397227466106415, 'Total loss': 0.3397227466106415} | train loss {'Reaction outcome loss': 0.20994345105607132, 'Total loss': 0.20994345105607132}
2023-01-04 04:44:23,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:23,816 INFO:     Epoch: 48
2023-01-04 04:44:25,411 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.34389595985412597, 'Total loss': 0.34389595985412597} | train loss {'Reaction outcome loss': 0.2101037170449306, 'Total loss': 0.2101037170449306}
2023-01-04 04:44:25,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:25,411 INFO:     Epoch: 49
2023-01-04 04:44:27,004 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.33464307884375255, 'Total loss': 0.33464307884375255} | train loss {'Reaction outcome loss': 0.2060873570999756, 'Total loss': 0.2060873570999756}
2023-01-04 04:44:27,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:27,005 INFO:     Epoch: 50
2023-01-04 04:44:28,602 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38403796404600143, 'Total loss': 0.38403796404600143} | train loss {'Reaction outcome loss': 0.20436648217569417, 'Total loss': 0.20436648217569417}
2023-01-04 04:44:28,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:28,602 INFO:     Epoch: 51
2023-01-04 04:44:30,175 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3405500849088033, 'Total loss': 0.3405500849088033} | train loss {'Reaction outcome loss': 0.20368336909536505, 'Total loss': 0.20368336909536505}
2023-01-04 04:44:30,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:30,175 INFO:     Epoch: 52
2023-01-04 04:44:31,740 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3616743271549543, 'Total loss': 0.3616743271549543} | train loss {'Reaction outcome loss': 0.20110099693945854, 'Total loss': 0.20110099693945854}
2023-01-04 04:44:31,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:31,740 INFO:     Epoch: 53
2023-01-04 04:44:33,363 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3801602214574814, 'Total loss': 0.3801602214574814} | train loss {'Reaction outcome loss': 0.19943582865914736, 'Total loss': 0.19943582865914736}
2023-01-04 04:44:33,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:33,364 INFO:     Epoch: 54
2023-01-04 04:44:34,985 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.33083277692397434, 'Total loss': 0.33083277692397434} | train loss {'Reaction outcome loss': 0.19966440055368131, 'Total loss': 0.19966440055368131}
2023-01-04 04:44:34,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:34,985 INFO:     Epoch: 55
2023-01-04 04:44:36,607 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3458709513147672, 'Total loss': 0.3458709513147672} | train loss {'Reaction outcome loss': 0.1959196322037395, 'Total loss': 0.1959196322037395}
2023-01-04 04:44:36,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:36,607 INFO:     Epoch: 56
2023-01-04 04:44:38,224 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.360186626513799, 'Total loss': 0.360186626513799} | train loss {'Reaction outcome loss': 0.19393194068182, 'Total loss': 0.19393194068182}
2023-01-04 04:44:38,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:38,225 INFO:     Epoch: 57
2023-01-04 04:44:39,779 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36535620292027793, 'Total loss': 0.36535620292027793} | train loss {'Reaction outcome loss': 0.19309600000011964, 'Total loss': 0.19309600000011964}
2023-01-04 04:44:39,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:39,780 INFO:     Epoch: 58
2023-01-04 04:44:41,332 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.33076207240422567, 'Total loss': 0.33076207240422567} | train loss {'Reaction outcome loss': 0.19291875193864658, 'Total loss': 0.19291875193864658}
2023-01-04 04:44:41,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:41,332 INFO:     Epoch: 59
2023-01-04 04:44:42,953 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35495192408561704, 'Total loss': 0.35495192408561704} | train loss {'Reaction outcome loss': 0.1915455504399604, 'Total loss': 0.1915455504399604}
2023-01-04 04:44:42,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:42,954 INFO:     Epoch: 60
2023-01-04 04:44:44,577 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.35013326704502107, 'Total loss': 0.35013326704502107} | train loss {'Reaction outcome loss': 0.1898975587446531, 'Total loss': 0.1898975587446531}
2023-01-04 04:44:44,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:44,577 INFO:     Epoch: 61
2023-01-04 04:44:46,199 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3330911695957184, 'Total loss': 0.3330911695957184} | train loss {'Reaction outcome loss': 0.19084996600872475, 'Total loss': 0.19084996600872475}
2023-01-04 04:44:46,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:46,200 INFO:     Epoch: 62
2023-01-04 04:44:47,774 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3615420391162237, 'Total loss': 0.3615420391162237} | train loss {'Reaction outcome loss': 0.18547846620208222, 'Total loss': 0.18547846620208222}
2023-01-04 04:44:47,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:47,774 INFO:     Epoch: 63
2023-01-04 04:44:49,359 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.33450123071670534, 'Total loss': 0.33450123071670534} | train loss {'Reaction outcome loss': 0.18566503259611086, 'Total loss': 0.18566503259611086}
2023-01-04 04:44:49,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:49,359 INFO:     Epoch: 64
2023-01-04 04:44:50,961 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.351283739010493, 'Total loss': 0.351283739010493} | train loss {'Reaction outcome loss': 0.18425698267000407, 'Total loss': 0.18425698267000407}
2023-01-04 04:44:50,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:50,962 INFO:     Epoch: 65
2023-01-04 04:44:52,556 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3493809883793195, 'Total loss': 0.3493809883793195} | train loss {'Reaction outcome loss': 0.185066690647844, 'Total loss': 0.185066690647844}
2023-01-04 04:44:52,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:52,556 INFO:     Epoch: 66
2023-01-04 04:44:54,157 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36787281880776085, 'Total loss': 0.36787281880776085} | train loss {'Reaction outcome loss': 0.18454194613612115, 'Total loss': 0.18454194613612115}
2023-01-04 04:44:54,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:54,157 INFO:     Epoch: 67
2023-01-04 04:44:55,709 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3553674469391505, 'Total loss': 0.3553674469391505} | train loss {'Reaction outcome loss': 0.18223466579819517, 'Total loss': 0.18223466579819517}
2023-01-04 04:44:55,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:55,709 INFO:     Epoch: 68
2023-01-04 04:44:57,283 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3461082398891449, 'Total loss': 0.3461082398891449} | train loss {'Reaction outcome loss': 0.18305626739077682, 'Total loss': 0.18305626739077682}
2023-01-04 04:44:57,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:57,284 INFO:     Epoch: 69
2023-01-04 04:44:58,852 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3587903380393982, 'Total loss': 0.3587903380393982} | train loss {'Reaction outcome loss': 0.17972363605820385, 'Total loss': 0.17972363605820385}
2023-01-04 04:44:58,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:44:58,853 INFO:     Epoch: 70
2023-01-04 04:45:00,443 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3692396402359009, 'Total loss': 0.3692396402359009} | train loss {'Reaction outcome loss': 0.18170639570816197, 'Total loss': 0.18170639570816197}
2023-01-04 04:45:00,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:00,443 INFO:     Epoch: 71
2023-01-04 04:45:02,045 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.376086562871933, 'Total loss': 0.376086562871933} | train loss {'Reaction outcome loss': 0.17761203478953055, 'Total loss': 0.17761203478953055}
2023-01-04 04:45:02,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:02,045 INFO:     Epoch: 72
2023-01-04 04:45:03,615 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3504870524009069, 'Total loss': 0.3504870524009069} | train loss {'Reaction outcome loss': 0.17496944295854147, 'Total loss': 0.17496944295854147}
2023-01-04 04:45:03,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:03,615 INFO:     Epoch: 73
2023-01-04 04:45:05,206 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3458502550919851, 'Total loss': 0.3458502550919851} | train loss {'Reaction outcome loss': 0.17731057262783562, 'Total loss': 0.17731057262783562}
2023-01-04 04:45:05,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:05,206 INFO:     Epoch: 74
2023-01-04 04:45:06,764 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36876825491587323, 'Total loss': 0.36876825491587323} | train loss {'Reaction outcome loss': 0.17578050081112948, 'Total loss': 0.17578050081112948}
2023-01-04 04:45:06,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:06,764 INFO:     Epoch: 75
2023-01-04 04:45:08,330 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.33942334732661644, 'Total loss': 0.33942334732661644} | train loss {'Reaction outcome loss': 0.17396777297105517, 'Total loss': 0.17396777297105517}
2023-01-04 04:45:08,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:08,331 INFO:     Epoch: 76
2023-01-04 04:45:09,886 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3585028648376465, 'Total loss': 0.3585028648376465} | train loss {'Reaction outcome loss': 0.17297773335706373, 'Total loss': 0.17297773335706373}
2023-01-04 04:45:09,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:09,886 INFO:     Epoch: 77
2023-01-04 04:45:11,481 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38595213492711383, 'Total loss': 0.38595213492711383} | train loss {'Reaction outcome loss': 0.17025361419053975, 'Total loss': 0.17025361419053975}
2023-01-04 04:45:11,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:11,481 INFO:     Epoch: 78
2023-01-04 04:45:13,071 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3682448258002599, 'Total loss': 0.3682448258002599} | train loss {'Reaction outcome loss': 0.17217370819616581, 'Total loss': 0.17217370819616581}
2023-01-04 04:45:13,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:13,071 INFO:     Epoch: 79
2023-01-04 04:45:14,664 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37165059596300126, 'Total loss': 0.37165059596300126} | train loss {'Reaction outcome loss': 0.16730822295610315, 'Total loss': 0.16730822295610315}
2023-01-04 04:45:14,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:14,665 INFO:     Epoch: 80
2023-01-04 04:45:16,207 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37551639080047605, 'Total loss': 0.37551639080047605} | train loss {'Reaction outcome loss': 0.16914942197336702, 'Total loss': 0.16914942197336702}
2023-01-04 04:45:16,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:16,208 INFO:     Epoch: 81
2023-01-04 04:45:17,781 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39929480453332267, 'Total loss': 0.39929480453332267} | train loss {'Reaction outcome loss': 0.16981117566188322, 'Total loss': 0.16981117566188322}
2023-01-04 04:45:17,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:17,781 INFO:     Epoch: 82
2023-01-04 04:45:19,382 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3437325502435366, 'Total loss': 0.3437325502435366} | train loss {'Reaction outcome loss': 0.1693318277679906, 'Total loss': 0.1693318277679906}
2023-01-04 04:45:19,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:19,382 INFO:     Epoch: 83
2023-01-04 04:45:20,980 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.34655992286279796, 'Total loss': 0.34655992286279796} | train loss {'Reaction outcome loss': 0.16558927778718216, 'Total loss': 0.16558927778718216}
2023-01-04 04:45:20,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:20,980 INFO:     Epoch: 84
2023-01-04 04:45:22,569 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.367975223561128, 'Total loss': 0.367975223561128} | train loss {'Reaction outcome loss': 0.16710675940110015, 'Total loss': 0.16710675940110015}
2023-01-04 04:45:22,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:22,569 INFO:     Epoch: 85
2023-01-04 04:45:24,148 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3584666927655538, 'Total loss': 0.3584666927655538} | train loss {'Reaction outcome loss': 0.16609965026296153, 'Total loss': 0.16609965026296153}
2023-01-04 04:45:24,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:24,148 INFO:     Epoch: 86
2023-01-04 04:45:25,718 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3616729140281677, 'Total loss': 0.3616729140281677} | train loss {'Reaction outcome loss': 0.16419662076058864, 'Total loss': 0.16419662076058864}
2023-01-04 04:45:25,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:25,719 INFO:     Epoch: 87
2023-01-04 04:45:27,315 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.354671569665273, 'Total loss': 0.354671569665273} | train loss {'Reaction outcome loss': 0.16467805054189974, 'Total loss': 0.16467805054189974}
2023-01-04 04:45:27,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:27,316 INFO:     Epoch: 88
2023-01-04 04:45:28,902 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.363192480802536, 'Total loss': 0.363192480802536} | train loss {'Reaction outcome loss': 0.16085918481389536, 'Total loss': 0.16085918481389536}
2023-01-04 04:45:28,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:28,903 INFO:     Epoch: 89
2023-01-04 04:45:30,502 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3563727189437486, 'Total loss': 0.3563727189437486} | train loss {'Reaction outcome loss': 0.16298753898109677, 'Total loss': 0.16298753898109677}
2023-01-04 04:45:30,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:30,502 INFO:     Epoch: 90
2023-01-04 04:45:32,094 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.355350516239802, 'Total loss': 0.355350516239802} | train loss {'Reaction outcome loss': 0.1620053673692295, 'Total loss': 0.1620053673692295}
2023-01-04 04:45:32,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:32,094 INFO:     Epoch: 91
2023-01-04 04:45:33,676 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3803713401158651, 'Total loss': 0.3803713401158651} | train loss {'Reaction outcome loss': 0.16435587669403132, 'Total loss': 0.16435587669403132}
2023-01-04 04:45:33,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:33,677 INFO:     Epoch: 92
2023-01-04 04:45:35,217 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34589660267035166, 'Total loss': 0.34589660267035166} | train loss {'Reaction outcome loss': 0.16146820568826695, 'Total loss': 0.16146820568826695}
2023-01-04 04:45:35,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:35,217 INFO:     Epoch: 93
2023-01-04 04:45:36,815 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36270908961693443, 'Total loss': 0.36270908961693443} | train loss {'Reaction outcome loss': 0.1629111115782903, 'Total loss': 0.1629111115782903}
2023-01-04 04:45:36,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:36,815 INFO:     Epoch: 94
2023-01-04 04:45:38,413 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3513604119420052, 'Total loss': 0.3513604119420052} | train loss {'Reaction outcome loss': 0.15910500128550722, 'Total loss': 0.15910500128550722}
2023-01-04 04:45:38,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:38,414 INFO:     Epoch: 95
2023-01-04 04:45:40,012 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.353691878169775, 'Total loss': 0.353691878169775} | train loss {'Reaction outcome loss': 0.16303390788938507, 'Total loss': 0.16303390788938507}
2023-01-04 04:45:40,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:40,012 INFO:     Epoch: 96
2023-01-04 04:45:41,592 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4079609384139379, 'Total loss': 0.4079609384139379} | train loss {'Reaction outcome loss': 0.1583489463613042, 'Total loss': 0.1583489463613042}
2023-01-04 04:45:41,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:41,592 INFO:     Epoch: 97
2023-01-04 04:45:43,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.34829300579925376, 'Total loss': 0.34829300579925376} | train loss {'Reaction outcome loss': 0.15726127971747264, 'Total loss': 0.15726127971747264}
2023-01-04 04:45:43,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:43,137 INFO:     Epoch: 98
2023-01-04 04:45:44,703 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34318055919526763, 'Total loss': 0.34318055919526763} | train loss {'Reaction outcome loss': 0.15804814347289364, 'Total loss': 0.15804814347289364}
2023-01-04 04:45:44,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:44,703 INFO:     Epoch: 99
2023-01-04 04:45:46,290 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37325809995333353, 'Total loss': 0.37325809995333353} | train loss {'Reaction outcome loss': 0.15702549060566068, 'Total loss': 0.15702549060566068}
2023-01-04 04:45:46,291 INFO:     Best model found after epoch 40 of 100.
2023-01-04 04:45:46,291 INFO:   Done with stage: TRAINING
2023-01-04 04:45:46,291 INFO:   Starting stage: EVALUATION
2023-01-04 04:45:46,439 INFO:   Done with stage: EVALUATION
2023-01-04 04:45:46,439 INFO:   Leaving out SEQ value Fold_1
2023-01-04 04:45:46,452 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 04:45:46,452 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:45:47,098 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:45:47,098 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:45:47,166 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:45:47,166 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:45:47,166 INFO:     No hyperparam tuning for this model
2023-01-04 04:45:47,166 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:45:47,166 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:45:47,167 INFO:     None feature selector for col prot
2023-01-04 04:45:47,167 INFO:     None feature selector for col prot
2023-01-04 04:45:47,167 INFO:     None feature selector for col prot
2023-01-04 04:45:47,168 INFO:     None feature selector for col chem
2023-01-04 04:45:47,168 INFO:     None feature selector for col chem
2023-01-04 04:45:47,168 INFO:     None feature selector for col chem
2023-01-04 04:45:47,168 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:45:47,168 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:45:47,169 INFO:     Number of params in model 70141
2023-01-04 04:45:47,172 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:45:47,172 INFO:   Starting stage: TRAINING
2023-01-04 04:45:47,217 INFO:     Val loss before train {'Reaction outcome loss': 0.9187809109687806, 'Total loss': 0.9187809109687806}
2023-01-04 04:45:47,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:47,217 INFO:     Epoch: 0
2023-01-04 04:45:48,827 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5471857011318206, 'Total loss': 0.5471857011318206} | train loss {'Reaction outcome loss': 0.8261163614309617, 'Total loss': 0.8261163614309617}
2023-01-04 04:45:48,827 INFO:     Found new best model at epoch 0
2023-01-04 04:45:48,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:48,828 INFO:     Epoch: 1
2023-01-04 04:45:50,396 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4524156451225281, 'Total loss': 0.4524156451225281} | train loss {'Reaction outcome loss': 0.5934302009043902, 'Total loss': 0.5934302009043902}
2023-01-04 04:45:50,396 INFO:     Found new best model at epoch 1
2023-01-04 04:45:50,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:50,397 INFO:     Epoch: 2
2023-01-04 04:45:51,976 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4149055073658625, 'Total loss': 0.4149055073658625} | train loss {'Reaction outcome loss': 0.5263427131041123, 'Total loss': 0.5263427131041123}
2023-01-04 04:45:51,976 INFO:     Found new best model at epoch 2
2023-01-04 04:45:51,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:51,977 INFO:     Epoch: 3
2023-01-04 04:45:53,544 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.3843988120555878, 'Total loss': 0.3843988120555878} | train loss {'Reaction outcome loss': 0.48738719604528735, 'Total loss': 0.48738719604528735}
2023-01-04 04:45:53,545 INFO:     Found new best model at epoch 3
2023-01-04 04:45:53,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:53,546 INFO:     Epoch: 4
2023-01-04 04:45:55,129 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.3662515719731649, 'Total loss': 0.3662515719731649} | train loss {'Reaction outcome loss': 0.46328307949278474, 'Total loss': 0.46328307949278474}
2023-01-04 04:45:55,129 INFO:     Found new best model at epoch 4
2023-01-04 04:45:55,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:55,130 INFO:     Epoch: 5
2023-01-04 04:45:56,714 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.3510529855887095, 'Total loss': 0.3510529855887095} | train loss {'Reaction outcome loss': 0.4463977970346047, 'Total loss': 0.4463977970346047}
2023-01-04 04:45:56,714 INFO:     Found new best model at epoch 5
2023-01-04 04:45:56,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:56,715 INFO:     Epoch: 6
2023-01-04 04:45:58,297 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3483820527791977, 'Total loss': 0.3483820527791977} | train loss {'Reaction outcome loss': 0.4297132530677928, 'Total loss': 0.4297132530677928}
2023-01-04 04:45:58,297 INFO:     Found new best model at epoch 6
2023-01-04 04:45:58,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:58,298 INFO:     Epoch: 7
2023-01-04 04:45:59,864 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3348645011583964, 'Total loss': 0.3348645011583964} | train loss {'Reaction outcome loss': 0.41564106386508387, 'Total loss': 0.41564106386508387}
2023-01-04 04:45:59,864 INFO:     Found new best model at epoch 7
2023-01-04 04:45:59,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:45:59,865 INFO:     Epoch: 8
2023-01-04 04:46:01,435 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.33386334975560505, 'Total loss': 0.33386334975560505} | train loss {'Reaction outcome loss': 0.40510332481051886, 'Total loss': 0.40510332481051886}
2023-01-04 04:46:01,435 INFO:     Found new best model at epoch 8
2023-01-04 04:46:01,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:01,436 INFO:     Epoch: 9
2023-01-04 04:46:03,047 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.33378392110268273, 'Total loss': 0.33378392110268273} | train loss {'Reaction outcome loss': 0.3934538896555883, 'Total loss': 0.3934538896555883}
2023-01-04 04:46:03,048 INFO:     Found new best model at epoch 9
2023-01-04 04:46:03,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:03,048 INFO:     Epoch: 10
2023-01-04 04:46:04,674 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.33274707992871605, 'Total loss': 0.33274707992871605} | train loss {'Reaction outcome loss': 0.38679934787924275, 'Total loss': 0.38679934787924275}
2023-01-04 04:46:04,674 INFO:     Found new best model at epoch 10
2023-01-04 04:46:04,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:04,675 INFO:     Epoch: 11
2023-01-04 04:46:06,290 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.33075476984182994, 'Total loss': 0.33075476984182994} | train loss {'Reaction outcome loss': 0.3778102956440327, 'Total loss': 0.3778102956440327}
2023-01-04 04:46:06,291 INFO:     Found new best model at epoch 11
2023-01-04 04:46:06,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:06,292 INFO:     Epoch: 12
2023-01-04 04:46:07,874 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3418350875377655, 'Total loss': 0.3418350875377655} | train loss {'Reaction outcome loss': 0.36762255759243545, 'Total loss': 0.36762255759243545}
2023-01-04 04:46:07,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:07,875 INFO:     Epoch: 13
2023-01-04 04:46:09,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3168708662192027, 'Total loss': 0.3168708662192027} | train loss {'Reaction outcome loss': 0.3602493976372002, 'Total loss': 0.3602493976372002}
2023-01-04 04:46:09,457 INFO:     Found new best model at epoch 13
2023-01-04 04:46:09,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:09,457 INFO:     Epoch: 14
2023-01-04 04:46:11,050 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.32117190062999723, 'Total loss': 0.32117190062999723} | train loss {'Reaction outcome loss': 0.35266122110459924, 'Total loss': 0.35266122110459924}
2023-01-04 04:46:11,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:11,050 INFO:     Epoch: 15
2023-01-04 04:46:12,667 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3205708354711533, 'Total loss': 0.3205708354711533} | train loss {'Reaction outcome loss': 0.3450854853285055, 'Total loss': 0.3450854853285055}
2023-01-04 04:46:12,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:12,668 INFO:     Epoch: 16
2023-01-04 04:46:14,284 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3139564702908198, 'Total loss': 0.3139564702908198} | train loss {'Reaction outcome loss': 0.33881963710606533, 'Total loss': 0.33881963710606533}
2023-01-04 04:46:14,285 INFO:     Found new best model at epoch 16
2023-01-04 04:46:14,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:14,285 INFO:     Epoch: 17
2023-01-04 04:46:15,899 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3125491887331009, 'Total loss': 0.3125491887331009} | train loss {'Reaction outcome loss': 0.33291520181037215, 'Total loss': 0.33291520181037215}
2023-01-04 04:46:15,900 INFO:     Found new best model at epoch 17
2023-01-04 04:46:15,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:15,900 INFO:     Epoch: 18
2023-01-04 04:46:17,493 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.32570026218891146, 'Total loss': 0.32570026218891146} | train loss {'Reaction outcome loss': 0.32564454971656315, 'Total loss': 0.32564454971656315}
2023-01-04 04:46:17,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:17,494 INFO:     Epoch: 19
2023-01-04 04:46:19,106 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.31297893027464546, 'Total loss': 0.31297893027464546} | train loss {'Reaction outcome loss': 0.31978528933042155, 'Total loss': 0.31978528933042155}
2023-01-04 04:46:19,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:19,106 INFO:     Epoch: 20
2023-01-04 04:46:20,685 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3084088017543157, 'Total loss': 0.3084088017543157} | train loss {'Reaction outcome loss': 0.31134817632336687, 'Total loss': 0.31134817632336687}
2023-01-04 04:46:20,686 INFO:     Found new best model at epoch 20
2023-01-04 04:46:20,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:20,687 INFO:     Epoch: 21
2023-01-04 04:46:22,314 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.32733756105105083, 'Total loss': 0.32733756105105083} | train loss {'Reaction outcome loss': 0.305285780262338, 'Total loss': 0.305285780262338}
2023-01-04 04:46:22,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:22,314 INFO:     Epoch: 22
2023-01-04 04:46:23,913 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.31686544318993887, 'Total loss': 0.31686544318993887} | train loss {'Reaction outcome loss': 0.30331292152948625, 'Total loss': 0.30331292152948625}
2023-01-04 04:46:23,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:23,913 INFO:     Epoch: 23
2023-01-04 04:46:25,505 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.32576586306095123, 'Total loss': 0.32576586306095123} | train loss {'Reaction outcome loss': 0.2965029541702166, 'Total loss': 0.2965029541702166}
2023-01-04 04:46:25,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:25,505 INFO:     Epoch: 24
2023-01-04 04:46:27,074 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.30514705752333005, 'Total loss': 0.30514705752333005} | train loss {'Reaction outcome loss': 0.29109009689766996, 'Total loss': 0.29109009689766996}
2023-01-04 04:46:27,075 INFO:     Found new best model at epoch 24
2023-01-04 04:46:27,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:27,076 INFO:     Epoch: 25
2023-01-04 04:46:28,635 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.31496719320615135, 'Total loss': 0.31496719320615135} | train loss {'Reaction outcome loss': 0.2840211524145447, 'Total loss': 0.2840211524145447}
2023-01-04 04:46:28,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:28,635 INFO:     Epoch: 26
2023-01-04 04:46:30,225 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.32793621967236203, 'Total loss': 0.32793621967236203} | train loss {'Reaction outcome loss': 0.27962492678287254, 'Total loss': 0.27962492678287254}
2023-01-04 04:46:30,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:30,226 INFO:     Epoch: 27
2023-01-04 04:46:31,817 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3214621484279633, 'Total loss': 0.3214621484279633} | train loss {'Reaction outcome loss': 0.27572142610149664, 'Total loss': 0.27572142610149664}
2023-01-04 04:46:31,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:31,817 INFO:     Epoch: 28
2023-01-04 04:46:33,409 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3339672495921453, 'Total loss': 0.3339672495921453} | train loss {'Reaction outcome loss': 0.27395747306953816, 'Total loss': 0.27395747306953816}
2023-01-04 04:46:33,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:33,410 INFO:     Epoch: 29
2023-01-04 04:46:35,000 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3227897047996521, 'Total loss': 0.3227897047996521} | train loss {'Reaction outcome loss': 0.2674166209669444, 'Total loss': 0.2674166209669444}
2023-01-04 04:46:35,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:35,000 INFO:     Epoch: 30
2023-01-04 04:46:36,570 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3320802758137385, 'Total loss': 0.3320802758137385} | train loss {'Reaction outcome loss': 0.2669956366239238, 'Total loss': 0.2669956366239238}
2023-01-04 04:46:36,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:36,570 INFO:     Epoch: 31
2023-01-04 04:46:38,149 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.31261048316955564, 'Total loss': 0.31261048316955564} | train loss {'Reaction outcome loss': 0.26140370457875034, 'Total loss': 0.26140370457875034}
2023-01-04 04:46:38,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:38,150 INFO:     Epoch: 32
2023-01-04 04:46:39,735 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.32328616877396904, 'Total loss': 0.32328616877396904} | train loss {'Reaction outcome loss': 0.2584517620993357, 'Total loss': 0.2584517620993357}
2023-01-04 04:46:39,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:39,736 INFO:     Epoch: 33
2023-01-04 04:46:41,324 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.30866472820440927, 'Total loss': 0.30866472820440927} | train loss {'Reaction outcome loss': 0.2540094696230044, 'Total loss': 0.2540094696230044}
2023-01-04 04:46:41,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:41,324 INFO:     Epoch: 34
2023-01-04 04:46:42,913 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3095894897977511, 'Total loss': 0.3095894897977511} | train loss {'Reaction outcome loss': 0.2497672687155487, 'Total loss': 0.2497672687155487}
2023-01-04 04:46:42,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:42,913 INFO:     Epoch: 35
2023-01-04 04:46:44,489 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.325559589266777, 'Total loss': 0.325559589266777} | train loss {'Reaction outcome loss': 0.2500703688303049, 'Total loss': 0.2500703688303049}
2023-01-04 04:46:44,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:44,489 INFO:     Epoch: 36
2023-01-04 04:46:46,055 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.31625298062960305, 'Total loss': 0.31625298062960305} | train loss {'Reaction outcome loss': 0.24720470004980147, 'Total loss': 0.24720470004980147}
2023-01-04 04:46:46,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:46,056 INFO:     Epoch: 37
2023-01-04 04:46:47,665 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.31583244502544405, 'Total loss': 0.31583244502544405} | train loss {'Reaction outcome loss': 0.243413081895696, 'Total loss': 0.243413081895696}
2023-01-04 04:46:47,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:47,665 INFO:     Epoch: 38
2023-01-04 04:46:49,267 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.32795821825663246, 'Total loss': 0.32795821825663246} | train loss {'Reaction outcome loss': 0.2413041724340759, 'Total loss': 0.2413041724340759}
2023-01-04 04:46:49,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:49,267 INFO:     Epoch: 39
2023-01-04 04:46:50,910 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3118152106801669, 'Total loss': 0.3118152106801669} | train loss {'Reaction outcome loss': 0.23892097336913112, 'Total loss': 0.23892097336913112}
2023-01-04 04:46:50,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:50,910 INFO:     Epoch: 40
2023-01-04 04:46:52,541 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.35793879528840383, 'Total loss': 0.35793879528840383} | train loss {'Reaction outcome loss': 0.23389829799913578, 'Total loss': 0.23389829799913578}
2023-01-04 04:46:52,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:52,541 INFO:     Epoch: 41
2023-01-04 04:46:54,153 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.31559356103340785, 'Total loss': 0.31559356103340785} | train loss {'Reaction outcome loss': 0.2338871864234879, 'Total loss': 0.2338871864234879}
2023-01-04 04:46:54,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:54,153 INFO:     Epoch: 42
2023-01-04 04:46:55,714 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.30486191908518473, 'Total loss': 0.30486191908518473} | train loss {'Reaction outcome loss': 0.22909950159055037, 'Total loss': 0.22909950159055037}
2023-01-04 04:46:55,714 INFO:     Found new best model at epoch 42
2023-01-04 04:46:55,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:55,715 INFO:     Epoch: 43
2023-01-04 04:46:57,327 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3028625677029292, 'Total loss': 0.3028625677029292} | train loss {'Reaction outcome loss': 0.22672513869665836, 'Total loss': 0.22672513869665836}
2023-01-04 04:46:57,328 INFO:     Found new best model at epoch 43
2023-01-04 04:46:57,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:57,329 INFO:     Epoch: 44
2023-01-04 04:46:58,908 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3137042780717214, 'Total loss': 0.3137042780717214} | train loss {'Reaction outcome loss': 0.22387118566862857, 'Total loss': 0.22387118566862857}
2023-01-04 04:46:58,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:46:58,908 INFO:     Epoch: 45
2023-01-04 04:47:00,522 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3216325879096985, 'Total loss': 0.3216325879096985} | train loss {'Reaction outcome loss': 0.2244159832841506, 'Total loss': 0.2244159832841506}
2023-01-04 04:47:00,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:00,523 INFO:     Epoch: 46
2023-01-04 04:47:02,097 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.33310590287049613, 'Total loss': 0.33310590287049613} | train loss {'Reaction outcome loss': 0.21895897350389593, 'Total loss': 0.21895897350389593}
2023-01-04 04:47:02,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:02,097 INFO:     Epoch: 47
2023-01-04 04:47:03,669 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.33885340541601183, 'Total loss': 0.33885340541601183} | train loss {'Reaction outcome loss': 0.21702776324466197, 'Total loss': 0.21702776324466197}
2023-01-04 04:47:03,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:03,670 INFO:     Epoch: 48
2023-01-04 04:47:05,242 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3126202111442884, 'Total loss': 0.3126202111442884} | train loss {'Reaction outcome loss': 0.21760903581650587, 'Total loss': 0.21760903581650587}
2023-01-04 04:47:05,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:05,242 INFO:     Epoch: 49
2023-01-04 04:47:06,832 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3059068813920021, 'Total loss': 0.3059068813920021} | train loss {'Reaction outcome loss': 0.2173319037487037, 'Total loss': 0.2173319037487037}
2023-01-04 04:47:06,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:06,832 INFO:     Epoch: 50
2023-01-04 04:47:08,438 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.32883096039295195, 'Total loss': 0.32883096039295195} | train loss {'Reaction outcome loss': 0.2112401767232775, 'Total loss': 0.2112401767232775}
2023-01-04 04:47:08,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:08,438 INFO:     Epoch: 51
2023-01-04 04:47:10,054 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.31875195453564326, 'Total loss': 0.31875195453564326} | train loss {'Reaction outcome loss': 0.21051144835124486, 'Total loss': 0.21051144835124486}
2023-01-04 04:47:10,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:10,054 INFO:     Epoch: 52
2023-01-04 04:47:11,651 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3289169232050578, 'Total loss': 0.3289169232050578} | train loss {'Reaction outcome loss': 0.2101171999068482, 'Total loss': 0.2101171999068482}
2023-01-04 04:47:11,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:11,651 INFO:     Epoch: 53
2023-01-04 04:47:13,240 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3328621452053388, 'Total loss': 0.3328621452053388} | train loss {'Reaction outcome loss': 0.20866225734624985, 'Total loss': 0.20866225734624985}
2023-01-04 04:47:13,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:13,240 INFO:     Epoch: 54
2023-01-04 04:47:14,824 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.30615482355157536, 'Total loss': 0.30615482355157536} | train loss {'Reaction outcome loss': 0.20401115465338213, 'Total loss': 0.20401115465338213}
2023-01-04 04:47:14,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:14,825 INFO:     Epoch: 55
2023-01-04 04:47:16,409 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3231975903113683, 'Total loss': 0.3231975903113683} | train loss {'Reaction outcome loss': 0.20667116519362821, 'Total loss': 0.20667116519362821}
2023-01-04 04:47:16,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:16,410 INFO:     Epoch: 56
2023-01-04 04:47:17,978 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32761632204055785, 'Total loss': 0.32761632204055785} | train loss {'Reaction outcome loss': 0.2052449675168108, 'Total loss': 0.2052449675168108}
2023-01-04 04:47:17,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:17,978 INFO:     Epoch: 57
2023-01-04 04:47:19,587 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3336657345294952, 'Total loss': 0.3336657345294952} | train loss {'Reaction outcome loss': 0.20283502682934712, 'Total loss': 0.20283502682934712}
2023-01-04 04:47:19,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:19,587 INFO:     Epoch: 58
2023-01-04 04:47:21,145 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3193542882800102, 'Total loss': 0.3193542882800102} | train loss {'Reaction outcome loss': 0.19750898688977217, 'Total loss': 0.19750898688977217}
2023-01-04 04:47:21,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:21,146 INFO:     Epoch: 59
2023-01-04 04:47:22,729 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.31028878688812256, 'Total loss': 0.31028878688812256} | train loss {'Reaction outcome loss': 0.19631411929200165, 'Total loss': 0.19631411929200165}
2023-01-04 04:47:22,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:22,729 INFO:     Epoch: 60
2023-01-04 04:47:24,349 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.31085789054632185, 'Total loss': 0.31085789054632185} | train loss {'Reaction outcome loss': 0.19736900980020092, 'Total loss': 0.19736900980020092}
2023-01-04 04:47:24,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:24,350 INFO:     Epoch: 61
2023-01-04 04:47:25,966 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3485642045736313, 'Total loss': 0.3485642045736313} | train loss {'Reaction outcome loss': 0.191196267268736, 'Total loss': 0.191196267268736}
2023-01-04 04:47:25,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:25,966 INFO:     Epoch: 62
2023-01-04 04:47:27,539 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.31956926683584846, 'Total loss': 0.31956926683584846} | train loss {'Reaction outcome loss': 0.19536258016515823, 'Total loss': 0.19536258016515823}
2023-01-04 04:47:27,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:27,540 INFO:     Epoch: 63
2023-01-04 04:47:29,103 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3274974634250005, 'Total loss': 0.3274974634250005} | train loss {'Reaction outcome loss': 0.19161424349422437, 'Total loss': 0.19161424349422437}
2023-01-04 04:47:29,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:29,103 INFO:     Epoch: 64
2023-01-04 04:47:30,676 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.30484389290213587, 'Total loss': 0.30484389290213587} | train loss {'Reaction outcome loss': 0.19195307562821104, 'Total loss': 0.19195307562821104}
2023-01-04 04:47:30,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:30,677 INFO:     Epoch: 65
2023-01-04 04:47:32,265 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3208499272664388, 'Total loss': 0.3208499272664388} | train loss {'Reaction outcome loss': 0.18854407510672608, 'Total loss': 0.18854407510672608}
2023-01-04 04:47:32,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:32,265 INFO:     Epoch: 66
2023-01-04 04:47:33,880 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3401711151003838, 'Total loss': 0.3401711151003838} | train loss {'Reaction outcome loss': 0.18819561086078412, 'Total loss': 0.18819561086078412}
2023-01-04 04:47:33,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:33,881 INFO:     Epoch: 67
2023-01-04 04:47:35,450 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3138465921084086, 'Total loss': 0.3138465921084086} | train loss {'Reaction outcome loss': 0.19043349051834457, 'Total loss': 0.19043349051834457}
2023-01-04 04:47:35,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:35,451 INFO:     Epoch: 68
2023-01-04 04:47:37,043 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.32152855694293975, 'Total loss': 0.32152855694293975} | train loss {'Reaction outcome loss': 0.1882015170162394, 'Total loss': 0.1882015170162394}
2023-01-04 04:47:37,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:37,043 INFO:     Epoch: 69
2023-01-04 04:47:38,632 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.31251276085774105, 'Total loss': 0.31251276085774105} | train loss {'Reaction outcome loss': 0.18521427853971068, 'Total loss': 0.18521427853971068}
2023-01-04 04:47:38,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:38,632 INFO:     Epoch: 70
2023-01-04 04:47:40,226 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.32326645652453107, 'Total loss': 0.32326645652453107} | train loss {'Reaction outcome loss': 0.1824292482359566, 'Total loss': 0.1824292482359566}
2023-01-04 04:47:40,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:40,226 INFO:     Epoch: 71
2023-01-04 04:47:41,809 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3236480345328649, 'Total loss': 0.3236480345328649} | train loss {'Reaction outcome loss': 0.1824333912482227, 'Total loss': 0.1824333912482227}
2023-01-04 04:47:41,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:41,810 INFO:     Epoch: 72
2023-01-04 04:47:43,392 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.32700598339239756, 'Total loss': 0.32700598339239756} | train loss {'Reaction outcome loss': 0.18400229608816823, 'Total loss': 0.18400229608816823}
2023-01-04 04:47:43,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:43,392 INFO:     Epoch: 73
2023-01-04 04:47:45,009 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.31239321728547415, 'Total loss': 0.31239321728547415} | train loss {'Reaction outcome loss': 0.18026702547867368, 'Total loss': 0.18026702547867368}
2023-01-04 04:47:45,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:45,009 INFO:     Epoch: 74
2023-01-04 04:47:46,617 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.31174061993757884, 'Total loss': 0.31174061993757884} | train loss {'Reaction outcome loss': 0.183329574994906, 'Total loss': 0.183329574994906}
2023-01-04 04:47:46,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:46,617 INFO:     Epoch: 75
2023-01-04 04:47:48,201 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.31078519895672796, 'Total loss': 0.31078519895672796} | train loss {'Reaction outcome loss': 0.18160886901097684, 'Total loss': 0.18160886901097684}
2023-01-04 04:47:48,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:48,201 INFO:     Epoch: 76
2023-01-04 04:47:49,777 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.31664092193047205, 'Total loss': 0.31664092193047205} | train loss {'Reaction outcome loss': 0.17826786872516148, 'Total loss': 0.17826786872516148}
2023-01-04 04:47:49,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:49,777 INFO:     Epoch: 77
2023-01-04 04:47:51,359 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3851767693956693, 'Total loss': 0.3851767693956693} | train loss {'Reaction outcome loss': 0.17745608323165318, 'Total loss': 0.17745608323165318}
2023-01-04 04:47:51,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:51,359 INFO:     Epoch: 78
2023-01-04 04:47:52,941 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.31553650051355364, 'Total loss': 0.31553650051355364} | train loss {'Reaction outcome loss': 0.17793389529424863, 'Total loss': 0.17793389529424863}
2023-01-04 04:47:52,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:52,942 INFO:     Epoch: 79
2023-01-04 04:47:54,524 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.31687701443831123, 'Total loss': 0.31687701443831123} | train loss {'Reaction outcome loss': 0.17644698703049744, 'Total loss': 0.17644698703049744}
2023-01-04 04:47:54,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:54,524 INFO:     Epoch: 80
2023-01-04 04:47:56,099 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.31308773954709374, 'Total loss': 0.31308773954709374} | train loss {'Reaction outcome loss': 0.17405598480118453, 'Total loss': 0.17405598480118453}
2023-01-04 04:47:56,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:56,100 INFO:     Epoch: 81
2023-01-04 04:47:57,666 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.32306204019114376, 'Total loss': 0.32306204019114376} | train loss {'Reaction outcome loss': 0.17585145697052026, 'Total loss': 0.17585145697052026}
2023-01-04 04:47:57,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:57,666 INFO:     Epoch: 82
2023-01-04 04:47:59,237 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3113254696130753, 'Total loss': 0.3113254696130753} | train loss {'Reaction outcome loss': 0.1783579791127874, 'Total loss': 0.1783579791127874}
2023-01-04 04:47:59,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:47:59,238 INFO:     Epoch: 83
2023-01-04 04:48:00,844 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3159911210338275, 'Total loss': 0.3159911210338275} | train loss {'Reaction outcome loss': 0.17198690131687336, 'Total loss': 0.17198690131687336}
2023-01-04 04:48:00,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:00,844 INFO:     Epoch: 84
2023-01-04 04:48:02,465 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3407427897055944, 'Total loss': 0.3407427897055944} | train loss {'Reaction outcome loss': 0.16954259539743627, 'Total loss': 0.16954259539743627}
2023-01-04 04:48:02,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:02,465 INFO:     Epoch: 85
2023-01-04 04:48:04,089 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3023553768793742, 'Total loss': 0.3023553768793742} | train loss {'Reaction outcome loss': 0.16893061337462306, 'Total loss': 0.16893061337462306}
2023-01-04 04:48:04,089 INFO:     Found new best model at epoch 85
2023-01-04 04:48:04,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:04,090 INFO:     Epoch: 86
2023-01-04 04:48:05,658 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3209167862931887, 'Total loss': 0.3209167862931887} | train loss {'Reaction outcome loss': 0.17073346906933037, 'Total loss': 0.17073346906933037}
2023-01-04 04:48:05,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:05,659 INFO:     Epoch: 87
2023-01-04 04:48:07,221 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3273734907309214, 'Total loss': 0.3273734907309214} | train loss {'Reaction outcome loss': 0.16881597812294308, 'Total loss': 0.16881597812294308}
2023-01-04 04:48:07,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:07,221 INFO:     Epoch: 88
2023-01-04 04:48:08,847 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3167503810177247, 'Total loss': 0.3167503810177247} | train loss {'Reaction outcome loss': 0.17044531490082723, 'Total loss': 0.17044531490082723}
2023-01-04 04:48:08,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:08,847 INFO:     Epoch: 89
2023-01-04 04:48:10,473 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.322699282070001, 'Total loss': 0.322699282070001} | train loss {'Reaction outcome loss': 0.16795974809431682, 'Total loss': 0.16795974809431682}
2023-01-04 04:48:10,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:10,473 INFO:     Epoch: 90
2023-01-04 04:48:12,086 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3049227510889371, 'Total loss': 0.3049227510889371} | train loss {'Reaction outcome loss': 0.16818326843535378, 'Total loss': 0.16818326843535378}
2023-01-04 04:48:12,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:12,086 INFO:     Epoch: 91
2023-01-04 04:48:13,682 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.30439765102540456, 'Total loss': 0.30439765102540456} | train loss {'Reaction outcome loss': 0.16786780126433629, 'Total loss': 0.16786780126433629}
2023-01-04 04:48:13,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:13,682 INFO:     Epoch: 92
2023-01-04 04:48:15,242 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.324773578842481, 'Total loss': 0.324773578842481} | train loss {'Reaction outcome loss': 0.16595233666853312, 'Total loss': 0.16595233666853312}
2023-01-04 04:48:15,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:15,242 INFO:     Epoch: 93
2023-01-04 04:48:16,816 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.303999952521796, 'Total loss': 0.303999952521796} | train loss {'Reaction outcome loss': 0.16564908378968274, 'Total loss': 0.16564908378968274}
2023-01-04 04:48:16,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:16,816 INFO:     Epoch: 94
2023-01-04 04:48:18,396 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3291348457336426, 'Total loss': 0.3291348457336426} | train loss {'Reaction outcome loss': 0.1633230014942097, 'Total loss': 0.1633230014942097}
2023-01-04 04:48:18,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:18,397 INFO:     Epoch: 95
2023-01-04 04:48:19,969 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3060698116819064, 'Total loss': 0.3060698116819064} | train loss {'Reaction outcome loss': 0.16743078416580484, 'Total loss': 0.16743078416580484}
2023-01-04 04:48:19,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:19,969 INFO:     Epoch: 96
2023-01-04 04:48:21,542 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.29988735914230347, 'Total loss': 0.29988735914230347} | train loss {'Reaction outcome loss': 0.16190260107608606, 'Total loss': 0.16190260107608606}
2023-01-04 04:48:21,542 INFO:     Found new best model at epoch 96
2023-01-04 04:48:21,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:21,543 INFO:     Epoch: 97
2023-01-04 04:48:23,104 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.32815872579813005, 'Total loss': 0.32815872579813005} | train loss {'Reaction outcome loss': 0.16391834618020668, 'Total loss': 0.16391834618020668}
2023-01-04 04:48:23,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:23,105 INFO:     Epoch: 98
2023-01-04 04:48:24,682 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3203043878078461, 'Total loss': 0.3203043878078461} | train loss {'Reaction outcome loss': 0.16486935285565846, 'Total loss': 0.16486935285565846}
2023-01-04 04:48:24,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:24,683 INFO:     Epoch: 99
2023-01-04 04:48:26,286 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3292480001846949, 'Total loss': 0.3292480001846949} | train loss {'Reaction outcome loss': 0.1646343469313842, 'Total loss': 0.1646343469313842}
2023-01-04 04:48:26,286 INFO:     Best model found after epoch 97 of 100.
2023-01-04 04:48:26,286 INFO:   Done with stage: TRAINING
2023-01-04 04:48:26,286 INFO:   Starting stage: EVALUATION
2023-01-04 04:48:26,420 INFO:   Done with stage: EVALUATION
2023-01-04 04:48:26,420 INFO:   Leaving out SEQ value Fold_2
2023-01-04 04:48:26,433 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:48:26,433 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:48:27,075 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:48:27,075 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:48:27,142 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:48:27,143 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:48:27,143 INFO:     No hyperparam tuning for this model
2023-01-04 04:48:27,143 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:48:27,143 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:48:27,144 INFO:     None feature selector for col prot
2023-01-04 04:48:27,144 INFO:     None feature selector for col prot
2023-01-04 04:48:27,144 INFO:     None feature selector for col prot
2023-01-04 04:48:27,144 INFO:     None feature selector for col chem
2023-01-04 04:48:27,145 INFO:     None feature selector for col chem
2023-01-04 04:48:27,145 INFO:     None feature selector for col chem
2023-01-04 04:48:27,145 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:48:27,145 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:48:27,146 INFO:     Number of params in model 70141
2023-01-04 04:48:27,149 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:48:27,149 INFO:   Starting stage: TRAINING
2023-01-04 04:48:27,194 INFO:     Val loss before train {'Reaction outcome loss': 1.0698401073614756, 'Total loss': 1.0698401073614756}
2023-01-04 04:48:27,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:27,194 INFO:     Epoch: 0
2023-01-04 04:48:28,827 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6450351556142171, 'Total loss': 0.6450351556142171} | train loss {'Reaction outcome loss': 0.8542833084213561, 'Total loss': 0.8542833084213561}
2023-01-04 04:48:28,827 INFO:     Found new best model at epoch 0
2023-01-04 04:48:28,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:28,828 INFO:     Epoch: 1
2023-01-04 04:48:30,413 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5513563533624013, 'Total loss': 0.5513563533624013} | train loss {'Reaction outcome loss': 0.5995886809682881, 'Total loss': 0.5995886809682881}
2023-01-04 04:48:30,414 INFO:     Found new best model at epoch 1
2023-01-04 04:48:30,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:30,415 INFO:     Epoch: 2
2023-01-04 04:48:31,988 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5056754430135091, 'Total loss': 0.5056754430135091} | train loss {'Reaction outcome loss': 0.5235835957219419, 'Total loss': 0.5235835957219419}
2023-01-04 04:48:31,988 INFO:     Found new best model at epoch 2
2023-01-04 04:48:31,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:31,989 INFO:     Epoch: 3
2023-01-04 04:48:33,555 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4819221794605255, 'Total loss': 0.4819221794605255} | train loss {'Reaction outcome loss': 0.479900667164538, 'Total loss': 0.479900667164538}
2023-01-04 04:48:33,555 INFO:     Found new best model at epoch 3
2023-01-04 04:48:33,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:33,556 INFO:     Epoch: 4
2023-01-04 04:48:35,143 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4790781795978546, 'Total loss': 0.4790781795978546} | train loss {'Reaction outcome loss': 0.45358990109968506, 'Total loss': 0.45358990109968506}
2023-01-04 04:48:35,144 INFO:     Found new best model at epoch 4
2023-01-04 04:48:35,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:35,144 INFO:     Epoch: 5
2023-01-04 04:48:36,741 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4538214266300201, 'Total loss': 0.4538214266300201} | train loss {'Reaction outcome loss': 0.4305661803894285, 'Total loss': 0.4305661803894285}
2023-01-04 04:48:36,741 INFO:     Found new best model at epoch 5
2023-01-04 04:48:36,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:36,742 INFO:     Epoch: 6
2023-01-04 04:48:38,330 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44761248032251993, 'Total loss': 0.44761248032251993} | train loss {'Reaction outcome loss': 0.4183635239799817, 'Total loss': 0.4183635239799817}
2023-01-04 04:48:38,331 INFO:     Found new best model at epoch 6
2023-01-04 04:48:38,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:38,331 INFO:     Epoch: 7
2023-01-04 04:48:39,964 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.453381293018659, 'Total loss': 0.453381293018659} | train loss {'Reaction outcome loss': 0.4073499923890821, 'Total loss': 0.4073499923890821}
2023-01-04 04:48:39,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:39,964 INFO:     Epoch: 8
2023-01-04 04:48:41,559 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4561394552389781, 'Total loss': 0.4561394552389781} | train loss {'Reaction outcome loss': 0.3896241601947965, 'Total loss': 0.3896241601947965}
2023-01-04 04:48:41,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:41,560 INFO:     Epoch: 9
2023-01-04 04:48:43,156 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4583840986092885, 'Total loss': 0.4583840986092885} | train loss {'Reaction outcome loss': 0.379530821706715, 'Total loss': 0.379530821706715}
2023-01-04 04:48:43,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:43,156 INFO:     Epoch: 10
2023-01-04 04:48:44,790 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4286411752303441, 'Total loss': 0.4286411752303441} | train loss {'Reaction outcome loss': 0.37323107126344374, 'Total loss': 0.37323107126344374}
2023-01-04 04:48:44,790 INFO:     Found new best model at epoch 10
2023-01-04 04:48:44,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:44,791 INFO:     Epoch: 11
2023-01-04 04:48:46,413 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42590424517790476, 'Total loss': 0.42590424517790476} | train loss {'Reaction outcome loss': 0.36427332132766227, 'Total loss': 0.36427332132766227}
2023-01-04 04:48:46,413 INFO:     Found new best model at epoch 11
2023-01-04 04:48:46,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:46,414 INFO:     Epoch: 12
2023-01-04 04:48:48,035 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42176454663276675, 'Total loss': 0.42176454663276675} | train loss {'Reaction outcome loss': 0.3568889464967061, 'Total loss': 0.3568889464967061}
2023-01-04 04:48:48,035 INFO:     Found new best model at epoch 12
2023-01-04 04:48:48,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:48,036 INFO:     Epoch: 13
2023-01-04 04:48:49,644 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44300898909568787, 'Total loss': 0.44300898909568787} | train loss {'Reaction outcome loss': 0.36263123508272826, 'Total loss': 0.36263123508272826}
2023-01-04 04:48:49,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:49,644 INFO:     Epoch: 14
2023-01-04 04:48:51,239 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44049652218818663, 'Total loss': 0.44049652218818663} | train loss {'Reaction outcome loss': 0.3503315046267665, 'Total loss': 0.3503315046267665}
2023-01-04 04:48:51,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:51,240 INFO:     Epoch: 15
2023-01-04 04:48:52,842 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.428324348727862, 'Total loss': 0.428324348727862} | train loss {'Reaction outcome loss': 0.34182967340229486, 'Total loss': 0.34182967340229486}
2023-01-04 04:48:52,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:52,843 INFO:     Epoch: 16
2023-01-04 04:48:54,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4300339788198471, 'Total loss': 0.4300339788198471} | train loss {'Reaction outcome loss': 0.33366622827167663, 'Total loss': 0.33366622827167663}
2023-01-04 04:48:54,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:54,468 INFO:     Epoch: 17
2023-01-04 04:48:56,058 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4347550849119822, 'Total loss': 0.4347550849119822} | train loss {'Reaction outcome loss': 0.32805057846522634, 'Total loss': 0.32805057846522634}
2023-01-04 04:48:56,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:56,058 INFO:     Epoch: 18
2023-01-04 04:48:57,680 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4472382128238678, 'Total loss': 0.4472382128238678} | train loss {'Reaction outcome loss': 0.32400379740241647, 'Total loss': 0.32400379740241647}
2023-01-04 04:48:57,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:57,681 INFO:     Epoch: 19
2023-01-04 04:48:59,283 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42669074833393095, 'Total loss': 0.42669074833393095} | train loss {'Reaction outcome loss': 0.31913259281925316, 'Total loss': 0.31913259281925316}
2023-01-04 04:48:59,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:48:59,283 INFO:     Epoch: 20
2023-01-04 04:49:00,876 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44632969895998637, 'Total loss': 0.44632969895998637} | train loss {'Reaction outcome loss': 0.3160687805409881, 'Total loss': 0.3160687805409881}
2023-01-04 04:49:00,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:00,876 INFO:     Epoch: 21
2023-01-04 04:49:02,473 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4358895440896352, 'Total loss': 0.4358895440896352} | train loss {'Reaction outcome loss': 0.31959280188100925, 'Total loss': 0.31959280188100925}
2023-01-04 04:49:02,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:02,473 INFO:     Epoch: 22
2023-01-04 04:49:04,072 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.419513405362765, 'Total loss': 0.419513405362765} | train loss {'Reaction outcome loss': 0.3192376295185607, 'Total loss': 0.3192376295185607}
2023-01-04 04:49:04,072 INFO:     Found new best model at epoch 22
2023-01-04 04:49:04,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:04,073 INFO:     Epoch: 23
2023-01-04 04:49:05,672 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42677064140637716, 'Total loss': 0.42677064140637716} | train loss {'Reaction outcome loss': 0.3046544328115989, 'Total loss': 0.3046544328115989}
2023-01-04 04:49:05,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:05,672 INFO:     Epoch: 24
2023-01-04 04:49:07,272 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44050156672795615, 'Total loss': 0.44050156672795615} | train loss {'Reaction outcome loss': 0.31677327521037363, 'Total loss': 0.31677327521037363}
2023-01-04 04:49:07,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:07,272 INFO:     Epoch: 25
2023-01-04 04:49:08,852 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42826353311538695, 'Total loss': 0.42826353311538695} | train loss {'Reaction outcome loss': 0.3080428491845943, 'Total loss': 0.3080428491845943}
2023-01-04 04:49:08,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:08,852 INFO:     Epoch: 26
2023-01-04 04:49:10,441 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42705660065015155, 'Total loss': 0.42705660065015155} | train loss {'Reaction outcome loss': 0.29817162615253817, 'Total loss': 0.29817162615253817}
2023-01-04 04:49:10,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:10,442 INFO:     Epoch: 27
2023-01-04 04:49:12,063 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42809712092081703, 'Total loss': 0.42809712092081703} | train loss {'Reaction outcome loss': 0.289977752310865, 'Total loss': 0.289977752310865}
2023-01-04 04:49:12,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:12,063 INFO:     Epoch: 28
2023-01-04 04:49:13,689 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4410040636857351, 'Total loss': 0.4410040636857351} | train loss {'Reaction outcome loss': 0.28457564170188876, 'Total loss': 0.28457564170188876}
2023-01-04 04:49:13,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:13,689 INFO:     Epoch: 29
2023-01-04 04:49:15,287 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43049604694048565, 'Total loss': 0.43049604694048565} | train loss {'Reaction outcome loss': 0.2836113740771037, 'Total loss': 0.2836113740771037}
2023-01-04 04:49:15,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:15,287 INFO:     Epoch: 30
2023-01-04 04:49:16,891 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43364590803782144, 'Total loss': 0.43364590803782144} | train loss {'Reaction outcome loss': 0.28404323673010734, 'Total loss': 0.28404323673010734}
2023-01-04 04:49:16,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:16,892 INFO:     Epoch: 31
2023-01-04 04:49:18,477 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4354202648003896, 'Total loss': 0.4354202648003896} | train loss {'Reaction outcome loss': 0.2835318160317568, 'Total loss': 0.2835318160317568}
2023-01-04 04:49:18,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:18,477 INFO:     Epoch: 32
2023-01-04 04:49:20,110 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42834550539652505, 'Total loss': 0.42834550539652505} | train loss {'Reaction outcome loss': 0.2770996926524474, 'Total loss': 0.2770996926524474}
2023-01-04 04:49:20,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:20,110 INFO:     Epoch: 33
2023-01-04 04:49:21,739 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44638945857683815, 'Total loss': 0.44638945857683815} | train loss {'Reaction outcome loss': 0.27119581862960174, 'Total loss': 0.27119581862960174}
2023-01-04 04:49:21,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:21,739 INFO:     Epoch: 34
2023-01-04 04:49:23,368 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4316860278447469, 'Total loss': 0.4316860278447469} | train loss {'Reaction outcome loss': 0.2679965935809457, 'Total loss': 0.2679965935809457}
2023-01-04 04:49:23,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:23,368 INFO:     Epoch: 35
2023-01-04 04:49:24,992 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4420185516277949, 'Total loss': 0.4420185516277949} | train loss {'Reaction outcome loss': 0.26576581672913785, 'Total loss': 0.26576581672913785}
2023-01-04 04:49:24,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:24,992 INFO:     Epoch: 36
2023-01-04 04:49:26,573 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4516072432200114, 'Total loss': 0.4516072432200114} | train loss {'Reaction outcome loss': 0.26501356277857785, 'Total loss': 0.26501356277857785}
2023-01-04 04:49:26,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:26,573 INFO:     Epoch: 37
2023-01-04 04:49:28,182 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42903830607732135, 'Total loss': 0.42903830607732135} | train loss {'Reaction outcome loss': 0.2697148476929768, 'Total loss': 0.2697148476929768}
2023-01-04 04:49:28,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:28,182 INFO:     Epoch: 38
2023-01-04 04:49:29,808 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45297000209490457, 'Total loss': 0.45297000209490457} | train loss {'Reaction outcome loss': 0.2710143477483855, 'Total loss': 0.2710143477483855}
2023-01-04 04:49:29,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:29,809 INFO:     Epoch: 39
2023-01-04 04:49:31,437 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4440542787313461, 'Total loss': 0.4440542787313461} | train loss {'Reaction outcome loss': 0.2569617669476007, 'Total loss': 0.2569617669476007}
2023-01-04 04:49:31,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:31,437 INFO:     Epoch: 40
2023-01-04 04:49:33,047 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46429583926995593, 'Total loss': 0.46429583926995593} | train loss {'Reaction outcome loss': 0.252067918945745, 'Total loss': 0.252067918945745}
2023-01-04 04:49:33,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:33,047 INFO:     Epoch: 41
2023-01-04 04:49:34,647 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44086311757564545, 'Total loss': 0.44086311757564545} | train loss {'Reaction outcome loss': 0.25146948471287184, 'Total loss': 0.25146948471287184}
2023-01-04 04:49:34,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:34,647 INFO:     Epoch: 42
2023-01-04 04:49:35,751 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44651920000712075, 'Total loss': 0.44651920000712075} | train loss {'Reaction outcome loss': 0.24770967019603762, 'Total loss': 0.24770967019603762}
2023-01-04 04:49:35,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:35,751 INFO:     Epoch: 43
2023-01-04 04:49:36,859 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43011056929826735, 'Total loss': 0.43011056929826735} | train loss {'Reaction outcome loss': 0.2475520973228782, 'Total loss': 0.2475520973228782}
2023-01-04 04:49:36,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:36,859 INFO:     Epoch: 44
2023-01-04 04:49:37,958 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4521287441253662, 'Total loss': 0.4521287441253662} | train loss {'Reaction outcome loss': 0.2447180509202605, 'Total loss': 0.2447180509202605}
2023-01-04 04:49:37,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:37,958 INFO:     Epoch: 45
2023-01-04 04:49:39,056 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45983056326707206, 'Total loss': 0.45983056326707206} | train loss {'Reaction outcome loss': 0.24507931204161781, 'Total loss': 0.24507931204161781}
2023-01-04 04:49:39,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:39,056 INFO:     Epoch: 46
2023-01-04 04:49:40,620 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45851898392041524, 'Total loss': 0.45851898392041524} | train loss {'Reaction outcome loss': 0.24045165412404668, 'Total loss': 0.24045165412404668}
2023-01-04 04:49:40,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:40,622 INFO:     Epoch: 47
2023-01-04 04:49:42,216 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4530296454826991, 'Total loss': 0.4530296454826991} | train loss {'Reaction outcome loss': 0.26270062194300303, 'Total loss': 0.26270062194300303}
2023-01-04 04:49:42,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:42,216 INFO:     Epoch: 48
2023-01-04 04:49:43,807 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44899560113747916, 'Total loss': 0.44899560113747916} | train loss {'Reaction outcome loss': 0.23858016191144893, 'Total loss': 0.23858016191144893}
2023-01-04 04:49:43,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:43,807 INFO:     Epoch: 49
2023-01-04 04:49:45,392 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47526119550069174, 'Total loss': 0.47526119550069174} | train loss {'Reaction outcome loss': 0.23396777963279275, 'Total loss': 0.23396777963279275}
2023-01-04 04:49:45,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:45,393 INFO:     Epoch: 50
2023-01-04 04:49:47,018 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4656963249047597, 'Total loss': 0.4656963249047597} | train loss {'Reaction outcome loss': 0.23351418973212223, 'Total loss': 0.23351418973212223}
2023-01-04 04:49:47,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:47,019 INFO:     Epoch: 51
2023-01-04 04:49:48,614 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4577731241782506, 'Total loss': 0.4577731241782506} | train loss {'Reaction outcome loss': 0.23166523122884994, 'Total loss': 0.23166523122884994}
2023-01-04 04:49:48,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:48,614 INFO:     Epoch: 52
2023-01-04 04:49:50,222 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4560032248497009, 'Total loss': 0.4560032248497009} | train loss {'Reaction outcome loss': 0.22944151217023423, 'Total loss': 0.22944151217023423}
2023-01-04 04:49:50,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:50,222 INFO:     Epoch: 53
2023-01-04 04:49:51,816 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49219985008239747, 'Total loss': 0.49219985008239747} | train loss {'Reaction outcome loss': 0.22521820833608744, 'Total loss': 0.22521820833608744}
2023-01-04 04:49:51,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:51,817 INFO:     Epoch: 54
2023-01-04 04:49:53,392 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47555689215660096, 'Total loss': 0.47555689215660096} | train loss {'Reaction outcome loss': 0.22637494565034116, 'Total loss': 0.22637494565034116}
2023-01-04 04:49:53,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:53,392 INFO:     Epoch: 55
2023-01-04 04:49:55,004 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4700362096230189, 'Total loss': 0.4700362096230189} | train loss {'Reaction outcome loss': 0.22185786373312652, 'Total loss': 0.22185786373312652}
2023-01-04 04:49:55,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:55,004 INFO:     Epoch: 56
2023-01-04 04:49:56,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4829219162464142, 'Total loss': 0.4829219162464142} | train loss {'Reaction outcome loss': 0.21826822020202236, 'Total loss': 0.21826822020202236}
2023-01-04 04:49:56,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:56,597 INFO:     Epoch: 57
2023-01-04 04:49:58,172 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48360379934310915, 'Total loss': 0.48360379934310915} | train loss {'Reaction outcome loss': 0.21926174612135452, 'Total loss': 0.21926174612135452}
2023-01-04 04:49:58,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:58,172 INFO:     Epoch: 58
2023-01-04 04:49:59,765 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47155171235402427, 'Total loss': 0.47155171235402427} | train loss {'Reaction outcome loss': 0.21919060440473992, 'Total loss': 0.21919060440473992}
2023-01-04 04:49:59,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:49:59,766 INFO:     Epoch: 59
2023-01-04 04:50:01,347 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4859101404746374, 'Total loss': 0.4859101404746374} | train loss {'Reaction outcome loss': 0.21655178137555503, 'Total loss': 0.21655178137555503}
2023-01-04 04:50:01,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:01,348 INFO:     Epoch: 60
2023-01-04 04:50:02,941 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4767120440800985, 'Total loss': 0.4767120440800985} | train loss {'Reaction outcome loss': 0.21444818244861485, 'Total loss': 0.21444818244861485}
2023-01-04 04:50:02,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:02,941 INFO:     Epoch: 61
2023-01-04 04:50:04,542 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5139396200577419, 'Total loss': 0.5139396200577419} | train loss {'Reaction outcome loss': 0.2148491469603302, 'Total loss': 0.2148491469603302}
2023-01-04 04:50:04,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:04,542 INFO:     Epoch: 62
2023-01-04 04:50:06,124 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5003561725219091, 'Total loss': 0.5003561725219091} | train loss {'Reaction outcome loss': 0.21944294964508287, 'Total loss': 0.21944294964508287}
2023-01-04 04:50:06,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:06,124 INFO:     Epoch: 63
2023-01-04 04:50:07,711 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5041028678417205, 'Total loss': 0.5041028678417205} | train loss {'Reaction outcome loss': 0.2118227873317559, 'Total loss': 0.2118227873317559}
2023-01-04 04:50:07,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:07,712 INFO:     Epoch: 64
2023-01-04 04:50:09,331 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49946955442428587, 'Total loss': 0.49946955442428587} | train loss {'Reaction outcome loss': 0.20831877160631795, 'Total loss': 0.20831877160631795}
2023-01-04 04:50:09,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:09,331 INFO:     Epoch: 65
2023-01-04 04:50:10,909 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4899701694647471, 'Total loss': 0.4899701694647471} | train loss {'Reaction outcome loss': 0.20726155747905833, 'Total loss': 0.20726155747905833}
2023-01-04 04:50:10,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:10,909 INFO:     Epoch: 66
2023-01-04 04:50:12,503 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5002099523941675, 'Total loss': 0.5002099523941675} | train loss {'Reaction outcome loss': 0.20696620535607613, 'Total loss': 0.20696620535607613}
2023-01-04 04:50:12,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:12,504 INFO:     Epoch: 67
2023-01-04 04:50:14,094 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4825445125500361, 'Total loss': 0.4825445125500361} | train loss {'Reaction outcome loss': 0.2048692390037262, 'Total loss': 0.2048692390037262}
2023-01-04 04:50:14,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:14,095 INFO:     Epoch: 68
2023-01-04 04:50:15,685 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5306769092877706, 'Total loss': 0.5306769092877706} | train loss {'Reaction outcome loss': 0.20167401235146354, 'Total loss': 0.20167401235146354}
2023-01-04 04:50:15,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:15,685 INFO:     Epoch: 69
2023-01-04 04:50:17,310 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48825294971466066, 'Total loss': 0.48825294971466066} | train loss {'Reaction outcome loss': 0.19996368759472016, 'Total loss': 0.19996368759472016}
2023-01-04 04:50:17,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:17,310 INFO:     Epoch: 70
2023-01-04 04:50:18,928 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5089581564068795, 'Total loss': 0.5089581564068795} | train loss {'Reaction outcome loss': 0.20262281041916297, 'Total loss': 0.20262281041916297}
2023-01-04 04:50:18,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:18,929 INFO:     Epoch: 71
2023-01-04 04:50:20,503 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49991660118103026, 'Total loss': 0.49991660118103026} | train loss {'Reaction outcome loss': 0.20309771283993963, 'Total loss': 0.20309771283993963}
2023-01-04 04:50:20,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:20,503 INFO:     Epoch: 72
2023-01-04 04:50:22,132 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5122533440589905, 'Total loss': 0.5122533440589905} | train loss {'Reaction outcome loss': 0.19872967875225173, 'Total loss': 0.19872967875225173}
2023-01-04 04:50:22,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:22,132 INFO:     Epoch: 73
2023-01-04 04:50:23,757 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.517344456911087, 'Total loss': 0.517344456911087} | train loss {'Reaction outcome loss': 0.19782160955630546, 'Total loss': 0.19782160955630546}
2023-01-04 04:50:23,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:23,757 INFO:     Epoch: 74
2023-01-04 04:50:25,352 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5482580502827962, 'Total loss': 0.5482580502827962} | train loss {'Reaction outcome loss': 0.1952967752427946, 'Total loss': 0.1952967752427946}
2023-01-04 04:50:25,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:25,352 INFO:     Epoch: 75
2023-01-04 04:50:26,959 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.519533692797025, 'Total loss': 0.519533692797025} | train loss {'Reaction outcome loss': 0.19187038657147912, 'Total loss': 0.19187038657147912}
2023-01-04 04:50:26,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:26,959 INFO:     Epoch: 76
2023-01-04 04:50:28,539 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5043700804313024, 'Total loss': 0.5043700804313024} | train loss {'Reaction outcome loss': 0.19294374510375917, 'Total loss': 0.19294374510375917}
2023-01-04 04:50:28,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:28,539 INFO:     Epoch: 77
2023-01-04 04:50:30,136 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5265403320391973, 'Total loss': 0.5265403320391973} | train loss {'Reaction outcome loss': 0.19320636517975642, 'Total loss': 0.19320636517975642}
2023-01-04 04:50:30,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:30,136 INFO:     Epoch: 78
2023-01-04 04:50:31,732 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5249259610970815, 'Total loss': 0.5249259610970815} | train loss {'Reaction outcome loss': 0.1918653705542438, 'Total loss': 0.1918653705542438}
2023-01-04 04:50:31,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:31,733 INFO:     Epoch: 79
2023-01-04 04:50:33,316 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5433911045392354, 'Total loss': 0.5433911045392354} | train loss {'Reaction outcome loss': 0.1920780840162848, 'Total loss': 0.1920780840162848}
2023-01-04 04:50:33,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:33,316 INFO:     Epoch: 80
2023-01-04 04:50:34,920 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.525965138276418, 'Total loss': 0.525965138276418} | train loss {'Reaction outcome loss': 0.18664965969968023, 'Total loss': 0.18664965969968023}
2023-01-04 04:50:34,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:34,920 INFO:     Epoch: 81
2023-01-04 04:50:36,549 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5371675938367844, 'Total loss': 0.5371675938367844} | train loss {'Reaction outcome loss': 0.18673874411013827, 'Total loss': 0.18673874411013827}
2023-01-04 04:50:36,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:36,549 INFO:     Epoch: 82
2023-01-04 04:50:38,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.527171661456426, 'Total loss': 0.527171661456426} | train loss {'Reaction outcome loss': 0.18659181635276595, 'Total loss': 0.18659181635276595}
2023-01-04 04:50:38,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:38,127 INFO:     Epoch: 83
2023-01-04 04:50:39,753 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5597160895665486, 'Total loss': 0.5597160895665486} | train loss {'Reaction outcome loss': 0.186791240698253, 'Total loss': 0.186791240698253}
2023-01-04 04:50:39,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:39,753 INFO:     Epoch: 84
2023-01-04 04:50:41,379 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5375098745028178, 'Total loss': 0.5375098745028178} | train loss {'Reaction outcome loss': 0.1874108725713323, 'Total loss': 0.1874108725713323}
2023-01-04 04:50:41,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:41,379 INFO:     Epoch: 85
2023-01-04 04:50:42,960 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5468855142593384, 'Total loss': 0.5468855142593384} | train loss {'Reaction outcome loss': 0.18331572204403093, 'Total loss': 0.18331572204403093}
2023-01-04 04:50:42,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:42,960 INFO:     Epoch: 86
2023-01-04 04:50:44,584 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5199932153026263, 'Total loss': 0.5199932153026263} | train loss {'Reaction outcome loss': 0.18167381311186415, 'Total loss': 0.18167381311186415}
2023-01-04 04:50:44,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:44,584 INFO:     Epoch: 87
2023-01-04 04:50:46,198 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5675676097472508, 'Total loss': 0.5675676097472508} | train loss {'Reaction outcome loss': 0.18556960946137924, 'Total loss': 0.18556960946137924}
2023-01-04 04:50:46,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:46,198 INFO:     Epoch: 88
2023-01-04 04:50:47,788 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5295799106359482, 'Total loss': 0.5295799106359482} | train loss {'Reaction outcome loss': 0.18792332576560802, 'Total loss': 0.18792332576560802}
2023-01-04 04:50:47,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:47,789 INFO:     Epoch: 89
2023-01-04 04:50:49,378 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5369606534639995, 'Total loss': 0.5369606534639995} | train loss {'Reaction outcome loss': 0.18635314741075729, 'Total loss': 0.18635314741075729}
2023-01-04 04:50:49,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:49,378 INFO:     Epoch: 90
2023-01-04 04:50:50,997 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5758079359928767, 'Total loss': 0.5758079359928767} | train loss {'Reaction outcome loss': 0.1792892826037976, 'Total loss': 0.1792892826037976}
2023-01-04 04:50:50,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:50,997 INFO:     Epoch: 91
2023-01-04 04:50:52,593 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5382635762294133, 'Total loss': 0.5382635762294133} | train loss {'Reaction outcome loss': 0.17938780586996142, 'Total loss': 0.17938780586996142}
2023-01-04 04:50:52,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:52,593 INFO:     Epoch: 92
2023-01-04 04:50:54,191 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5570600966612498, 'Total loss': 0.5570600966612498} | train loss {'Reaction outcome loss': 0.17559159040109185, 'Total loss': 0.17559159040109185}
2023-01-04 04:50:54,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:54,192 INFO:     Epoch: 93
2023-01-04 04:50:55,782 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5438341774046421, 'Total loss': 0.5438341774046421} | train loss {'Reaction outcome loss': 0.17713089529074816, 'Total loss': 0.17713089529074816}
2023-01-04 04:50:55,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:55,782 INFO:     Epoch: 94
2023-01-04 04:50:57,371 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5549389282862346, 'Total loss': 0.5549389282862346} | train loss {'Reaction outcome loss': 0.17541538509241314, 'Total loss': 0.17541538509241314}
2023-01-04 04:50:57,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:57,371 INFO:     Epoch: 95
2023-01-04 04:50:58,993 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5505306164423625, 'Total loss': 0.5505306164423625} | train loss {'Reaction outcome loss': 0.17618073199275017, 'Total loss': 0.17618073199275017}
2023-01-04 04:50:58,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:50:58,994 INFO:     Epoch: 96
2023-01-04 04:51:00,590 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5638511493802071, 'Total loss': 0.5638511493802071} | train loss {'Reaction outcome loss': 0.17394055821400337, 'Total loss': 0.17394055821400337}
2023-01-04 04:51:00,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:00,591 INFO:     Epoch: 97
2023-01-04 04:51:02,192 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5498971184094746, 'Total loss': 0.5498971184094746} | train loss {'Reaction outcome loss': 0.17963467972973982, 'Total loss': 0.17963467972973982}
2023-01-04 04:51:02,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:02,193 INFO:     Epoch: 98
2023-01-04 04:51:03,841 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6067011247078578, 'Total loss': 0.6067011247078578} | train loss {'Reaction outcome loss': 0.18871438071896, 'Total loss': 0.18871438071896}
2023-01-04 04:51:03,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:03,841 INFO:     Epoch: 99
2023-01-04 04:51:05,438 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5626172492901484, 'Total loss': 0.5626172492901484} | train loss {'Reaction outcome loss': 0.17270054900006432, 'Total loss': 0.17270054900006432}
2023-01-04 04:51:05,438 INFO:     Best model found after epoch 23 of 100.
2023-01-04 04:51:05,439 INFO:   Done with stage: TRAINING
2023-01-04 04:51:05,439 INFO:   Starting stage: EVALUATION
2023-01-04 04:51:05,567 INFO:   Done with stage: EVALUATION
2023-01-04 04:51:05,567 INFO:   Leaving out SEQ value Fold_3
2023-01-04 04:51:05,580 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 04:51:05,580 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:51:06,232 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:51:06,233 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:51:06,301 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:51:06,301 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:51:06,301 INFO:     No hyperparam tuning for this model
2023-01-04 04:51:06,301 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:51:06,301 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:51:06,302 INFO:     None feature selector for col prot
2023-01-04 04:51:06,302 INFO:     None feature selector for col prot
2023-01-04 04:51:06,302 INFO:     None feature selector for col prot
2023-01-04 04:51:06,303 INFO:     None feature selector for col chem
2023-01-04 04:51:06,303 INFO:     None feature selector for col chem
2023-01-04 04:51:06,303 INFO:     None feature selector for col chem
2023-01-04 04:51:06,303 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:51:06,303 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:51:06,304 INFO:     Number of params in model 70141
2023-01-04 04:51:06,308 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:51:06,308 INFO:   Starting stage: TRAINING
2023-01-04 04:51:06,354 INFO:     Val loss before train {'Reaction outcome loss': 1.095668077468872, 'Total loss': 1.095668077468872}
2023-01-04 04:51:06,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:06,354 INFO:     Epoch: 0
2023-01-04 04:51:07,981 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7140909671783447, 'Total loss': 0.7140909671783447} | train loss {'Reaction outcome loss': 0.8378911903397976, 'Total loss': 0.8378911903397976}
2023-01-04 04:51:07,981 INFO:     Found new best model at epoch 0
2023-01-04 04:51:07,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:07,982 INFO:     Epoch: 1
2023-01-04 04:51:09,554 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5874010364214579, 'Total loss': 0.5874010364214579} | train loss {'Reaction outcome loss': 0.5869611403989214, 'Total loss': 0.5869611403989214}
2023-01-04 04:51:09,554 INFO:     Found new best model at epoch 1
2023-01-04 04:51:09,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:09,555 INFO:     Epoch: 2
2023-01-04 04:51:11,161 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.565724539756775, 'Total loss': 0.565724539756775} | train loss {'Reaction outcome loss': 0.5190075218077096, 'Total loss': 0.5190075218077096}
2023-01-04 04:51:11,161 INFO:     Found new best model at epoch 2
2023-01-04 04:51:11,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:11,162 INFO:     Epoch: 3
2023-01-04 04:51:12,749 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5324856797854106, 'Total loss': 0.5324856797854106} | train loss {'Reaction outcome loss': 0.48363431323103717, 'Total loss': 0.48363431323103717}
2023-01-04 04:51:12,749 INFO:     Found new best model at epoch 3
2023-01-04 04:51:12,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:12,750 INFO:     Epoch: 4
2023-01-04 04:51:14,361 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5167705317338308, 'Total loss': 0.5167705317338308} | train loss {'Reaction outcome loss': 0.4546315132950743, 'Total loss': 0.4546315132950743}
2023-01-04 04:51:14,361 INFO:     Found new best model at epoch 4
2023-01-04 04:51:14,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:14,362 INFO:     Epoch: 5
2023-01-04 04:51:15,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4879644234975179, 'Total loss': 0.4879644234975179} | train loss {'Reaction outcome loss': 0.4412995393293491, 'Total loss': 0.4412995393293491}
2023-01-04 04:51:15,952 INFO:     Found new best model at epoch 5
2023-01-04 04:51:15,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:15,953 INFO:     Epoch: 6
2023-01-04 04:51:17,578 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4621132721503576, 'Total loss': 0.4621132721503576} | train loss {'Reaction outcome loss': 0.432600444857625, 'Total loss': 0.432600444857625}
2023-01-04 04:51:17,578 INFO:     Found new best model at epoch 6
2023-01-04 04:51:17,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:17,579 INFO:     Epoch: 7
2023-01-04 04:51:19,148 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.469516600171725, 'Total loss': 0.469516600171725} | train loss {'Reaction outcome loss': 0.41228298637746036, 'Total loss': 0.41228298637746036}
2023-01-04 04:51:19,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:19,149 INFO:     Epoch: 8
2023-01-04 04:51:20,728 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4503539323806763, 'Total loss': 0.4503539323806763} | train loss {'Reaction outcome loss': 0.39918849093542585, 'Total loss': 0.39918849093542585}
2023-01-04 04:51:20,728 INFO:     Found new best model at epoch 8
2023-01-04 04:51:20,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:20,729 INFO:     Epoch: 9
2023-01-04 04:51:22,328 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4776926358540853, 'Total loss': 0.4776926358540853} | train loss {'Reaction outcome loss': 0.38768763395964395, 'Total loss': 0.38768763395964395}
2023-01-04 04:51:22,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:22,329 INFO:     Epoch: 10
2023-01-04 04:51:23,955 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43747676809628805, 'Total loss': 0.43747676809628805} | train loss {'Reaction outcome loss': 0.3815156900040481, 'Total loss': 0.3815156900040481}
2023-01-04 04:51:23,955 INFO:     Found new best model at epoch 10
2023-01-04 04:51:23,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:23,956 INFO:     Epoch: 11
2023-01-04 04:51:25,542 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43885764678319295, 'Total loss': 0.43885764678319295} | train loss {'Reaction outcome loss': 0.3778916285035835, 'Total loss': 0.3778916285035835}
2023-01-04 04:51:25,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:25,543 INFO:     Epoch: 12
2023-01-04 04:51:27,122 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4458911220232646, 'Total loss': 0.4458911220232646} | train loss {'Reaction outcome loss': 0.3708280642395434, 'Total loss': 0.3708280642395434}
2023-01-04 04:51:27,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:27,122 INFO:     Epoch: 13
2023-01-04 04:51:28,716 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4423912286758423, 'Total loss': 0.4423912286758423} | train loss {'Reaction outcome loss': 0.36258626367518865, 'Total loss': 0.36258626367518865}
2023-01-04 04:51:28,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:28,716 INFO:     Epoch: 14
2023-01-04 04:51:30,311 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.433168097337087, 'Total loss': 0.433168097337087} | train loss {'Reaction outcome loss': 0.3518940097503904, 'Total loss': 0.3518940097503904}
2023-01-04 04:51:30,311 INFO:     Found new best model at epoch 14
2023-01-04 04:51:30,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:30,312 INFO:     Epoch: 15
2023-01-04 04:51:31,910 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4276284992694855, 'Total loss': 0.4276284992694855} | train loss {'Reaction outcome loss': 0.34616427847008774, 'Total loss': 0.34616427847008774}
2023-01-04 04:51:31,910 INFO:     Found new best model at epoch 15
2023-01-04 04:51:31,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:31,911 INFO:     Epoch: 16
2023-01-04 04:51:33,501 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4481291929880778, 'Total loss': 0.4481291929880778} | train loss {'Reaction outcome loss': 0.33737366085541365, 'Total loss': 0.33737366085541365}
2023-01-04 04:51:33,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:33,501 INFO:     Epoch: 17
2023-01-04 04:51:35,094 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42823333938916525, 'Total loss': 0.42823333938916525} | train loss {'Reaction outcome loss': 0.32968346498766576, 'Total loss': 0.32968346498766576}
2023-01-04 04:51:35,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:35,094 INFO:     Epoch: 18
2023-01-04 04:51:36,695 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4442876289288203, 'Total loss': 0.4442876289288203} | train loss {'Reaction outcome loss': 0.33176672582825023, 'Total loss': 0.33176672582825023}
2023-01-04 04:51:36,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:36,695 INFO:     Epoch: 19
2023-01-04 04:51:38,285 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42856895724932353, 'Total loss': 0.42856895724932353} | train loss {'Reaction outcome loss': 0.32551960328145063, 'Total loss': 0.32551960328145063}
2023-01-04 04:51:38,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:38,286 INFO:     Epoch: 20
2023-01-04 04:51:39,866 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44936508138974507, 'Total loss': 0.44936508138974507} | train loss {'Reaction outcome loss': 0.3153471476904562, 'Total loss': 0.3153471476904562}
2023-01-04 04:51:39,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:39,866 INFO:     Epoch: 21
2023-01-04 04:51:41,492 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4432632327079773, 'Total loss': 0.4432632327079773} | train loss {'Reaction outcome loss': 0.31142526615977933, 'Total loss': 0.31142526615977933}
2023-01-04 04:51:41,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:41,492 INFO:     Epoch: 22
2023-01-04 04:51:43,096 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44169718225797017, 'Total loss': 0.44169718225797017} | train loss {'Reaction outcome loss': 0.3071898231147856, 'Total loss': 0.3071898231147856}
2023-01-04 04:51:43,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:43,096 INFO:     Epoch: 23
2023-01-04 04:51:44,706 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43823794821898143, 'Total loss': 0.43823794821898143} | train loss {'Reaction outcome loss': 0.3036090616116543, 'Total loss': 0.3036090616116543}
2023-01-04 04:51:44,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:44,707 INFO:     Epoch: 24
2023-01-04 04:51:46,333 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43243904610474904, 'Total loss': 0.43243904610474904} | train loss {'Reaction outcome loss': 0.29751438561125076, 'Total loss': 0.29751438561125076}
2023-01-04 04:51:46,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:46,333 INFO:     Epoch: 25
2023-01-04 04:51:47,954 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4555985450744629, 'Total loss': 0.4555985450744629} | train loss {'Reaction outcome loss': 0.2940889217669779, 'Total loss': 0.2940889217669779}
2023-01-04 04:51:47,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:47,954 INFO:     Epoch: 26
2023-01-04 04:51:49,539 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.46040471295515695, 'Total loss': 0.46040471295515695} | train loss {'Reaction outcome loss': 0.28884250076700246, 'Total loss': 0.28884250076700246}
2023-01-04 04:51:49,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:49,539 INFO:     Epoch: 27
2023-01-04 04:51:51,134 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4497583558162053, 'Total loss': 0.4497583558162053} | train loss {'Reaction outcome loss': 0.28630973871095455, 'Total loss': 0.28630973871095455}
2023-01-04 04:51:51,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:51,135 INFO:     Epoch: 28
2023-01-04 04:51:52,728 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44744911789894104, 'Total loss': 0.44744911789894104} | train loss {'Reaction outcome loss': 0.2822882325280512, 'Total loss': 0.2822882325280512}
2023-01-04 04:51:52,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:52,729 INFO:     Epoch: 29
2023-01-04 04:51:54,307 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46228012839953103, 'Total loss': 0.46228012839953103} | train loss {'Reaction outcome loss': 0.27722537336154823, 'Total loss': 0.27722537336154823}
2023-01-04 04:51:54,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:54,308 INFO:     Epoch: 30
2023-01-04 04:51:55,901 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4327547301848729, 'Total loss': 0.4327547301848729} | train loss {'Reaction outcome loss': 0.2741544166971268, 'Total loss': 0.2741544166971268}
2023-01-04 04:51:55,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:55,901 INFO:     Epoch: 31
2023-01-04 04:51:57,491 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45351141691207886, 'Total loss': 0.45351141691207886} | train loss {'Reaction outcome loss': 0.27101999990291137, 'Total loss': 0.27101999990291137}
2023-01-04 04:51:57,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:57,491 INFO:     Epoch: 32
2023-01-04 04:51:59,072 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46718192199865977, 'Total loss': 0.46718192199865977} | train loss {'Reaction outcome loss': 0.2702166008470079, 'Total loss': 0.2702166008470079}
2023-01-04 04:51:59,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:51:59,072 INFO:     Epoch: 33
2023-01-04 04:52:00,664 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44921314120292666, 'Total loss': 0.44921314120292666} | train loss {'Reaction outcome loss': 0.26688541692641116, 'Total loss': 0.26688541692641116}
2023-01-04 04:52:00,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:00,665 INFO:     Epoch: 34
2023-01-04 04:52:02,255 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46315943201382953, 'Total loss': 0.46315943201382953} | train loss {'Reaction outcome loss': 0.2682390447598005, 'Total loss': 0.2682390447598005}
2023-01-04 04:52:02,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:02,256 INFO:     Epoch: 35
2023-01-04 04:52:03,823 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4453010678291321, 'Total loss': 0.4453010678291321} | train loss {'Reaction outcome loss': 0.2677524579635444, 'Total loss': 0.2677524579635444}
2023-01-04 04:52:03,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:03,823 INFO:     Epoch: 36
2023-01-04 04:52:05,441 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4465946137905121, 'Total loss': 0.4465946137905121} | train loss {'Reaction outcome loss': 0.2571828447761473, 'Total loss': 0.2571828447761473}
2023-01-04 04:52:05,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:05,441 INFO:     Epoch: 37
2023-01-04 04:52:07,046 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4841785957415899, 'Total loss': 0.4841785957415899} | train loss {'Reaction outcome loss': 0.25692186324749194, 'Total loss': 0.25692186324749194}
2023-01-04 04:52:07,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:07,046 INFO:     Epoch: 38
2023-01-04 04:52:08,668 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44313836594422656, 'Total loss': 0.44313836594422656} | train loss {'Reaction outcome loss': 0.25215315688430984, 'Total loss': 0.25215315688430984}
2023-01-04 04:52:08,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:08,668 INFO:     Epoch: 39
2023-01-04 04:52:10,293 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45329201221466064, 'Total loss': 0.45329201221466064} | train loss {'Reaction outcome loss': 0.24873490178404187, 'Total loss': 0.24873490178404187}
2023-01-04 04:52:10,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:10,293 INFO:     Epoch: 40
2023-01-04 04:52:11,870 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46962202588717145, 'Total loss': 0.46962202588717145} | train loss {'Reaction outcome loss': 0.24901289265224055, 'Total loss': 0.24901289265224055}
2023-01-04 04:52:11,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:11,871 INFO:     Epoch: 41
2023-01-04 04:52:13,473 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46804937918980916, 'Total loss': 0.46804937918980916} | train loss {'Reaction outcome loss': 0.24381070791919163, 'Total loss': 0.24381070791919163}
2023-01-04 04:52:13,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:13,474 INFO:     Epoch: 42
2023-01-04 04:52:15,093 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4574733505646388, 'Total loss': 0.4574733505646388} | train loss {'Reaction outcome loss': 0.24296761138590967, 'Total loss': 0.24296761138590967}
2023-01-04 04:52:15,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:15,094 INFO:     Epoch: 43
2023-01-04 04:52:16,681 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46705728669961294, 'Total loss': 0.46705728669961294} | train loss {'Reaction outcome loss': 0.24008650015499713, 'Total loss': 0.24008650015499713}
2023-01-04 04:52:16,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:16,681 INFO:     Epoch: 44
2023-01-04 04:52:18,310 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46797706683476764, 'Total loss': 0.46797706683476764} | train loss {'Reaction outcome loss': 0.23758052557747325, 'Total loss': 0.23758052557747325}
2023-01-04 04:52:18,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:18,310 INFO:     Epoch: 45
2023-01-04 04:52:19,931 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46156359612941744, 'Total loss': 0.46156359612941744} | train loss {'Reaction outcome loss': 0.23403493388542446, 'Total loss': 0.23403493388542446}
2023-01-04 04:52:19,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:19,931 INFO:     Epoch: 46
2023-01-04 04:52:21,525 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4527076999346415, 'Total loss': 0.4527076999346415} | train loss {'Reaction outcome loss': 0.23389352453734213, 'Total loss': 0.23389352453734213}
2023-01-04 04:52:21,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:21,525 INFO:     Epoch: 47
2023-01-04 04:52:23,148 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45697369625171025, 'Total loss': 0.45697369625171025} | train loss {'Reaction outcome loss': 0.22997841435152214, 'Total loss': 0.22997841435152214}
2023-01-04 04:52:23,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:23,149 INFO:     Epoch: 48
2023-01-04 04:52:24,748 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44544804394245147, 'Total loss': 0.44544804394245147} | train loss {'Reaction outcome loss': 0.2307708687621398, 'Total loss': 0.2307708687621398}
2023-01-04 04:52:24,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:24,749 INFO:     Epoch: 49
2023-01-04 04:52:26,362 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4494111821055412, 'Total loss': 0.4494111821055412} | train loss {'Reaction outcome loss': 0.23498131927318763, 'Total loss': 0.23498131927318763}
2023-01-04 04:52:26,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:26,362 INFO:     Epoch: 50
2023-01-04 04:52:27,980 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4668027947346369, 'Total loss': 0.4668027947346369} | train loss {'Reaction outcome loss': 0.23303854320977774, 'Total loss': 0.23303854320977774}
2023-01-04 04:52:27,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:27,981 INFO:     Epoch: 51
2023-01-04 04:52:29,586 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45442322790622713, 'Total loss': 0.45442322790622713} | train loss {'Reaction outcome loss': 0.22247844593822147, 'Total loss': 0.22247844593822147}
2023-01-04 04:52:29,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:29,586 INFO:     Epoch: 52
2023-01-04 04:52:31,176 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.478886616230011, 'Total loss': 0.478886616230011} | train loss {'Reaction outcome loss': 0.21980983140109447, 'Total loss': 0.21980983140109447}
2023-01-04 04:52:31,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:31,177 INFO:     Epoch: 53
2023-01-04 04:52:32,773 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47555841455856956, 'Total loss': 0.47555841455856956} | train loss {'Reaction outcome loss': 0.22210488754554072, 'Total loss': 0.22210488754554072}
2023-01-04 04:52:32,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:32,773 INFO:     Epoch: 54
2023-01-04 04:52:34,351 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4787638376156489, 'Total loss': 0.4787638376156489} | train loss {'Reaction outcome loss': 0.2203590899462933, 'Total loss': 0.2203590899462933}
2023-01-04 04:52:34,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:34,351 INFO:     Epoch: 55
2023-01-04 04:52:35,952 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4622882823149363, 'Total loss': 0.4622882823149363} | train loss {'Reaction outcome loss': 0.22516845207175482, 'Total loss': 0.22516845207175482}
2023-01-04 04:52:35,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:35,952 INFO:     Epoch: 56
2023-01-04 04:52:37,560 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4608992064992587, 'Total loss': 0.4608992064992587} | train loss {'Reaction outcome loss': 0.22868800024245528, 'Total loss': 0.22868800024245528}
2023-01-04 04:52:37,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:37,561 INFO:     Epoch: 57
2023-01-04 04:52:39,164 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48567029436429343, 'Total loss': 0.48567029436429343} | train loss {'Reaction outcome loss': 0.21403383431902182, 'Total loss': 0.21403383431902182}
2023-01-04 04:52:39,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:39,165 INFO:     Epoch: 58
2023-01-04 04:52:40,803 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4836366583903631, 'Total loss': 0.4836366583903631} | train loss {'Reaction outcome loss': 0.2117430192782827, 'Total loss': 0.2117430192782827}
2023-01-04 04:52:40,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:40,803 INFO:     Epoch: 59
2023-01-04 04:52:42,429 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48472654322783154, 'Total loss': 0.48472654322783154} | train loss {'Reaction outcome loss': 0.22468534954216168, 'Total loss': 0.22468534954216168}
2023-01-04 04:52:42,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:42,429 INFO:     Epoch: 60
2023-01-04 04:52:44,035 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4849721093972524, 'Total loss': 0.4849721093972524} | train loss {'Reaction outcome loss': 0.2214508429897778, 'Total loss': 0.2214508429897778}
2023-01-04 04:52:44,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:44,036 INFO:     Epoch: 61
2023-01-04 04:52:45,654 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4761586884657542, 'Total loss': 0.4761586884657542} | train loss {'Reaction outcome loss': 0.21525203447411026, 'Total loss': 0.21525203447411026}
2023-01-04 04:52:45,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:45,654 INFO:     Epoch: 62
2023-01-04 04:52:47,262 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4950548847516378, 'Total loss': 0.4950548847516378} | train loss {'Reaction outcome loss': 0.22471681353551726, 'Total loss': 0.22471681353551726}
2023-01-04 04:52:47,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:47,262 INFO:     Epoch: 63
2023-01-04 04:52:48,849 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4690794100364049, 'Total loss': 0.4690794100364049} | train loss {'Reaction outcome loss': 0.2081531748845009, 'Total loss': 0.2081531748845009}
2023-01-04 04:52:48,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:48,849 INFO:     Epoch: 64
2023-01-04 04:52:50,479 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4882144232590993, 'Total loss': 0.4882144232590993} | train loss {'Reaction outcome loss': 0.2025988653227957, 'Total loss': 0.2025988653227957}
2023-01-04 04:52:50,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:50,479 INFO:     Epoch: 65
2023-01-04 04:52:52,069 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4569538364807765, 'Total loss': 0.4569538364807765} | train loss {'Reaction outcome loss': 0.20299055370286215, 'Total loss': 0.20299055370286215}
2023-01-04 04:52:52,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:52,070 INFO:     Epoch: 66
2023-01-04 04:52:53,694 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4720694124698639, 'Total loss': 0.4720694124698639} | train loss {'Reaction outcome loss': 0.2013260273590171, 'Total loss': 0.2013260273590171}
2023-01-04 04:52:53,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:53,694 INFO:     Epoch: 67
2023-01-04 04:52:55,316 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48866040309270226, 'Total loss': 0.48866040309270226} | train loss {'Reaction outcome loss': 0.20308247661718717, 'Total loss': 0.20308247661718717}
2023-01-04 04:52:55,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:55,317 INFO:     Epoch: 68
2023-01-04 04:52:56,919 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5112751543521881, 'Total loss': 0.5112751543521881} | train loss {'Reaction outcome loss': 0.19967789637351982, 'Total loss': 0.19967789637351982}
2023-01-04 04:52:56,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:56,920 INFO:     Epoch: 69
2023-01-04 04:52:58,517 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5145492096741994, 'Total loss': 0.5145492096741994} | train loss {'Reaction outcome loss': 0.20631783342231874, 'Total loss': 0.20631783342231874}
2023-01-04 04:52:58,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:52:58,517 INFO:     Epoch: 70
2023-01-04 04:53:00,114 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4932263116041819, 'Total loss': 0.4932263116041819} | train loss {'Reaction outcome loss': 0.21540472158433302, 'Total loss': 0.21540472158433302}
2023-01-04 04:53:00,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:00,114 INFO:     Epoch: 71
2023-01-04 04:53:01,699 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5024306267499924, 'Total loss': 0.5024306267499924} | train loss {'Reaction outcome loss': 0.19737599142388426, 'Total loss': 0.19737599142388426}
2023-01-04 04:53:01,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:01,700 INFO:     Epoch: 72
2023-01-04 04:53:03,295 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.480983446041743, 'Total loss': 0.480983446041743} | train loss {'Reaction outcome loss': 0.2009409363584026, 'Total loss': 0.2009409363584026}
2023-01-04 04:53:03,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:03,295 INFO:     Epoch: 73
2023-01-04 04:53:04,892 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4884788811206818, 'Total loss': 0.4884788811206818} | train loss {'Reaction outcome loss': 0.20496901152881142, 'Total loss': 0.20496901152881142}
2023-01-04 04:53:04,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:04,892 INFO:     Epoch: 74
2023-01-04 04:53:06,479 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5023191303014756, 'Total loss': 0.5023191303014756} | train loss {'Reaction outcome loss': 0.19606121380533348, 'Total loss': 0.19606121380533348}
2023-01-04 04:53:06,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:06,479 INFO:     Epoch: 75
2023-01-04 04:53:08,075 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4604407399892807, 'Total loss': 0.4604407399892807} | train loss {'Reaction outcome loss': 0.1951137619517643, 'Total loss': 0.1951137619517643}
2023-01-04 04:53:08,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:08,076 INFO:     Epoch: 76
2023-01-04 04:53:09,661 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5019696692625681, 'Total loss': 0.5019696692625681} | train loss {'Reaction outcome loss': 0.19379990470453934, 'Total loss': 0.19379990470453934}
2023-01-04 04:53:09,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:09,662 INFO:     Epoch: 77
2023-01-04 04:53:11,254 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49505662520726523, 'Total loss': 0.49505662520726523} | train loss {'Reaction outcome loss': 0.1932733338190187, 'Total loss': 0.1932733338190187}
2023-01-04 04:53:11,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:11,254 INFO:     Epoch: 78
2023-01-04 04:53:12,850 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5053875207901001, 'Total loss': 0.5053875207901001} | train loss {'Reaction outcome loss': 0.19381580168408327, 'Total loss': 0.19381580168408327}
2023-01-04 04:53:12,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:12,850 INFO:     Epoch: 79
2023-01-04 04:53:14,439 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4936709846059481, 'Total loss': 0.4936709846059481} | train loss {'Reaction outcome loss': 0.19126202865247277, 'Total loss': 0.19126202865247277}
2023-01-04 04:53:14,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:14,440 INFO:     Epoch: 80
2023-01-04 04:53:16,018 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4811065152287483, 'Total loss': 0.4811065152287483} | train loss {'Reaction outcome loss': 0.1923351490168252, 'Total loss': 0.1923351490168252}
2023-01-04 04:53:16,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:16,019 INFO:     Epoch: 81
2023-01-04 04:53:17,630 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5071424235900243, 'Total loss': 0.5071424235900243} | train loss {'Reaction outcome loss': 0.19204873982116755, 'Total loss': 0.19204873982116755}
2023-01-04 04:53:17,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:17,630 INFO:     Epoch: 82
2023-01-04 04:53:19,216 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48970838586489357, 'Total loss': 0.48970838586489357} | train loss {'Reaction outcome loss': 0.18967474433863402, 'Total loss': 0.18967474433863402}
2023-01-04 04:53:19,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:19,217 INFO:     Epoch: 83
2023-01-04 04:53:20,834 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5360541482766469, 'Total loss': 0.5360541482766469} | train loss {'Reaction outcome loss': 0.18823494154956122, 'Total loss': 0.18823494154956122}
2023-01-04 04:53:20,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:20,834 INFO:     Epoch: 84
2023-01-04 04:53:22,468 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5076856811841329, 'Total loss': 0.5076856811841329} | train loss {'Reaction outcome loss': 0.1884901704413452, 'Total loss': 0.1884901704413452}
2023-01-04 04:53:22,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:22,469 INFO:     Epoch: 85
2023-01-04 04:53:24,064 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5392219603061676, 'Total loss': 0.5392219603061676} | train loss {'Reaction outcome loss': 0.188275417711892, 'Total loss': 0.188275417711892}
2023-01-04 04:53:24,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:24,064 INFO:     Epoch: 86
2023-01-04 04:53:25,669 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5347765405972799, 'Total loss': 0.5347765405972799} | train loss {'Reaction outcome loss': 0.18557685147433126, 'Total loss': 0.18557685147433126}
2023-01-04 04:53:25,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:25,670 INFO:     Epoch: 87
2023-01-04 04:53:27,289 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5349225163459778, 'Total loss': 0.5349225163459778} | train loss {'Reaction outcome loss': 0.18468672076646792, 'Total loss': 0.18468672076646792}
2023-01-04 04:53:27,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:27,290 INFO:     Epoch: 88
2023-01-04 04:53:28,885 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5128928403059642, 'Total loss': 0.5128928403059642} | train loss {'Reaction outcome loss': 0.18530468130315506, 'Total loss': 0.18530468130315506}
2023-01-04 04:53:28,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:28,885 INFO:     Epoch: 89
2023-01-04 04:53:30,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5207578619321187, 'Total loss': 0.5207578619321187} | train loss {'Reaction outcome loss': 0.1827133164350517, 'Total loss': 0.1827133164350517}
2023-01-04 04:53:30,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:30,514 INFO:     Epoch: 90
2023-01-04 04:53:32,135 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.521540054678917, 'Total loss': 0.521540054678917} | train loss {'Reaction outcome loss': 0.19248163281683472, 'Total loss': 0.19248163281683472}
2023-01-04 04:53:32,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:32,136 INFO:     Epoch: 91
2023-01-04 04:53:33,722 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49391962960362434, 'Total loss': 0.49391962960362434} | train loss {'Reaction outcome loss': 0.19355085535325867, 'Total loss': 0.19355085535325867}
2023-01-04 04:53:33,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:33,722 INFO:     Epoch: 92
2023-01-04 04:53:35,350 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.512760712703069, 'Total loss': 0.512760712703069} | train loss {'Reaction outcome loss': 0.1860070414802159, 'Total loss': 0.1860070414802159}
2023-01-04 04:53:35,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:35,350 INFO:     Epoch: 93
2023-01-04 04:53:36,943 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5111357231934865, 'Total loss': 0.5111357231934865} | train loss {'Reaction outcome loss': 0.1821663647106502, 'Total loss': 0.1821663647106502}
2023-01-04 04:53:36,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:36,944 INFO:     Epoch: 94
2023-01-04 04:53:38,540 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5178546567757925, 'Total loss': 0.5178546567757925} | train loss {'Reaction outcome loss': 0.18019011052535422, 'Total loss': 0.18019011052535422}
2023-01-04 04:53:38,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:38,540 INFO:     Epoch: 95
2023-01-04 04:53:40,136 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4942402203877767, 'Total loss': 0.4942402203877767} | train loss {'Reaction outcome loss': 0.17853728239846323, 'Total loss': 0.17853728239846323}
2023-01-04 04:53:40,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:40,136 INFO:     Epoch: 96
2023-01-04 04:53:41,724 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5201258798440297, 'Total loss': 0.5201258798440297} | train loss {'Reaction outcome loss': 0.17900163232859442, 'Total loss': 0.17900163232859442}
2023-01-04 04:53:41,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:41,724 INFO:     Epoch: 97
2023-01-04 04:53:43,321 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5144254475831985, 'Total loss': 0.5144254475831985} | train loss {'Reaction outcome loss': 0.18027942984000497, 'Total loss': 0.18027942984000497}
2023-01-04 04:53:43,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:43,321 INFO:     Epoch: 98
2023-01-04 04:53:44,921 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4901591032743454, 'Total loss': 0.4901591032743454} | train loss {'Reaction outcome loss': 0.18796350775907436, 'Total loss': 0.18796350775907436}
2023-01-04 04:53:44,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:44,922 INFO:     Epoch: 99
2023-01-04 04:53:46,498 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5243317822615305, 'Total loss': 0.5243317822615305} | train loss {'Reaction outcome loss': 0.18442240844318725, 'Total loss': 0.18442240844318725}
2023-01-04 04:53:46,498 INFO:     Best model found after epoch 16 of 100.
2023-01-04 04:53:46,498 INFO:   Done with stage: TRAINING
2023-01-04 04:53:46,498 INFO:   Starting stage: EVALUATION
2023-01-04 04:53:46,627 INFO:   Done with stage: EVALUATION
2023-01-04 04:53:46,627 INFO:   Leaving out SEQ value Fold_4
2023-01-04 04:53:46,640 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 04:53:46,640 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:53:47,306 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:53:47,306 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:53:47,374 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:53:47,375 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:53:47,375 INFO:     No hyperparam tuning for this model
2023-01-04 04:53:47,375 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:53:47,375 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:53:47,376 INFO:     None feature selector for col prot
2023-01-04 04:53:47,376 INFO:     None feature selector for col prot
2023-01-04 04:53:47,376 INFO:     None feature selector for col prot
2023-01-04 04:53:47,376 INFO:     None feature selector for col chem
2023-01-04 04:53:47,376 INFO:     None feature selector for col chem
2023-01-04 04:53:47,376 INFO:     None feature selector for col chem
2023-01-04 04:53:47,377 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:53:47,377 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:53:47,378 INFO:     Number of params in model 70141
2023-01-04 04:53:47,381 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:53:47,381 INFO:   Starting stage: TRAINING
2023-01-04 04:53:47,426 INFO:     Val loss before train {'Reaction outcome loss': 1.027638312180837, 'Total loss': 1.027638312180837}
2023-01-04 04:53:47,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:47,426 INFO:     Epoch: 0
2023-01-04 04:53:49,028 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.693785301844279, 'Total loss': 0.693785301844279} | train loss {'Reaction outcome loss': 0.85854030914255, 'Total loss': 0.85854030914255}
2023-01-04 04:53:49,028 INFO:     Found new best model at epoch 0
2023-01-04 04:53:49,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:49,029 INFO:     Epoch: 1
2023-01-04 04:53:50,615 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6022578914960225, 'Total loss': 0.6022578914960225} | train loss {'Reaction outcome loss': 0.6222892313227326, 'Total loss': 0.6222892313227326}
2023-01-04 04:53:50,615 INFO:     Found new best model at epoch 1
2023-01-04 04:53:50,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:50,616 INFO:     Epoch: 2
2023-01-04 04:53:52,215 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5432271480560302, 'Total loss': 0.5432271480560302} | train loss {'Reaction outcome loss': 0.5358223537460561, 'Total loss': 0.5358223537460561}
2023-01-04 04:53:52,216 INFO:     Found new best model at epoch 2
2023-01-04 04:53:52,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:52,216 INFO:     Epoch: 3
2023-01-04 04:53:53,817 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5453480223814646, 'Total loss': 0.5453480223814646} | train loss {'Reaction outcome loss': 0.49317521620743543, 'Total loss': 0.49317521620743543}
2023-01-04 04:53:53,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:53,817 INFO:     Epoch: 4
2023-01-04 04:53:55,400 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5234121203422546, 'Total loss': 0.5234121203422546} | train loss {'Reaction outcome loss': 0.4688671389964513, 'Total loss': 0.4688671389964513}
2023-01-04 04:53:55,400 INFO:     Found new best model at epoch 4
2023-01-04 04:53:55,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:55,401 INFO:     Epoch: 5
2023-01-04 04:53:56,996 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5095225930213928, 'Total loss': 0.5095225930213928} | train loss {'Reaction outcome loss': 0.45120786501612475, 'Total loss': 0.45120786501612475}
2023-01-04 04:53:56,996 INFO:     Found new best model at epoch 5
2023-01-04 04:53:56,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:56,997 INFO:     Epoch: 6
2023-01-04 04:53:58,607 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5034427146116892, 'Total loss': 0.5034427146116892} | train loss {'Reaction outcome loss': 0.4360492469386504, 'Total loss': 0.4360492469386504}
2023-01-04 04:53:58,607 INFO:     Found new best model at epoch 6
2023-01-04 04:53:58,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:53:58,608 INFO:     Epoch: 7
2023-01-04 04:54:00,216 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.489830082654953, 'Total loss': 0.489830082654953} | train loss {'Reaction outcome loss': 0.4243681240383038, 'Total loss': 0.4243681240383038}
2023-01-04 04:54:00,216 INFO:     Found new best model at epoch 7
2023-01-04 04:54:00,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:00,217 INFO:     Epoch: 8
2023-01-04 04:54:01,839 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49408676028251647, 'Total loss': 0.49408676028251647} | train loss {'Reaction outcome loss': 0.41071069584856823, 'Total loss': 0.41071069584856823}
2023-01-04 04:54:01,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:01,840 INFO:     Epoch: 9
2023-01-04 04:54:03,431 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48027060031890867, 'Total loss': 0.48027060031890867} | train loss {'Reaction outcome loss': 0.40127325708900546, 'Total loss': 0.40127325708900546}
2023-01-04 04:54:03,432 INFO:     Found new best model at epoch 9
2023-01-04 04:54:03,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:03,432 INFO:     Epoch: 10
2023-01-04 04:54:05,022 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4741605391105016, 'Total loss': 0.4741605391105016} | train loss {'Reaction outcome loss': 0.39308225538326086, 'Total loss': 0.39308225538326086}
2023-01-04 04:54:05,022 INFO:     Found new best model at epoch 10
2023-01-04 04:54:05,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:05,023 INFO:     Epoch: 11
2023-01-04 04:54:06,627 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4744670947392782, 'Total loss': 0.4744670947392782} | train loss {'Reaction outcome loss': 0.3823381711591022, 'Total loss': 0.3823381711591022}
2023-01-04 04:54:06,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:06,628 INFO:     Epoch: 12
2023-01-04 04:54:08,248 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.461451123158137, 'Total loss': 0.461451123158137} | train loss {'Reaction outcome loss': 0.3750749475689141, 'Total loss': 0.3750749475689141}
2023-01-04 04:54:08,249 INFO:     Found new best model at epoch 12
2023-01-04 04:54:08,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:08,250 INFO:     Epoch: 13
2023-01-04 04:54:09,839 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4692165007193883, 'Total loss': 0.4692165007193883} | train loss {'Reaction outcome loss': 0.36767390440302206, 'Total loss': 0.36767390440302206}
2023-01-04 04:54:09,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:09,839 INFO:     Epoch: 14
2023-01-04 04:54:11,470 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4667743543783824, 'Total loss': 0.4667743543783824} | train loss {'Reaction outcome loss': 0.35939807216182945, 'Total loss': 0.35939807216182945}
2023-01-04 04:54:11,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:11,471 INFO:     Epoch: 15
2023-01-04 04:54:13,073 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.456938362121582, 'Total loss': 0.456938362121582} | train loss {'Reaction outcome loss': 0.3528803846519777, 'Total loss': 0.3528803846519777}
2023-01-04 04:54:13,073 INFO:     Found new best model at epoch 15
2023-01-04 04:54:13,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:13,074 INFO:     Epoch: 16
2023-01-04 04:54:14,708 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47555534839630126, 'Total loss': 0.47555534839630126} | train loss {'Reaction outcome loss': 0.34729633902599666, 'Total loss': 0.34729633902599666}
2023-01-04 04:54:14,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:14,709 INFO:     Epoch: 17
2023-01-04 04:54:16,341 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4529570023218791, 'Total loss': 0.4529570023218791} | train loss {'Reaction outcome loss': 0.3400776951644395, 'Total loss': 0.3400776951644395}
2023-01-04 04:54:16,342 INFO:     Found new best model at epoch 17
2023-01-04 04:54:16,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:16,343 INFO:     Epoch: 18
2023-01-04 04:54:17,925 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4639957010746002, 'Total loss': 0.4639957010746002} | train loss {'Reaction outcome loss': 0.3335004742610325, 'Total loss': 0.3335004742610325}
2023-01-04 04:54:17,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:17,925 INFO:     Epoch: 19
2023-01-04 04:54:19,533 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46227352023124696, 'Total loss': 0.46227352023124696} | train loss {'Reaction outcome loss': 0.32955551499816915, 'Total loss': 0.32955551499816915}
2023-01-04 04:54:19,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:19,533 INFO:     Epoch: 20
2023-01-04 04:54:21,153 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.467423802614212, 'Total loss': 0.467423802614212} | train loss {'Reaction outcome loss': 0.3229018255046128, 'Total loss': 0.3229018255046128}
2023-01-04 04:54:21,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:21,154 INFO:     Epoch: 21
2023-01-04 04:54:22,743 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4636410733064016, 'Total loss': 0.4636410733064016} | train loss {'Reaction outcome loss': 0.32135805767365744, 'Total loss': 0.32135805767365744}
2023-01-04 04:54:22,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:22,743 INFO:     Epoch: 22
2023-01-04 04:54:24,344 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4542297144730886, 'Total loss': 0.4542297144730886} | train loss {'Reaction outcome loss': 0.3151305014207045, 'Total loss': 0.3151305014207045}
2023-01-04 04:54:24,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:24,344 INFO:     Epoch: 23
2023-01-04 04:54:25,950 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4603930234909058, 'Total loss': 0.4603930234909058} | train loss {'Reaction outcome loss': 0.31008731971901676, 'Total loss': 0.31008731971901676}
2023-01-04 04:54:25,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:25,950 INFO:     Epoch: 24
2023-01-04 04:54:27,553 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47447043855985005, 'Total loss': 0.47447043855985005} | train loss {'Reaction outcome loss': 0.3042179265930334, 'Total loss': 0.3042179265930334}
2023-01-04 04:54:27,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:27,554 INFO:     Epoch: 25
2023-01-04 04:54:29,168 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4634469042221705, 'Total loss': 0.4634469042221705} | train loss {'Reaction outcome loss': 0.3020105701114727, 'Total loss': 0.3020105701114727}
2023-01-04 04:54:29,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:29,168 INFO:     Epoch: 26
2023-01-04 04:54:30,756 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4732286810874939, 'Total loss': 0.4732286810874939} | train loss {'Reaction outcome loss': 0.2995377901928089, 'Total loss': 0.2995377901928089}
2023-01-04 04:54:30,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:30,756 INFO:     Epoch: 27
2023-01-04 04:54:32,358 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4616622438033422, 'Total loss': 0.4616622438033422} | train loss {'Reaction outcome loss': 0.2951481708389327, 'Total loss': 0.2951481708389327}
2023-01-04 04:54:32,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:32,360 INFO:     Epoch: 28
2023-01-04 04:54:33,962 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4920745015144348, 'Total loss': 0.4920745015144348} | train loss {'Reaction outcome loss': 0.2922566869037246, 'Total loss': 0.2922566869037246}
2023-01-04 04:54:33,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:33,962 INFO:     Epoch: 29
2023-01-04 04:54:35,564 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4544960300127665, 'Total loss': 0.4544960300127665} | train loss {'Reaction outcome loss': 0.28878858728529316, 'Total loss': 0.28878858728529316}
2023-01-04 04:54:35,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:35,564 INFO:     Epoch: 30
2023-01-04 04:54:37,165 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48143568336963655, 'Total loss': 0.48143568336963655} | train loss {'Reaction outcome loss': 0.2840446322510819, 'Total loss': 0.2840446322510819}
2023-01-04 04:54:37,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:37,165 INFO:     Epoch: 31
2023-01-04 04:54:38,766 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4590139110883077, 'Total loss': 0.4590139110883077} | train loss {'Reaction outcome loss': 0.2811353573515097, 'Total loss': 0.2811353573515097}
2023-01-04 04:54:38,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:38,767 INFO:     Epoch: 32
2023-01-04 04:54:40,373 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45561837156613666, 'Total loss': 0.45561837156613666} | train loss {'Reaction outcome loss': 0.2782576113455132, 'Total loss': 0.2782576113455132}
2023-01-04 04:54:40,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:40,373 INFO:     Epoch: 33
2023-01-04 04:54:41,977 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4661790589491526, 'Total loss': 0.4661790589491526} | train loss {'Reaction outcome loss': 0.2773597518836118, 'Total loss': 0.2773597518836118}
2023-01-04 04:54:41,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:41,977 INFO:     Epoch: 34
2023-01-04 04:54:43,610 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4763593763113022, 'Total loss': 0.4763593763113022} | train loss {'Reaction outcome loss': 0.2727658903421262, 'Total loss': 0.2727658903421262}
2023-01-04 04:54:43,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:43,610 INFO:     Epoch: 35
2023-01-04 04:54:45,214 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4545655111471812, 'Total loss': 0.4545655111471812} | train loss {'Reaction outcome loss': 0.2713645977448901, 'Total loss': 0.2713645977448901}
2023-01-04 04:54:45,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:45,214 INFO:     Epoch: 36
2023-01-04 04:54:46,840 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46270230412483215, 'Total loss': 0.46270230412483215} | train loss {'Reaction outcome loss': 0.2661771726683589, 'Total loss': 0.2661771726683589}
2023-01-04 04:54:46,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:46,840 INFO:     Epoch: 37
2023-01-04 04:54:48,447 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4576551894346873, 'Total loss': 0.4576551894346873} | train loss {'Reaction outcome loss': 0.2620597550988413, 'Total loss': 0.2620597550988413}
2023-01-04 04:54:48,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:48,448 INFO:     Epoch: 38
2023-01-04 04:54:50,057 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4451089262962341, 'Total loss': 0.4451089262962341} | train loss {'Reaction outcome loss': 0.25959311162091336, 'Total loss': 0.25959311162091336}
2023-01-04 04:54:50,057 INFO:     Found new best model at epoch 38
2023-01-04 04:54:50,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:50,058 INFO:     Epoch: 39
2023-01-04 04:54:51,682 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44772352476914723, 'Total loss': 0.44772352476914723} | train loss {'Reaction outcome loss': 0.25982641547057606, 'Total loss': 0.25982641547057606}
2023-01-04 04:54:51,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:51,683 INFO:     Epoch: 40
2023-01-04 04:54:53,294 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46712149182955426, 'Total loss': 0.46712149182955426} | train loss {'Reaction outcome loss': 0.25674436946100276, 'Total loss': 0.25674436946100276}
2023-01-04 04:54:53,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:53,294 INFO:     Epoch: 41
2023-01-04 04:54:54,893 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.465832394361496, 'Total loss': 0.465832394361496} | train loss {'Reaction outcome loss': 0.25328247713106633, 'Total loss': 0.25328247713106633}
2023-01-04 04:54:54,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:54,893 INFO:     Epoch: 42
2023-01-04 04:54:56,498 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45734462241331736, 'Total loss': 0.45734462241331736} | train loss {'Reaction outcome loss': 0.25344246346167276, 'Total loss': 0.25344246346167276}
2023-01-04 04:54:56,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:56,498 INFO:     Epoch: 43
2023-01-04 04:54:57,875 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4841527327895164, 'Total loss': 0.4841527327895164} | train loss {'Reaction outcome loss': 0.25073486426677083, 'Total loss': 0.25073486426677083}
2023-01-04 04:54:57,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:57,875 INFO:     Epoch: 44
2023-01-04 04:54:58,950 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48884185155232746, 'Total loss': 0.48884185155232746} | train loss {'Reaction outcome loss': 0.2507884466233882, 'Total loss': 0.2507884466233882}
2023-01-04 04:54:58,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:54:58,951 INFO:     Epoch: 45
2023-01-04 04:55:00,018 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4544620340069135, 'Total loss': 0.4544620340069135} | train loss {'Reaction outcome loss': 0.24612962882226125, 'Total loss': 0.24612962882226125}
2023-01-04 04:55:00,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:00,018 INFO:     Epoch: 46
2023-01-04 04:55:01,095 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4495422760645548, 'Total loss': 0.4495422760645548} | train loss {'Reaction outcome loss': 0.24494505279599973, 'Total loss': 0.24494505279599973}
2023-01-04 04:55:01,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:01,095 INFO:     Epoch: 47
2023-01-04 04:55:02,450 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46648411204417545, 'Total loss': 0.46648411204417545} | train loss {'Reaction outcome loss': 0.24135646133915611, 'Total loss': 0.24135646133915611}
2023-01-04 04:55:02,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:02,450 INFO:     Epoch: 48
2023-01-04 04:55:04,050 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4810757637023926, 'Total loss': 0.4810757637023926} | train loss {'Reaction outcome loss': 0.24044951686252325, 'Total loss': 0.24044951686252325}
2023-01-04 04:55:04,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:04,051 INFO:     Epoch: 49
2023-01-04 04:55:05,649 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.481106028954188, 'Total loss': 0.481106028954188} | train loss {'Reaction outcome loss': 0.23846780541033522, 'Total loss': 0.23846780541033522}
2023-01-04 04:55:05,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:05,649 INFO:     Epoch: 50
2023-01-04 04:55:07,248 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44656594693660734, 'Total loss': 0.44656594693660734} | train loss {'Reaction outcome loss': 0.2392664298630363, 'Total loss': 0.2392664298630363}
2023-01-04 04:55:07,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:07,248 INFO:     Epoch: 51
2023-01-04 04:55:08,849 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4873540421326955, 'Total loss': 0.4873540421326955} | train loss {'Reaction outcome loss': 0.2354071463327115, 'Total loss': 0.2354071463327115}
2023-01-04 04:55:08,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:08,849 INFO:     Epoch: 52
2023-01-04 04:55:10,436 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4741743286450704, 'Total loss': 0.4741743286450704} | train loss {'Reaction outcome loss': 0.23430282640059072, 'Total loss': 0.23430282640059072}
2023-01-04 04:55:10,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:10,437 INFO:     Epoch: 53
2023-01-04 04:55:12,044 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49789581100145974, 'Total loss': 0.49789581100145974} | train loss {'Reaction outcome loss': 0.23208990187421172, 'Total loss': 0.23208990187421172}
2023-01-04 04:55:12,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:12,044 INFO:     Epoch: 54
2023-01-04 04:55:13,675 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46757126649220787, 'Total loss': 0.46757126649220787} | train loss {'Reaction outcome loss': 0.22956448061801896, 'Total loss': 0.22956448061801896}
2023-01-04 04:55:13,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:13,675 INFO:     Epoch: 55
2023-01-04 04:55:15,306 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47445951302846273, 'Total loss': 0.47445951302846273} | train loss {'Reaction outcome loss': 0.22903197671585995, 'Total loss': 0.22903197671585995}
2023-01-04 04:55:15,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:15,306 INFO:     Epoch: 56
2023-01-04 04:55:16,899 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4814187288284302, 'Total loss': 0.4814187288284302} | train loss {'Reaction outcome loss': 0.2277535597259172, 'Total loss': 0.2277535597259172}
2023-01-04 04:55:16,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:16,899 INFO:     Epoch: 57
2023-01-04 04:55:18,506 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4824440836906433, 'Total loss': 0.4824440836906433} | train loss {'Reaction outcome loss': 0.2259618809265135, 'Total loss': 0.2259618809265135}
2023-01-04 04:55:18,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:18,507 INFO:     Epoch: 58
2023-01-04 04:55:20,099 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4691663642724355, 'Total loss': 0.4691663642724355} | train loss {'Reaction outcome loss': 0.22346201968053186, 'Total loss': 0.22346201968053186}
2023-01-04 04:55:20,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:20,100 INFO:     Epoch: 59
2023-01-04 04:55:21,736 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49765541156133014, 'Total loss': 0.49765541156133014} | train loss {'Reaction outcome loss': 0.22222278723056135, 'Total loss': 0.22222278723056135}
2023-01-04 04:55:21,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:21,736 INFO:     Epoch: 60
2023-01-04 04:55:23,375 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47996636033058165, 'Total loss': 0.47996636033058165} | train loss {'Reaction outcome loss': 0.2221880078665401, 'Total loss': 0.2221880078665401}
2023-01-04 04:55:23,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:23,376 INFO:     Epoch: 61
2023-01-04 04:55:25,004 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4594778597354889, 'Total loss': 0.4594778597354889} | train loss {'Reaction outcome loss': 0.21915173646237446, 'Total loss': 0.21915173646237446}
2023-01-04 04:55:25,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:25,005 INFO:     Epoch: 62
2023-01-04 04:55:26,636 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4495262881120046, 'Total loss': 0.4495262881120046} | train loss {'Reaction outcome loss': 0.22087083758268547, 'Total loss': 0.22087083758268547}
2023-01-04 04:55:26,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:26,636 INFO:     Epoch: 63
2023-01-04 04:55:28,246 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4621898372968038, 'Total loss': 0.4621898372968038} | train loss {'Reaction outcome loss': 0.21751915986922027, 'Total loss': 0.21751915986922027}
2023-01-04 04:55:28,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:28,246 INFO:     Epoch: 64
2023-01-04 04:55:29,853 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.471961388985316, 'Total loss': 0.471961388985316} | train loss {'Reaction outcome loss': 0.2157267870428545, 'Total loss': 0.2157267870428545}
2023-01-04 04:55:29,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:29,853 INFO:     Epoch: 65
2023-01-04 04:55:31,488 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4806011358896891, 'Total loss': 0.4806011358896891} | train loss {'Reaction outcome loss': 0.21108353036432276, 'Total loss': 0.21108353036432276}
2023-01-04 04:55:31,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:31,488 INFO:     Epoch: 66
2023-01-04 04:55:33,121 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48964945673942567, 'Total loss': 0.48964945673942567} | train loss {'Reaction outcome loss': 0.2122339856699916, 'Total loss': 0.2122339856699916}
2023-01-04 04:55:33,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:33,121 INFO:     Epoch: 67
2023-01-04 04:55:34,753 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47833741903305055, 'Total loss': 0.47833741903305055} | train loss {'Reaction outcome loss': 0.21221797040492188, 'Total loss': 0.21221797040492188}
2023-01-04 04:55:34,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:34,754 INFO:     Epoch: 68
2023-01-04 04:55:36,339 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4723272914687792, 'Total loss': 0.4723272914687792} | train loss {'Reaction outcome loss': 0.2098985316924455, 'Total loss': 0.2098985316924455}
2023-01-04 04:55:36,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:36,340 INFO:     Epoch: 69
2023-01-04 04:55:37,924 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4686376651128133, 'Total loss': 0.4686376651128133} | train loss {'Reaction outcome loss': 0.20694364039798938, 'Total loss': 0.20694364039798938}
2023-01-04 04:55:37,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:37,924 INFO:     Epoch: 70
2023-01-04 04:55:39,562 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47343588471412656, 'Total loss': 0.47343588471412656} | train loss {'Reaction outcome loss': 0.20689288854921767, 'Total loss': 0.20689288854921767}
2023-01-04 04:55:39,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:39,562 INFO:     Epoch: 71
2023-01-04 04:55:41,202 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45231881986061734, 'Total loss': 0.45231881986061734} | train loss {'Reaction outcome loss': 0.20642226389760576, 'Total loss': 0.20642226389760576}
2023-01-04 04:55:41,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:41,203 INFO:     Epoch: 72
2023-01-04 04:55:42,825 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4955203652381897, 'Total loss': 0.4955203652381897} | train loss {'Reaction outcome loss': 0.20588424227566926, 'Total loss': 0.20588424227566926}
2023-01-04 04:55:42,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:42,825 INFO:     Epoch: 73
2023-01-04 04:55:44,460 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46976393858591714, 'Total loss': 0.46976393858591714} | train loss {'Reaction outcome loss': 0.2023600774013609, 'Total loss': 0.2023600774013609}
2023-01-04 04:55:44,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:44,461 INFO:     Epoch: 74
2023-01-04 04:55:46,077 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4641347289085388, 'Total loss': 0.4641347289085388} | train loss {'Reaction outcome loss': 0.2024064466411026, 'Total loss': 0.2024064466411026}
2023-01-04 04:55:46,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:46,077 INFO:     Epoch: 75
2023-01-04 04:55:47,689 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47640022337436677, 'Total loss': 0.47640022337436677} | train loss {'Reaction outcome loss': 0.2023634910583496, 'Total loss': 0.2023634910583496}
2023-01-04 04:55:47,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:47,690 INFO:     Epoch: 76
2023-01-04 04:55:49,328 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45992116729418436, 'Total loss': 0.45992116729418436} | train loss {'Reaction outcome loss': 0.2001611060170383, 'Total loss': 0.2001611060170383}
2023-01-04 04:55:49,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:49,328 INFO:     Epoch: 77
2023-01-04 04:55:50,918 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4962702661752701, 'Total loss': 0.4962702661752701} | train loss {'Reaction outcome loss': 0.20274819093436972, 'Total loss': 0.20274819093436972}
2023-01-04 04:55:50,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:50,918 INFO:     Epoch: 78
2023-01-04 04:55:52,550 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47405026356379193, 'Total loss': 0.47405026356379193} | train loss {'Reaction outcome loss': 0.20041365433309483, 'Total loss': 0.20041365433309483}
2023-01-04 04:55:52,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:52,551 INFO:     Epoch: 79
2023-01-04 04:55:54,180 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47644654512405393, 'Total loss': 0.47644654512405393} | train loss {'Reaction outcome loss': 0.19825466839253686, 'Total loss': 0.19825466839253686}
2023-01-04 04:55:54,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:54,181 INFO:     Epoch: 80
2023-01-04 04:55:55,793 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4536277721325556, 'Total loss': 0.4536277721325556} | train loss {'Reaction outcome loss': 0.197001272281262, 'Total loss': 0.197001272281262}
2023-01-04 04:55:55,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:55,794 INFO:     Epoch: 81
2023-01-04 04:55:57,384 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48273486296335855, 'Total loss': 0.48273486296335855} | train loss {'Reaction outcome loss': 0.19406578770505822, 'Total loss': 0.19406578770505822}
2023-01-04 04:55:57,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:57,384 INFO:     Epoch: 82
2023-01-04 04:55:58,981 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46296247442563376, 'Total loss': 0.46296247442563376} | train loss {'Reaction outcome loss': 0.19575285648637947, 'Total loss': 0.19575285648637947}
2023-01-04 04:55:58,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:55:58,981 INFO:     Epoch: 83
2023-01-04 04:56:00,580 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47845715781052905, 'Total loss': 0.47845715781052905} | train loss {'Reaction outcome loss': 0.19424594594468278, 'Total loss': 0.19424594594468278}
2023-01-04 04:56:00,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:00,581 INFO:     Epoch: 84
2023-01-04 04:56:02,178 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44115814169247947, 'Total loss': 0.44115814169247947} | train loss {'Reaction outcome loss': 0.19571192901487386, 'Total loss': 0.19571192901487386}
2023-01-04 04:56:02,178 INFO:     Found new best model at epoch 84
2023-01-04 04:56:02,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:02,179 INFO:     Epoch: 85
2023-01-04 04:56:03,772 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4643604323267937, 'Total loss': 0.4643604323267937} | train loss {'Reaction outcome loss': 0.19574004547529272, 'Total loss': 0.19574004547529272}
2023-01-04 04:56:03,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:03,772 INFO:     Epoch: 86
2023-01-04 04:56:05,372 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47326340277989704, 'Total loss': 0.47326340277989704} | train loss {'Reaction outcome loss': 0.18998047578340188, 'Total loss': 0.18998047578340188}
2023-01-04 04:56:05,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:05,373 INFO:     Epoch: 87
2023-01-04 04:56:06,975 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4686189293861389, 'Total loss': 0.4686189293861389} | train loss {'Reaction outcome loss': 0.19165338672670645, 'Total loss': 0.19165338672670645}
2023-01-04 04:56:06,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:06,976 INFO:     Epoch: 88
2023-01-04 04:56:08,578 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4639384458462397, 'Total loss': 0.4639384458462397} | train loss {'Reaction outcome loss': 0.19165701362630522, 'Total loss': 0.19165701362630522}
2023-01-04 04:56:08,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:08,578 INFO:     Epoch: 89
2023-01-04 04:56:10,181 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4959637403488159, 'Total loss': 0.4959637403488159} | train loss {'Reaction outcome loss': 0.19173588104788147, 'Total loss': 0.19173588104788147}
2023-01-04 04:56:10,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:10,182 INFO:     Epoch: 90
2023-01-04 04:56:11,784 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4635609875122706, 'Total loss': 0.4635609875122706} | train loss {'Reaction outcome loss': 0.1886243435490325, 'Total loss': 0.1886243435490325}
2023-01-04 04:56:11,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:11,784 INFO:     Epoch: 91
2023-01-04 04:56:13,393 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5000757356484731, 'Total loss': 0.5000757356484731} | train loss {'Reaction outcome loss': 0.18898248400821582, 'Total loss': 0.18898248400821582}
2023-01-04 04:56:13,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:13,393 INFO:     Epoch: 92
2023-01-04 04:56:14,988 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48768352568149564, 'Total loss': 0.48768352568149564} | train loss {'Reaction outcome loss': 0.1871709587314714, 'Total loss': 0.1871709587314714}
2023-01-04 04:56:14,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:14,988 INFO:     Epoch: 93
2023-01-04 04:56:16,628 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4626612345377604, 'Total loss': 0.4626612345377604} | train loss {'Reaction outcome loss': 0.1869999172589624, 'Total loss': 0.1869999172589624}
2023-01-04 04:56:16,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:16,629 INFO:     Epoch: 94
2023-01-04 04:56:18,244 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4740315556526184, 'Total loss': 0.4740315556526184} | train loss {'Reaction outcome loss': 0.18725556284458197, 'Total loss': 0.18725556284458197}
2023-01-04 04:56:18,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:18,244 INFO:     Epoch: 95
2023-01-04 04:56:19,872 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48207731246948243, 'Total loss': 0.48207731246948243} | train loss {'Reaction outcome loss': 0.18621847748971587, 'Total loss': 0.18621847748971587}
2023-01-04 04:56:19,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:19,872 INFO:     Epoch: 96
2023-01-04 04:56:21,493 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.481122080485026, 'Total loss': 0.481122080485026} | train loss {'Reaction outcome loss': 0.1865551879004128, 'Total loss': 0.1865551879004128}
2023-01-04 04:56:21,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:21,493 INFO:     Epoch: 97
2023-01-04 04:56:23,078 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47552669942379, 'Total loss': 0.47552669942379} | train loss {'Reaction outcome loss': 0.1844125134527468, 'Total loss': 0.1844125134527468}
2023-01-04 04:56:23,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:23,078 INFO:     Epoch: 98
2023-01-04 04:56:24,712 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47177776247262954, 'Total loss': 0.47177776247262954} | train loss {'Reaction outcome loss': 0.18419064461700752, 'Total loss': 0.18419064461700752}
2023-01-04 04:56:24,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:24,712 INFO:     Epoch: 99
2023-01-04 04:56:26,354 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4481121649344762, 'Total loss': 0.4481121649344762} | train loss {'Reaction outcome loss': 0.18365243145866514, 'Total loss': 0.18365243145866514}
2023-01-04 04:56:26,354 INFO:     Best model found after epoch 85 of 100.
2023-01-04 04:56:26,354 INFO:   Done with stage: TRAINING
2023-01-04 04:56:26,354 INFO:   Starting stage: EVALUATION
2023-01-04 04:56:26,478 INFO:   Done with stage: EVALUATION
2023-01-04 04:56:26,478 INFO:   Leaving out SEQ value Fold_5
2023-01-04 04:56:26,490 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 04:56:26,490 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:56:27,131 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:56:27,132 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:56:27,198 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:56:27,198 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:56:27,199 INFO:     No hyperparam tuning for this model
2023-01-04 04:56:27,199 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:56:27,199 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:56:27,199 INFO:     None feature selector for col prot
2023-01-04 04:56:27,199 INFO:     None feature selector for col prot
2023-01-04 04:56:27,200 INFO:     None feature selector for col prot
2023-01-04 04:56:27,200 INFO:     None feature selector for col chem
2023-01-04 04:56:27,200 INFO:     None feature selector for col chem
2023-01-04 04:56:27,200 INFO:     None feature selector for col chem
2023-01-04 04:56:27,200 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:56:27,200 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:56:27,201 INFO:     Number of params in model 70141
2023-01-04 04:56:27,205 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:56:27,205 INFO:   Starting stage: TRAINING
2023-01-04 04:56:27,248 INFO:     Val loss before train {'Reaction outcome loss': 0.8759511629740397, 'Total loss': 0.8759511629740397}
2023-01-04 04:56:27,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:27,248 INFO:     Epoch: 0
2023-01-04 04:56:28,854 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6341910183429718, 'Total loss': 0.6341910183429718} | train loss {'Reaction outcome loss': 0.8551978926806554, 'Total loss': 0.8551978926806554}
2023-01-04 04:56:28,855 INFO:     Found new best model at epoch 0
2023-01-04 04:56:28,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:28,856 INFO:     Epoch: 1
2023-01-04 04:56:30,425 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.563054770231247, 'Total loss': 0.563054770231247} | train loss {'Reaction outcome loss': 0.5986068913862653, 'Total loss': 0.5986068913862653}
2023-01-04 04:56:30,425 INFO:     Found new best model at epoch 1
2023-01-04 04:56:30,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:30,426 INFO:     Epoch: 2
2023-01-04 04:56:31,986 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5222794274489085, 'Total loss': 0.5222794274489085} | train loss {'Reaction outcome loss': 0.5218970447669934, 'Total loss': 0.5218970447669934}
2023-01-04 04:56:31,987 INFO:     Found new best model at epoch 2
2023-01-04 04:56:31,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:31,987 INFO:     Epoch: 3
2023-01-04 04:56:33,599 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5037682016690572, 'Total loss': 0.5037682016690572} | train loss {'Reaction outcome loss': 0.48261068995199063, 'Total loss': 0.48261068995199063}
2023-01-04 04:56:33,600 INFO:     Found new best model at epoch 3
2023-01-04 04:56:33,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:33,601 INFO:     Epoch: 4
2023-01-04 04:56:35,200 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.473178901274999, 'Total loss': 0.473178901274999} | train loss {'Reaction outcome loss': 0.45819035292106824, 'Total loss': 0.45819035292106824}
2023-01-04 04:56:35,200 INFO:     Found new best model at epoch 4
2023-01-04 04:56:35,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:35,201 INFO:     Epoch: 5
2023-01-04 04:56:36,803 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4620173990726471, 'Total loss': 0.4620173990726471} | train loss {'Reaction outcome loss': 0.4394302726553304, 'Total loss': 0.4394302726553304}
2023-01-04 04:56:36,803 INFO:     Found new best model at epoch 5
2023-01-04 04:56:36,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:36,804 INFO:     Epoch: 6
2023-01-04 04:56:38,410 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45858307381471, 'Total loss': 0.45858307381471} | train loss {'Reaction outcome loss': 0.42725084422931187, 'Total loss': 0.42725084422931187}
2023-01-04 04:56:38,410 INFO:     Found new best model at epoch 6
2023-01-04 04:56:38,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:38,411 INFO:     Epoch: 7
2023-01-04 04:56:39,975 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42372660438219706, 'Total loss': 0.42372660438219706} | train loss {'Reaction outcome loss': 0.41145706424204104, 'Total loss': 0.41145706424204104}
2023-01-04 04:56:39,975 INFO:     Found new best model at epoch 7
2023-01-04 04:56:39,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:39,976 INFO:     Epoch: 8
2023-01-04 04:56:41,545 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4173915167649587, 'Total loss': 0.4173915167649587} | train loss {'Reaction outcome loss': 0.3982163599427164, 'Total loss': 0.3982163599427164}
2023-01-04 04:56:41,546 INFO:     Found new best model at epoch 8
2023-01-04 04:56:41,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:41,547 INFO:     Epoch: 9
2023-01-04 04:56:43,129 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4162573883930842, 'Total loss': 0.4162573883930842} | train loss {'Reaction outcome loss': 0.3912253846434781, 'Total loss': 0.3912253846434781}
2023-01-04 04:56:43,129 INFO:     Found new best model at epoch 9
2023-01-04 04:56:43,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:43,130 INFO:     Epoch: 10
2023-01-04 04:56:44,711 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4225395033756892, 'Total loss': 0.4225395033756892} | train loss {'Reaction outcome loss': 0.3837551020466498, 'Total loss': 0.3837551020466498}
2023-01-04 04:56:44,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:44,711 INFO:     Epoch: 11
2023-01-04 04:56:46,294 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40463756720225014, 'Total loss': 0.40463756720225014} | train loss {'Reaction outcome loss': 0.3737483496376633, 'Total loss': 0.3737483496376633}
2023-01-04 04:56:46,294 INFO:     Found new best model at epoch 11
2023-01-04 04:56:46,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:46,295 INFO:     Epoch: 12
2023-01-04 04:56:47,862 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41272754967212677, 'Total loss': 0.41272754967212677} | train loss {'Reaction outcome loss': 0.3680383297104905, 'Total loss': 0.3680383297104905}
2023-01-04 04:56:47,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:47,863 INFO:     Epoch: 13
2023-01-04 04:56:49,427 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43875430325667064, 'Total loss': 0.43875430325667064} | train loss {'Reaction outcome loss': 0.35999183054931844, 'Total loss': 0.35999183054931844}
2023-01-04 04:56:49,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:49,428 INFO:     Epoch: 14
2023-01-04 04:56:51,038 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3966009676456451, 'Total loss': 0.3966009676456451} | train loss {'Reaction outcome loss': 0.3514837247938135, 'Total loss': 0.3514837247938135}
2023-01-04 04:56:51,038 INFO:     Found new best model at epoch 14
2023-01-04 04:56:51,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:51,039 INFO:     Epoch: 15
2023-01-04 04:56:52,638 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41061675945917764, 'Total loss': 0.41061675945917764} | train loss {'Reaction outcome loss': 0.34877390735340813, 'Total loss': 0.34877390735340813}
2023-01-04 04:56:52,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:52,639 INFO:     Epoch: 16
2023-01-04 04:56:54,245 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4013886620601018, 'Total loss': 0.4013886620601018} | train loss {'Reaction outcome loss': 0.33991201518334613, 'Total loss': 0.33991201518334613}
2023-01-04 04:56:54,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:54,245 INFO:     Epoch: 17
2023-01-04 04:56:55,852 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4119799276192983, 'Total loss': 0.4119799276192983} | train loss {'Reaction outcome loss': 0.3332735497205362, 'Total loss': 0.3332735497205362}
2023-01-04 04:56:55,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:55,852 INFO:     Epoch: 18
2023-01-04 04:56:57,411 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3955010006825129, 'Total loss': 0.3955010006825129} | train loss {'Reaction outcome loss': 0.32863545349805895, 'Total loss': 0.32863545349805895}
2023-01-04 04:56:57,412 INFO:     Found new best model at epoch 18
2023-01-04 04:56:57,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:57,412 INFO:     Epoch: 19
2023-01-04 04:56:58,997 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4021087149779002, 'Total loss': 0.4021087149779002} | train loss {'Reaction outcome loss': 0.32303739049519503, 'Total loss': 0.32303739049519503}
2023-01-04 04:56:58,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:56:58,997 INFO:     Epoch: 20
2023-01-04 04:57:00,605 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4046836386124293, 'Total loss': 0.4046836386124293} | train loss {'Reaction outcome loss': 0.31856075470356177, 'Total loss': 0.31856075470356177}
2023-01-04 04:57:00,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:00,606 INFO:     Epoch: 21
2023-01-04 04:57:02,210 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4208278040091197, 'Total loss': 0.4208278040091197} | train loss {'Reaction outcome loss': 0.3134090293497935, 'Total loss': 0.3134090293497935}
2023-01-04 04:57:02,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:02,210 INFO:     Epoch: 22
2023-01-04 04:57:03,808 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4167868226766586, 'Total loss': 0.4167868226766586} | train loss {'Reaction outcome loss': 0.3053701863671741, 'Total loss': 0.3053701863671741}
2023-01-04 04:57:03,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:03,809 INFO:     Epoch: 23
2023-01-04 04:57:05,424 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3986040711402893, 'Total loss': 0.3986040711402893} | train loss {'Reaction outcome loss': 0.30422042791534515, 'Total loss': 0.30422042791534515}
2023-01-04 04:57:05,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:05,424 INFO:     Epoch: 24
2023-01-04 04:57:07,006 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40152857502301537, 'Total loss': 0.40152857502301537} | train loss {'Reaction outcome loss': 0.299819437990876, 'Total loss': 0.299819437990876}
2023-01-04 04:57:07,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:07,007 INFO:     Epoch: 25
2023-01-04 04:57:08,579 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41342094043890637, 'Total loss': 0.41342094043890637} | train loss {'Reaction outcome loss': 0.29329803216196326, 'Total loss': 0.29329803216196326}
2023-01-04 04:57:08,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:08,579 INFO:     Epoch: 26
2023-01-04 04:57:10,164 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41004054148991903, 'Total loss': 0.41004054148991903} | train loss {'Reaction outcome loss': 0.2899164769281871, 'Total loss': 0.2899164769281871}
2023-01-04 04:57:10,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:10,164 INFO:     Epoch: 27
2023-01-04 04:57:11,749 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4022333284219106, 'Total loss': 0.4022333284219106} | train loss {'Reaction outcome loss': 0.2873437870429815, 'Total loss': 0.2873437870429815}
2023-01-04 04:57:11,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:11,749 INFO:     Epoch: 28
2023-01-04 04:57:13,331 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40699920654296873, 'Total loss': 0.40699920654296873} | train loss {'Reaction outcome loss': 0.28345755881962986, 'Total loss': 0.28345755881962986}
2023-01-04 04:57:13,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:13,332 INFO:     Epoch: 29
2023-01-04 04:57:14,899 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4071782996257146, 'Total loss': 0.4071782996257146} | train loss {'Reaction outcome loss': 0.28061798628229295, 'Total loss': 0.28061798628229295}
2023-01-04 04:57:14,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:14,899 INFO:     Epoch: 30
2023-01-04 04:57:16,489 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40172719955444336, 'Total loss': 0.40172719955444336} | train loss {'Reaction outcome loss': 0.276148961653022, 'Total loss': 0.276148961653022}
2023-01-04 04:57:16,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:16,489 INFO:     Epoch: 31
2023-01-04 04:57:18,099 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40839554617802304, 'Total loss': 0.40839554617802304} | train loss {'Reaction outcome loss': 0.27216693523754604, 'Total loss': 0.27216693523754604}
2023-01-04 04:57:18,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:18,100 INFO:     Epoch: 32
2023-01-04 04:57:19,711 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4384508490562439, 'Total loss': 0.4384508490562439} | train loss {'Reaction outcome loss': 0.26837069598318886, 'Total loss': 0.26837069598318886}
2023-01-04 04:57:19,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:19,711 INFO:     Epoch: 33
2023-01-04 04:57:21,279 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4068398435910543, 'Total loss': 0.4068398435910543} | train loss {'Reaction outcome loss': 0.2680914053543858, 'Total loss': 0.2680914053543858}
2023-01-04 04:57:21,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:21,280 INFO:     Epoch: 34
2023-01-04 04:57:22,891 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41469384332497916, 'Total loss': 0.41469384332497916} | train loss {'Reaction outcome loss': 0.26424910870455476, 'Total loss': 0.26424910870455476}
2023-01-04 04:57:22,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:22,892 INFO:     Epoch: 35
2023-01-04 04:57:24,461 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41408153573671974, 'Total loss': 0.41408153573671974} | train loss {'Reaction outcome loss': 0.2639196629833131, 'Total loss': 0.2639196629833131}
2023-01-04 04:57:24,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:24,462 INFO:     Epoch: 36
2023-01-04 04:57:26,034 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42907550036907194, 'Total loss': 0.42907550036907194} | train loss {'Reaction outcome loss': 0.25765660214815694, 'Total loss': 0.25765660214815694}
2023-01-04 04:57:26,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:26,034 INFO:     Epoch: 37
2023-01-04 04:57:27,645 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41850777765115105, 'Total loss': 0.41850777765115105} | train loss {'Reaction outcome loss': 0.25576650226203196, 'Total loss': 0.25576650226203196}
2023-01-04 04:57:27,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:27,645 INFO:     Epoch: 38
2023-01-04 04:57:29,255 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42455024321873985, 'Total loss': 0.42455024321873985} | train loss {'Reaction outcome loss': 0.2498849228187634, 'Total loss': 0.2498849228187634}
2023-01-04 04:57:29,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:29,255 INFO:     Epoch: 39
2023-01-04 04:57:30,841 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4039731154839198, 'Total loss': 0.4039731154839198} | train loss {'Reaction outcome loss': 0.2519803672185997, 'Total loss': 0.2519803672185997}
2023-01-04 04:57:30,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:30,841 INFO:     Epoch: 40
2023-01-04 04:57:32,455 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41116757889588673, 'Total loss': 0.41116757889588673} | train loss {'Reaction outcome loss': 0.2508521076482143, 'Total loss': 0.2508521076482143}
2023-01-04 04:57:32,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:32,456 INFO:     Epoch: 41
2023-01-04 04:57:34,036 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38697212288777033, 'Total loss': 0.38697212288777033} | train loss {'Reaction outcome loss': 0.24630258993728318, 'Total loss': 0.24630258993728318}
2023-01-04 04:57:34,037 INFO:     Found new best model at epoch 41
2023-01-04 04:57:34,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:34,038 INFO:     Epoch: 42
2023-01-04 04:57:35,609 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4307545671860377, 'Total loss': 0.4307545671860377} | train loss {'Reaction outcome loss': 0.24226636458596174, 'Total loss': 0.24226636458596174}
2023-01-04 04:57:35,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:35,609 INFO:     Epoch: 43
2023-01-04 04:57:37,184 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40828073819478355, 'Total loss': 0.40828073819478355} | train loss {'Reaction outcome loss': 0.24133877505133622, 'Total loss': 0.24133877505133622}
2023-01-04 04:57:37,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:37,184 INFO:     Epoch: 44
2023-01-04 04:57:38,761 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4156103491783142, 'Total loss': 0.4156103491783142} | train loss {'Reaction outcome loss': 0.24055753240402597, 'Total loss': 0.24055753240402597}
2023-01-04 04:57:38,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:38,761 INFO:     Epoch: 45
2023-01-04 04:57:40,338 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4167666405439377, 'Total loss': 0.4167666405439377} | train loss {'Reaction outcome loss': 0.23739217167353108, 'Total loss': 0.23739217167353108}
2023-01-04 04:57:40,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:40,339 INFO:     Epoch: 46
2023-01-04 04:57:41,904 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4095303108294805, 'Total loss': 0.4095303108294805} | train loss {'Reaction outcome loss': 0.235683023916, 'Total loss': 0.235683023916}
2023-01-04 04:57:41,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:41,904 INFO:     Epoch: 47
2023-01-04 04:57:43,468 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42125084698200227, 'Total loss': 0.42125084698200227} | train loss {'Reaction outcome loss': 0.2348165119977763, 'Total loss': 0.2348165119977763}
2023-01-04 04:57:43,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:43,468 INFO:     Epoch: 48
2023-01-04 04:57:45,073 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.400536169608434, 'Total loss': 0.400536169608434} | train loss {'Reaction outcome loss': 0.2332662858585589, 'Total loss': 0.2332662858585589}
2023-01-04 04:57:45,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:45,073 INFO:     Epoch: 49
2023-01-04 04:57:46,661 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4435590833425522, 'Total loss': 0.4435590833425522} | train loss {'Reaction outcome loss': 0.23119857262847196, 'Total loss': 0.23119857262847196}
2023-01-04 04:57:46,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:46,661 INFO:     Epoch: 50
2023-01-04 04:57:48,243 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4227374792098999, 'Total loss': 0.4227374792098999} | train loss {'Reaction outcome loss': 0.22842765375156038, 'Total loss': 0.22842765375156038}
2023-01-04 04:57:48,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:48,244 INFO:     Epoch: 51
2023-01-04 04:57:49,830 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40922263463338215, 'Total loss': 0.40922263463338215} | train loss {'Reaction outcome loss': 0.22500501037405354, 'Total loss': 0.22500501037405354}
2023-01-04 04:57:49,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:49,831 INFO:     Epoch: 52
2023-01-04 04:57:51,405 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4358206828435262, 'Total loss': 0.4358206828435262} | train loss {'Reaction outcome loss': 0.2251221151193128, 'Total loss': 0.2251221151193128}
2023-01-04 04:57:51,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:51,405 INFO:     Epoch: 53
2023-01-04 04:57:52,967 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4218635559082031, 'Total loss': 0.4218635559082031} | train loss {'Reaction outcome loss': 0.2223058941291414, 'Total loss': 0.2223058941291414}
2023-01-04 04:57:52,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:52,967 INFO:     Epoch: 54
2023-01-04 04:57:54,561 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42868826985359193, 'Total loss': 0.42868826985359193} | train loss {'Reaction outcome loss': 0.2205628813074453, 'Total loss': 0.2205628813074453}
2023-01-04 04:57:54,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:54,562 INFO:     Epoch: 55
2023-01-04 04:57:56,141 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3927376310030619, 'Total loss': 0.3927376310030619} | train loss {'Reaction outcome loss': 0.21872437525078328, 'Total loss': 0.21872437525078328}
2023-01-04 04:57:56,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:56,141 INFO:     Epoch: 56
2023-01-04 04:57:57,731 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4123641520738602, 'Total loss': 0.4123641520738602} | train loss {'Reaction outcome loss': 0.2179469979456524, 'Total loss': 0.2179469979456524}
2023-01-04 04:57:57,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:57,731 INFO:     Epoch: 57
2023-01-04 04:57:59,346 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41372072796026865, 'Total loss': 0.41372072796026865} | train loss {'Reaction outcome loss': 0.21513314734818073, 'Total loss': 0.21513314734818073}
2023-01-04 04:57:59,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:57:59,346 INFO:     Epoch: 58
2023-01-04 04:58:00,907 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4165389130512873, 'Total loss': 0.4165389130512873} | train loss {'Reaction outcome loss': 0.21428751374465704, 'Total loss': 0.21428751374465704}
2023-01-04 04:58:00,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:00,907 INFO:     Epoch: 59
2023-01-04 04:58:02,471 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4215046683947245, 'Total loss': 0.4215046683947245} | train loss {'Reaction outcome loss': 0.21169596875127214, 'Total loss': 0.21169596875127214}
2023-01-04 04:58:02,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:02,471 INFO:     Epoch: 60
2023-01-04 04:58:04,045 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40837443669637047, 'Total loss': 0.40837443669637047} | train loss {'Reaction outcome loss': 0.2125167232278707, 'Total loss': 0.2125167232278707}
2023-01-04 04:58:04,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:04,045 INFO:     Epoch: 61
2023-01-04 04:58:05,625 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4122182736794154, 'Total loss': 0.4122182736794154} | train loss {'Reaction outcome loss': 0.21065797043597176, 'Total loss': 0.21065797043597176}
2023-01-04 04:58:05,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:05,626 INFO:     Epoch: 62
2023-01-04 04:58:07,199 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3986633986234665, 'Total loss': 0.3986633986234665} | train loss {'Reaction outcome loss': 0.20846999821382284, 'Total loss': 0.20846999821382284}
2023-01-04 04:58:07,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:07,200 INFO:     Epoch: 63
2023-01-04 04:58:08,770 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40532410542170205, 'Total loss': 0.40532410542170205} | train loss {'Reaction outcome loss': 0.20869388508807568, 'Total loss': 0.20869388508807568}
2023-01-04 04:58:08,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:08,770 INFO:     Epoch: 64
2023-01-04 04:58:10,356 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42581933240095776, 'Total loss': 0.42581933240095776} | train loss {'Reaction outcome loss': 0.20584764649724438, 'Total loss': 0.20584764649724438}
2023-01-04 04:58:10,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:10,356 INFO:     Epoch: 65
2023-01-04 04:58:11,929 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40261840919653574, 'Total loss': 0.40261840919653574} | train loss {'Reaction outcome loss': 0.20372830892838265, 'Total loss': 0.20372830892838265}
2023-01-04 04:58:11,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:11,929 INFO:     Epoch: 66
2023-01-04 04:58:13,517 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4003362268209457, 'Total loss': 0.4003362268209457} | train loss {'Reaction outcome loss': 0.2023559727155379, 'Total loss': 0.2023559727155379}
2023-01-04 04:58:13,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:13,517 INFO:     Epoch: 67
2023-01-04 04:58:15,100 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.435419029990832, 'Total loss': 0.435419029990832} | train loss {'Reaction outcome loss': 0.20481983702765763, 'Total loss': 0.20481983702765763}
2023-01-04 04:58:15,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:15,100 INFO:     Epoch: 68
2023-01-04 04:58:16,685 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42763643463452655, 'Total loss': 0.42763643463452655} | train loss {'Reaction outcome loss': 0.2025082059286154, 'Total loss': 0.2025082059286154}
2023-01-04 04:58:16,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:16,685 INFO:     Epoch: 69
2023-01-04 04:58:18,255 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42488270401954653, 'Total loss': 0.42488270401954653} | train loss {'Reaction outcome loss': 0.20021490717007623, 'Total loss': 0.20021490717007623}
2023-01-04 04:58:18,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:18,256 INFO:     Epoch: 70
2023-01-04 04:58:19,833 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4018528610467911, 'Total loss': 0.4018528610467911} | train loss {'Reaction outcome loss': 0.19935456551883343, 'Total loss': 0.19935456551883343}
2023-01-04 04:58:19,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:19,835 INFO:     Epoch: 71
2023-01-04 04:58:21,441 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.410193810860316, 'Total loss': 0.410193810860316} | train loss {'Reaction outcome loss': 0.19730859508153295, 'Total loss': 0.19730859508153295}
2023-01-04 04:58:21,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:21,441 INFO:     Epoch: 72
2023-01-04 04:58:23,040 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4121119926373164, 'Total loss': 0.4121119926373164} | train loss {'Reaction outcome loss': 0.1957955559321346, 'Total loss': 0.1957955559321346}
2023-01-04 04:58:23,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:23,040 INFO:     Epoch: 73
2023-01-04 04:58:24,627 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4064837982257207, 'Total loss': 0.4064837982257207} | train loss {'Reaction outcome loss': 0.19544676702170477, 'Total loss': 0.19544676702170477}
2023-01-04 04:58:24,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:24,627 INFO:     Epoch: 74
2023-01-04 04:58:26,218 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4163707047700882, 'Total loss': 0.4163707047700882} | train loss {'Reaction outcome loss': 0.19379130064299072, 'Total loss': 0.19379130064299072}
2023-01-04 04:58:26,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:26,219 INFO:     Epoch: 75
2023-01-04 04:58:27,792 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41697328686714175, 'Total loss': 0.41697328686714175} | train loss {'Reaction outcome loss': 0.194142343931879, 'Total loss': 0.194142343931879}
2023-01-04 04:58:27,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:27,792 INFO:     Epoch: 76
2023-01-04 04:58:29,395 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4466181735197703, 'Total loss': 0.4466181735197703} | train loss {'Reaction outcome loss': 0.19211819675499506, 'Total loss': 0.19211819675499506}
2023-01-04 04:58:29,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:29,395 INFO:     Epoch: 77
2023-01-04 04:58:30,999 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4185921122630437, 'Total loss': 0.4185921122630437} | train loss {'Reaction outcome loss': 0.19381662450023812, 'Total loss': 0.19381662450023812}
2023-01-04 04:58:30,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:30,999 INFO:     Epoch: 78
2023-01-04 04:58:32,589 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.399139337738355, 'Total loss': 0.399139337738355} | train loss {'Reaction outcome loss': 0.1884643690640202, 'Total loss': 0.1884643690640202}
2023-01-04 04:58:32,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:32,589 INFO:     Epoch: 79
2023-01-04 04:58:34,175 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4144092798233032, 'Total loss': 0.4144092798233032} | train loss {'Reaction outcome loss': 0.19177832788903348, 'Total loss': 0.19177832788903348}
2023-01-04 04:58:34,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:34,175 INFO:     Epoch: 80
2023-01-04 04:58:35,742 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42251902222633364, 'Total loss': 0.42251902222633364} | train loss {'Reaction outcome loss': 0.1896618238249182, 'Total loss': 0.1896618238249182}
2023-01-04 04:58:35,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:35,743 INFO:     Epoch: 81
2023-01-04 04:58:37,323 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40304571837186814, 'Total loss': 0.40304571837186814} | train loss {'Reaction outcome loss': 0.1864665014410976, 'Total loss': 0.1864665014410976}
2023-01-04 04:58:37,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:37,324 INFO:     Epoch: 82
2023-01-04 04:58:38,907 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4095463921626409, 'Total loss': 0.4095463921626409} | train loss {'Reaction outcome loss': 0.18732654147638675, 'Total loss': 0.18732654147638675}
2023-01-04 04:58:38,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:38,908 INFO:     Epoch: 83
2023-01-04 04:58:40,513 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41353948016961417, 'Total loss': 0.41353948016961417} | train loss {'Reaction outcome loss': 0.1893035595026547, 'Total loss': 0.1893035595026547}
2023-01-04 04:58:40,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:40,513 INFO:     Epoch: 84
2023-01-04 04:58:42,125 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.392249196767807, 'Total loss': 0.392249196767807} | train loss {'Reaction outcome loss': 0.1852167569318392, 'Total loss': 0.1852167569318392}
2023-01-04 04:58:42,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:42,125 INFO:     Epoch: 85
2023-01-04 04:58:43,708 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39909983177979785, 'Total loss': 0.39909983177979785} | train loss {'Reaction outcome loss': 0.18424134078795892, 'Total loss': 0.18424134078795892}
2023-01-04 04:58:43,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:43,709 INFO:     Epoch: 86
2023-01-04 04:58:45,287 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41677186886469525, 'Total loss': 0.41677186886469525} | train loss {'Reaction outcome loss': 0.18280064485232977, 'Total loss': 0.18280064485232977}
2023-01-04 04:58:45,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:45,287 INFO:     Epoch: 87
2023-01-04 04:58:46,863 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4431014637152354, 'Total loss': 0.4431014637152354} | train loss {'Reaction outcome loss': 0.1819504459667271, 'Total loss': 0.1819504459667271}
2023-01-04 04:58:46,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:46,863 INFO:     Epoch: 88
2023-01-04 04:58:48,449 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42069534262021385, 'Total loss': 0.42069534262021385} | train loss {'Reaction outcome loss': 0.18190864446389415, 'Total loss': 0.18190864446389415}
2023-01-04 04:58:48,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:48,449 INFO:     Epoch: 89
2023-01-04 04:58:50,032 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.421827299396197, 'Total loss': 0.421827299396197} | train loss {'Reaction outcome loss': 0.18304856923701118, 'Total loss': 0.18304856923701118}
2023-01-04 04:58:50,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:50,032 INFO:     Epoch: 90
2023-01-04 04:58:51,617 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44275730550289155, 'Total loss': 0.44275730550289155} | train loss {'Reaction outcome loss': 0.18005831747648926, 'Total loss': 0.18005831747648926}
2023-01-04 04:58:51,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:51,617 INFO:     Epoch: 91
2023-01-04 04:58:53,184 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41802912950515747, 'Total loss': 0.41802912950515747} | train loss {'Reaction outcome loss': 0.17898927119145863, 'Total loss': 0.17898927119145863}
2023-01-04 04:58:53,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:53,184 INFO:     Epoch: 92
2023-01-04 04:58:54,734 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4299245695273081, 'Total loss': 0.4299245695273081} | train loss {'Reaction outcome loss': 0.1804785448649939, 'Total loss': 0.1804785448649939}
2023-01-04 04:58:54,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:54,736 INFO:     Epoch: 93
2023-01-04 04:58:56,348 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42730278968811036, 'Total loss': 0.42730278968811036} | train loss {'Reaction outcome loss': 0.17682747759713527, 'Total loss': 0.17682747759713527}
2023-01-04 04:58:56,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:56,349 INFO:     Epoch: 94
2023-01-04 04:58:57,937 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39594639440377555, 'Total loss': 0.39594639440377555} | train loss {'Reaction outcome loss': 0.17636430075215379, 'Total loss': 0.17636430075215379}
2023-01-04 04:58:57,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:57,937 INFO:     Epoch: 95
2023-01-04 04:58:59,547 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4399205724398295, 'Total loss': 0.4399205724398295} | train loss {'Reaction outcome loss': 0.17919392879698834, 'Total loss': 0.17919392879698834}
2023-01-04 04:58:59,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:58:59,548 INFO:     Epoch: 96
2023-01-04 04:59:01,159 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4157061199347178, 'Total loss': 0.4157061199347178} | train loss {'Reaction outcome loss': 0.17559251597110373, 'Total loss': 0.17559251597110373}
2023-01-04 04:59:01,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:01,160 INFO:     Epoch: 97
2023-01-04 04:59:02,727 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44088520109653473, 'Total loss': 0.44088520109653473} | train loss {'Reaction outcome loss': 0.17586513722900057, 'Total loss': 0.17586513722900057}
2023-01-04 04:59:02,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:02,727 INFO:     Epoch: 98
2023-01-04 04:59:04,313 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4107393264770508, 'Total loss': 0.4107393264770508} | train loss {'Reaction outcome loss': 0.1759231103393827, 'Total loss': 0.1759231103393827}
2023-01-04 04:59:04,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:04,314 INFO:     Epoch: 99
2023-01-04 04:59:05,926 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4259762972593307, 'Total loss': 0.4259762972593307} | train loss {'Reaction outcome loss': 0.17300558556551046, 'Total loss': 0.17300558556551046}
2023-01-04 04:59:05,926 INFO:     Best model found after epoch 42 of 100.
2023-01-04 04:59:05,926 INFO:   Done with stage: TRAINING
2023-01-04 04:59:05,926 INFO:   Starting stage: EVALUATION
2023-01-04 04:59:06,061 INFO:   Done with stage: EVALUATION
2023-01-04 04:59:06,061 INFO:   Leaving out SEQ value Fold_6
2023-01-04 04:59:06,074 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-04 04:59:06,074 INFO:   Starting stage: FEATURE SCALING
2023-01-04 04:59:06,719 INFO:   Done with stage: FEATURE SCALING
2023-01-04 04:59:06,719 INFO:   Starting stage: SCALING TARGETS
2023-01-04 04:59:06,786 INFO:   Done with stage: SCALING TARGETS
2023-01-04 04:59:06,786 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:59:06,786 INFO:     No hyperparam tuning for this model
2023-01-04 04:59:06,787 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 04:59:06,787 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 04:59:06,787 INFO:     None feature selector for col prot
2023-01-04 04:59:06,787 INFO:     None feature selector for col prot
2023-01-04 04:59:06,788 INFO:     None feature selector for col prot
2023-01-04 04:59:06,788 INFO:     None feature selector for col chem
2023-01-04 04:59:06,788 INFO:     None feature selector for col chem
2023-01-04 04:59:06,788 INFO:     None feature selector for col chem
2023-01-04 04:59:06,788 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 04:59:06,788 INFO:   Starting stage: BUILD MODEL
2023-01-04 04:59:06,789 INFO:     Number of params in model 70141
2023-01-04 04:59:06,793 INFO:   Done with stage: BUILD MODEL
2023-01-04 04:59:06,793 INFO:   Starting stage: TRAINING
2023-01-04 04:59:06,837 INFO:     Val loss before train {'Reaction outcome loss': 1.070137349764506, 'Total loss': 1.070137349764506}
2023-01-04 04:59:06,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:06,837 INFO:     Epoch: 0
2023-01-04 04:59:08,430 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7292337218920389, 'Total loss': 0.7292337218920389} | train loss {'Reaction outcome loss': 0.8358444293121715, 'Total loss': 0.8358444293121715}
2023-01-04 04:59:08,430 INFO:     Found new best model at epoch 0
2023-01-04 04:59:08,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:08,431 INFO:     Epoch: 1
2023-01-04 04:59:10,015 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6352052231629689, 'Total loss': 0.6352052231629689} | train loss {'Reaction outcome loss': 0.6179863111876742, 'Total loss': 0.6179863111876742}
2023-01-04 04:59:10,015 INFO:     Found new best model at epoch 1
2023-01-04 04:59:10,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:10,016 INFO:     Epoch: 2
2023-01-04 04:59:11,583 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6215238173802694, 'Total loss': 0.6215238173802694} | train loss {'Reaction outcome loss': 0.5387279473163269, 'Total loss': 0.5387279473163269}
2023-01-04 04:59:11,583 INFO:     Found new best model at epoch 2
2023-01-04 04:59:11,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:11,584 INFO:     Epoch: 3
2023-01-04 04:59:13,146 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5519905984401703, 'Total loss': 0.5519905984401703} | train loss {'Reaction outcome loss': 0.4997826101797404, 'Total loss': 0.4997826101797404}
2023-01-04 04:59:13,147 INFO:     Found new best model at epoch 3
2023-01-04 04:59:13,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:13,147 INFO:     Epoch: 4
2023-01-04 04:59:14,732 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5589845041433971, 'Total loss': 0.5589845041433971} | train loss {'Reaction outcome loss': 0.4726991082504119, 'Total loss': 0.4726991082504119}
2023-01-04 04:59:14,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:14,733 INFO:     Epoch: 5
2023-01-04 04:59:16,319 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.537712675333023, 'Total loss': 0.537712675333023} | train loss {'Reaction outcome loss': 0.4514527385542681, 'Total loss': 0.4514527385542681}
2023-01-04 04:59:16,319 INFO:     Found new best model at epoch 5
2023-01-04 04:59:16,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:16,320 INFO:     Epoch: 6
2023-01-04 04:59:17,904 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5264235407114028, 'Total loss': 0.5264235407114028} | train loss {'Reaction outcome loss': 0.4330305544993816, 'Total loss': 0.4330305544993816}
2023-01-04 04:59:17,905 INFO:     Found new best model at epoch 6
2023-01-04 04:59:17,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:17,905 INFO:     Epoch: 7
2023-01-04 04:59:19,489 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.501221376657486, 'Total loss': 0.501221376657486} | train loss {'Reaction outcome loss': 0.4212956645222374, 'Total loss': 0.4212956645222374}
2023-01-04 04:59:19,490 INFO:     Found new best model at epoch 7
2023-01-04 04:59:19,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:19,490 INFO:     Epoch: 8
2023-01-04 04:59:21,076 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4886073629061381, 'Total loss': 0.4886073629061381} | train loss {'Reaction outcome loss': 0.407625961004869, 'Total loss': 0.407625961004869}
2023-01-04 04:59:21,076 INFO:     Found new best model at epoch 8
2023-01-04 04:59:21,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:21,077 INFO:     Epoch: 9
2023-01-04 04:59:22,634 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4991223673025767, 'Total loss': 0.4991223673025767} | train loss {'Reaction outcome loss': 0.39289562224031804, 'Total loss': 0.39289562224031804}
2023-01-04 04:59:22,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:22,634 INFO:     Epoch: 10
2023-01-04 04:59:24,240 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49111925065517426, 'Total loss': 0.49111925065517426} | train loss {'Reaction outcome loss': 0.3859622243778173, 'Total loss': 0.3859622243778173}
2023-01-04 04:59:24,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:24,240 INFO:     Epoch: 11
2023-01-04 04:59:25,845 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4961844046910604, 'Total loss': 0.4961844046910604} | train loss {'Reaction outcome loss': 0.37770226024664366, 'Total loss': 0.37770226024664366}
2023-01-04 04:59:25,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:25,846 INFO:     Epoch: 12
2023-01-04 04:59:27,447 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48763818144798277, 'Total loss': 0.48763818144798277} | train loss {'Reaction outcome loss': 0.366006185010676, 'Total loss': 0.366006185010676}
2023-01-04 04:59:27,447 INFO:     Found new best model at epoch 12
2023-01-04 04:59:27,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:27,448 INFO:     Epoch: 13
2023-01-04 04:59:29,030 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47555991808573406, 'Total loss': 0.47555991808573406} | train loss {'Reaction outcome loss': 0.35792119287964186, 'Total loss': 0.35792119287964186}
2023-01-04 04:59:29,031 INFO:     Found new best model at epoch 13
2023-01-04 04:59:29,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:29,031 INFO:     Epoch: 14
2023-01-04 04:59:30,601 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47836487293243407, 'Total loss': 0.47836487293243407} | train loss {'Reaction outcome loss': 0.3510566647727411, 'Total loss': 0.3510566647727411}
2023-01-04 04:59:30,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:30,601 INFO:     Epoch: 15
2023-01-04 04:59:32,225 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4984545946121216, 'Total loss': 0.4984545946121216} | train loss {'Reaction outcome loss': 0.34127015737823513, 'Total loss': 0.34127015737823513}
2023-01-04 04:59:32,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:32,226 INFO:     Epoch: 16
2023-01-04 04:59:33,837 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48379730184872943, 'Total loss': 0.48379730184872943} | train loss {'Reaction outcome loss': 0.33730862256917327, 'Total loss': 0.33730862256917327}
2023-01-04 04:59:33,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:33,837 INFO:     Epoch: 17
2023-01-04 04:59:35,438 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4740581035614014, 'Total loss': 0.4740581035614014} | train loss {'Reaction outcome loss': 0.32876620223343156, 'Total loss': 0.32876620223343156}
2023-01-04 04:59:35,439 INFO:     Found new best model at epoch 17
2023-01-04 04:59:35,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:35,439 INFO:     Epoch: 18
2023-01-04 04:59:37,060 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4880262275536855, 'Total loss': 0.4880262275536855} | train loss {'Reaction outcome loss': 0.3231214192378652, 'Total loss': 0.3231214192378652}
2023-01-04 04:59:37,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:37,061 INFO:     Epoch: 19
2023-01-04 04:59:38,631 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5088704099257787, 'Total loss': 0.5088704099257787} | train loss {'Reaction outcome loss': 0.3208098445401524, 'Total loss': 0.3208098445401524}
2023-01-04 04:59:38,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:38,631 INFO:     Epoch: 20
2023-01-04 04:59:40,228 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48574880162874856, 'Total loss': 0.48574880162874856} | train loss {'Reaction outcome loss': 0.31463341071055484, 'Total loss': 0.31463341071055484}
2023-01-04 04:59:40,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:40,228 INFO:     Epoch: 21
2023-01-04 04:59:41,842 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49220295548439025, 'Total loss': 0.49220295548439025} | train loss {'Reaction outcome loss': 0.31065348464818227, 'Total loss': 0.31065348464818227}
2023-01-04 04:59:41,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:41,842 INFO:     Epoch: 22
2023-01-04 04:59:43,457 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4737661292155584, 'Total loss': 0.4737661292155584} | train loss {'Reaction outcome loss': 0.3061973702558231, 'Total loss': 0.3061973702558231}
2023-01-04 04:59:43,457 INFO:     Found new best model at epoch 22
2023-01-04 04:59:43,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:43,458 INFO:     Epoch: 23
2023-01-04 04:59:45,062 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4918978343407313, 'Total loss': 0.4918978343407313} | train loss {'Reaction outcome loss': 0.3005209929504237, 'Total loss': 0.3005209929504237}
2023-01-04 04:59:45,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:45,063 INFO:     Epoch: 24
2023-01-04 04:59:46,646 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4905834436416626, 'Total loss': 0.4905834436416626} | train loss {'Reaction outcome loss': 0.2974344615316216, 'Total loss': 0.2974344615316216}
2023-01-04 04:59:46,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:46,646 INFO:     Epoch: 25
2023-01-04 04:59:48,226 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4820600907007853, 'Total loss': 0.4820600907007853} | train loss {'Reaction outcome loss': 0.29335401234500136, 'Total loss': 0.29335401234500136}
2023-01-04 04:59:48,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:48,227 INFO:     Epoch: 26
2023-01-04 04:59:49,824 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4809653123219808, 'Total loss': 0.4809653123219808} | train loss {'Reaction outcome loss': 0.2860256045947581, 'Total loss': 0.2860256045947581}
2023-01-04 04:59:49,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:49,824 INFO:     Epoch: 27
2023-01-04 04:59:51,434 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5051065901915233, 'Total loss': 0.5051065901915233} | train loss {'Reaction outcome loss': 0.28392155383860235, 'Total loss': 0.28392155383860235}
2023-01-04 04:59:51,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:51,434 INFO:     Epoch: 28
2023-01-04 04:59:53,046 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4981619089841843, 'Total loss': 0.4981619089841843} | train loss {'Reaction outcome loss': 0.276417932176328, 'Total loss': 0.276417932176328}
2023-01-04 04:59:53,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:53,046 INFO:     Epoch: 29
2023-01-04 04:59:54,655 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4856261054674784, 'Total loss': 0.4856261054674784} | train loss {'Reaction outcome loss': 0.27527265417161006, 'Total loss': 0.27527265417161006}
2023-01-04 04:59:54,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:54,656 INFO:     Epoch: 30
2023-01-04 04:59:56,242 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5344149808088938, 'Total loss': 0.5344149808088938} | train loss {'Reaction outcome loss': 0.2701835761413033, 'Total loss': 0.2701835761413033}
2023-01-04 04:59:56,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:56,243 INFO:     Epoch: 31
2023-01-04 04:59:57,820 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47734801371892294, 'Total loss': 0.47734801371892294} | train loss {'Reaction outcome loss': 0.266535460457697, 'Total loss': 0.266535460457697}
2023-01-04 04:59:57,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:57,820 INFO:     Epoch: 32
2023-01-04 04:59:59,420 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4988826205333074, 'Total loss': 0.4988826205333074} | train loss {'Reaction outcome loss': 0.25960095370727365, 'Total loss': 0.25960095370727365}
2023-01-04 04:59:59,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 04:59:59,420 INFO:     Epoch: 33
2023-01-04 05:00:01,029 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4827223837375641, 'Total loss': 0.4827223837375641} | train loss {'Reaction outcome loss': 0.261742512958172, 'Total loss': 0.261742512958172}
2023-01-04 05:00:01,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:01,029 INFO:     Epoch: 34
2023-01-04 05:00:02,648 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49270193576812743, 'Total loss': 0.49270193576812743} | train loss {'Reaction outcome loss': 0.25679653659190016, 'Total loss': 0.25679653659190016}
2023-01-04 05:00:02,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:02,649 INFO:     Epoch: 35
2023-01-04 05:00:04,262 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5109692494074504, 'Total loss': 0.5109692494074504} | train loss {'Reaction outcome loss': 0.2537577897856087, 'Total loss': 0.2537577897856087}
2023-01-04 05:00:04,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:04,262 INFO:     Epoch: 36
2023-01-04 05:00:05,836 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5033459156751633, 'Total loss': 0.5033459156751633} | train loss {'Reaction outcome loss': 0.2492525714548516, 'Total loss': 0.2492525714548516}
2023-01-04 05:00:05,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:05,836 INFO:     Epoch: 37
2023-01-04 05:00:07,423 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5062549591064454, 'Total loss': 0.5062549591064454} | train loss {'Reaction outcome loss': 0.24790417782334617, 'Total loss': 0.24790417782334617}
2023-01-04 05:00:07,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:07,423 INFO:     Epoch: 38
2023-01-04 05:00:09,032 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4927614430586497, 'Total loss': 0.4927614430586497} | train loss {'Reaction outcome loss': 0.24633715522813274, 'Total loss': 0.24633715522813274}
2023-01-04 05:00:09,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:09,032 INFO:     Epoch: 39
2023-01-04 05:00:10,649 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5104082743326823, 'Total loss': 0.5104082743326823} | train loss {'Reaction outcome loss': 0.2407084464235402, 'Total loss': 0.2407084464235402}
2023-01-04 05:00:10,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:10,649 INFO:     Epoch: 40
2023-01-04 05:00:12,265 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49784659743309023, 'Total loss': 0.49784659743309023} | train loss {'Reaction outcome loss': 0.24032925164852387, 'Total loss': 0.24032925164852387}
2023-01-04 05:00:12,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:12,266 INFO:     Epoch: 41
2023-01-04 05:00:13,872 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49237146278222405, 'Total loss': 0.49237146278222405} | train loss {'Reaction outcome loss': 0.23659691992369328, 'Total loss': 0.23659691992369328}
2023-01-04 05:00:13,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:13,872 INFO:     Epoch: 42
2023-01-04 05:00:15,426 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4891155203183492, 'Total loss': 0.4891155203183492} | train loss {'Reaction outcome loss': 0.23425893003851067, 'Total loss': 0.23425893003851067}
2023-01-04 05:00:15,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:15,427 INFO:     Epoch: 43
2023-01-04 05:00:17,020 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5001349111398061, 'Total loss': 0.5001349111398061} | train loss {'Reaction outcome loss': 0.2344360387723743, 'Total loss': 0.2344360387723743}
2023-01-04 05:00:17,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:17,021 INFO:     Epoch: 44
2023-01-04 05:00:18,626 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.498886971672376, 'Total loss': 0.498886971672376} | train loss {'Reaction outcome loss': 0.22756706139980218, 'Total loss': 0.22756706139980218}
2023-01-04 05:00:18,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:18,626 INFO:     Epoch: 45
2023-01-04 05:00:20,212 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48550732533137003, 'Total loss': 0.48550732533137003} | train loss {'Reaction outcome loss': 0.22695266275287984, 'Total loss': 0.22695266275287984}
2023-01-04 05:00:20,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:20,213 INFO:     Epoch: 46
2023-01-04 05:00:21,794 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5208375215530395, 'Total loss': 0.5208375215530395} | train loss {'Reaction outcome loss': 0.22649398154063977, 'Total loss': 0.22649398154063977}
2023-01-04 05:00:21,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:21,794 INFO:     Epoch: 47
2023-01-04 05:00:23,356 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5338026950756709, 'Total loss': 0.5338026950756709} | train loss {'Reaction outcome loss': 0.22156778847177824, 'Total loss': 0.22156778847177824}
2023-01-04 05:00:23,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:23,356 INFO:     Epoch: 48
2023-01-04 05:00:24,917 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5220967113971711, 'Total loss': 0.5220967113971711} | train loss {'Reaction outcome loss': 0.22086267289279143, 'Total loss': 0.22086267289279143}
2023-01-04 05:00:24,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:24,917 INFO:     Epoch: 49
2023-01-04 05:00:26,502 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5423507670561473, 'Total loss': 0.5423507670561473} | train loss {'Reaction outcome loss': 0.220264233485028, 'Total loss': 0.220264233485028}
2023-01-04 05:00:26,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:26,502 INFO:     Epoch: 50
2023-01-04 05:00:28,089 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.548957884311676, 'Total loss': 0.548957884311676} | train loss {'Reaction outcome loss': 0.2143503025774554, 'Total loss': 0.2143503025774554}
2023-01-04 05:00:28,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:28,091 INFO:     Epoch: 51
2023-01-04 05:00:29,673 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5226505935192108, 'Total loss': 0.5226505935192108} | train loss {'Reaction outcome loss': 0.21608224991477015, 'Total loss': 0.21608224991477015}
2023-01-04 05:00:29,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:29,674 INFO:     Epoch: 52
2023-01-04 05:00:31,260 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5103397210439046, 'Total loss': 0.5103397210439046} | train loss {'Reaction outcome loss': 0.2124308991235691, 'Total loss': 0.2124308991235691}
2023-01-04 05:00:31,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:31,261 INFO:     Epoch: 53
2023-01-04 05:00:32,831 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4974740674098333, 'Total loss': 0.4974740674098333} | train loss {'Reaction outcome loss': 0.21249142631670057, 'Total loss': 0.21249142631670057}
2023-01-04 05:00:32,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:32,831 INFO:     Epoch: 54
2023-01-04 05:00:34,402 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5194033682346344, 'Total loss': 0.5194033682346344} | train loss {'Reaction outcome loss': 0.2088888127888952, 'Total loss': 0.2088888127888952}
2023-01-04 05:00:34,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:34,402 INFO:     Epoch: 55
2023-01-04 05:00:35,987 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.500451057155927, 'Total loss': 0.500451057155927} | train loss {'Reaction outcome loss': 0.20519754650999175, 'Total loss': 0.20519754650999175}
2023-01-04 05:00:35,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:35,987 INFO:     Epoch: 56
2023-01-04 05:00:37,574 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5198070486386617, 'Total loss': 0.5198070486386617} | train loss {'Reaction outcome loss': 0.2034659327550249, 'Total loss': 0.2034659327550249}
2023-01-04 05:00:37,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:37,574 INFO:     Epoch: 57
2023-01-04 05:00:39,160 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5191760778427124, 'Total loss': 0.5191760778427124} | train loss {'Reaction outcome loss': 0.20170962137780785, 'Total loss': 0.20170962137780785}
2023-01-04 05:00:39,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:39,161 INFO:     Epoch: 58
2023-01-04 05:00:40,737 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5047727644443512, 'Total loss': 0.5047727644443512} | train loss {'Reaction outcome loss': 0.20148932933807373, 'Total loss': 0.20148932933807373}
2023-01-04 05:00:40,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:40,738 INFO:     Epoch: 59
2023-01-04 05:00:42,305 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5412636578083039, 'Total loss': 0.5412636578083039} | train loss {'Reaction outcome loss': 0.19996459711165654, 'Total loss': 0.19996459711165654}
2023-01-04 05:00:42,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:42,306 INFO:     Epoch: 60
2023-01-04 05:00:43,897 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5372819374005, 'Total loss': 0.5372819374005} | train loss {'Reaction outcome loss': 0.19807312137450708, 'Total loss': 0.19807312137450708}
2023-01-04 05:00:43,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:43,897 INFO:     Epoch: 61
2023-01-04 05:00:45,502 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5283607562383016, 'Total loss': 0.5283607562383016} | train loss {'Reaction outcome loss': 0.19505758478473395, 'Total loss': 0.19505758478473395}
2023-01-04 05:00:45,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:45,503 INFO:     Epoch: 62
2023-01-04 05:00:47,103 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5038618306318919, 'Total loss': 0.5038618306318919} | train loss {'Reaction outcome loss': 0.19526713061736617, 'Total loss': 0.19526713061736617}
2023-01-04 05:00:47,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:47,104 INFO:     Epoch: 63
2023-01-04 05:00:48,704 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5403085082769394, 'Total loss': 0.5403085082769394} | train loss {'Reaction outcome loss': 0.19140859243234845, 'Total loss': 0.19140859243234845}
2023-01-04 05:00:48,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:48,704 INFO:     Epoch: 64
2023-01-04 05:00:50,282 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5135248839855194, 'Total loss': 0.5135248839855194} | train loss {'Reaction outcome loss': 0.19260386587035305, 'Total loss': 0.19260386587035305}
2023-01-04 05:00:50,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:50,282 INFO:     Epoch: 65
2023-01-04 05:00:51,864 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5521577139695485, 'Total loss': 0.5521577139695485} | train loss {'Reaction outcome loss': 0.1911189287709884, 'Total loss': 0.1911189287709884}
2023-01-04 05:00:51,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:51,864 INFO:     Epoch: 66
2023-01-04 05:00:53,482 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5162978123873472, 'Total loss': 0.5162978123873472} | train loss {'Reaction outcome loss': 0.1885501640565666, 'Total loss': 0.1885501640565666}
2023-01-04 05:00:53,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:53,482 INFO:     Epoch: 67
2023-01-04 05:00:55,068 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5156642297903696, 'Total loss': 0.5156642297903696} | train loss {'Reaction outcome loss': 0.18718401206172866, 'Total loss': 0.18718401206172866}
2023-01-04 05:00:55,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:55,069 INFO:     Epoch: 68
2023-01-04 05:00:56,669 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5222402036190033, 'Total loss': 0.5222402036190033} | train loss {'Reaction outcome loss': 0.18832417765134202, 'Total loss': 0.18832417765134202}
2023-01-04 05:00:56,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:56,669 INFO:     Epoch: 69
2023-01-04 05:00:58,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5393027404944102, 'Total loss': 0.5393027404944102} | train loss {'Reaction outcome loss': 0.18593035467760466, 'Total loss': 0.18593035467760466}
2023-01-04 05:00:58,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:58,268 INFO:     Epoch: 70
2023-01-04 05:00:59,851 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5195169319709142, 'Total loss': 0.5195169319709142} | train loss {'Reaction outcome loss': 0.18277836258048977, 'Total loss': 0.18277836258048977}
2023-01-04 05:00:59,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:00:59,852 INFO:     Epoch: 71
2023-01-04 05:01:01,429 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5277617593606313, 'Total loss': 0.5277617593606313} | train loss {'Reaction outcome loss': 0.18050046191438213, 'Total loss': 0.18050046191438213}
2023-01-04 05:01:01,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:01,429 INFO:     Epoch: 72
2023-01-04 05:01:03,014 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5188796490430831, 'Total loss': 0.5188796490430831} | train loss {'Reaction outcome loss': 0.18028574657964183, 'Total loss': 0.18028574657964183}
2023-01-04 05:01:03,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:03,015 INFO:     Epoch: 73
2023-01-04 05:01:04,598 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5225362072388331, 'Total loss': 0.5225362072388331} | train loss {'Reaction outcome loss': 0.18096404684359554, 'Total loss': 0.18096404684359554}
2023-01-04 05:01:04,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:04,598 INFO:     Epoch: 74
2023-01-04 05:01:06,182 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5294167667627334, 'Total loss': 0.5294167667627334} | train loss {'Reaction outcome loss': 0.18035578493015234, 'Total loss': 0.18035578493015234}
2023-01-04 05:01:06,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:06,182 INFO:     Epoch: 75
2023-01-04 05:01:07,767 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5182598650455474, 'Total loss': 0.5182598650455474} | train loss {'Reaction outcome loss': 0.17913270964809172, 'Total loss': 0.17913270964809172}
2023-01-04 05:01:07,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:07,767 INFO:     Epoch: 76
2023-01-04 05:01:09,336 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49527203341325127, 'Total loss': 0.49527203341325127} | train loss {'Reaction outcome loss': 0.17504290686135654, 'Total loss': 0.17504290686135654}
2023-01-04 05:01:09,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:09,337 INFO:     Epoch: 77
2023-01-04 05:01:10,903 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5611041516065598, 'Total loss': 0.5611041516065598} | train loss {'Reaction outcome loss': 0.17445717034213273, 'Total loss': 0.17445717034213273}
2023-01-04 05:01:10,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:10,903 INFO:     Epoch: 78
2023-01-04 05:01:12,488 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5520692944526673, 'Total loss': 0.5520692944526673} | train loss {'Reaction outcome loss': 0.1737999317232833, 'Total loss': 0.1737999317232833}
2023-01-04 05:01:12,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:12,489 INFO:     Epoch: 79
2023-01-04 05:01:14,074 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5319647093613943, 'Total loss': 0.5319647093613943} | train loss {'Reaction outcome loss': 0.17488774041826036, 'Total loss': 0.17488774041826036}
2023-01-04 05:01:14,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:14,074 INFO:     Epoch: 80
2023-01-04 05:01:15,658 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5232497970263164, 'Total loss': 0.5232497970263164} | train loss {'Reaction outcome loss': 0.16974694618866557, 'Total loss': 0.16974694618866557}
2023-01-04 05:01:15,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:15,658 INFO:     Epoch: 81
2023-01-04 05:01:17,219 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.540883426864942, 'Total loss': 0.540883426864942} | train loss {'Reaction outcome loss': 0.17038550391970647, 'Total loss': 0.17038550391970647}
2023-01-04 05:01:17,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:17,220 INFO:     Epoch: 82
2023-01-04 05:01:18,809 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5157731533050537, 'Total loss': 0.5157731533050537} | train loss {'Reaction outcome loss': 0.16854906801966738, 'Total loss': 0.16854906801966738}
2023-01-04 05:01:18,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:18,809 INFO:     Epoch: 83
2023-01-04 05:01:20,418 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5306116998195648, 'Total loss': 0.5306116998195648} | train loss {'Reaction outcome loss': 0.16789088304744754, 'Total loss': 0.16789088304744754}
2023-01-04 05:01:20,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:20,419 INFO:     Epoch: 84
2023-01-04 05:01:22,018 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5564679116010666, 'Total loss': 0.5564679116010666} | train loss {'Reaction outcome loss': 0.16713024252316072, 'Total loss': 0.16713024252316072}
2023-01-04 05:01:22,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:22,019 INFO:     Epoch: 85
2023-01-04 05:01:23,616 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5314711411794026, 'Total loss': 0.5314711411794026} | train loss {'Reaction outcome loss': 0.16523589316632722, 'Total loss': 0.16523589316632722}
2023-01-04 05:01:23,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:23,616 INFO:     Epoch: 86
2023-01-04 05:01:25,224 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5032226741313934, 'Total loss': 0.5032226741313934} | train loss {'Reaction outcome loss': 0.1672019834831466, 'Total loss': 0.1672019834831466}
2023-01-04 05:01:25,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:25,224 INFO:     Epoch: 87
2023-01-04 05:01:26,801 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5426391025384267, 'Total loss': 0.5426391025384267} | train loss {'Reaction outcome loss': 0.16385638519384704, 'Total loss': 0.16385638519384704}
2023-01-04 05:01:26,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:26,801 INFO:     Epoch: 88
2023-01-04 05:01:28,366 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.556731383005778, 'Total loss': 0.556731383005778} | train loss {'Reaction outcome loss': 0.164293786924462, 'Total loss': 0.164293786924462}
2023-01-04 05:01:28,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:28,367 INFO:     Epoch: 89
2023-01-04 05:01:29,952 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5444820086161296, 'Total loss': 0.5444820086161296} | train loss {'Reaction outcome loss': 0.16589465830133948, 'Total loss': 0.16589465830133948}
2023-01-04 05:01:29,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:29,952 INFO:     Epoch: 90
2023-01-04 05:01:31,534 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5274527986844381, 'Total loss': 0.5274527986844381} | train loss {'Reaction outcome loss': 0.16388108614736643, 'Total loss': 0.16388108614736643}
2023-01-04 05:01:31,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:31,535 INFO:     Epoch: 91
2023-01-04 05:01:33,115 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5372739513715108, 'Total loss': 0.5372739513715108} | train loss {'Reaction outcome loss': 0.1616324540091194, 'Total loss': 0.1616324540091194}
2023-01-04 05:01:33,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:33,115 INFO:     Epoch: 92
2023-01-04 05:01:34,695 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5763012150923411, 'Total loss': 0.5763012150923411} | train loss {'Reaction outcome loss': 0.16131060882625017, 'Total loss': 0.16131060882625017}
2023-01-04 05:01:34,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:34,696 INFO:     Epoch: 93
2023-01-04 05:01:36,246 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5148169904947281, 'Total loss': 0.5148169904947281} | train loss {'Reaction outcome loss': 0.16242515803365917, 'Total loss': 0.16242515803365917}
2023-01-04 05:01:36,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:36,246 INFO:     Epoch: 94
2023-01-04 05:01:37,792 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.507161017258962, 'Total loss': 0.507161017258962} | train loss {'Reaction outcome loss': 0.1630807590940387, 'Total loss': 0.1630807590940387}
2023-01-04 05:01:37,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:37,793 INFO:     Epoch: 95
2023-01-04 05:01:39,392 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.532709942261378, 'Total loss': 0.532709942261378} | train loss {'Reaction outcome loss': 0.15911169278507048, 'Total loss': 0.15911169278507048}
2023-01-04 05:01:39,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:39,392 INFO:     Epoch: 96
2023-01-04 05:01:40,981 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5240343193213145, 'Total loss': 0.5240343193213145} | train loss {'Reaction outcome loss': 0.16225165989754836, 'Total loss': 0.16225165989754836}
2023-01-04 05:01:40,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:40,982 INFO:     Epoch: 97
2023-01-04 05:01:42,594 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5343354205290477, 'Total loss': 0.5343354205290477} | train loss {'Reaction outcome loss': 0.15705760952508274, 'Total loss': 0.15705760952508274}
2023-01-04 05:01:42,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:42,594 INFO:     Epoch: 98
2023-01-04 05:01:44,184 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5372536073128382, 'Total loss': 0.5372536073128382} | train loss {'Reaction outcome loss': 0.16108347390925054, 'Total loss': 0.16108347390925054}
2023-01-04 05:01:44,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:44,184 INFO:     Epoch: 99
2023-01-04 05:01:45,749 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5541156649589538, 'Total loss': 0.5541156649589538} | train loss {'Reaction outcome loss': 0.15734660628869201, 'Total loss': 0.15734660628869201}
2023-01-04 05:01:45,750 INFO:     Best model found after epoch 23 of 100.
2023-01-04 05:01:45,750 INFO:   Done with stage: TRAINING
2023-01-04 05:01:45,750 INFO:   Starting stage: EVALUATION
2023-01-04 05:01:45,889 INFO:   Done with stage: EVALUATION
2023-01-04 05:01:45,890 INFO:   Leaving out SEQ value Fold_7
2023-01-04 05:01:45,902 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:01:45,902 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:01:46,552 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:01:46,552 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:01:46,619 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:01:46,619 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:01:46,619 INFO:     No hyperparam tuning for this model
2023-01-04 05:01:46,620 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:01:46,620 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:01:46,620 INFO:     None feature selector for col prot
2023-01-04 05:01:46,620 INFO:     None feature selector for col prot
2023-01-04 05:01:46,620 INFO:     None feature selector for col prot
2023-01-04 05:01:46,621 INFO:     None feature selector for col chem
2023-01-04 05:01:46,621 INFO:     None feature selector for col chem
2023-01-04 05:01:46,621 INFO:     None feature selector for col chem
2023-01-04 05:01:46,621 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:01:46,621 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:01:46,622 INFO:     Number of params in model 70141
2023-01-04 05:01:46,625 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:01:46,625 INFO:   Starting stage: TRAINING
2023-01-04 05:01:46,670 INFO:     Val loss before train {'Reaction outcome loss': 0.9985288143157959, 'Total loss': 0.9985288143157959}
2023-01-04 05:01:46,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:46,670 INFO:     Epoch: 0
2023-01-04 05:01:48,277 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7441029866536458, 'Total loss': 0.7441029866536458} | train loss {'Reaction outcome loss': 0.8890478708898978, 'Total loss': 0.8890478708898978}
2023-01-04 05:01:48,278 INFO:     Found new best model at epoch 0
2023-01-04 05:01:48,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:48,278 INFO:     Epoch: 1
2023-01-04 05:01:49,885 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6196423689524333, 'Total loss': 0.6196423689524333} | train loss {'Reaction outcome loss': 0.6734302915390649, 'Total loss': 0.6734302915390649}
2023-01-04 05:01:49,885 INFO:     Found new best model at epoch 1
2023-01-04 05:01:49,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:49,886 INFO:     Epoch: 2
2023-01-04 05:01:51,490 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5601511299610138, 'Total loss': 0.5601511299610138} | train loss {'Reaction outcome loss': 0.5610713841467558, 'Total loss': 0.5610713841467558}
2023-01-04 05:01:51,490 INFO:     Found new best model at epoch 2
2023-01-04 05:01:51,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:51,491 INFO:     Epoch: 3
2023-01-04 05:01:53,077 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.50908203125, 'Total loss': 0.50908203125} | train loss {'Reaction outcome loss': 0.5019439785919465, 'Total loss': 0.5019439785919465}
2023-01-04 05:01:53,077 INFO:     Found new best model at epoch 3
2023-01-04 05:01:53,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:53,078 INFO:     Epoch: 4
2023-01-04 05:01:54,680 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.487129271030426, 'Total loss': 0.487129271030426} | train loss {'Reaction outcome loss': 0.46874694122734484, 'Total loss': 0.46874694122734484}
2023-01-04 05:01:54,680 INFO:     Found new best model at epoch 4
2023-01-04 05:01:54,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:54,681 INFO:     Epoch: 5
2023-01-04 05:01:56,286 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4689427614212036, 'Total loss': 0.4689427614212036} | train loss {'Reaction outcome loss': 0.44444670299545525, 'Total loss': 0.44444670299545525}
2023-01-04 05:01:56,286 INFO:     Found new best model at epoch 5
2023-01-04 05:01:56,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:56,287 INFO:     Epoch: 6
2023-01-04 05:01:57,894 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46578684250513713, 'Total loss': 0.46578684250513713} | train loss {'Reaction outcome loss': 0.422719800757372, 'Total loss': 0.422719800757372}
2023-01-04 05:01:57,894 INFO:     Found new best model at epoch 6
2023-01-04 05:01:57,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:57,895 INFO:     Epoch: 7
2023-01-04 05:01:59,502 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46251947979132335, 'Total loss': 0.46251947979132335} | train loss {'Reaction outcome loss': 0.4093718669958924, 'Total loss': 0.4093718669958924}
2023-01-04 05:01:59,502 INFO:     Found new best model at epoch 7
2023-01-04 05:01:59,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:01:59,503 INFO:     Epoch: 8
2023-01-04 05:02:01,121 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4376504341761271, 'Total loss': 0.4376504341761271} | train loss {'Reaction outcome loss': 0.39623080979400593, 'Total loss': 0.39623080979400593}
2023-01-04 05:02:01,121 INFO:     Found new best model at epoch 8
2023-01-04 05:02:01,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:01,122 INFO:     Epoch: 9
2023-01-04 05:02:02,710 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4565143833557765, 'Total loss': 0.4565143833557765} | train loss {'Reaction outcome loss': 0.3839602428438001, 'Total loss': 0.3839602428438001}
2023-01-04 05:02:02,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:02,711 INFO:     Epoch: 10
2023-01-04 05:02:04,297 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4408103068669637, 'Total loss': 0.4408103068669637} | train loss {'Reaction outcome loss': 0.3764701792533217, 'Total loss': 0.3764701792533217}
2023-01-04 05:02:04,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:04,297 INFO:     Epoch: 11
2023-01-04 05:02:05,903 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4253246754407883, 'Total loss': 0.4253246754407883} | train loss {'Reaction outcome loss': 0.36966828055114953, 'Total loss': 0.36966828055114953}
2023-01-04 05:02:05,903 INFO:     Found new best model at epoch 11
2023-01-04 05:02:05,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:05,904 INFO:     Epoch: 12
2023-01-04 05:02:07,513 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4177778164545695, 'Total loss': 0.4177778164545695} | train loss {'Reaction outcome loss': 0.35656340681150933, 'Total loss': 0.35656340681150933}
2023-01-04 05:02:07,513 INFO:     Found new best model at epoch 12
2023-01-04 05:02:07,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:07,514 INFO:     Epoch: 13
2023-01-04 05:02:09,119 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4176508039236069, 'Total loss': 0.4176508039236069} | train loss {'Reaction outcome loss': 0.3509862259137932, 'Total loss': 0.3509862259137932}
2023-01-04 05:02:09,120 INFO:     Found new best model at epoch 13
2023-01-04 05:02:09,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:09,121 INFO:     Epoch: 14
2023-01-04 05:02:10,707 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41544104417165123, 'Total loss': 0.41544104417165123} | train loss {'Reaction outcome loss': 0.3448593255253475, 'Total loss': 0.3448593255253475}
2023-01-04 05:02:10,707 INFO:     Found new best model at epoch 14
2023-01-04 05:02:10,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:10,708 INFO:     Epoch: 15
2023-01-04 05:02:12,290 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42042431732018787, 'Total loss': 0.42042431732018787} | train loss {'Reaction outcome loss': 0.33814725438502724, 'Total loss': 0.33814725438502724}
2023-01-04 05:02:12,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:12,290 INFO:     Epoch: 16
2023-01-04 05:02:13,896 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40231404900550843, 'Total loss': 0.40231404900550843} | train loss {'Reaction outcome loss': 0.32802379499811557, 'Total loss': 0.32802379499811557}
2023-01-04 05:02:13,896 INFO:     Found new best model at epoch 16
2023-01-04 05:02:13,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:13,897 INFO:     Epoch: 17
2023-01-04 05:02:15,498 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40898660322030383, 'Total loss': 0.40898660322030383} | train loss {'Reaction outcome loss': 0.3265444014207981, 'Total loss': 0.3265444014207981}
2023-01-04 05:02:15,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:15,499 INFO:     Epoch: 18
2023-01-04 05:02:17,097 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4001801987489065, 'Total loss': 0.4001801987489065} | train loss {'Reaction outcome loss': 0.3210904357235354, 'Total loss': 0.3210904357235354}
2023-01-04 05:02:17,097 INFO:     Found new best model at epoch 18
2023-01-04 05:02:17,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:17,098 INFO:     Epoch: 19
2023-01-04 05:02:18,717 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4046205182870229, 'Total loss': 0.4046205182870229} | train loss {'Reaction outcome loss': 0.3153876270359174, 'Total loss': 0.3153876270359174}
2023-01-04 05:02:18,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:18,718 INFO:     Epoch: 20
2023-01-04 05:02:20,319 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40132147868474327, 'Total loss': 0.40132147868474327} | train loss {'Reaction outcome loss': 0.312008364294195, 'Total loss': 0.312008364294195}
2023-01-04 05:02:20,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:20,319 INFO:     Epoch: 21
2023-01-04 05:02:21,898 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3911141445239385, 'Total loss': 0.3911141445239385} | train loss {'Reaction outcome loss': 0.3048018685101602, 'Total loss': 0.3048018685101602}
2023-01-04 05:02:21,898 INFO:     Found new best model at epoch 21
2023-01-04 05:02:21,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:21,899 INFO:     Epoch: 22
2023-01-04 05:02:23,505 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40393100182215375, 'Total loss': 0.40393100182215375} | train loss {'Reaction outcome loss': 0.3005771361264511, 'Total loss': 0.3005771361264511}
2023-01-04 05:02:23,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:23,505 INFO:     Epoch: 23
2023-01-04 05:02:25,112 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4087755093971888, 'Total loss': 0.4087755093971888} | train loss {'Reaction outcome loss': 0.2968946050328038, 'Total loss': 0.2968946050328038}
2023-01-04 05:02:25,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:25,112 INFO:     Epoch: 24
2023-01-04 05:02:26,720 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39821152687072753, 'Total loss': 0.39821152687072753} | train loss {'Reaction outcome loss': 0.29212408539728135, 'Total loss': 0.29212408539728135}
2023-01-04 05:02:26,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:26,720 INFO:     Epoch: 25
2023-01-04 05:02:28,325 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4061359018087387, 'Total loss': 0.4061359018087387} | train loss {'Reaction outcome loss': 0.2909337278953098, 'Total loss': 0.2909337278953098}
2023-01-04 05:02:28,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:28,326 INFO:     Epoch: 26
2023-01-04 05:02:29,915 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39085501035054526, 'Total loss': 0.39085501035054526} | train loss {'Reaction outcome loss': 0.282605611890662, 'Total loss': 0.282605611890662}
2023-01-04 05:02:29,915 INFO:     Found new best model at epoch 26
2023-01-04 05:02:29,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:29,916 INFO:     Epoch: 27
2023-01-04 05:02:31,510 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4045788158973058, 'Total loss': 0.4045788158973058} | train loss {'Reaction outcome loss': 0.27635179357838546, 'Total loss': 0.27635179357838546}
2023-01-04 05:02:31,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:31,510 INFO:     Epoch: 28
2023-01-04 05:02:33,137 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3940627525250117, 'Total loss': 0.3940627525250117} | train loss {'Reaction outcome loss': 0.2773634571084477, 'Total loss': 0.2773634571084477}
2023-01-04 05:02:33,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:33,137 INFO:     Epoch: 29
2023-01-04 05:02:34,760 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3936421533425649, 'Total loss': 0.3936421533425649} | train loss {'Reaction outcome loss': 0.2745735043195826, 'Total loss': 0.2745735043195826}
2023-01-04 05:02:34,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:34,761 INFO:     Epoch: 30
2023-01-04 05:02:36,390 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41189345220724743, 'Total loss': 0.41189345220724743} | train loss {'Reaction outcome loss': 0.27038570683086394, 'Total loss': 0.27038570683086394}
2023-01-04 05:02:36,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:36,390 INFO:     Epoch: 31
2023-01-04 05:02:37,972 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41128167311350505, 'Total loss': 0.41128167311350505} | train loss {'Reaction outcome loss': 0.2673054102956173, 'Total loss': 0.2673054102956173}
2023-01-04 05:02:37,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:37,972 INFO:     Epoch: 32
2023-01-04 05:02:39,566 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4101702372233073, 'Total loss': 0.4101702372233073} | train loss {'Reaction outcome loss': 0.2621793465601408, 'Total loss': 0.2621793465601408}
2023-01-04 05:02:39,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:39,567 INFO:     Epoch: 33
2023-01-04 05:02:41,196 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4068629870812098, 'Total loss': 0.4068629870812098} | train loss {'Reaction outcome loss': 0.2626933258981696, 'Total loss': 0.2626933258981696}
2023-01-04 05:02:41,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:41,196 INFO:     Epoch: 34
2023-01-04 05:02:42,795 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4070262352625529, 'Total loss': 0.4070262352625529} | train loss {'Reaction outcome loss': 0.2589555704959463, 'Total loss': 0.2589555704959463}
2023-01-04 05:02:42,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:42,795 INFO:     Epoch: 35
2023-01-04 05:02:44,423 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40422582427660625, 'Total loss': 0.40422582427660625} | train loss {'Reaction outcome loss': 0.25460518331734283, 'Total loss': 0.25460518331734283}
2023-01-04 05:02:44,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:44,423 INFO:     Epoch: 36
2023-01-04 05:02:46,022 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40436020692189534, 'Total loss': 0.40436020692189534} | train loss {'Reaction outcome loss': 0.25533287212360206, 'Total loss': 0.25533287212360206}
2023-01-04 05:02:46,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:46,023 INFO:     Epoch: 37
2023-01-04 05:02:47,612 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41769711176554364, 'Total loss': 0.41769711176554364} | train loss {'Reaction outcome loss': 0.2495212523058218, 'Total loss': 0.2495212523058218}
2023-01-04 05:02:47,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:47,612 INFO:     Epoch: 38
2023-01-04 05:02:49,199 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3956253916025162, 'Total loss': 0.3956253916025162} | train loss {'Reaction outcome loss': 0.24981888429352522, 'Total loss': 0.24981888429352522}
2023-01-04 05:02:49,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:49,199 INFO:     Epoch: 39
2023-01-04 05:02:50,828 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41498175263404846, 'Total loss': 0.41498175263404846} | train loss {'Reaction outcome loss': 0.24650723495207968, 'Total loss': 0.24650723495207968}
2023-01-04 05:02:50,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:50,828 INFO:     Epoch: 40
2023-01-04 05:02:52,410 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4026000380516052, 'Total loss': 0.4026000380516052} | train loss {'Reaction outcome loss': 0.24315343553785382, 'Total loss': 0.24315343553785382}
2023-01-04 05:02:52,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:52,411 INFO:     Epoch: 41
2023-01-04 05:02:54,034 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4062441090742747, 'Total loss': 0.4062441090742747} | train loss {'Reaction outcome loss': 0.2407003452577746, 'Total loss': 0.2407003452577746}
2023-01-04 05:02:54,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:54,035 INFO:     Epoch: 42
2023-01-04 05:02:55,643 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41196059385935463, 'Total loss': 0.41196059385935463} | train loss {'Reaction outcome loss': 0.24140163051092237, 'Total loss': 0.24140163051092237}
2023-01-04 05:02:55,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:55,643 INFO:     Epoch: 43
2023-01-04 05:02:57,228 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4253285070260366, 'Total loss': 0.4253285070260366} | train loss {'Reaction outcome loss': 0.237221792098202, 'Total loss': 0.237221792098202}
2023-01-04 05:02:57,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:57,228 INFO:     Epoch: 44
2023-01-04 05:02:58,833 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4261311670144399, 'Total loss': 0.4261311670144399} | train loss {'Reaction outcome loss': 0.23421754826546146, 'Total loss': 0.23421754826546146}
2023-01-04 05:02:58,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:02:58,834 INFO:     Epoch: 45
2023-01-04 05:03:00,444 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40138904452323915, 'Total loss': 0.40138904452323915} | train loss {'Reaction outcome loss': 0.2342238957701177, 'Total loss': 0.2342238957701177}
2023-01-04 05:03:00,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:00,444 INFO:     Epoch: 46
2023-01-04 05:03:02,068 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40031286676724753, 'Total loss': 0.40031286676724753} | train loss {'Reaction outcome loss': 0.23469539952299656, 'Total loss': 0.23469539952299656}
2023-01-04 05:03:02,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:02,069 INFO:     Epoch: 47
2023-01-04 05:03:03,695 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4174050917228063, 'Total loss': 0.4174050917228063} | train loss {'Reaction outcome loss': 0.23105826177751976, 'Total loss': 0.23105826177751976}
2023-01-04 05:03:03,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:03,695 INFO:     Epoch: 48
2023-01-04 05:03:05,301 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3959093322356542, 'Total loss': 0.3959093322356542} | train loss {'Reaction outcome loss': 0.22709609136415732, 'Total loss': 0.22709609136415732}
2023-01-04 05:03:05,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:05,301 INFO:     Epoch: 49
2023-01-04 05:03:06,872 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.400953729947408, 'Total loss': 0.400953729947408} | train loss {'Reaction outcome loss': 0.22765729127162632, 'Total loss': 0.22765729127162632}
2023-01-04 05:03:06,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:06,872 INFO:     Epoch: 50
2023-01-04 05:03:08,501 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4071611861387889, 'Total loss': 0.4071611861387889} | train loss {'Reaction outcome loss': 0.22786883034134814, 'Total loss': 0.22786883034134814}
2023-01-04 05:03:08,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:08,501 INFO:     Epoch: 51
2023-01-04 05:03:10,128 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3949250270922979, 'Total loss': 0.3949250270922979} | train loss {'Reaction outcome loss': 0.22296292087338893, 'Total loss': 0.22296292087338893}
2023-01-04 05:03:10,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:10,128 INFO:     Epoch: 52
2023-01-04 05:03:11,723 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4123969962199529, 'Total loss': 0.4123969962199529} | train loss {'Reaction outcome loss': 0.22037618604592898, 'Total loss': 0.22037618604592898}
2023-01-04 05:03:11,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:11,723 INFO:     Epoch: 53
2023-01-04 05:03:13,337 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4167143603165944, 'Total loss': 0.4167143603165944} | train loss {'Reaction outcome loss': 0.2202562539424707, 'Total loss': 0.2202562539424707}
2023-01-04 05:03:13,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:13,337 INFO:     Epoch: 54
2023-01-04 05:03:14,916 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39576588571071625, 'Total loss': 0.39576588571071625} | train loss {'Reaction outcome loss': 0.21817489522458844, 'Total loss': 0.21817489522458844}
2023-01-04 05:03:14,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:14,916 INFO:     Epoch: 55
2023-01-04 05:03:16,508 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4132300943136215, 'Total loss': 0.4132300943136215} | train loss {'Reaction outcome loss': 0.21779326092626644, 'Total loss': 0.21779326092626644}
2023-01-04 05:03:16,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:16,509 INFO:     Epoch: 56
2023-01-04 05:03:18,112 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3894710585474968, 'Total loss': 0.3894710585474968} | train loss {'Reaction outcome loss': 0.2138979013619225, 'Total loss': 0.2138979013619225}
2023-01-04 05:03:18,112 INFO:     Found new best model at epoch 56
2023-01-04 05:03:18,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:18,113 INFO:     Epoch: 57
2023-01-04 05:03:19,718 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4108151654402415, 'Total loss': 0.4108151654402415} | train loss {'Reaction outcome loss': 0.2153625101429353, 'Total loss': 0.2153625101429353}
2023-01-04 05:03:19,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:19,718 INFO:     Epoch: 58
2023-01-04 05:03:21,324 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.392138201991717, 'Total loss': 0.392138201991717} | train loss {'Reaction outcome loss': 0.21300503415213595, 'Total loss': 0.21300503415213595}
2023-01-04 05:03:21,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:21,325 INFO:     Epoch: 59
2023-01-04 05:03:22,920 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4266997198263804, 'Total loss': 0.4266997198263804} | train loss {'Reaction outcome loss': 0.2096680650077357, 'Total loss': 0.2096680650077357}
2023-01-04 05:03:22,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:22,920 INFO:     Epoch: 60
2023-01-04 05:03:24,512 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4010758250951767, 'Total loss': 0.4010758250951767} | train loss {'Reaction outcome loss': 0.21127137981543473, 'Total loss': 0.21127137981543473}
2023-01-04 05:03:24,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:24,513 INFO:     Epoch: 61
2023-01-04 05:03:26,139 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40499866008758545, 'Total loss': 0.40499866008758545} | train loss {'Reaction outcome loss': 0.20783939123799225, 'Total loss': 0.20783939123799225}
2023-01-04 05:03:26,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:26,140 INFO:     Epoch: 62
2023-01-04 05:03:27,745 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4109445552031199, 'Total loss': 0.4109445552031199} | train loss {'Reaction outcome loss': 0.2085099020360932, 'Total loss': 0.2085099020360932}
2023-01-04 05:03:27,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:27,746 INFO:     Epoch: 63
2023-01-04 05:03:29,365 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3860894689957301, 'Total loss': 0.3860894689957301} | train loss {'Reaction outcome loss': 0.2076329283604553, 'Total loss': 0.2076329283604553}
2023-01-04 05:03:29,365 INFO:     Found new best model at epoch 63
2023-01-04 05:03:29,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:29,366 INFO:     Epoch: 64
2023-01-04 05:03:30,977 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3949421813090642, 'Total loss': 0.3949421813090642} | train loss {'Reaction outcome loss': 0.20230705034162594, 'Total loss': 0.20230705034162594}
2023-01-04 05:03:30,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:30,977 INFO:     Epoch: 65
2023-01-04 05:03:32,565 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41725237568219503, 'Total loss': 0.41725237568219503} | train loss {'Reaction outcome loss': 0.2039874763722239, 'Total loss': 0.2039874763722239}
2023-01-04 05:03:32,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:32,565 INFO:     Epoch: 66
2023-01-04 05:03:34,157 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39203234513600665, 'Total loss': 0.39203234513600665} | train loss {'Reaction outcome loss': 0.19923079431406643, 'Total loss': 0.19923079431406643}
2023-01-04 05:03:34,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:34,157 INFO:     Epoch: 67
2023-01-04 05:03:35,749 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38081156810124717, 'Total loss': 0.38081156810124717} | train loss {'Reaction outcome loss': 0.20052973272460461, 'Total loss': 0.20052973272460461}
2023-01-04 05:03:35,749 INFO:     Found new best model at epoch 67
2023-01-04 05:03:35,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:35,750 INFO:     Epoch: 68
2023-01-04 05:03:37,352 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3964339433858792, 'Total loss': 0.3964339433858792} | train loss {'Reaction outcome loss': 0.20026849982217762, 'Total loss': 0.20026849982217762}
2023-01-04 05:03:37,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:37,353 INFO:     Epoch: 69
2023-01-04 05:03:38,956 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.407669589916865, 'Total loss': 0.407669589916865} | train loss {'Reaction outcome loss': 0.19964202200247494, 'Total loss': 0.19964202200247494}
2023-01-04 05:03:38,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:38,956 INFO:     Epoch: 70
2023-01-04 05:03:40,540 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38930637538433077, 'Total loss': 0.38930637538433077} | train loss {'Reaction outcome loss': 0.19700896481744648, 'Total loss': 0.19700896481744648}
2023-01-04 05:03:40,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:40,541 INFO:     Epoch: 71
2023-01-04 05:03:42,147 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4025462319453557, 'Total loss': 0.4025462319453557} | train loss {'Reaction outcome loss': 0.19679110930284438, 'Total loss': 0.19679110930284438}
2023-01-04 05:03:42,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:42,148 INFO:     Epoch: 72
2023-01-04 05:03:43,775 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3968426366647085, 'Total loss': 0.3968426366647085} | train loss {'Reaction outcome loss': 0.19514112347999205, 'Total loss': 0.19514112347999205}
2023-01-04 05:03:43,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:43,776 INFO:     Epoch: 73
2023-01-04 05:03:45,377 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41109693348407744, 'Total loss': 0.41109693348407744} | train loss {'Reaction outcome loss': 0.19520477282340615, 'Total loss': 0.19520477282340615}
2023-01-04 05:03:45,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:45,377 INFO:     Epoch: 74
2023-01-04 05:03:46,991 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41159162918726605, 'Total loss': 0.41159162918726605} | train loss {'Reaction outcome loss': 0.19413377118670122, 'Total loss': 0.19413377118670122}
2023-01-04 05:03:46,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:46,991 INFO:     Epoch: 75
2023-01-04 05:03:48,595 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4100453992684682, 'Total loss': 0.4100453992684682} | train loss {'Reaction outcome loss': 0.19141782798706838, 'Total loss': 0.19141782798706838}
2023-01-04 05:03:48,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:48,595 INFO:     Epoch: 76
2023-01-04 05:03:50,195 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3818604121605555, 'Total loss': 0.3818604121605555} | train loss {'Reaction outcome loss': 0.1898618327178034, 'Total loss': 0.1898618327178034}
2023-01-04 05:03:50,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:50,195 INFO:     Epoch: 77
2023-01-04 05:03:51,796 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3878554493188858, 'Total loss': 0.3878554493188858} | train loss {'Reaction outcome loss': 0.19008325771949783, 'Total loss': 0.19008325771949783}
2023-01-04 05:03:51,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:51,798 INFO:     Epoch: 78
2023-01-04 05:03:53,421 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40432801842689514, 'Total loss': 0.40432801842689514} | train loss {'Reaction outcome loss': 0.189792434661397, 'Total loss': 0.189792434661397}
2023-01-04 05:03:53,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:53,421 INFO:     Epoch: 79
2023-01-04 05:03:55,048 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39313022991021473, 'Total loss': 0.39313022991021473} | train loss {'Reaction outcome loss': 0.18895057089868866, 'Total loss': 0.18895057089868866}
2023-01-04 05:03:55,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:55,048 INFO:     Epoch: 80
2023-01-04 05:03:56,673 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4117831110954285, 'Total loss': 0.4117831110954285} | train loss {'Reaction outcome loss': 0.18873495780039135, 'Total loss': 0.18873495780039135}
2023-01-04 05:03:56,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:56,673 INFO:     Epoch: 81
2023-01-04 05:03:58,290 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3965756018956502, 'Total loss': 0.3965756018956502} | train loss {'Reaction outcome loss': 0.18970046934775928, 'Total loss': 0.18970046934775928}
2023-01-04 05:03:58,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:58,290 INFO:     Epoch: 82
2023-01-04 05:03:59,863 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3817140758037567, 'Total loss': 0.3817140758037567} | train loss {'Reaction outcome loss': 0.18764632729147745, 'Total loss': 0.18764632729147745}
2023-01-04 05:03:59,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:03:59,864 INFO:     Epoch: 83
2023-01-04 05:04:01,488 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40548210839430493, 'Total loss': 0.40548210839430493} | train loss {'Reaction outcome loss': 0.18718980502888613, 'Total loss': 0.18718980502888613}
2023-01-04 05:04:01,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:01,489 INFO:     Epoch: 84
2023-01-04 05:04:03,114 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3856242249409358, 'Total loss': 0.3856242249409358} | train loss {'Reaction outcome loss': 0.18308789332797382, 'Total loss': 0.18308789332797382}
2023-01-04 05:04:03,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:03,114 INFO:     Epoch: 85
2023-01-04 05:04:04,737 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4180527667204539, 'Total loss': 0.4180527667204539} | train loss {'Reaction outcome loss': 0.1865122590267809, 'Total loss': 0.1865122590267809}
2023-01-04 05:04:04,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:04,738 INFO:     Epoch: 86
2023-01-04 05:04:06,359 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39553553983569145, 'Total loss': 0.39553553983569145} | train loss {'Reaction outcome loss': 0.1873285292785628, 'Total loss': 0.1873285292785628}
2023-01-04 05:04:06,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:06,359 INFO:     Epoch: 87
2023-01-04 05:04:07,957 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3950806826353073, 'Total loss': 0.3950806826353073} | train loss {'Reaction outcome loss': 0.18339575400125463, 'Total loss': 0.18339575400125463}
2023-01-04 05:04:07,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:07,957 INFO:     Epoch: 88
2023-01-04 05:04:09,550 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3927705099185308, 'Total loss': 0.3927705099185308} | train loss {'Reaction outcome loss': 0.1839510745331914, 'Total loss': 0.1839510745331914}
2023-01-04 05:04:09,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:09,550 INFO:     Epoch: 89
2023-01-04 05:04:11,176 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4013994793097178, 'Total loss': 0.4013994793097178} | train loss {'Reaction outcome loss': 0.1798274101897913, 'Total loss': 0.1798274101897913}
2023-01-04 05:04:11,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:11,177 INFO:     Epoch: 90
2023-01-04 05:04:12,796 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3895191629727682, 'Total loss': 0.3895191629727682} | train loss {'Reaction outcome loss': 0.18016232153407502, 'Total loss': 0.18016232153407502}
2023-01-04 05:04:12,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:12,796 INFO:     Epoch: 91
2023-01-04 05:04:14,421 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.413441742459933, 'Total loss': 0.413441742459933} | train loss {'Reaction outcome loss': 0.17928202017227235, 'Total loss': 0.17928202017227235}
2023-01-04 05:04:14,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:14,421 INFO:     Epoch: 92
2023-01-04 05:04:16,048 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3956333756446838, 'Total loss': 0.3956333756446838} | train loss {'Reaction outcome loss': 0.1791176684873199, 'Total loss': 0.1791176684873199}
2023-01-04 05:04:16,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:16,048 INFO:     Epoch: 93
2023-01-04 05:04:17,641 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3787142405907313, 'Total loss': 0.3787142405907313} | train loss {'Reaction outcome loss': 0.18073574676168308, 'Total loss': 0.18073574676168308}
2023-01-04 05:04:17,641 INFO:     Found new best model at epoch 93
2023-01-04 05:04:17,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:17,642 INFO:     Epoch: 94
2023-01-04 05:04:19,228 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4090393091241519, 'Total loss': 0.4090393091241519} | train loss {'Reaction outcome loss': 0.17859163762672067, 'Total loss': 0.17859163762672067}
2023-01-04 05:04:19,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:19,228 INFO:     Epoch: 95
2023-01-04 05:04:20,832 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38517283300558725, 'Total loss': 0.38517283300558725} | train loss {'Reaction outcome loss': 0.17765171935828908, 'Total loss': 0.17765171935828908}
2023-01-04 05:04:20,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:20,832 INFO:     Epoch: 96
2023-01-04 05:04:22,438 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.366546299867332, 'Total loss': 0.366546299867332} | train loss {'Reaction outcome loss': 0.17621498722381326, 'Total loss': 0.17621498722381326}
2023-01-04 05:04:22,439 INFO:     Found new best model at epoch 96
2023-01-04 05:04:22,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:22,439 INFO:     Epoch: 97
2023-01-04 05:04:24,045 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4030579725901286, 'Total loss': 0.4030579725901286} | train loss {'Reaction outcome loss': 0.17667010811826597, 'Total loss': 0.17667010811826597}
2023-01-04 05:04:24,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:24,045 INFO:     Epoch: 98
2023-01-04 05:04:25,632 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38935630172491076, 'Total loss': 0.38935630172491076} | train loss {'Reaction outcome loss': 0.1745064615033271, 'Total loss': 0.1745064615033271}
2023-01-04 05:04:25,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:25,632 INFO:     Epoch: 99
2023-01-04 05:04:27,219 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39930779139200845, 'Total loss': 0.39930779139200845} | train loss {'Reaction outcome loss': 0.17378139323706232, 'Total loss': 0.17378139323706232}
2023-01-04 05:04:27,219 INFO:     Best model found after epoch 97 of 100.
2023-01-04 05:04:27,220 INFO:   Done with stage: TRAINING
2023-01-04 05:04:27,220 INFO:   Starting stage: EVALUATION
2023-01-04 05:04:27,340 INFO:   Done with stage: EVALUATION
2023-01-04 05:04:27,340 INFO:   Leaving out SEQ value Fold_8
2023-01-04 05:04:27,352 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:04:27,353 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:04:27,994 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:04:27,994 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:04:28,061 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:04:28,062 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:04:28,062 INFO:     No hyperparam tuning for this model
2023-01-04 05:04:28,062 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:04:28,062 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:04:28,063 INFO:     None feature selector for col prot
2023-01-04 05:04:28,063 INFO:     None feature selector for col prot
2023-01-04 05:04:28,063 INFO:     None feature selector for col prot
2023-01-04 05:04:28,063 INFO:     None feature selector for col chem
2023-01-04 05:04:28,063 INFO:     None feature selector for col chem
2023-01-04 05:04:28,063 INFO:     None feature selector for col chem
2023-01-04 05:04:28,064 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:04:28,064 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:04:28,065 INFO:     Number of params in model 70141
2023-01-04 05:04:28,068 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:04:28,068 INFO:   Starting stage: TRAINING
2023-01-04 05:04:28,114 INFO:     Val loss before train {'Reaction outcome loss': 1.12031858364741, 'Total loss': 1.12031858364741}
2023-01-04 05:04:28,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:28,114 INFO:     Epoch: 0
2023-01-04 05:04:29,710 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6617078145345052, 'Total loss': 0.6617078145345052} | train loss {'Reaction outcome loss': 0.8089021845464257, 'Total loss': 0.8089021845464257}
2023-01-04 05:04:29,711 INFO:     Found new best model at epoch 0
2023-01-04 05:04:29,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:29,711 INFO:     Epoch: 1
2023-01-04 05:04:31,343 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5660269995530446, 'Total loss': 0.5660269995530446} | train loss {'Reaction outcome loss': 0.5771463463231381, 'Total loss': 0.5771463463231381}
2023-01-04 05:04:31,343 INFO:     Found new best model at epoch 1
2023-01-04 05:04:31,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:31,344 INFO:     Epoch: 2
2023-01-04 05:04:32,952 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5200389534235, 'Total loss': 0.5200389534235} | train loss {'Reaction outcome loss': 0.5153658454157952, 'Total loss': 0.5153658454157952}
2023-01-04 05:04:32,952 INFO:     Found new best model at epoch 2
2023-01-04 05:04:32,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:32,953 INFO:     Epoch: 3
2023-01-04 05:04:34,464 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4986120144526164, 'Total loss': 0.4986120144526164} | train loss {'Reaction outcome loss': 0.47790023640128854, 'Total loss': 0.47790023640128854}
2023-01-04 05:04:34,464 INFO:     Found new best model at epoch 3
2023-01-04 05:04:34,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:34,465 INFO:     Epoch: 4
2023-01-04 05:04:35,546 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48932133118311566, 'Total loss': 0.48932133118311566} | train loss {'Reaction outcome loss': 0.45252947891266015, 'Total loss': 0.45252947891266015}
2023-01-04 05:04:35,546 INFO:     Found new best model at epoch 4
2023-01-04 05:04:35,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:35,547 INFO:     Epoch: 5
2023-01-04 05:04:36,613 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46373292009035744, 'Total loss': 0.46373292009035744} | train loss {'Reaction outcome loss': 0.4319365611615164, 'Total loss': 0.4319365611615164}
2023-01-04 05:04:36,613 INFO:     Found new best model at epoch 5
2023-01-04 05:04:36,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:36,614 INFO:     Epoch: 6
2023-01-04 05:04:37,681 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4470672031243642, 'Total loss': 0.4470672031243642} | train loss {'Reaction outcome loss': 0.4140740373927722, 'Total loss': 0.4140740373927722}
2023-01-04 05:04:37,681 INFO:     Found new best model at epoch 6
2023-01-04 05:04:37,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:37,682 INFO:     Epoch: 7
2023-01-04 05:04:38,771 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42030314008394876, 'Total loss': 0.42030314008394876} | train loss {'Reaction outcome loss': 0.4024664321239444, 'Total loss': 0.4024664321239444}
2023-01-04 05:04:38,771 INFO:     Found new best model at epoch 7
2023-01-04 05:04:38,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:38,772 INFO:     Epoch: 8
2023-01-04 05:04:40,360 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43284437159697214, 'Total loss': 0.43284437159697214} | train loss {'Reaction outcome loss': 0.39146179354925087, 'Total loss': 0.39146179354925087}
2023-01-04 05:04:40,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:40,361 INFO:     Epoch: 9
2023-01-04 05:04:41,990 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41900781194368997, 'Total loss': 0.41900781194368997} | train loss {'Reaction outcome loss': 0.3792798776187777, 'Total loss': 0.3792798776187777}
2023-01-04 05:04:41,991 INFO:     Found new best model at epoch 9
2023-01-04 05:04:41,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:41,991 INFO:     Epoch: 10
2023-01-04 05:04:43,583 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43691970805327096, 'Total loss': 0.43691970805327096} | train loss {'Reaction outcome loss': 0.3683600029165762, 'Total loss': 0.3683600029165762}
2023-01-04 05:04:43,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:43,583 INFO:     Epoch: 11
2023-01-04 05:04:45,205 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40984214544296266, 'Total loss': 0.40984214544296266} | train loss {'Reaction outcome loss': 0.36588068857141165, 'Total loss': 0.36588068857141165}
2023-01-04 05:04:45,205 INFO:     Found new best model at epoch 11
2023-01-04 05:04:45,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:45,206 INFO:     Epoch: 12
2023-01-04 05:04:46,812 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4074978768825531, 'Total loss': 0.4074978768825531} | train loss {'Reaction outcome loss': 0.3573098616506668, 'Total loss': 0.3573098616506668}
2023-01-04 05:04:46,812 INFO:     Found new best model at epoch 12
2023-01-04 05:04:46,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:46,813 INFO:     Epoch: 13
2023-01-04 05:04:48,390 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40629357198874155, 'Total loss': 0.40629357198874155} | train loss {'Reaction outcome loss': 0.3477166135697558, 'Total loss': 0.3477166135697558}
2023-01-04 05:04:48,390 INFO:     Found new best model at epoch 13
2023-01-04 05:04:48,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:48,391 INFO:     Epoch: 14
2023-01-04 05:04:50,008 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39874534010887147, 'Total loss': 0.39874534010887147} | train loss {'Reaction outcome loss': 0.3385995296741147, 'Total loss': 0.3385995296741147}
2023-01-04 05:04:50,008 INFO:     Found new best model at epoch 14
2023-01-04 05:04:50,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:50,009 INFO:     Epoch: 15
2023-01-04 05:04:51,611 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39205034375190734, 'Total loss': 0.39205034375190734} | train loss {'Reaction outcome loss': 0.33338082762624044, 'Total loss': 0.33338082762624044}
2023-01-04 05:04:51,611 INFO:     Found new best model at epoch 15
2023-01-04 05:04:51,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:51,612 INFO:     Epoch: 16
2023-01-04 05:04:53,244 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4151535193125407, 'Total loss': 0.4151535193125407} | train loss {'Reaction outcome loss': 0.3292567954966849, 'Total loss': 0.3292567954966849}
2023-01-04 05:04:53,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:53,244 INFO:     Epoch: 17
2023-01-04 05:04:54,872 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41136376361052196, 'Total loss': 0.41136376361052196} | train loss {'Reaction outcome loss': 0.3216957184671681, 'Total loss': 0.3216957184671681}
2023-01-04 05:04:54,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:54,872 INFO:     Epoch: 18
2023-01-04 05:04:56,495 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4207303444544474, 'Total loss': 0.4207303444544474} | train loss {'Reaction outcome loss': 0.316613521123224, 'Total loss': 0.316613521123224}
2023-01-04 05:04:56,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:56,496 INFO:     Epoch: 19
2023-01-04 05:04:58,073 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3883393436670303, 'Total loss': 0.3883393436670303} | train loss {'Reaction outcome loss': 0.31257236765913826, 'Total loss': 0.31257236765913826}
2023-01-04 05:04:58,074 INFO:     Found new best model at epoch 19
2023-01-04 05:04:58,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:58,075 INFO:     Epoch: 20
2023-01-04 05:04:59,692 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3960460205872854, 'Total loss': 0.3960460205872854} | train loss {'Reaction outcome loss': 0.3041688056892135, 'Total loss': 0.3041688056892135}
2023-01-04 05:04:59,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:04:59,692 INFO:     Epoch: 21
2023-01-04 05:05:01,294 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39814659357070925, 'Total loss': 0.39814659357070925} | train loss {'Reaction outcome loss': 0.29892742662259086, 'Total loss': 0.29892742662259086}
2023-01-04 05:05:01,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:01,296 INFO:     Epoch: 22
2023-01-04 05:05:02,927 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39345645606517793, 'Total loss': 0.39345645606517793} | train loss {'Reaction outcome loss': 0.29509010876400693, 'Total loss': 0.29509010876400693}
2023-01-04 05:05:02,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:02,928 INFO:     Epoch: 23
2023-01-04 05:05:04,548 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4073306272427241, 'Total loss': 0.4073306272427241} | train loss {'Reaction outcome loss': 0.29108363046353863, 'Total loss': 0.29108363046353863}
2023-01-04 05:05:04,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:04,549 INFO:     Epoch: 24
2023-01-04 05:05:06,148 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40158920685450233, 'Total loss': 0.40158920685450233} | train loss {'Reaction outcome loss': 0.28557990945578704, 'Total loss': 0.28557990945578704}
2023-01-04 05:05:06,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:06,148 INFO:     Epoch: 25
2023-01-04 05:05:07,770 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3821192403634389, 'Total loss': 0.3821192403634389} | train loss {'Reaction outcome loss': 0.2836184302476518, 'Total loss': 0.2836184302476518}
2023-01-04 05:05:07,771 INFO:     Found new best model at epoch 25
2023-01-04 05:05:07,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:07,772 INFO:     Epoch: 26
2023-01-04 05:05:09,400 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.396369328101476, 'Total loss': 0.396369328101476} | train loss {'Reaction outcome loss': 0.28207540283978416, 'Total loss': 0.28207540283978416}
2023-01-04 05:05:09,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:09,400 INFO:     Epoch: 27
2023-01-04 05:05:11,009 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39522116879622143, 'Total loss': 0.39522116879622143} | train loss {'Reaction outcome loss': 0.28273749504080403, 'Total loss': 0.28273749504080403}
2023-01-04 05:05:11,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:11,010 INFO:     Epoch: 28
2023-01-04 05:05:12,638 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41213834285736084, 'Total loss': 0.41213834285736084} | train loss {'Reaction outcome loss': 0.27521045355799445, 'Total loss': 0.27521045355799445}
2023-01-04 05:05:12,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:12,639 INFO:     Epoch: 29
2023-01-04 05:05:14,259 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3871416836977005, 'Total loss': 0.3871416836977005} | train loss {'Reaction outcome loss': 0.2700255836737241, 'Total loss': 0.2700255836737241}
2023-01-04 05:05:14,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:14,259 INFO:     Epoch: 30
2023-01-04 05:05:15,846 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3914372056722641, 'Total loss': 0.3914372056722641} | train loss {'Reaction outcome loss': 0.2667625793593301, 'Total loss': 0.2667625793593301}
2023-01-04 05:05:15,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:15,846 INFO:     Epoch: 31
2023-01-04 05:05:17,433 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38488207856814066, 'Total loss': 0.38488207856814066} | train loss {'Reaction outcome loss': 0.2692181746866824, 'Total loss': 0.2692181746866824}
2023-01-04 05:05:17,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:17,433 INFO:     Epoch: 32
2023-01-04 05:05:19,006 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3916701227426529, 'Total loss': 0.3916701227426529} | train loss {'Reaction outcome loss': 0.2688848589806593, 'Total loss': 0.2688848589806593}
2023-01-04 05:05:19,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:19,006 INFO:     Epoch: 33
2023-01-04 05:05:20,594 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38123742043972014, 'Total loss': 0.38123742043972014} | train loss {'Reaction outcome loss': 0.25797743049949623, 'Total loss': 0.25797743049949623}
2023-01-04 05:05:20,595 INFO:     Found new best model at epoch 33
2023-01-04 05:05:20,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:20,596 INFO:     Epoch: 34
2023-01-04 05:05:22,182 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4085420151551565, 'Total loss': 0.4085420151551565} | train loss {'Reaction outcome loss': 0.2569315643505809, 'Total loss': 0.2569315643505809}
2023-01-04 05:05:22,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:22,182 INFO:     Epoch: 35
2023-01-04 05:05:23,767 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40803655982017517, 'Total loss': 0.40803655982017517} | train loss {'Reaction outcome loss': 0.25458243604917835, 'Total loss': 0.25458243604917835}
2023-01-04 05:05:23,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:23,767 INFO:     Epoch: 36
2023-01-04 05:05:25,349 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4037936359643936, 'Total loss': 0.4037936359643936} | train loss {'Reaction outcome loss': 0.24948719899723495, 'Total loss': 0.24948719899723495}
2023-01-04 05:05:25,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:25,349 INFO:     Epoch: 37
2023-01-04 05:05:26,938 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4054650674263636, 'Total loss': 0.4054650674263636} | train loss {'Reaction outcome loss': 0.24856572254625, 'Total loss': 0.24856572254625}
2023-01-04 05:05:26,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:26,938 INFO:     Epoch: 38
2023-01-04 05:05:28,527 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3904886374870936, 'Total loss': 0.3904886374870936} | train loss {'Reaction outcome loss': 0.24431396626860605, 'Total loss': 0.24431396626860605}
2023-01-04 05:05:28,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:28,527 INFO:     Epoch: 39
2023-01-04 05:05:30,125 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39246690074602764, 'Total loss': 0.39246690074602764} | train loss {'Reaction outcome loss': 0.24842824209211528, 'Total loss': 0.24842824209211528}
2023-01-04 05:05:30,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:30,125 INFO:     Epoch: 40
2023-01-04 05:05:31,748 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3908719887336095, 'Total loss': 0.3908719887336095} | train loss {'Reaction outcome loss': 0.2524999606227367, 'Total loss': 0.2524999606227367}
2023-01-04 05:05:31,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:31,748 INFO:     Epoch: 41
2023-01-04 05:05:33,349 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41033374269803363, 'Total loss': 0.41033374269803363} | train loss {'Reaction outcome loss': 0.24063403359141902, 'Total loss': 0.24063403359141902}
2023-01-04 05:05:33,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:33,349 INFO:     Epoch: 42
2023-01-04 05:05:34,972 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38513525823752087, 'Total loss': 0.38513525823752087} | train loss {'Reaction outcome loss': 0.2390111885489086, 'Total loss': 0.2390111885489086}
2023-01-04 05:05:34,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:34,973 INFO:     Epoch: 43
2023-01-04 05:05:36,571 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3897786259651184, 'Total loss': 0.3897786259651184} | train loss {'Reaction outcome loss': 0.234778747569088, 'Total loss': 0.234778747569088}
2023-01-04 05:05:36,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:36,571 INFO:     Epoch: 44
2023-01-04 05:05:38,153 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4041229565938314, 'Total loss': 0.4041229565938314} | train loss {'Reaction outcome loss': 0.2325993471313268, 'Total loss': 0.2325993471313268}
2023-01-04 05:05:38,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:38,153 INFO:     Epoch: 45
2023-01-04 05:05:39,738 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4137132922808329, 'Total loss': 0.4137132922808329} | train loss {'Reaction outcome loss': 0.23234385272919916, 'Total loss': 0.23234385272919916}
2023-01-04 05:05:39,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:39,739 INFO:     Epoch: 46
2023-01-04 05:05:41,347 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40015617410341897, 'Total loss': 0.40015617410341897} | train loss {'Reaction outcome loss': 0.2281402794596152, 'Total loss': 0.2281402794596152}
2023-01-04 05:05:41,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:41,348 INFO:     Epoch: 47
2023-01-04 05:05:42,920 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4284889390071233, 'Total loss': 0.4284889390071233} | train loss {'Reaction outcome loss': 0.2421174119024173, 'Total loss': 0.2421174119024173}
2023-01-04 05:05:42,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:42,921 INFO:     Epoch: 48
2023-01-04 05:05:44,506 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4097553859154383, 'Total loss': 0.4097553859154383} | train loss {'Reaction outcome loss': 0.2537455780809556, 'Total loss': 0.2537455780809556}
2023-01-04 05:05:44,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:44,506 INFO:     Epoch: 49
2023-01-04 05:05:46,088 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41057827124993007, 'Total loss': 0.41057827124993007} | train loss {'Reaction outcome loss': 0.2332079276793461, 'Total loss': 0.2332079276793461}
2023-01-04 05:05:46,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:46,088 INFO:     Epoch: 50
2023-01-04 05:05:47,703 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4116149882475535, 'Total loss': 0.4116149882475535} | train loss {'Reaction outcome loss': 0.22244241974355342, 'Total loss': 0.22244241974355342}
2023-01-04 05:05:47,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:47,703 INFO:     Epoch: 51
2023-01-04 05:05:49,325 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3882185926040014, 'Total loss': 0.3882185926040014} | train loss {'Reaction outcome loss': 0.2208416627423055, 'Total loss': 0.2208416627423055}
2023-01-04 05:05:49,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:49,325 INFO:     Epoch: 52
2023-01-04 05:05:50,931 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4248643676439921, 'Total loss': 0.4248643676439921} | train loss {'Reaction outcome loss': 0.21978325020624884, 'Total loss': 0.21978325020624884}
2023-01-04 05:05:50,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:50,931 INFO:     Epoch: 53
2023-01-04 05:05:52,552 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40758859515190127, 'Total loss': 0.40758859515190127} | train loss {'Reaction outcome loss': 0.21626700328298562, 'Total loss': 0.21626700328298562}
2023-01-04 05:05:52,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:52,552 INFO:     Epoch: 54
2023-01-04 05:05:54,175 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40869684318701427, 'Total loss': 0.40869684318701427} | train loss {'Reaction outcome loss': 0.2183263013923905, 'Total loss': 0.2183263013923905}
2023-01-04 05:05:54,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:54,176 INFO:     Epoch: 55
2023-01-04 05:05:55,779 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4035388241211573, 'Total loss': 0.4035388241211573} | train loss {'Reaction outcome loss': 0.21534311489233296, 'Total loss': 0.21534311489233296}
2023-01-04 05:05:55,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:55,779 INFO:     Epoch: 56
2023-01-04 05:05:57,396 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4262374887863795, 'Total loss': 0.4262374887863795} | train loss {'Reaction outcome loss': 0.21504409895346, 'Total loss': 0.21504409895346}
2023-01-04 05:05:57,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:57,396 INFO:     Epoch: 57
2023-01-04 05:05:59,021 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4058536907037099, 'Total loss': 0.4058536907037099} | train loss {'Reaction outcome loss': 0.21357541523225929, 'Total loss': 0.21357541523225929}
2023-01-04 05:05:59,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:05:59,021 INFO:     Epoch: 58
2023-01-04 05:06:00,608 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4083183397849401, 'Total loss': 0.4083183397849401} | train loss {'Reaction outcome loss': 0.2208687650407597, 'Total loss': 0.2208687650407597}
2023-01-04 05:06:00,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:00,608 INFO:     Epoch: 59
2023-01-04 05:06:02,217 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42153935035069784, 'Total loss': 0.42153935035069784} | train loss {'Reaction outcome loss': 0.20975724758708553, 'Total loss': 0.20975724758708553}
2023-01-04 05:06:02,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:02,217 INFO:     Epoch: 60
2023-01-04 05:06:03,816 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4253971209128698, 'Total loss': 0.4253971209128698} | train loss {'Reaction outcome loss': 0.20865516695261432, 'Total loss': 0.20865516695261432}
2023-01-04 05:06:03,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:03,816 INFO:     Epoch: 61
2023-01-04 05:06:05,433 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4062537391980489, 'Total loss': 0.4062537391980489} | train loss {'Reaction outcome loss': 0.2140296024027402, 'Total loss': 0.2140296024027402}
2023-01-04 05:06:05,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:05,434 INFO:     Epoch: 62
2023-01-04 05:06:07,054 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4029683917760849, 'Total loss': 0.4029683917760849} | train loss {'Reaction outcome loss': 0.20652647228269125, 'Total loss': 0.20652647228269125}
2023-01-04 05:06:07,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:07,054 INFO:     Epoch: 63
2023-01-04 05:06:08,640 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4576438089211782, 'Total loss': 0.4576438089211782} | train loss {'Reaction outcome loss': 0.20639706234299188, 'Total loss': 0.20639706234299188}
2023-01-04 05:06:08,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:08,640 INFO:     Epoch: 64
2023-01-04 05:06:10,211 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4300972799460093, 'Total loss': 0.4300972799460093} | train loss {'Reaction outcome loss': 0.20999864861116155, 'Total loss': 0.20999864861116155}
2023-01-04 05:06:10,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:10,212 INFO:     Epoch: 65
2023-01-04 05:06:11,797 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4342872182528178, 'Total loss': 0.4342872182528178} | train loss {'Reaction outcome loss': 0.2028596987526027, 'Total loss': 0.2028596987526027}
2023-01-04 05:06:11,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:11,798 INFO:     Epoch: 66
2023-01-04 05:06:13,389 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4253634611765544, 'Total loss': 0.4253634611765544} | train loss {'Reaction outcome loss': 0.20225120150638942, 'Total loss': 0.20225120150638942}
2023-01-04 05:06:13,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:13,390 INFO:     Epoch: 67
2023-01-04 05:06:15,018 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4032371699810028, 'Total loss': 0.4032371699810028} | train loss {'Reaction outcome loss': 0.20082607163635988, 'Total loss': 0.20082607163635988}
2023-01-04 05:06:15,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:15,019 INFO:     Epoch: 68
2023-01-04 05:06:16,637 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4118848542372386, 'Total loss': 0.4118848542372386} | train loss {'Reaction outcome loss': 0.20172719217911092, 'Total loss': 0.20172719217911092}
2023-01-04 05:06:16,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:16,637 INFO:     Epoch: 69
2023-01-04 05:06:18,218 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4218351205190023, 'Total loss': 0.4218351205190023} | train loss {'Reaction outcome loss': 0.1986332131985008, 'Total loss': 0.1986332131985008}
2023-01-04 05:06:18,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:18,218 INFO:     Epoch: 70
2023-01-04 05:06:19,812 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4207177678743998, 'Total loss': 0.4207177678743998} | train loss {'Reaction outcome loss': 0.19891899045340825, 'Total loss': 0.19891899045340825}
2023-01-04 05:06:19,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:19,812 INFO:     Epoch: 71
2023-01-04 05:06:21,391 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4375173141558965, 'Total loss': 0.4375173141558965} | train loss {'Reaction outcome loss': 0.1967091818097169, 'Total loss': 0.1967091818097169}
2023-01-04 05:06:21,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:21,391 INFO:     Epoch: 72
2023-01-04 05:06:23,016 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40751151045163475, 'Total loss': 0.40751151045163475} | train loss {'Reaction outcome loss': 0.19694568375562876, 'Total loss': 0.19694568375562876}
2023-01-04 05:06:23,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:23,016 INFO:     Epoch: 73
2023-01-04 05:06:24,643 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41791009704271953, 'Total loss': 0.41791009704271953} | train loss {'Reaction outcome loss': 0.1927822858913029, 'Total loss': 0.1927822858913029}
2023-01-04 05:06:24,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:24,643 INFO:     Epoch: 74
2023-01-04 05:06:26,273 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4251087615887324, 'Total loss': 0.4251087615887324} | train loss {'Reaction outcome loss': 0.19625826262315546, 'Total loss': 0.19625826262315546}
2023-01-04 05:06:26,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:26,273 INFO:     Epoch: 75
2023-01-04 05:06:27,874 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43313798159360883, 'Total loss': 0.43313798159360883} | train loss {'Reaction outcome loss': 0.1983921499165948, 'Total loss': 0.1983921499165948}
2023-01-04 05:06:27,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:27,874 INFO:     Epoch: 76
2023-01-04 05:06:29,497 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.462510492404302, 'Total loss': 0.462510492404302} | train loss {'Reaction outcome loss': 0.19471920069401571, 'Total loss': 0.19471920069401571}
2023-01-04 05:06:29,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:29,498 INFO:     Epoch: 77
2023-01-04 05:06:31,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41694507797559105, 'Total loss': 0.41694507797559105} | train loss {'Reaction outcome loss': 0.19042512117016155, 'Total loss': 0.19042512117016155}
2023-01-04 05:06:31,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:31,089 INFO:     Epoch: 78
2023-01-04 05:06:32,702 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4306304042538007, 'Total loss': 0.4306304042538007} | train loss {'Reaction outcome loss': 0.19242122128886968, 'Total loss': 0.19242122128886968}
2023-01-04 05:06:32,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:32,702 INFO:     Epoch: 79
2023-01-04 05:06:34,310 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4256862610578537, 'Total loss': 0.4256862610578537} | train loss {'Reaction outcome loss': 0.19291730710993643, 'Total loss': 0.19291730710993643}
2023-01-04 05:06:34,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:34,310 INFO:     Epoch: 80
2023-01-04 05:06:35,899 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4325852870941162, 'Total loss': 0.4325852870941162} | train loss {'Reaction outcome loss': 0.19570353791873524, 'Total loss': 0.19570353791873524}
2023-01-04 05:06:35,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:35,899 INFO:     Epoch: 81
2023-01-04 05:06:37,498 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4189145108064016, 'Total loss': 0.4189145108064016} | train loss {'Reaction outcome loss': 0.18848623071107137, 'Total loss': 0.18848623071107137}
2023-01-04 05:06:37,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:37,498 INFO:     Epoch: 82
2023-01-04 05:06:39,098 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42629462480545044, 'Total loss': 0.42629462480545044} | train loss {'Reaction outcome loss': 0.18873610643060892, 'Total loss': 0.18873610643060892}
2023-01-04 05:06:39,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:39,099 INFO:     Epoch: 83
2023-01-04 05:06:40,679 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42308881307641666, 'Total loss': 0.42308881307641666} | train loss {'Reaction outcome loss': 0.18777255137599463, 'Total loss': 0.18777255137599463}
2023-01-04 05:06:40,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:40,680 INFO:     Epoch: 84
2023-01-04 05:06:42,296 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43750682175159455, 'Total loss': 0.43750682175159455} | train loss {'Reaction outcome loss': 0.18783670434714766, 'Total loss': 0.18783670434714766}
2023-01-04 05:06:42,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:42,296 INFO:     Epoch: 85
2023-01-04 05:06:43,881 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4288166801134745, 'Total loss': 0.4288166801134745} | train loss {'Reaction outcome loss': 0.187395575669288, 'Total loss': 0.187395575669288}
2023-01-04 05:06:43,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:43,881 INFO:     Epoch: 86
2023-01-04 05:06:45,486 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42574187914530437, 'Total loss': 0.42574187914530437} | train loss {'Reaction outcome loss': 0.1834472669685003, 'Total loss': 0.1834472669685003}
2023-01-04 05:06:45,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:45,487 INFO:     Epoch: 87
2023-01-04 05:06:47,095 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.432104554772377, 'Total loss': 0.432104554772377} | train loss {'Reaction outcome loss': 0.187450029651054, 'Total loss': 0.187450029651054}
2023-01-04 05:06:47,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:47,096 INFO:     Epoch: 88
2023-01-04 05:06:48,677 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41937674979368844, 'Total loss': 0.41937674979368844} | train loss {'Reaction outcome loss': 0.19362383755092658, 'Total loss': 0.19362383755092658}
2023-01-04 05:06:48,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:48,677 INFO:     Epoch: 89
2023-01-04 05:06:50,277 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.429033899307251, 'Total loss': 0.429033899307251} | train loss {'Reaction outcome loss': 0.185905661085111, 'Total loss': 0.185905661085111}
2023-01-04 05:06:50,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:50,278 INFO:     Epoch: 90
2023-01-04 05:06:51,879 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43037992616494497, 'Total loss': 0.43037992616494497} | train loss {'Reaction outcome loss': 0.18276767299739996, 'Total loss': 0.18276767299739996}
2023-01-04 05:06:51,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:51,879 INFO:     Epoch: 91
2023-01-04 05:06:53,481 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.419842803478241, 'Total loss': 0.419842803478241} | train loss {'Reaction outcome loss': 0.1847567550493809, 'Total loss': 0.1847567550493809}
2023-01-04 05:06:53,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:53,482 INFO:     Epoch: 92
2023-01-04 05:06:55,096 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41642031669616697, 'Total loss': 0.41642031669616697} | train loss {'Reaction outcome loss': 0.18205518649161948, 'Total loss': 0.18205518649161948}
2023-01-04 05:06:55,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:55,096 INFO:     Epoch: 93
2023-01-04 05:06:56,717 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4324605980267127, 'Total loss': 0.4324605980267127} | train loss {'Reaction outcome loss': 0.180154621674497, 'Total loss': 0.180154621674497}
2023-01-04 05:06:56,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:56,717 INFO:     Epoch: 94
2023-01-04 05:06:58,289 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43278710742791493, 'Total loss': 0.43278710742791493} | train loss {'Reaction outcome loss': 0.17911156520189042, 'Total loss': 0.17911156520189042}
2023-01-04 05:06:58,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:58,289 INFO:     Epoch: 95
2023-01-04 05:06:59,891 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4396297911802928, 'Total loss': 0.4396297911802928} | train loss {'Reaction outcome loss': 0.17947604346061227, 'Total loss': 0.17947604346061227}
2023-01-04 05:06:59,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:06:59,892 INFO:     Epoch: 96
2023-01-04 05:07:01,494 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44072607855002083, 'Total loss': 0.44072607855002083} | train loss {'Reaction outcome loss': 0.17865570702048464, 'Total loss': 0.17865570702048464}
2023-01-04 05:07:01,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:01,495 INFO:     Epoch: 97
2023-01-04 05:07:03,078 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4247207261621952, 'Total loss': 0.4247207261621952} | train loss {'Reaction outcome loss': 0.17723523391377702, 'Total loss': 0.17723523391377702}
2023-01-04 05:07:03,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:03,079 INFO:     Epoch: 98
2023-01-04 05:07:04,681 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45776330928007763, 'Total loss': 0.45776330928007763} | train loss {'Reaction outcome loss': 0.1802001808942093, 'Total loss': 0.1802001808942093}
2023-01-04 05:07:04,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:04,682 INFO:     Epoch: 99
2023-01-04 05:07:06,274 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4271625538667043, 'Total loss': 0.4271625538667043} | train loss {'Reaction outcome loss': 0.17980290161769674, 'Total loss': 0.17980290161769674}
2023-01-04 05:07:06,274 INFO:     Best model found after epoch 34 of 100.
2023-01-04 05:07:06,274 INFO:   Done with stage: TRAINING
2023-01-04 05:07:06,274 INFO:   Starting stage: EVALUATION
2023-01-04 05:07:06,401 INFO:   Done with stage: EVALUATION
2023-01-04 05:07:06,401 INFO:   Leaving out SEQ value Fold_9
2023-01-04 05:07:06,413 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:07:06,413 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:07:07,056 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:07:07,056 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:07:07,123 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:07:07,123 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:07:07,123 INFO:     No hyperparam tuning for this model
2023-01-04 05:07:07,123 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:07:07,123 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:07:07,124 INFO:     None feature selector for col prot
2023-01-04 05:07:07,124 INFO:     None feature selector for col prot
2023-01-04 05:07:07,124 INFO:     None feature selector for col prot
2023-01-04 05:07:07,125 INFO:     None feature selector for col chem
2023-01-04 05:07:07,125 INFO:     None feature selector for col chem
2023-01-04 05:07:07,125 INFO:     None feature selector for col chem
2023-01-04 05:07:07,125 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:07:07,125 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:07:07,126 INFO:     Number of params in model 70141
2023-01-04 05:07:07,129 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:07:07,129 INFO:   Starting stage: TRAINING
2023-01-04 05:07:07,172 INFO:     Val loss before train {'Reaction outcome loss': 0.9815519909063976, 'Total loss': 0.9815519909063976}
2023-01-04 05:07:07,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:07,173 INFO:     Epoch: 0
2023-01-04 05:07:08,823 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7189414183298747, 'Total loss': 0.7189414183298747} | train loss {'Reaction outcome loss': 0.8606398084103416, 'Total loss': 0.8606398084103416}
2023-01-04 05:07:08,823 INFO:     Found new best model at epoch 0
2023-01-04 05:07:08,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:08,824 INFO:     Epoch: 1
2023-01-04 05:07:10,469 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.565691594282786, 'Total loss': 0.565691594282786} | train loss {'Reaction outcome loss': 0.6173436574449608, 'Total loss': 0.6173436574449608}
2023-01-04 05:07:10,470 INFO:     Found new best model at epoch 1
2023-01-04 05:07:10,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:10,470 INFO:     Epoch: 2
2023-01-04 05:07:12,063 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5345054626464844, 'Total loss': 0.5345054626464844} | train loss {'Reaction outcome loss': 0.5226532406432534, 'Total loss': 0.5226532406432534}
2023-01-04 05:07:12,064 INFO:     Found new best model at epoch 2
2023-01-04 05:07:12,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:12,065 INFO:     Epoch: 3
2023-01-04 05:07:13,671 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49401536186536155, 'Total loss': 0.49401536186536155} | train loss {'Reaction outcome loss': 0.4827148685171286, 'Total loss': 0.4827148685171286}
2023-01-04 05:07:13,671 INFO:     Found new best model at epoch 3
2023-01-04 05:07:13,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:13,672 INFO:     Epoch: 4
2023-01-04 05:07:15,261 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4812858422597249, 'Total loss': 0.4812858422597249} | train loss {'Reaction outcome loss': 0.4556315363206588, 'Total loss': 0.4556315363206588}
2023-01-04 05:07:15,261 INFO:     Found new best model at epoch 4
2023-01-04 05:07:15,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:15,262 INFO:     Epoch: 5
2023-01-04 05:07:16,868 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.472841947277387, 'Total loss': 0.472841947277387} | train loss {'Reaction outcome loss': 0.4369065067613168, 'Total loss': 0.4369065067613168}
2023-01-04 05:07:16,868 INFO:     Found new best model at epoch 5
2023-01-04 05:07:16,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:16,869 INFO:     Epoch: 6
2023-01-04 05:07:18,475 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45952750245730084, 'Total loss': 0.45952750245730084} | train loss {'Reaction outcome loss': 0.420024560515631, 'Total loss': 0.420024560515631}
2023-01-04 05:07:18,476 INFO:     Found new best model at epoch 6
2023-01-04 05:07:18,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:18,477 INFO:     Epoch: 7
2023-01-04 05:07:20,082 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4601774056752523, 'Total loss': 0.4601774056752523} | train loss {'Reaction outcome loss': 0.40732352978916375, 'Total loss': 0.40732352978916375}
2023-01-04 05:07:20,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:20,083 INFO:     Epoch: 8
2023-01-04 05:07:21,674 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.442059201002121, 'Total loss': 0.442059201002121} | train loss {'Reaction outcome loss': 0.3953023875394453, 'Total loss': 0.3953023875394453}
2023-01-04 05:07:21,674 INFO:     Found new best model at epoch 8
2023-01-04 05:07:21,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:21,675 INFO:     Epoch: 9
2023-01-04 05:07:23,282 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4475589176019033, 'Total loss': 0.4475589176019033} | train loss {'Reaction outcome loss': 0.3844493285951201, 'Total loss': 0.3844493285951201}
2023-01-04 05:07:23,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:23,282 INFO:     Epoch: 10
2023-01-04 05:07:24,868 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45155152479807537, 'Total loss': 0.45155152479807537} | train loss {'Reaction outcome loss': 0.3768531241141502, 'Total loss': 0.3768531241141502}
2023-01-04 05:07:24,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:24,868 INFO:     Epoch: 11
2023-01-04 05:07:26,476 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.445011830329895, 'Total loss': 0.445011830329895} | train loss {'Reaction outcome loss': 0.3698576844502442, 'Total loss': 0.3698576844502442}
2023-01-04 05:07:26,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:26,476 INFO:     Epoch: 12
2023-01-04 05:07:28,084 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45540540516376493, 'Total loss': 0.45540540516376493} | train loss {'Reaction outcome loss': 0.3605711268335043, 'Total loss': 0.3605711268335043}
2023-01-04 05:07:28,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:28,084 INFO:     Epoch: 13
2023-01-04 05:07:29,680 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4283148288726807, 'Total loss': 0.4283148288726807} | train loss {'Reaction outcome loss': 0.35449925667542415, 'Total loss': 0.35449925667542415}
2023-01-04 05:07:29,680 INFO:     Found new best model at epoch 13
2023-01-04 05:07:29,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:29,681 INFO:     Epoch: 14
2023-01-04 05:07:31,294 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4209172040224075, 'Total loss': 0.4209172040224075} | train loss {'Reaction outcome loss': 0.34560193379648324, 'Total loss': 0.34560193379648324}
2023-01-04 05:07:31,295 INFO:     Found new best model at epoch 14
2023-01-04 05:07:31,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:31,296 INFO:     Epoch: 15
2023-01-04 05:07:32,888 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42007105400164924, 'Total loss': 0.42007105400164924} | train loss {'Reaction outcome loss': 0.3374402664790085, 'Total loss': 0.3374402664790085}
2023-01-04 05:07:32,888 INFO:     Found new best model at epoch 15
2023-01-04 05:07:32,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:32,889 INFO:     Epoch: 16
2023-01-04 05:07:34,489 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41946940620740253, 'Total loss': 0.41946940620740253} | train loss {'Reaction outcome loss': 0.33409120190875197, 'Total loss': 0.33409120190875197}
2023-01-04 05:07:34,490 INFO:     Found new best model at epoch 16
2023-01-04 05:07:34,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:34,490 INFO:     Epoch: 17
2023-01-04 05:07:36,111 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42971064150333405, 'Total loss': 0.42971064150333405} | train loss {'Reaction outcome loss': 0.32739396710688456, 'Total loss': 0.32739396710688456}
2023-01-04 05:07:36,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:36,112 INFO:     Epoch: 18
2023-01-04 05:07:37,739 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43879184226195017, 'Total loss': 0.43879184226195017} | train loss {'Reaction outcome loss': 0.32303297664929814, 'Total loss': 0.32303297664929814}
2023-01-04 05:07:37,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:37,740 INFO:     Epoch: 19
2023-01-04 05:07:39,324 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4296246627966563, 'Total loss': 0.4296246627966563} | train loss {'Reaction outcome loss': 0.3175384071168056, 'Total loss': 0.3175384071168056}
2023-01-04 05:07:39,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:39,324 INFO:     Epoch: 20
2023-01-04 05:07:40,950 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4141225834687551, 'Total loss': 0.4141225834687551} | train loss {'Reaction outcome loss': 0.3100253435302297, 'Total loss': 0.3100253435302297}
2023-01-04 05:07:40,951 INFO:     Found new best model at epoch 20
2023-01-04 05:07:40,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:40,951 INFO:     Epoch: 21
2023-01-04 05:07:42,538 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4318308522303899, 'Total loss': 0.4318308522303899} | train loss {'Reaction outcome loss': 0.30871434437131196, 'Total loss': 0.30871434437131196}
2023-01-04 05:07:42,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:42,539 INFO:     Epoch: 22
2023-01-04 05:07:44,128 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41572645405928293, 'Total loss': 0.41572645405928293} | train loss {'Reaction outcome loss': 0.30059573460464445, 'Total loss': 0.30059573460464445}
2023-01-04 05:07:44,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:44,128 INFO:     Epoch: 23
2023-01-04 05:07:45,756 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4157738834619522, 'Total loss': 0.4157738834619522} | train loss {'Reaction outcome loss': 0.29419730896876606, 'Total loss': 0.29419730896876606}
2023-01-04 05:07:45,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:45,756 INFO:     Epoch: 24
2023-01-04 05:07:47,362 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4081605613231659, 'Total loss': 0.4081605613231659} | train loss {'Reaction outcome loss': 0.29241714731450547, 'Total loss': 0.29241714731450547}
2023-01-04 05:07:47,362 INFO:     Found new best model at epoch 24
2023-01-04 05:07:47,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:47,363 INFO:     Epoch: 25
2023-01-04 05:07:48,961 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4150583972533544, 'Total loss': 0.4150583972533544} | train loss {'Reaction outcome loss': 0.28805567991217124, 'Total loss': 0.28805567991217124}
2023-01-04 05:07:48,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:48,962 INFO:     Epoch: 26
2023-01-04 05:07:50,597 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4101505935192108, 'Total loss': 0.4101505935192108} | train loss {'Reaction outcome loss': 0.28224865465495563, 'Total loss': 0.28224865465495563}
2023-01-04 05:07:50,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:50,598 INFO:     Epoch: 27
2023-01-04 05:07:52,206 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4210429658492406, 'Total loss': 0.4210429658492406} | train loss {'Reaction outcome loss': 0.2811563635776189, 'Total loss': 0.2811563635776189}
2023-01-04 05:07:52,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:52,207 INFO:     Epoch: 28
2023-01-04 05:07:53,842 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4212914248307546, 'Total loss': 0.4212914248307546} | train loss {'Reaction outcome loss': 0.27563928276139044, 'Total loss': 0.27563928276139044}
2023-01-04 05:07:53,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:53,842 INFO:     Epoch: 29
2023-01-04 05:07:55,476 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4218162178993225, 'Total loss': 0.4218162178993225} | train loss {'Reaction outcome loss': 0.2725931144309388, 'Total loss': 0.2725931144309388}
2023-01-04 05:07:55,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:55,476 INFO:     Epoch: 30
2023-01-04 05:07:57,084 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4326902727286021, 'Total loss': 0.4326902727286021} | train loss {'Reaction outcome loss': 0.2680722823911195, 'Total loss': 0.2680722823911195}
2023-01-04 05:07:57,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:57,084 INFO:     Epoch: 31
2023-01-04 05:07:58,695 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40904246767361957, 'Total loss': 0.40904246767361957} | train loss {'Reaction outcome loss': 0.26672005139640953, 'Total loss': 0.26672005139640953}
2023-01-04 05:07:58,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:07:58,695 INFO:     Epoch: 32
2023-01-04 05:08:00,286 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4265627781550089, 'Total loss': 0.4265627781550089} | train loss {'Reaction outcome loss': 0.263482851430182, 'Total loss': 0.263482851430182}
2023-01-04 05:08:00,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:00,286 INFO:     Epoch: 33
2023-01-04 05:08:01,898 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4225124334295591, 'Total loss': 0.4225124334295591} | train loss {'Reaction outcome loss': 0.26084556200605435, 'Total loss': 0.26084556200605435}
2023-01-04 05:08:01,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:01,899 INFO:     Epoch: 34
2023-01-04 05:08:03,509 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4130557656288147, 'Total loss': 0.4130557656288147} | train loss {'Reaction outcome loss': 0.25647935701621566, 'Total loss': 0.25647935701621566}
2023-01-04 05:08:03,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:03,509 INFO:     Epoch: 35
2023-01-04 05:08:05,118 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41507470806439717, 'Total loss': 0.41507470806439717} | train loss {'Reaction outcome loss': 0.2531748424529599, 'Total loss': 0.2531748424529599}
2023-01-04 05:08:05,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:05,119 INFO:     Epoch: 36
2023-01-04 05:08:06,691 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.415077601869901, 'Total loss': 0.415077601869901} | train loss {'Reaction outcome loss': 0.2503723416894352, 'Total loss': 0.2503723416894352}
2023-01-04 05:08:06,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:06,691 INFO:     Epoch: 37
2023-01-04 05:08:08,320 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4096938639879227, 'Total loss': 0.4096938639879227} | train loss {'Reaction outcome loss': 0.24959473435629145, 'Total loss': 0.24959473435629145}
2023-01-04 05:08:08,321 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:08,321 INFO:     Epoch: 38
2023-01-04 05:08:09,916 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4229543844858805, 'Total loss': 0.4229543844858805} | train loss {'Reaction outcome loss': 0.24449486409176127, 'Total loss': 0.24449486409176127}
2023-01-04 05:08:09,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:09,917 INFO:     Epoch: 39
2023-01-04 05:08:11,529 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41784817576408384, 'Total loss': 0.41784817576408384} | train loss {'Reaction outcome loss': 0.24330445904190576, 'Total loss': 0.24330445904190576}
2023-01-04 05:08:11,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:11,530 INFO:     Epoch: 40
2023-01-04 05:08:13,143 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42778834104537966, 'Total loss': 0.42778834104537966} | train loss {'Reaction outcome loss': 0.2409840647521217, 'Total loss': 0.2409840647521217}
2023-01-04 05:08:13,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:13,144 INFO:     Epoch: 41
2023-01-04 05:08:14,735 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4336200644572576, 'Total loss': 0.4336200644572576} | train loss {'Reaction outcome loss': 0.2394634309335736, 'Total loss': 0.2394634309335736}
2023-01-04 05:08:14,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:14,735 INFO:     Epoch: 42
2023-01-04 05:08:16,351 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43882414102554324, 'Total loss': 0.43882414102554324} | train loss {'Reaction outcome loss': 0.2361604898145913, 'Total loss': 0.2361604898145913}
2023-01-04 05:08:16,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:16,351 INFO:     Epoch: 43
2023-01-04 05:08:17,948 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4392812252044678, 'Total loss': 0.4392812252044678} | train loss {'Reaction outcome loss': 0.234621006793709, 'Total loss': 0.234621006793709}
2023-01-04 05:08:17,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:17,948 INFO:     Epoch: 44
2023-01-04 05:08:19,577 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43025698934992157, 'Total loss': 0.43025698934992157} | train loss {'Reaction outcome loss': 0.23223830634452375, 'Total loss': 0.23223830634452375}
2023-01-04 05:08:19,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:19,577 INFO:     Epoch: 45
2023-01-04 05:08:21,195 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42945571839809416, 'Total loss': 0.42945571839809416} | train loss {'Reaction outcome loss': 0.23068268474742823, 'Total loss': 0.23068268474742823}
2023-01-04 05:08:21,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:21,195 INFO:     Epoch: 46
2023-01-04 05:08:22,819 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44666462937990825, 'Total loss': 0.44666462937990825} | train loss {'Reaction outcome loss': 0.2292995187000032, 'Total loss': 0.2292995187000032}
2023-01-04 05:08:22,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:22,819 INFO:     Epoch: 47
2023-01-04 05:08:24,413 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4320537914832433, 'Total loss': 0.4320537914832433} | train loss {'Reaction outcome loss': 0.22672321394570039, 'Total loss': 0.22672321394570039}
2023-01-04 05:08:24,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:24,413 INFO:     Epoch: 48
2023-01-04 05:08:26,020 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43959364493687947, 'Total loss': 0.43959364493687947} | train loss {'Reaction outcome loss': 0.22458020764460201, 'Total loss': 0.22458020764460201}
2023-01-04 05:08:26,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:26,020 INFO:     Epoch: 49
2023-01-04 05:08:27,609 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44979179203510283, 'Total loss': 0.44979179203510283} | train loss {'Reaction outcome loss': 0.22231445008290374, 'Total loss': 0.22231445008290374}
2023-01-04 05:08:27,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:27,609 INFO:     Epoch: 50
2023-01-04 05:08:29,216 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4359581768512726, 'Total loss': 0.4359581768512726} | train loss {'Reaction outcome loss': 0.223009734780995, 'Total loss': 0.223009734780995}
2023-01-04 05:08:29,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:29,216 INFO:     Epoch: 51
2023-01-04 05:08:30,825 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47676602800687157, 'Total loss': 0.47676602800687157} | train loss {'Reaction outcome loss': 0.22120495794159412, 'Total loss': 0.22120495794159412}
2023-01-04 05:08:30,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:30,826 INFO:     Epoch: 52
2023-01-04 05:08:32,417 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44292255441347755, 'Total loss': 0.44292255441347755} | train loss {'Reaction outcome loss': 0.21971389836218166, 'Total loss': 0.21971389836218166}
2023-01-04 05:08:32,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:32,418 INFO:     Epoch: 53
2023-01-04 05:08:34,026 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43118602434794107, 'Total loss': 0.43118602434794107} | train loss {'Reaction outcome loss': 0.21566933039777544, 'Total loss': 0.21566933039777544}
2023-01-04 05:08:34,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:34,026 INFO:     Epoch: 54
2023-01-04 05:08:35,636 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45555482506752015, 'Total loss': 0.45555482506752015} | train loss {'Reaction outcome loss': 0.21468215946793986, 'Total loss': 0.21468215946793986}
2023-01-04 05:08:35,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:35,636 INFO:     Epoch: 55
2023-01-04 05:08:37,248 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43578601678212486, 'Total loss': 0.43578601678212486} | train loss {'Reaction outcome loss': 0.2109087249163256, 'Total loss': 0.2109087249163256}
2023-01-04 05:08:37,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:37,248 INFO:     Epoch: 56
2023-01-04 05:08:38,881 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46188155909379325, 'Total loss': 0.46188155909379325} | train loss {'Reaction outcome loss': 0.21317906349574617, 'Total loss': 0.21317906349574617}
2023-01-04 05:08:38,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:38,881 INFO:     Epoch: 57
2023-01-04 05:08:40,506 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46099719901879627, 'Total loss': 0.46099719901879627} | train loss {'Reaction outcome loss': 0.21073332012022444, 'Total loss': 0.21073332012022444}
2023-01-04 05:08:40,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:40,506 INFO:     Epoch: 58
2023-01-04 05:08:42,105 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4357105533281962, 'Total loss': 0.4357105533281962} | train loss {'Reaction outcome loss': 0.21154986888116448, 'Total loss': 0.21154986888116448}
2023-01-04 05:08:42,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:42,105 INFO:     Epoch: 59
2023-01-04 05:08:43,715 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4626345098018646, 'Total loss': 0.4626345098018646} | train loss {'Reaction outcome loss': 0.2078874222396298, 'Total loss': 0.2078874222396298}
2023-01-04 05:08:43,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:43,717 INFO:     Epoch: 60
2023-01-04 05:08:45,310 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46334996322790784, 'Total loss': 0.46334996322790784} | train loss {'Reaction outcome loss': 0.20727578194186574, 'Total loss': 0.20727578194186574}
2023-01-04 05:08:45,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:45,310 INFO:     Epoch: 61
2023-01-04 05:08:46,945 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44352245777845384, 'Total loss': 0.44352245777845384} | train loss {'Reaction outcome loss': 0.2050625750667244, 'Total loss': 0.2050625750667244}
2023-01-04 05:08:46,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:46,945 INFO:     Epoch: 62
2023-01-04 05:08:48,563 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47089526454607644, 'Total loss': 0.47089526454607644} | train loss {'Reaction outcome loss': 0.2028394800876452, 'Total loss': 0.2028394800876452}
2023-01-04 05:08:48,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:48,563 INFO:     Epoch: 63
2023-01-04 05:08:50,196 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4618516614039739, 'Total loss': 0.4618516614039739} | train loss {'Reaction outcome loss': 0.20326248119292706, 'Total loss': 0.20326248119292706}
2023-01-04 05:08:50,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:50,197 INFO:     Epoch: 64
2023-01-04 05:08:51,795 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4643954515457153, 'Total loss': 0.4643954515457153} | train loss {'Reaction outcome loss': 0.20184794364880354, 'Total loss': 0.20184794364880354}
2023-01-04 05:08:51,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:51,795 INFO:     Epoch: 65
2023-01-04 05:08:53,406 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4581568022569021, 'Total loss': 0.4581568022569021} | train loss {'Reaction outcome loss': 0.19893483567431516, 'Total loss': 0.19893483567431516}
2023-01-04 05:08:53,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:53,406 INFO:     Epoch: 66
2023-01-04 05:08:55,016 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4404841889937719, 'Total loss': 0.4404841889937719} | train loss {'Reaction outcome loss': 0.19927628273783177, 'Total loss': 0.19927628273783177}
2023-01-04 05:08:55,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:55,016 INFO:     Epoch: 67
2023-01-04 05:08:56,653 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4788425912459691, 'Total loss': 0.4788425912459691} | train loss {'Reaction outcome loss': 0.19962298899673814, 'Total loss': 0.19962298899673814}
2023-01-04 05:08:56,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:56,653 INFO:     Epoch: 68
2023-01-04 05:08:58,282 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4581189195315043, 'Total loss': 0.4581189195315043} | train loss {'Reaction outcome loss': 0.1968198739772239, 'Total loss': 0.1968198739772239}
2023-01-04 05:08:58,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:58,282 INFO:     Epoch: 69
2023-01-04 05:08:59,893 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47264432509740195, 'Total loss': 0.47264432509740195} | train loss {'Reaction outcome loss': 0.1954262141904891, 'Total loss': 0.1954262141904891}
2023-01-04 05:08:59,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:08:59,893 INFO:     Epoch: 70
2023-01-04 05:09:01,523 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4597170650959015, 'Total loss': 0.4597170650959015} | train loss {'Reaction outcome loss': 0.19328506396484935, 'Total loss': 0.19328506396484935}
2023-01-04 05:09:01,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:01,524 INFO:     Epoch: 71
2023-01-04 05:09:03,114 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4579336961110433, 'Total loss': 0.4579336961110433} | train loss {'Reaction outcome loss': 0.19292412296825154, 'Total loss': 0.19292412296825154}
2023-01-04 05:09:03,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:03,115 INFO:     Epoch: 72
2023-01-04 05:09:04,709 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4884754608074824, 'Total loss': 0.4884754608074824} | train loss {'Reaction outcome loss': 0.19014373704091736, 'Total loss': 0.19014373704091736}
2023-01-04 05:09:04,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:04,709 INFO:     Epoch: 73
2023-01-04 05:09:06,343 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46312814156214394, 'Total loss': 0.46312814156214394} | train loss {'Reaction outcome loss': 0.19197731650693323, 'Total loss': 0.19197731650693323}
2023-01-04 05:09:06,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:06,343 INFO:     Epoch: 74
2023-01-04 05:09:07,966 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4772162770231565, 'Total loss': 0.4772162770231565} | train loss {'Reaction outcome loss': 0.1927585419307762, 'Total loss': 0.1927585419307762}
2023-01-04 05:09:07,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:07,966 INFO:     Epoch: 75
2023-01-04 05:09:09,579 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4667410612106323, 'Total loss': 0.4667410612106323} | train loss {'Reaction outcome loss': 0.19015638550427416, 'Total loss': 0.19015638550427416}
2023-01-04 05:09:09,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:09,579 INFO:     Epoch: 76
2023-01-04 05:09:11,207 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4580787549416224, 'Total loss': 0.4580787549416224} | train loss {'Reaction outcome loss': 0.1863162905509022, 'Total loss': 0.1863162905509022}
2023-01-04 05:09:11,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:11,207 INFO:     Epoch: 77
2023-01-04 05:09:12,814 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4689213901758194, 'Total loss': 0.4689213901758194} | train loss {'Reaction outcome loss': 0.18826413315986468, 'Total loss': 0.18826413315986468}
2023-01-04 05:09:12,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:12,814 INFO:     Epoch: 78
2023-01-04 05:09:14,430 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4797552655140559, 'Total loss': 0.4797552655140559} | train loss {'Reaction outcome loss': 0.18789860236354253, 'Total loss': 0.18789860236354253}
2023-01-04 05:09:14,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:14,431 INFO:     Epoch: 79
2023-01-04 05:09:16,036 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4628512312968572, 'Total loss': 0.4628512312968572} | train loss {'Reaction outcome loss': 0.18747108754456474, 'Total loss': 0.18747108754456474}
2023-01-04 05:09:16,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:16,037 INFO:     Epoch: 80
2023-01-04 05:09:17,629 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46980651915073396, 'Total loss': 0.46980651915073396} | train loss {'Reaction outcome loss': 0.18871561090868733, 'Total loss': 0.18871561090868733}
2023-01-04 05:09:17,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:17,630 INFO:     Epoch: 81
2023-01-04 05:09:19,239 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4819828122854233, 'Total loss': 0.4819828122854233} | train loss {'Reaction outcome loss': 0.18716370249805897, 'Total loss': 0.18716370249805897}
2023-01-04 05:09:19,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:19,240 INFO:     Epoch: 82
2023-01-04 05:09:20,842 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4754658261934916, 'Total loss': 0.4754658261934916} | train loss {'Reaction outcome loss': 0.18320972952547918, 'Total loss': 0.18320972952547918}
2023-01-04 05:09:20,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:20,843 INFO:     Epoch: 83
2023-01-04 05:09:22,441 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49768983423709867, 'Total loss': 0.49768983423709867} | train loss {'Reaction outcome loss': 0.18289875551816143, 'Total loss': 0.18289875551816143}
2023-01-04 05:09:22,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:22,441 INFO:     Epoch: 84
2023-01-04 05:09:24,052 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46591241558392843, 'Total loss': 0.46591241558392843} | train loss {'Reaction outcome loss': 0.1848704275483474, 'Total loss': 0.1848704275483474}
2023-01-04 05:09:24,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:24,052 INFO:     Epoch: 85
2023-01-04 05:09:25,662 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5095699369907379, 'Total loss': 0.5095699369907379} | train loss {'Reaction outcome loss': 0.18226042420801702, 'Total loss': 0.18226042420801702}
2023-01-04 05:09:25,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:25,662 INFO:     Epoch: 86
2023-01-04 05:09:27,250 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4794298549493154, 'Total loss': 0.4794298549493154} | train loss {'Reaction outcome loss': 0.18295440322548043, 'Total loss': 0.18295440322548043}
2023-01-04 05:09:27,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:27,250 INFO:     Epoch: 87
2023-01-04 05:09:28,898 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4916253358125687, 'Total loss': 0.4916253358125687} | train loss {'Reaction outcome loss': 0.18044151531176017, 'Total loss': 0.18044151531176017}
2023-01-04 05:09:28,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:28,898 INFO:     Epoch: 88
2023-01-04 05:09:30,503 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4927537480990092, 'Total loss': 0.4927537480990092} | train loss {'Reaction outcome loss': 0.18057900831937143, 'Total loss': 0.18057900831937143}
2023-01-04 05:09:30,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:30,504 INFO:     Epoch: 89
2023-01-04 05:09:32,115 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4723956694205602, 'Total loss': 0.4723956694205602} | train loss {'Reaction outcome loss': 0.18281567207661992, 'Total loss': 0.18281567207661992}
2023-01-04 05:09:32,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:32,115 INFO:     Epoch: 90
2023-01-04 05:09:33,725 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4902486781279246, 'Total loss': 0.4902486781279246} | train loss {'Reaction outcome loss': 0.18003978779277216, 'Total loss': 0.18003978779277216}
2023-01-04 05:09:33,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:33,725 INFO:     Epoch: 91
2023-01-04 05:09:35,317 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48468082944552104, 'Total loss': 0.48468082944552104} | train loss {'Reaction outcome loss': 0.17991965656111603, 'Total loss': 0.17991965656111603}
2023-01-04 05:09:35,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:35,317 INFO:     Epoch: 92
2023-01-04 05:09:36,899 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5198628942171732, 'Total loss': 0.5198628942171732} | train loss {'Reaction outcome loss': 0.17770130237033221, 'Total loss': 0.17770130237033221}
2023-01-04 05:09:36,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:36,899 INFO:     Epoch: 93
2023-01-04 05:09:38,529 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4842446287473043, 'Total loss': 0.4842446287473043} | train loss {'Reaction outcome loss': 0.17755295759880585, 'Total loss': 0.17755295759880585}
2023-01-04 05:09:38,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:38,529 INFO:     Epoch: 94
2023-01-04 05:09:40,120 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5005421191453934, 'Total loss': 0.5005421191453934} | train loss {'Reaction outcome loss': 0.1776544266793917, 'Total loss': 0.1776544266793917}
2023-01-04 05:09:40,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:40,120 INFO:     Epoch: 95
2023-01-04 05:09:41,728 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.469343172510465, 'Total loss': 0.469343172510465} | train loss {'Reaction outcome loss': 0.17675490048629927, 'Total loss': 0.17675490048629927}
2023-01-04 05:09:41,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:41,728 INFO:     Epoch: 96
2023-01-04 05:09:43,334 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4858275165160497, 'Total loss': 0.4858275165160497} | train loss {'Reaction outcome loss': 0.17461484340473418, 'Total loss': 0.17461484340473418}
2023-01-04 05:09:43,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:43,335 INFO:     Epoch: 97
2023-01-04 05:09:44,931 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49411290387312573, 'Total loss': 0.49411290387312573} | train loss {'Reaction outcome loss': 0.17394259588839991, 'Total loss': 0.17394259588839991}
2023-01-04 05:09:44,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:44,932 INFO:     Epoch: 98
2023-01-04 05:09:46,527 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4937940468390783, 'Total loss': 0.4937940468390783} | train loss {'Reaction outcome loss': 0.1758286555227067, 'Total loss': 0.1758286555227067}
2023-01-04 05:09:46,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:46,528 INFO:     Epoch: 99
2023-01-04 05:09:48,137 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5077575842539469, 'Total loss': 0.5077575842539469} | train loss {'Reaction outcome loss': 0.17446220389799305, 'Total loss': 0.17446220389799305}
2023-01-04 05:09:48,138 INFO:     Best model found after epoch 25 of 100.
2023-01-04 05:09:48,138 INFO:   Done with stage: TRAINING
2023-01-04 05:09:48,138 INFO:   Starting stage: EVALUATION
2023-01-04 05:09:48,260 INFO:   Done with stage: EVALUATION
2023-01-04 05:09:48,268 INFO:   Leaving out SEQ value Fold_0
2023-01-04 05:09:48,281 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:09:48,281 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:09:48,924 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:09:48,924 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:09:48,990 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:09:48,990 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:09:48,990 INFO:     No hyperparam tuning for this model
2023-01-04 05:09:48,990 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:09:48,990 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:09:48,991 INFO:     None feature selector for col prot
2023-01-04 05:09:48,991 INFO:     None feature selector for col prot
2023-01-04 05:09:48,991 INFO:     None feature selector for col prot
2023-01-04 05:09:48,992 INFO:     None feature selector for col chem
2023-01-04 05:09:48,992 INFO:     None feature selector for col chem
2023-01-04 05:09:48,992 INFO:     None feature selector for col chem
2023-01-04 05:09:48,992 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:09:48,992 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:09:48,993 INFO:     Number of params in model 70141
2023-01-04 05:09:48,996 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:09:48,996 INFO:   Starting stage: TRAINING
2023-01-04 05:09:49,039 INFO:     Val loss before train {'Reaction outcome loss': 0.9463249206542969, 'Total loss': 0.9463249206542969}
2023-01-04 05:09:49,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:49,040 INFO:     Epoch: 0
2023-01-04 05:09:50,674 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6917701522509258, 'Total loss': 0.6917701522509258} | train loss {'Reaction outcome loss': 0.8598259692286998, 'Total loss': 0.8598259692286998}
2023-01-04 05:09:50,674 INFO:     Found new best model at epoch 0
2023-01-04 05:09:50,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:50,675 INFO:     Epoch: 1
2023-01-04 05:09:52,290 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5756065249443054, 'Total loss': 0.5756065249443054} | train loss {'Reaction outcome loss': 0.6086201221088244, 'Total loss': 0.6086201221088244}
2023-01-04 05:09:52,290 INFO:     Found new best model at epoch 1
2023-01-04 05:09:52,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:52,291 INFO:     Epoch: 2
2023-01-04 05:09:53,881 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5567795296510061, 'Total loss': 0.5567795296510061} | train loss {'Reaction outcome loss': 0.5287976556902995, 'Total loss': 0.5287976556902995}
2023-01-04 05:09:53,881 INFO:     Found new best model at epoch 2
2023-01-04 05:09:53,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:53,882 INFO:     Epoch: 3
2023-01-04 05:09:55,496 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5318560173114141, 'Total loss': 0.5318560173114141} | train loss {'Reaction outcome loss': 0.4845904783629205, 'Total loss': 0.4845904783629205}
2023-01-04 05:09:55,496 INFO:     Found new best model at epoch 3
2023-01-04 05:09:55,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:55,497 INFO:     Epoch: 4
2023-01-04 05:09:56,905 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.508433981736501, 'Total loss': 0.508433981736501} | train loss {'Reaction outcome loss': 0.45371074752672913, 'Total loss': 0.45371074752672913}
2023-01-04 05:09:56,905 INFO:     Found new best model at epoch 4
2023-01-04 05:09:56,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:56,906 INFO:     Epoch: 5
2023-01-04 05:09:57,973 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49514559110005696, 'Total loss': 0.49514559110005696} | train loss {'Reaction outcome loss': 0.45284412504322286, 'Total loss': 0.45284412504322286}
2023-01-04 05:09:57,973 INFO:     Found new best model at epoch 5
2023-01-04 05:09:57,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:57,974 INFO:     Epoch: 6
2023-01-04 05:09:59,035 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49844273626804353, 'Total loss': 0.49844273626804353} | train loss {'Reaction outcome loss': 0.4236028100266054, 'Total loss': 0.4236028100266054}
2023-01-04 05:09:59,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:09:59,035 INFO:     Epoch: 7
2023-01-04 05:10:00,100 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48932363986968996, 'Total loss': 0.48932363986968996} | train loss {'Reaction outcome loss': 0.4055005733267087, 'Total loss': 0.4055005733267087}
2023-01-04 05:10:00,100 INFO:     Found new best model at epoch 7
2023-01-04 05:10:00,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:00,101 INFO:     Epoch: 8
2023-01-04 05:10:01,428 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4761245399713516, 'Total loss': 0.4761245399713516} | train loss {'Reaction outcome loss': 0.39411085687469743, 'Total loss': 0.39411085687469743}
2023-01-04 05:10:01,428 INFO:     Found new best model at epoch 8
2023-01-04 05:10:01,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:01,429 INFO:     Epoch: 9
2023-01-04 05:10:03,036 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4753162682056427, 'Total loss': 0.4753162682056427} | train loss {'Reaction outcome loss': 0.38478175812749704, 'Total loss': 0.38478175812749704}
2023-01-04 05:10:03,036 INFO:     Found new best model at epoch 9
2023-01-04 05:10:03,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:03,037 INFO:     Epoch: 10
2023-01-04 05:10:04,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4623848766088486, 'Total loss': 0.4623848766088486} | train loss {'Reaction outcome loss': 0.3792734671438086, 'Total loss': 0.3792734671438086}
2023-01-04 05:10:04,654 INFO:     Found new best model at epoch 10
2023-01-04 05:10:04,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:04,655 INFO:     Epoch: 11
2023-01-04 05:10:06,249 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4613337824741999, 'Total loss': 0.4613337824741999} | train loss {'Reaction outcome loss': 0.3751494679330052, 'Total loss': 0.3751494679330052}
2023-01-04 05:10:06,249 INFO:     Found new best model at epoch 11
2023-01-04 05:10:06,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:06,250 INFO:     Epoch: 12
2023-01-04 05:10:07,874 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45597193042437234, 'Total loss': 0.45597193042437234} | train loss {'Reaction outcome loss': 0.36660746511989745, 'Total loss': 0.36660746511989745}
2023-01-04 05:10:07,874 INFO:     Found new best model at epoch 12
2023-01-04 05:10:07,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:07,875 INFO:     Epoch: 13
2023-01-04 05:10:09,472 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4560211236278216, 'Total loss': 0.4560211236278216} | train loss {'Reaction outcome loss': 0.3605500054208265, 'Total loss': 0.3605500054208265}
2023-01-04 05:10:09,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:09,473 INFO:     Epoch: 14
2023-01-04 05:10:11,075 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4608431080977122, 'Total loss': 0.4608431080977122} | train loss {'Reaction outcome loss': 0.35790504234424536, 'Total loss': 0.35790504234424536}
2023-01-04 05:10:11,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:11,076 INFO:     Epoch: 15
2023-01-04 05:10:12,665 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4684348483880361, 'Total loss': 0.4684348483880361} | train loss {'Reaction outcome loss': 0.3527694379613883, 'Total loss': 0.3527694379613883}
2023-01-04 05:10:12,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:12,666 INFO:     Epoch: 16
2023-01-04 05:10:14,248 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4593467215696971, 'Total loss': 0.4593467215696971} | train loss {'Reaction outcome loss': 0.34026101855156216, 'Total loss': 0.34026101855156216}
2023-01-04 05:10:14,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:14,248 INFO:     Epoch: 17
2023-01-04 05:10:15,858 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4962245980898539, 'Total loss': 0.4962245980898539} | train loss {'Reaction outcome loss': 0.3347208943501439, 'Total loss': 0.3347208943501439}
2023-01-04 05:10:15,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:15,859 INFO:     Epoch: 18
2023-01-04 05:10:17,467 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4500468194484711, 'Total loss': 0.4500468194484711} | train loss {'Reaction outcome loss': 0.3276803690608611, 'Total loss': 0.3276803690608611}
2023-01-04 05:10:17,467 INFO:     Found new best model at epoch 18
2023-01-04 05:10:17,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:17,468 INFO:     Epoch: 19
2023-01-04 05:10:19,034 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46347308655579883, 'Total loss': 0.46347308655579883} | train loss {'Reaction outcome loss': 0.3202833761777215, 'Total loss': 0.3202833761777215}
2023-01-04 05:10:19,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:19,034 INFO:     Epoch: 20
2023-01-04 05:10:20,643 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45563143988450366, 'Total loss': 0.45563143988450366} | train loss {'Reaction outcome loss': 0.3159576315378797, 'Total loss': 0.3159576315378797}
2023-01-04 05:10:20,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:20,644 INFO:     Epoch: 21
2023-01-04 05:10:22,236 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44883720576763153, 'Total loss': 0.44883720576763153} | train loss {'Reaction outcome loss': 0.3115877128793332, 'Total loss': 0.3115877128793332}
2023-01-04 05:10:22,236 INFO:     Found new best model at epoch 21
2023-01-04 05:10:22,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:22,237 INFO:     Epoch: 22
2023-01-04 05:10:23,877 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4576220750808716, 'Total loss': 0.4576220750808716} | train loss {'Reaction outcome loss': 0.30729759591159184, 'Total loss': 0.30729759591159184}
2023-01-04 05:10:23,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:23,877 INFO:     Epoch: 23
2023-01-04 05:10:25,471 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43250711063543956, 'Total loss': 0.43250711063543956} | train loss {'Reaction outcome loss': 0.30940063650753774, 'Total loss': 0.30940063650753774}
2023-01-04 05:10:25,472 INFO:     Found new best model at epoch 23
2023-01-04 05:10:25,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:25,472 INFO:     Epoch: 24
2023-01-04 05:10:27,041 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46200925608476, 'Total loss': 0.46200925608476} | train loss {'Reaction outcome loss': 0.2973351910325658, 'Total loss': 0.2973351910325658}
2023-01-04 05:10:27,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:27,042 INFO:     Epoch: 25
2023-01-04 05:10:28,643 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4559545854727427, 'Total loss': 0.4559545854727427} | train loss {'Reaction outcome loss': 0.2919807430977623, 'Total loss': 0.2919807430977623}
2023-01-04 05:10:28,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:28,644 INFO:     Epoch: 26
2023-01-04 05:10:30,273 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4404606223106384, 'Total loss': 0.4404606223106384} | train loss {'Reaction outcome loss': 0.2906057649170575, 'Total loss': 0.2906057649170575}
2023-01-04 05:10:30,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:30,273 INFO:     Epoch: 27
2023-01-04 05:10:31,904 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45408450563748676, 'Total loss': 0.45408450563748676} | train loss {'Reaction outcome loss': 0.2842109488505546, 'Total loss': 0.2842109488505546}
2023-01-04 05:10:31,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:31,904 INFO:     Epoch: 28
2023-01-04 05:10:33,532 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45684288640817006, 'Total loss': 0.45684288640817006} | train loss {'Reaction outcome loss': 0.2861473699896664, 'Total loss': 0.2861473699896664}
2023-01-04 05:10:33,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:33,532 INFO:     Epoch: 29
2023-01-04 05:10:35,168 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4512827922900518, 'Total loss': 0.4512827922900518} | train loss {'Reaction outcome loss': 0.28951280599837936, 'Total loss': 0.28951280599837936}
2023-01-04 05:10:35,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:35,168 INFO:     Epoch: 30
2023-01-04 05:10:36,743 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4451495409011841, 'Total loss': 0.4451495409011841} | train loss {'Reaction outcome loss': 0.2768574627791194, 'Total loss': 0.2768574627791194}
2023-01-04 05:10:36,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:36,743 INFO:     Epoch: 31
2023-01-04 05:10:38,358 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44569573998451234, 'Total loss': 0.44569573998451234} | train loss {'Reaction outcome loss': 0.2748735759098212, 'Total loss': 0.2748735759098212}
2023-01-04 05:10:38,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:38,358 INFO:     Epoch: 32
2023-01-04 05:10:39,994 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45438228646914164, 'Total loss': 0.45438228646914164} | train loss {'Reaction outcome loss': 0.26645047155519325, 'Total loss': 0.26645047155519325}
2023-01-04 05:10:39,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:39,995 INFO:     Epoch: 33
2023-01-04 05:10:41,627 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4243091414372126, 'Total loss': 0.4243091414372126} | train loss {'Reaction outcome loss': 0.26500143022554845, 'Total loss': 0.26500143022554845}
2023-01-04 05:10:41,628 INFO:     Found new best model at epoch 33
2023-01-04 05:10:41,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:41,628 INFO:     Epoch: 34
2023-01-04 05:10:43,258 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43698055545488995, 'Total loss': 0.43698055545488995} | train loss {'Reaction outcome loss': 0.26044971632190805, 'Total loss': 0.26044971632190805}
2023-01-04 05:10:43,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:43,258 INFO:     Epoch: 35
2023-01-04 05:10:44,872 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4468573108315468, 'Total loss': 0.4468573108315468} | train loss {'Reaction outcome loss': 0.25940013377238874, 'Total loss': 0.25940013377238874}
2023-01-04 05:10:44,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:44,873 INFO:     Epoch: 36
2023-01-04 05:10:46,448 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4305978775024414, 'Total loss': 0.4305978775024414} | train loss {'Reaction outcome loss': 0.2592242041339531, 'Total loss': 0.2592242041339531}
2023-01-04 05:10:46,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:46,448 INFO:     Epoch: 37
2023-01-04 05:10:48,063 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43044716119766235, 'Total loss': 0.43044716119766235} | train loss {'Reaction outcome loss': 0.252093762248768, 'Total loss': 0.252093762248768}
2023-01-04 05:10:48,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:48,063 INFO:     Epoch: 38
2023-01-04 05:10:49,687 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4380632976690928, 'Total loss': 0.4380632976690928} | train loss {'Reaction outcome loss': 0.24922875411868808, 'Total loss': 0.24922875411868808}
2023-01-04 05:10:49,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:49,687 INFO:     Epoch: 39
2023-01-04 05:10:51,316 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45389380554358166, 'Total loss': 0.45389380554358166} | train loss {'Reaction outcome loss': 0.2458545094232777, 'Total loss': 0.2458545094232777}
2023-01-04 05:10:51,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:51,316 INFO:     Epoch: 40
2023-01-04 05:10:52,935 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4321546514829, 'Total loss': 0.4321546514829} | train loss {'Reaction outcome loss': 0.24438197767569259, 'Total loss': 0.24438197767569259}
2023-01-04 05:10:52,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:52,935 INFO:     Epoch: 41
2023-01-04 05:10:54,504 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4304474651813507, 'Total loss': 0.4304474651813507} | train loss {'Reaction outcome loss': 0.24263081813199056, 'Total loss': 0.24263081813199056}
2023-01-04 05:10:54,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:54,504 INFO:     Epoch: 42
2023-01-04 05:10:56,088 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42264338334401447, 'Total loss': 0.42264338334401447} | train loss {'Reaction outcome loss': 0.23911906760590879, 'Total loss': 0.23911906760590879}
2023-01-04 05:10:56,088 INFO:     Found new best model at epoch 42
2023-01-04 05:10:56,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:56,089 INFO:     Epoch: 43
2023-01-04 05:10:57,708 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4220985581477483, 'Total loss': 0.4220985581477483} | train loss {'Reaction outcome loss': 0.26300265357924113, 'Total loss': 0.26300265357924113}
2023-01-04 05:10:57,709 INFO:     Found new best model at epoch 43
2023-01-04 05:10:57,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:57,710 INFO:     Epoch: 44
2023-01-04 05:10:59,293 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42144772311051687, 'Total loss': 0.42144772311051687} | train loss {'Reaction outcome loss': 0.23593049948576136, 'Total loss': 0.23593049948576136}
2023-01-04 05:10:59,293 INFO:     Found new best model at epoch 44
2023-01-04 05:10:59,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:10:59,294 INFO:     Epoch: 45
2023-01-04 05:11:00,926 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43188630441824594, 'Total loss': 0.43188630441824594} | train loss {'Reaction outcome loss': 0.23476676559126328, 'Total loss': 0.23476676559126328}
2023-01-04 05:11:00,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:00,926 INFO:     Epoch: 46
2023-01-04 05:11:02,554 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4328858564297358, 'Total loss': 0.4328858564297358} | train loss {'Reaction outcome loss': 0.23020003073501014, 'Total loss': 0.23020003073501014}
2023-01-04 05:11:02,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:02,554 INFO:     Epoch: 47
2023-01-04 05:11:04,111 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4263319363196691, 'Total loss': 0.4263319363196691} | train loss {'Reaction outcome loss': 0.2280150203138307, 'Total loss': 0.2280150203138307}
2023-01-04 05:11:04,112 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:04,112 INFO:     Epoch: 48
2023-01-04 05:11:05,704 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4349889357884725, 'Total loss': 0.4349889357884725} | train loss {'Reaction outcome loss': 0.22640474378409714, 'Total loss': 0.22640474378409714}
2023-01-04 05:11:05,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:05,704 INFO:     Epoch: 49
2023-01-04 05:11:07,298 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4323386569817861, 'Total loss': 0.4323386569817861} | train loss {'Reaction outcome loss': 0.22682707463863536, 'Total loss': 0.22682707463863536}
2023-01-04 05:11:07,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:07,298 INFO:     Epoch: 50
2023-01-04 05:11:08,890 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44994506041208904, 'Total loss': 0.44994506041208904} | train loss {'Reaction outcome loss': 0.23023257007150896, 'Total loss': 0.23023257007150896}
2023-01-04 05:11:08,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:08,891 INFO:     Epoch: 51
2023-01-04 05:11:10,482 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4305313150087992, 'Total loss': 0.4305313150087992} | train loss {'Reaction outcome loss': 0.22418697929495704, 'Total loss': 0.22418697929495704}
2023-01-04 05:11:10,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:10,482 INFO:     Epoch: 52
2023-01-04 05:11:12,063 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4237106998761495, 'Total loss': 0.4237106998761495} | train loss {'Reaction outcome loss': 0.22012175599018624, 'Total loss': 0.22012175599018624}
2023-01-04 05:11:12,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:12,063 INFO:     Epoch: 53
2023-01-04 05:11:13,649 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4427634060382843, 'Total loss': 0.4427634060382843} | train loss {'Reaction outcome loss': 0.2180513182175818, 'Total loss': 0.2180513182175818}
2023-01-04 05:11:13,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:13,650 INFO:     Epoch: 54
2023-01-04 05:11:15,271 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4308069795370102, 'Total loss': 0.4308069795370102} | train loss {'Reaction outcome loss': 0.22106658232708773, 'Total loss': 0.22106658232708773}
2023-01-04 05:11:15,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:15,271 INFO:     Epoch: 55
2023-01-04 05:11:16,900 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4413640985886256, 'Total loss': 0.4413640985886256} | train loss {'Reaction outcome loss': 0.2369124953351591, 'Total loss': 0.2369124953351591}
2023-01-04 05:11:16,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:16,901 INFO:     Epoch: 56
2023-01-04 05:11:18,478 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4364681680997213, 'Total loss': 0.4364681680997213} | train loss {'Reaction outcome loss': 0.23936975864774507, 'Total loss': 0.23936975864774507}
2023-01-04 05:11:18,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:18,478 INFO:     Epoch: 57
2023-01-04 05:11:20,099 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44502777059872944, 'Total loss': 0.44502777059872944} | train loss {'Reaction outcome loss': 0.21753381174462644, 'Total loss': 0.21753381174462644}
2023-01-04 05:11:20,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:20,100 INFO:     Epoch: 58
2023-01-04 05:11:21,707 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45222474535306295, 'Total loss': 0.45222474535306295} | train loss {'Reaction outcome loss': 0.23202086700315494, 'Total loss': 0.23202086700315494}
2023-01-04 05:11:21,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:21,707 INFO:     Epoch: 59
2023-01-04 05:11:23,287 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.441257152458032, 'Total loss': 0.441257152458032} | train loss {'Reaction outcome loss': 0.21688545167284168, 'Total loss': 0.21688545167284168}
2023-01-04 05:11:23,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:23,288 INFO:     Epoch: 60
2023-01-04 05:11:24,881 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4420140172044436, 'Total loss': 0.4420140172044436} | train loss {'Reaction outcome loss': 0.20965679850812285, 'Total loss': 0.20965679850812285}
2023-01-04 05:11:24,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:24,881 INFO:     Epoch: 61
2023-01-04 05:11:26,472 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4435145825147629, 'Total loss': 0.4435145825147629} | train loss {'Reaction outcome loss': 0.2072280142085114, 'Total loss': 0.2072280142085114}
2023-01-04 05:11:26,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:26,472 INFO:     Epoch: 62
2023-01-04 05:11:28,064 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42985789974530536, 'Total loss': 0.42985789974530536} | train loss {'Reaction outcome loss': 0.20561930731555483, 'Total loss': 0.20561930731555483}
2023-01-04 05:11:28,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:28,064 INFO:     Epoch: 63
2023-01-04 05:11:29,642 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4478890796502431, 'Total loss': 0.4478890796502431} | train loss {'Reaction outcome loss': 0.20607465398242694, 'Total loss': 0.20607465398242694}
2023-01-04 05:11:29,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:29,642 INFO:     Epoch: 64
2023-01-04 05:11:31,221 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4397961805264155, 'Total loss': 0.4397961805264155} | train loss {'Reaction outcome loss': 0.20209040907144116, 'Total loss': 0.20209040907144116}
2023-01-04 05:11:31,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:31,222 INFO:     Epoch: 65
2023-01-04 05:11:32,854 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44633994102478025, 'Total loss': 0.44633994102478025} | train loss {'Reaction outcome loss': 0.20272517421930705, 'Total loss': 0.20272517421930705}
2023-01-04 05:11:32,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:32,855 INFO:     Epoch: 66
2023-01-04 05:11:34,441 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43419285118579865, 'Total loss': 0.43419285118579865} | train loss {'Reaction outcome loss': 0.20255376784589843, 'Total loss': 0.20255376784589843}
2023-01-04 05:11:34,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:34,441 INFO:     Epoch: 67
2023-01-04 05:11:36,054 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49821045994758606, 'Total loss': 0.49821045994758606} | train loss {'Reaction outcome loss': 0.20536905091147925, 'Total loss': 0.20536905091147925}
2023-01-04 05:11:36,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:36,054 INFO:     Epoch: 68
2023-01-04 05:11:37,690 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4543369779984156, 'Total loss': 0.4543369779984156} | train loss {'Reaction outcome loss': 0.20573605673574924, 'Total loss': 0.20573605673574924}
2023-01-04 05:11:37,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:37,690 INFO:     Epoch: 69
2023-01-04 05:11:39,289 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4455582767724991, 'Total loss': 0.4455582767724991} | train loss {'Reaction outcome loss': 0.19961511002057322, 'Total loss': 0.19961511002057322}
2023-01-04 05:11:39,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:39,290 INFO:     Epoch: 70
2023-01-04 05:11:40,884 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43911667267481486, 'Total loss': 0.43911667267481486} | train loss {'Reaction outcome loss': 0.19672529908121508, 'Total loss': 0.19672529908121508}
2023-01-04 05:11:40,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:40,884 INFO:     Epoch: 71
2023-01-04 05:11:42,512 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46620701948801674, 'Total loss': 0.46620701948801674} | train loss {'Reaction outcome loss': 0.19530613095180277, 'Total loss': 0.19530613095180277}
2023-01-04 05:11:42,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:42,512 INFO:     Epoch: 72
2023-01-04 05:11:44,114 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4383475164572398, 'Total loss': 0.4383475164572398} | train loss {'Reaction outcome loss': 0.19638089984935347, 'Total loss': 0.19638089984935347}
2023-01-04 05:11:44,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:44,115 INFO:     Epoch: 73
2023-01-04 05:11:45,716 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.455544251203537, 'Total loss': 0.455544251203537} | train loss {'Reaction outcome loss': 0.19674599979180787, 'Total loss': 0.19674599979180787}
2023-01-04 05:11:45,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:45,717 INFO:     Epoch: 74
2023-01-04 05:11:47,348 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46624826788902285, 'Total loss': 0.46624826788902285} | train loss {'Reaction outcome loss': 0.19255755681618777, 'Total loss': 0.19255755681618777}
2023-01-04 05:11:47,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:47,348 INFO:     Epoch: 75
2023-01-04 05:11:48,904 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47778875231742857, 'Total loss': 0.47778875231742857} | train loss {'Reaction outcome loss': 0.19282595310379175, 'Total loss': 0.19282595310379175}
2023-01-04 05:11:48,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:48,904 INFO:     Epoch: 76
2023-01-04 05:11:50,536 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47180493076642355, 'Total loss': 0.47180493076642355} | train loss {'Reaction outcome loss': 0.1928706854392869, 'Total loss': 0.1928706854392869}
2023-01-04 05:11:50,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:50,537 INFO:     Epoch: 77
2023-01-04 05:11:52,169 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4448149621486664, 'Total loss': 0.4448149621486664} | train loss {'Reaction outcome loss': 0.1968488974600431, 'Total loss': 0.1968488974600431}
2023-01-04 05:11:52,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:52,170 INFO:     Epoch: 78
2023-01-04 05:11:53,771 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4526830315589905, 'Total loss': 0.4526830315589905} | train loss {'Reaction outcome loss': 0.19231672842008687, 'Total loss': 0.19231672842008687}
2023-01-04 05:11:53,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:53,771 INFO:     Epoch: 79
2023-01-04 05:11:55,372 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.433909983932972, 'Total loss': 0.433909983932972} | train loss {'Reaction outcome loss': 0.18931140031908517, 'Total loss': 0.18931140031908517}
2023-01-04 05:11:55,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:55,372 INFO:     Epoch: 80
2023-01-04 05:11:56,951 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4485556989908218, 'Total loss': 0.4485556989908218} | train loss {'Reaction outcome loss': 0.1874366099007543, 'Total loss': 0.1874366099007543}
2023-01-04 05:11:56,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:56,951 INFO:     Epoch: 81
2023-01-04 05:11:58,531 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46526094476381935, 'Total loss': 0.46526094476381935} | train loss {'Reaction outcome loss': 0.1996143693914232, 'Total loss': 0.1996143693914232}
2023-01-04 05:11:58,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:11:58,531 INFO:     Epoch: 82
2023-01-04 05:12:00,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46949639916419983, 'Total loss': 0.46949639916419983} | train loss {'Reaction outcome loss': 0.20826740221852652, 'Total loss': 0.20826740221852652}
2023-01-04 05:12:00,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:00,128 INFO:     Epoch: 83
2023-01-04 05:12:01,726 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46435806155204773, 'Total loss': 0.46435806155204773} | train loss {'Reaction outcome loss': 0.18932609896665267, 'Total loss': 0.18932609896665267}
2023-01-04 05:12:01,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:01,726 INFO:     Epoch: 84
2023-01-04 05:12:03,325 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45477403750022255, 'Total loss': 0.45477403750022255} | train loss {'Reaction outcome loss': 0.18473682014703535, 'Total loss': 0.18473682014703535}
2023-01-04 05:12:03,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:03,326 INFO:     Epoch: 85
2023-01-04 05:12:04,923 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45237529079119365, 'Total loss': 0.45237529079119365} | train loss {'Reaction outcome loss': 0.1842174032379104, 'Total loss': 0.1842174032379104}
2023-01-04 05:12:04,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:04,924 INFO:     Epoch: 86
2023-01-04 05:12:06,517 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4535958803879718, 'Total loss': 0.4535958803879718} | train loss {'Reaction outcome loss': 0.18245690479955595, 'Total loss': 0.18245690479955595}
2023-01-04 05:12:06,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:06,517 INFO:     Epoch: 87
2023-01-04 05:12:08,125 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46943025837341945, 'Total loss': 0.46943025837341945} | train loss {'Reaction outcome loss': 0.1833998527387545, 'Total loss': 0.1833998527387545}
2023-01-04 05:12:08,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:08,125 INFO:     Epoch: 88
2023-01-04 05:12:09,740 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47285515666007993, 'Total loss': 0.47285515666007993} | train loss {'Reaction outcome loss': 0.18199401093230283, 'Total loss': 0.18199401093230283}
2023-01-04 05:12:09,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:09,741 INFO:     Epoch: 89
2023-01-04 05:12:11,362 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48198822339375813, 'Total loss': 0.48198822339375813} | train loss {'Reaction outcome loss': 0.18073276702046354, 'Total loss': 0.18073276702046354}
2023-01-04 05:12:11,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:11,363 INFO:     Epoch: 90
2023-01-04 05:12:12,940 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4734029730161031, 'Total loss': 0.4734029730161031} | train loss {'Reaction outcome loss': 0.18902899337041637, 'Total loss': 0.18902899337041637}
2023-01-04 05:12:12,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:12,940 INFO:     Epoch: 91
2023-01-04 05:12:14,554 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4707444220781326, 'Total loss': 0.4707444220781326} | train loss {'Reaction outcome loss': 0.1949137406988049, 'Total loss': 0.1949137406988049}
2023-01-04 05:12:14,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:14,554 INFO:     Epoch: 92
2023-01-04 05:12:16,128 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47536655167738595, 'Total loss': 0.47536655167738595} | train loss {'Reaction outcome loss': 0.1820211976153297, 'Total loss': 0.1820211976153297}
2023-01-04 05:12:16,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:16,129 INFO:     Epoch: 93
2023-01-04 05:12:17,749 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4860896329085032, 'Total loss': 0.4860896329085032} | train loss {'Reaction outcome loss': 0.18033917349833023, 'Total loss': 0.18033917349833023}
2023-01-04 05:12:17,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:17,749 INFO:     Epoch: 94
2023-01-04 05:12:19,381 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4746807177861532, 'Total loss': 0.4746807177861532} | train loss {'Reaction outcome loss': 0.17971515823105816, 'Total loss': 0.17971515823105816}
2023-01-04 05:12:19,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:19,381 INFO:     Epoch: 95
2023-01-04 05:12:21,010 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4781538526217143, 'Total loss': 0.4781538526217143} | train loss {'Reaction outcome loss': 0.18032146379943426, 'Total loss': 0.18032146379943426}
2023-01-04 05:12:21,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:21,010 INFO:     Epoch: 96
2023-01-04 05:12:22,596 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47901348272959393, 'Total loss': 0.47901348272959393} | train loss {'Reaction outcome loss': 0.1749662597179902, 'Total loss': 0.1749662597179902}
2023-01-04 05:12:22,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:22,597 INFO:     Epoch: 97
2023-01-04 05:12:24,162 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.506822618842125, 'Total loss': 0.506822618842125} | train loss {'Reaction outcome loss': 0.17800776298600543, 'Total loss': 0.17800776298600543}
2023-01-04 05:12:24,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:24,163 INFO:     Epoch: 98
2023-01-04 05:12:25,746 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49426823953787485, 'Total loss': 0.49426823953787485} | train loss {'Reaction outcome loss': 0.17640975280803922, 'Total loss': 0.17640975280803922}
2023-01-04 05:12:25,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:25,746 INFO:     Epoch: 99
2023-01-04 05:12:27,368 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4899714857339859, 'Total loss': 0.4899714857339859} | train loss {'Reaction outcome loss': 0.17777372759145152, 'Total loss': 0.17777372759145152}
2023-01-04 05:12:27,368 INFO:     Best model found after epoch 45 of 100.
2023-01-04 05:12:27,368 INFO:   Done with stage: TRAINING
2023-01-04 05:12:27,368 INFO:   Starting stage: EVALUATION
2023-01-04 05:12:27,499 INFO:   Done with stage: EVALUATION
2023-01-04 05:12:27,499 INFO:   Leaving out SEQ value Fold_1
2023-01-04 05:12:27,512 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-04 05:12:27,512 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:12:28,161 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:12:28,161 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:12:28,229 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:12:28,229 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:12:28,229 INFO:     No hyperparam tuning for this model
2023-01-04 05:12:28,230 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:12:28,230 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:12:28,230 INFO:     None feature selector for col prot
2023-01-04 05:12:28,231 INFO:     None feature selector for col prot
2023-01-04 05:12:28,231 INFO:     None feature selector for col prot
2023-01-04 05:12:28,231 INFO:     None feature selector for col chem
2023-01-04 05:12:28,231 INFO:     None feature selector for col chem
2023-01-04 05:12:28,231 INFO:     None feature selector for col chem
2023-01-04 05:12:28,231 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:12:28,231 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:12:28,233 INFO:     Number of params in model 70141
2023-01-04 05:12:28,236 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:12:28,236 INFO:   Starting stage: TRAINING
2023-01-04 05:12:28,280 INFO:     Val loss before train {'Reaction outcome loss': 0.9548832138379415, 'Total loss': 0.9548832138379415}
2023-01-04 05:12:28,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:28,280 INFO:     Epoch: 0
2023-01-04 05:12:29,891 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6353178183237712, 'Total loss': 0.6353178183237712} | train loss {'Reaction outcome loss': 0.8622557569457137, 'Total loss': 0.8622557569457137}
2023-01-04 05:12:29,891 INFO:     Found new best model at epoch 0
2023-01-04 05:12:29,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:29,892 INFO:     Epoch: 1
2023-01-04 05:12:31,522 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49430503050486246, 'Total loss': 0.49430503050486246} | train loss {'Reaction outcome loss': 0.6195739329509113, 'Total loss': 0.6195739329509113}
2023-01-04 05:12:31,522 INFO:     Found new best model at epoch 1
2023-01-04 05:12:31,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:31,523 INFO:     Epoch: 2
2023-01-04 05:12:33,113 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4394915262858073, 'Total loss': 0.4394915262858073} | train loss {'Reaction outcome loss': 0.5435587952750317, 'Total loss': 0.5435587952750317}
2023-01-04 05:12:33,113 INFO:     Found new best model at epoch 2
2023-01-04 05:12:33,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:33,114 INFO:     Epoch: 3
2023-01-04 05:12:34,723 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42232098082701364, 'Total loss': 0.42232098082701364} | train loss {'Reaction outcome loss': 0.5042497256797724, 'Total loss': 0.5042497256797724}
2023-01-04 05:12:34,724 INFO:     Found new best model at epoch 3
2023-01-04 05:12:34,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:34,725 INFO:     Epoch: 4
2023-01-04 05:12:36,359 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4173983862002691, 'Total loss': 0.4173983862002691} | train loss {'Reaction outcome loss': 0.47478075822194415, 'Total loss': 0.47478075822194415}
2023-01-04 05:12:36,359 INFO:     Found new best model at epoch 4
2023-01-04 05:12:36,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:36,360 INFO:     Epoch: 5
2023-01-04 05:12:37,963 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.393761016925176, 'Total loss': 0.393761016925176} | train loss {'Reaction outcome loss': 0.45333799803494546, 'Total loss': 0.45333799803494546}
2023-01-04 05:12:37,963 INFO:     Found new best model at epoch 5
2023-01-04 05:12:37,964 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:37,964 INFO:     Epoch: 6
2023-01-04 05:12:39,592 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.37922229468822477, 'Total loss': 0.37922229468822477} | train loss {'Reaction outcome loss': 0.43423029013902653, 'Total loss': 0.43423029013902653}
2023-01-04 05:12:39,592 INFO:     Found new best model at epoch 6
2023-01-04 05:12:39,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:39,593 INFO:     Epoch: 7
2023-01-04 05:12:41,198 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.36668486098448433, 'Total loss': 0.36668486098448433} | train loss {'Reaction outcome loss': 0.41745617010536185, 'Total loss': 0.41745617010536185}
2023-01-04 05:12:41,199 INFO:     Found new best model at epoch 7
2023-01-04 05:12:41,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:41,199 INFO:     Epoch: 8
2023-01-04 05:12:42,775 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.37330529689788816, 'Total loss': 0.37330529689788816} | train loss {'Reaction outcome loss': 0.40915782720928645, 'Total loss': 0.40915782720928645}
2023-01-04 05:12:42,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:42,775 INFO:     Epoch: 9
2023-01-04 05:12:44,377 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.37723457217216494, 'Total loss': 0.37723457217216494} | train loss {'Reaction outcome loss': 0.3995432540018489, 'Total loss': 0.3995432540018489}
2023-01-04 05:12:44,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:44,377 INFO:     Epoch: 10
2023-01-04 05:12:45,978 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3628383735815684, 'Total loss': 0.3628383735815684} | train loss {'Reaction outcome loss': 0.39049912690846383, 'Total loss': 0.39049912690846383}
2023-01-04 05:12:45,978 INFO:     Found new best model at epoch 10
2023-01-04 05:12:45,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:45,979 INFO:     Epoch: 11
2023-01-04 05:12:47,582 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.36189976533253987, 'Total loss': 0.36189976533253987} | train loss {'Reaction outcome loss': 0.38462972227969894, 'Total loss': 0.38462972227969894}
2023-01-04 05:12:47,582 INFO:     Found new best model at epoch 11
2023-01-04 05:12:47,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:47,583 INFO:     Epoch: 12
2023-01-04 05:12:49,182 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36360015869140627, 'Total loss': 0.36360015869140627} | train loss {'Reaction outcome loss': 0.3797269189406348, 'Total loss': 0.3797269189406348}
2023-01-04 05:12:49,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:49,182 INFO:     Epoch: 13
2023-01-04 05:12:50,761 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3594883640607198, 'Total loss': 0.3594883640607198} | train loss {'Reaction outcome loss': 0.3684329597087091, 'Total loss': 0.3684329597087091}
2023-01-04 05:12:50,761 INFO:     Found new best model at epoch 13
2023-01-04 05:12:50,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:50,762 INFO:     Epoch: 14
2023-01-04 05:12:52,357 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.35048116048177086, 'Total loss': 0.35048116048177086} | train loss {'Reaction outcome loss': 0.36219437622624, 'Total loss': 0.36219437622624}
2023-01-04 05:12:52,357 INFO:     Found new best model at epoch 14
2023-01-04 05:12:52,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:52,358 INFO:     Epoch: 15
2023-01-04 05:12:53,947 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3613192265232404, 'Total loss': 0.3613192265232404} | train loss {'Reaction outcome loss': 0.35616461789586407, 'Total loss': 0.35616461789586407}
2023-01-04 05:12:53,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:53,948 INFO:     Epoch: 16
2023-01-04 05:12:55,524 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.345287424325943, 'Total loss': 0.345287424325943} | train loss {'Reaction outcome loss': 0.3531332392974392, 'Total loss': 0.3531332392974392}
2023-01-04 05:12:55,524 INFO:     Found new best model at epoch 16
2023-01-04 05:12:55,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:55,525 INFO:     Epoch: 17
2023-01-04 05:12:57,136 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3441906273365021, 'Total loss': 0.3441906273365021} | train loss {'Reaction outcome loss': 0.34543040144237, 'Total loss': 0.34543040144237}
2023-01-04 05:12:57,137 INFO:     Found new best model at epoch 17
2023-01-04 05:12:57,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:57,137 INFO:     Epoch: 18
2023-01-04 05:12:58,761 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.340356574455897, 'Total loss': 0.340356574455897} | train loss {'Reaction outcome loss': 0.34088550662736583, 'Total loss': 0.34088550662736583}
2023-01-04 05:12:58,762 INFO:     Found new best model at epoch 18
2023-01-04 05:12:58,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:12:58,762 INFO:     Epoch: 19
2023-01-04 05:13:00,328 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3554038653771083, 'Total loss': 0.3554038653771083} | train loss {'Reaction outcome loss': 0.3393387223823347, 'Total loss': 0.3393387223823347}
2023-01-04 05:13:00,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:00,329 INFO:     Epoch: 20
2023-01-04 05:13:01,920 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.342862402399381, 'Total loss': 0.342862402399381} | train loss {'Reaction outcome loss': 0.3345888163902851, 'Total loss': 0.3345888163902851}
2023-01-04 05:13:01,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:01,920 INFO:     Epoch: 21
2023-01-04 05:13:03,515 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.35162566900253295, 'Total loss': 0.35162566900253295} | train loss {'Reaction outcome loss': 0.32808839679574187, 'Total loss': 0.32808839679574187}
2023-01-04 05:13:03,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:03,515 INFO:     Epoch: 22
2023-01-04 05:13:05,110 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.34919493397076923, 'Total loss': 0.34919493397076923} | train loss {'Reaction outcome loss': 0.32212355838872603, 'Total loss': 0.32212355838872603}
2023-01-04 05:13:05,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:05,110 INFO:     Epoch: 23
2023-01-04 05:13:06,704 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.34782934685548145, 'Total loss': 0.34782934685548145} | train loss {'Reaction outcome loss': 0.31845013171392644, 'Total loss': 0.31845013171392644}
2023-01-04 05:13:06,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:06,704 INFO:     Epoch: 24
2023-01-04 05:13:08,282 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.351613804201285, 'Total loss': 0.351613804201285} | train loss {'Reaction outcome loss': 0.3136897434747168, 'Total loss': 0.3136897434747168}
2023-01-04 05:13:08,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:08,282 INFO:     Epoch: 25
2023-01-04 05:13:09,865 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3325084721048673, 'Total loss': 0.3325084721048673} | train loss {'Reaction outcome loss': 0.3108501824233141, 'Total loss': 0.3108501824233141}
2023-01-04 05:13:09,866 INFO:     Found new best model at epoch 25
2023-01-04 05:13:09,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:09,867 INFO:     Epoch: 26
2023-01-04 05:13:11,466 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.33577586462100345, 'Total loss': 0.33577586462100345} | train loss {'Reaction outcome loss': 0.30652719472224516, 'Total loss': 0.30652719472224516}
2023-01-04 05:13:11,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:11,466 INFO:     Epoch: 27
2023-01-04 05:13:13,068 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3403171638647715, 'Total loss': 0.3403171638647715} | train loss {'Reaction outcome loss': 0.3065198888003394, 'Total loss': 0.3065198888003394}
2023-01-04 05:13:13,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:13,068 INFO:     Epoch: 28
2023-01-04 05:13:14,669 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3314702073733012, 'Total loss': 0.3314702073733012} | train loss {'Reaction outcome loss': 0.29783540504876577, 'Total loss': 0.29783540504876577}
2023-01-04 05:13:14,669 INFO:     Found new best model at epoch 28
2023-01-04 05:13:14,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:14,670 INFO:     Epoch: 29
2023-01-04 05:13:16,267 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3248638351758321, 'Total loss': 0.3248638351758321} | train loss {'Reaction outcome loss': 0.29561970515857433, 'Total loss': 0.29561970515857433}
2023-01-04 05:13:16,268 INFO:     Found new best model at epoch 29
2023-01-04 05:13:16,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:16,269 INFO:     Epoch: 30
2023-01-04 05:13:17,858 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3433886746565501, 'Total loss': 0.3433886746565501} | train loss {'Reaction outcome loss': 0.29332313956557843, 'Total loss': 0.29332313956557843}
2023-01-04 05:13:17,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:17,858 INFO:     Epoch: 31
2023-01-04 05:13:19,449 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3566194673379262, 'Total loss': 0.3566194673379262} | train loss {'Reaction outcome loss': 0.288453986544324, 'Total loss': 0.288453986544324}
2023-01-04 05:13:19,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:19,449 INFO:     Epoch: 32
2023-01-04 05:13:21,052 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.33813744882742564, 'Total loss': 0.33813744882742564} | train loss {'Reaction outcome loss': 0.3004435505448044, 'Total loss': 0.3004435505448044}
2023-01-04 05:13:21,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:21,052 INFO:     Epoch: 33
2023-01-04 05:13:22,671 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34061840971310936, 'Total loss': 0.34061840971310936} | train loss {'Reaction outcome loss': 0.306504730783079, 'Total loss': 0.306504730783079}
2023-01-04 05:13:22,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:22,671 INFO:     Epoch: 34
2023-01-04 05:13:24,302 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3279199987649918, 'Total loss': 0.3279199987649918} | train loss {'Reaction outcome loss': 0.2876279046252856, 'Total loss': 0.2876279046252856}
2023-01-04 05:13:24,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:24,302 INFO:     Epoch: 35
2023-01-04 05:13:25,909 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.33535374303658805, 'Total loss': 0.33535374303658805} | train loss {'Reaction outcome loss': 0.27458133265642665, 'Total loss': 0.27458133265642665}
2023-01-04 05:13:25,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:25,909 INFO:     Epoch: 36
2023-01-04 05:13:27,474 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3386359671751658, 'Total loss': 0.3386359671751658} | train loss {'Reaction outcome loss': 0.27089002663186246, 'Total loss': 0.27089002663186246}
2023-01-04 05:13:27,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:27,474 INFO:     Epoch: 37
2023-01-04 05:13:29,072 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.31487848261992135, 'Total loss': 0.31487848261992135} | train loss {'Reaction outcome loss': 0.26850422905704036, 'Total loss': 0.26850422905704036}
2023-01-04 05:13:29,073 INFO:     Found new best model at epoch 37
2023-01-04 05:13:29,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:29,074 INFO:     Epoch: 38
2023-01-04 05:13:30,665 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3438947170972824, 'Total loss': 0.3438947170972824} | train loss {'Reaction outcome loss': 0.2682510758412705, 'Total loss': 0.2682510758412705}
2023-01-04 05:13:30,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:30,665 INFO:     Epoch: 39
2023-01-04 05:13:32,296 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.32456963260968524, 'Total loss': 0.32456963260968524} | train loss {'Reaction outcome loss': 0.2647176946267027, 'Total loss': 0.2647176946267027}
2023-01-04 05:13:32,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:32,297 INFO:     Epoch: 40
2023-01-04 05:13:33,917 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.32860428988933565, 'Total loss': 0.32860428988933565} | train loss {'Reaction outcome loss': 0.261452563397126, 'Total loss': 0.261452563397126}
2023-01-04 05:13:33,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:33,917 INFO:     Epoch: 41
2023-01-04 05:13:35,527 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.31680163989464444, 'Total loss': 0.31680163989464444} | train loss {'Reaction outcome loss': 0.25693669551063963, 'Total loss': 0.25693669551063963}
2023-01-04 05:13:35,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:35,527 INFO:     Epoch: 42
2023-01-04 05:13:37,108 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3235798408587774, 'Total loss': 0.3235798408587774} | train loss {'Reaction outcome loss': 0.2555394506101341, 'Total loss': 0.2555394506101341}
2023-01-04 05:13:37,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:37,108 INFO:     Epoch: 43
2023-01-04 05:13:38,728 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.33733406364917756, 'Total loss': 0.33733406364917756} | train loss {'Reaction outcome loss': 0.25212028379673546, 'Total loss': 0.25212028379673546}
2023-01-04 05:13:38,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:38,729 INFO:     Epoch: 44
2023-01-04 05:13:40,351 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3400112211704254, 'Total loss': 0.3400112211704254} | train loss {'Reaction outcome loss': 0.25047110742214473, 'Total loss': 0.25047110742214473}
2023-01-04 05:13:40,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:40,353 INFO:     Epoch: 45
2023-01-04 05:13:41,984 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33281934559345244, 'Total loss': 0.33281934559345244} | train loss {'Reaction outcome loss': 0.24974972032941878, 'Total loss': 0.24974972032941878}
2023-01-04 05:13:41,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:41,984 INFO:     Epoch: 46
2023-01-04 05:13:43,603 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3360793501138687, 'Total loss': 0.3360793501138687} | train loss {'Reaction outcome loss': 0.24606170996591664, 'Total loss': 0.24606170996591664}
2023-01-04 05:13:43,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:43,603 INFO:     Epoch: 47
2023-01-04 05:13:45,172 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3255836923917135, 'Total loss': 0.3255836923917135} | train loss {'Reaction outcome loss': 0.24355025204114508, 'Total loss': 0.24355025204114508}
2023-01-04 05:13:45,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:45,172 INFO:     Epoch: 48
2023-01-04 05:13:46,821 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.333172016342481, 'Total loss': 0.333172016342481} | train loss {'Reaction outcome loss': 0.24978038532308477, 'Total loss': 0.24978038532308477}
2023-01-04 05:13:46,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:46,822 INFO:     Epoch: 49
2023-01-04 05:13:48,502 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.32477791905403136, 'Total loss': 0.32477791905403136} | train loss {'Reaction outcome loss': 0.2526572580157507, 'Total loss': 0.2526572580157507}
2023-01-04 05:13:48,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:48,502 INFO:     Epoch: 50
2023-01-04 05:13:50,178 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3199840227762858, 'Total loss': 0.3199840227762858} | train loss {'Reaction outcome loss': 0.23649965377905796, 'Total loss': 0.23649965377905796}
2023-01-04 05:13:50,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:50,178 INFO:     Epoch: 51
2023-01-04 05:13:51,865 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3308275143305461, 'Total loss': 0.3308275143305461} | train loss {'Reaction outcome loss': 0.2329690859448907, 'Total loss': 0.2329690859448907}
2023-01-04 05:13:51,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:51,865 INFO:     Epoch: 52
2023-01-04 05:13:53,488 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34111794233322146, 'Total loss': 0.34111794233322146} | train loss {'Reaction outcome loss': 0.2302251171415159, 'Total loss': 0.2302251171415159}
2023-01-04 05:13:53,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:53,488 INFO:     Epoch: 53
2023-01-04 05:13:55,069 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.32720326085885365, 'Total loss': 0.32720326085885365} | train loss {'Reaction outcome loss': 0.23008865358280964, 'Total loss': 0.23008865358280964}
2023-01-04 05:13:55,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:55,070 INFO:     Epoch: 54
2023-01-04 05:13:56,700 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3401378015677134, 'Total loss': 0.3401378015677134} | train loss {'Reaction outcome loss': 0.23179699097206627, 'Total loss': 0.23179699097206627}
2023-01-04 05:13:56,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:56,700 INFO:     Epoch: 55
2023-01-04 05:13:58,303 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3257729882995288, 'Total loss': 0.3257729882995288} | train loss {'Reaction outcome loss': 0.22952659638679546, 'Total loss': 0.22952659638679546}
2023-01-04 05:13:58,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:58,304 INFO:     Epoch: 56
2023-01-04 05:13:59,930 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3553962101538976, 'Total loss': 0.3553962101538976} | train loss {'Reaction outcome loss': 0.22742657671156136, 'Total loss': 0.22742657671156136}
2023-01-04 05:13:59,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:13:59,931 INFO:     Epoch: 57
2023-01-04 05:14:01,537 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3314585576454798, 'Total loss': 0.3314585576454798} | train loss {'Reaction outcome loss': 0.22973292744532903, 'Total loss': 0.22973292744532903}
2023-01-04 05:14:01,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:01,538 INFO:     Epoch: 58
2023-01-04 05:14:03,133 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.32971792419751483, 'Total loss': 0.32971792419751483} | train loss {'Reaction outcome loss': 0.22161858717479027, 'Total loss': 0.22161858717479027}
2023-01-04 05:14:03,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:03,133 INFO:     Epoch: 59
2023-01-04 05:14:04,732 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35128542681535085, 'Total loss': 0.35128542681535085} | train loss {'Reaction outcome loss': 0.21873279388966985, 'Total loss': 0.21873279388966985}
2023-01-04 05:14:04,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:04,732 INFO:     Epoch: 60
2023-01-04 05:14:06,353 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3310487776994705, 'Total loss': 0.3310487776994705} | train loss {'Reaction outcome loss': 0.21922731288857217, 'Total loss': 0.21922731288857217}
2023-01-04 05:14:06,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:06,354 INFO:     Epoch: 61
2023-01-04 05:14:07,965 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3420634001493454, 'Total loss': 0.3420634001493454} | train loss {'Reaction outcome loss': 0.21855971378618447, 'Total loss': 0.21855971378618447}
2023-01-04 05:14:07,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:07,965 INFO:     Epoch: 62
2023-01-04 05:14:09,589 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.32900247573852537, 'Total loss': 0.32900247573852537} | train loss {'Reaction outcome loss': 0.2139293192725534, 'Total loss': 0.2139293192725534}
2023-01-04 05:14:09,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:09,589 INFO:     Epoch: 63
2023-01-04 05:14:11,224 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3279506221413612, 'Total loss': 0.3279506221413612} | train loss {'Reaction outcome loss': 0.21363425084833026, 'Total loss': 0.21363425084833026}
2023-01-04 05:14:11,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:11,224 INFO:     Epoch: 64
2023-01-04 05:14:12,789 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3222888583938281, 'Total loss': 0.3222888583938281} | train loss {'Reaction outcome loss': 0.20918039716543982, 'Total loss': 0.20918039716543982}
2023-01-04 05:14:12,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:12,789 INFO:     Epoch: 65
2023-01-04 05:14:14,413 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33527112429340683, 'Total loss': 0.33527112429340683} | train loss {'Reaction outcome loss': 0.21200502095271603, 'Total loss': 0.21200502095271603}
2023-01-04 05:14:14,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:14,413 INFO:     Epoch: 66
2023-01-04 05:14:16,024 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.34779325822989143, 'Total loss': 0.34779325822989143} | train loss {'Reaction outcome loss': 0.20707545810095643, 'Total loss': 0.20707545810095643}
2023-01-04 05:14:16,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:16,024 INFO:     Epoch: 67
2023-01-04 05:14:17,646 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.341299107670784, 'Total loss': 0.341299107670784} | train loss {'Reaction outcome loss': 0.20842628636905103, 'Total loss': 0.20842628636905103}
2023-01-04 05:14:17,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:17,648 INFO:     Epoch: 68
2023-01-04 05:14:19,226 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.32196279664834343, 'Total loss': 0.32196279664834343} | train loss {'Reaction outcome loss': 0.20783653458393941, 'Total loss': 0.20783653458393941}
2023-01-04 05:14:19,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:19,226 INFO:     Epoch: 69
2023-01-04 05:14:20,825 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3485313455263774, 'Total loss': 0.3485313455263774} | train loss {'Reaction outcome loss': 0.2061673919585925, 'Total loss': 0.2061673919585925}
2023-01-04 05:14:20,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:20,826 INFO:     Epoch: 70
2023-01-04 05:14:22,417 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3508799230058988, 'Total loss': 0.3508799230058988} | train loss {'Reaction outcome loss': 0.20384620701994552, 'Total loss': 0.20384620701994552}
2023-01-04 05:14:22,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:22,418 INFO:     Epoch: 71
2023-01-04 05:14:24,042 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3485211630662282, 'Total loss': 0.3485211630662282} | train loss {'Reaction outcome loss': 0.20089665571894316, 'Total loss': 0.20089665571894316}
2023-01-04 05:14:24,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:24,043 INFO:     Epoch: 72
2023-01-04 05:14:25,649 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.34989572564760846, 'Total loss': 0.34989572564760846} | train loss {'Reaction outcome loss': 0.20175131145810735, 'Total loss': 0.20175131145810735}
2023-01-04 05:14:25,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:25,649 INFO:     Epoch: 73
2023-01-04 05:14:27,271 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35025524695714316, 'Total loss': 0.35025524695714316} | train loss {'Reaction outcome loss': 0.20017092589008878, 'Total loss': 0.20017092589008878}
2023-01-04 05:14:27,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:27,271 INFO:     Epoch: 74
2023-01-04 05:14:28,908 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.339506001273791, 'Total loss': 0.339506001273791} | train loss {'Reaction outcome loss': 0.19931748698371043, 'Total loss': 0.19931748698371043}
2023-01-04 05:14:28,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:28,908 INFO:     Epoch: 75
2023-01-04 05:14:30,498 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36723788479963937, 'Total loss': 0.36723788479963937} | train loss {'Reaction outcome loss': 0.20105089858660233, 'Total loss': 0.20105089858660233}
2023-01-04 05:14:30,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:30,499 INFO:     Epoch: 76
2023-01-04 05:14:32,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34813507795333865, 'Total loss': 0.34813507795333865} | train loss {'Reaction outcome loss': 0.19669013139555583, 'Total loss': 0.19669013139555583}
2023-01-04 05:14:32,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:32,101 INFO:     Epoch: 77
2023-01-04 05:14:33,724 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.33560356199741365, 'Total loss': 0.33560356199741365} | train loss {'Reaction outcome loss': 0.19490022984319838, 'Total loss': 0.19490022984319838}
2023-01-04 05:14:33,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:33,724 INFO:     Epoch: 78
2023-01-04 05:14:35,329 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.354420992732048, 'Total loss': 0.354420992732048} | train loss {'Reaction outcome loss': 0.2000207621705435, 'Total loss': 0.2000207621705435}
2023-01-04 05:14:35,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:35,329 INFO:     Epoch: 79
2023-01-04 05:14:36,939 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.35774588187535605, 'Total loss': 0.35774588187535605} | train loss {'Reaction outcome loss': 0.19442534294364083, 'Total loss': 0.19442534294364083}
2023-01-04 05:14:36,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:36,940 INFO:     Epoch: 80
2023-01-04 05:14:38,539 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36479047536849973, 'Total loss': 0.36479047536849973} | train loss {'Reaction outcome loss': 0.1922818342219229, 'Total loss': 0.1922818342219229}
2023-01-04 05:14:38,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:38,539 INFO:     Epoch: 81
2023-01-04 05:14:40,120 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3640804429848989, 'Total loss': 0.3640804429848989} | train loss {'Reaction outcome loss': 0.1890514394018691, 'Total loss': 0.1890514394018691}
2023-01-04 05:14:40,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:40,120 INFO:     Epoch: 82
2023-01-04 05:14:41,726 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3645771344502767, 'Total loss': 0.3645771344502767} | train loss {'Reaction outcome loss': 0.190572904698522, 'Total loss': 0.190572904698522}
2023-01-04 05:14:41,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:41,726 INFO:     Epoch: 83
2023-01-04 05:14:43,332 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3590712661544482, 'Total loss': 0.3590712661544482} | train loss {'Reaction outcome loss': 0.19047929978595826, 'Total loss': 0.19047929978595826}
2023-01-04 05:14:43,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:43,333 INFO:     Epoch: 84
2023-01-04 05:14:44,935 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3519088725248973, 'Total loss': 0.3519088725248973} | train loss {'Reaction outcome loss': 0.18852423341329838, 'Total loss': 0.18852423341329838}
2023-01-04 05:14:44,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:44,935 INFO:     Epoch: 85
2023-01-04 05:14:46,543 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.34821381121873857, 'Total loss': 0.34821381121873857} | train loss {'Reaction outcome loss': 0.18783607508690245, 'Total loss': 0.18783607508690245}
2023-01-04 05:14:46,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:46,543 INFO:     Epoch: 86
2023-01-04 05:14:48,140 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35854122837384544, 'Total loss': 0.35854122837384544} | train loss {'Reaction outcome loss': 0.18581300105670115, 'Total loss': 0.18581300105670115}
2023-01-04 05:14:48,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:48,140 INFO:     Epoch: 87
2023-01-04 05:14:49,722 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.37216764042774836, 'Total loss': 0.37216764042774836} | train loss {'Reaction outcome loss': 0.19472352750059488, 'Total loss': 0.19472352750059488}
2023-01-04 05:14:49,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:49,723 INFO:     Epoch: 88
2023-01-04 05:14:51,327 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37721318503220874, 'Total loss': 0.37721318503220874} | train loss {'Reaction outcome loss': 0.20545209996888172, 'Total loss': 0.20545209996888172}
2023-01-04 05:14:51,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:51,327 INFO:     Epoch: 89
2023-01-04 05:14:52,929 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40373365879058837, 'Total loss': 0.40373365879058837} | train loss {'Reaction outcome loss': 0.1839307258379067, 'Total loss': 0.1839307258379067}
2023-01-04 05:14:52,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:52,930 INFO:     Epoch: 90
2023-01-04 05:14:54,533 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3445802719642719, 'Total loss': 0.3445802719642719} | train loss {'Reaction outcome loss': 0.18402552716535234, 'Total loss': 0.18402552716535234}
2023-01-04 05:14:54,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:54,534 INFO:     Epoch: 91
2023-01-04 05:14:56,138 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35124962429205575, 'Total loss': 0.35124962429205575} | train loss {'Reaction outcome loss': 0.18287449446939139, 'Total loss': 0.18287449446939139}
2023-01-04 05:14:56,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:56,138 INFO:     Epoch: 92
2023-01-04 05:14:57,702 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3704840262730916, 'Total loss': 0.3704840262730916} | train loss {'Reaction outcome loss': 0.18222699989902152, 'Total loss': 0.18222699989902152}
2023-01-04 05:14:57,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:57,702 INFO:     Epoch: 93
2023-01-04 05:14:59,331 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3784902448455493, 'Total loss': 0.3784902448455493} | train loss {'Reaction outcome loss': 0.17834598257246873, 'Total loss': 0.17834598257246873}
2023-01-04 05:14:59,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:14:59,332 INFO:     Epoch: 94
2023-01-04 05:15:00,950 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3957313577334086, 'Total loss': 0.3957313577334086} | train loss {'Reaction outcome loss': 0.18338754176640604, 'Total loss': 0.18338754176640604}
2023-01-04 05:15:00,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:00,950 INFO:     Epoch: 95
2023-01-04 05:15:02,573 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37567881494760513, 'Total loss': 0.37567881494760513} | train loss {'Reaction outcome loss': 0.1794615222699603, 'Total loss': 0.1794615222699603}
2023-01-04 05:15:02,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:02,573 INFO:     Epoch: 96
2023-01-04 05:15:04,199 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37402207106351854, 'Total loss': 0.37402207106351854} | train loss {'Reaction outcome loss': 0.1788471058526488, 'Total loss': 0.1788471058526488}
2023-01-04 05:15:04,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:04,199 INFO:     Epoch: 97
2023-01-04 05:15:05,788 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36761002937952675, 'Total loss': 0.36761002937952675} | train loss {'Reaction outcome loss': 0.1796403228675616, 'Total loss': 0.1796403228675616}
2023-01-04 05:15:05,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:05,789 INFO:     Epoch: 98
2023-01-04 05:15:07,376 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37005718251069386, 'Total loss': 0.37005718251069386} | train loss {'Reaction outcome loss': 0.17921552295540122, 'Total loss': 0.17921552295540122}
2023-01-04 05:15:07,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:07,376 INFO:     Epoch: 99
2023-01-04 05:15:08,976 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37907863159974414, 'Total loss': 0.37907863159974414} | train loss {'Reaction outcome loss': 0.17989844608582908, 'Total loss': 0.17989844608582908}
2023-01-04 05:15:08,976 INFO:     Best model found after epoch 38 of 100.
2023-01-04 05:15:08,977 INFO:   Done with stage: TRAINING
2023-01-04 05:15:08,977 INFO:   Starting stage: EVALUATION
2023-01-04 05:15:09,106 INFO:   Done with stage: EVALUATION
2023-01-04 05:15:09,106 INFO:   Leaving out SEQ value Fold_2
2023-01-04 05:15:09,118 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 05:15:09,118 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:15:09,744 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:15:09,744 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:15:09,811 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:15:09,811 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:15:09,811 INFO:     No hyperparam tuning for this model
2023-01-04 05:15:09,811 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:15:09,811 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:15:09,812 INFO:     None feature selector for col prot
2023-01-04 05:15:09,812 INFO:     None feature selector for col prot
2023-01-04 05:15:09,812 INFO:     None feature selector for col prot
2023-01-04 05:15:09,812 INFO:     None feature selector for col chem
2023-01-04 05:15:09,813 INFO:     None feature selector for col chem
2023-01-04 05:15:09,813 INFO:     None feature selector for col chem
2023-01-04 05:15:09,813 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:15:09,813 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:15:09,814 INFO:     Number of params in model 70141
2023-01-04 05:15:09,817 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:15:09,817 INFO:   Starting stage: TRAINING
2023-01-04 05:15:09,861 INFO:     Val loss before train {'Reaction outcome loss': 1.079506520430247, 'Total loss': 1.079506520430247}
2023-01-04 05:15:09,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:09,861 INFO:     Epoch: 0
2023-01-04 05:15:11,440 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7410775264104207, 'Total loss': 0.7410775264104207} | train loss {'Reaction outcome loss': 0.8580622828094722, 'Total loss': 0.8580622828094722}
2023-01-04 05:15:11,441 INFO:     Found new best model at epoch 0
2023-01-04 05:15:11,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:11,442 INFO:     Epoch: 1
2023-01-04 05:15:13,029 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.581766672929128, 'Total loss': 0.581766672929128} | train loss {'Reaction outcome loss': 0.619870349379923, 'Total loss': 0.619870349379923}
2023-01-04 05:15:13,030 INFO:     Found new best model at epoch 1
2023-01-04 05:15:13,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:13,030 INFO:     Epoch: 2
2023-01-04 05:15:14,601 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5302771210670472, 'Total loss': 0.5302771210670472} | train loss {'Reaction outcome loss': 0.5321432795251867, 'Total loss': 0.5321432795251867}
2023-01-04 05:15:14,601 INFO:     Found new best model at epoch 2
2023-01-04 05:15:14,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:14,602 INFO:     Epoch: 3
2023-01-04 05:15:16,158 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4800108939409256, 'Total loss': 0.4800108939409256} | train loss {'Reaction outcome loss': 0.48907066012880457, 'Total loss': 0.48907066012880457}
2023-01-04 05:15:16,158 INFO:     Found new best model at epoch 3
2023-01-04 05:15:16,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:16,159 INFO:     Epoch: 4
2023-01-04 05:15:17,735 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5049711227416992, 'Total loss': 0.5049711227416992} | train loss {'Reaction outcome loss': 0.4587372089444051, 'Total loss': 0.4587372089444051}
2023-01-04 05:15:17,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:17,735 INFO:     Epoch: 5
2023-01-04 05:15:19,313 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46934068500995635, 'Total loss': 0.46934068500995635} | train loss {'Reaction outcome loss': 0.439048391206678, 'Total loss': 0.439048391206678}
2023-01-04 05:15:19,313 INFO:     Found new best model at epoch 5
2023-01-04 05:15:19,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:19,314 INFO:     Epoch: 6
2023-01-04 05:15:20,890 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44665834804375965, 'Total loss': 0.44665834804375965} | train loss {'Reaction outcome loss': 0.42278250708241305, 'Total loss': 0.42278250708241305}
2023-01-04 05:15:20,890 INFO:     Found new best model at epoch 6
2023-01-04 05:15:20,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:20,891 INFO:     Epoch: 7
2023-01-04 05:15:22,466 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44571645855903624, 'Total loss': 0.44571645855903624} | train loss {'Reaction outcome loss': 0.40859437214272487, 'Total loss': 0.40859437214272487}
2023-01-04 05:15:22,466 INFO:     Found new best model at epoch 7
2023-01-04 05:15:22,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:22,467 INFO:     Epoch: 8
2023-01-04 05:15:24,022 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43667572339375815, 'Total loss': 0.43667572339375815} | train loss {'Reaction outcome loss': 0.3936891603623809, 'Total loss': 0.3936891603623809}
2023-01-04 05:15:24,023 INFO:     Found new best model at epoch 8
2023-01-04 05:15:24,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:24,023 INFO:     Epoch: 9
2023-01-04 05:15:25,578 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4339707334836324, 'Total loss': 0.4339707334836324} | train loss {'Reaction outcome loss': 0.3856975647356237, 'Total loss': 0.3856975647356237}
2023-01-04 05:15:25,578 INFO:     Found new best model at epoch 9
2023-01-04 05:15:25,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:25,579 INFO:     Epoch: 10
2023-01-04 05:15:27,164 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44962285955746967, 'Total loss': 0.44962285955746967} | train loss {'Reaction outcome loss': 0.3749582559915046, 'Total loss': 0.3749582559915046}
2023-01-04 05:15:27,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:27,164 INFO:     Epoch: 11
2023-01-04 05:15:28,755 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4196860979000727, 'Total loss': 0.4196860979000727} | train loss {'Reaction outcome loss': 0.36673318333511423, 'Total loss': 0.36673318333511423}
2023-01-04 05:15:28,756 INFO:     Found new best model at epoch 11
2023-01-04 05:15:28,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:28,757 INFO:     Epoch: 12
2023-01-04 05:15:30,316 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4089058548212051, 'Total loss': 0.4089058548212051} | train loss {'Reaction outcome loss': 0.359691152246016, 'Total loss': 0.359691152246016}
2023-01-04 05:15:30,316 INFO:     Found new best model at epoch 12
2023-01-04 05:15:30,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:30,317 INFO:     Epoch: 13
2023-01-04 05:15:31,910 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4286121199528376, 'Total loss': 0.4286121199528376} | train loss {'Reaction outcome loss': 0.35328391353802485, 'Total loss': 0.35328391353802485}
2023-01-04 05:15:31,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:31,910 INFO:     Epoch: 14
2023-01-04 05:15:33,477 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4188301533460617, 'Total loss': 0.4188301533460617} | train loss {'Reaction outcome loss': 0.3457888465965806, 'Total loss': 0.3457888465965806}
2023-01-04 05:15:33,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:33,478 INFO:     Epoch: 15
2023-01-04 05:15:35,046 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4139331122239431, 'Total loss': 0.4139331122239431} | train loss {'Reaction outcome loss': 0.33828251536701875, 'Total loss': 0.33828251536701875}
2023-01-04 05:15:35,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:35,047 INFO:     Epoch: 16
2023-01-04 05:15:36,607 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41175467570622765, 'Total loss': 0.41175467570622765} | train loss {'Reaction outcome loss': 0.33145404686787033, 'Total loss': 0.33145404686787033}
2023-01-04 05:15:36,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:36,607 INFO:     Epoch: 17
2023-01-04 05:15:38,201 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40516582926114403, 'Total loss': 0.40516582926114403} | train loss {'Reaction outcome loss': 0.32696012503766486, 'Total loss': 0.32696012503766486}
2023-01-04 05:15:38,201 INFO:     Found new best model at epoch 17
2023-01-04 05:15:38,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:38,202 INFO:     Epoch: 18
2023-01-04 05:15:39,796 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4292608439922333, 'Total loss': 0.4292608439922333} | train loss {'Reaction outcome loss': 0.3200568608472268, 'Total loss': 0.3200568608472268}
2023-01-04 05:15:39,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:39,796 INFO:     Epoch: 19
2023-01-04 05:15:41,369 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39949460079272586, 'Total loss': 0.39949460079272586} | train loss {'Reaction outcome loss': 0.31496425396401945, 'Total loss': 0.31496425396401945}
2023-01-04 05:15:41,369 INFO:     Found new best model at epoch 19
2023-01-04 05:15:41,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:41,370 INFO:     Epoch: 20
2023-01-04 05:15:42,945 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39627499245107173, 'Total loss': 0.39627499245107173} | train loss {'Reaction outcome loss': 0.3107249409070314, 'Total loss': 0.3107249409070314}
2023-01-04 05:15:42,945 INFO:     Found new best model at epoch 20
2023-01-04 05:15:42,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:42,946 INFO:     Epoch: 21
2023-01-04 05:15:44,562 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4524312178293864, 'Total loss': 0.4524312178293864} | train loss {'Reaction outcome loss': 0.30648612096300865, 'Total loss': 0.30648612096300865}
2023-01-04 05:15:44,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:44,562 INFO:     Epoch: 22
2023-01-04 05:15:46,166 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4451292266448339, 'Total loss': 0.4451292266448339} | train loss {'Reaction outcome loss': 0.302035814364238, 'Total loss': 0.302035814364238}
2023-01-04 05:15:46,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:46,166 INFO:     Epoch: 23
2023-01-04 05:15:47,766 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42477602461973823, 'Total loss': 0.42477602461973823} | train loss {'Reaction outcome loss': 0.29878069927771594, 'Total loss': 0.29878069927771594}
2023-01-04 05:15:47,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:47,767 INFO:     Epoch: 24
2023-01-04 05:15:49,344 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4052319943904877, 'Total loss': 0.4052319943904877} | train loss {'Reaction outcome loss': 0.29252424341286243, 'Total loss': 0.29252424341286243}
2023-01-04 05:15:49,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:49,344 INFO:     Epoch: 25
2023-01-04 05:15:50,897 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40348703861236573, 'Total loss': 0.40348703861236573} | train loss {'Reaction outcome loss': 0.28820744967878525, 'Total loss': 0.28820744967878525}
2023-01-04 05:15:50,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:50,897 INFO:     Epoch: 26
2023-01-04 05:15:52,450 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4331342776616414, 'Total loss': 0.4331342776616414} | train loss {'Reaction outcome loss': 0.2844392531362407, 'Total loss': 0.2844392531362407}
2023-01-04 05:15:52,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:52,451 INFO:     Epoch: 27
2023-01-04 05:15:54,026 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4306844353675842, 'Total loss': 0.4306844353675842} | train loss {'Reaction outcome loss': 0.27995589743901, 'Total loss': 0.27995589743901}
2023-01-04 05:15:54,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:54,027 INFO:     Epoch: 28
2023-01-04 05:15:55,603 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4335004876057307, 'Total loss': 0.4335004876057307} | train loss {'Reaction outcome loss': 0.27401972540080327, 'Total loss': 0.27401972540080327}
2023-01-04 05:15:55,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:55,604 INFO:     Epoch: 29
2023-01-04 05:15:57,183 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4181629498799642, 'Total loss': 0.4181629498799642} | train loss {'Reaction outcome loss': 0.274773044875957, 'Total loss': 0.274773044875957}
2023-01-04 05:15:57,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:57,183 INFO:     Epoch: 30
2023-01-04 05:15:58,763 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42543962597846985, 'Total loss': 0.42543962597846985} | train loss {'Reaction outcome loss': 0.2694015861987188, 'Total loss': 0.2694015861987188}
2023-01-04 05:15:58,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:15:58,763 INFO:     Epoch: 31
2023-01-04 05:16:00,312 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4275113930304845, 'Total loss': 0.4275113930304845} | train loss {'Reaction outcome loss': 0.26622195973497476, 'Total loss': 0.26622195973497476}
2023-01-04 05:16:00,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:00,312 INFO:     Epoch: 32
2023-01-04 05:16:01,896 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5054163912932078, 'Total loss': 0.5054163912932078} | train loss {'Reaction outcome loss': 0.2640098735305216, 'Total loss': 0.2640098735305216}
2023-01-04 05:16:01,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:01,896 INFO:     Epoch: 33
2023-01-04 05:16:03,501 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41368580162525176, 'Total loss': 0.41368580162525176} | train loss {'Reaction outcome loss': 0.25972435917581577, 'Total loss': 0.25972435917581577}
2023-01-04 05:16:03,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:03,501 INFO:     Epoch: 34
2023-01-04 05:16:05,098 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43693128004670145, 'Total loss': 0.43693128004670145} | train loss {'Reaction outcome loss': 0.2575506795183979, 'Total loss': 0.2575506795183979}
2023-01-04 05:16:05,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:05,100 INFO:     Epoch: 35
2023-01-04 05:16:06,663 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45475323994954425, 'Total loss': 0.45475323994954425} | train loss {'Reaction outcome loss': 0.2538239782421791, 'Total loss': 0.2538239782421791}
2023-01-04 05:16:06,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:06,663 INFO:     Epoch: 36
2023-01-04 05:16:08,256 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.427099801103274, 'Total loss': 0.427099801103274} | train loss {'Reaction outcome loss': 0.2519570912932118, 'Total loss': 0.2519570912932118}
2023-01-04 05:16:08,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:08,256 INFO:     Epoch: 37
2023-01-04 05:16:09,797 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43414402306079863, 'Total loss': 0.43414402306079863} | train loss {'Reaction outcome loss': 0.24858167795017636, 'Total loss': 0.24858167795017636}
2023-01-04 05:16:09,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:09,797 INFO:     Epoch: 38
2023-01-04 05:16:11,368 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42623188098271686, 'Total loss': 0.42623188098271686} | train loss {'Reaction outcome loss': 0.246131722117702, 'Total loss': 0.246131722117702}
2023-01-04 05:16:11,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:11,368 INFO:     Epoch: 39
2023-01-04 05:16:12,936 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44375416537125906, 'Total loss': 0.44375416537125906} | train loss {'Reaction outcome loss': 0.24397993567519963, 'Total loss': 0.24397993567519963}
2023-01-04 05:16:12,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:12,937 INFO:     Epoch: 40
2023-01-04 05:16:14,506 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4260421653588613, 'Total loss': 0.4260421653588613} | train loss {'Reaction outcome loss': 0.23961200647578468, 'Total loss': 0.23961200647578468}
2023-01-04 05:16:14,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:14,507 INFO:     Epoch: 41
2023-01-04 05:16:16,073 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4473513593276342, 'Total loss': 0.4473513593276342} | train loss {'Reaction outcome loss': 0.2393697573634971, 'Total loss': 0.2393697573634971}
2023-01-04 05:16:16,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:16,073 INFO:     Epoch: 42
2023-01-04 05:16:17,623 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4513160268465678, 'Total loss': 0.4513160268465678} | train loss {'Reaction outcome loss': 0.2347500221975615, 'Total loss': 0.2347500221975615}
2023-01-04 05:16:17,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:17,624 INFO:     Epoch: 43
2023-01-04 05:16:19,197 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49263510207335154, 'Total loss': 0.49263510207335154} | train loss {'Reaction outcome loss': 0.2362034251961541, 'Total loss': 0.2362034251961541}
2023-01-04 05:16:19,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:19,197 INFO:     Epoch: 44
2023-01-04 05:16:20,757 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42115645880500474, 'Total loss': 0.42115645880500474} | train loss {'Reaction outcome loss': 0.2306331132170899, 'Total loss': 0.2306331132170899}
2023-01-04 05:16:20,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:20,757 INFO:     Epoch: 45
2023-01-04 05:16:22,353 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44567760626475017, 'Total loss': 0.44567760626475017} | train loss {'Reaction outcome loss': 0.2303861332747989, 'Total loss': 0.2303861332747989}
2023-01-04 05:16:22,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:22,353 INFO:     Epoch: 46
2023-01-04 05:16:23,929 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4433968206246694, 'Total loss': 0.4433968206246694} | train loss {'Reaction outcome loss': 0.22591103666987805, 'Total loss': 0.22591103666987805}
2023-01-04 05:16:23,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:23,930 INFO:     Epoch: 47
2023-01-04 05:16:25,494 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45423746506373086, 'Total loss': 0.45423746506373086} | train loss {'Reaction outcome loss': 0.2265615311908326, 'Total loss': 0.2265615311908326}
2023-01-04 05:16:25,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:25,494 INFO:     Epoch: 48
2023-01-04 05:16:27,057 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4377468513014416, 'Total loss': 0.4377468513014416} | train loss {'Reaction outcome loss': 0.22370346811534733, 'Total loss': 0.22370346811534733}
2023-01-04 05:16:27,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:27,057 INFO:     Epoch: 49
2023-01-04 05:16:28,608 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43615993758042654, 'Total loss': 0.43615993758042654} | train loss {'Reaction outcome loss': 0.22083187525287765, 'Total loss': 0.22083187525287765}
2023-01-04 05:16:28,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:28,608 INFO:     Epoch: 50
2023-01-04 05:16:30,171 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4298511544863383, 'Total loss': 0.4298511544863383} | train loss {'Reaction outcome loss': 0.22126158960575987, 'Total loss': 0.22126158960575987}
2023-01-04 05:16:30,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:30,172 INFO:     Epoch: 51
2023-01-04 05:16:31,736 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4549253443876902, 'Total loss': 0.4549253443876902} | train loss {'Reaction outcome loss': 0.21682052377515174, 'Total loss': 0.21682052377515174}
2023-01-04 05:16:31,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:31,736 INFO:     Epoch: 52
2023-01-04 05:16:33,300 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43638486166795093, 'Total loss': 0.43638486166795093} | train loss {'Reaction outcome loss': 0.21812308207154274, 'Total loss': 0.21812308207154274}
2023-01-04 05:16:33,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:33,301 INFO:     Epoch: 53
2023-01-04 05:16:34,864 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46181378364562986, 'Total loss': 0.46181378364562986} | train loss {'Reaction outcome loss': 0.2151127539547607, 'Total loss': 0.2151127539547607}
2023-01-04 05:16:34,865 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:34,865 INFO:     Epoch: 54
2023-01-04 05:16:36,398 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44565294285615287, 'Total loss': 0.44565294285615287} | train loss {'Reaction outcome loss': 0.2145301990513432, 'Total loss': 0.2145301990513432}
2023-01-04 05:16:36,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:36,398 INFO:     Epoch: 55
2023-01-04 05:16:37,959 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42235871801773706, 'Total loss': 0.42235871801773706} | train loss {'Reaction outcome loss': 0.21145696076134915, 'Total loss': 0.21145696076134915}
2023-01-04 05:16:37,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:37,959 INFO:     Epoch: 56
2023-01-04 05:16:39,521 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4480843871831894, 'Total loss': 0.4480843871831894} | train loss {'Reaction outcome loss': 0.20910363086255274, 'Total loss': 0.20910363086255274}
2023-01-04 05:16:39,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:39,522 INFO:     Epoch: 57
2023-01-04 05:16:41,092 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.438425146540006, 'Total loss': 0.438425146540006} | train loss {'Reaction outcome loss': 0.20925719515039032, 'Total loss': 0.20925719515039032}
2023-01-04 05:16:41,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:41,092 INFO:     Epoch: 58
2023-01-04 05:16:42,690 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4691245953241984, 'Total loss': 0.4691245953241984} | train loss {'Reaction outcome loss': 0.20704709827844947, 'Total loss': 0.20704709827844947}
2023-01-04 05:16:42,690 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:42,691 INFO:     Epoch: 59
2023-01-04 05:16:44,267 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4390521456797918, 'Total loss': 0.4390521456797918} | train loss {'Reaction outcome loss': 0.20649530492530538, 'Total loss': 0.20649530492530538}
2023-01-04 05:16:44,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:44,267 INFO:     Epoch: 60
2023-01-04 05:16:45,816 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45285676618417103, 'Total loss': 0.45285676618417103} | train loss {'Reaction outcome loss': 0.205040730714688, 'Total loss': 0.205040730714688}
2023-01-04 05:16:45,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:45,816 INFO:     Epoch: 61
2023-01-04 05:16:47,415 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4422755133360624, 'Total loss': 0.4422755133360624} | train loss {'Reaction outcome loss': 0.20349687159171403, 'Total loss': 0.20349687159171403}
2023-01-04 05:16:47,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:47,415 INFO:     Epoch: 62
2023-01-04 05:16:48,983 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4432291650523742, 'Total loss': 0.4432291650523742} | train loss {'Reaction outcome loss': 0.20331350884424365, 'Total loss': 0.20331350884424365}
2023-01-04 05:16:48,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:48,984 INFO:     Epoch: 63
2023-01-04 05:16:50,552 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44915197292963666, 'Total loss': 0.44915197292963666} | train loss {'Reaction outcome loss': 0.20270686736845883, 'Total loss': 0.20270686736845883}
2023-01-04 05:16:50,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:50,553 INFO:     Epoch: 64
2023-01-04 05:16:52,121 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5131259351968765, 'Total loss': 0.5131259351968765} | train loss {'Reaction outcome loss': 0.19962062048846066, 'Total loss': 0.19962062048846066}
2023-01-04 05:16:52,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:52,121 INFO:     Epoch: 65
2023-01-04 05:16:53,674 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4846086392800013, 'Total loss': 0.4846086392800013} | train loss {'Reaction outcome loss': 0.19553730489747992, 'Total loss': 0.19553730489747992}
2023-01-04 05:16:53,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:53,674 INFO:     Epoch: 66
2023-01-04 05:16:55,249 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46608661909898125, 'Total loss': 0.46608661909898125} | train loss {'Reaction outcome loss': 0.1962220073021206, 'Total loss': 0.1962220073021206}
2023-01-04 05:16:55,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:55,249 INFO:     Epoch: 67
2023-01-04 05:16:56,831 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4582963764667511, 'Total loss': 0.4582963764667511} | train loss {'Reaction outcome loss': 0.19724489265977235, 'Total loss': 0.19724489265977235}
2023-01-04 05:16:56,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:56,832 INFO:     Epoch: 68
2023-01-04 05:16:58,440 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4673503816127777, 'Total loss': 0.4673503816127777} | train loss {'Reaction outcome loss': 0.19544260232705912, 'Total loss': 0.19544260232705912}
2023-01-04 05:16:58,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:16:58,440 INFO:     Epoch: 69
2023-01-04 05:17:00,033 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46802141865094504, 'Total loss': 0.46802141865094504} | train loss {'Reaction outcome loss': 0.19517145910716144, 'Total loss': 0.19517145910716144}
2023-01-04 05:17:00,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:00,033 INFO:     Epoch: 70
2023-01-04 05:17:01,637 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5087028195460638, 'Total loss': 0.5087028195460638} | train loss {'Reaction outcome loss': 0.19546261717087668, 'Total loss': 0.19546261717087668}
2023-01-04 05:17:01,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:01,638 INFO:     Epoch: 71
2023-01-04 05:17:03,194 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48117448190848033, 'Total loss': 0.48117448190848033} | train loss {'Reaction outcome loss': 0.1915517591104956, 'Total loss': 0.1915517591104956}
2023-01-04 05:17:03,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:03,194 INFO:     Epoch: 72
2023-01-04 05:17:04,780 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47695629398028055, 'Total loss': 0.47695629398028055} | train loss {'Reaction outcome loss': 0.191506223313208, 'Total loss': 0.191506223313208}
2023-01-04 05:17:04,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:04,781 INFO:     Epoch: 73
2023-01-04 05:17:06,380 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4479276925325394, 'Total loss': 0.4479276925325394} | train loss {'Reaction outcome loss': 0.18880697306781677, 'Total loss': 0.18880697306781677}
2023-01-04 05:17:06,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:06,380 INFO:     Epoch: 74
2023-01-04 05:17:07,982 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44014861493681867, 'Total loss': 0.44014861493681867} | train loss {'Reaction outcome loss': 0.18771271943372445, 'Total loss': 0.18771271943372445}
2023-01-04 05:17:07,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:07,982 INFO:     Epoch: 75
2023-01-04 05:17:09,585 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.502591269214948, 'Total loss': 0.502591269214948} | train loss {'Reaction outcome loss': 0.1895653861626378, 'Total loss': 0.1895653861626378}
2023-01-04 05:17:09,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:09,586 INFO:     Epoch: 76
2023-01-04 05:17:11,172 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4648139407237371, 'Total loss': 0.4648139407237371} | train loss {'Reaction outcome loss': 0.18832824880951446, 'Total loss': 0.18832824880951446}
2023-01-04 05:17:11,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:11,172 INFO:     Epoch: 77
2023-01-04 05:17:12,722 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.482478799422582, 'Total loss': 0.482478799422582} | train loss {'Reaction outcome loss': 0.18612947327349458, 'Total loss': 0.18612947327349458}
2023-01-04 05:17:12,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:12,722 INFO:     Epoch: 78
2023-01-04 05:17:14,290 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47644312381744386, 'Total loss': 0.47644312381744386} | train loss {'Reaction outcome loss': 0.18693398294551125, 'Total loss': 0.18693398294551125}
2023-01-04 05:17:14,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:14,290 INFO:     Epoch: 79
2023-01-04 05:17:15,859 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47034483154614765, 'Total loss': 0.47034483154614765} | train loss {'Reaction outcome loss': 0.1838952711477491, 'Total loss': 0.1838952711477491}
2023-01-04 05:17:15,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:15,860 INFO:     Epoch: 80
2023-01-04 05:17:17,444 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45623037169377006, 'Total loss': 0.45623037169377006} | train loss {'Reaction outcome loss': 0.18318386602720652, 'Total loss': 0.18318386602720652}
2023-01-04 05:17:17,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:17,445 INFO:     Epoch: 81
2023-01-04 05:17:19,039 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4603085219860077, 'Total loss': 0.4603085219860077} | train loss {'Reaction outcome loss': 0.1822195383290523, 'Total loss': 0.1822195383290523}
2023-01-04 05:17:19,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:19,039 INFO:     Epoch: 82
2023-01-04 05:17:20,602 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46764974196751913, 'Total loss': 0.46764974196751913} | train loss {'Reaction outcome loss': 0.18145891820592633, 'Total loss': 0.18145891820592633}
2023-01-04 05:17:20,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:20,602 INFO:     Epoch: 83
2023-01-04 05:17:22,164 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.464480992158254, 'Total loss': 0.464480992158254} | train loss {'Reaction outcome loss': 0.1819959805377955, 'Total loss': 0.1819959805377955}
2023-01-04 05:17:22,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:22,165 INFO:     Epoch: 84
2023-01-04 05:17:23,733 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45941566228866576, 'Total loss': 0.45941566228866576} | train loss {'Reaction outcome loss': 0.1822898714662258, 'Total loss': 0.1822898714662258}
2023-01-04 05:17:23,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:23,733 INFO:     Epoch: 85
2023-01-04 05:17:25,303 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5031946738560994, 'Total loss': 0.5031946738560994} | train loss {'Reaction outcome loss': 0.1817757165080067, 'Total loss': 0.1817757165080067}
2023-01-04 05:17:25,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:25,303 INFO:     Epoch: 86
2023-01-04 05:17:26,871 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48701767524083456, 'Total loss': 0.48701767524083456} | train loss {'Reaction outcome loss': 0.18264274583696438, 'Total loss': 0.18264274583696438}
2023-01-04 05:17:26,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:26,871 INFO:     Epoch: 87
2023-01-04 05:17:28,439 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4756767143805822, 'Total loss': 0.4756767143805822} | train loss {'Reaction outcome loss': 0.18084992536402056, 'Total loss': 0.18084992536402056}
2023-01-04 05:17:28,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:28,439 INFO:     Epoch: 88
2023-01-04 05:17:30,008 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4913688004016876, 'Total loss': 0.4913688004016876} | train loss {'Reaction outcome loss': 0.17953485353571463, 'Total loss': 0.17953485353571463}
2023-01-04 05:17:30,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:30,009 INFO:     Epoch: 89
2023-01-04 05:17:31,578 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49224345088005067, 'Total loss': 0.49224345088005067} | train loss {'Reaction outcome loss': 0.178053685900415, 'Total loss': 0.178053685900415}
2023-01-04 05:17:31,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:31,578 INFO:     Epoch: 90
2023-01-04 05:17:33,175 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48964283665021263, 'Total loss': 0.48964283665021263} | train loss {'Reaction outcome loss': 0.17632015013716756, 'Total loss': 0.17632015013716756}
2023-01-04 05:17:33,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:33,175 INFO:     Epoch: 91
2023-01-04 05:17:34,738 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46804028128584224, 'Total loss': 0.46804028128584224} | train loss {'Reaction outcome loss': 0.1787698933669122, 'Total loss': 0.1787698933669122}
2023-01-04 05:17:34,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:34,739 INFO:     Epoch: 92
2023-01-04 05:17:36,304 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46840910812218983, 'Total loss': 0.46840910812218983} | train loss {'Reaction outcome loss': 0.17357315266731702, 'Total loss': 0.17357315266731702}
2023-01-04 05:17:36,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:36,304 INFO:     Epoch: 93
2023-01-04 05:17:37,902 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4745591811835766, 'Total loss': 0.4745591811835766} | train loss {'Reaction outcome loss': 0.1745220164036399, 'Total loss': 0.1745220164036399}
2023-01-04 05:17:37,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:37,902 INFO:     Epoch: 94
2023-01-04 05:17:39,439 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48281280100345614, 'Total loss': 0.48281280100345614} | train loss {'Reaction outcome loss': 0.17637334878099362, 'Total loss': 0.17637334878099362}
2023-01-04 05:17:39,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:39,439 INFO:     Epoch: 95
2023-01-04 05:17:41,036 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48714433014392855, 'Total loss': 0.48714433014392855} | train loss {'Reaction outcome loss': 0.17460151706784413, 'Total loss': 0.17460151706784413}
2023-01-04 05:17:41,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:41,036 INFO:     Epoch: 96
2023-01-04 05:17:42,641 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4740245580673218, 'Total loss': 0.4740245580673218} | train loss {'Reaction outcome loss': 0.17272407466346376, 'Total loss': 0.17272407466346376}
2023-01-04 05:17:42,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:42,641 INFO:     Epoch: 97
2023-01-04 05:17:44,245 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.484870637813583, 'Total loss': 0.484870637813583} | train loss {'Reaction outcome loss': 0.17459321171182768, 'Total loss': 0.17459321171182768}
2023-01-04 05:17:44,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:44,245 INFO:     Epoch: 98
2023-01-04 05:17:45,806 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4944917897383372, 'Total loss': 0.4944917897383372} | train loss {'Reaction outcome loss': 0.17361755639562088, 'Total loss': 0.17361755639562088}
2023-01-04 05:17:45,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:45,806 INFO:     Epoch: 99
2023-01-04 05:17:47,381 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46965316037336985, 'Total loss': 0.46965316037336985} | train loss {'Reaction outcome loss': 0.17678085931772675, 'Total loss': 0.17678085931772675}
2023-01-04 05:17:47,383 INFO:     Best model found after epoch 21 of 100.
2023-01-04 05:17:47,383 INFO:   Done with stage: TRAINING
2023-01-04 05:17:47,383 INFO:   Starting stage: EVALUATION
2023-01-04 05:17:47,528 INFO:   Done with stage: EVALUATION
2023-01-04 05:17:47,528 INFO:   Leaving out SEQ value Fold_3
2023-01-04 05:17:47,541 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-04 05:17:47,541 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:17:48,188 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:17:48,188 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:17:48,253 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:17:48,254 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:17:48,254 INFO:     No hyperparam tuning for this model
2023-01-04 05:17:48,254 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:17:48,254 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:17:48,254 INFO:     None feature selector for col prot
2023-01-04 05:17:48,255 INFO:     None feature selector for col prot
2023-01-04 05:17:48,255 INFO:     None feature selector for col prot
2023-01-04 05:17:48,255 INFO:     None feature selector for col chem
2023-01-04 05:17:48,255 INFO:     None feature selector for col chem
2023-01-04 05:17:48,255 INFO:     None feature selector for col chem
2023-01-04 05:17:48,255 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:17:48,255 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:17:48,257 INFO:     Number of params in model 70141
2023-01-04 05:17:48,260 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:17:48,260 INFO:   Starting stage: TRAINING
2023-01-04 05:17:48,305 INFO:     Val loss before train {'Reaction outcome loss': 1.0892132560412089, 'Total loss': 1.0892132560412089}
2023-01-04 05:17:48,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:48,305 INFO:     Epoch: 0
2023-01-04 05:17:49,893 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6933038075764973, 'Total loss': 0.6933038075764973} | train loss {'Reaction outcome loss': 0.8365735764653041, 'Total loss': 0.8365735764653041}
2023-01-04 05:17:49,893 INFO:     Found new best model at epoch 0
2023-01-04 05:17:49,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:49,894 INFO:     Epoch: 1
2023-01-04 05:17:51,480 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5486980160077413, 'Total loss': 0.5486980160077413} | train loss {'Reaction outcome loss': 0.5907929747526935, 'Total loss': 0.5907929747526935}
2023-01-04 05:17:51,480 INFO:     Found new best model at epoch 1
2023-01-04 05:17:51,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:51,481 INFO:     Epoch: 2
2023-01-04 05:17:53,079 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.510862777630488, 'Total loss': 0.510862777630488} | train loss {'Reaction outcome loss': 0.5136268240609292, 'Total loss': 0.5136268240609292}
2023-01-04 05:17:53,079 INFO:     Found new best model at epoch 2
2023-01-04 05:17:53,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:53,080 INFO:     Epoch: 3
2023-01-04 05:17:54,676 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5000845114390056, 'Total loss': 0.5000845114390056} | train loss {'Reaction outcome loss': 0.47850425772341415, 'Total loss': 0.47850425772341415}
2023-01-04 05:17:54,677 INFO:     Found new best model at epoch 3
2023-01-04 05:17:54,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:54,678 INFO:     Epoch: 4
2023-01-04 05:17:56,244 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47658299704392754, 'Total loss': 0.47658299704392754} | train loss {'Reaction outcome loss': 0.4511833403713149, 'Total loss': 0.4511833403713149}
2023-01-04 05:17:56,245 INFO:     Found new best model at epoch 4
2023-01-04 05:17:56,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:56,245 INFO:     Epoch: 5
2023-01-04 05:17:57,803 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5119661569595337, 'Total loss': 0.5119661569595337} | train loss {'Reaction outcome loss': 0.43315317039120244, 'Total loss': 0.43315317039120244}
2023-01-04 05:17:57,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:57,803 INFO:     Epoch: 6
2023-01-04 05:17:59,386 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45008067091306053, 'Total loss': 0.45008067091306053} | train loss {'Reaction outcome loss': 0.4169318155279019, 'Total loss': 0.4169318155279019}
2023-01-04 05:17:59,386 INFO:     Found new best model at epoch 6
2023-01-04 05:17:59,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:17:59,387 INFO:     Epoch: 7
2023-01-04 05:18:00,971 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4368284293760856, 'Total loss': 0.4368284293760856} | train loss {'Reaction outcome loss': 0.39980126801891963, 'Total loss': 0.39980126801891963}
2023-01-04 05:18:00,971 INFO:     Found new best model at epoch 7
2023-01-04 05:18:00,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:00,972 INFO:     Epoch: 8
2023-01-04 05:18:02,560 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45958245793978375, 'Total loss': 0.45958245793978375} | train loss {'Reaction outcome loss': 0.3903334236178011, 'Total loss': 0.3903334236178011}
2023-01-04 05:18:02,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:02,560 INFO:     Epoch: 9
2023-01-04 05:18:04,151 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4363456914822261, 'Total loss': 0.4363456914822261} | train loss {'Reaction outcome loss': 0.3779442720802508, 'Total loss': 0.3779442720802508}
2023-01-04 05:18:04,151 INFO:     Found new best model at epoch 9
2023-01-04 05:18:04,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:04,152 INFO:     Epoch: 10
2023-01-04 05:18:05,702 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4266159137090047, 'Total loss': 0.4266159137090047} | train loss {'Reaction outcome loss': 0.3678340066732956, 'Total loss': 0.3678340066732956}
2023-01-04 05:18:05,702 INFO:     Found new best model at epoch 10
2023-01-04 05:18:05,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:05,703 INFO:     Epoch: 11
2023-01-04 05:18:07,278 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.451175527771314, 'Total loss': 0.451175527771314} | train loss {'Reaction outcome loss': 0.3577628949196576, 'Total loss': 0.3577628949196576}
2023-01-04 05:18:07,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:07,279 INFO:     Epoch: 12
2023-01-04 05:18:08,852 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44008907675743103, 'Total loss': 0.44008907675743103} | train loss {'Reaction outcome loss': 0.34951686600697435, 'Total loss': 0.34951686600697435}
2023-01-04 05:18:08,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:08,852 INFO:     Epoch: 13
2023-01-04 05:18:10,424 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4112631974120935, 'Total loss': 0.4112631974120935} | train loss {'Reaction outcome loss': 0.34167959422862837, 'Total loss': 0.34167959422862837}
2023-01-04 05:18:10,424 INFO:     Found new best model at epoch 13
2023-01-04 05:18:10,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:10,425 INFO:     Epoch: 14
2023-01-04 05:18:11,995 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43218757609526315, 'Total loss': 0.43218757609526315} | train loss {'Reaction outcome loss': 0.3356259288713061, 'Total loss': 0.3356259288713061}
2023-01-04 05:18:11,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:11,995 INFO:     Epoch: 15
2023-01-04 05:18:13,567 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4454471985499064, 'Total loss': 0.4454471985499064} | train loss {'Reaction outcome loss': 0.328639745794759, 'Total loss': 0.328639745794759}
2023-01-04 05:18:13,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:13,568 INFO:     Epoch: 16
2023-01-04 05:18:15,122 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43780687848726907, 'Total loss': 0.43780687848726907} | train loss {'Reaction outcome loss': 0.32140870342835287, 'Total loss': 0.32140870342835287}
2023-01-04 05:18:15,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:15,122 INFO:     Epoch: 17
2023-01-04 05:18:16,720 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4464608480532964, 'Total loss': 0.4464608480532964} | train loss {'Reaction outcome loss': 0.31597408283900513, 'Total loss': 0.31597408283900513}
2023-01-04 05:18:16,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:16,720 INFO:     Epoch: 18
2023-01-04 05:18:18,327 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4173739979664485, 'Total loss': 0.4173739979664485} | train loss {'Reaction outcome loss': 0.3099129732244569, 'Total loss': 0.3099129732244569}
2023-01-04 05:18:18,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:18,328 INFO:     Epoch: 19
2023-01-04 05:18:19,898 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.419636740287145, 'Total loss': 0.419636740287145} | train loss {'Reaction outcome loss': 0.3048880915415243, 'Total loss': 0.3048880915415243}
2023-01-04 05:18:19,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:19,899 INFO:     Epoch: 20
2023-01-04 05:18:21,470 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4035919566949209, 'Total loss': 0.4035919566949209} | train loss {'Reaction outcome loss': 0.2987024321657265, 'Total loss': 0.2987024321657265}
2023-01-04 05:18:21,470 INFO:     Found new best model at epoch 20
2023-01-04 05:18:21,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:21,471 INFO:     Epoch: 21
2023-01-04 05:18:23,029 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4110575278600057, 'Total loss': 0.4110575278600057} | train loss {'Reaction outcome loss': 0.29425659707001656, 'Total loss': 0.29425659707001656}
2023-01-04 05:18:23,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:23,030 INFO:     Epoch: 22
2023-01-04 05:18:24,573 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4370040655136108, 'Total loss': 0.4370040655136108} | train loss {'Reaction outcome loss': 0.28919049872023594, 'Total loss': 0.28919049872023594}
2023-01-04 05:18:24,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:24,573 INFO:     Epoch: 23
2023-01-04 05:18:26,170 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4232856233914693, 'Total loss': 0.4232856233914693} | train loss {'Reaction outcome loss': 0.28855274153041666, 'Total loss': 0.28855274153041666}
2023-01-04 05:18:26,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:26,170 INFO:     Epoch: 24
2023-01-04 05:18:27,758 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41063793301582335, 'Total loss': 0.41063793301582335} | train loss {'Reaction outcome loss': 0.2814827688395757, 'Total loss': 0.2814827688395757}
2023-01-04 05:18:27,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:27,759 INFO:     Epoch: 25
2023-01-04 05:18:29,333 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4512888818979263, 'Total loss': 0.4512888818979263} | train loss {'Reaction outcome loss': 0.27949952413895035, 'Total loss': 0.27949952413895035}
2023-01-04 05:18:29,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:29,334 INFO:     Epoch: 26
2023-01-04 05:18:30,907 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.446219132343928, 'Total loss': 0.446219132343928} | train loss {'Reaction outcome loss': 0.27594535448674345, 'Total loss': 0.27594535448674345}
2023-01-04 05:18:30,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:30,907 INFO:     Epoch: 27
2023-01-04 05:18:32,465 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40599484741687775, 'Total loss': 0.40599484741687775} | train loss {'Reaction outcome loss': 0.27048564542813497, 'Total loss': 0.27048564542813497}
2023-01-04 05:18:32,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:32,465 INFO:     Epoch: 28
2023-01-04 05:18:34,035 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.400127474963665, 'Total loss': 0.400127474963665} | train loss {'Reaction outcome loss': 0.2688965041644019, 'Total loss': 0.2688965041644019}
2023-01-04 05:18:34,035 INFO:     Found new best model at epoch 28
2023-01-04 05:18:34,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:34,036 INFO:     Epoch: 29
2023-01-04 05:18:35,601 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40995268325010936, 'Total loss': 0.40995268325010936} | train loss {'Reaction outcome loss': 0.26271066069602966, 'Total loss': 0.26271066069602966}
2023-01-04 05:18:35,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:35,602 INFO:     Epoch: 30
2023-01-04 05:18:37,211 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4285740822553635, 'Total loss': 0.4285740822553635} | train loss {'Reaction outcome loss': 0.2620948188254314, 'Total loss': 0.2620948188254314}
2023-01-04 05:18:37,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:37,212 INFO:     Epoch: 31
2023-01-04 05:18:38,804 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4322713494300842, 'Total loss': 0.4322713494300842} | train loss {'Reaction outcome loss': 0.2606080019935911, 'Total loss': 0.2606080019935911}
2023-01-04 05:18:38,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:38,804 INFO:     Epoch: 32
2023-01-04 05:18:40,385 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41923612728714943, 'Total loss': 0.41923612728714943} | train loss {'Reaction outcome loss': 0.2571314372314738, 'Total loss': 0.2571314372314738}
2023-01-04 05:18:40,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:40,385 INFO:     Epoch: 33
2023-01-04 05:18:41,945 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41185881992181145, 'Total loss': 0.41185881992181145} | train loss {'Reaction outcome loss': 0.25473809518552354, 'Total loss': 0.25473809518552354}
2023-01-04 05:18:41,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:41,946 INFO:     Epoch: 34
2023-01-04 05:18:43,513 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41023465245962143, 'Total loss': 0.41023465245962143} | train loss {'Reaction outcome loss': 0.24694322008378392, 'Total loss': 0.24694322008378392}
2023-01-04 05:18:43,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:43,513 INFO:     Epoch: 35
2023-01-04 05:18:45,109 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4134445130825043, 'Total loss': 0.4134445130825043} | train loss {'Reaction outcome loss': 0.24816919830232528, 'Total loss': 0.24816919830232528}
2023-01-04 05:18:45,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:45,109 INFO:     Epoch: 36
2023-01-04 05:18:46,715 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43174713452657065, 'Total loss': 0.43174713452657065} | train loss {'Reaction outcome loss': 0.24597179555640009, 'Total loss': 0.24597179555640009}
2023-01-04 05:18:46,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:46,716 INFO:     Epoch: 37
2023-01-04 05:18:48,312 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43142642577489215, 'Total loss': 0.43142642577489215} | train loss {'Reaction outcome loss': 0.24130201214628905, 'Total loss': 0.24130201214628905}
2023-01-04 05:18:48,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:48,312 INFO:     Epoch: 38
2023-01-04 05:18:49,914 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4117892081538836, 'Total loss': 0.4117892081538836} | train loss {'Reaction outcome loss': 0.2374848694131603, 'Total loss': 0.2374848694131603}
2023-01-04 05:18:49,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:49,914 INFO:     Epoch: 39
2023-01-04 05:18:51,456 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4312283158302307, 'Total loss': 0.4312283158302307} | train loss {'Reaction outcome loss': 0.2360432701137233, 'Total loss': 0.2360432701137233}
2023-01-04 05:18:51,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:51,456 INFO:     Epoch: 40
2023-01-04 05:18:53,054 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42977871298789977, 'Total loss': 0.42977871298789977} | train loss {'Reaction outcome loss': 0.23690918075587478, 'Total loss': 0.23690918075587478}
2023-01-04 05:18:53,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:53,054 INFO:     Epoch: 41
2023-01-04 05:18:54,651 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42155158817768096, 'Total loss': 0.42155158817768096} | train loss {'Reaction outcome loss': 0.23223717967082655, 'Total loss': 0.23223717967082655}
2023-01-04 05:18:54,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:54,652 INFO:     Epoch: 42
2023-01-04 05:18:56,251 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40591513104736804, 'Total loss': 0.40591513104736804} | train loss {'Reaction outcome loss': 0.23038001178430456, 'Total loss': 0.23038001178430456}
2023-01-04 05:18:56,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:56,251 INFO:     Epoch: 43
2023-01-04 05:18:57,849 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42954368591308595, 'Total loss': 0.42954368591308595} | train loss {'Reaction outcome loss': 0.22614663179510194, 'Total loss': 0.22614663179510194}
2023-01-04 05:18:57,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:57,850 INFO:     Epoch: 44
2023-01-04 05:18:59,420 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4243405371904373, 'Total loss': 0.4243405371904373} | train loss {'Reaction outcome loss': 0.22490097949370688, 'Total loss': 0.22490097949370688}
2023-01-04 05:18:59,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:18:59,420 INFO:     Epoch: 45
2023-01-04 05:19:00,996 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4513353963692983, 'Total loss': 0.4513353963692983} | train loss {'Reaction outcome loss': 0.22342733450481372, 'Total loss': 0.22342733450481372}
2023-01-04 05:19:00,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:00,996 INFO:     Epoch: 46
2023-01-04 05:19:02,595 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42985361615816753, 'Total loss': 0.42985361615816753} | train loss {'Reaction outcome loss': 0.21854631613761297, 'Total loss': 0.21854631613761297}
2023-01-04 05:19:02,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:02,596 INFO:     Epoch: 47
2023-01-04 05:19:04,176 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45704825123151144, 'Total loss': 0.45704825123151144} | train loss {'Reaction outcome loss': 0.21643146670447505, 'Total loss': 0.21643146670447505}
2023-01-04 05:19:04,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:04,177 INFO:     Epoch: 48
2023-01-04 05:19:05,726 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4229799012343089, 'Total loss': 0.4229799012343089} | train loss {'Reaction outcome loss': 0.21931516010712873, 'Total loss': 0.21931516010712873}
2023-01-04 05:19:05,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:05,726 INFO:     Epoch: 49
2023-01-04 05:19:07,323 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44492408633232117, 'Total loss': 0.44492408633232117} | train loss {'Reaction outcome loss': 0.21304690473578952, 'Total loss': 0.21304690473578952}
2023-01-04 05:19:07,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:07,323 INFO:     Epoch: 50
2023-01-04 05:19:08,893 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43368081251780194, 'Total loss': 0.43368081251780194} | train loss {'Reaction outcome loss': 0.21127310554699705, 'Total loss': 0.21127310554699705}
2023-01-04 05:19:08,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:08,893 INFO:     Epoch: 51
2023-01-04 05:19:10,474 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44386894156535467, 'Total loss': 0.44386894156535467} | train loss {'Reaction outcome loss': 0.20905556274076229, 'Total loss': 0.20905556274076229}
2023-01-04 05:19:10,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:10,474 INFO:     Epoch: 52
2023-01-04 05:19:12,059 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45888825356960294, 'Total loss': 0.45888825356960294} | train loss {'Reaction outcome loss': 0.21019388595080463, 'Total loss': 0.21019388595080463}
2023-01-04 05:19:12,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:12,059 INFO:     Epoch: 53
2023-01-04 05:19:13,651 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46769996285438536, 'Total loss': 0.46769996285438536} | train loss {'Reaction outcome loss': 0.2083695684714291, 'Total loss': 0.2083695684714291}
2023-01-04 05:19:13,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:13,651 INFO:     Epoch: 54
2023-01-04 05:19:15,227 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4197083741426468, 'Total loss': 0.4197083741426468} | train loss {'Reaction outcome loss': 0.20516829332852277, 'Total loss': 0.20516829332852277}
2023-01-04 05:19:15,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:15,227 INFO:     Epoch: 55
2023-01-04 05:19:16,820 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44212130109469094, 'Total loss': 0.44212130109469094} | train loss {'Reaction outcome loss': 0.2036074222343874, 'Total loss': 0.2036074222343874}
2023-01-04 05:19:16,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:16,821 INFO:     Epoch: 56
2023-01-04 05:19:18,343 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43392581393321356, 'Total loss': 0.43392581393321356} | train loss {'Reaction outcome loss': 0.20215862552288275, 'Total loss': 0.20215862552288275}
2023-01-04 05:19:18,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:18,343 INFO:     Epoch: 57
2023-01-04 05:19:19,953 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4691174556811651, 'Total loss': 0.4691174556811651} | train loss {'Reaction outcome loss': 0.20133519596746707, 'Total loss': 0.20133519596746707}
2023-01-04 05:19:19,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:19,954 INFO:     Epoch: 58
2023-01-04 05:19:21,565 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44217116038004556, 'Total loss': 0.44217116038004556} | train loss {'Reaction outcome loss': 0.20080807207090387, 'Total loss': 0.20080807207090387}
2023-01-04 05:19:21,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:21,565 INFO:     Epoch: 59
2023-01-04 05:19:23,168 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46256268421808877, 'Total loss': 0.46256268421808877} | train loss {'Reaction outcome loss': 0.20153792004523682, 'Total loss': 0.20153792004523682}
2023-01-04 05:19:23,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:23,169 INFO:     Epoch: 60
2023-01-04 05:19:24,782 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4522583335638046, 'Total loss': 0.4522583335638046} | train loss {'Reaction outcome loss': 0.1955003266624859, 'Total loss': 0.1955003266624859}
2023-01-04 05:19:24,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:24,782 INFO:     Epoch: 61
2023-01-04 05:19:26,365 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46570276419321693, 'Total loss': 0.46570276419321693} | train loss {'Reaction outcome loss': 0.19354592310436539, 'Total loss': 0.19354592310436539}
2023-01-04 05:19:26,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:26,365 INFO:     Epoch: 62
2023-01-04 05:19:27,946 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45509359141190847, 'Total loss': 0.45509359141190847} | train loss {'Reaction outcome loss': 0.19322926672072427, 'Total loss': 0.19322926672072427}
2023-01-04 05:19:27,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:27,946 INFO:     Epoch: 63
2023-01-04 05:19:29,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44738389551639557, 'Total loss': 0.44738389551639557} | train loss {'Reaction outcome loss': 0.19108760140396353, 'Total loss': 0.19108760140396353}
2023-01-04 05:19:29,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:29,551 INFO:     Epoch: 64
2023-01-04 05:19:31,100 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5068127185106277, 'Total loss': 0.5068127185106277} | train loss {'Reaction outcome loss': 0.18890782921640306, 'Total loss': 0.18890782921640306}
2023-01-04 05:19:31,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:31,100 INFO:     Epoch: 65
2023-01-04 05:19:32,694 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4643422822157542, 'Total loss': 0.4643422822157542} | train loss {'Reaction outcome loss': 0.1883419267627036, 'Total loss': 0.1883419267627036}
2023-01-04 05:19:32,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:32,695 INFO:     Epoch: 66
2023-01-04 05:19:34,284 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48210480908552805, 'Total loss': 0.48210480908552805} | train loss {'Reaction outcome loss': 0.18628866680488815, 'Total loss': 0.18628866680488815}
2023-01-04 05:19:34,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:34,285 INFO:     Epoch: 67
2023-01-04 05:19:35,702 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47184361616770426, 'Total loss': 0.47184361616770426} | train loss {'Reaction outcome loss': 0.18683758275617754, 'Total loss': 0.18683758275617754}
2023-01-04 05:19:35,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:35,702 INFO:     Epoch: 68
2023-01-04 05:19:36,749 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47890666921933495, 'Total loss': 0.47890666921933495} | train loss {'Reaction outcome loss': 0.1846574883894287, 'Total loss': 0.1846574883894287}
2023-01-04 05:19:36,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:36,750 INFO:     Epoch: 69
2023-01-04 05:19:37,802 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4678305109341939, 'Total loss': 0.4678305109341939} | train loss {'Reaction outcome loss': 0.18369930262275289, 'Total loss': 0.18369930262275289}
2023-01-04 05:19:37,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:37,802 INFO:     Epoch: 70
2023-01-04 05:19:38,856 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47774571577707925, 'Total loss': 0.47774571577707925} | train loss {'Reaction outcome loss': 0.1796424614808546, 'Total loss': 0.1796424614808546}
2023-01-04 05:19:38,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:38,856 INFO:     Epoch: 71
2023-01-04 05:19:39,947 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4718078007300695, 'Total loss': 0.4718078007300695} | train loss {'Reaction outcome loss': 0.18015492629136107, 'Total loss': 0.18015492629136107}
2023-01-04 05:19:39,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:39,947 INFO:     Epoch: 72
2023-01-04 05:19:41,537 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4373954303562641, 'Total loss': 0.4373954303562641} | train loss {'Reaction outcome loss': 0.17956667485547242, 'Total loss': 0.17956667485547242}
2023-01-04 05:19:41,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:41,538 INFO:     Epoch: 73
2023-01-04 05:19:43,126 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4680408259232839, 'Total loss': 0.4680408259232839} | train loss {'Reaction outcome loss': 0.17785375984557442, 'Total loss': 0.17785375984557442}
2023-01-04 05:19:43,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:43,127 INFO:     Epoch: 74
2023-01-04 05:19:44,683 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.459524933497111, 'Total loss': 0.459524933497111} | train loss {'Reaction outcome loss': 0.1779703529572245, 'Total loss': 0.1779703529572245}
2023-01-04 05:19:44,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:44,683 INFO:     Epoch: 75
2023-01-04 05:19:46,300 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4713419089714686, 'Total loss': 0.4713419089714686} | train loss {'Reaction outcome loss': 0.17554601015200033, 'Total loss': 0.17554601015200033}
2023-01-04 05:19:46,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:46,300 INFO:     Epoch: 76
2023-01-04 05:19:47,892 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4656940490007401, 'Total loss': 0.4656940490007401} | train loss {'Reaction outcome loss': 0.1750842627220378, 'Total loss': 0.1750842627220378}
2023-01-04 05:19:47,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:47,893 INFO:     Epoch: 77
2023-01-04 05:19:49,468 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46372803300619125, 'Total loss': 0.46372803300619125} | train loss {'Reaction outcome loss': 0.1733625617593087, 'Total loss': 0.1733625617593087}
2023-01-04 05:19:49,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:49,468 INFO:     Epoch: 78
2023-01-04 05:19:51,088 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4796140412489573, 'Total loss': 0.4796140412489573} | train loss {'Reaction outcome loss': 0.17395564102708633, 'Total loss': 0.17395564102708633}
2023-01-04 05:19:51,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:51,089 INFO:     Epoch: 79
2023-01-04 05:19:52,696 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4958263913790385, 'Total loss': 0.4958263913790385} | train loss {'Reaction outcome loss': 0.168556796582725, 'Total loss': 0.168556796582725}
2023-01-04 05:19:52,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:52,697 INFO:     Epoch: 80
2023-01-04 05:19:54,310 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.465414274421831, 'Total loss': 0.465414274421831} | train loss {'Reaction outcome loss': 0.17069477346000636, 'Total loss': 0.17069477346000636}
2023-01-04 05:19:54,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:54,311 INFO:     Epoch: 81
2023-01-04 05:19:55,918 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.514792087674141, 'Total loss': 0.514792087674141} | train loss {'Reaction outcome loss': 0.16967199936619104, 'Total loss': 0.16967199936619104}
2023-01-04 05:19:55,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:55,918 INFO:     Epoch: 82
2023-01-04 05:19:57,524 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47562250345945356, 'Total loss': 0.47562250345945356} | train loss {'Reaction outcome loss': 0.17046765756288138, 'Total loss': 0.17046765756288138}
2023-01-04 05:19:57,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:57,524 INFO:     Epoch: 83
2023-01-04 05:19:59,075 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4839187820752462, 'Total loss': 0.4839187820752462} | train loss {'Reaction outcome loss': 0.16769898774933992, 'Total loss': 0.16769898774933992}
2023-01-04 05:19:59,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:19:59,076 INFO:     Epoch: 84
2023-01-04 05:20:00,644 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4855995446443558, 'Total loss': 0.4855995446443558} | train loss {'Reaction outcome loss': 0.16751298984698265, 'Total loss': 0.16751298984698265}
2023-01-04 05:20:00,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:00,644 INFO:     Epoch: 85
2023-01-04 05:20:02,209 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4822479406992594, 'Total loss': 0.4822479406992594} | train loss {'Reaction outcome loss': 0.16542787262241998, 'Total loss': 0.16542787262241998}
2023-01-04 05:20:02,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:02,209 INFO:     Epoch: 86
2023-01-04 05:20:03,806 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4916016767422358, 'Total loss': 0.4916016767422358} | train loss {'Reaction outcome loss': 0.1658411164084154, 'Total loss': 0.1658411164084154}
2023-01-04 05:20:03,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:03,807 INFO:     Epoch: 87
2023-01-04 05:20:05,404 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4800066463649273, 'Total loss': 0.4800066463649273} | train loss {'Reaction outcome loss': 0.16463686616548312, 'Total loss': 0.16463686616548312}
2023-01-04 05:20:05,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:05,405 INFO:     Epoch: 88
2023-01-04 05:20:06,958 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49282344182332355, 'Total loss': 0.49282344182332355} | train loss {'Reaction outcome loss': 0.16408524879450287, 'Total loss': 0.16408524879450287}
2023-01-04 05:20:06,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:06,958 INFO:     Epoch: 89
2023-01-04 05:20:08,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4967280725638072, 'Total loss': 0.4967280725638072} | train loss {'Reaction outcome loss': 0.16386003357210502, 'Total loss': 0.16386003357210502}
2023-01-04 05:20:08,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:08,515 INFO:     Epoch: 90
2023-01-04 05:20:10,111 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5266769508520762, 'Total loss': 0.5266769508520762} | train loss {'Reaction outcome loss': 0.1620752132700488, 'Total loss': 0.1620752132700488}
2023-01-04 05:20:10,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:10,111 INFO:     Epoch: 91
2023-01-04 05:20:11,667 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.515552235643069, 'Total loss': 0.515552235643069} | train loss {'Reaction outcome loss': 0.16280940832824506, 'Total loss': 0.16280940832824506}
2023-01-04 05:20:11,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:11,668 INFO:     Epoch: 92
2023-01-04 05:20:13,220 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4820559074481328, 'Total loss': 0.4820559074481328} | train loss {'Reaction outcome loss': 0.16041819949898992, 'Total loss': 0.16041819949898992}
2023-01-04 05:20:13,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:13,221 INFO:     Epoch: 93
2023-01-04 05:20:14,819 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5674981753031413, 'Total loss': 0.5674981753031413} | train loss {'Reaction outcome loss': 0.15881766210141768, 'Total loss': 0.15881766210141768}
2023-01-04 05:20:14,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:14,819 INFO:     Epoch: 94
2023-01-04 05:20:16,404 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47764672540749115, 'Total loss': 0.47764672540749115} | train loss {'Reaction outcome loss': 0.1598761715407301, 'Total loss': 0.1598761715407301}
2023-01-04 05:20:16,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:16,405 INFO:     Epoch: 95
2023-01-04 05:20:17,973 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5113417406876882, 'Total loss': 0.5113417406876882} | train loss {'Reaction outcome loss': 0.15767043841336045, 'Total loss': 0.15767043841336045}
2023-01-04 05:20:17,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:17,973 INFO:     Epoch: 96
2023-01-04 05:20:19,520 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.514950015147527, 'Total loss': 0.514950015147527} | train loss {'Reaction outcome loss': 0.15828535843956734, 'Total loss': 0.15828535843956734}
2023-01-04 05:20:19,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:19,520 INFO:     Epoch: 97
2023-01-04 05:20:21,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5329111456871033, 'Total loss': 0.5329111456871033} | train loss {'Reaction outcome loss': 0.15985432272000286, 'Total loss': 0.15985432272000286}
2023-01-04 05:20:21,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:21,137 INFO:     Epoch: 98
2023-01-04 05:20:22,732 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5048668523629506, 'Total loss': 0.5048668523629506} | train loss {'Reaction outcome loss': 0.1568727445998315, 'Total loss': 0.1568727445998315}
2023-01-04 05:20:22,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:22,733 INFO:     Epoch: 99
2023-01-04 05:20:24,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5358564118544261, 'Total loss': 0.5358564118544261} | train loss {'Reaction outcome loss': 0.15627989997723005, 'Total loss': 0.15627989997723005}
2023-01-04 05:20:24,330 INFO:     Best model found after epoch 29 of 100.
2023-01-04 05:20:24,330 INFO:   Done with stage: TRAINING
2023-01-04 05:20:24,330 INFO:   Starting stage: EVALUATION
2023-01-04 05:20:24,477 INFO:   Done with stage: EVALUATION
2023-01-04 05:20:24,477 INFO:   Leaving out SEQ value Fold_4
2023-01-04 05:20:24,490 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:20:24,490 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:20:25,140 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:20:25,141 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:20:25,208 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:20:25,208 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:20:25,208 INFO:     No hyperparam tuning for this model
2023-01-04 05:20:25,209 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:20:25,209 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:20:25,209 INFO:     None feature selector for col prot
2023-01-04 05:20:25,209 INFO:     None feature selector for col prot
2023-01-04 05:20:25,210 INFO:     None feature selector for col prot
2023-01-04 05:20:25,210 INFO:     None feature selector for col chem
2023-01-04 05:20:25,210 INFO:     None feature selector for col chem
2023-01-04 05:20:25,210 INFO:     None feature selector for col chem
2023-01-04 05:20:25,210 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:20:25,210 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:20:25,211 INFO:     Number of params in model 70141
2023-01-04 05:20:25,215 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:20:25,215 INFO:   Starting stage: TRAINING
2023-01-04 05:20:25,259 INFO:     Val loss before train {'Reaction outcome loss': 0.9071758071581523, 'Total loss': 0.9071758071581523}
2023-01-04 05:20:25,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:25,260 INFO:     Epoch: 0
2023-01-04 05:20:26,846 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6631538271903992, 'Total loss': 0.6631538271903992} | train loss {'Reaction outcome loss': 0.8505370350090605, 'Total loss': 0.8505370350090605}
2023-01-04 05:20:26,846 INFO:     Found new best model at epoch 0
2023-01-04 05:20:26,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:26,847 INFO:     Epoch: 1
2023-01-04 05:20:28,437 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.552765832344691, 'Total loss': 0.552765832344691} | train loss {'Reaction outcome loss': 0.6175347027580661, 'Total loss': 0.6175347027580661}
2023-01-04 05:20:28,437 INFO:     Found new best model at epoch 1
2023-01-04 05:20:28,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:28,438 INFO:     Epoch: 2
2023-01-04 05:20:30,044 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49996047616004946, 'Total loss': 0.49996047616004946} | train loss {'Reaction outcome loss': 0.5317231642102507, 'Total loss': 0.5317231642102507}
2023-01-04 05:20:30,044 INFO:     Found new best model at epoch 2
2023-01-04 05:20:30,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:30,045 INFO:     Epoch: 3
2023-01-04 05:20:31,651 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4881295402844747, 'Total loss': 0.4881295402844747} | train loss {'Reaction outcome loss': 0.4912975497194146, 'Total loss': 0.4912975497194146}
2023-01-04 05:20:31,651 INFO:     Found new best model at epoch 3
2023-01-04 05:20:31,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:31,652 INFO:     Epoch: 4
2023-01-04 05:20:33,259 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45838966568311057, 'Total loss': 0.45838966568311057} | train loss {'Reaction outcome loss': 0.4648851366034484, 'Total loss': 0.4648851366034484}
2023-01-04 05:20:33,259 INFO:     Found new best model at epoch 4
2023-01-04 05:20:33,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:33,260 INFO:     Epoch: 5
2023-01-04 05:20:34,851 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47052783370018003, 'Total loss': 0.47052783370018003} | train loss {'Reaction outcome loss': 0.44264192744712966, 'Total loss': 0.44264192744712966}
2023-01-04 05:20:34,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:34,851 INFO:     Epoch: 6
2023-01-04 05:20:36,458 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46249382694562274, 'Total loss': 0.46249382694562274} | train loss {'Reaction outcome loss': 0.4242569092486309, 'Total loss': 0.4242569092486309}
2023-01-04 05:20:36,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:36,458 INFO:     Epoch: 7
2023-01-04 05:20:38,044 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4233382632335027, 'Total loss': 0.4233382632335027} | train loss {'Reaction outcome loss': 0.4085205705695204, 'Total loss': 0.4085205705695204}
2023-01-04 05:20:38,045 INFO:     Found new best model at epoch 7
2023-01-04 05:20:38,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:38,045 INFO:     Epoch: 8
2023-01-04 05:20:39,656 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4151461581389109, 'Total loss': 0.4151461581389109} | train loss {'Reaction outcome loss': 0.3968634591959013, 'Total loss': 0.3968634591959013}
2023-01-04 05:20:39,657 INFO:     Found new best model at epoch 8
2023-01-04 05:20:39,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:39,657 INFO:     Epoch: 9
2023-01-04 05:20:41,266 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4204275111357371, 'Total loss': 0.4204275111357371} | train loss {'Reaction outcome loss': 0.38451385492667395, 'Total loss': 0.38451385492667395}
2023-01-04 05:20:41,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:41,267 INFO:     Epoch: 10
2023-01-04 05:20:42,858 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41799313624699913, 'Total loss': 0.41799313624699913} | train loss {'Reaction outcome loss': 0.3755577319042777, 'Total loss': 0.3755577319042777}
2023-01-04 05:20:42,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:42,858 INFO:     Epoch: 11
2023-01-04 05:20:44,489 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4134813606739044, 'Total loss': 0.4134813606739044} | train loss {'Reaction outcome loss': 0.36774507885805535, 'Total loss': 0.36774507885805535}
2023-01-04 05:20:44,490 INFO:     Found new best model at epoch 11
2023-01-04 05:20:44,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:44,491 INFO:     Epoch: 12
2023-01-04 05:20:46,089 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3979456434647242, 'Total loss': 0.3979456434647242} | train loss {'Reaction outcome loss': 0.35939178785262127, 'Total loss': 0.35939178785262127}
2023-01-04 05:20:46,089 INFO:     Found new best model at epoch 12
2023-01-04 05:20:46,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:46,090 INFO:     Epoch: 13
2023-01-04 05:20:47,700 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41987683773040774, 'Total loss': 0.41987683773040774} | train loss {'Reaction outcome loss': 0.35283398173668756, 'Total loss': 0.35283398173668756}
2023-01-04 05:20:47,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:47,701 INFO:     Epoch: 14
2023-01-04 05:20:49,311 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4034595489501953, 'Total loss': 0.4034595489501953} | train loss {'Reaction outcome loss': 0.3437494005913769, 'Total loss': 0.3437494005913769}
2023-01-04 05:20:49,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:49,311 INFO:     Epoch: 15
2023-01-04 05:20:50,941 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41779671708742777, 'Total loss': 0.41779671708742777} | train loss {'Reaction outcome loss': 0.33750809452056024, 'Total loss': 0.33750809452056024}
2023-01-04 05:20:50,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:50,941 INFO:     Epoch: 16
2023-01-04 05:20:52,547 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40154639979203544, 'Total loss': 0.40154639979203544} | train loss {'Reaction outcome loss': 0.33075626606007347, 'Total loss': 0.33075626606007347}
2023-01-04 05:20:52,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:52,547 INFO:     Epoch: 17
2023-01-04 05:20:54,156 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39913177688916524, 'Total loss': 0.39913177688916524} | train loss {'Reaction outcome loss': 0.3240268030052581, 'Total loss': 0.3240268030052581}
2023-01-04 05:20:54,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:54,157 INFO:     Epoch: 18
2023-01-04 05:20:55,759 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4207988719145457, 'Total loss': 0.4207988719145457} | train loss {'Reaction outcome loss': 0.3200338002738109, 'Total loss': 0.3200338002738109}
2023-01-04 05:20:55,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:55,759 INFO:     Epoch: 19
2023-01-04 05:20:57,386 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4099433898925781, 'Total loss': 0.4099433898925781} | train loss {'Reaction outcome loss': 0.3161313551535245, 'Total loss': 0.3161313551535245}
2023-01-04 05:20:57,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:57,386 INFO:     Epoch: 20
2023-01-04 05:20:59,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39382736682891845, 'Total loss': 0.39382736682891845} | train loss {'Reaction outcome loss': 0.312252016677538, 'Total loss': 0.312252016677538}
2023-01-04 05:20:59,019 INFO:     Found new best model at epoch 20
2023-01-04 05:20:59,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:20:59,020 INFO:     Epoch: 21
2023-01-04 05:21:00,647 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41289336880048116, 'Total loss': 0.41289336880048116} | train loss {'Reaction outcome loss': 0.3063816313870547, 'Total loss': 0.3063816313870547}
2023-01-04 05:21:00,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:00,648 INFO:     Epoch: 22
2023-01-04 05:21:02,280 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39237464865048727, 'Total loss': 0.39237464865048727} | train loss {'Reaction outcome loss': 0.3021926946588372, 'Total loss': 0.3021926946588372}
2023-01-04 05:21:02,280 INFO:     Found new best model at epoch 22
2023-01-04 05:21:02,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:02,281 INFO:     Epoch: 23
2023-01-04 05:21:03,923 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4045446336269379, 'Total loss': 0.4045446336269379} | train loss {'Reaction outcome loss': 0.2989868826437943, 'Total loss': 0.2989868826437943}
2023-01-04 05:21:03,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:03,923 INFO:     Epoch: 24
2023-01-04 05:21:05,524 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4143515884876251, 'Total loss': 0.4143515884876251} | train loss {'Reaction outcome loss': 0.29371011956504106, 'Total loss': 0.29371011956504106}
2023-01-04 05:21:05,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:05,525 INFO:     Epoch: 25
2023-01-04 05:21:07,127 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39595781366030375, 'Total loss': 0.39595781366030375} | train loss {'Reaction outcome loss': 0.2877602952159269, 'Total loss': 0.2877602952159269}
2023-01-04 05:21:07,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:07,127 INFO:     Epoch: 26
2023-01-04 05:21:08,745 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4073196709156036, 'Total loss': 0.4073196709156036} | train loss {'Reaction outcome loss': 0.28674044024320283, 'Total loss': 0.28674044024320283}
2023-01-04 05:21:08,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:08,745 INFO:     Epoch: 27
2023-01-04 05:21:10,348 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3963171601295471, 'Total loss': 0.3963171601295471} | train loss {'Reaction outcome loss': 0.2817157378642137, 'Total loss': 0.2817157378642137}
2023-01-04 05:21:10,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:10,348 INFO:     Epoch: 28
2023-01-04 05:21:11,950 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3974197208881378, 'Total loss': 0.3974197208881378} | train loss {'Reaction outcome loss': 0.2807602560423341, 'Total loss': 0.2807602560423341}
2023-01-04 05:21:11,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:11,950 INFO:     Epoch: 29
2023-01-04 05:21:13,548 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3870660215616226, 'Total loss': 0.3870660215616226} | train loss {'Reaction outcome loss': 0.2761845430258379, 'Total loss': 0.2761845430258379}
2023-01-04 05:21:13,548 INFO:     Found new best model at epoch 29
2023-01-04 05:21:13,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:13,549 INFO:     Epoch: 30
2023-01-04 05:21:15,195 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.403361443678538, 'Total loss': 0.403361443678538} | train loss {'Reaction outcome loss': 0.2730864068015818, 'Total loss': 0.2730864068015818}
2023-01-04 05:21:15,195 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:15,196 INFO:     Epoch: 31
2023-01-04 05:21:16,832 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.403983810544014, 'Total loss': 0.403983810544014} | train loss {'Reaction outcome loss': 0.27053114076545093, 'Total loss': 0.27053114076545093}
2023-01-04 05:21:16,833 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:16,833 INFO:     Epoch: 32
2023-01-04 05:21:18,440 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4006548305352529, 'Total loss': 0.4006548305352529} | train loss {'Reaction outcome loss': 0.2657275330208054, 'Total loss': 0.2657275330208054}
2023-01-04 05:21:18,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:18,440 INFO:     Epoch: 33
2023-01-04 05:21:20,035 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41332652370134987, 'Total loss': 0.41332652370134987} | train loss {'Reaction outcome loss': 0.2636893401426744, 'Total loss': 0.2636893401426744}
2023-01-04 05:21:20,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:20,035 INFO:     Epoch: 34
2023-01-04 05:21:21,687 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4234732280174891, 'Total loss': 0.4234732280174891} | train loss {'Reaction outcome loss': 0.2622597630165975, 'Total loss': 0.2622597630165975}
2023-01-04 05:21:21,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:21,687 INFO:     Epoch: 35
2023-01-04 05:21:23,273 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41032004952430723, 'Total loss': 0.41032004952430723} | train loss {'Reaction outcome loss': 0.25730028267048755, 'Total loss': 0.25730028267048755}
2023-01-04 05:21:23,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:23,274 INFO:     Epoch: 36
2023-01-04 05:21:24,878 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4185323039690653, 'Total loss': 0.4185323039690653} | train loss {'Reaction outcome loss': 0.25709856761491684, 'Total loss': 0.25709856761491684}
2023-01-04 05:21:24,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:24,878 INFO:     Epoch: 37
2023-01-04 05:21:26,484 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39808279077212017, 'Total loss': 0.39808279077212017} | train loss {'Reaction outcome loss': 0.25379598450036683, 'Total loss': 0.25379598450036683}
2023-01-04 05:21:26,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:26,485 INFO:     Epoch: 38
2023-01-04 05:21:28,073 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40464498003323873, 'Total loss': 0.40464498003323873} | train loss {'Reaction outcome loss': 0.24977109019076352, 'Total loss': 0.24977109019076352}
2023-01-04 05:21:28,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:28,073 INFO:     Epoch: 39
2023-01-04 05:21:29,714 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4053145945072174, 'Total loss': 0.4053145945072174} | train loss {'Reaction outcome loss': 0.24902122309061595, 'Total loss': 0.24902122309061595}
2023-01-04 05:21:29,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:29,715 INFO:     Epoch: 40
2023-01-04 05:21:31,329 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4238177537918091, 'Total loss': 0.4238177537918091} | train loss {'Reaction outcome loss': 0.2449736206217363, 'Total loss': 0.2449736206217363}
2023-01-04 05:21:31,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:31,329 INFO:     Epoch: 41
2023-01-04 05:21:32,990 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41555216113726295, 'Total loss': 0.41555216113726295} | train loss {'Reaction outcome loss': 0.2454015194885567, 'Total loss': 0.2454015194885567}
2023-01-04 05:21:32,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:32,991 INFO:     Epoch: 42
2023-01-04 05:21:34,629 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4279248754183451, 'Total loss': 0.4279248754183451} | train loss {'Reaction outcome loss': 0.24581831634475004, 'Total loss': 0.24581831634475004}
2023-01-04 05:21:34,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:34,629 INFO:     Epoch: 43
2023-01-04 05:21:36,291 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4064779887596766, 'Total loss': 0.4064779887596766} | train loss {'Reaction outcome loss': 0.24164615870060044, 'Total loss': 0.24164615870060044}
2023-01-04 05:21:36,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:36,292 INFO:     Epoch: 44
2023-01-04 05:21:37,935 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4084613064924876, 'Total loss': 0.4084613064924876} | train loss {'Reaction outcome loss': 0.23853599851688753, 'Total loss': 0.23853599851688753}
2023-01-04 05:21:37,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:37,935 INFO:     Epoch: 45
2023-01-04 05:21:39,587 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4195871829986572, 'Total loss': 0.4195871829986572} | train loss {'Reaction outcome loss': 0.2378376213974901, 'Total loss': 0.2378376213974901}
2023-01-04 05:21:39,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:39,587 INFO:     Epoch: 46
2023-01-04 05:21:41,204 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4353936791419983, 'Total loss': 0.4353936791419983} | train loss {'Reaction outcome loss': 0.2316494073907068, 'Total loss': 0.2316494073907068}
2023-01-04 05:21:41,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:41,205 INFO:     Epoch: 47
2023-01-04 05:21:42,838 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.404567817846934, 'Total loss': 0.404567817846934} | train loss {'Reaction outcome loss': 0.2356356605080491, 'Total loss': 0.2356356605080491}
2023-01-04 05:21:42,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:42,838 INFO:     Epoch: 48
2023-01-04 05:21:44,480 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4064276764790217, 'Total loss': 0.4064276764790217} | train loss {'Reaction outcome loss': 0.2321374447955767, 'Total loss': 0.2321374447955767}
2023-01-04 05:21:44,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:44,480 INFO:     Epoch: 49
2023-01-04 05:21:46,108 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40905944208304085, 'Total loss': 0.40905944208304085} | train loss {'Reaction outcome loss': 0.22885865778645453, 'Total loss': 0.22885865778645453}
2023-01-04 05:21:46,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:46,108 INFO:     Epoch: 50
2023-01-04 05:21:47,708 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4166859487692515, 'Total loss': 0.4166859487692515} | train loss {'Reaction outcome loss': 0.22680961902821536, 'Total loss': 0.22680961902821536}
2023-01-04 05:21:47,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:47,709 INFO:     Epoch: 51
2023-01-04 05:21:49,303 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3985289603471756, 'Total loss': 0.3985289603471756} | train loss {'Reaction outcome loss': 0.2268250285637723, 'Total loss': 0.2268250285637723}
2023-01-04 05:21:49,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:49,304 INFO:     Epoch: 52
2023-01-04 05:21:50,895 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4239682932694753, 'Total loss': 0.4239682932694753} | train loss {'Reaction outcome loss': 0.22621225436564388, 'Total loss': 0.22621225436564388}
2023-01-04 05:21:50,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:50,895 INFO:     Epoch: 53
2023-01-04 05:21:52,499 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3908654441436132, 'Total loss': 0.3908654441436132} | train loss {'Reaction outcome loss': 0.22473105593224726, 'Total loss': 0.22473105593224726}
2023-01-04 05:21:52,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:52,500 INFO:     Epoch: 54
2023-01-04 05:21:54,103 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42855322162310283, 'Total loss': 0.42855322162310283} | train loss {'Reaction outcome loss': 0.22323475072046048, 'Total loss': 0.22323475072046048}
2023-01-04 05:21:54,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:54,104 INFO:     Epoch: 55
2023-01-04 05:21:55,691 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41006403267383573, 'Total loss': 0.41006403267383573} | train loss {'Reaction outcome loss': 0.22119463676257253, 'Total loss': 0.22119463676257253}
2023-01-04 05:21:55,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:55,691 INFO:     Epoch: 56
2023-01-04 05:21:57,295 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4104079087575277, 'Total loss': 0.4104079087575277} | train loss {'Reaction outcome loss': 0.21977946807761484, 'Total loss': 0.21977946807761484}
2023-01-04 05:21:57,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:57,295 INFO:     Epoch: 57
2023-01-04 05:21:58,884 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4085256020228068, 'Total loss': 0.4085256020228068} | train loss {'Reaction outcome loss': 0.21767118862335863, 'Total loss': 0.21767118862335863}
2023-01-04 05:21:58,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:21:58,884 INFO:     Epoch: 58
2023-01-04 05:22:00,516 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4078158070643743, 'Total loss': 0.4078158070643743} | train loss {'Reaction outcome loss': 0.21682010855969538, 'Total loss': 0.21682010855969538}
2023-01-04 05:22:00,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:00,516 INFO:     Epoch: 59
2023-01-04 05:22:02,139 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40071883896986643, 'Total loss': 0.40071883896986643} | train loss {'Reaction outcome loss': 0.21457444358657413, 'Total loss': 0.21457444358657413}
2023-01-04 05:22:02,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:02,139 INFO:     Epoch: 60
2023-01-04 05:22:03,775 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.404813747604688, 'Total loss': 0.404813747604688} | train loss {'Reaction outcome loss': 0.21228600220774915, 'Total loss': 0.21228600220774915}
2023-01-04 05:22:03,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:03,775 INFO:     Epoch: 61
2023-01-04 05:22:05,393 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41828088561693827, 'Total loss': 0.41828088561693827} | train loss {'Reaction outcome loss': 0.21121869953046638, 'Total loss': 0.21121869953046638}
2023-01-04 05:22:05,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:05,393 INFO:     Epoch: 62
2023-01-04 05:22:07,012 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4259636402130127, 'Total loss': 0.4259636402130127} | train loss {'Reaction outcome loss': 0.21183554205492086, 'Total loss': 0.21183554205492086}
2023-01-04 05:22:07,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:07,013 INFO:     Epoch: 63
2023-01-04 05:22:08,604 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4072720353802045, 'Total loss': 0.4072720353802045} | train loss {'Reaction outcome loss': 0.21185956446164783, 'Total loss': 0.21185956446164783}
2023-01-04 05:22:08,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:08,604 INFO:     Epoch: 64
2023-01-04 05:22:10,235 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41031529506047565, 'Total loss': 0.41031529506047565} | train loss {'Reaction outcome loss': 0.20890124966575352, 'Total loss': 0.20890124966575352}
2023-01-04 05:22:10,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:10,235 INFO:     Epoch: 65
2023-01-04 05:22:11,872 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4179779549439748, 'Total loss': 0.4179779549439748} | train loss {'Reaction outcome loss': 0.20889216579416167, 'Total loss': 0.20889216579416167}
2023-01-04 05:22:11,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:11,873 INFO:     Epoch: 66
2023-01-04 05:22:13,452 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38986408213774365, 'Total loss': 0.38986408213774365} | train loss {'Reaction outcome loss': 0.20666636627449886, 'Total loss': 0.20666636627449886}
2023-01-04 05:22:13,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:13,452 INFO:     Epoch: 67
2023-01-04 05:22:15,078 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4095924506584803, 'Total loss': 0.4095924506584803} | train loss {'Reaction outcome loss': 0.2061481475157643, 'Total loss': 0.2061481475157643}
2023-01-04 05:22:15,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:15,078 INFO:     Epoch: 68
2023-01-04 05:22:16,655 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4067352597912153, 'Total loss': 0.4067352597912153} | train loss {'Reaction outcome loss': 0.2050360123684045, 'Total loss': 0.2050360123684045}
2023-01-04 05:22:16,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:16,656 INFO:     Epoch: 69
2023-01-04 05:22:18,266 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39246369401613873, 'Total loss': 0.39246369401613873} | train loss {'Reaction outcome loss': 0.202942402098691, 'Total loss': 0.202942402098691}
2023-01-04 05:22:18,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:18,266 INFO:     Epoch: 70
2023-01-04 05:22:19,906 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40886449615160625, 'Total loss': 0.40886449615160625} | train loss {'Reaction outcome loss': 0.20183307455603827, 'Total loss': 0.20183307455603827}
2023-01-04 05:22:19,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:19,906 INFO:     Epoch: 71
2023-01-04 05:22:21,546 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4060623427232107, 'Total loss': 0.4060623427232107} | train loss {'Reaction outcome loss': 0.2015529091231229, 'Total loss': 0.2015529091231229}
2023-01-04 05:22:21,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:21,546 INFO:     Epoch: 72
2023-01-04 05:22:23,156 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39454357673724494, 'Total loss': 0.39454357673724494} | train loss {'Reaction outcome loss': 0.20230592354217591, 'Total loss': 0.20230592354217591}
2023-01-04 05:22:23,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:23,158 INFO:     Epoch: 73
2023-01-04 05:22:24,762 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41753742297490437, 'Total loss': 0.41753742297490437} | train loss {'Reaction outcome loss': 0.19796223548452777, 'Total loss': 0.19796223548452777}
2023-01-04 05:22:24,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:24,762 INFO:     Epoch: 74
2023-01-04 05:22:26,372 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4202439251045386, 'Total loss': 0.4202439251045386} | train loss {'Reaction outcome loss': 0.1977014536112009, 'Total loss': 0.1977014536112009}
2023-01-04 05:22:26,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:26,372 INFO:     Epoch: 75
2023-01-04 05:22:27,980 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4177426507075628, 'Total loss': 0.4177426507075628} | train loss {'Reaction outcome loss': 0.19768617027825827, 'Total loss': 0.19768617027825827}
2023-01-04 05:22:27,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:27,981 INFO:     Epoch: 76
2023-01-04 05:22:29,591 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39885832866032916, 'Total loss': 0.39885832866032916} | train loss {'Reaction outcome loss': 0.19526855456592374, 'Total loss': 0.19526855456592374}
2023-01-04 05:22:29,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:29,592 INFO:     Epoch: 77
2023-01-04 05:22:31,200 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4035524740815163, 'Total loss': 0.4035524740815163} | train loss {'Reaction outcome loss': 0.19312718017060404, 'Total loss': 0.19312718017060404}
2023-01-04 05:22:31,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:31,200 INFO:     Epoch: 78
2023-01-04 05:22:32,802 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41626675327618917, 'Total loss': 0.41626675327618917} | train loss {'Reaction outcome loss': 0.19231597877474038, 'Total loss': 0.19231597877474038}
2023-01-04 05:22:32,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:32,802 INFO:     Epoch: 79
2023-01-04 05:22:34,419 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4166802962621053, 'Total loss': 0.4166802962621053} | train loss {'Reaction outcome loss': 0.19315762443985748, 'Total loss': 0.19315762443985748}
2023-01-04 05:22:34,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:34,420 INFO:     Epoch: 80
2023-01-04 05:22:36,009 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4091319441795349, 'Total loss': 0.4091319441795349} | train loss {'Reaction outcome loss': 0.19604158544045494, 'Total loss': 0.19604158544045494}
2023-01-04 05:22:36,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:36,009 INFO:     Epoch: 81
2023-01-04 05:22:37,609 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4054533491532008, 'Total loss': 0.4054533491532008} | train loss {'Reaction outcome loss': 0.1925898201709835, 'Total loss': 0.1925898201709835}
2023-01-04 05:22:37,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:37,610 INFO:     Epoch: 82
2023-01-04 05:22:39,207 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39403717319170634, 'Total loss': 0.39403717319170634} | train loss {'Reaction outcome loss': 0.19050768566475879, 'Total loss': 0.19050768566475879}
2023-01-04 05:22:39,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:39,207 INFO:     Epoch: 83
2023-01-04 05:22:40,806 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4076157738765081, 'Total loss': 0.4076157738765081} | train loss {'Reaction outcome loss': 0.18889539648479503, 'Total loss': 0.18889539648479503}
2023-01-04 05:22:40,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:40,807 INFO:     Epoch: 84
2023-01-04 05:22:42,443 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4119358748197556, 'Total loss': 0.4119358748197556} | train loss {'Reaction outcome loss': 0.18752585058957877, 'Total loss': 0.18752585058957877}
2023-01-04 05:22:42,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:42,444 INFO:     Epoch: 85
2023-01-04 05:22:44,049 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.39578379640976585, 'Total loss': 0.39578379640976585} | train loss {'Reaction outcome loss': 0.18950532835366923, 'Total loss': 0.18950532835366923}
2023-01-04 05:22:44,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:44,049 INFO:     Epoch: 86
2023-01-04 05:22:45,653 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4169196476538976, 'Total loss': 0.4169196476538976} | train loss {'Reaction outcome loss': 0.18793673705753436, 'Total loss': 0.18793673705753436}
2023-01-04 05:22:45,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:45,653 INFO:     Epoch: 87
2023-01-04 05:22:47,253 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4443070908387502, 'Total loss': 0.4443070908387502} | train loss {'Reaction outcome loss': 0.18654869935250024, 'Total loss': 0.18654869935250024}
2023-01-04 05:22:47,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:47,253 INFO:     Epoch: 88
2023-01-04 05:22:48,854 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4086152732372284, 'Total loss': 0.4086152732372284} | train loss {'Reaction outcome loss': 0.18471242808854538, 'Total loss': 0.18471242808854538}
2023-01-04 05:22:48,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:48,854 INFO:     Epoch: 89
2023-01-04 05:22:50,459 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4021486600240072, 'Total loss': 0.4021486600240072} | train loss {'Reaction outcome loss': 0.18553031194914765, 'Total loss': 0.18553031194914765}
2023-01-04 05:22:50,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:50,459 INFO:     Epoch: 90
2023-01-04 05:22:52,061 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4134589860836665, 'Total loss': 0.4134589860836665} | train loss {'Reaction outcome loss': 0.18434889585667355, 'Total loss': 0.18434889585667355}
2023-01-04 05:22:52,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:52,061 INFO:     Epoch: 91
2023-01-04 05:22:53,647 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4067655324935913, 'Total loss': 0.4067655324935913} | train loss {'Reaction outcome loss': 0.18622976384841794, 'Total loss': 0.18622976384841794}
2023-01-04 05:22:53,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:53,648 INFO:     Epoch: 92
2023-01-04 05:22:55,248 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43394895692666374, 'Total loss': 0.43394895692666374} | train loss {'Reaction outcome loss': 0.18343951302960462, 'Total loss': 0.18343951302960462}
2023-01-04 05:22:55,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:55,249 INFO:     Epoch: 93
2023-01-04 05:22:56,851 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4309801201025645, 'Total loss': 0.4309801201025645} | train loss {'Reaction outcome loss': 0.18291806038267347, 'Total loss': 0.18291806038267347}
2023-01-04 05:22:56,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:56,851 INFO:     Epoch: 94
2023-01-04 05:22:58,432 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3871492033203443, 'Total loss': 0.3871492033203443} | train loss {'Reaction outcome loss': 0.18196202837105585, 'Total loss': 0.18196202837105585}
2023-01-04 05:22:58,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:22:58,432 INFO:     Epoch: 95
2023-01-04 05:23:00,029 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42550516029198965, 'Total loss': 0.42550516029198965} | train loss {'Reaction outcome loss': 0.179500558410203, 'Total loss': 0.179500558410203}
2023-01-04 05:23:00,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:00,030 INFO:     Epoch: 96
2023-01-04 05:23:01,627 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4168462495009104, 'Total loss': 0.4168462495009104} | train loss {'Reaction outcome loss': 0.17938046244776637, 'Total loss': 0.17938046244776637}
2023-01-04 05:23:01,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:01,628 INFO:     Epoch: 97
2023-01-04 05:23:03,231 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.412446928024292, 'Total loss': 0.412446928024292} | train loss {'Reaction outcome loss': 0.18072542146063453, 'Total loss': 0.18072542146063453}
2023-01-04 05:23:03,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:03,231 INFO:     Epoch: 98
2023-01-04 05:23:04,856 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4279353141784668, 'Total loss': 0.4279353141784668} | train loss {'Reaction outcome loss': 0.18092228075496125, 'Total loss': 0.18092228075496125}
2023-01-04 05:23:04,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:04,856 INFO:     Epoch: 99
2023-01-04 05:23:06,479 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4095369279384613, 'Total loss': 0.4095369279384613} | train loss {'Reaction outcome loss': 0.1799774028844997, 'Total loss': 0.1799774028844997}
2023-01-04 05:23:06,479 INFO:     Best model found after epoch 30 of 100.
2023-01-04 05:23:06,479 INFO:   Done with stage: TRAINING
2023-01-04 05:23:06,479 INFO:   Starting stage: EVALUATION
2023-01-04 05:23:06,603 INFO:   Done with stage: EVALUATION
2023-01-04 05:23:06,603 INFO:   Leaving out SEQ value Fold_5
2023-01-04 05:23:06,616 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 05:23:06,616 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:23:07,257 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:23:07,257 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:23:07,324 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:23:07,325 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:23:07,325 INFO:     No hyperparam tuning for this model
2023-01-04 05:23:07,325 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:23:07,325 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:23:07,325 INFO:     None feature selector for col prot
2023-01-04 05:23:07,326 INFO:     None feature selector for col prot
2023-01-04 05:23:07,326 INFO:     None feature selector for col prot
2023-01-04 05:23:07,326 INFO:     None feature selector for col chem
2023-01-04 05:23:07,326 INFO:     None feature selector for col chem
2023-01-04 05:23:07,326 INFO:     None feature selector for col chem
2023-01-04 05:23:07,326 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:23:07,326 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:23:07,327 INFO:     Number of params in model 70141
2023-01-04 05:23:07,331 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:23:07,331 INFO:   Starting stage: TRAINING
2023-01-04 05:23:07,376 INFO:     Val loss before train {'Reaction outcome loss': 1.0784371415774028, 'Total loss': 1.0784371415774028}
2023-01-04 05:23:07,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:07,376 INFO:     Epoch: 0
2023-01-04 05:23:08,955 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7775595664978028, 'Total loss': 0.7775595664978028} | train loss {'Reaction outcome loss': 0.8690818815770811, 'Total loss': 0.8690818815770811}
2023-01-04 05:23:08,955 INFO:     Found new best model at epoch 0
2023-01-04 05:23:08,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:08,956 INFO:     Epoch: 1
2023-01-04 05:23:10,523 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5985231131315232, 'Total loss': 0.5985231131315232} | train loss {'Reaction outcome loss': 0.628428569131524, 'Total loss': 0.628428569131524}
2023-01-04 05:23:10,523 INFO:     Found new best model at epoch 1
2023-01-04 05:23:10,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:10,524 INFO:     Epoch: 2
2023-01-04 05:23:12,136 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5607721527417501, 'Total loss': 0.5607721527417501} | train loss {'Reaction outcome loss': 0.542036799238111, 'Total loss': 0.542036799238111}
2023-01-04 05:23:12,137 INFO:     Found new best model at epoch 2
2023-01-04 05:23:12,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:12,137 INFO:     Epoch: 3
2023-01-04 05:23:13,756 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5359354654947917, 'Total loss': 0.5359354654947917} | train loss {'Reaction outcome loss': 0.4981869246511564, 'Total loss': 0.4981869246511564}
2023-01-04 05:23:13,756 INFO:     Found new best model at epoch 3
2023-01-04 05:23:13,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:13,757 INFO:     Epoch: 4
2023-01-04 05:23:15,376 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49326907098293304, 'Total loss': 0.49326907098293304} | train loss {'Reaction outcome loss': 0.4599015714913389, 'Total loss': 0.4599015714913389}
2023-01-04 05:23:15,376 INFO:     Found new best model at epoch 4
2023-01-04 05:23:15,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:15,377 INFO:     Epoch: 5
2023-01-04 05:23:16,933 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4994360864162445, 'Total loss': 0.4994360864162445} | train loss {'Reaction outcome loss': 0.4371982778075838, 'Total loss': 0.4371982778075838}
2023-01-04 05:23:16,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:16,933 INFO:     Epoch: 6
2023-01-04 05:23:18,538 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4614727695782979, 'Total loss': 0.4614727695782979} | train loss {'Reaction outcome loss': 0.41928604876037934, 'Total loss': 0.41928604876037934}
2023-01-04 05:23:18,539 INFO:     Found new best model at epoch 6
2023-01-04 05:23:18,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:18,539 INFO:     Epoch: 7
2023-01-04 05:23:20,094 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.472917636235555, 'Total loss': 0.472917636235555} | train loss {'Reaction outcome loss': 0.4068584014682004, 'Total loss': 0.4068584014682004}
2023-01-04 05:23:20,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:20,095 INFO:     Epoch: 8
2023-01-04 05:23:21,712 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4706747094790141, 'Total loss': 0.4706747094790141} | train loss {'Reaction outcome loss': 0.3938520669284528, 'Total loss': 0.3938520669284528}
2023-01-04 05:23:21,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:21,712 INFO:     Epoch: 9
2023-01-04 05:23:23,281 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47151301900545756, 'Total loss': 0.47151301900545756} | train loss {'Reaction outcome loss': 0.3822227367030008, 'Total loss': 0.3822227367030008}
2023-01-04 05:23:23,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:23,281 INFO:     Epoch: 10
2023-01-04 05:23:24,867 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4593533833821615, 'Total loss': 0.4593533833821615} | train loss {'Reaction outcome loss': 0.3723055486478945, 'Total loss': 0.3723055486478945}
2023-01-04 05:23:24,868 INFO:     Found new best model at epoch 10
2023-01-04 05:23:24,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:24,869 INFO:     Epoch: 11
2023-01-04 05:23:26,447 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4467124591271083, 'Total loss': 0.4467124591271083} | train loss {'Reaction outcome loss': 0.3669477870048833, 'Total loss': 0.3669477870048833}
2023-01-04 05:23:26,447 INFO:     Found new best model at epoch 11
2023-01-04 05:23:26,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:26,448 INFO:     Epoch: 12
2023-01-04 05:23:28,015 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45095489819844564, 'Total loss': 0.45095489819844564} | train loss {'Reaction outcome loss': 0.35612238329039875, 'Total loss': 0.35612238329039875}
2023-01-04 05:23:28,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:28,015 INFO:     Epoch: 13
2023-01-04 05:23:29,624 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4407434642314911, 'Total loss': 0.4407434642314911} | train loss {'Reaction outcome loss': 0.3499600463648782, 'Total loss': 0.3499600463648782}
2023-01-04 05:23:29,624 INFO:     Found new best model at epoch 13
2023-01-04 05:23:29,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:29,625 INFO:     Epoch: 14
2023-01-04 05:23:31,217 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4615470687548319, 'Total loss': 0.4615470687548319} | train loss {'Reaction outcome loss': 0.3429017690465833, 'Total loss': 0.3429017690465833}
2023-01-04 05:23:31,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:31,218 INFO:     Epoch: 15
2023-01-04 05:23:32,783 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4459281007448832, 'Total loss': 0.4459281007448832} | train loss {'Reaction outcome loss': 0.3326430540450298, 'Total loss': 0.3326430540450298}
2023-01-04 05:23:32,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:32,783 INFO:     Epoch: 16
2023-01-04 05:23:34,356 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4511607964833578, 'Total loss': 0.4511607964833578} | train loss {'Reaction outcome loss': 0.32620925730923667, 'Total loss': 0.32620925730923667}
2023-01-04 05:23:34,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:34,356 INFO:     Epoch: 17
2023-01-04 05:23:35,938 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45748037795225777, 'Total loss': 0.45748037795225777} | train loss {'Reaction outcome loss': 0.3214930126810596, 'Total loss': 0.3214930126810596}
2023-01-04 05:23:35,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:35,938 INFO:     Epoch: 18
2023-01-04 05:23:37,500 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4312104086081187, 'Total loss': 0.4312104086081187} | train loss {'Reaction outcome loss': 0.31943536337709777, 'Total loss': 0.31943536337709777}
2023-01-04 05:23:37,500 INFO:     Found new best model at epoch 18
2023-01-04 05:23:37,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:37,501 INFO:     Epoch: 19
2023-01-04 05:23:39,108 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4447747111320496, 'Total loss': 0.4447747111320496} | train loss {'Reaction outcome loss': 0.3097752824045011, 'Total loss': 0.3097752824045011}
2023-01-04 05:23:39,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:39,109 INFO:     Epoch: 20
2023-01-04 05:23:40,716 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4630405048529307, 'Total loss': 0.4630405048529307} | train loss {'Reaction outcome loss': 0.3021034728463766, 'Total loss': 0.3021034728463766}
2023-01-04 05:23:40,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:40,717 INFO:     Epoch: 21
2023-01-04 05:23:42,326 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43214828372001646, 'Total loss': 0.43214828372001646} | train loss {'Reaction outcome loss': 0.2996699423767137, 'Total loss': 0.2996699423767137}
2023-01-04 05:23:42,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:42,326 INFO:     Epoch: 22
2023-01-04 05:23:43,883 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4413609405358632, 'Total loss': 0.4413609405358632} | train loss {'Reaction outcome loss': 0.29727229078973294, 'Total loss': 0.29727229078973294}
2023-01-04 05:23:43,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:43,883 INFO:     Epoch: 23
2023-01-04 05:23:45,484 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44447146852811176, 'Total loss': 0.44447146852811176} | train loss {'Reaction outcome loss': 0.2905194093983104, 'Total loss': 0.2905194093983104}
2023-01-04 05:23:45,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:45,484 INFO:     Epoch: 24
2023-01-04 05:23:47,060 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4512089292208354, 'Total loss': 0.4512089292208354} | train loss {'Reaction outcome loss': 0.2852971596493773, 'Total loss': 0.2852971596493773}
2023-01-04 05:23:47,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:47,060 INFO:     Epoch: 25
2023-01-04 05:23:48,645 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4388219167788823, 'Total loss': 0.4388219167788823} | train loss {'Reaction outcome loss': 0.2809608239327034, 'Total loss': 0.2809608239327034}
2023-01-04 05:23:48,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:48,645 INFO:     Epoch: 26
2023-01-04 05:23:50,230 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41294869780540466, 'Total loss': 0.41294869780540466} | train loss {'Reaction outcome loss': 0.2771406602522318, 'Total loss': 0.2771406602522318}
2023-01-04 05:23:50,231 INFO:     Found new best model at epoch 26
2023-01-04 05:23:50,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:50,231 INFO:     Epoch: 27
2023-01-04 05:23:51,797 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41205245405435564, 'Total loss': 0.41205245405435564} | train loss {'Reaction outcome loss': 0.2735154754924078, 'Total loss': 0.2735154754924078}
2023-01-04 05:23:51,797 INFO:     Found new best model at epoch 27
2023-01-04 05:23:51,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:51,798 INFO:     Epoch: 28
2023-01-04 05:23:53,394 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42719484567642213, 'Total loss': 0.42719484567642213} | train loss {'Reaction outcome loss': 0.27061185966769274, 'Total loss': 0.27061185966769274}
2023-01-04 05:23:53,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:53,394 INFO:     Epoch: 29
2023-01-04 05:23:54,980 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42024364372094475, 'Total loss': 0.42024364372094475} | train loss {'Reaction outcome loss': 0.26773382213483327, 'Total loss': 0.26773382213483327}
2023-01-04 05:23:54,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:54,982 INFO:     Epoch: 30
2023-01-04 05:23:56,559 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43351799647013345, 'Total loss': 0.43351799647013345} | train loss {'Reaction outcome loss': 0.2622766718812232, 'Total loss': 0.2622766718812232}
2023-01-04 05:23:56,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:56,560 INFO:     Epoch: 31
2023-01-04 05:23:58,180 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.429082257548968, 'Total loss': 0.429082257548968} | train loss {'Reaction outcome loss': 0.2599166189626294, 'Total loss': 0.2599166189626294}
2023-01-04 05:23:58,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:58,180 INFO:     Epoch: 32
2023-01-04 05:23:59,795 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4105244090159734, 'Total loss': 0.4105244090159734} | train loss {'Reaction outcome loss': 0.2565068093257664, 'Total loss': 0.2565068093257664}
2023-01-04 05:23:59,795 INFO:     Found new best model at epoch 32
2023-01-04 05:23:59,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:23:59,796 INFO:     Epoch: 33
2023-01-04 05:24:01,369 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4282156407833099, 'Total loss': 0.4282156407833099} | train loss {'Reaction outcome loss': 0.25151126514984307, 'Total loss': 0.25151126514984307}
2023-01-04 05:24:01,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:01,370 INFO:     Epoch: 34
2023-01-04 05:24:02,944 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4059518754482269, 'Total loss': 0.4059518754482269} | train loss {'Reaction outcome loss': 0.25198082893706153, 'Total loss': 0.25198082893706153}
2023-01-04 05:24:02,944 INFO:     Found new best model at epoch 34
2023-01-04 05:24:02,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:02,945 INFO:     Epoch: 35
2023-01-04 05:24:04,509 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4584394653638204, 'Total loss': 0.4584394653638204} | train loss {'Reaction outcome loss': 0.24878341934378564, 'Total loss': 0.24878341934378564}
2023-01-04 05:24:04,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:04,509 INFO:     Epoch: 36
2023-01-04 05:24:06,129 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42974868019421897, 'Total loss': 0.42974868019421897} | train loss {'Reaction outcome loss': 0.24598087563458151, 'Total loss': 0.24598087563458151}
2023-01-04 05:24:06,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:06,129 INFO:     Epoch: 37
2023-01-04 05:24:07,747 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44032442768414815, 'Total loss': 0.44032442768414815} | train loss {'Reaction outcome loss': 0.24236184305572597, 'Total loss': 0.24236184305572597}
2023-01-04 05:24:07,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:07,747 INFO:     Epoch: 38
2023-01-04 05:24:09,366 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4302024493614833, 'Total loss': 0.4302024493614833} | train loss {'Reaction outcome loss': 0.23996199496144796, 'Total loss': 0.23996199496144796}
2023-01-04 05:24:09,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:09,366 INFO:     Epoch: 39
2023-01-04 05:24:10,958 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4160160293181737, 'Total loss': 0.4160160293181737} | train loss {'Reaction outcome loss': 0.23849523888669744, 'Total loss': 0.23849523888669744}
2023-01-04 05:24:10,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:10,958 INFO:     Epoch: 40
2023-01-04 05:24:12,527 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39975163141886394, 'Total loss': 0.39975163141886394} | train loss {'Reaction outcome loss': 0.2359222654919446, 'Total loss': 0.2359222654919446}
2023-01-04 05:24:12,527 INFO:     Found new best model at epoch 40
2023-01-04 05:24:12,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:12,528 INFO:     Epoch: 41
2023-01-04 05:24:14,115 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4173859606186549, 'Total loss': 0.4173859606186549} | train loss {'Reaction outcome loss': 0.23145017677741328, 'Total loss': 0.23145017677741328}
2023-01-04 05:24:14,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:14,116 INFO:     Epoch: 42
2023-01-04 05:24:15,697 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39062152033050856, 'Total loss': 0.39062152033050856} | train loss {'Reaction outcome loss': 0.2301810115684558, 'Total loss': 0.2301810115684558}
2023-01-04 05:24:15,697 INFO:     Found new best model at epoch 42
2023-01-04 05:24:15,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:15,698 INFO:     Epoch: 43
2023-01-04 05:24:17,332 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4087420225143433, 'Total loss': 0.4087420225143433} | train loss {'Reaction outcome loss': 0.22685302293648685, 'Total loss': 0.22685302293648685}
2023-01-04 05:24:17,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:17,332 INFO:     Epoch: 44
2023-01-04 05:24:18,898 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4202471574147542, 'Total loss': 0.4202471574147542} | train loss {'Reaction outcome loss': 0.22647862362056753, 'Total loss': 0.22647862362056753}
2023-01-04 05:24:18,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:18,899 INFO:     Epoch: 45
2023-01-04 05:24:20,507 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4122223238150279, 'Total loss': 0.4122223238150279} | train loss {'Reaction outcome loss': 0.2240624760896185, 'Total loss': 0.2240624760896185}
2023-01-04 05:24:20,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:20,508 INFO:     Epoch: 46
2023-01-04 05:24:22,092 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43912365833918254, 'Total loss': 0.43912365833918254} | train loss {'Reaction outcome loss': 0.22022708334083105, 'Total loss': 0.22022708334083105}
2023-01-04 05:24:22,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:22,093 INFO:     Epoch: 47
2023-01-04 05:24:23,677 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4045106440782547, 'Total loss': 0.4045106440782547} | train loss {'Reaction outcome loss': 0.21815015098256788, 'Total loss': 0.21815015098256788}
2023-01-04 05:24:23,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:23,677 INFO:     Epoch: 48
2023-01-04 05:24:25,260 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4276328146457672, 'Total loss': 0.4276328146457672} | train loss {'Reaction outcome loss': 0.2176738177786452, 'Total loss': 0.2176738177786452}
2023-01-04 05:24:25,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:25,261 INFO:     Epoch: 49
2023-01-04 05:24:26,848 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44395158886909486, 'Total loss': 0.44395158886909486} | train loss {'Reaction outcome loss': 0.21386352209986126, 'Total loss': 0.21386352209986126}
2023-01-04 05:24:26,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:26,850 INFO:     Epoch: 50
2023-01-04 05:24:28,427 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4217915972073873, 'Total loss': 0.4217915972073873} | train loss {'Reaction outcome loss': 0.2149507793033645, 'Total loss': 0.2149507793033645}
2023-01-04 05:24:28,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:28,427 INFO:     Epoch: 51
2023-01-04 05:24:30,040 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3962777773539225, 'Total loss': 0.3962777773539225} | train loss {'Reaction outcome loss': 0.21062640089840784, 'Total loss': 0.21062640089840784}
2023-01-04 05:24:30,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:30,040 INFO:     Epoch: 52
2023-01-04 05:24:31,633 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41192203561464946, 'Total loss': 0.41192203561464946} | train loss {'Reaction outcome loss': 0.20905373694144025, 'Total loss': 0.20905373694144025}
2023-01-04 05:24:31,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:31,634 INFO:     Epoch: 53
2023-01-04 05:24:33,216 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40036419133345286, 'Total loss': 0.40036419133345286} | train loss {'Reaction outcome loss': 0.20814849202432772, 'Total loss': 0.20814849202432772}
2023-01-04 05:24:33,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:33,217 INFO:     Epoch: 54
2023-01-04 05:24:34,820 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40898859053850173, 'Total loss': 0.40898859053850173} | train loss {'Reaction outcome loss': 0.2069827216357863, 'Total loss': 0.2069827216357863}
2023-01-04 05:24:34,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:34,820 INFO:     Epoch: 55
2023-01-04 05:24:36,424 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40389931003252666, 'Total loss': 0.40389931003252666} | train loss {'Reaction outcome loss': 0.20558219045455003, 'Total loss': 0.20558219045455003}
2023-01-04 05:24:36,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:36,425 INFO:     Epoch: 56
2023-01-04 05:24:38,022 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43556552827358247, 'Total loss': 0.43556552827358247} | train loss {'Reaction outcome loss': 0.2043063091793961, 'Total loss': 0.2043063091793961}
2023-01-04 05:24:38,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:38,022 INFO:     Epoch: 57
2023-01-04 05:24:39,631 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41801943679650627, 'Total loss': 0.41801943679650627} | train loss {'Reaction outcome loss': 0.20017828698521548, 'Total loss': 0.20017828698521548}
2023-01-04 05:24:39,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:39,632 INFO:     Epoch: 58
2023-01-04 05:24:41,229 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3876481086015701, 'Total loss': 0.3876481086015701} | train loss {'Reaction outcome loss': 0.20027468992519554, 'Total loss': 0.20027468992519554}
2023-01-04 05:24:41,229 INFO:     Found new best model at epoch 58
2023-01-04 05:24:41,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:41,230 INFO:     Epoch: 59
2023-01-04 05:24:42,853 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4027441600958506, 'Total loss': 0.4027441600958506} | train loss {'Reaction outcome loss': 0.19981597621592073, 'Total loss': 0.19981597621592073}
2023-01-04 05:24:42,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:42,853 INFO:     Epoch: 60
2023-01-04 05:24:44,476 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4141078978776932, 'Total loss': 0.4141078978776932} | train loss {'Reaction outcome loss': 0.19883495550194796, 'Total loss': 0.19883495550194796}
2023-01-04 05:24:44,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:44,477 INFO:     Epoch: 61
2023-01-04 05:24:46,064 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4172482192516327, 'Total loss': 0.4172482192516327} | train loss {'Reaction outcome loss': 0.1970477439327179, 'Total loss': 0.1970477439327179}
2023-01-04 05:24:46,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:46,065 INFO:     Epoch: 62
2023-01-04 05:24:47,647 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4177888135115306, 'Total loss': 0.4177888135115306} | train loss {'Reaction outcome loss': 0.1940435959148581, 'Total loss': 0.1940435959148581}
2023-01-04 05:24:47,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:47,647 INFO:     Epoch: 63
2023-01-04 05:24:49,239 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43476777523756027, 'Total loss': 0.43476777523756027} | train loss {'Reaction outcome loss': 0.19137751829749258, 'Total loss': 0.19137751829749258}
2023-01-04 05:24:49,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:49,239 INFO:     Epoch: 64
2023-01-04 05:24:50,864 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42588568925857545, 'Total loss': 0.42588568925857545} | train loss {'Reaction outcome loss': 0.1923135064107223, 'Total loss': 0.1923135064107223}
2023-01-04 05:24:50,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:50,864 INFO:     Epoch: 65
2023-01-04 05:24:52,490 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43849724531173706, 'Total loss': 0.43849724531173706} | train loss {'Reaction outcome loss': 0.19121329623689182, 'Total loss': 0.19121329623689182}
2023-01-04 05:24:52,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:52,490 INFO:     Epoch: 66
2023-01-04 05:24:54,117 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4287673582633336, 'Total loss': 0.4287673582633336} | train loss {'Reaction outcome loss': 0.18864589051962116, 'Total loss': 0.18864589051962116}
2023-01-04 05:24:54,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:54,117 INFO:     Epoch: 67
2023-01-04 05:24:55,695 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42276957432428997, 'Total loss': 0.42276957432428997} | train loss {'Reaction outcome loss': 0.18760965238359287, 'Total loss': 0.18760965238359287}
2023-01-04 05:24:55,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:55,695 INFO:     Epoch: 68
2023-01-04 05:24:57,303 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4302046949664752, 'Total loss': 0.4302046949664752} | train loss {'Reaction outcome loss': 0.18463999396665906, 'Total loss': 0.18463999396665906}
2023-01-04 05:24:57,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:57,303 INFO:     Epoch: 69
2023-01-04 05:24:58,645 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41243810852368673, 'Total loss': 0.41243810852368673} | train loss {'Reaction outcome loss': 0.18503644520647988, 'Total loss': 0.18503644520647988}
2023-01-04 05:24:58,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:58,645 INFO:     Epoch: 70
2023-01-04 05:24:59,726 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4217759688695272, 'Total loss': 0.4217759688695272} | train loss {'Reaction outcome loss': 0.18513668638511296, 'Total loss': 0.18513668638511296}
2023-01-04 05:24:59,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:24:59,726 INFO:     Epoch: 71
2023-01-04 05:25:00,803 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40765796105066937, 'Total loss': 0.40765796105066937} | train loss {'Reaction outcome loss': 0.1819436353542944, 'Total loss': 0.1819436353542944}
2023-01-04 05:25:00,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:00,803 INFO:     Epoch: 72
2023-01-04 05:25:01,887 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4093489766120911, 'Total loss': 0.4093489766120911} | train loss {'Reaction outcome loss': 0.1806372996474052, 'Total loss': 0.1806372996474052}
2023-01-04 05:25:01,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:01,888 INFO:     Epoch: 73
2023-01-04 05:25:03,331 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43169495165348054, 'Total loss': 0.43169495165348054} | train loss {'Reaction outcome loss': 0.18083054425507566, 'Total loss': 0.18083054425507566}
2023-01-04 05:25:03,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:03,331 INFO:     Epoch: 74
2023-01-04 05:25:04,937 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42344124615192413, 'Total loss': 0.42344124615192413} | train loss {'Reaction outcome loss': 0.18102092872353365, 'Total loss': 0.18102092872353365}
2023-01-04 05:25:04,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:04,937 INFO:     Epoch: 75
2023-01-04 05:25:06,543 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4142736891905467, 'Total loss': 0.4142736891905467} | train loss {'Reaction outcome loss': 0.17908576908555343, 'Total loss': 0.17908576908555343}
2023-01-04 05:25:06,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:06,543 INFO:     Epoch: 76
2023-01-04 05:25:08,144 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4244185189406077, 'Total loss': 0.4244185189406077} | train loss {'Reaction outcome loss': 0.1760937522784093, 'Total loss': 0.1760937522784093}
2023-01-04 05:25:08,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:08,145 INFO:     Epoch: 77
2023-01-04 05:25:09,751 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43806645770867664, 'Total loss': 0.43806645770867664} | train loss {'Reaction outcome loss': 0.17693747223837533, 'Total loss': 0.17693747223837533}
2023-01-04 05:25:09,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:09,751 INFO:     Epoch: 78
2023-01-04 05:25:11,323 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40346094767252605, 'Total loss': 0.40346094767252605} | train loss {'Reaction outcome loss': 0.1782075135601535, 'Total loss': 0.1782075135601535}
2023-01-04 05:25:11,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:11,324 INFO:     Epoch: 79
2023-01-04 05:25:12,933 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42114084760348003, 'Total loss': 0.42114084760348003} | train loss {'Reaction outcome loss': 0.17753859271506106, 'Total loss': 0.17753859271506106}
2023-01-04 05:25:12,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:12,933 INFO:     Epoch: 80
2023-01-04 05:25:14,541 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41810528337955477, 'Total loss': 0.41810528337955477} | train loss {'Reaction outcome loss': 0.1728156892324451, 'Total loss': 0.1728156892324451}
2023-01-04 05:25:14,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:14,542 INFO:     Epoch: 81
2023-01-04 05:25:16,172 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4297656863927841, 'Total loss': 0.4297656863927841} | train loss {'Reaction outcome loss': 0.17272644050854402, 'Total loss': 0.17272644050854402}
2023-01-04 05:25:16,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:16,172 INFO:     Epoch: 82
2023-01-04 05:25:17,783 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.417355681459109, 'Total loss': 0.417355681459109} | train loss {'Reaction outcome loss': 0.17091420351316894, 'Total loss': 0.17091420351316894}
2023-01-04 05:25:17,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:17,783 INFO:     Epoch: 83
2023-01-04 05:25:19,393 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4374552796284358, 'Total loss': 0.4374552796284358} | train loss {'Reaction outcome loss': 0.16937746489624472, 'Total loss': 0.16937746489624472}
2023-01-04 05:25:19,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:19,394 INFO:     Epoch: 84
2023-01-04 05:25:20,960 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45393275916576387, 'Total loss': 0.45393275916576387} | train loss {'Reaction outcome loss': 0.16900488297815305, 'Total loss': 0.16900488297815305}
2023-01-04 05:25:20,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:20,961 INFO:     Epoch: 85
2023-01-04 05:25:22,568 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41710827549298607, 'Total loss': 0.41710827549298607} | train loss {'Reaction outcome loss': 0.17002830249223397, 'Total loss': 0.17002830249223397}
2023-01-04 05:25:22,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:22,568 INFO:     Epoch: 86
2023-01-04 05:25:24,197 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44712462822596233, 'Total loss': 0.44712462822596233} | train loss {'Reaction outcome loss': 0.16945590967326052, 'Total loss': 0.16945590967326052}
2023-01-04 05:25:24,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:24,197 INFO:     Epoch: 87
2023-01-04 05:25:25,787 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.430796787639459, 'Total loss': 0.430796787639459} | train loss {'Reaction outcome loss': 0.16665076123836048, 'Total loss': 0.16665076123836048}
2023-01-04 05:25:25,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:25,787 INFO:     Epoch: 88
2023-01-04 05:25:27,379 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38958749373753865, 'Total loss': 0.38958749373753865} | train loss {'Reaction outcome loss': 0.16826571497631115, 'Total loss': 0.16826571497631115}
2023-01-04 05:25:27,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:27,379 INFO:     Epoch: 89
2023-01-04 05:25:28,952 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.413749897480011, 'Total loss': 0.413749897480011} | train loss {'Reaction outcome loss': 0.16626262774582218, 'Total loss': 0.16626262774582218}
2023-01-04 05:25:28,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:28,952 INFO:     Epoch: 90
2023-01-04 05:25:30,540 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43718585471312205, 'Total loss': 0.43718585471312205} | train loss {'Reaction outcome loss': 0.16736478527776733, 'Total loss': 0.16736478527776733}
2023-01-04 05:25:30,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:30,540 INFO:     Epoch: 91
2023-01-04 05:25:32,171 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.438528972864151, 'Total loss': 0.438528972864151} | train loss {'Reaction outcome loss': 0.16783557618784645, 'Total loss': 0.16783557618784645}
2023-01-04 05:25:32,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:32,173 INFO:     Epoch: 92
2023-01-04 05:25:33,775 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39519649744033813, 'Total loss': 0.39519649744033813} | train loss {'Reaction outcome loss': 0.16756941852615262, 'Total loss': 0.16756941852615262}
2023-01-04 05:25:33,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:33,775 INFO:     Epoch: 93
2023-01-04 05:25:35,399 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4567269871632258, 'Total loss': 0.4567269871632258} | train loss {'Reaction outcome loss': 0.16251875649471462, 'Total loss': 0.16251875649471462}
2023-01-04 05:25:35,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:35,400 INFO:     Epoch: 94
2023-01-04 05:25:37,000 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4319029986858368, 'Total loss': 0.4319029986858368} | train loss {'Reaction outcome loss': 0.16398572212724138, 'Total loss': 0.16398572212724138}
2023-01-04 05:25:37,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:37,001 INFO:     Epoch: 95
2023-01-04 05:25:38,560 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43154383103052774, 'Total loss': 0.43154383103052774} | train loss {'Reaction outcome loss': 0.165274606823894, 'Total loss': 0.165274606823894}
2023-01-04 05:25:38,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:38,561 INFO:     Epoch: 96
2023-01-04 05:25:40,169 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4395495255788167, 'Total loss': 0.4395495255788167} | train loss {'Reaction outcome loss': 0.16160134889566116, 'Total loss': 0.16160134889566116}
2023-01-04 05:25:40,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:40,169 INFO:     Epoch: 97
2023-01-04 05:25:41,782 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.427541650334994, 'Total loss': 0.427541650334994} | train loss {'Reaction outcome loss': 0.15753007355574383, 'Total loss': 0.15753007355574383}
2023-01-04 05:25:41,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:41,782 INFO:     Epoch: 98
2023-01-04 05:25:43,411 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4400265634059906, 'Total loss': 0.4400265634059906} | train loss {'Reaction outcome loss': 0.1621255291741423, 'Total loss': 0.1621255291741423}
2023-01-04 05:25:43,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:43,412 INFO:     Epoch: 99
2023-01-04 05:25:45,041 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41471411287784576, 'Total loss': 0.41471411287784576} | train loss {'Reaction outcome loss': 0.15963892888169, 'Total loss': 0.15963892888169}
2023-01-04 05:25:45,041 INFO:     Best model found after epoch 59 of 100.
2023-01-04 05:25:45,041 INFO:   Done with stage: TRAINING
2023-01-04 05:25:45,041 INFO:   Starting stage: EVALUATION
2023-01-04 05:25:45,174 INFO:   Done with stage: EVALUATION
2023-01-04 05:25:45,174 INFO:   Leaving out SEQ value Fold_6
2023-01-04 05:25:45,187 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:25:45,187 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:25:45,827 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:25:45,827 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:25:45,895 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:25:45,895 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:25:45,895 INFO:     No hyperparam tuning for this model
2023-01-04 05:25:45,895 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:25:45,895 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:25:45,896 INFO:     None feature selector for col prot
2023-01-04 05:25:45,896 INFO:     None feature selector for col prot
2023-01-04 05:25:45,896 INFO:     None feature selector for col prot
2023-01-04 05:25:45,896 INFO:     None feature selector for col chem
2023-01-04 05:25:45,896 INFO:     None feature selector for col chem
2023-01-04 05:25:45,897 INFO:     None feature selector for col chem
2023-01-04 05:25:45,897 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:25:45,897 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:25:45,898 INFO:     Number of params in model 70141
2023-01-04 05:25:45,901 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:25:45,901 INFO:   Starting stage: TRAINING
2023-01-04 05:25:45,945 INFO:     Val loss before train {'Reaction outcome loss': 1.0230887214342752, 'Total loss': 1.0230887214342752}
2023-01-04 05:25:45,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:45,945 INFO:     Epoch: 0
2023-01-04 05:25:47,524 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6604590296745301, 'Total loss': 0.6604590296745301} | train loss {'Reaction outcome loss': 0.8527264120561552, 'Total loss': 0.8527264120561552}
2023-01-04 05:25:47,524 INFO:     Found new best model at epoch 0
2023-01-04 05:25:47,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:47,525 INFO:     Epoch: 1
2023-01-04 05:25:49,165 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5324361244837443, 'Total loss': 0.5324361244837443} | train loss {'Reaction outcome loss': 0.5999741537045916, 'Total loss': 0.5999741537045916}
2023-01-04 05:25:49,165 INFO:     Found new best model at epoch 1
2023-01-04 05:25:49,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:49,166 INFO:     Epoch: 2
2023-01-04 05:25:50,798 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4919307231903076, 'Total loss': 0.4919307231903076} | train loss {'Reaction outcome loss': 0.5256014793896072, 'Total loss': 0.5256014793896072}
2023-01-04 05:25:50,799 INFO:     Found new best model at epoch 2
2023-01-04 05:25:50,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:50,799 INFO:     Epoch: 3
2023-01-04 05:25:52,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4573647598425547, 'Total loss': 0.4573647598425547} | train loss {'Reaction outcome loss': 0.49201800483228497, 'Total loss': 0.49201800483228497}
2023-01-04 05:25:52,445 INFO:     Found new best model at epoch 3
2023-01-04 05:25:52,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:52,446 INFO:     Epoch: 4
2023-01-04 05:25:54,051 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4306654850641886, 'Total loss': 0.4306654850641886} | train loss {'Reaction outcome loss': 0.4658604422416067, 'Total loss': 0.4658604422416067}
2023-01-04 05:25:54,051 INFO:     Found new best model at epoch 4
2023-01-04 05:25:54,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:54,052 INFO:     Epoch: 5
2023-01-04 05:25:55,677 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.418701625863711, 'Total loss': 0.418701625863711} | train loss {'Reaction outcome loss': 0.44305642573196535, 'Total loss': 0.44305642573196535}
2023-01-04 05:25:55,677 INFO:     Found new best model at epoch 5
2023-01-04 05:25:55,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:55,678 INFO:     Epoch: 6
2023-01-04 05:25:57,269 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43104637662569684, 'Total loss': 0.43104637662569684} | train loss {'Reaction outcome loss': 0.4306962450273631, 'Total loss': 0.4306962450273631}
2023-01-04 05:25:57,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:57,269 INFO:     Epoch: 7
2023-01-04 05:25:58,876 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40532066822052004, 'Total loss': 0.40532066822052004} | train loss {'Reaction outcome loss': 0.41740370071106436, 'Total loss': 0.41740370071106436}
2023-01-04 05:25:58,876 INFO:     Found new best model at epoch 7
2023-01-04 05:25:58,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:25:58,877 INFO:     Epoch: 8
2023-01-04 05:26:00,485 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41645358701546986, 'Total loss': 0.41645358701546986} | train loss {'Reaction outcome loss': 0.40701207228085623, 'Total loss': 0.40701207228085623}
2023-01-04 05:26:00,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:00,486 INFO:     Epoch: 9
2023-01-04 05:26:02,094 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40330424706141155, 'Total loss': 0.40330424706141155} | train loss {'Reaction outcome loss': 0.3969318975933192, 'Total loss': 0.3969318975933192}
2023-01-04 05:26:02,094 INFO:     Found new best model at epoch 9
2023-01-04 05:26:02,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:02,095 INFO:     Epoch: 10
2023-01-04 05:26:03,703 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38665225307146706, 'Total loss': 0.38665225307146706} | train loss {'Reaction outcome loss': 0.3902841532058234, 'Total loss': 0.3902841532058234}
2023-01-04 05:26:03,703 INFO:     Found new best model at epoch 10
2023-01-04 05:26:03,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:03,704 INFO:     Epoch: 11
2023-01-04 05:26:05,284 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.400048424800237, 'Total loss': 0.400048424800237} | train loss {'Reaction outcome loss': 0.37929705334054004, 'Total loss': 0.37929705334054004}
2023-01-04 05:26:05,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:05,284 INFO:     Epoch: 12
2023-01-04 05:26:06,897 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3862501084804535, 'Total loss': 0.3862501084804535} | train loss {'Reaction outcome loss': 0.374113239966575, 'Total loss': 0.374113239966575}
2023-01-04 05:26:06,897 INFO:     Found new best model at epoch 12
2023-01-04 05:26:06,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:06,898 INFO:     Epoch: 13
2023-01-04 05:26:08,534 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38481053411960603, 'Total loss': 0.38481053411960603} | train loss {'Reaction outcome loss': 0.36746684227824644, 'Total loss': 0.36746684227824644}
2023-01-04 05:26:08,535 INFO:     Found new best model at epoch 13
2023-01-04 05:26:08,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:08,536 INFO:     Epoch: 14
2023-01-04 05:26:10,170 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3931924233833949, 'Total loss': 0.3931924233833949} | train loss {'Reaction outcome loss': 0.358725140779027, 'Total loss': 0.358725140779027}
2023-01-04 05:26:10,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:10,170 INFO:     Epoch: 15
2023-01-04 05:26:11,799 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3788028458754222, 'Total loss': 0.3788028458754222} | train loss {'Reaction outcome loss': 0.352580559840056, 'Total loss': 0.352580559840056}
2023-01-04 05:26:11,800 INFO:     Found new best model at epoch 15
2023-01-04 05:26:11,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:11,801 INFO:     Epoch: 16
2023-01-04 05:26:13,427 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38053945899009706, 'Total loss': 0.38053945899009706} | train loss {'Reaction outcome loss': 0.3454753510949844, 'Total loss': 0.3454753510949844}
2023-01-04 05:26:13,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:13,427 INFO:     Epoch: 17
2023-01-04 05:26:15,012 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3776913280288378, 'Total loss': 0.3776913280288378} | train loss {'Reaction outcome loss': 0.3395804283528552, 'Total loss': 0.3395804283528552}
2023-01-04 05:26:15,013 INFO:     Found new best model at epoch 17
2023-01-04 05:26:15,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:15,013 INFO:     Epoch: 18
2023-01-04 05:26:16,639 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4058023035526276, 'Total loss': 0.4058023035526276} | train loss {'Reaction outcome loss': 0.33570783044672187, 'Total loss': 0.33570783044672187}
2023-01-04 05:26:16,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:16,639 INFO:     Epoch: 19
2023-01-04 05:26:18,267 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.37881539861361185, 'Total loss': 0.37881539861361185} | train loss {'Reaction outcome loss': 0.3275509062172704, 'Total loss': 0.3275509062172704}
2023-01-04 05:26:18,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:18,267 INFO:     Epoch: 20
2023-01-04 05:26:19,884 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3871303786834081, 'Total loss': 0.3871303786834081} | train loss {'Reaction outcome loss': 0.3239663239259152, 'Total loss': 0.3239663239259152}
2023-01-04 05:26:19,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:19,884 INFO:     Epoch: 21
2023-01-04 05:26:21,512 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3932265410820643, 'Total loss': 0.3932265410820643} | train loss {'Reaction outcome loss': 0.31600486984752146, 'Total loss': 0.31600486984752146}
2023-01-04 05:26:21,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:21,512 INFO:     Epoch: 22
2023-01-04 05:26:23,105 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3812130590279897, 'Total loss': 0.3812130590279897} | train loss {'Reaction outcome loss': 0.3129229222555453, 'Total loss': 0.3129229222555453}
2023-01-04 05:26:23,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:23,105 INFO:     Epoch: 23
2023-01-04 05:26:24,693 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3641442105174065, 'Total loss': 0.3641442105174065} | train loss {'Reaction outcome loss': 0.30783847856607677, 'Total loss': 0.30783847856607677}
2023-01-04 05:26:24,693 INFO:     Found new best model at epoch 23
2023-01-04 05:26:24,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:24,694 INFO:     Epoch: 24
2023-01-04 05:26:26,299 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.37280550301074983, 'Total loss': 0.37280550301074983} | train loss {'Reaction outcome loss': 0.30418224581634956, 'Total loss': 0.30418224581634956}
2023-01-04 05:26:26,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:26,299 INFO:     Epoch: 25
2023-01-04 05:26:27,904 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3758439511060715, 'Total loss': 0.3758439511060715} | train loss {'Reaction outcome loss': 0.29950084697307233, 'Total loss': 0.29950084697307233}
2023-01-04 05:26:27,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:27,905 INFO:     Epoch: 26
2023-01-04 05:26:29,509 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3609529664119085, 'Total loss': 0.3609529664119085} | train loss {'Reaction outcome loss': 0.29622526090282825, 'Total loss': 0.29622526090282825}
2023-01-04 05:26:29,509 INFO:     Found new best model at epoch 26
2023-01-04 05:26:29,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:29,510 INFO:     Epoch: 27
2023-01-04 05:26:31,116 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37932249506314597, 'Total loss': 0.37932249506314597} | train loss {'Reaction outcome loss': 0.2918937361466325, 'Total loss': 0.2918937361466325}
2023-01-04 05:26:31,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:31,116 INFO:     Epoch: 28
2023-01-04 05:26:32,698 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.37548937698205315, 'Total loss': 0.37548937698205315} | train loss {'Reaction outcome loss': 0.28847045919417474, 'Total loss': 0.28847045919417474}
2023-01-04 05:26:32,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:32,698 INFO:     Epoch: 29
2023-01-04 05:26:34,286 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.36815112431844077, 'Total loss': 0.36815112431844077} | train loss {'Reaction outcome loss': 0.28497954441859835, 'Total loss': 0.28497954441859835}
2023-01-04 05:26:34,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:34,286 INFO:     Epoch: 30
2023-01-04 05:26:35,918 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3872984637816747, 'Total loss': 0.3872984637816747} | train loss {'Reaction outcome loss': 0.28057660294246156, 'Total loss': 0.28057660294246156}
2023-01-04 05:26:35,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:35,918 INFO:     Epoch: 31
2023-01-04 05:26:37,576 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.35962642629941305, 'Total loss': 0.35962642629941305} | train loss {'Reaction outcome loss': 0.2793157958973616, 'Total loss': 0.2793157958973616}
2023-01-04 05:26:37,577 INFO:     Found new best model at epoch 31
2023-01-04 05:26:37,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:37,578 INFO:     Epoch: 32
2023-01-04 05:26:39,258 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3702710926532745, 'Total loss': 0.3702710926532745} | train loss {'Reaction outcome loss': 0.27457594022907933, 'Total loss': 0.27457594022907933}
2023-01-04 05:26:39,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:39,258 INFO:     Epoch: 33
2023-01-04 05:26:40,908 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.35458499590555825, 'Total loss': 0.35458499590555825} | train loss {'Reaction outcome loss': 0.27173235356162173, 'Total loss': 0.27173235356162173}
2023-01-04 05:26:40,908 INFO:     Found new best model at epoch 33
2023-01-04 05:26:40,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:40,910 INFO:     Epoch: 34
2023-01-04 05:26:42,550 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37038976748784386, 'Total loss': 0.37038976748784386} | train loss {'Reaction outcome loss': 0.2684466634012947, 'Total loss': 0.2684466634012947}
2023-01-04 05:26:42,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:42,550 INFO:     Epoch: 35
2023-01-04 05:26:44,228 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.36494691173235577, 'Total loss': 0.36494691173235577} | train loss {'Reaction outcome loss': 0.2643579147514023, 'Total loss': 0.2643579147514023}
2023-01-04 05:26:44,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:44,229 INFO:     Epoch: 36
2023-01-04 05:26:45,906 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3713890641927719, 'Total loss': 0.3713890641927719} | train loss {'Reaction outcome loss': 0.26103468978985983, 'Total loss': 0.26103468978985983}
2023-01-04 05:26:45,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:45,906 INFO:     Epoch: 37
2023-01-04 05:26:47,572 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.352461772163709, 'Total loss': 0.352461772163709} | train loss {'Reaction outcome loss': 0.25796303518842706, 'Total loss': 0.25796303518842706}
2023-01-04 05:26:47,572 INFO:     Found new best model at epoch 37
2023-01-04 05:26:47,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:47,573 INFO:     Epoch: 38
2023-01-04 05:26:49,169 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3412502686182658, 'Total loss': 0.3412502686182658} | train loss {'Reaction outcome loss': 0.25748678358668453, 'Total loss': 0.25748678358668453}
2023-01-04 05:26:49,169 INFO:     Found new best model at epoch 38
2023-01-04 05:26:49,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:49,170 INFO:     Epoch: 39
2023-01-04 05:26:50,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3666974743207296, 'Total loss': 0.3666974743207296} | train loss {'Reaction outcome loss': 0.25221384970289706, 'Total loss': 0.25221384970289706}
2023-01-04 05:26:50,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:50,746 INFO:     Epoch: 40
2023-01-04 05:26:52,382 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3726237714290619, 'Total loss': 0.3726237714290619} | train loss {'Reaction outcome loss': 0.2512377530659149, 'Total loss': 0.2512377530659149}
2023-01-04 05:26:52,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:52,383 INFO:     Epoch: 41
2023-01-04 05:26:54,020 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.345506996413072, 'Total loss': 0.345506996413072} | train loss {'Reaction outcome loss': 0.2460308046708899, 'Total loss': 0.2460308046708899}
2023-01-04 05:26:54,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:54,020 INFO:     Epoch: 42
2023-01-04 05:26:55,645 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.35008938511212667, 'Total loss': 0.35008938511212667} | train loss {'Reaction outcome loss': 0.2472881763393483, 'Total loss': 0.2472881763393483}
2023-01-04 05:26:55,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:55,645 INFO:     Epoch: 43
2023-01-04 05:26:57,238 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36122656961282096, 'Total loss': 0.36122656961282096} | train loss {'Reaction outcome loss': 0.2410471773830777, 'Total loss': 0.2410471773830777}
2023-01-04 05:26:57,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:57,238 INFO:     Epoch: 44
2023-01-04 05:26:58,836 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36465286562840143, 'Total loss': 0.36465286562840143} | train loss {'Reaction outcome loss': 0.23762370643310168, 'Total loss': 0.23762370643310168}
2023-01-04 05:26:58,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:26:58,837 INFO:     Epoch: 45
2023-01-04 05:27:00,436 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37331744929154714, 'Total loss': 0.37331744929154714} | train loss {'Reaction outcome loss': 0.23492974950679804, 'Total loss': 0.23492974950679804}
2023-01-04 05:27:00,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:00,437 INFO:     Epoch: 46
2023-01-04 05:27:02,087 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36239838004112246, 'Total loss': 0.36239838004112246} | train loss {'Reaction outcome loss': 0.23530754980896784, 'Total loss': 0.23530754980896784}
2023-01-04 05:27:02,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:02,088 INFO:     Epoch: 47
2023-01-04 05:27:03,703 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.383786940574646, 'Total loss': 0.383786940574646} | train loss {'Reaction outcome loss': 0.23432316754806773, 'Total loss': 0.23432316754806773}
2023-01-04 05:27:03,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:03,704 INFO:     Epoch: 48
2023-01-04 05:27:05,326 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38828977147738136, 'Total loss': 0.38828977147738136} | train loss {'Reaction outcome loss': 0.2311211111770425, 'Total loss': 0.2311211111770425}
2023-01-04 05:27:05,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:05,327 INFO:     Epoch: 49
2023-01-04 05:27:06,954 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3568437327941259, 'Total loss': 0.3568437327941259} | train loss {'Reaction outcome loss': 0.2284570729985349, 'Total loss': 0.2284570729985349}
2023-01-04 05:27:06,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:06,954 INFO:     Epoch: 50
2023-01-04 05:27:08,562 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.37038163244724276, 'Total loss': 0.37038163244724276} | train loss {'Reaction outcome loss': 0.22653060196646715, 'Total loss': 0.22653060196646715}
2023-01-04 05:27:08,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:08,563 INFO:     Epoch: 51
2023-01-04 05:27:10,176 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36327764987945554, 'Total loss': 0.36327764987945554} | train loss {'Reaction outcome loss': 0.22574615575346274, 'Total loss': 0.22574615575346274}
2023-01-04 05:27:10,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:10,176 INFO:     Epoch: 52
2023-01-04 05:27:11,823 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36431798338890076, 'Total loss': 0.36431798338890076} | train loss {'Reaction outcome loss': 0.22429772537699244, 'Total loss': 0.22429772537699244}
2023-01-04 05:27:11,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:11,823 INFO:     Epoch: 53
2023-01-04 05:27:13,440 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3784814288218816, 'Total loss': 0.3784814288218816} | train loss {'Reaction outcome loss': 0.2211242426280941, 'Total loss': 0.2211242426280941}
2023-01-04 05:27:13,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:13,440 INFO:     Epoch: 54
2023-01-04 05:27:15,033 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3716248114903768, 'Total loss': 0.3716248114903768} | train loss {'Reaction outcome loss': 0.2173813976455036, 'Total loss': 0.2173813976455036}
2023-01-04 05:27:15,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:15,033 INFO:     Epoch: 55
2023-01-04 05:27:16,662 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3683656737208366, 'Total loss': 0.3683656737208366} | train loss {'Reaction outcome loss': 0.217214427727009, 'Total loss': 0.217214427727009}
2023-01-04 05:27:16,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:16,662 INFO:     Epoch: 56
2023-01-04 05:27:18,240 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3621469080448151, 'Total loss': 0.3621469080448151} | train loss {'Reaction outcome loss': 0.2139659719642534, 'Total loss': 0.2139659719642534}
2023-01-04 05:27:18,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:18,240 INFO:     Epoch: 57
2023-01-04 05:27:19,831 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40318886935710907, 'Total loss': 0.40318886935710907} | train loss {'Reaction outcome loss': 0.21194516496215057, 'Total loss': 0.21194516496215057}
2023-01-04 05:27:19,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:19,831 INFO:     Epoch: 58
2023-01-04 05:27:21,458 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3801024258136749, 'Total loss': 0.3801024258136749} | train loss {'Reaction outcome loss': 0.2150216751365455, 'Total loss': 0.2150216751365455}
2023-01-04 05:27:21,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:21,459 INFO:     Epoch: 59
2023-01-04 05:27:23,072 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38993972589572273, 'Total loss': 0.38993972589572273} | train loss {'Reaction outcome loss': 0.20754691732489244, 'Total loss': 0.20754691732489244}
2023-01-04 05:27:23,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:23,072 INFO:     Epoch: 60
2023-01-04 05:27:24,669 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3786312679449717, 'Total loss': 0.3786312679449717} | train loss {'Reaction outcome loss': 0.20875244278339702, 'Total loss': 0.20875244278339702}
2023-01-04 05:27:24,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:24,669 INFO:     Epoch: 61
2023-01-04 05:27:26,266 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4315339436133703, 'Total loss': 0.4315339436133703} | train loss {'Reaction outcome loss': 0.20824313733982266, 'Total loss': 0.20824313733982266}
2023-01-04 05:27:26,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:26,266 INFO:     Epoch: 62
2023-01-04 05:27:27,873 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37870619893074037, 'Total loss': 0.37870619893074037} | train loss {'Reaction outcome loss': 0.20637526531243153, 'Total loss': 0.20637526531243153}
2023-01-04 05:27:27,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:27,874 INFO:     Epoch: 63
2023-01-04 05:27:29,502 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38407581945260366, 'Total loss': 0.38407581945260366} | train loss {'Reaction outcome loss': 0.20496944301771775, 'Total loss': 0.20496944301771775}
2023-01-04 05:27:29,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:29,502 INFO:     Epoch: 64
2023-01-04 05:27:31,093 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38278047839800516, 'Total loss': 0.38278047839800516} | train loss {'Reaction outcome loss': 0.20418107875417715, 'Total loss': 0.20418107875417715}
2023-01-04 05:27:31,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:31,094 INFO:     Epoch: 65
2023-01-04 05:27:32,723 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3723339279492696, 'Total loss': 0.3723339279492696} | train loss {'Reaction outcome loss': 0.20196844295796934, 'Total loss': 0.20196844295796934}
2023-01-04 05:27:32,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:32,723 INFO:     Epoch: 66
2023-01-04 05:27:34,353 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39657573302586874, 'Total loss': 0.39657573302586874} | train loss {'Reaction outcome loss': 0.19807455759320663, 'Total loss': 0.19807455759320663}
2023-01-04 05:27:34,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:34,353 INFO:     Epoch: 67
2023-01-04 05:27:35,918 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3816656365990639, 'Total loss': 0.3816656365990639} | train loss {'Reaction outcome loss': 0.19817257317502576, 'Total loss': 0.19817257317502576}
2023-01-04 05:27:35,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:35,918 INFO:     Epoch: 68
2023-01-04 05:27:37,558 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36705679396788277, 'Total loss': 0.36705679396788277} | train loss {'Reaction outcome loss': 0.1987881916793675, 'Total loss': 0.1987881916793675}
2023-01-04 05:27:37,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:37,558 INFO:     Epoch: 69
2023-01-04 05:27:39,151 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3934845174352328, 'Total loss': 0.3934845174352328} | train loss {'Reaction outcome loss': 0.1961411694636306, 'Total loss': 0.1961411694636306}
2023-01-04 05:27:39,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:39,151 INFO:     Epoch: 70
2023-01-04 05:27:40,769 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3912688801685969, 'Total loss': 0.3912688801685969} | train loss {'Reaction outcome loss': 0.197791591972543, 'Total loss': 0.197791591972543}
2023-01-04 05:27:40,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:40,770 INFO:     Epoch: 71
2023-01-04 05:27:42,384 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38095805843671166, 'Total loss': 0.38095805843671166} | train loss {'Reaction outcome loss': 0.19390235331568478, 'Total loss': 0.19390235331568478}
2023-01-04 05:27:42,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:42,384 INFO:     Epoch: 72
2023-01-04 05:27:44,013 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3917272130648295, 'Total loss': 0.3917272130648295} | train loss {'Reaction outcome loss': 0.19052818363081891, 'Total loss': 0.19052818363081891}
2023-01-04 05:27:44,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:44,013 INFO:     Epoch: 73
2023-01-04 05:27:45,589 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37733453313509624, 'Total loss': 0.37733453313509624} | train loss {'Reaction outcome loss': 0.19158113127177587, 'Total loss': 0.19158113127177587}
2023-01-04 05:27:45,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:45,590 INFO:     Epoch: 74
2023-01-04 05:27:47,208 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38533155421415966, 'Total loss': 0.38533155421415966} | train loss {'Reaction outcome loss': 0.18936119584992045, 'Total loss': 0.18936119584992045}
2023-01-04 05:27:47,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:47,208 INFO:     Epoch: 75
2023-01-04 05:27:48,844 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3699442168076833, 'Total loss': 0.3699442168076833} | train loss {'Reaction outcome loss': 0.18902610666000885, 'Total loss': 0.18902610666000885}
2023-01-04 05:27:48,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:48,844 INFO:     Epoch: 76
2023-01-04 05:27:50,478 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3829314718643824, 'Total loss': 0.3829314718643824} | train loss {'Reaction outcome loss': 0.1874434533747525, 'Total loss': 0.1874434533747525}
2023-01-04 05:27:50,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:50,478 INFO:     Epoch: 77
2023-01-04 05:27:52,091 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39745125969251, 'Total loss': 0.39745125969251} | train loss {'Reaction outcome loss': 0.18598143578866758, 'Total loss': 0.18598143578866758}
2023-01-04 05:27:52,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:52,092 INFO:     Epoch: 78
2023-01-04 05:27:53,691 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40058670192956924, 'Total loss': 0.40058670192956924} | train loss {'Reaction outcome loss': 0.18295990020063596, 'Total loss': 0.18295990020063596}
2023-01-04 05:27:53,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:53,691 INFO:     Epoch: 79
2023-01-04 05:27:55,313 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3955083688100179, 'Total loss': 0.3955083688100179} | train loss {'Reaction outcome loss': 0.18642945719432313, 'Total loss': 0.18642945719432313}
2023-01-04 05:27:55,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:55,314 INFO:     Epoch: 80
2023-01-04 05:27:56,948 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.385979404548804, 'Total loss': 0.385979404548804} | train loss {'Reaction outcome loss': 0.1829555539905164, 'Total loss': 0.1829555539905164}
2023-01-04 05:27:56,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:56,949 INFO:     Epoch: 81
2023-01-04 05:27:58,552 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3766742909948031, 'Total loss': 0.3766742909948031} | train loss {'Reaction outcome loss': 0.18385228282681226, 'Total loss': 0.18385228282681226}
2023-01-04 05:27:58,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:27:58,553 INFO:     Epoch: 82
2023-01-04 05:28:00,202 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39055078228314716, 'Total loss': 0.39055078228314716} | train loss {'Reaction outcome loss': 0.1826341265025767, 'Total loss': 0.1826341265025767}
2023-01-04 05:28:00,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:00,203 INFO:     Epoch: 83
2023-01-04 05:28:01,856 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4137263466914495, 'Total loss': 0.4137263466914495} | train loss {'Reaction outcome loss': 0.1816026543700792, 'Total loss': 0.1816026543700792}
2023-01-04 05:28:01,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:01,857 INFO:     Epoch: 84
2023-01-04 05:28:03,429 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.39724527299404144, 'Total loss': 0.39724527299404144} | train loss {'Reaction outcome loss': 0.18086350988932895, 'Total loss': 0.18086350988932895}
2023-01-04 05:28:03,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:03,430 INFO:     Epoch: 85
2023-01-04 05:28:05,034 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3735061732431253, 'Total loss': 0.3735061732431253} | train loss {'Reaction outcome loss': 0.17964036462808344, 'Total loss': 0.17964036462808344}
2023-01-04 05:28:05,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:05,034 INFO:     Epoch: 86
2023-01-04 05:28:06,639 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39664604266484577, 'Total loss': 0.39664604266484577} | train loss {'Reaction outcome loss': 0.17888815396394755, 'Total loss': 0.17888815396394755}
2023-01-04 05:28:06,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:06,640 INFO:     Epoch: 87
2023-01-04 05:28:08,245 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39101901749769846, 'Total loss': 0.39101901749769846} | train loss {'Reaction outcome loss': 0.17709258810654013, 'Total loss': 0.17709258810654013}
2023-01-04 05:28:08,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:08,246 INFO:     Epoch: 88
2023-01-04 05:28:09,851 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3962908685207367, 'Total loss': 0.3962908685207367} | train loss {'Reaction outcome loss': 0.17677780066613472, 'Total loss': 0.17677780066613472}
2023-01-04 05:28:09,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:09,851 INFO:     Epoch: 89
2023-01-04 05:28:11,432 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3862926661968231, 'Total loss': 0.3862926661968231} | train loss {'Reaction outcome loss': 0.176734005117836, 'Total loss': 0.176734005117836}
2023-01-04 05:28:11,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:11,432 INFO:     Epoch: 90
2023-01-04 05:28:13,052 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38229058086872103, 'Total loss': 0.38229058086872103} | train loss {'Reaction outcome loss': 0.17505374874933102, 'Total loss': 0.17505374874933102}
2023-01-04 05:28:13,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:13,052 INFO:     Epoch: 91
2023-01-04 05:28:14,632 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.412746728459994, 'Total loss': 0.412746728459994} | train loss {'Reaction outcome loss': 0.17397017807898107, 'Total loss': 0.17397017807898107}
2023-01-04 05:28:14,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:14,633 INFO:     Epoch: 92
2023-01-04 05:28:16,263 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38135410149892174, 'Total loss': 0.38135410149892174} | train loss {'Reaction outcome loss': 0.17207758402996545, 'Total loss': 0.17207758402996545}
2023-01-04 05:28:16,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:16,264 INFO:     Epoch: 93
2023-01-04 05:28:17,896 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3972570985555649, 'Total loss': 0.3972570985555649} | train loss {'Reaction outcome loss': 0.17191767279690784, 'Total loss': 0.17191767279690784}
2023-01-04 05:28:17,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:17,896 INFO:     Epoch: 94
2023-01-04 05:28:19,477 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42954113508264224, 'Total loss': 0.42954113508264224} | train loss {'Reaction outcome loss': 0.16859626639567127, 'Total loss': 0.16859626639567127}
2023-01-04 05:28:19,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:19,477 INFO:     Epoch: 95
2023-01-04 05:28:21,049 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3976041913032532, 'Total loss': 0.3976041913032532} | train loss {'Reaction outcome loss': 0.16975134315930765, 'Total loss': 0.16975134315930765}
2023-01-04 05:28:21,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:21,049 INFO:     Epoch: 96
2023-01-04 05:28:22,635 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4046039630969365, 'Total loss': 0.4046039630969365} | train loss {'Reaction outcome loss': 0.1706470604649735, 'Total loss': 0.1706470604649735}
2023-01-04 05:28:22,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:22,635 INFO:     Epoch: 97
2023-01-04 05:28:24,250 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42547781964143117, 'Total loss': 0.42547781964143117} | train loss {'Reaction outcome loss': 0.17100388494854799, 'Total loss': 0.17100388494854799}
2023-01-04 05:28:24,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:24,250 INFO:     Epoch: 98
2023-01-04 05:28:25,845 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39943746229012805, 'Total loss': 0.39943746229012805} | train loss {'Reaction outcome loss': 0.16778393161721825, 'Total loss': 0.16778393161721825}
2023-01-04 05:28:25,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:25,845 INFO:     Epoch: 99
2023-01-04 05:28:27,427 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4015943874915441, 'Total loss': 0.4015943874915441} | train loss {'Reaction outcome loss': 0.16849371583103487, 'Total loss': 0.16849371583103487}
2023-01-04 05:28:27,427 INFO:     Best model found after epoch 39 of 100.
2023-01-04 05:28:27,427 INFO:   Done with stage: TRAINING
2023-01-04 05:28:27,427 INFO:   Starting stage: EVALUATION
2023-01-04 05:28:27,550 INFO:   Done with stage: EVALUATION
2023-01-04 05:28:27,550 INFO:   Leaving out SEQ value Fold_7
2023-01-04 05:28:27,563 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:28:27,563 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:28:28,209 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:28:28,209 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:28:28,276 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:28:28,276 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:28:28,276 INFO:     No hyperparam tuning for this model
2023-01-04 05:28:28,276 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:28:28,276 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:28:28,277 INFO:     None feature selector for col prot
2023-01-04 05:28:28,277 INFO:     None feature selector for col prot
2023-01-04 05:28:28,277 INFO:     None feature selector for col prot
2023-01-04 05:28:28,278 INFO:     None feature selector for col chem
2023-01-04 05:28:28,278 INFO:     None feature selector for col chem
2023-01-04 05:28:28,278 INFO:     None feature selector for col chem
2023-01-04 05:28:28,278 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:28:28,278 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:28:28,279 INFO:     Number of params in model 70141
2023-01-04 05:28:28,283 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:28:28,283 INFO:   Starting stage: TRAINING
2023-01-04 05:28:28,326 INFO:     Val loss before train {'Reaction outcome loss': 1.0378358840942383, 'Total loss': 1.0378358840942383}
2023-01-04 05:28:28,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:28,326 INFO:     Epoch: 0
2023-01-04 05:28:29,890 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6319034417470296, 'Total loss': 0.6319034417470296} | train loss {'Reaction outcome loss': 0.8293123195748037, 'Total loss': 0.8293123195748037}
2023-01-04 05:28:29,890 INFO:     Found new best model at epoch 0
2023-01-04 05:28:29,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:29,891 INFO:     Epoch: 1
2023-01-04 05:28:31,530 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5317738691965739, 'Total loss': 0.5317738691965739} | train loss {'Reaction outcome loss': 0.5892455783884448, 'Total loss': 0.5892455783884448}
2023-01-04 05:28:31,530 INFO:     Found new best model at epoch 1
2023-01-04 05:28:31,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:31,531 INFO:     Epoch: 2
2023-01-04 05:28:33,173 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5091499388217926, 'Total loss': 0.5091499388217926} | train loss {'Reaction outcome loss': 0.5264281916704419, 'Total loss': 0.5264281916704419}
2023-01-04 05:28:33,174 INFO:     Found new best model at epoch 2
2023-01-04 05:28:33,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:33,175 INFO:     Epoch: 3
2023-01-04 05:28:34,764 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4754452566305796, 'Total loss': 0.4754452566305796} | train loss {'Reaction outcome loss': 0.49016065787967794, 'Total loss': 0.49016065787967794}
2023-01-04 05:28:34,764 INFO:     Found new best model at epoch 3
2023-01-04 05:28:34,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:34,765 INFO:     Epoch: 4
2023-01-04 05:28:36,387 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46417262057463327, 'Total loss': 0.46417262057463327} | train loss {'Reaction outcome loss': 0.46331656952842476, 'Total loss': 0.46331656952842476}
2023-01-04 05:28:36,387 INFO:     Found new best model at epoch 4
2023-01-04 05:28:36,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:36,388 INFO:     Epoch: 5
2023-01-04 05:28:37,970 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4618937472502391, 'Total loss': 0.4618937472502391} | train loss {'Reaction outcome loss': 0.4401516160702447, 'Total loss': 0.4401516160702447}
2023-01-04 05:28:37,970 INFO:     Found new best model at epoch 5
2023-01-04 05:28:37,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:37,971 INFO:     Epoch: 6
2023-01-04 05:28:39,585 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4539271136124929, 'Total loss': 0.4539271136124929} | train loss {'Reaction outcome loss': 0.4229559495991318, 'Total loss': 0.4229559495991318}
2023-01-04 05:28:39,586 INFO:     Found new best model at epoch 6
2023-01-04 05:28:39,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:39,587 INFO:     Epoch: 7
2023-01-04 05:28:41,213 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4525302330652873, 'Total loss': 0.4525302330652873} | train loss {'Reaction outcome loss': 0.41047749558080404, 'Total loss': 0.41047749558080404}
2023-01-04 05:28:41,214 INFO:     Found new best model at epoch 7
2023-01-04 05:28:41,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:41,214 INFO:     Epoch: 8
2023-01-04 05:28:42,801 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4452876706918081, 'Total loss': 0.4452876706918081} | train loss {'Reaction outcome loss': 0.3978644599230281, 'Total loss': 0.3978644599230281}
2023-01-04 05:28:42,801 INFO:     Found new best model at epoch 8
2023-01-04 05:28:42,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:42,802 INFO:     Epoch: 9
2023-01-04 05:28:44,412 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4348384340604146, 'Total loss': 0.4348384340604146} | train loss {'Reaction outcome loss': 0.3864235965138308, 'Total loss': 0.3864235965138308}
2023-01-04 05:28:44,412 INFO:     Found new best model at epoch 9
2023-01-04 05:28:44,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:44,413 INFO:     Epoch: 10
2023-01-04 05:28:46,069 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42908164660135906, 'Total loss': 0.42908164660135906} | train loss {'Reaction outcome loss': 0.3756054956936664, 'Total loss': 0.3756054956936664}
2023-01-04 05:28:46,069 INFO:     Found new best model at epoch 10
2023-01-04 05:28:46,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:46,070 INFO:     Epoch: 11
2023-01-04 05:28:47,639 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.434624050060908, 'Total loss': 0.434624050060908} | train loss {'Reaction outcome loss': 0.36767857548669786, 'Total loss': 0.36767857548669786}
2023-01-04 05:28:47,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:47,640 INFO:     Epoch: 12
2023-01-04 05:28:49,268 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4356481522321701, 'Total loss': 0.4356481522321701} | train loss {'Reaction outcome loss': 0.3561454707427145, 'Total loss': 0.3561454707427145}
2023-01-04 05:28:49,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:49,269 INFO:     Epoch: 13
2023-01-04 05:28:50,897 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42791787087917327, 'Total loss': 0.42791787087917327} | train loss {'Reaction outcome loss': 0.35172238278905404, 'Total loss': 0.35172238278905404}
2023-01-04 05:28:50,898 INFO:     Found new best model at epoch 13
2023-01-04 05:28:50,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:50,898 INFO:     Epoch: 14
2023-01-04 05:28:52,509 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4270810643831889, 'Total loss': 0.4270810643831889} | train loss {'Reaction outcome loss': 0.3440319291628655, 'Total loss': 0.3440319291628655}
2023-01-04 05:28:52,510 INFO:     Found new best model at epoch 14
2023-01-04 05:28:52,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:52,511 INFO:     Epoch: 15
2023-01-04 05:28:54,118 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43199032346407573, 'Total loss': 0.43199032346407573} | train loss {'Reaction outcome loss': 0.336168946449507, 'Total loss': 0.336168946449507}
2023-01-04 05:28:54,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:54,118 INFO:     Epoch: 16
2023-01-04 05:28:55,704 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42945472002029417, 'Total loss': 0.42945472002029417} | train loss {'Reaction outcome loss': 0.33076553673412823, 'Total loss': 0.33076553673412823}
2023-01-04 05:28:55,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:55,704 INFO:     Epoch: 17
2023-01-04 05:28:57,301 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41939712017774583, 'Total loss': 0.41939712017774583} | train loss {'Reaction outcome loss': 0.3259113847886612, 'Total loss': 0.3259113847886612}
2023-01-04 05:28:57,301 INFO:     Found new best model at epoch 17
2023-01-04 05:28:57,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:57,302 INFO:     Epoch: 18
2023-01-04 05:28:58,925 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4328530271848043, 'Total loss': 0.4328530271848043} | train loss {'Reaction outcome loss': 0.3216616153071503, 'Total loss': 0.3216616153071503}
2023-01-04 05:28:58,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:28:58,925 INFO:     Epoch: 19
2023-01-04 05:29:00,547 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43444516360759733, 'Total loss': 0.43444516360759733} | train loss {'Reaction outcome loss': 0.3126730139397542, 'Total loss': 0.3126730139397542}
2023-01-04 05:29:00,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:00,547 INFO:     Epoch: 20
2023-01-04 05:29:02,167 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4413879374663035, 'Total loss': 0.4413879374663035} | train loss {'Reaction outcome loss': 0.3092379352945283, 'Total loss': 0.3092379352945283}
2023-01-04 05:29:02,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:02,167 INFO:     Epoch: 21
2023-01-04 05:29:03,752 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4289741615454356, 'Total loss': 0.4289741615454356} | train loss {'Reaction outcome loss': 0.306119576849662, 'Total loss': 0.306119576849662}
2023-01-04 05:29:03,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:03,752 INFO:     Epoch: 22
2023-01-04 05:29:05,345 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4446780145168304, 'Total loss': 0.4446780145168304} | train loss {'Reaction outcome loss': 0.30290082735866847, 'Total loss': 0.30290082735866847}
2023-01-04 05:29:05,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:05,346 INFO:     Epoch: 23
2023-01-04 05:29:06,943 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45000606775283813, 'Total loss': 0.45000606775283813} | train loss {'Reaction outcome loss': 0.29663684106152843, 'Total loss': 0.29663684106152843}
2023-01-04 05:29:06,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:06,943 INFO:     Epoch: 24
2023-01-04 05:29:08,564 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4542504111925761, 'Total loss': 0.4542504111925761} | train loss {'Reaction outcome loss': 0.2929389011182079, 'Total loss': 0.2929389011182079}
2023-01-04 05:29:08,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:08,565 INFO:     Epoch: 25
2023-01-04 05:29:10,171 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44871325890223185, 'Total loss': 0.44871325890223185} | train loss {'Reaction outcome loss': 0.2853526274542516, 'Total loss': 0.2853526274542516}
2023-01-04 05:29:10,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:10,172 INFO:     Epoch: 26
2023-01-04 05:29:11,779 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43385778566201527, 'Total loss': 0.43385778566201527} | train loss {'Reaction outcome loss': 0.2835127493427118, 'Total loss': 0.2835127493427118}
2023-01-04 05:29:11,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:11,780 INFO:     Epoch: 27
2023-01-04 05:29:13,411 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43899784684181214, 'Total loss': 0.43899784684181214} | train loss {'Reaction outcome loss': 0.28033971641253047, 'Total loss': 0.28033971641253047}
2023-01-04 05:29:13,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:13,412 INFO:     Epoch: 28
2023-01-04 05:29:14,981 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44706522623697914, 'Total loss': 0.44706522623697914} | train loss {'Reaction outcome loss': 0.2757628415358196, 'Total loss': 0.2757628415358196}
2023-01-04 05:29:14,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:14,982 INFO:     Epoch: 29
2023-01-04 05:29:16,625 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4469644486904144, 'Total loss': 0.4469644486904144} | train loss {'Reaction outcome loss': 0.2751901143832327, 'Total loss': 0.2751901143832327}
2023-01-04 05:29:16,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:16,626 INFO:     Epoch: 30
2023-01-04 05:29:18,260 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43906705180803934, 'Total loss': 0.43906705180803934} | train loss {'Reaction outcome loss': 0.2710442926048802, 'Total loss': 0.2710442926048802}
2023-01-04 05:29:18,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:18,260 INFO:     Epoch: 31
2023-01-04 05:29:19,872 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45728302995363873, 'Total loss': 0.45728302995363873} | train loss {'Reaction outcome loss': 0.26952109690284903, 'Total loss': 0.26952109690284903}
2023-01-04 05:29:19,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:19,872 INFO:     Epoch: 32
2023-01-04 05:29:21,504 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4558905601501465, 'Total loss': 0.4558905601501465} | train loss {'Reaction outcome loss': 0.2655820390646638, 'Total loss': 0.2655820390646638}
2023-01-04 05:29:21,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:21,504 INFO:     Epoch: 33
2023-01-04 05:29:23,121 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45801207025845847, 'Total loss': 0.45801207025845847} | train loss {'Reaction outcome loss': 0.2629169629960714, 'Total loss': 0.2629169629960714}
2023-01-04 05:29:23,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:23,121 INFO:     Epoch: 34
2023-01-04 05:29:24,740 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43685575673977534, 'Total loss': 0.43685575673977534} | train loss {'Reaction outcome loss': 0.2609700859130935, 'Total loss': 0.2609700859130935}
2023-01-04 05:29:24,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:24,740 INFO:     Epoch: 35
2023-01-04 05:29:26,341 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45938438375790913, 'Total loss': 0.45938438375790913} | train loss {'Reaction outcome loss': 0.255358558672645, 'Total loss': 0.255358558672645}
2023-01-04 05:29:26,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:26,341 INFO:     Epoch: 36
2023-01-04 05:29:27,951 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4468461453914642, 'Total loss': 0.4468461453914642} | train loss {'Reaction outcome loss': 0.2557611334329263, 'Total loss': 0.2557611334329263}
2023-01-04 05:29:27,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:27,952 INFO:     Epoch: 37
2023-01-04 05:29:29,560 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4438075959682465, 'Total loss': 0.4438075959682465} | train loss {'Reaction outcome loss': 0.25372997294802097, 'Total loss': 0.25372997294802097}
2023-01-04 05:29:29,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:29,560 INFO:     Epoch: 38
2023-01-04 05:29:31,168 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4606225083271662, 'Total loss': 0.4606225083271662} | train loss {'Reaction outcome loss': 0.2496188097374534, 'Total loss': 0.2496188097374534}
2023-01-04 05:29:31,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:31,169 INFO:     Epoch: 39
2023-01-04 05:29:32,751 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45460371176401776, 'Total loss': 0.45460371176401776} | train loss {'Reaction outcome loss': 0.24813796001543637, 'Total loss': 0.24813796001543637}
2023-01-04 05:29:32,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:32,751 INFO:     Epoch: 40
2023-01-04 05:29:34,359 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4554445644219716, 'Total loss': 0.4554445644219716} | train loss {'Reaction outcome loss': 0.246841644874979, 'Total loss': 0.246841644874979}
2023-01-04 05:29:34,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:34,359 INFO:     Epoch: 41
2023-01-04 05:29:35,968 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4592403084039688, 'Total loss': 0.4592403084039688} | train loss {'Reaction outcome loss': 0.243987599676912, 'Total loss': 0.243987599676912}
2023-01-04 05:29:35,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:35,969 INFO:     Epoch: 42
2023-01-04 05:29:37,577 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4653624614079793, 'Total loss': 0.4653624614079793} | train loss {'Reaction outcome loss': 0.24022556068073112, 'Total loss': 0.24022556068073112}
2023-01-04 05:29:37,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:37,578 INFO:     Epoch: 43
2023-01-04 05:29:39,185 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45125303069750466, 'Total loss': 0.45125303069750466} | train loss {'Reaction outcome loss': 0.24004526702613177, 'Total loss': 0.24004526702613177}
2023-01-04 05:29:39,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:39,185 INFO:     Epoch: 44
2023-01-04 05:29:40,773 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4547106365362803, 'Total loss': 0.4547106365362803} | train loss {'Reaction outcome loss': 0.23726657989169286, 'Total loss': 0.23726657989169286}
2023-01-04 05:29:40,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:40,774 INFO:     Epoch: 45
2023-01-04 05:29:42,358 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4571550408999125, 'Total loss': 0.4571550408999125} | train loss {'Reaction outcome loss': 0.2339788838172002, 'Total loss': 0.2339788838172002}
2023-01-04 05:29:42,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:42,358 INFO:     Epoch: 46
2023-01-04 05:29:43,975 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44248505706588426, 'Total loss': 0.44248505706588426} | train loss {'Reaction outcome loss': 0.2347919862139096, 'Total loss': 0.2347919862139096}
2023-01-04 05:29:43,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:43,976 INFO:     Epoch: 47
2023-01-04 05:29:45,568 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45502450366814934, 'Total loss': 0.45502450366814934} | train loss {'Reaction outcome loss': 0.23199734983407633, 'Total loss': 0.23199734983407633}
2023-01-04 05:29:45,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:45,568 INFO:     Epoch: 48
2023-01-04 05:29:47,197 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4854505101839701, 'Total loss': 0.4854505101839701} | train loss {'Reaction outcome loss': 0.22952563501894474, 'Total loss': 0.22952563501894474}
2023-01-04 05:29:47,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:47,197 INFO:     Epoch: 49
2023-01-04 05:29:48,827 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4684744209051132, 'Total loss': 0.4684744209051132} | train loss {'Reaction outcome loss': 0.22727126837960218, 'Total loss': 0.22727126837960218}
2023-01-04 05:29:48,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:48,827 INFO:     Epoch: 50
2023-01-04 05:29:50,410 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45650429725646974, 'Total loss': 0.45650429725646974} | train loss {'Reaction outcome loss': 0.22730655900945732, 'Total loss': 0.22730655900945732}
2023-01-04 05:29:50,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:50,410 INFO:     Epoch: 51
2023-01-04 05:29:52,052 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45582339763641355, 'Total loss': 0.45582339763641355} | train loss {'Reaction outcome loss': 0.22495619893504393, 'Total loss': 0.22495619893504393}
2023-01-04 05:29:52,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:52,052 INFO:     Epoch: 52
2023-01-04 05:29:53,703 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4675874908765157, 'Total loss': 0.4675874908765157} | train loss {'Reaction outcome loss': 0.22195802982694837, 'Total loss': 0.22195802982694837}
2023-01-04 05:29:53,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:53,703 INFO:     Epoch: 53
2023-01-04 05:29:55,351 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4693855265776316, 'Total loss': 0.4693855265776316} | train loss {'Reaction outcome loss': 0.21913584941722425, 'Total loss': 0.21913584941722425}
2023-01-04 05:29:55,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:55,352 INFO:     Epoch: 54
2023-01-04 05:29:57,000 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4630413283904394, 'Total loss': 0.4630413283904394} | train loss {'Reaction outcome loss': 0.21850979571577014, 'Total loss': 0.21850979571577014}
2023-01-04 05:29:57,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:57,000 INFO:     Epoch: 55
2023-01-04 05:29:58,591 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4791770855585734, 'Total loss': 0.4791770855585734} | train loss {'Reaction outcome loss': 0.21827298186262162, 'Total loss': 0.21827298186262162}
2023-01-04 05:29:58,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:29:58,591 INFO:     Epoch: 56
2023-01-04 05:30:00,172 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4674582282702128, 'Total loss': 0.4674582282702128} | train loss {'Reaction outcome loss': 0.21616232010539257, 'Total loss': 0.21616232010539257}
2023-01-04 05:30:00,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:00,172 INFO:     Epoch: 57
2023-01-04 05:30:01,804 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.472339125474294, 'Total loss': 0.472339125474294} | train loss {'Reaction outcome loss': 0.2159028894701697, 'Total loss': 0.2159028894701697}
2023-01-04 05:30:01,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:01,805 INFO:     Epoch: 58
2023-01-04 05:30:03,411 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43611096143722533, 'Total loss': 0.43611096143722533} | train loss {'Reaction outcome loss': 0.21179172974954014, 'Total loss': 0.21179172974954014}
2023-01-04 05:30:03,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:03,412 INFO:     Epoch: 59
2023-01-04 05:30:05,020 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4568532327810923, 'Total loss': 0.4568532327810923} | train loss {'Reaction outcome loss': 0.21457188380108844, 'Total loss': 0.21457188380108844}
2023-01-04 05:30:05,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:05,020 INFO:     Epoch: 60
2023-01-04 05:30:06,647 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44850759506225585, 'Total loss': 0.44850759506225585} | train loss {'Reaction outcome loss': 0.20934712011299839, 'Total loss': 0.20934712011299839}
2023-01-04 05:30:06,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:06,647 INFO:     Epoch: 61
2023-01-04 05:30:08,228 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4531128625075022, 'Total loss': 0.4531128625075022} | train loss {'Reaction outcome loss': 0.21004031481564261, 'Total loss': 0.21004031481564261}
2023-01-04 05:30:08,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:08,228 INFO:     Epoch: 62
2023-01-04 05:30:09,845 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4762743294239044, 'Total loss': 0.4762743294239044} | train loss {'Reaction outcome loss': 0.2085707366251343, 'Total loss': 0.2085707366251343}
2023-01-04 05:30:09,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:09,845 INFO:     Epoch: 63
2023-01-04 05:30:11,491 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.465543070435524, 'Total loss': 0.465543070435524} | train loss {'Reaction outcome loss': 0.20583402198682194, 'Total loss': 0.20583402198682194}
2023-01-04 05:30:11,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:11,491 INFO:     Epoch: 64
2023-01-04 05:30:13,139 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49663957158724464, 'Total loss': 0.49663957158724464} | train loss {'Reaction outcome loss': 0.2040857537666383, 'Total loss': 0.2040857537666383}
2023-01-04 05:30:13,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:13,139 INFO:     Epoch: 65
2023-01-04 05:30:14,795 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47484545906384784, 'Total loss': 0.47484545906384784} | train loss {'Reaction outcome loss': 0.2038666628744951, 'Total loss': 0.2038666628744951}
2023-01-04 05:30:14,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:14,796 INFO:     Epoch: 66
2023-01-04 05:30:16,440 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4770662059386571, 'Total loss': 0.4770662059386571} | train loss {'Reaction outcome loss': 0.20357940495283164, 'Total loss': 0.20357940495283164}
2023-01-04 05:30:16,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:16,440 INFO:     Epoch: 67
2023-01-04 05:30:18,027 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47876917322476703, 'Total loss': 0.47876917322476703} | train loss {'Reaction outcome loss': 0.2009312580289178, 'Total loss': 0.2009312580289178}
2023-01-04 05:30:18,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:18,027 INFO:     Epoch: 68
2023-01-04 05:30:19,678 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4691152771313985, 'Total loss': 0.4691152771313985} | train loss {'Reaction outcome loss': 0.20152118787277046, 'Total loss': 0.20152118787277046}
2023-01-04 05:30:19,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:19,679 INFO:     Epoch: 69
2023-01-04 05:30:21,324 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4637780288855235, 'Total loss': 0.4637780288855235} | train loss {'Reaction outcome loss': 0.19834068327442833, 'Total loss': 0.19834068327442833}
2023-01-04 05:30:21,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:21,324 INFO:     Epoch: 70
2023-01-04 05:30:22,970 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4761493762334188, 'Total loss': 0.4761493762334188} | train loss {'Reaction outcome loss': 0.19780533255114882, 'Total loss': 0.19780533255114882}
2023-01-04 05:30:22,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:22,970 INFO:     Epoch: 71
2023-01-04 05:30:24,588 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4594955046971639, 'Total loss': 0.4594955046971639} | train loss {'Reaction outcome loss': 0.19587561774608891, 'Total loss': 0.19587561774608891}
2023-01-04 05:30:24,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:24,589 INFO:     Epoch: 72
2023-01-04 05:30:26,198 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47152817944685615, 'Total loss': 0.47152817944685615} | train loss {'Reaction outcome loss': 0.1949863968692747, 'Total loss': 0.1949863968692747}
2023-01-04 05:30:26,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:26,198 INFO:     Epoch: 73
2023-01-04 05:30:27,775 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46058192253112795, 'Total loss': 0.46058192253112795} | train loss {'Reaction outcome loss': 0.1945508880009505, 'Total loss': 0.1945508880009505}
2023-01-04 05:30:27,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:27,776 INFO:     Epoch: 74
2023-01-04 05:30:29,368 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4645910898844401, 'Total loss': 0.4645910898844401} | train loss {'Reaction outcome loss': 0.19351365355378022, 'Total loss': 0.19351365355378022}
2023-01-04 05:30:29,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:29,369 INFO:     Epoch: 75
2023-01-04 05:30:30,971 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46409720182418823, 'Total loss': 0.46409720182418823} | train loss {'Reaction outcome loss': 0.19244869721764263, 'Total loss': 0.19244869721764263}
2023-01-04 05:30:30,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:30,972 INFO:     Epoch: 76
2023-01-04 05:30:32,562 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4697711398204168, 'Total loss': 0.4697711398204168} | train loss {'Reaction outcome loss': 0.19250887750718568, 'Total loss': 0.19250887750718568}
2023-01-04 05:30:32,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:32,562 INFO:     Epoch: 77
2023-01-04 05:30:34,191 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47310769160588584, 'Total loss': 0.47310769160588584} | train loss {'Reaction outcome loss': 0.1910621945877368, 'Total loss': 0.1910621945877368}
2023-01-04 05:30:34,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:34,192 INFO:     Epoch: 78
2023-01-04 05:30:35,763 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47371778190135955, 'Total loss': 0.47371778190135955} | train loss {'Reaction outcome loss': 0.187950206698601, 'Total loss': 0.187950206698601}
2023-01-04 05:30:35,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:35,763 INFO:     Epoch: 79
2023-01-04 05:30:37,373 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48943092226982116, 'Total loss': 0.48943092226982116} | train loss {'Reaction outcome loss': 0.18899489130945843, 'Total loss': 0.18899489130945843}
2023-01-04 05:30:37,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:37,373 INFO:     Epoch: 80
2023-01-04 05:30:38,978 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47525172928969067, 'Total loss': 0.47525172928969067} | train loss {'Reaction outcome loss': 0.18804762191021485, 'Total loss': 0.18804762191021485}
2023-01-04 05:30:38,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:38,978 INFO:     Epoch: 81
2023-01-04 05:30:40,582 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5022470355033875, 'Total loss': 0.5022470355033875} | train loss {'Reaction outcome loss': 0.18597802939397765, 'Total loss': 0.18597802939397765}
2023-01-04 05:30:40,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:40,583 INFO:     Epoch: 82
2023-01-04 05:30:42,187 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4786308983961741, 'Total loss': 0.4786308983961741} | train loss {'Reaction outcome loss': 0.18421719537960493, 'Total loss': 0.18421719537960493}
2023-01-04 05:30:42,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:42,187 INFO:     Epoch: 83
2023-01-04 05:30:43,782 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4831431130568186, 'Total loss': 0.4831431130568186} | train loss {'Reaction outcome loss': 0.18496308148256924, 'Total loss': 0.18496308148256924}
2023-01-04 05:30:43,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:43,782 INFO:     Epoch: 84
2023-01-04 05:30:45,379 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45985722144444785, 'Total loss': 0.45985722144444785} | train loss {'Reaction outcome loss': 0.18547326745969725, 'Total loss': 0.18547326745969725}
2023-01-04 05:30:45,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:45,381 INFO:     Epoch: 85
2023-01-04 05:30:46,995 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47750069896380104, 'Total loss': 0.47750069896380104} | train loss {'Reaction outcome loss': 0.1841674749453683, 'Total loss': 0.1841674749453683}
2023-01-04 05:30:46,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:46,996 INFO:     Epoch: 86
2023-01-04 05:30:48,600 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4713677068551381, 'Total loss': 0.4713677068551381} | train loss {'Reaction outcome loss': 0.18244260405644183, 'Total loss': 0.18244260405644183}
2023-01-04 05:30:48,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:48,600 INFO:     Epoch: 87
2023-01-04 05:30:50,204 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4862186382214228, 'Total loss': 0.4862186382214228} | train loss {'Reaction outcome loss': 0.18270599289329903, 'Total loss': 0.18270599289329903}
2023-01-04 05:30:50,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:50,205 INFO:     Epoch: 88
2023-01-04 05:30:51,808 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48748894929885866, 'Total loss': 0.48748894929885866} | train loss {'Reaction outcome loss': 0.1853149012941531, 'Total loss': 0.1853149012941531}
2023-01-04 05:30:51,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:51,809 INFO:     Epoch: 89
2023-01-04 05:30:53,395 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4628201355536779, 'Total loss': 0.4628201355536779} | train loss {'Reaction outcome loss': 0.18067633528733082, 'Total loss': 0.18067633528733082}
2023-01-04 05:30:53,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:53,395 INFO:     Epoch: 90
2023-01-04 05:30:55,037 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48906309306621554, 'Total loss': 0.48906309306621554} | train loss {'Reaction outcome loss': 0.18147956624304346, 'Total loss': 0.18147956624304346}
2023-01-04 05:30:55,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:55,038 INFO:     Epoch: 91
2023-01-04 05:30:56,675 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4701494599382083, 'Total loss': 0.4701494599382083} | train loss {'Reaction outcome loss': 0.17670038797042, 'Total loss': 0.17670038797042}
2023-01-04 05:30:56,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:56,675 INFO:     Epoch: 92
2023-01-04 05:30:58,311 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47959790627161664, 'Total loss': 0.47959790627161664} | train loss {'Reaction outcome loss': 0.17605011587431285, 'Total loss': 0.17605011587431285}
2023-01-04 05:30:58,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:58,311 INFO:     Epoch: 93
2023-01-04 05:30:59,963 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4760971466700236, 'Total loss': 0.4760971466700236} | train loss {'Reaction outcome loss': 0.1784751134107582, 'Total loss': 0.1784751134107582}
2023-01-04 05:30:59,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:30:59,963 INFO:     Epoch: 94
2023-01-04 05:31:01,557 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4768910090128581, 'Total loss': 0.4768910090128581} | train loss {'Reaction outcome loss': 0.17734357863261166, 'Total loss': 0.17734357863261166}
2023-01-04 05:31:01,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:01,557 INFO:     Epoch: 95
2023-01-04 05:31:03,131 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48814688324928285, 'Total loss': 0.48814688324928285} | train loss {'Reaction outcome loss': 0.17768146671919616, 'Total loss': 0.17768146671919616}
2023-01-04 05:31:03,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:03,132 INFO:     Epoch: 96
2023-01-04 05:31:04,757 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4786329557498296, 'Total loss': 0.4786329557498296} | train loss {'Reaction outcome loss': 0.17612164481021866, 'Total loss': 0.17612164481021866}
2023-01-04 05:31:04,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:04,758 INFO:     Epoch: 97
2023-01-04 05:31:06,369 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5009875526030858, 'Total loss': 0.5009875526030858} | train loss {'Reaction outcome loss': 0.17687964524791344, 'Total loss': 0.17687964524791344}
2023-01-04 05:31:06,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:06,369 INFO:     Epoch: 98
2023-01-04 05:31:08,008 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46463922460873924, 'Total loss': 0.46463922460873924} | train loss {'Reaction outcome loss': 0.17483363633417265, 'Total loss': 0.17483363633417265}
2023-01-04 05:31:08,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:08,008 INFO:     Epoch: 99
2023-01-04 05:31:09,633 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48470416764418284, 'Total loss': 0.48470416764418284} | train loss {'Reaction outcome loss': 0.17503467915640195, 'Total loss': 0.17503467915640195}
2023-01-04 05:31:09,633 INFO:     Best model found after epoch 18 of 100.
2023-01-04 05:31:09,633 INFO:   Done with stage: TRAINING
2023-01-04 05:31:09,633 INFO:   Starting stage: EVALUATION
2023-01-04 05:31:09,757 INFO:   Done with stage: EVALUATION
2023-01-04 05:31:09,757 INFO:   Leaving out SEQ value Fold_8
2023-01-04 05:31:09,770 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-04 05:31:09,770 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:31:10,417 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:31:10,417 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:31:10,485 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:31:10,485 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:31:10,485 INFO:     No hyperparam tuning for this model
2023-01-04 05:31:10,486 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:31:10,486 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:31:10,486 INFO:     None feature selector for col prot
2023-01-04 05:31:10,487 INFO:     None feature selector for col prot
2023-01-04 05:31:10,487 INFO:     None feature selector for col prot
2023-01-04 05:31:10,487 INFO:     None feature selector for col chem
2023-01-04 05:31:10,487 INFO:     None feature selector for col chem
2023-01-04 05:31:10,487 INFO:     None feature selector for col chem
2023-01-04 05:31:10,487 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:31:10,487 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:31:10,488 INFO:     Number of params in model 70141
2023-01-04 05:31:10,492 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:31:10,492 INFO:   Starting stage: TRAINING
2023-01-04 05:31:10,534 INFO:     Val loss before train {'Reaction outcome loss': 0.9558007478713989, 'Total loss': 0.9558007478713989}
2023-01-04 05:31:10,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:10,535 INFO:     Epoch: 0
2023-01-04 05:31:12,116 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6445190171400706, 'Total loss': 0.6445190171400706} | train loss {'Reaction outcome loss': 0.8409305803314613, 'Total loss': 0.8409305803314613}
2023-01-04 05:31:12,116 INFO:     Found new best model at epoch 0
2023-01-04 05:31:12,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:12,117 INFO:     Epoch: 1
2023-01-04 05:31:13,727 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.533521193265915, 'Total loss': 0.533521193265915} | train loss {'Reaction outcome loss': 0.6173597649283653, 'Total loss': 0.6173597649283653}
2023-01-04 05:31:13,727 INFO:     Found new best model at epoch 1
2023-01-04 05:31:13,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:13,728 INFO:     Epoch: 2
2023-01-04 05:31:15,297 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48049171765645343, 'Total loss': 0.48049171765645343} | train loss {'Reaction outcome loss': 0.5225186745507003, 'Total loss': 0.5225186745507003}
2023-01-04 05:31:15,297 INFO:     Found new best model at epoch 2
2023-01-04 05:31:15,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:15,298 INFO:     Epoch: 3
2023-01-04 05:31:16,868 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4764752447605133, 'Total loss': 0.4764752447605133} | train loss {'Reaction outcome loss': 0.4756120909413282, 'Total loss': 0.4756120909413282}
2023-01-04 05:31:16,869 INFO:     Found new best model at epoch 3
2023-01-04 05:31:16,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:16,870 INFO:     Epoch: 4
2023-01-04 05:31:18,475 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4418956865866979, 'Total loss': 0.4418956865866979} | train loss {'Reaction outcome loss': 0.449186723162658, 'Total loss': 0.449186723162658}
2023-01-04 05:31:18,475 INFO:     Found new best model at epoch 4
2023-01-04 05:31:18,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:18,476 INFO:     Epoch: 5
2023-01-04 05:31:20,051 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45183250854412715, 'Total loss': 0.45183250854412715} | train loss {'Reaction outcome loss': 0.427051900675262, 'Total loss': 0.427051900675262}
2023-01-04 05:31:20,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:20,051 INFO:     Epoch: 6
2023-01-04 05:31:21,642 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41863928039868675, 'Total loss': 0.41863928039868675} | train loss {'Reaction outcome loss': 0.40948401812980645, 'Total loss': 0.40948401812980645}
2023-01-04 05:31:21,642 INFO:     Found new best model at epoch 6
2023-01-04 05:31:21,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:21,643 INFO:     Epoch: 7
2023-01-04 05:31:23,251 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43125814696153003, 'Total loss': 0.43125814696153003} | train loss {'Reaction outcome loss': 0.3963005691766739, 'Total loss': 0.3963005691766739}
2023-01-04 05:31:23,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:23,252 INFO:     Epoch: 8
2023-01-04 05:31:24,863 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4043550421794256, 'Total loss': 0.4043550421794256} | train loss {'Reaction outcome loss': 0.387657003953074, 'Total loss': 0.387657003953074}
2023-01-04 05:31:24,863 INFO:     Found new best model at epoch 8
2023-01-04 05:31:24,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:24,864 INFO:     Epoch: 9
2023-01-04 05:31:26,457 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4094647487004598, 'Total loss': 0.4094647487004598} | train loss {'Reaction outcome loss': 0.37626683592361254, 'Total loss': 0.37626683592361254}
2023-01-04 05:31:26,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:26,457 INFO:     Epoch: 10
2023-01-04 05:31:28,086 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41921950777371725, 'Total loss': 0.41921950777371725} | train loss {'Reaction outcome loss': 0.3663978916015068, 'Total loss': 0.3663978916015068}
2023-01-04 05:31:28,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:28,087 INFO:     Epoch: 11
2023-01-04 05:31:29,640 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4266509125630061, 'Total loss': 0.4266509125630061} | train loss {'Reaction outcome loss': 0.3601926072724979, 'Total loss': 0.3601926072724979}
2023-01-04 05:31:29,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:29,640 INFO:     Epoch: 12
2023-01-04 05:31:31,259 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40193788607915243, 'Total loss': 0.40193788607915243} | train loss {'Reaction outcome loss': 0.3500133023264199, 'Total loss': 0.3500133023264199}
2023-01-04 05:31:31,259 INFO:     Found new best model at epoch 12
2023-01-04 05:31:31,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:31,260 INFO:     Epoch: 13
2023-01-04 05:31:32,884 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39924002488454186, 'Total loss': 0.39924002488454186} | train loss {'Reaction outcome loss': 0.34335198707497905, 'Total loss': 0.34335198707497905}
2023-01-04 05:31:32,885 INFO:     Found new best model at epoch 13
2023-01-04 05:31:32,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:32,885 INFO:     Epoch: 14
2023-01-04 05:31:34,453 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3995330890019735, 'Total loss': 0.3995330890019735} | train loss {'Reaction outcome loss': 0.33603236628492383, 'Total loss': 0.33603236628492383}
2023-01-04 05:31:34,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:34,454 INFO:     Epoch: 15
2023-01-04 05:31:36,047 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3950145939985911, 'Total loss': 0.3950145939985911} | train loss {'Reaction outcome loss': 0.32886096769875856, 'Total loss': 0.32886096769875856}
2023-01-04 05:31:36,048 INFO:     Found new best model at epoch 15
2023-01-04 05:31:36,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:36,049 INFO:     Epoch: 16
2023-01-04 05:31:37,643 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4013776332139969, 'Total loss': 0.4013776332139969} | train loss {'Reaction outcome loss': 0.3227470146668871, 'Total loss': 0.3227470146668871}
2023-01-04 05:31:37,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:37,644 INFO:     Epoch: 17
2023-01-04 05:31:39,252 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3903462370236715, 'Total loss': 0.3903462370236715} | train loss {'Reaction outcome loss': 0.3161003117306824, 'Total loss': 0.3161003117306824}
2023-01-04 05:31:39,252 INFO:     Found new best model at epoch 17
2023-01-04 05:31:39,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:39,254 INFO:     Epoch: 18
2023-01-04 05:31:40,889 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3910827706257502, 'Total loss': 0.3910827706257502} | train loss {'Reaction outcome loss': 0.3127198968164242, 'Total loss': 0.3127198968164242}
2023-01-04 05:31:40,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:40,889 INFO:     Epoch: 19
2023-01-04 05:31:42,524 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3914414962132772, 'Total loss': 0.3914414962132772} | train loss {'Reaction outcome loss': 0.3052423889238904, 'Total loss': 0.3052423889238904}
2023-01-04 05:31:42,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:42,524 INFO:     Epoch: 20
2023-01-04 05:31:44,130 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3874999821186066, 'Total loss': 0.3874999821186066} | train loss {'Reaction outcome loss': 0.3006739640050996, 'Total loss': 0.3006739640050996}
2023-01-04 05:31:44,130 INFO:     Found new best model at epoch 20
2023-01-04 05:31:44,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:44,131 INFO:     Epoch: 21
2023-01-04 05:31:45,704 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38843807876110076, 'Total loss': 0.38843807876110076} | train loss {'Reaction outcome loss': 0.2936626023810058, 'Total loss': 0.2936626023810058}
2023-01-04 05:31:45,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:45,704 INFO:     Epoch: 22
2023-01-04 05:31:47,296 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3912921239932378, 'Total loss': 0.3912921239932378} | train loss {'Reaction outcome loss': 0.290568527242128, 'Total loss': 0.290568527242128}
2023-01-04 05:31:47,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:47,296 INFO:     Epoch: 23
2023-01-04 05:31:48,864 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4007411688566208, 'Total loss': 0.4007411688566208} | train loss {'Reaction outcome loss': 0.28811126789689934, 'Total loss': 0.28811126789689934}
2023-01-04 05:31:48,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:48,864 INFO:     Epoch: 24
2023-01-04 05:31:50,446 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4070704271396001, 'Total loss': 0.4070704271396001} | train loss {'Reaction outcome loss': 0.28135175427870596, 'Total loss': 0.28135175427870596}
2023-01-04 05:31:50,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:50,447 INFO:     Epoch: 25
2023-01-04 05:31:52,029 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3935582309961319, 'Total loss': 0.3935582309961319} | train loss {'Reaction outcome loss': 0.27978570948280124, 'Total loss': 0.27978570948280124}
2023-01-04 05:31:52,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:52,030 INFO:     Epoch: 26
2023-01-04 05:31:53,616 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41791342695554096, 'Total loss': 0.41791342695554096} | train loss {'Reaction outcome loss': 0.27301519116672285, 'Total loss': 0.27301519116672285}
2023-01-04 05:31:53,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:53,616 INFO:     Epoch: 27
2023-01-04 05:31:55,202 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38946236769358317, 'Total loss': 0.38946236769358317} | train loss {'Reaction outcome loss': 0.27077461406588554, 'Total loss': 0.27077461406588554}
2023-01-04 05:31:55,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:55,202 INFO:     Epoch: 28
2023-01-04 05:31:56,758 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3935602178176244, 'Total loss': 0.3935602178176244} | train loss {'Reaction outcome loss': 0.26802396864025263, 'Total loss': 0.26802396864025263}
2023-01-04 05:31:56,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:56,758 INFO:     Epoch: 29
2023-01-04 05:31:58,386 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41341454684734347, 'Total loss': 0.41341454684734347} | train loss {'Reaction outcome loss': 0.26044853132245316, 'Total loss': 0.26044853132245316}
2023-01-04 05:31:58,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:58,387 INFO:     Epoch: 30
2023-01-04 05:31:59,955 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3933235247929891, 'Total loss': 0.3933235247929891} | train loss {'Reaction outcome loss': 0.2581296912428454, 'Total loss': 0.2581296912428454}
2023-01-04 05:31:59,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:31:59,956 INFO:     Epoch: 31
2023-01-04 05:32:01,567 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4138856093088786, 'Total loss': 0.4138856093088786} | train loss {'Reaction outcome loss': 0.2533685556225424, 'Total loss': 0.2533685556225424}
2023-01-04 05:32:01,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:01,568 INFO:     Epoch: 32
2023-01-04 05:32:03,179 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38674671252568565, 'Total loss': 0.38674671252568565} | train loss {'Reaction outcome loss': 0.252754427642174, 'Total loss': 0.252754427642174}
2023-01-04 05:32:03,179 INFO:     Found new best model at epoch 32
2023-01-04 05:32:03,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:03,180 INFO:     Epoch: 33
2023-01-04 05:32:04,743 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40192426145076754, 'Total loss': 0.40192426145076754} | train loss {'Reaction outcome loss': 0.2450004312189391, 'Total loss': 0.2450004312189391}
2023-01-04 05:32:04,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:04,743 INFO:     Epoch: 34
2023-01-04 05:32:06,339 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40430257717768353, 'Total loss': 0.40430257717768353} | train loss {'Reaction outcome loss': 0.24410594594630883, 'Total loss': 0.24410594594630883}
2023-01-04 05:32:06,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:06,340 INFO:     Epoch: 35
2023-01-04 05:32:07,950 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4138598650693893, 'Total loss': 0.4138598650693893} | train loss {'Reaction outcome loss': 0.24115731144310348, 'Total loss': 0.24115731144310348}
2023-01-04 05:32:07,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:07,951 INFO:     Epoch: 36
2023-01-04 05:32:09,563 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40992063879966734, 'Total loss': 0.40992063879966734} | train loss {'Reaction outcome loss': 0.23720715869299686, 'Total loss': 0.23720715869299686}
2023-01-04 05:32:09,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:09,563 INFO:     Epoch: 37
2023-01-04 05:32:11,160 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3981908053159714, 'Total loss': 0.3981908053159714} | train loss {'Reaction outcome loss': 0.23549831228969742, 'Total loss': 0.23549831228969742}
2023-01-04 05:32:11,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:11,161 INFO:     Epoch: 38
2023-01-04 05:32:12,753 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4001662095387777, 'Total loss': 0.4001662095387777} | train loss {'Reaction outcome loss': 0.23589208641898457, 'Total loss': 0.23589208641898457}
2023-01-04 05:32:12,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:12,753 INFO:     Epoch: 39
2023-01-04 05:32:14,342 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40580371419588723, 'Total loss': 0.40580371419588723} | train loss {'Reaction outcome loss': 0.23129966107271885, 'Total loss': 0.23129966107271885}
2023-01-04 05:32:14,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:14,342 INFO:     Epoch: 40
2023-01-04 05:32:15,911 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4066822697718938, 'Total loss': 0.4066822697718938} | train loss {'Reaction outcome loss': 0.22580272902183943, 'Total loss': 0.22580272902183943}
2023-01-04 05:32:15,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:15,911 INFO:     Epoch: 41
2023-01-04 05:32:17,499 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41162999868392947, 'Total loss': 0.41162999868392947} | train loss {'Reaction outcome loss': 0.2242958114285321, 'Total loss': 0.2242958114285321}
2023-01-04 05:32:17,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:17,499 INFO:     Epoch: 42
2023-01-04 05:32:19,075 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44278175632158917, 'Total loss': 0.44278175632158917} | train loss {'Reaction outcome loss': 0.22289923653278473, 'Total loss': 0.22289923653278473}
2023-01-04 05:32:19,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:19,075 INFO:     Epoch: 43
2023-01-04 05:32:20,684 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39868905941645305, 'Total loss': 0.39868905941645305} | train loss {'Reaction outcome loss': 0.22001209895867502, 'Total loss': 0.22001209895867502}
2023-01-04 05:32:20,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:20,684 INFO:     Epoch: 44
2023-01-04 05:32:22,317 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40779968599478406, 'Total loss': 0.40779968599478406} | train loss {'Reaction outcome loss': 0.21819519034049806, 'Total loss': 0.21819519034049806}
2023-01-04 05:32:22,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:22,318 INFO:     Epoch: 45
2023-01-04 05:32:23,862 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4168360561132431, 'Total loss': 0.4168360561132431} | train loss {'Reaction outcome loss': 0.21699141088302118, 'Total loss': 0.21699141088302118}
2023-01-04 05:32:23,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:23,862 INFO:     Epoch: 46
2023-01-04 05:32:25,450 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4027808551987012, 'Total loss': 0.4027808551987012} | train loss {'Reaction outcome loss': 0.21573235732197327, 'Total loss': 0.21573235732197327}
2023-01-04 05:32:25,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:25,450 INFO:     Epoch: 47
2023-01-04 05:32:27,038 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4246498892704646, 'Total loss': 0.4246498892704646} | train loss {'Reaction outcome loss': 0.2129686188741322, 'Total loss': 0.2129686188741322}
2023-01-04 05:32:27,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:27,038 INFO:     Epoch: 48
2023-01-04 05:32:28,624 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41606954832871756, 'Total loss': 0.41606954832871756} | train loss {'Reaction outcome loss': 0.20945235982156582, 'Total loss': 0.20945235982156582}
2023-01-04 05:32:28,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:28,625 INFO:     Epoch: 49
2023-01-04 05:32:30,213 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4029876902699471, 'Total loss': 0.4029876902699471} | train loss {'Reaction outcome loss': 0.2091437555360098, 'Total loss': 0.2091437555360098}
2023-01-04 05:32:30,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:30,213 INFO:     Epoch: 50
2023-01-04 05:32:31,779 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3994275316596031, 'Total loss': 0.3994275316596031} | train loss {'Reaction outcome loss': 0.20587149651272454, 'Total loss': 0.20587149651272454}
2023-01-04 05:32:31,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:31,779 INFO:     Epoch: 51
2023-01-04 05:32:33,357 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4106158713499705, 'Total loss': 0.4106158713499705} | train loss {'Reaction outcome loss': 0.2031088035254583, 'Total loss': 0.2031088035254583}
2023-01-04 05:32:33,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:33,357 INFO:     Epoch: 52
2023-01-04 05:32:34,984 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41230473717053734, 'Total loss': 0.41230473717053734} | train loss {'Reaction outcome loss': 0.2045377464693067, 'Total loss': 0.2045377464693067}
2023-01-04 05:32:34,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:34,985 INFO:     Epoch: 53
2023-01-04 05:32:36,612 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4203842540582021, 'Total loss': 0.4203842540582021} | train loss {'Reaction outcome loss': 0.19996559739547926, 'Total loss': 0.19996559739547926}
2023-01-04 05:32:36,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:36,612 INFO:     Epoch: 54
2023-01-04 05:32:38,225 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43621482054392496, 'Total loss': 0.43621482054392496} | train loss {'Reaction outcome loss': 0.2014138236315581, 'Total loss': 0.2014138236315581}
2023-01-04 05:32:38,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:38,225 INFO:     Epoch: 55
2023-01-04 05:32:39,798 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4079041540622711, 'Total loss': 0.4079041540622711} | train loss {'Reaction outcome loss': 0.19849380391248822, 'Total loss': 0.19849380391248822}
2023-01-04 05:32:39,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:39,798 INFO:     Epoch: 56
2023-01-04 05:32:41,374 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41152353485425314, 'Total loss': 0.41152353485425314} | train loss {'Reaction outcome loss': 0.19635867486524322, 'Total loss': 0.19635867486524322}
2023-01-04 05:32:41,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:41,375 INFO:     Epoch: 57
2023-01-04 05:32:42,951 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4133498748143514, 'Total loss': 0.4133498748143514} | train loss {'Reaction outcome loss': 0.19559663557277543, 'Total loss': 0.19559663557277543}
2023-01-04 05:32:42,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:42,951 INFO:     Epoch: 58
2023-01-04 05:32:44,524 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4248512516419093, 'Total loss': 0.4248512516419093} | train loss {'Reaction outcome loss': 0.19674108605695903, 'Total loss': 0.19674108605695903}
2023-01-04 05:32:44,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:44,524 INFO:     Epoch: 59
2023-01-04 05:32:46,137 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4217943171660105, 'Total loss': 0.4217943171660105} | train loss {'Reaction outcome loss': 0.19220911563258536, 'Total loss': 0.19220911563258536}
2023-01-04 05:32:46,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:46,137 INFO:     Epoch: 60
2023-01-04 05:32:47,752 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4051957383751869, 'Total loss': 0.4051957383751869} | train loss {'Reaction outcome loss': 0.19219940139429412, 'Total loss': 0.19219940139429412}
2023-01-04 05:32:47,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:47,753 INFO:     Epoch: 61
2023-01-04 05:32:49,327 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4279323607683182, 'Total loss': 0.4279323607683182} | train loss {'Reaction outcome loss': 0.19171269755321044, 'Total loss': 0.19171269755321044}
2023-01-04 05:32:49,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:49,327 INFO:     Epoch: 62
2023-01-04 05:32:50,891 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4211862862110138, 'Total loss': 0.4211862862110138} | train loss {'Reaction outcome loss': 0.19111119025815143, 'Total loss': 0.19111119025815143}
2023-01-04 05:32:50,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:50,892 INFO:     Epoch: 63
2023-01-04 05:32:52,504 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4381782799959183, 'Total loss': 0.4381782799959183} | train loss {'Reaction outcome loss': 0.18896032157388046, 'Total loss': 0.18896032157388046}
2023-01-04 05:32:52,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:52,504 INFO:     Epoch: 64
2023-01-04 05:32:54,068 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4077292442321777, 'Total loss': 0.4077292442321777} | train loss {'Reaction outcome loss': 0.18594741588798316, 'Total loss': 0.18594741588798316}
2023-01-04 05:32:54,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:54,068 INFO:     Epoch: 65
2023-01-04 05:32:55,681 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39560478627681733, 'Total loss': 0.39560478627681733} | train loss {'Reaction outcome loss': 0.1864364779397954, 'Total loss': 0.1864364779397954}
2023-01-04 05:32:55,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:55,681 INFO:     Epoch: 66
2023-01-04 05:32:57,245 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4304882844289144, 'Total loss': 0.4304882844289144} | train loss {'Reaction outcome loss': 0.18672026409665599, 'Total loss': 0.18672026409665599}
2023-01-04 05:32:57,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:57,245 INFO:     Epoch: 67
2023-01-04 05:32:58,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42624599238236743, 'Total loss': 0.42624599238236743} | train loss {'Reaction outcome loss': 0.18425225108916307, 'Total loss': 0.18425225108916307}
2023-01-04 05:32:58,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:32:58,840 INFO:     Epoch: 68
2023-01-04 05:33:00,397 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4226682682832082, 'Total loss': 0.4226682682832082} | train loss {'Reaction outcome loss': 0.1826101587745395, 'Total loss': 0.1826101587745395}
2023-01-04 05:33:00,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:00,397 INFO:     Epoch: 69
2023-01-04 05:33:02,011 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41041496594746907, 'Total loss': 0.41041496594746907} | train loss {'Reaction outcome loss': 0.18322375214855818, 'Total loss': 0.18322375214855818}
2023-01-04 05:33:02,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:02,012 INFO:     Epoch: 70
2023-01-04 05:33:03,626 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40124614437421163, 'Total loss': 0.40124614437421163} | train loss {'Reaction outcome loss': 0.1837904274082967, 'Total loss': 0.1837904274082967}
2023-01-04 05:33:03,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:03,626 INFO:     Epoch: 71
2023-01-04 05:33:05,238 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42801592151323953, 'Total loss': 0.42801592151323953} | train loss {'Reaction outcome loss': 0.18020110302706704, 'Total loss': 0.18020110302706704}
2023-01-04 05:33:05,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:05,239 INFO:     Epoch: 72
2023-01-04 05:33:06,855 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45349470476309456, 'Total loss': 0.45349470476309456} | train loss {'Reaction outcome loss': 0.18031218552105402, 'Total loss': 0.18031218552105402}
2023-01-04 05:33:06,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:06,855 INFO:     Epoch: 73
2023-01-04 05:33:08,418 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44862980842590333, 'Total loss': 0.44862980842590333} | train loss {'Reaction outcome loss': 0.17866829055341055, 'Total loss': 0.17866829055341055}
2023-01-04 05:33:08,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:08,419 INFO:     Epoch: 74
2023-01-04 05:33:10,002 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39745458761850994, 'Total loss': 0.39745458761850994} | train loss {'Reaction outcome loss': 0.17908423614898955, 'Total loss': 0.17908423614898955}
2023-01-04 05:33:10,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:10,002 INFO:     Epoch: 75
2023-01-04 05:33:11,591 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4540307233730952, 'Total loss': 0.4540307233730952} | train loss {'Reaction outcome loss': 0.17497600959172052, 'Total loss': 0.17497600959172052}
2023-01-04 05:33:11,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:11,591 INFO:     Epoch: 76
2023-01-04 05:33:13,178 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4151417036851247, 'Total loss': 0.4151417036851247} | train loss {'Reaction outcome loss': 0.17667976538072863, 'Total loss': 0.17667976538072863}
2023-01-04 05:33:13,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:13,178 INFO:     Epoch: 77
2023-01-04 05:33:14,768 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4127675066391627, 'Total loss': 0.4127675066391627} | train loss {'Reaction outcome loss': 0.17946268783297634, 'Total loss': 0.17946268783297634}
2023-01-04 05:33:14,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:14,768 INFO:     Epoch: 78
2023-01-04 05:33:16,348 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.42760355869928995, 'Total loss': 0.42760355869928995} | train loss {'Reaction outcome loss': 0.17575636613488632, 'Total loss': 0.17575636613488632}
2023-01-04 05:33:16,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:16,348 INFO:     Epoch: 79
2023-01-04 05:33:17,919 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4298241138458252, 'Total loss': 0.4298241138458252} | train loss {'Reaction outcome loss': 0.17474700227706103, 'Total loss': 0.17474700227706103}
2023-01-04 05:33:17,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:17,920 INFO:     Epoch: 80
2023-01-04 05:33:19,490 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4201371014118195, 'Total loss': 0.4201371014118195} | train loss {'Reaction outcome loss': 0.17469632276843716, 'Total loss': 0.17469632276843716}
2023-01-04 05:33:19,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:19,490 INFO:     Epoch: 81
2023-01-04 05:33:21,106 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4368119160334269, 'Total loss': 0.4368119160334269} | train loss {'Reaction outcome loss': 0.17244354507675136, 'Total loss': 0.17244354507675136}
2023-01-04 05:33:21,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:21,106 INFO:     Epoch: 82
2023-01-04 05:33:22,701 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.401603627204895, 'Total loss': 0.401603627204895} | train loss {'Reaction outcome loss': 0.170211801917231, 'Total loss': 0.170211801917231}
2023-01-04 05:33:22,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:22,701 INFO:     Epoch: 83
2023-01-04 05:33:24,290 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41427191694577536, 'Total loss': 0.41427191694577536} | train loss {'Reaction outcome loss': 0.17161077995152368, 'Total loss': 0.17161077995152368}
2023-01-04 05:33:24,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:24,291 INFO:     Epoch: 84
2023-01-04 05:33:25,856 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41546133160591125, 'Total loss': 0.41546133160591125} | train loss {'Reaction outcome loss': 0.17303785230339008, 'Total loss': 0.17303785230339008}
2023-01-04 05:33:25,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:25,856 INFO:     Epoch: 85
2023-01-04 05:33:27,432 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4112836947043737, 'Total loss': 0.4112836947043737} | train loss {'Reaction outcome loss': 0.16970753471237898, 'Total loss': 0.16970753471237898}
2023-01-04 05:33:27,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:27,432 INFO:     Epoch: 86
2023-01-04 05:33:29,020 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41422121226787567, 'Total loss': 0.41422121226787567} | train loss {'Reaction outcome loss': 0.171318267016624, 'Total loss': 0.171318267016624}
2023-01-04 05:33:29,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:29,020 INFO:     Epoch: 87
2023-01-04 05:33:30,610 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4156680603822072, 'Total loss': 0.4156680603822072} | train loss {'Reaction outcome loss': 0.16698195068777477, 'Total loss': 0.16698195068777477}
2023-01-04 05:33:30,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:30,610 INFO:     Epoch: 88
2023-01-04 05:33:32,199 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4064744055271149, 'Total loss': 0.4064744055271149} | train loss {'Reaction outcome loss': 0.1682209123170724, 'Total loss': 0.1682209123170724}
2023-01-04 05:33:32,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:32,199 INFO:     Epoch: 89
2023-01-04 05:33:33,789 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4395984311898549, 'Total loss': 0.4395984311898549} | train loss {'Reaction outcome loss': 0.16813019155286743, 'Total loss': 0.16813019155286743}
2023-01-04 05:33:33,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:33,790 INFO:     Epoch: 90
2023-01-04 05:33:35,343 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4326829145352046, 'Total loss': 0.4326829145352046} | train loss {'Reaction outcome loss': 0.16565384574397637, 'Total loss': 0.16565384574397637}
2023-01-04 05:33:35,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:35,343 INFO:     Epoch: 91
2023-01-04 05:33:36,934 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41125190059343975, 'Total loss': 0.41125190059343975} | train loss {'Reaction outcome loss': 0.16441945839047867, 'Total loss': 0.16441945839047867}
2023-01-04 05:33:36,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:36,934 INFO:     Epoch: 92
2023-01-04 05:33:38,526 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.456011164188385, 'Total loss': 0.456011164188385} | train loss {'Reaction outcome loss': 0.16602223155081924, 'Total loss': 0.16602223155081924}
2023-01-04 05:33:38,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:38,526 INFO:     Epoch: 93
2023-01-04 05:33:40,117 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4171697566906611, 'Total loss': 0.4171697566906611} | train loss {'Reaction outcome loss': 0.1637494337207971, 'Total loss': 0.1637494337207971}
2023-01-04 05:33:40,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:40,118 INFO:     Epoch: 94
2023-01-04 05:33:41,708 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4433044781287511, 'Total loss': 0.4433044781287511} | train loss {'Reaction outcome loss': 0.16598576231159434, 'Total loss': 0.16598576231159434}
2023-01-04 05:33:41,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:41,708 INFO:     Epoch: 95
2023-01-04 05:33:43,287 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44038344820340475, 'Total loss': 0.44038344820340475} | train loss {'Reaction outcome loss': 0.16453850892691935, 'Total loss': 0.16453850892691935}
2023-01-04 05:33:43,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:43,287 INFO:     Epoch: 96
2023-01-04 05:33:44,870 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42423760493596396, 'Total loss': 0.42423760493596396} | train loss {'Reaction outcome loss': 0.16294408801698337, 'Total loss': 0.16294408801698337}
2023-01-04 05:33:44,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:44,871 INFO:     Epoch: 97
2023-01-04 05:33:46,450 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41986582179864246, 'Total loss': 0.41986582179864246} | train loss {'Reaction outcome loss': 0.16212240629659516, 'Total loss': 0.16212240629659516}
2023-01-04 05:33:46,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:46,451 INFO:     Epoch: 98
2023-01-04 05:33:48,065 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4184364000956217, 'Total loss': 0.4184364000956217} | train loss {'Reaction outcome loss': 0.15978516011165766, 'Total loss': 0.15978516011165766}
2023-01-04 05:33:48,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:48,066 INFO:     Epoch: 99
2023-01-04 05:33:49,680 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42951979239781696, 'Total loss': 0.42951979239781696} | train loss {'Reaction outcome loss': 0.16385834825218376, 'Total loss': 0.16385834825218376}
2023-01-04 05:33:49,680 INFO:     Best model found after epoch 33 of 100.
2023-01-04 05:33:49,680 INFO:   Done with stage: TRAINING
2023-01-04 05:33:49,681 INFO:   Starting stage: EVALUATION
2023-01-04 05:33:49,817 INFO:   Done with stage: EVALUATION
2023-01-04 05:33:49,817 INFO:   Leaving out SEQ value Fold_9
2023-01-04 05:33:49,830 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-04 05:33:49,830 INFO:   Starting stage: FEATURE SCALING
2023-01-04 05:33:50,473 INFO:   Done with stage: FEATURE SCALING
2023-01-04 05:33:50,473 INFO:   Starting stage: SCALING TARGETS
2023-01-04 05:33:50,540 INFO:   Done with stage: SCALING TARGETS
2023-01-04 05:33:50,540 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:33:50,540 INFO:     No hyperparam tuning for this model
2023-01-04 05:33:50,540 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-04 05:33:50,541 INFO:   Starting stage: FEATURE SELECTION
2023-01-04 05:33:50,541 INFO:     None feature selector for col prot
2023-01-04 05:33:50,541 INFO:     None feature selector for col prot
2023-01-04 05:33:50,541 INFO:     None feature selector for col prot
2023-01-04 05:33:50,542 INFO:     None feature selector for col chem
2023-01-04 05:33:50,542 INFO:     None feature selector for col chem
2023-01-04 05:33:50,542 INFO:     None feature selector for col chem
2023-01-04 05:33:50,542 INFO:   Done with stage: FEATURE SELECTION
2023-01-04 05:33:50,542 INFO:   Starting stage: BUILD MODEL
2023-01-04 05:33:50,543 INFO:     Number of params in model 70141
2023-01-04 05:33:50,546 INFO:   Done with stage: BUILD MODEL
2023-01-04 05:33:50,547 INFO:   Starting stage: TRAINING
2023-01-04 05:33:50,590 INFO:     Val loss before train {'Reaction outcome loss': 0.8679144541422527, 'Total loss': 0.8679144541422527}
2023-01-04 05:33:50,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:50,590 INFO:     Epoch: 0
2023-01-04 05:33:52,192 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6023937304814656, 'Total loss': 0.6023937304814656} | train loss {'Reaction outcome loss': 0.8392357924139456, 'Total loss': 0.8392357924139456}
2023-01-04 05:33:52,193 INFO:     Found new best model at epoch 0
2023-01-04 05:33:52,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:52,194 INFO:     Epoch: 1
2023-01-04 05:33:53,775 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5449604094028473, 'Total loss': 0.5449604094028473} | train loss {'Reaction outcome loss': 0.6058084796912403, 'Total loss': 0.6058084796912403}
2023-01-04 05:33:53,775 INFO:     Found new best model at epoch 1
2023-01-04 05:33:53,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:53,776 INFO:     Epoch: 2
2023-01-04 05:33:55,378 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.510853053132693, 'Total loss': 0.510853053132693} | train loss {'Reaction outcome loss': 0.5349187144626348, 'Total loss': 0.5349187144626348}
2023-01-04 05:33:55,378 INFO:     Found new best model at epoch 2
2023-01-04 05:33:55,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:55,379 INFO:     Epoch: 3
2023-01-04 05:33:56,969 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47919814189275106, 'Total loss': 0.47919814189275106} | train loss {'Reaction outcome loss': 0.49363791996391243, 'Total loss': 0.49363791996391243}
2023-01-04 05:33:56,969 INFO:     Found new best model at epoch 3
2023-01-04 05:33:56,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:56,970 INFO:     Epoch: 4
2023-01-04 05:33:58,594 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4558286428451538, 'Total loss': 0.4558286428451538} | train loss {'Reaction outcome loss': 0.465479275003237, 'Total loss': 0.465479275003237}
2023-01-04 05:33:58,594 INFO:     Found new best model at epoch 4
2023-01-04 05:33:58,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:33:58,595 INFO:     Epoch: 5
2023-01-04 05:34:00,178 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.42550505995750426, 'Total loss': 0.42550505995750426} | train loss {'Reaction outcome loss': 0.4456490937768337, 'Total loss': 0.4456490937768337}
2023-01-04 05:34:00,178 INFO:     Found new best model at epoch 5
2023-01-04 05:34:00,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:00,179 INFO:     Epoch: 6
2023-01-04 05:34:01,743 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4261847337086995, 'Total loss': 0.4261847337086995} | train loss {'Reaction outcome loss': 0.4288812241506921, 'Total loss': 0.4288812241506921}
2023-01-04 05:34:01,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:01,743 INFO:     Epoch: 7
2023-01-04 05:34:03,375 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4166362444559733, 'Total loss': 0.4166362444559733} | train loss {'Reaction outcome loss': 0.41417477083550464, 'Total loss': 0.41417477083550464}
2023-01-04 05:34:03,376 INFO:     Found new best model at epoch 7
2023-01-04 05:34:03,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:03,376 INFO:     Epoch: 8
2023-01-04 05:34:04,958 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4131545782089233, 'Total loss': 0.4131545782089233} | train loss {'Reaction outcome loss': 0.40488352392554716, 'Total loss': 0.40488352392554716}
2023-01-04 05:34:04,958 INFO:     Found new best model at epoch 8
2023-01-04 05:34:04,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:04,959 INFO:     Epoch: 9
2023-01-04 05:34:06,593 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4090997199217478, 'Total loss': 0.4090997199217478} | train loss {'Reaction outcome loss': 0.39335536246695674, 'Total loss': 0.39335536246695674}
2023-01-04 05:34:06,593 INFO:     Found new best model at epoch 9
2023-01-04 05:34:06,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:06,594 INFO:     Epoch: 10
2023-01-04 05:34:08,175 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39908601144949596, 'Total loss': 0.39908601144949596} | train loss {'Reaction outcome loss': 0.38684053589936196, 'Total loss': 0.38684053589936196}
2023-01-04 05:34:08,175 INFO:     Found new best model at epoch 10
2023-01-04 05:34:08,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:08,176 INFO:     Epoch: 11
2023-01-04 05:34:09,747 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38382457494735717, 'Total loss': 0.38382457494735717} | train loss {'Reaction outcome loss': 0.37590642450948913, 'Total loss': 0.37590642450948913}
2023-01-04 05:34:09,748 INFO:     Found new best model at epoch 11
2023-01-04 05:34:09,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:09,749 INFO:     Epoch: 12
2023-01-04 05:34:11,328 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3814852217833201, 'Total loss': 0.3814852217833201} | train loss {'Reaction outcome loss': 0.3686206962119801, 'Total loss': 0.3686206962119801}
2023-01-04 05:34:11,328 INFO:     Found new best model at epoch 12
2023-01-04 05:34:11,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:11,329 INFO:     Epoch: 13
2023-01-04 05:34:12,931 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.402405912677447, 'Total loss': 0.402405912677447} | train loss {'Reaction outcome loss': 0.3605482920278065, 'Total loss': 0.3605482920278065}
2023-01-04 05:34:12,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:12,931 INFO:     Epoch: 14
2023-01-04 05:34:14,534 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3843763788541158, 'Total loss': 0.3843763788541158} | train loss {'Reaction outcome loss': 0.3534337140162499, 'Total loss': 0.3534337140162499}
2023-01-04 05:34:14,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:14,534 INFO:     Epoch: 15
2023-01-04 05:34:16,138 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3806607186794281, 'Total loss': 0.3806607186794281} | train loss {'Reaction outcome loss': 0.34629064550898997, 'Total loss': 0.34629064550898997}
2023-01-04 05:34:16,139 INFO:     Found new best model at epoch 15
2023-01-04 05:34:16,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:16,139 INFO:     Epoch: 16
2023-01-04 05:34:17,742 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3770812361190716, 'Total loss': 0.3770812361190716} | train loss {'Reaction outcome loss': 0.3421100116324769, 'Total loss': 0.3421100116324769}
2023-01-04 05:34:17,742 INFO:     Found new best model at epoch 16
2023-01-04 05:34:17,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:17,743 INFO:     Epoch: 17
2023-01-04 05:34:19,318 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3912420113881429, 'Total loss': 0.3912420113881429} | train loss {'Reaction outcome loss': 0.3357099639756155, 'Total loss': 0.3357099639756155}
2023-01-04 05:34:19,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:19,318 INFO:     Epoch: 18
2023-01-04 05:34:20,926 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39929233491420746, 'Total loss': 0.39929233491420746} | train loss {'Reaction outcome loss': 0.3295732694627576, 'Total loss': 0.3295732694627576}
2023-01-04 05:34:20,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:20,926 INFO:     Epoch: 19
2023-01-04 05:34:22,530 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.385506941874822, 'Total loss': 0.385506941874822} | train loss {'Reaction outcome loss': 0.3233456778128225, 'Total loss': 0.3233456778128225}
2023-01-04 05:34:22,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:22,530 INFO:     Epoch: 20
2023-01-04 05:34:24,133 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39468267957369485, 'Total loss': 0.39468267957369485} | train loss {'Reaction outcome loss': 0.3178267069160938, 'Total loss': 0.3178267069160938}
2023-01-04 05:34:24,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:24,134 INFO:     Epoch: 21
2023-01-04 05:34:25,736 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37632275422414146, 'Total loss': 0.37632275422414146} | train loss {'Reaction outcome loss': 0.31149620211780715, 'Total loss': 0.31149620211780715}
2023-01-04 05:34:25,736 INFO:     Found new best model at epoch 21
2023-01-04 05:34:25,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:25,737 INFO:     Epoch: 22
2023-01-04 05:34:27,336 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38490031361579896, 'Total loss': 0.38490031361579896} | train loss {'Reaction outcome loss': 0.3084268417975963, 'Total loss': 0.3084268417975963}
2023-01-04 05:34:27,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:27,337 INFO:     Epoch: 23
2023-01-04 05:34:28,894 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40021604200204214, 'Total loss': 0.40021604200204214} | train loss {'Reaction outcome loss': 0.3031961522619862, 'Total loss': 0.3031961522619862}
2023-01-04 05:34:28,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:28,895 INFO:     Epoch: 24
2023-01-04 05:34:30,475 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40534306565920514, 'Total loss': 0.40534306565920514} | train loss {'Reaction outcome loss': 0.2985105679945395, 'Total loss': 0.2985105679945395}
2023-01-04 05:34:30,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:30,475 INFO:     Epoch: 25
2023-01-04 05:34:32,093 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4163270543018977, 'Total loss': 0.4163270543018977} | train loss {'Reaction outcome loss': 0.29309805614423234, 'Total loss': 0.29309805614423234}
2023-01-04 05:34:32,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:32,093 INFO:     Epoch: 26
2023-01-04 05:34:33,724 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38838814695676166, 'Total loss': 0.38838814695676166} | train loss {'Reaction outcome loss': 0.289472435167335, 'Total loss': 0.289472435167335}
2023-01-04 05:34:33,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:33,724 INFO:     Epoch: 27
2023-01-04 05:34:35,306 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38708025415738423, 'Total loss': 0.38708025415738423} | train loss {'Reaction outcome loss': 0.28592880995480163, 'Total loss': 0.28592880995480163}
2023-01-04 05:34:35,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:35,307 INFO:     Epoch: 28
2023-01-04 05:34:36,778 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3684591069817543, 'Total loss': 0.3684591069817543} | train loss {'Reaction outcome loss': 0.27934380943486836, 'Total loss': 0.27934380943486836}
2023-01-04 05:34:36,778 INFO:     Found new best model at epoch 28
2023-01-04 05:34:36,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:36,779 INFO:     Epoch: 29
2023-01-04 05:34:37,856 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38922826449076336, 'Total loss': 0.38922826449076336} | train loss {'Reaction outcome loss': 0.27881486734059313, 'Total loss': 0.27881486734059313}
2023-01-04 05:34:37,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:37,856 INFO:     Epoch: 30
2023-01-04 05:34:38,916 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4002461552619934, 'Total loss': 0.4002461552619934} | train loss {'Reaction outcome loss': 0.2732245996594429, 'Total loss': 0.2732245996594429}
2023-01-04 05:34:38,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:38,917 INFO:     Epoch: 31
2023-01-04 05:34:39,976 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38273376822471616, 'Total loss': 0.38273376822471616} | train loss {'Reaction outcome loss': 0.26833960448899424, 'Total loss': 0.26833960448899424}
2023-01-04 05:34:39,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:39,976 INFO:     Epoch: 32
2023-01-04 05:34:41,106 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3900304873784383, 'Total loss': 0.3900304873784383} | train loss {'Reaction outcome loss': 0.2685409386773402, 'Total loss': 0.2685409386773402}
2023-01-04 05:34:41,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:41,106 INFO:     Epoch: 33
2023-01-04 05:34:42,684 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3801882316668828, 'Total loss': 0.3801882316668828} | train loss {'Reaction outcome loss': 0.26445504186493396, 'Total loss': 0.26445504186493396}
2023-01-04 05:34:42,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:42,684 INFO:     Epoch: 34
2023-01-04 05:34:44,291 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4102403879165649, 'Total loss': 0.4102403879165649} | train loss {'Reaction outcome loss': 0.2626063296914316, 'Total loss': 0.2626063296914316}
2023-01-04 05:34:44,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:44,292 INFO:     Epoch: 35
2023-01-04 05:34:45,893 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40122814774513244, 'Total loss': 0.40122814774513244} | train loss {'Reaction outcome loss': 0.25657500723370147, 'Total loss': 0.25657500723370147}
2023-01-04 05:34:45,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:45,894 INFO:     Epoch: 36
2023-01-04 05:34:47,481 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39314606140057246, 'Total loss': 0.39314606140057246} | train loss {'Reaction outcome loss': 0.25428634994942356, 'Total loss': 0.25428634994942356}
2023-01-04 05:34:47,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:47,481 INFO:     Epoch: 37
2023-01-04 05:34:49,126 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39056492944558463, 'Total loss': 0.39056492944558463} | train loss {'Reaction outcome loss': 0.2542614136765365, 'Total loss': 0.2542614136765365}
2023-01-04 05:34:49,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:49,126 INFO:     Epoch: 38
2023-01-04 05:34:50,744 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3821813901265462, 'Total loss': 0.3821813901265462} | train loss {'Reaction outcome loss': 0.24869158118963242, 'Total loss': 0.24869158118963242}
2023-01-04 05:34:50,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:50,744 INFO:     Epoch: 39
2023-01-04 05:34:52,368 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39726021786530813, 'Total loss': 0.39726021786530813} | train loss {'Reaction outcome loss': 0.24937482159383031, 'Total loss': 0.24937482159383031}
2023-01-04 05:34:52,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:52,369 INFO:     Epoch: 40
2023-01-04 05:34:53,959 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37014573216438296, 'Total loss': 0.37014573216438296} | train loss {'Reaction outcome loss': 0.24536616749227694, 'Total loss': 0.24536616749227694}
2023-01-04 05:34:53,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:53,960 INFO:     Epoch: 41
2023-01-04 05:34:55,563 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39273796081542967, 'Total loss': 0.39273796081542967} | train loss {'Reaction outcome loss': 0.2397771711706685, 'Total loss': 0.2397771711706685}
2023-01-04 05:34:55,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:55,563 INFO:     Epoch: 42
2023-01-04 05:34:57,187 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3855456074078878, 'Total loss': 0.3855456074078878} | train loss {'Reaction outcome loss': 0.24106928567647504, 'Total loss': 0.24106928567647504}
2023-01-04 05:34:57,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:57,188 INFO:     Epoch: 43
2023-01-04 05:34:58,816 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3759528656800588, 'Total loss': 0.3759528656800588} | train loss {'Reaction outcome loss': 0.23779189916805024, 'Total loss': 0.23779189916805024}
2023-01-04 05:34:58,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:34:58,816 INFO:     Epoch: 44
2023-01-04 05:35:00,388 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38814713905255, 'Total loss': 0.38814713905255} | train loss {'Reaction outcome loss': 0.23539921672281805, 'Total loss': 0.23539921672281805}
2023-01-04 05:35:00,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:00,388 INFO:     Epoch: 45
2023-01-04 05:35:02,003 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37390995025634766, 'Total loss': 0.37390995025634766} | train loss {'Reaction outcome loss': 0.23249513392306406, 'Total loss': 0.23249513392306406}
2023-01-04 05:35:02,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:02,003 INFO:     Epoch: 46
2023-01-04 05:35:03,593 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.37688076347112653, 'Total loss': 0.37688076347112653} | train loss {'Reaction outcome loss': 0.23206734303586748, 'Total loss': 0.23206734303586748}
2023-01-04 05:35:03,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:03,593 INFO:     Epoch: 47
2023-01-04 05:35:05,195 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38578519523143767, 'Total loss': 0.38578519523143767} | train loss {'Reaction outcome loss': 0.2292056707429972, 'Total loss': 0.2292056707429972}
2023-01-04 05:35:05,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:05,196 INFO:     Epoch: 48
2023-01-04 05:35:06,804 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39349158306916554, 'Total loss': 0.39349158306916554} | train loss {'Reaction outcome loss': 0.22921846164155094, 'Total loss': 0.22921846164155094}
2023-01-04 05:35:06,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:06,804 INFO:     Epoch: 49
2023-01-04 05:35:08,408 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39426942467689513, 'Total loss': 0.39426942467689513} | train loss {'Reaction outcome loss': 0.2253980275902507, 'Total loss': 0.2253980275902507}
2023-01-04 05:35:08,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:08,409 INFO:     Epoch: 50
2023-01-04 05:35:10,041 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39504021406173706, 'Total loss': 0.39504021406173706} | train loss {'Reaction outcome loss': 0.22233046324997602, 'Total loss': 0.22233046324997602}
2023-01-04 05:35:10,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:10,041 INFO:     Epoch: 51
2023-01-04 05:35:11,628 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39747210244337716, 'Total loss': 0.39747210244337716} | train loss {'Reaction outcome loss': 0.2228340693894061, 'Total loss': 0.2228340693894061}
2023-01-04 05:35:11,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:11,628 INFO:     Epoch: 52
2023-01-04 05:35:13,272 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38788615763187406, 'Total loss': 0.38788615763187406} | train loss {'Reaction outcome loss': 0.2213675044208012, 'Total loss': 0.2213675044208012}
2023-01-04 05:35:13,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:13,272 INFO:     Epoch: 53
2023-01-04 05:35:14,917 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38116689721743263, 'Total loss': 0.38116689721743263} | train loss {'Reaction outcome loss': 0.21778317609472395, 'Total loss': 0.21778317609472395}
2023-01-04 05:35:14,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:14,917 INFO:     Epoch: 54
2023-01-04 05:35:16,498 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4008525609970093, 'Total loss': 0.4008525609970093} | train loss {'Reaction outcome loss': 0.21716203922506705, 'Total loss': 0.21716203922506705}
2023-01-04 05:35:16,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:16,499 INFO:     Epoch: 55
2023-01-04 05:35:18,083 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40273580451806384, 'Total loss': 0.40273580451806384} | train loss {'Reaction outcome loss': 0.21708630440951684, 'Total loss': 0.21708630440951684}
2023-01-04 05:35:18,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:18,083 INFO:     Epoch: 56
2023-01-04 05:35:19,679 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43988813857237496, 'Total loss': 0.43988813857237496} | train loss {'Reaction outcome loss': 0.21460509906768369, 'Total loss': 0.21460509906768369}
2023-01-04 05:35:19,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:19,679 INFO:     Epoch: 57
2023-01-04 05:35:21,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4047231843074163, 'Total loss': 0.4047231843074163} | train loss {'Reaction outcome loss': 0.21559396868954928, 'Total loss': 0.21559396868954928}
2023-01-04 05:35:21,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:21,293 INFO:     Epoch: 58
2023-01-04 05:35:22,934 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4037950446208318, 'Total loss': 0.4037950446208318} | train loss {'Reaction outcome loss': 0.20999907961767503, 'Total loss': 0.20999907961767503}
2023-01-04 05:35:22,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:22,935 INFO:     Epoch: 59
2023-01-04 05:35:24,570 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3768039306004842, 'Total loss': 0.3768039306004842} | train loss {'Reaction outcome loss': 0.20923229616256397, 'Total loss': 0.20923229616256397}
2023-01-04 05:35:24,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:24,571 INFO:     Epoch: 60
2023-01-04 05:35:26,187 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3975353171428045, 'Total loss': 0.3975353171428045} | train loss {'Reaction outcome loss': 0.20759905309883697, 'Total loss': 0.20759905309883697}
2023-01-04 05:35:26,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:26,188 INFO:     Epoch: 61
2023-01-04 05:35:27,811 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40356595317522687, 'Total loss': 0.40356595317522687} | train loss {'Reaction outcome loss': 0.20618640861410095, 'Total loss': 0.20618640861410095}
2023-01-04 05:35:27,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:27,811 INFO:     Epoch: 62
2023-01-04 05:35:29,387 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39299389024575554, 'Total loss': 0.39299389024575554} | train loss {'Reaction outcome loss': 0.20335954999288927, 'Total loss': 0.20335954999288927}
2023-01-04 05:35:29,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:29,387 INFO:     Epoch: 63
2023-01-04 05:35:31,021 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3862768848737081, 'Total loss': 0.3862768848737081} | train loss {'Reaction outcome loss': 0.2066779445708874, 'Total loss': 0.2066779445708874}
2023-01-04 05:35:31,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:31,021 INFO:     Epoch: 64
2023-01-04 05:35:32,607 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3837403123577436, 'Total loss': 0.3837403123577436} | train loss {'Reaction outcome loss': 0.20270830788229346, 'Total loss': 0.20270830788229346}
2023-01-04 05:35:32,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:32,607 INFO:     Epoch: 65
2023-01-04 05:35:34,232 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42852313121159874, 'Total loss': 0.42852313121159874} | train loss {'Reaction outcome loss': 0.20069883032180771, 'Total loss': 0.20069883032180771}
2023-01-04 05:35:34,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:34,232 INFO:     Epoch: 66
2023-01-04 05:35:35,826 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.416972013314565, 'Total loss': 0.416972013314565} | train loss {'Reaction outcome loss': 0.20059608803248363, 'Total loss': 0.20059608803248363}
2023-01-04 05:35:35,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:35,827 INFO:     Epoch: 67
2023-01-04 05:35:37,426 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40350754658381144, 'Total loss': 0.40350754658381144} | train loss {'Reaction outcome loss': 0.2028889820006565, 'Total loss': 0.2028889820006565}
2023-01-04 05:35:37,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:37,426 INFO:     Epoch: 68
2023-01-04 05:35:39,027 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38469384213288627, 'Total loss': 0.38469384213288627} | train loss {'Reaction outcome loss': 0.19750422183491478, 'Total loss': 0.19750422183491478}
2023-01-04 05:35:39,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:39,027 INFO:     Epoch: 69
2023-01-04 05:35:40,646 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41983500123023987, 'Total loss': 0.41983500123023987} | train loss {'Reaction outcome loss': 0.1991844712369924, 'Total loss': 0.1991844712369924}
2023-01-04 05:35:40,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:40,646 INFO:     Epoch: 70
2023-01-04 05:35:42,269 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4010824918746948, 'Total loss': 0.4010824918746948} | train loss {'Reaction outcome loss': 0.1984583170082595, 'Total loss': 0.1984583170082595}
2023-01-04 05:35:42,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:42,269 INFO:     Epoch: 71
2023-01-04 05:35:43,896 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4084686319033305, 'Total loss': 0.4084686319033305} | train loss {'Reaction outcome loss': 0.19536664546719526, 'Total loss': 0.19536664546719526}
2023-01-04 05:35:43,896 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:43,896 INFO:     Epoch: 72
2023-01-04 05:35:45,490 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4077570060888926, 'Total loss': 0.4077570060888926} | train loss {'Reaction outcome loss': 0.19356797258991626, 'Total loss': 0.19356797258991626}
2023-01-04 05:35:45,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:45,490 INFO:     Epoch: 73
2023-01-04 05:35:47,101 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39009839395682017, 'Total loss': 0.39009839395682017} | train loss {'Reaction outcome loss': 0.19463073300863432, 'Total loss': 0.19463073300863432}
2023-01-04 05:35:47,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:47,102 INFO:     Epoch: 74
2023-01-04 05:35:48,736 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42553908228874204, 'Total loss': 0.42553908228874204} | train loss {'Reaction outcome loss': 0.19185513496022363, 'Total loss': 0.19185513496022363}
2023-01-04 05:35:48,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:48,736 INFO:     Epoch: 75
2023-01-04 05:35:50,345 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40314948062102, 'Total loss': 0.40314948062102} | train loss {'Reaction outcome loss': 0.1906892859279464, 'Total loss': 0.1906892859279464}
2023-01-04 05:35:50,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:50,345 INFO:     Epoch: 76
2023-01-04 05:35:51,951 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4046004593372345, 'Total loss': 0.4046004593372345} | train loss {'Reaction outcome loss': 0.1927183015668758, 'Total loss': 0.1927183015668758}
2023-01-04 05:35:51,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:51,951 INFO:     Epoch: 77
2023-01-04 05:35:53,538 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42195177177588145, 'Total loss': 0.42195177177588145} | train loss {'Reaction outcome loss': 0.19060366868381035, 'Total loss': 0.19060366868381035}
2023-01-04 05:35:53,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:53,538 INFO:     Epoch: 78
2023-01-04 05:35:55,143 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4329651914536953, 'Total loss': 0.4329651914536953} | train loss {'Reaction outcome loss': 0.18830277977867677, 'Total loss': 0.18830277977867677}
2023-01-04 05:35:55,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:55,143 INFO:     Epoch: 79
2023-01-04 05:35:56,728 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42873401939868927, 'Total loss': 0.42873401939868927} | train loss {'Reaction outcome loss': 0.18688190801048968, 'Total loss': 0.18688190801048968}
2023-01-04 05:35:56,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:56,729 INFO:     Epoch: 80
2023-01-04 05:35:58,330 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4073887134591738, 'Total loss': 0.4073887134591738} | train loss {'Reaction outcome loss': 0.187864078417259, 'Total loss': 0.187864078417259}
2023-01-04 05:35:58,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:58,331 INFO:     Epoch: 81
2023-01-04 05:35:59,928 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43345552881558735, 'Total loss': 0.43345552881558735} | train loss {'Reaction outcome loss': 0.18423851385766418, 'Total loss': 0.18423851385766418}
2023-01-04 05:35:59,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:35:59,929 INFO:     Epoch: 82
2023-01-04 05:36:01,552 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42590879996617637, 'Total loss': 0.42590879996617637} | train loss {'Reaction outcome loss': 0.18523062912189142, 'Total loss': 0.18523062912189142}
2023-01-04 05:36:01,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:01,552 INFO:     Epoch: 83
2023-01-04 05:36:03,132 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41808769007523855, 'Total loss': 0.41808769007523855} | train loss {'Reaction outcome loss': 0.18622502621384304, 'Total loss': 0.18622502621384304}
2023-01-04 05:36:03,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:03,132 INFO:     Epoch: 84
2023-01-04 05:36:04,759 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4497283319632212, 'Total loss': 0.4497283319632212} | train loss {'Reaction outcome loss': 0.18738716227483232, 'Total loss': 0.18738716227483232}
2023-01-04 05:36:04,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:04,759 INFO:     Epoch: 85
2023-01-04 05:36:06,379 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44259636104106903, 'Total loss': 0.44259636104106903} | train loss {'Reaction outcome loss': 0.18285266872804734, 'Total loss': 0.18285266872804734}
2023-01-04 05:36:06,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:06,380 INFO:     Epoch: 86
2023-01-04 05:36:07,986 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4205677797396978, 'Total loss': 0.4205677797396978} | train loss {'Reaction outcome loss': 0.18349019123328722, 'Total loss': 0.18349019123328722}
2023-01-04 05:36:07,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:07,986 INFO:     Epoch: 87
2023-01-04 05:36:09,612 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41767835319042207, 'Total loss': 0.41767835319042207} | train loss {'Reaction outcome loss': 0.18440603177039633, 'Total loss': 0.18440603177039633}
2023-01-04 05:36:09,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:09,612 INFO:     Epoch: 88
2023-01-04 05:36:11,223 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4237253983815511, 'Total loss': 0.4237253983815511} | train loss {'Reaction outcome loss': 0.1831110724338771, 'Total loss': 0.1831110724338771}
2023-01-04 05:36:11,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:11,224 INFO:     Epoch: 89
2023-01-04 05:36:12,852 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4115991622209549, 'Total loss': 0.4115991622209549} | train loss {'Reaction outcome loss': 0.18013727841797933, 'Total loss': 0.18013727841797933}
2023-01-04 05:36:12,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:12,852 INFO:     Epoch: 90
2023-01-04 05:36:14,458 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4469130575656891, 'Total loss': 0.4469130575656891} | train loss {'Reaction outcome loss': 0.1808724497925719, 'Total loss': 0.1808724497925719}
2023-01-04 05:36:14,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:14,458 INFO:     Epoch: 91
2023-01-04 05:36:16,087 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43112220565478004, 'Total loss': 0.43112220565478004} | train loss {'Reaction outcome loss': 0.17928966968606094, 'Total loss': 0.17928966968606094}
2023-01-04 05:36:16,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:16,087 INFO:     Epoch: 92
2023-01-04 05:36:17,731 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41783726811408994, 'Total loss': 0.41783726811408994} | train loss {'Reaction outcome loss': 0.1785101845779789, 'Total loss': 0.1785101845779789}
2023-01-04 05:36:17,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:17,731 INFO:     Epoch: 93
2023-01-04 05:36:19,359 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42618004480997723, 'Total loss': 0.42618004480997723} | train loss {'Reaction outcome loss': 0.1774288747688278, 'Total loss': 0.1774288747688278}
2023-01-04 05:36:19,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:19,359 INFO:     Epoch: 94
2023-01-04 05:36:20,979 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4134765883286794, 'Total loss': 0.4134765883286794} | train loss {'Reaction outcome loss': 0.17360018163462193, 'Total loss': 0.17360018163462193}
2023-01-04 05:36:20,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:20,979 INFO:     Epoch: 95
2023-01-04 05:36:22,589 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44327797293663024, 'Total loss': 0.44327797293663024} | train loss {'Reaction outcome loss': 0.17901667680201333, 'Total loss': 0.17901667680201333}
2023-01-04 05:36:22,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:22,589 INFO:     Epoch: 96
2023-01-04 05:36:24,190 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4260208417971929, 'Total loss': 0.4260208417971929} | train loss {'Reaction outcome loss': 0.17718969350041897, 'Total loss': 0.17718969350041897}
2023-01-04 05:36:24,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:24,191 INFO:     Epoch: 97
2023-01-04 05:36:25,780 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4373121897379557, 'Total loss': 0.4373121897379557} | train loss {'Reaction outcome loss': 0.17616072322648785, 'Total loss': 0.17616072322648785}
2023-01-04 05:36:25,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:25,780 INFO:     Epoch: 98
2023-01-04 05:36:27,411 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.429924288392067, 'Total loss': 0.429924288392067} | train loss {'Reaction outcome loss': 0.1753995687522613, 'Total loss': 0.1753995687522613}
2023-01-04 05:36:27,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-04 05:36:27,412 INFO:     Epoch: 99
2023-01-04 05:36:29,041 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45213675796985625, 'Total loss': 0.45213675796985625} | train loss {'Reaction outcome loss': 0.17217042219122394, 'Total loss': 0.17217042219122394}
2023-01-04 05:36:29,042 INFO:     Best model found after epoch 29 of 100.
2023-01-04 05:36:29,042 INFO:   Done with stage: TRAINING
2023-01-04 05:36:29,042 INFO:   Starting stage: EVALUATION
2023-01-04 05:36:29,163 INFO:   Done with stage: EVALUATION
2023-01-04 05:36:29,164 INFO: Done with stage: RUNNING SPLITS
2023-01-04 05:36:29,164 INFO: Starting stage: COMPUTE METRICS
2023-01-04 05:36:30,323 INFO: Done with stage: COMPUTE METRICS
2023-01-04 05:36:30,324 INFO: Starting stage: EXPORT RESULTS
2023-01-04 05:36:30,341 INFO:   Final results averaged over 50 folds: 
2023-01-04 05:36:30,345 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.182633           NaN  0.313766       NaN
2023-01-04 05:36:31,997 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-04 05:36:32,002 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-04 05:36:32,004 DEBUG:   interactive is False
2023-01-04 05:36:32,004 DEBUG:   platform is linux
2023-01-04 05:36:32,004 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-04 05:36:32,176 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-04 05:36:32,178 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-04 05:36:32,621 DEBUG:   Loaded backend agg version unknown.
2023-01-04 05:36:32,623 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 05:36:32,623 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,623 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,623 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,623 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,623 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,623 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,624 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 05:36:32,625 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,626 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,626 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,626 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 05:36:32,626 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,626 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 05:36:32,662 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,662 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,663 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 05:36:32,664 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,664 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 05:36:32,673 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,673 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,674 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-04 05:36:32,675 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-04 05:36:32,676 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-04 05:36:33,045 INFO: Done with stage: EXPORT RESULTS
2023-01-04 05:36:33,045 INFO: Starting stage: SAVE MODEL
2023-01-04 05:36:33,099 INFO: Done with stage: SAVE MODEL
2023-01-04 05:36:33,099 INFO: Wall time for program:  8009.03 seconds
