2022-12-05 21:33:51,691 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffndot/a28b65658b83a26dd0e06e8e8422ebb0/2022_12_05-191940",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffndot",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-05 21:33:51,703 INFO: Starting stage: BUILD FEATURIZERS
2022-12-05 21:33:51,705 INFO:   Creating esm representation model
2022-12-05 21:33:51,705 INFO:   Done esm representation model
2022-12-05 21:33:51,705 INFO: Done with stage: BUILD FEATURIZERS
2022-12-05 21:33:51,705 INFO: Starting stage: BUILDING DATASET
2022-12-05 21:33:51,759 INFO: Done with stage: BUILDING DATASET
2022-12-05 21:33:51,759 INFO: Starting stage: FEATURIZING DATA
2022-12-05 21:33:51,759 INFO:   Featurizing proteins
2022-12-05 21:33:51,760 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-05 21:33:51,778 INFO:   Loaded feature cache of size 204
2022-12-05 21:33:51,779 INFO:   Starting to pool ESM Embeddings
2022-12-05 21:33:51,900 INFO:   Featurizing molecules
2022-12-05 21:33:51,902 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-05 21:33:51,905 INFO:   Loaded feature cache of size 495
2022-12-05 21:33:53,267 INFO: Done with stage: FEATURIZING DATA
2022-12-05 21:33:53,267 INFO: Starting stage: RUNNING SPLITS
2022-12-05 21:33:53,275 INFO:   Leaving out SEQ value Fold_0
2022-12-05 21:33:53,289 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 21:33:53,290 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:33:53,941 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:33:53,941 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:33:54,009 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:33:54,009 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:33:54,010 INFO:     No hyperparam tuning for this model
2022-12-05 21:33:54,010 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:33:54,010 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:33:54,010 INFO:     None feature selector for col prot
2022-12-05 21:33:54,011 INFO:     None feature selector for col prot
2022-12-05 21:33:54,011 INFO:     None feature selector for col prot
2022-12-05 21:33:54,011 INFO:     None feature selector for col chem
2022-12-05 21:33:54,011 INFO:     None feature selector for col chem
2022-12-05 21:33:54,011 INFO:     None feature selector for col chem
2022-12-05 21:33:54,011 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:33:54,012 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:33:54,013 INFO:     Number of params in model 215821
2022-12-05 21:33:54,013 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:33:54,014 INFO:   Starting stage: TRAINING
2022-12-05 21:33:56,074 INFO:     Val loss before train {'Reaction outcome loss': 1.0583376329998637, 'Total loss': 1.0583376329998637}
2022-12-05 21:33:56,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:56,075 INFO:     Epoch: 0
2022-12-05 21:33:56,861 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.668908202370932, 'Total loss': 0.668908202370932} | train loss {'Reaction outcome loss': 0.7762640349444796, 'Total loss': 0.7762640349444796}
2022-12-05 21:33:56,861 INFO:     Found new best model at epoch 0
2022-12-05 21:33:56,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:56,862 INFO:     Epoch: 1
2022-12-05 21:33:57,646 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5759299896484198, 'Total loss': 0.5759299896484198} | train loss {'Reaction outcome loss': 0.5393780048509114, 'Total loss': 0.5393780048509114}
2022-12-05 21:33:57,646 INFO:     Found new best model at epoch 1
2022-12-05 21:33:57,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:57,647 INFO:     Epoch: 2
2022-12-05 21:33:58,432 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5364878725173862, 'Total loss': 0.5364878725173862} | train loss {'Reaction outcome loss': 0.47503616502050494, 'Total loss': 0.47503616502050494}
2022-12-05 21:33:58,432 INFO:     Found new best model at epoch 2
2022-12-05 21:33:58,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:58,433 INFO:     Epoch: 3
2022-12-05 21:33:59,224 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5137248538261237, 'Total loss': 0.5137248538261237} | train loss {'Reaction outcome loss': 0.4336531173254623, 'Total loss': 0.4336531173254623}
2022-12-05 21:33:59,224 INFO:     Found new best model at epoch 3
2022-12-05 21:33:59,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:33:59,225 INFO:     Epoch: 4
2022-12-05 21:34:00,004 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4948824900527333, 'Total loss': 0.4948824900527333} | train loss {'Reaction outcome loss': 0.40070886222920454, 'Total loss': 0.40070886222920454}
2022-12-05 21:34:00,004 INFO:     Found new best model at epoch 4
2022-12-05 21:34:00,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:00,005 INFO:     Epoch: 5
2022-12-05 21:34:00,792 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4855873259001, 'Total loss': 0.4855873259001} | train loss {'Reaction outcome loss': 0.3749063409193129, 'Total loss': 0.3749063409193129}
2022-12-05 21:34:00,792 INFO:     Found new best model at epoch 5
2022-12-05 21:34:00,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:00,793 INFO:     Epoch: 6
2022-12-05 21:34:01,579 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47350244154763776, 'Total loss': 0.47350244154763776} | train loss {'Reaction outcome loss': 0.35631923725614784, 'Total loss': 0.35631923725614784}
2022-12-05 21:34:01,579 INFO:     Found new best model at epoch 6
2022-12-05 21:34:01,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:01,580 INFO:     Epoch: 7
2022-12-05 21:34:02,365 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46598606331403863, 'Total loss': 0.46598606331403863} | train loss {'Reaction outcome loss': 0.3390450819593961, 'Total loss': 0.3390450819593961}
2022-12-05 21:34:02,366 INFO:     Found new best model at epoch 7
2022-12-05 21:34:02,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:02,367 INFO:     Epoch: 8
2022-12-05 21:34:03,153 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.472286504714988, 'Total loss': 0.472286504714988} | train loss {'Reaction outcome loss': 0.32029968802435477, 'Total loss': 0.32029968802435477}
2022-12-05 21:34:03,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:03,153 INFO:     Epoch: 9
2022-12-05 21:34:03,932 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4639736119397851, 'Total loss': 0.4639736119397851} | train loss {'Reaction outcome loss': 0.30816559777518765, 'Total loss': 0.30816559777518765}
2022-12-05 21:34:03,932 INFO:     Found new best model at epoch 9
2022-12-05 21:34:03,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:03,933 INFO:     Epoch: 10
2022-12-05 21:34:04,715 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4601649579613708, 'Total loss': 0.4601649579613708} | train loss {'Reaction outcome loss': 0.2978794006783454, 'Total loss': 0.2978794006783454}
2022-12-05 21:34:04,715 INFO:     Found new best model at epoch 10
2022-12-05 21:34:04,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:04,716 INFO:     Epoch: 11
2022-12-05 21:34:05,503 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46022324749203614, 'Total loss': 0.46022324749203614} | train loss {'Reaction outcome loss': 0.2835403088113812, 'Total loss': 0.2835403088113812}
2022-12-05 21:34:05,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:05,503 INFO:     Epoch: 12
2022-12-05 21:34:06,286 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46464663466741873, 'Total loss': 0.46464663466741873} | train loss {'Reaction outcome loss': 0.27308356761932373, 'Total loss': 0.27308356761932373}
2022-12-05 21:34:06,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:06,287 INFO:     Epoch: 13
2022-12-05 21:34:07,066 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4760813661092936, 'Total loss': 0.4760813661092936} | train loss {'Reaction outcome loss': 0.26443394612459864, 'Total loss': 0.26443394612459864}
2022-12-05 21:34:07,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:07,067 INFO:     Epoch: 14
2022-12-05 21:34:07,845 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4583047008098558, 'Total loss': 0.4583047008098558} | train loss {'Reaction outcome loss': 0.2587040597420247, 'Total loss': 0.2587040597420247}
2022-12-05 21:34:07,845 INFO:     Found new best model at epoch 14
2022-12-05 21:34:07,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:07,846 INFO:     Epoch: 15
2022-12-05 21:34:08,631 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4748485400233158, 'Total loss': 0.4748485400233158} | train loss {'Reaction outcome loss': 0.24905630714092097, 'Total loss': 0.24905630714092097}
2022-12-05 21:34:08,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:08,631 INFO:     Epoch: 16
2022-12-05 21:34:09,412 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47424106715723524, 'Total loss': 0.47424106715723524} | train loss {'Reaction outcome loss': 0.24237414020434267, 'Total loss': 0.24237414020434267}
2022-12-05 21:34:09,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:09,412 INFO:     Epoch: 17
2022-12-05 21:34:10,195 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45769180114879165, 'Total loss': 0.45769180114879165} | train loss {'Reaction outcome loss': 0.23777002847341241, 'Total loss': 0.23777002847341241}
2022-12-05 21:34:10,196 INFO:     Found new best model at epoch 17
2022-12-05 21:34:10,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:10,196 INFO:     Epoch: 18
2022-12-05 21:34:10,982 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46446830311486886, 'Total loss': 0.46446830311486886} | train loss {'Reaction outcome loss': 0.2288889279741733, 'Total loss': 0.2288889279741733}
2022-12-05 21:34:10,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:10,982 INFO:     Epoch: 19
2022-12-05 21:34:11,767 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4651487414226976, 'Total loss': 0.4651487414226976} | train loss {'Reaction outcome loss': 0.2241298312657192, 'Total loss': 0.2241298312657192}
2022-12-05 21:34:11,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:11,767 INFO:     Epoch: 20
2022-12-05 21:34:12,546 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.459449463805487, 'Total loss': 0.459449463805487} | train loss {'Reaction outcome loss': 0.21874287788618785, 'Total loss': 0.21874287788618785}
2022-12-05 21:34:12,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:12,546 INFO:     Epoch: 21
2022-12-05 21:34:13,323 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45472861791765967, 'Total loss': 0.45472861791765967} | train loss {'Reaction outcome loss': 0.21230341251328833, 'Total loss': 0.21230341251328833}
2022-12-05 21:34:13,323 INFO:     Found new best model at epoch 21
2022-12-05 21:34:13,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:13,324 INFO:     Epoch: 22
2022-12-05 21:34:14,103 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45451470308525616, 'Total loss': 0.45451470308525616} | train loss {'Reaction outcome loss': 0.2078718743058013, 'Total loss': 0.2078718743058013}
2022-12-05 21:34:14,104 INFO:     Found new best model at epoch 22
2022-12-05 21:34:14,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:14,104 INFO:     Epoch: 23
2022-12-05 21:34:14,879 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4572688659956289, 'Total loss': 0.4572688659956289} | train loss {'Reaction outcome loss': 0.20685479754856864, 'Total loss': 0.20685479754856864}
2022-12-05 21:34:14,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:14,880 INFO:     Epoch: 24
2022-12-05 21:34:15,659 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45940291742945827, 'Total loss': 0.45940291742945827} | train loss {'Reaction outcome loss': 0.20137587891219824, 'Total loss': 0.20137587891219824}
2022-12-05 21:34:15,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:15,659 INFO:     Epoch: 25
2022-12-05 21:34:16,434 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45863805434038474, 'Total loss': 0.45863805434038474} | train loss {'Reaction outcome loss': 0.1974395270932649, 'Total loss': 0.1974395270932649}
2022-12-05 21:34:16,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:16,434 INFO:     Epoch: 26
2022-12-05 21:34:17,209 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45683829451716224, 'Total loss': 0.45683829451716224} | train loss {'Reaction outcome loss': 0.194614282000016, 'Total loss': 0.194614282000016}
2022-12-05 21:34:17,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:17,209 INFO:     Epoch: 27
2022-12-05 21:34:17,982 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4524125380571498, 'Total loss': 0.4524125380571498} | train loss {'Reaction outcome loss': 0.19196674491843727, 'Total loss': 0.19196674491843727}
2022-12-05 21:34:17,982 INFO:     Found new best model at epoch 27
2022-12-05 21:34:17,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:17,983 INFO:     Epoch: 28
2022-12-05 21:34:18,756 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4583842179109884, 'Total loss': 0.4583842179109884} | train loss {'Reaction outcome loss': 0.18606333164345534, 'Total loss': 0.18606333164345534}
2022-12-05 21:34:18,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:18,756 INFO:     Epoch: 29
2022-12-05 21:34:19,533 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45678280813749444, 'Total loss': 0.45678280813749444} | train loss {'Reaction outcome loss': 0.18350999741280666, 'Total loss': 0.18350999741280666}
2022-12-05 21:34:19,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:19,533 INFO:     Epoch: 30
2022-12-05 21:34:20,312 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47177177529002345, 'Total loss': 0.47177177529002345} | train loss {'Reaction outcome loss': 0.1775738703025902, 'Total loss': 0.1775738703025902}
2022-12-05 21:34:20,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:20,313 INFO:     Epoch: 31
2022-12-05 21:34:21,087 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46774146723192794, 'Total loss': 0.46774146723192794} | train loss {'Reaction outcome loss': 0.1762318297319847, 'Total loss': 0.1762318297319847}
2022-12-05 21:34:21,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:21,088 INFO:     Epoch: 32
2022-12-05 21:34:21,863 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4654197814159615, 'Total loss': 0.4654197814159615} | train loss {'Reaction outcome loss': 0.17622273176389394, 'Total loss': 0.17622273176389394}
2022-12-05 21:34:21,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:21,864 INFO:     Epoch: 33
2022-12-05 21:34:22,646 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47725643148255903, 'Total loss': 0.47725643148255903} | train loss {'Reaction outcome loss': 0.17093220996655156, 'Total loss': 0.17093220996655156}
2022-12-05 21:34:22,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:22,646 INFO:     Epoch: 34
2022-12-05 21:34:23,425 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4657256135413813, 'Total loss': 0.4657256135413813} | train loss {'Reaction outcome loss': 0.16922761111321752, 'Total loss': 0.16922761111321752}
2022-12-05 21:34:23,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:23,426 INFO:     Epoch: 35
2022-12-05 21:34:24,205 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4542168264472207, 'Total loss': 0.4542168264472207} | train loss {'Reaction outcome loss': 0.16739581968085687, 'Total loss': 0.16739581968085687}
2022-12-05 21:34:24,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:24,205 INFO:     Epoch: 36
2022-12-05 21:34:24,994 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4809715851794842, 'Total loss': 0.4809715851794842} | train loss {'Reaction outcome loss': 0.16793523708236266, 'Total loss': 0.16793523708236266}
2022-12-05 21:34:24,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:24,995 INFO:     Epoch: 37
2022-12-05 21:34:25,780 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46447390283263007, 'Total loss': 0.46447390283263007} | train loss {'Reaction outcome loss': 0.16610937378537216, 'Total loss': 0.16610937378537216}
2022-12-05 21:34:25,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:25,780 INFO:     Epoch: 38
2022-12-05 21:34:26,561 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4748280401839766, 'Total loss': 0.4748280401839766} | train loss {'Reaction outcome loss': 0.16378712386167685, 'Total loss': 0.16378712386167685}
2022-12-05 21:34:26,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:26,561 INFO:     Epoch: 39
2022-12-05 21:34:27,338 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46514304519392724, 'Total loss': 0.46514304519392724} | train loss {'Reaction outcome loss': 0.16110855959294762, 'Total loss': 0.16110855959294762}
2022-12-05 21:34:27,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:27,339 INFO:     Epoch: 40
2022-12-05 21:34:28,114 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.456022642726122, 'Total loss': 0.456022642726122} | train loss {'Reaction outcome loss': 0.1604593697263569, 'Total loss': 0.1604593697263569}
2022-12-05 21:34:28,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:28,116 INFO:     Epoch: 41
2022-12-05 21:34:28,893 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4728862199672433, 'Total loss': 0.4728862199672433} | train loss {'Reaction outcome loss': 0.1571819077352764, 'Total loss': 0.1571819077352764}
2022-12-05 21:34:28,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:28,893 INFO:     Epoch: 42
2022-12-05 21:34:29,672 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46799253620380576, 'Total loss': 0.46799253620380576} | train loss {'Reaction outcome loss': 0.15600518719674866, 'Total loss': 0.15600518719674866}
2022-12-05 21:34:29,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:29,672 INFO:     Epoch: 43
2022-12-05 21:34:30,448 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49076931923627853, 'Total loss': 0.49076931923627853} | train loss {'Reaction outcome loss': 0.15369611412676082, 'Total loss': 0.15369611412676082}
2022-12-05 21:34:30,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:30,448 INFO:     Epoch: 44
2022-12-05 21:34:31,227 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4727523576381595, 'Total loss': 0.4727523576381595} | train loss {'Reaction outcome loss': 0.15340605900302284, 'Total loss': 0.15340605900302284}
2022-12-05 21:34:31,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:31,227 INFO:     Epoch: 45
2022-12-05 21:34:32,007 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4842869036419447, 'Total loss': 0.4842869036419447} | train loss {'Reaction outcome loss': 0.15407208780773352, 'Total loss': 0.15407208780773352}
2022-12-05 21:34:32,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:32,008 INFO:     Epoch: 46
2022-12-05 21:34:32,786 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48656951826672223, 'Total loss': 0.48656951826672223} | train loss {'Reaction outcome loss': 0.14927602290618616, 'Total loss': 0.14927602290618616}
2022-12-05 21:34:32,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:32,786 INFO:     Epoch: 47
2022-12-05 21:34:33,567 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4790550768375397, 'Total loss': 0.4790550768375397} | train loss {'Reaction outcome loss': 0.14873843121754585, 'Total loss': 0.14873843121754585}
2022-12-05 21:34:33,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:33,567 INFO:     Epoch: 48
2022-12-05 21:34:34,342 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4769472947647405, 'Total loss': 0.4769472947647405} | train loss {'Reaction outcome loss': 0.14919852459284125, 'Total loss': 0.14919852459284125}
2022-12-05 21:34:34,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:34,343 INFO:     Epoch: 49
2022-12-05 21:34:35,122 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46556467476279234, 'Total loss': 0.46556467476279234} | train loss {'Reaction outcome loss': 0.14758369605224886, 'Total loss': 0.14758369605224886}
2022-12-05 21:34:35,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:35,122 INFO:     Epoch: 50
2022-12-05 21:34:35,899 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.481636440684629, 'Total loss': 0.481636440684629} | train loss {'Reaction outcome loss': 0.14617107974243213, 'Total loss': 0.14617107974243213}
2022-12-05 21:34:35,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:35,899 INFO:     Epoch: 51
2022-12-05 21:34:36,678 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.478729066114093, 'Total loss': 0.478729066114093} | train loss {'Reaction outcome loss': 0.14674562170765684, 'Total loss': 0.14674562170765684}
2022-12-05 21:34:36,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:36,678 INFO:     Epoch: 52
2022-12-05 21:34:37,464 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48246482569117877, 'Total loss': 0.48246482569117877} | train loss {'Reaction outcome loss': 0.14465570428454486, 'Total loss': 0.14465570428454486}
2022-12-05 21:34:37,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:37,464 INFO:     Epoch: 53
2022-12-05 21:34:38,240 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4877426669348118, 'Total loss': 0.4877426669348118} | train loss {'Reaction outcome loss': 0.14383822521500167, 'Total loss': 0.14383822521500167}
2022-12-05 21:34:38,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:38,240 INFO:     Epoch: 54
2022-12-05 21:34:39,016 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4846170603535896, 'Total loss': 0.4846170603535896} | train loss {'Reaction outcome loss': 0.1413594690136245, 'Total loss': 0.1413594690136245}
2022-12-05 21:34:39,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:39,016 INFO:     Epoch: 55
2022-12-05 21:34:39,800 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4759072498526684, 'Total loss': 0.4759072498526684} | train loss {'Reaction outcome loss': 0.14281493384910168, 'Total loss': 0.14281493384910168}
2022-12-05 21:34:39,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:39,801 INFO:     Epoch: 56
2022-12-05 21:34:40,581 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4795900859198598, 'Total loss': 0.4795900859198598} | train loss {'Reaction outcome loss': 0.13835751033983515, 'Total loss': 0.13835751033983515}
2022-12-05 21:34:40,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:40,582 INFO:     Epoch: 57
2022-12-05 21:34:41,364 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4897119735562524, 'Total loss': 0.4897119735562524} | train loss {'Reaction outcome loss': 0.14127481497869995, 'Total loss': 0.14127481497869995}
2022-12-05 21:34:41,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:41,365 INFO:     Epoch: 58
2022-12-05 21:34:42,148 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48063718926074894, 'Total loss': 0.48063718926074894} | train loss {'Reaction outcome loss': 0.14071862463701945, 'Total loss': 0.14071862463701945}
2022-12-05 21:34:42,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:42,149 INFO:     Epoch: 59
2022-12-05 21:34:42,928 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.491596941338029, 'Total loss': 0.491596941338029} | train loss {'Reaction outcome loss': 0.13622560028414257, 'Total loss': 0.13622560028414257}
2022-12-05 21:34:42,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:42,929 INFO:     Epoch: 60
2022-12-05 21:34:43,714 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4914337233748547, 'Total loss': 0.4914337233748547} | train loss {'Reaction outcome loss': 0.13736161317096138, 'Total loss': 0.13736161317096138}
2022-12-05 21:34:43,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:43,714 INFO:     Epoch: 61
2022-12-05 21:34:44,494 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4962254163137702, 'Total loss': 0.4962254163137702} | train loss {'Reaction outcome loss': 0.13658434690022078, 'Total loss': 0.13658434690022078}
2022-12-05 21:34:44,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:44,494 INFO:     Epoch: 62
2022-12-05 21:34:45,277 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49517825973588364, 'Total loss': 0.49517825973588364} | train loss {'Reaction outcome loss': 0.135927535837791, 'Total loss': 0.135927535837791}
2022-12-05 21:34:45,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:45,278 INFO:     Epoch: 63
2022-12-05 21:34:46,061 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48105264992214913, 'Total loss': 0.48105264992214913} | train loss {'Reaction outcome loss': 0.13508271899257526, 'Total loss': 0.13508271899257526}
2022-12-05 21:34:46,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:46,061 INFO:     Epoch: 64
2022-12-05 21:34:46,844 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48740643574747927, 'Total loss': 0.48740643574747927} | train loss {'Reaction outcome loss': 0.13565746926870503, 'Total loss': 0.13565746926870503}
2022-12-05 21:34:46,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:46,845 INFO:     Epoch: 65
2022-12-05 21:34:47,629 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48328190140945965, 'Total loss': 0.48328190140945965} | train loss {'Reaction outcome loss': 0.1351392823653143, 'Total loss': 0.1351392823653143}
2022-12-05 21:34:47,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:47,630 INFO:     Epoch: 66
2022-12-05 21:34:48,410 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48816908168238266, 'Total loss': 0.48816908168238266} | train loss {'Reaction outcome loss': 0.13120218646544657, 'Total loss': 0.13120218646544657}
2022-12-05 21:34:48,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:48,410 INFO:     Epoch: 67
2022-12-05 21:34:49,188 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48759140940599666, 'Total loss': 0.48759140940599666} | train loss {'Reaction outcome loss': 0.1321918498762868, 'Total loss': 0.1321918498762868}
2022-12-05 21:34:49,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:49,188 INFO:     Epoch: 68
2022-12-05 21:34:49,967 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48776930639910143, 'Total loss': 0.48776930639910143} | train loss {'Reaction outcome loss': 0.13029187426093172, 'Total loss': 0.13029187426093172}
2022-12-05 21:34:49,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:49,967 INFO:     Epoch: 69
2022-12-05 21:34:50,753 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47479535777901494, 'Total loss': 0.47479535777901494} | train loss {'Reaction outcome loss': 0.13175494979578453, 'Total loss': 0.13175494979578453}
2022-12-05 21:34:50,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:50,753 INFO:     Epoch: 70
2022-12-05 21:34:51,539 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4883449916229692, 'Total loss': 0.4883449916229692} | train loss {'Reaction outcome loss': 0.126345283409092, 'Total loss': 0.126345283409092}
2022-12-05 21:34:51,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:51,539 INFO:     Epoch: 71
2022-12-05 21:34:52,319 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48303664094486903, 'Total loss': 0.48303664094486903} | train loss {'Reaction outcome loss': 0.13176427156946882, 'Total loss': 0.13176427156946882}
2022-12-05 21:34:52,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:52,319 INFO:     Epoch: 72
2022-12-05 21:34:53,096 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4799616381872532, 'Total loss': 0.4799616381872532} | train loss {'Reaction outcome loss': 0.13134362294384447, 'Total loss': 0.13134362294384447}
2022-12-05 21:34:53,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:53,096 INFO:     Epoch: 73
2022-12-05 21:34:53,872 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49366251119347504, 'Total loss': 0.49366251119347504} | train loss {'Reaction outcome loss': 0.12809919390338856, 'Total loss': 0.12809919390338856}
2022-12-05 21:34:53,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:53,873 INFO:     Epoch: 74
2022-12-05 21:34:54,651 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48655105780723484, 'Total loss': 0.48655105780723484} | train loss {'Reaction outcome loss': 0.13029150314415333, 'Total loss': 0.13029150314415333}
2022-12-05 21:34:54,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:54,651 INFO:     Epoch: 75
2022-12-05 21:34:55,429 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4926447455966195, 'Total loss': 0.4926447455966195} | train loss {'Reaction outcome loss': 0.12885825277199267, 'Total loss': 0.12885825277199267}
2022-12-05 21:34:55,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:55,429 INFO:     Epoch: 76
2022-12-05 21:34:56,210 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49538690839395966, 'Total loss': 0.49538690839395966} | train loss {'Reaction outcome loss': 0.1251224009281971, 'Total loss': 0.1251224009281971}
2022-12-05 21:34:56,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:56,210 INFO:     Epoch: 77
2022-12-05 21:34:56,996 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48682361113470657, 'Total loss': 0.48682361113470657} | train loss {'Reaction outcome loss': 0.12538968873988898, 'Total loss': 0.12538968873988898}
2022-12-05 21:34:56,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:56,996 INFO:     Epoch: 78
2022-12-05 21:34:57,778 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4880532885706702, 'Total loss': 0.4880532885706702} | train loss {'Reaction outcome loss': 0.12769942023394415, 'Total loss': 0.12769942023394415}
2022-12-05 21:34:57,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:57,778 INFO:     Epoch: 79
2022-12-05 21:34:58,560 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4858437776565552, 'Total loss': 0.4858437776565552} | train loss {'Reaction outcome loss': 0.125584588584597, 'Total loss': 0.125584588584597}
2022-12-05 21:34:58,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:58,560 INFO:     Epoch: 80
2022-12-05 21:34:59,344 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49342522129069927, 'Total loss': 0.49342522129069927} | train loss {'Reaction outcome loss': 0.12426598196406467, 'Total loss': 0.12426598196406467}
2022-12-05 21:34:59,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:34:59,345 INFO:     Epoch: 81
2022-12-05 21:35:00,127 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47707988633665926, 'Total loss': 0.47707988633665926} | train loss {'Reaction outcome loss': 0.12335986924953148, 'Total loss': 0.12335986924953148}
2022-12-05 21:35:00,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:00,127 INFO:     Epoch: 82
2022-12-05 21:35:00,916 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48561856185281, 'Total loss': 0.48561856185281} | train loss {'Reaction outcome loss': 0.1265635617138421, 'Total loss': 0.1265635617138421}
2022-12-05 21:35:00,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:00,916 INFO:     Epoch: 83
2022-12-05 21:35:01,699 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48474936221921167, 'Total loss': 0.48474936221921167} | train loss {'Reaction outcome loss': 0.12545535766107382, 'Total loss': 0.12545535766107382}
2022-12-05 21:35:01,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:01,699 INFO:     Epoch: 84
2022-12-05 21:35:02,484 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48736586369747337, 'Total loss': 0.48736586369747337} | train loss {'Reaction outcome loss': 0.12473234577012844, 'Total loss': 0.12473234577012844}
2022-12-05 21:35:02,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:02,484 INFO:     Epoch: 85
2022-12-05 21:35:03,271 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4892469817815825, 'Total loss': 0.4892469817815825} | train loss {'Reaction outcome loss': 0.12413080002669795, 'Total loss': 0.12413080002669795}
2022-12-05 21:35:03,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:03,271 INFO:     Epoch: 86
2022-12-05 21:35:04,052 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48394233334896175, 'Total loss': 0.48394233334896175} | train loss {'Reaction outcome loss': 0.12565779671088229, 'Total loss': 0.12565779671088229}
2022-12-05 21:35:04,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:04,052 INFO:     Epoch: 87
2022-12-05 21:35:04,836 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4810203896012417, 'Total loss': 0.4810203896012417} | train loss {'Reaction outcome loss': 0.12317262939559143, 'Total loss': 0.12317262939559143}
2022-12-05 21:35:04,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:04,837 INFO:     Epoch: 88
2022-12-05 21:35:05,621 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4988085946371389, 'Total loss': 0.4988085946371389} | train loss {'Reaction outcome loss': 0.12008902399617506, 'Total loss': 0.12008902399617506}
2022-12-05 21:35:05,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:05,622 INFO:     Epoch: 89
2022-12-05 21:35:06,404 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49537426198637763, 'Total loss': 0.49537426198637763} | train loss {'Reaction outcome loss': 0.12181996917504756, 'Total loss': 0.12181996917504756}
2022-12-05 21:35:06,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:06,404 INFO:     Epoch: 90
2022-12-05 21:35:07,180 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4825261193652486, 'Total loss': 0.4825261193652486} | train loss {'Reaction outcome loss': 0.121446828480016, 'Total loss': 0.121446828480016}
2022-12-05 21:35:07,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:07,181 INFO:     Epoch: 91
2022-12-05 21:35:07,959 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48991521118685255, 'Total loss': 0.48991521118685255} | train loss {'Reaction outcome loss': 0.12113470737020805, 'Total loss': 0.12113470737020805}
2022-12-05 21:35:07,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:07,959 INFO:     Epoch: 92
2022-12-05 21:35:08,735 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4849414343750754, 'Total loss': 0.4849414343750754} | train loss {'Reaction outcome loss': 0.12241406195232125, 'Total loss': 0.12241406195232125}
2022-12-05 21:35:08,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:08,735 INFO:     Epoch: 93
2022-12-05 21:35:09,510 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4821049934902856, 'Total loss': 0.4821049934902856} | train loss {'Reaction outcome loss': 0.12013148137780487, 'Total loss': 0.12013148137780487}
2022-12-05 21:35:09,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:09,510 INFO:     Epoch: 94
2022-12-05 21:35:10,291 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4849031349254209, 'Total loss': 0.4849031349254209} | train loss {'Reaction outcome loss': 0.12055704862902276, 'Total loss': 0.12055704862902276}
2022-12-05 21:35:10,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:10,292 INFO:     Epoch: 95
2022-12-05 21:35:11,069 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4870831592138423, 'Total loss': 0.4870831592138423} | train loss {'Reaction outcome loss': 0.12130462235129881, 'Total loss': 0.12130462235129881}
2022-12-05 21:35:11,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:11,069 INFO:     Epoch: 96
2022-12-05 21:35:11,848 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49096950403479644, 'Total loss': 0.49096950403479644} | train loss {'Reaction outcome loss': 0.12021202371898489, 'Total loss': 0.12021202371898489}
2022-12-05 21:35:11,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:11,849 INFO:     Epoch: 97
2022-12-05 21:35:12,627 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49576651114364, 'Total loss': 0.49576651114364} | train loss {'Reaction outcome loss': 0.11726602036925796, 'Total loss': 0.11726602036925796}
2022-12-05 21:35:12,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:12,628 INFO:     Epoch: 98
2022-12-05 21:35:13,407 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4958465634736904, 'Total loss': 0.4958465634736904} | train loss {'Reaction outcome loss': 0.11922283708232409, 'Total loss': 0.11922283708232409}
2022-12-05 21:35:13,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:13,407 INFO:     Epoch: 99
2022-12-05 21:35:14,186 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4871387800504995, 'Total loss': 0.4871387800504995} | train loss {'Reaction outcome loss': 0.11969648810775309, 'Total loss': 0.11969648810775309}
2022-12-05 21:35:14,186 INFO:     Best model found after epoch 28 of 100.
2022-12-05 21:35:14,186 INFO:   Done with stage: TRAINING
2022-12-05 21:35:14,186 INFO:   Starting stage: EVALUATION
2022-12-05 21:35:14,324 INFO:   Done with stage: EVALUATION
2022-12-05 21:35:14,324 INFO:   Leaving out SEQ value Fold_1
2022-12-05 21:35:14,336 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:35:14,337 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:35:14,994 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:35:14,994 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:35:15,063 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:35:15,063 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:35:15,063 INFO:     No hyperparam tuning for this model
2022-12-05 21:35:15,063 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:35:15,063 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:35:15,064 INFO:     None feature selector for col prot
2022-12-05 21:35:15,064 INFO:     None feature selector for col prot
2022-12-05 21:35:15,064 INFO:     None feature selector for col prot
2022-12-05 21:35:15,065 INFO:     None feature selector for col chem
2022-12-05 21:35:15,065 INFO:     None feature selector for col chem
2022-12-05 21:35:15,065 INFO:     None feature selector for col chem
2022-12-05 21:35:15,065 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:35:15,065 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:35:15,067 INFO:     Number of params in model 215821
2022-12-05 21:35:15,070 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:35:15,070 INFO:   Starting stage: TRAINING
2022-12-05 21:35:15,130 INFO:     Val loss before train {'Reaction outcome loss': 1.0060102357105776, 'Total loss': 1.0060102357105776}
2022-12-05 21:35:15,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:15,130 INFO:     Epoch: 0
2022-12-05 21:35:15,927 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6059402972459793, 'Total loss': 0.6059402972459793} | train loss {'Reaction outcome loss': 0.8075434427994949, 'Total loss': 0.8075434427994949}
2022-12-05 21:35:15,927 INFO:     Found new best model at epoch 0
2022-12-05 21:35:15,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:15,928 INFO:     Epoch: 1
2022-12-05 21:35:16,719 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5021342103454199, 'Total loss': 0.5021342103454199} | train loss {'Reaction outcome loss': 0.5605560984568074, 'Total loss': 0.5605560984568074}
2022-12-05 21:35:16,719 INFO:     Found new best model at epoch 1
2022-12-05 21:35:16,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:16,720 INFO:     Epoch: 2
2022-12-05 21:35:17,514 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46462782235308125, 'Total loss': 0.46462782235308125} | train loss {'Reaction outcome loss': 0.4890301465867502, 'Total loss': 0.4890301465867502}
2022-12-05 21:35:17,515 INFO:     Found new best model at epoch 2
2022-12-05 21:35:17,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:17,515 INFO:     Epoch: 3
2022-12-05 21:35:18,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4497517675838687, 'Total loss': 0.4497517675838687} | train loss {'Reaction outcome loss': 0.4435662055908427, 'Total loss': 0.4435662055908427}
2022-12-05 21:35:18,312 INFO:     Found new best model at epoch 3
2022-12-05 21:35:18,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:18,313 INFO:     Epoch: 4
2022-12-05 21:35:19,106 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42735816639932717, 'Total loss': 0.42735816639932717} | train loss {'Reaction outcome loss': 0.41055435246150745, 'Total loss': 0.41055435246150745}
2022-12-05 21:35:19,106 INFO:     Found new best model at epoch 4
2022-12-05 21:35:19,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:19,107 INFO:     Epoch: 5
2022-12-05 21:35:19,897 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4222472262653438, 'Total loss': 0.4222472262653438} | train loss {'Reaction outcome loss': 0.3851880670302672, 'Total loss': 0.3851880670302672}
2022-12-05 21:35:19,898 INFO:     Found new best model at epoch 5
2022-12-05 21:35:19,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:19,898 INFO:     Epoch: 6
2022-12-05 21:35:20,699 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40716709941625595, 'Total loss': 0.40716709941625595} | train loss {'Reaction outcome loss': 0.3659831980311195, 'Total loss': 0.3659831980311195}
2022-12-05 21:35:20,699 INFO:     Found new best model at epoch 6
2022-12-05 21:35:20,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:20,700 INFO:     Epoch: 7
2022-12-05 21:35:21,492 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40370807728984137, 'Total loss': 0.40370807728984137} | train loss {'Reaction outcome loss': 0.35617963800787444, 'Total loss': 0.35617963800787444}
2022-12-05 21:35:21,492 INFO:     Found new best model at epoch 7
2022-12-05 21:35:21,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:21,493 INFO:     Epoch: 8
2022-12-05 21:35:22,286 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4011929759925062, 'Total loss': 0.4011929759925062} | train loss {'Reaction outcome loss': 0.33765614551571216, 'Total loss': 0.33765614551571216}
2022-12-05 21:35:22,286 INFO:     Found new best model at epoch 8
2022-12-05 21:35:22,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:22,287 INFO:     Epoch: 9
2022-12-05 21:35:23,075 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39956283738667314, 'Total loss': 0.39956283738667314} | train loss {'Reaction outcome loss': 0.32076290213627373, 'Total loss': 0.32076290213627373}
2022-12-05 21:35:23,075 INFO:     Found new best model at epoch 9
2022-12-05 21:35:23,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:23,076 INFO:     Epoch: 10
2022-12-05 21:35:23,871 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40629331462762575, 'Total loss': 0.40629331462762575} | train loss {'Reaction outcome loss': 0.3068090022394532, 'Total loss': 0.3068090022394532}
2022-12-05 21:35:23,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:23,871 INFO:     Epoch: 11
2022-12-05 21:35:24,660 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40216844088651915, 'Total loss': 0.40216844088651915} | train loss {'Reaction outcome loss': 0.29554520079843427, 'Total loss': 0.29554520079843427}
2022-12-05 21:35:24,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:24,660 INFO:     Epoch: 12
2022-12-05 21:35:25,448 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3934902304952795, 'Total loss': 0.3934902304952795} | train loss {'Reaction outcome loss': 0.2898139493306156, 'Total loss': 0.2898139493306156}
2022-12-05 21:35:25,448 INFO:     Found new best model at epoch 12
2022-12-05 21:35:25,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:25,449 INFO:     Epoch: 13
2022-12-05 21:35:26,236 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40762015618383884, 'Total loss': 0.40762015618383884} | train loss {'Reaction outcome loss': 0.278519748977804, 'Total loss': 0.278519748977804}
2022-12-05 21:35:26,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:26,236 INFO:     Epoch: 14
2022-12-05 21:35:27,024 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3919215163385326, 'Total loss': 0.3919215163385326} | train loss {'Reaction outcome loss': 0.26719487958487786, 'Total loss': 0.26719487958487786}
2022-12-05 21:35:27,024 INFO:     Found new best model at epoch 14
2022-12-05 21:35:27,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:27,025 INFO:     Epoch: 15
2022-12-05 21:35:27,820 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3939068913459778, 'Total loss': 0.3939068913459778} | train loss {'Reaction outcome loss': 0.2545494105862944, 'Total loss': 0.2545494105862944}
2022-12-05 21:35:27,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:27,820 INFO:     Epoch: 16
2022-12-05 21:35:28,611 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4003150307319381, 'Total loss': 0.4003150307319381} | train loss {'Reaction outcome loss': 0.24799451335646241, 'Total loss': 0.24799451335646241}
2022-12-05 21:35:28,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:28,612 INFO:     Epoch: 17
2022-12-05 21:35:29,402 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3966196711090478, 'Total loss': 0.3966196711090478} | train loss {'Reaction outcome loss': 0.24438723807151502, 'Total loss': 0.24438723807151502}
2022-12-05 21:35:29,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:29,403 INFO:     Epoch: 18
2022-12-05 21:35:30,195 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3831408030607484, 'Total loss': 0.3831408030607484} | train loss {'Reaction outcome loss': 0.23719507202445736, 'Total loss': 0.23719507202445736}
2022-12-05 21:35:30,196 INFO:     Found new best model at epoch 18
2022-12-05 21:35:30,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:30,197 INFO:     Epoch: 19
2022-12-05 21:35:30,991 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3914576494558291, 'Total loss': 0.3914576494558291} | train loss {'Reaction outcome loss': 0.23000346013129905, 'Total loss': 0.23000346013129905}
2022-12-05 21:35:30,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:30,991 INFO:     Epoch: 20
2022-12-05 21:35:31,784 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39611040089618077, 'Total loss': 0.39611040089618077} | train loss {'Reaction outcome loss': 0.2227084351635655, 'Total loss': 0.2227084351635655}
2022-12-05 21:35:31,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:31,784 INFO:     Epoch: 21
2022-12-05 21:35:32,588 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4029307616027919, 'Total loss': 0.4029307616027919} | train loss {'Reaction outcome loss': 0.2204666110547448, 'Total loss': 0.2204666110547448}
2022-12-05 21:35:32,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:32,588 INFO:     Epoch: 22
2022-12-05 21:35:33,387 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39234282448887825, 'Total loss': 0.39234282448887825} | train loss {'Reaction outcome loss': 0.21628664460161376, 'Total loss': 0.21628664460161376}
2022-12-05 21:35:33,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:33,387 INFO:     Epoch: 23
2022-12-05 21:35:34,189 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4002392329275608, 'Total loss': 0.4002392329275608} | train loss {'Reaction outcome loss': 0.20856061330449727, 'Total loss': 0.20856061330449727}
2022-12-05 21:35:34,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:34,189 INFO:     Epoch: 24
2022-12-05 21:35:34,986 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39868570931933145, 'Total loss': 0.39868570931933145} | train loss {'Reaction outcome loss': 0.2089761931464257, 'Total loss': 0.2089761931464257}
2022-12-05 21:35:34,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:34,987 INFO:     Epoch: 25
2022-12-05 21:35:35,787 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41083127446472645, 'Total loss': 0.41083127446472645} | train loss {'Reaction outcome loss': 0.20384510641216266, 'Total loss': 0.20384510641216266}
2022-12-05 21:35:35,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:35,787 INFO:     Epoch: 26
2022-12-05 21:35:36,587 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.403475705195557, 'Total loss': 0.403475705195557} | train loss {'Reaction outcome loss': 0.1989993104929866, 'Total loss': 0.1989993104929866}
2022-12-05 21:35:36,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:36,588 INFO:     Epoch: 27
2022-12-05 21:35:37,381 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38832247917625035, 'Total loss': 0.38832247917625035} | train loss {'Reaction outcome loss': 0.19130885469958636, 'Total loss': 0.19130885469958636}
2022-12-05 21:35:37,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:37,381 INFO:     Epoch: 28
2022-12-05 21:35:38,183 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3964851369911974, 'Total loss': 0.3964851369911974} | train loss {'Reaction outcome loss': 0.1910648731673174, 'Total loss': 0.1910648731673174}
2022-12-05 21:35:38,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:38,183 INFO:     Epoch: 29
2022-12-05 21:35:38,982 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39544770324772055, 'Total loss': 0.39544770324772055} | train loss {'Reaction outcome loss': 0.19024441333917472, 'Total loss': 0.19024441333917472}
2022-12-05 21:35:38,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:38,982 INFO:     Epoch: 30
2022-12-05 21:35:39,772 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40285096368329093, 'Total loss': 0.40285096368329093} | train loss {'Reaction outcome loss': 0.1831335184213362, 'Total loss': 0.1831335184213362}
2022-12-05 21:35:39,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:39,772 INFO:     Epoch: 31
2022-12-05 21:35:40,563 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4039347161623565, 'Total loss': 0.4039347161623565} | train loss {'Reaction outcome loss': 0.18325751402221152, 'Total loss': 0.18325751402221152}
2022-12-05 21:35:40,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:40,564 INFO:     Epoch: 32
2022-12-05 21:35:41,359 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4190335852855986, 'Total loss': 0.4190335852855986} | train loss {'Reaction outcome loss': 0.1779573510140784, 'Total loss': 0.1779573510140784}
2022-12-05 21:35:41,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:41,359 INFO:     Epoch: 33
2022-12-05 21:35:42,150 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4210660799660466, 'Total loss': 0.4210660799660466} | train loss {'Reaction outcome loss': 0.18252732147752998, 'Total loss': 0.18252732147752998}
2022-12-05 21:35:42,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:42,150 INFO:     Epoch: 34
2022-12-05 21:35:42,937 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41443786126646126, 'Total loss': 0.41443786126646126} | train loss {'Reaction outcome loss': 0.18336272511163704, 'Total loss': 0.18336272511163704}
2022-12-05 21:35:42,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:42,937 INFO:     Epoch: 35
2022-12-05 21:35:43,727 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41465499285947194, 'Total loss': 0.41465499285947194} | train loss {'Reaction outcome loss': 0.17963979383440395, 'Total loss': 0.17963979383440395}
2022-12-05 21:35:43,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:43,727 INFO:     Epoch: 36
2022-12-05 21:35:44,516 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41889924759214575, 'Total loss': 0.41889924759214575} | train loss {'Reaction outcome loss': 0.16925386834497513, 'Total loss': 0.16925386834497513}
2022-12-05 21:35:44,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:44,517 INFO:     Epoch: 37
2022-12-05 21:35:45,307 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41587031429464166, 'Total loss': 0.41587031429464166} | train loss {'Reaction outcome loss': 0.16555295963790495, 'Total loss': 0.16555295963790495}
2022-12-05 21:35:45,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:45,307 INFO:     Epoch: 38
2022-12-05 21:35:46,097 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41626748036254535, 'Total loss': 0.41626748036254535} | train loss {'Reaction outcome loss': 0.17048540240839907, 'Total loss': 0.17048540240839907}
2022-12-05 21:35:46,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:46,097 INFO:     Epoch: 39
2022-12-05 21:35:46,889 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4251761764965274, 'Total loss': 0.4251761764965274} | train loss {'Reaction outcome loss': 0.16361834536408365, 'Total loss': 0.16361834536408365}
2022-12-05 21:35:46,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:46,889 INFO:     Epoch: 40
2022-12-05 21:35:47,686 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4231926595622843, 'Total loss': 0.4231926595622843} | train loss {'Reaction outcome loss': 0.16495943312280573, 'Total loss': 0.16495943312280573}
2022-12-05 21:35:47,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:47,686 INFO:     Epoch: 41
2022-12-05 21:35:48,484 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42333082177422265, 'Total loss': 0.42333082177422265} | train loss {'Reaction outcome loss': 0.16112115041462155, 'Total loss': 0.16112115041462155}
2022-12-05 21:35:48,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:48,484 INFO:     Epoch: 42
2022-12-05 21:35:49,277 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43436239033260127, 'Total loss': 0.43436239033260127} | train loss {'Reaction outcome loss': 0.1583058422257905, 'Total loss': 0.1583058422257905}
2022-12-05 21:35:49,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:49,278 INFO:     Epoch: 43
2022-12-05 21:35:50,071 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4238061308860779, 'Total loss': 0.4238061308860779} | train loss {'Reaction outcome loss': 0.15822045936396248, 'Total loss': 0.15822045936396248}
2022-12-05 21:35:50,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:50,071 INFO:     Epoch: 44
2022-12-05 21:35:50,864 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4291965067386627, 'Total loss': 0.4291965067386627} | train loss {'Reaction outcome loss': 0.15817649653822424, 'Total loss': 0.15817649653822424}
2022-12-05 21:35:50,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:50,864 INFO:     Epoch: 45
2022-12-05 21:35:51,660 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4401089171455665, 'Total loss': 0.4401089171455665} | train loss {'Reaction outcome loss': 0.1561493919822972, 'Total loss': 0.1561493919822972}
2022-12-05 21:35:51,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:51,660 INFO:     Epoch: 46
2022-12-05 21:35:52,460 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4298081435263157, 'Total loss': 0.4298081435263157} | train loss {'Reaction outcome loss': 0.1533906228221983, 'Total loss': 0.1533906228221983}
2022-12-05 21:35:52,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:52,460 INFO:     Epoch: 47
2022-12-05 21:35:53,259 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43321639544923196, 'Total loss': 0.43321639544923196} | train loss {'Reaction outcome loss': 0.1506571699884015, 'Total loss': 0.1506571699884015}
2022-12-05 21:35:53,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:53,260 INFO:     Epoch: 48
2022-12-05 21:35:54,052 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44438690827651456, 'Total loss': 0.44438690827651456} | train loss {'Reaction outcome loss': 0.14925177147242463, 'Total loss': 0.14925177147242463}
2022-12-05 21:35:54,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:54,052 INFO:     Epoch: 49
2022-12-05 21:35:54,847 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44104724478992546, 'Total loss': 0.44104724478992546} | train loss {'Reaction outcome loss': 0.1513988489095642, 'Total loss': 0.1513988489095642}
2022-12-05 21:35:54,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:54,848 INFO:     Epoch: 50
2022-12-05 21:35:55,647 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46037582375786523, 'Total loss': 0.46037582375786523} | train loss {'Reaction outcome loss': 0.14952443269041824, 'Total loss': 0.14952443269041824}
2022-12-05 21:35:55,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:55,647 INFO:     Epoch: 51
2022-12-05 21:35:56,440 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43640872395851393, 'Total loss': 0.43640872395851393} | train loss {'Reaction outcome loss': 0.1491193522233516, 'Total loss': 0.1491193522233516}
2022-12-05 21:35:56,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:56,441 INFO:     Epoch: 52
2022-12-05 21:35:57,239 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4477123801003803, 'Total loss': 0.4477123801003803} | train loss {'Reaction outcome loss': 0.14631872018233605, 'Total loss': 0.14631872018233605}
2022-12-05 21:35:57,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:57,239 INFO:     Epoch: 53
2022-12-05 21:35:58,035 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43788042376664554, 'Total loss': 0.43788042376664554} | train loss {'Reaction outcome loss': 0.14483123836918219, 'Total loss': 0.14483123836918219}
2022-12-05 21:35:58,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:58,036 INFO:     Epoch: 54
2022-12-05 21:35:58,837 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4294365295632319, 'Total loss': 0.4294365295632319} | train loss {'Reaction outcome loss': 0.1472605205091991, 'Total loss': 0.1472605205091991}
2022-12-05 21:35:58,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:58,838 INFO:     Epoch: 55
2022-12-05 21:35:59,637 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43927357549017126, 'Total loss': 0.43927357549017126} | train loss {'Reaction outcome loss': 0.14606236857607177, 'Total loss': 0.14606236857607177}
2022-12-05 21:35:59,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:35:59,637 INFO:     Epoch: 56
2022-12-05 21:36:00,437 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43625887212428177, 'Total loss': 0.43625887212428177} | train loss {'Reaction outcome loss': 0.15012172329982343, 'Total loss': 0.15012172329982343}
2022-12-05 21:36:00,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:00,437 INFO:     Epoch: 57
2022-12-05 21:36:01,233 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43969823758710513, 'Total loss': 0.43969823758710513} | train loss {'Reaction outcome loss': 0.1465970852340643, 'Total loss': 0.1465970852340643}
2022-12-05 21:36:01,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:01,234 INFO:     Epoch: 58
2022-12-05 21:36:02,031 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43953347189182584, 'Total loss': 0.43953347189182584} | train loss {'Reaction outcome loss': 0.14654456056382975, 'Total loss': 0.14654456056382975}
2022-12-05 21:36:02,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:02,032 INFO:     Epoch: 59
2022-12-05 21:36:02,829 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44206334989179263, 'Total loss': 0.44206334989179263} | train loss {'Reaction outcome loss': 0.14584478529298353, 'Total loss': 0.14584478529298353}
2022-12-05 21:36:02,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:02,829 INFO:     Epoch: 60
2022-12-05 21:36:03,625 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44378589669411833, 'Total loss': 0.44378589669411833} | train loss {'Reaction outcome loss': 0.1507818323186776, 'Total loss': 0.1507818323186776}
2022-12-05 21:36:03,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:03,625 INFO:     Epoch: 61
2022-12-05 21:36:04,422 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44308651848272845, 'Total loss': 0.44308651848272845} | train loss {'Reaction outcome loss': 0.14293260906675928, 'Total loss': 0.14293260906675928}
2022-12-05 21:36:04,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:04,422 INFO:     Epoch: 62
2022-12-05 21:36:05,221 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4244628870351748, 'Total loss': 0.4244628870351748} | train loss {'Reaction outcome loss': 0.14503252143718995, 'Total loss': 0.14503252143718995}
2022-12-05 21:36:05,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:05,221 INFO:     Epoch: 63
2022-12-05 21:36:06,018 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44035425274209544, 'Total loss': 0.44035425274209544} | train loss {'Reaction outcome loss': 0.13976366992527053, 'Total loss': 0.13976366992527053}
2022-12-05 21:36:06,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:06,018 INFO:     Epoch: 64
2022-12-05 21:36:06,817 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43961768089370296, 'Total loss': 0.43961768089370296} | train loss {'Reaction outcome loss': 0.14798327140992712, 'Total loss': 0.14798327140992712}
2022-12-05 21:36:06,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:06,817 INFO:     Epoch: 65
2022-12-05 21:36:07,616 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43167582391337916, 'Total loss': 0.43167582391337916} | train loss {'Reaction outcome loss': 0.13765049459571058, 'Total loss': 0.13765049459571058}
2022-12-05 21:36:07,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:07,617 INFO:     Epoch: 66
2022-12-05 21:36:08,415 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4300374783236872, 'Total loss': 0.4300374783236872} | train loss {'Reaction outcome loss': 0.13470380476756993, 'Total loss': 0.13470380476756993}
2022-12-05 21:36:08,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:08,415 INFO:     Epoch: 67
2022-12-05 21:36:09,216 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42853583801876416, 'Total loss': 0.42853583801876416} | train loss {'Reaction outcome loss': 0.13198656401774178, 'Total loss': 0.13198656401774178}
2022-12-05 21:36:09,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:09,216 INFO:     Epoch: 68
2022-12-05 21:36:10,010 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4359584745358337, 'Total loss': 0.4359584745358337} | train loss {'Reaction outcome loss': 0.13584950084417213, 'Total loss': 0.13584950084417213}
2022-12-05 21:36:10,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:10,010 INFO:     Epoch: 69
2022-12-05 21:36:10,808 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44338365441018884, 'Total loss': 0.44338365441018884} | train loss {'Reaction outcome loss': 0.13712904182251406, 'Total loss': 0.13712904182251406}
2022-12-05 21:36:10,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:10,808 INFO:     Epoch: 70
2022-12-05 21:36:11,608 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44019945101304486, 'Total loss': 0.44019945101304486} | train loss {'Reaction outcome loss': 0.13454054759038606, 'Total loss': 0.13454054759038606}
2022-12-05 21:36:11,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:11,608 INFO:     Epoch: 71
2022-12-05 21:36:12,410 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44543650407682767, 'Total loss': 0.44543650407682767} | train loss {'Reaction outcome loss': 0.14017070448667052, 'Total loss': 0.14017070448667052}
2022-12-05 21:36:12,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:12,411 INFO:     Epoch: 72
2022-12-05 21:36:13,213 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45124259116974746, 'Total loss': 0.45124259116974746} | train loss {'Reaction outcome loss': 0.1328550426078289, 'Total loss': 0.1328550426078289}
2022-12-05 21:36:13,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:13,214 INFO:     Epoch: 73
2022-12-05 21:36:14,007 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42992002110589633, 'Total loss': 0.42992002110589633} | train loss {'Reaction outcome loss': 0.1344137261037221, 'Total loss': 0.1344137261037221}
2022-12-05 21:36:14,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:14,007 INFO:     Epoch: 74
2022-12-05 21:36:14,803 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.430099599740722, 'Total loss': 0.430099599740722} | train loss {'Reaction outcome loss': 0.13267486292099664, 'Total loss': 0.13267486292099664}
2022-12-05 21:36:14,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:14,803 INFO:     Epoch: 75
2022-12-05 21:36:15,599 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45032655786384235, 'Total loss': 0.45032655786384235} | train loss {'Reaction outcome loss': 0.1329812816446006, 'Total loss': 0.1329812816446006}
2022-12-05 21:36:15,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:15,599 INFO:     Epoch: 76
2022-12-05 21:36:16,394 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44815642285076057, 'Total loss': 0.44815642285076057} | train loss {'Reaction outcome loss': 0.13063608625006337, 'Total loss': 0.13063608625006337}
2022-12-05 21:36:16,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:16,394 INFO:     Epoch: 77
2022-12-05 21:36:17,191 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44888043484057893, 'Total loss': 0.44888043484057893} | train loss {'Reaction outcome loss': 0.12918128421990133, 'Total loss': 0.12918128421990133}
2022-12-05 21:36:17,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:17,191 INFO:     Epoch: 78
2022-12-05 21:36:17,984 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44663607803258026, 'Total loss': 0.44663607803258026} | train loss {'Reaction outcome loss': 0.1299589925072333, 'Total loss': 0.1299589925072333}
2022-12-05 21:36:17,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:17,984 INFO:     Epoch: 79
2022-12-05 21:36:18,780 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44443466971543705, 'Total loss': 0.44443466971543705} | train loss {'Reaction outcome loss': 0.12969793134221905, 'Total loss': 0.12969793134221905}
2022-12-05 21:36:18,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:18,780 INFO:     Epoch: 80
2022-12-05 21:36:19,586 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4531065821647644, 'Total loss': 0.4531065821647644} | train loss {'Reaction outcome loss': 0.12827369201973624, 'Total loss': 0.12827369201973624}
2022-12-05 21:36:19,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:19,586 INFO:     Epoch: 81
2022-12-05 21:36:20,397 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4467522720382972, 'Total loss': 0.4467522720382972} | train loss {'Reaction outcome loss': 0.13214506864215922, 'Total loss': 0.13214506864215922}
2022-12-05 21:36:20,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:20,397 INFO:     Epoch: 82
2022-12-05 21:36:21,209 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45198480649427936, 'Total loss': 0.45198480649427936} | train loss {'Reaction outcome loss': 0.13154440574764617, 'Total loss': 0.13154440574764617}
2022-12-05 21:36:21,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:21,209 INFO:     Epoch: 83
2022-12-05 21:36:22,017 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44465878809040243, 'Total loss': 0.44465878809040243} | train loss {'Reaction outcome loss': 0.12763833371839423, 'Total loss': 0.12763833371839423}
2022-12-05 21:36:22,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:22,017 INFO:     Epoch: 84
2022-12-05 21:36:22,826 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45957504686984146, 'Total loss': 0.45957504686984146} | train loss {'Reaction outcome loss': 0.12833288586005637, 'Total loss': 0.12833288586005637}
2022-12-05 21:36:22,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:22,826 INFO:     Epoch: 85
2022-12-05 21:36:23,634 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4365541103549979, 'Total loss': 0.4365541103549979} | train loss {'Reaction outcome loss': 0.1263029482932045, 'Total loss': 0.1263029482932045}
2022-12-05 21:36:23,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:23,634 INFO:     Epoch: 86
2022-12-05 21:36:24,445 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44413700157945807, 'Total loss': 0.44413700157945807} | train loss {'Reaction outcome loss': 0.12283703098676887, 'Total loss': 0.12283703098676887}
2022-12-05 21:36:24,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:24,445 INFO:     Epoch: 87
2022-12-05 21:36:25,254 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44888366013765335, 'Total loss': 0.44888366013765335} | train loss {'Reaction outcome loss': 0.12745511671716747, 'Total loss': 0.12745511671716747}
2022-12-05 21:36:25,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:25,254 INFO:     Epoch: 88
2022-12-05 21:36:26,065 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4420239662920887, 'Total loss': 0.4420239662920887} | train loss {'Reaction outcome loss': 0.1276017262521181, 'Total loss': 0.1276017262521181}
2022-12-05 21:36:26,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:26,065 INFO:     Epoch: 89
2022-12-05 21:36:26,873 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43648484349250793, 'Total loss': 0.43648484349250793} | train loss {'Reaction outcome loss': 0.1351328490901482, 'Total loss': 0.1351328490901482}
2022-12-05 21:36:26,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:26,874 INFO:     Epoch: 90
2022-12-05 21:36:27,685 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42897832800041547, 'Total loss': 0.42897832800041547} | train loss {'Reaction outcome loss': 0.13529247762673055, 'Total loss': 0.13529247762673055}
2022-12-05 21:36:27,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:27,685 INFO:     Epoch: 91
2022-12-05 21:36:28,494 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4228789167140018, 'Total loss': 0.4228789167140018} | train loss {'Reaction outcome loss': 0.12720779716395414, 'Total loss': 0.12720779716395414}
2022-12-05 21:36:28,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:28,494 INFO:     Epoch: 92
2022-12-05 21:36:29,312 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43842380053617735, 'Total loss': 0.43842380053617735} | train loss {'Reaction outcome loss': 0.1288746865591136, 'Total loss': 0.1288746865591136}
2022-12-05 21:36:29,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:29,312 INFO:     Epoch: 93
2022-12-05 21:36:30,132 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4257766339419918, 'Total loss': 0.4257766339419918} | train loss {'Reaction outcome loss': 0.12642398404206343, 'Total loss': 0.12642398404206343}
2022-12-05 21:36:30,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:30,132 INFO:     Epoch: 94
2022-12-05 21:36:30,941 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4410665901377797, 'Total loss': 0.4410665901377797} | train loss {'Reaction outcome loss': 0.13015441018484744, 'Total loss': 0.13015441018484744}
2022-12-05 21:36:30,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:30,941 INFO:     Epoch: 95
2022-12-05 21:36:31,752 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.437776715579358, 'Total loss': 0.437776715579358} | train loss {'Reaction outcome loss': 0.12223287083600697, 'Total loss': 0.12223287083600697}
2022-12-05 21:36:31,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:31,754 INFO:     Epoch: 96
2022-12-05 21:36:32,565 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44452007656747644, 'Total loss': 0.44452007656747644} | train loss {'Reaction outcome loss': 0.12897063951999674, 'Total loss': 0.12897063951999674}
2022-12-05 21:36:32,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:32,565 INFO:     Epoch: 97
2022-12-05 21:36:33,375 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45714390599592164, 'Total loss': 0.45714390599592164} | train loss {'Reaction outcome loss': 0.13588577779085348, 'Total loss': 0.13588577779085348}
2022-12-05 21:36:33,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:33,375 INFO:     Epoch: 98
2022-12-05 21:36:34,187 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45175863633101637, 'Total loss': 0.45175863633101637} | train loss {'Reaction outcome loss': 0.12100302993776163, 'Total loss': 0.12100302993776163}
2022-12-05 21:36:34,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:34,187 INFO:     Epoch: 99
2022-12-05 21:36:34,998 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4328528071161021, 'Total loss': 0.4328528071161021} | train loss {'Reaction outcome loss': 0.12103202036367013, 'Total loss': 0.12103202036367013}
2022-12-05 21:36:34,998 INFO:     Best model found after epoch 19 of 100.
2022-12-05 21:36:34,998 INFO:   Done with stage: TRAINING
2022-12-05 21:36:34,998 INFO:   Starting stage: EVALUATION
2022-12-05 21:36:35,123 INFO:   Done with stage: EVALUATION
2022-12-05 21:36:35,123 INFO:   Leaving out SEQ value Fold_2
2022-12-05 21:36:35,136 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 21:36:35,136 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:36:35,774 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:36:35,774 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:36:35,844 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:36:35,844 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:36:35,844 INFO:     No hyperparam tuning for this model
2022-12-05 21:36:35,844 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:36:35,844 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:36:35,845 INFO:     None feature selector for col prot
2022-12-05 21:36:35,845 INFO:     None feature selector for col prot
2022-12-05 21:36:35,845 INFO:     None feature selector for col prot
2022-12-05 21:36:35,846 INFO:     None feature selector for col chem
2022-12-05 21:36:35,846 INFO:     None feature selector for col chem
2022-12-05 21:36:35,846 INFO:     None feature selector for col chem
2022-12-05 21:36:35,846 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:36:35,846 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:36:35,847 INFO:     Number of params in model 215821
2022-12-05 21:36:35,850 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:36:35,851 INFO:   Starting stage: TRAINING
2022-12-05 21:36:35,910 INFO:     Val loss before train {'Reaction outcome loss': 0.9630440127017886, 'Total loss': 0.9630440127017886}
2022-12-05 21:36:35,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:35,910 INFO:     Epoch: 0
2022-12-05 21:36:36,718 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6101822582788246, 'Total loss': 0.6101822582788246} | train loss {'Reaction outcome loss': 0.8185209434051983, 'Total loss': 0.8185209434051983}
2022-12-05 21:36:36,718 INFO:     Found new best model at epoch 0
2022-12-05 21:36:36,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:36,719 INFO:     Epoch: 1
2022-12-05 21:36:37,523 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5181442644706992, 'Total loss': 0.5181442644706992} | train loss {'Reaction outcome loss': 0.5632723993087401, 'Total loss': 0.5632723993087401}
2022-12-05 21:36:37,523 INFO:     Found new best model at epoch 1
2022-12-05 21:36:37,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:37,524 INFO:     Epoch: 2
2022-12-05 21:36:38,324 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4791399732578632, 'Total loss': 0.4791399732578632} | train loss {'Reaction outcome loss': 0.4861238571952601, 'Total loss': 0.4861238571952601}
2022-12-05 21:36:38,325 INFO:     Found new best model at epoch 2
2022-12-05 21:36:38,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:38,326 INFO:     Epoch: 3
2022-12-05 21:36:39,127 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4622009905964829, 'Total loss': 0.4622009905964829} | train loss {'Reaction outcome loss': 0.4439570928206209, 'Total loss': 0.4439570928206209}
2022-12-05 21:36:39,127 INFO:     Found new best model at epoch 3
2022-12-05 21:36:39,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:39,128 INFO:     Epoch: 4
2022-12-05 21:36:39,929 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4405267533174781, 'Total loss': 0.4405267533174781} | train loss {'Reaction outcome loss': 0.4127696572390736, 'Total loss': 0.4127696572390736}
2022-12-05 21:36:39,929 INFO:     Found new best model at epoch 4
2022-12-05 21:36:39,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:39,930 INFO:     Epoch: 5
2022-12-05 21:36:40,733 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43542009176209917, 'Total loss': 0.43542009176209917} | train loss {'Reaction outcome loss': 0.3897809202126304, 'Total loss': 0.3897809202126304}
2022-12-05 21:36:40,733 INFO:     Found new best model at epoch 5
2022-12-05 21:36:40,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:40,734 INFO:     Epoch: 6
2022-12-05 21:36:41,543 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4195337888113288, 'Total loss': 0.4195337888113288} | train loss {'Reaction outcome loss': 0.3699778239013719, 'Total loss': 0.3699778239013719}
2022-12-05 21:36:41,544 INFO:     Found new best model at epoch 6
2022-12-05 21:36:41,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:41,544 INFO:     Epoch: 7
2022-12-05 21:36:42,347 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4246489024439523, 'Total loss': 0.4246489024439523} | train loss {'Reaction outcome loss': 0.3492537047103292, 'Total loss': 0.3492537047103292}
2022-12-05 21:36:42,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:42,348 INFO:     Epoch: 8
2022-12-05 21:36:43,144 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4307455770498098, 'Total loss': 0.4307455770498098} | train loss {'Reaction outcome loss': 0.3337444221203933, 'Total loss': 0.3337444221203933}
2022-12-05 21:36:43,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:43,144 INFO:     Epoch: 9
2022-12-05 21:36:43,929 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4233079790029415, 'Total loss': 0.4233079790029415} | train loss {'Reaction outcome loss': 0.32033200546732693, 'Total loss': 0.32033200546732693}
2022-12-05 21:36:43,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:43,929 INFO:     Epoch: 10
2022-12-05 21:36:44,713 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4227145927589993, 'Total loss': 0.4227145927589993} | train loss {'Reaction outcome loss': 0.30535698544661527, 'Total loss': 0.30535698544661527}
2022-12-05 21:36:44,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:44,713 INFO:     Epoch: 11
2022-12-05 21:36:45,495 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42120774055636206, 'Total loss': 0.42120774055636206} | train loss {'Reaction outcome loss': 0.295524249799916, 'Total loss': 0.295524249799916}
2022-12-05 21:36:45,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:45,495 INFO:     Epoch: 12
2022-12-05 21:36:46,281 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42823976867420727, 'Total loss': 0.42823976867420727} | train loss {'Reaction outcome loss': 0.28571598607375, 'Total loss': 0.28571598607375}
2022-12-05 21:36:46,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:46,281 INFO:     Epoch: 13
2022-12-05 21:36:47,068 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41846439658209333, 'Total loss': 0.41846439658209333} | train loss {'Reaction outcome loss': 0.2748556486407264, 'Total loss': 0.2748556486407264}
2022-12-05 21:36:47,068 INFO:     Found new best model at epoch 13
2022-12-05 21:36:47,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:47,069 INFO:     Epoch: 14
2022-12-05 21:36:47,855 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4123817460481511, 'Total loss': 0.4123817460481511} | train loss {'Reaction outcome loss': 0.2691028336154633, 'Total loss': 0.2691028336154633}
2022-12-05 21:36:47,855 INFO:     Found new best model at epoch 14
2022-12-05 21:36:47,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:47,856 INFO:     Epoch: 15
2022-12-05 21:36:48,640 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4286019791697347, 'Total loss': 0.4286019791697347} | train loss {'Reaction outcome loss': 0.26245289073005074, 'Total loss': 0.26245289073005074}
2022-12-05 21:36:48,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:48,640 INFO:     Epoch: 16
2022-12-05 21:36:49,424 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4144076675523159, 'Total loss': 0.4144076675523159} | train loss {'Reaction outcome loss': 0.25457042530484375, 'Total loss': 0.25457042530484375}
2022-12-05 21:36:49,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:49,424 INFO:     Epoch: 17
2022-12-05 21:36:50,211 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.418068585700767, 'Total loss': 0.418068585700767} | train loss {'Reaction outcome loss': 0.24670062565290538, 'Total loss': 0.24670062565290538}
2022-12-05 21:36:50,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:50,211 INFO:     Epoch: 18
2022-12-05 21:36:50,998 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4254965394042259, 'Total loss': 0.4254965394042259} | train loss {'Reaction outcome loss': 0.2417826805508039, 'Total loss': 0.2417826805508039}
2022-12-05 21:36:50,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:50,999 INFO:     Epoch: 19
2022-12-05 21:36:51,785 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41004837390988375, 'Total loss': 0.41004837390988375} | train loss {'Reaction outcome loss': 0.23581512977720284, 'Total loss': 0.23581512977720284}
2022-12-05 21:36:51,785 INFO:     Found new best model at epoch 19
2022-12-05 21:36:51,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:51,786 INFO:     Epoch: 20
2022-12-05 21:36:52,573 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41551427058009216, 'Total loss': 0.41551427058009216} | train loss {'Reaction outcome loss': 0.2283287453388826, 'Total loss': 0.2283287453388826}
2022-12-05 21:36:52,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:52,573 INFO:     Epoch: 21
2022-12-05 21:36:53,360 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4129034367411636, 'Total loss': 0.4129034367411636} | train loss {'Reaction outcome loss': 0.22536905708371616, 'Total loss': 0.22536905708371616}
2022-12-05 21:36:53,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:53,360 INFO:     Epoch: 22
2022-12-05 21:36:54,142 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4041268735430961, 'Total loss': 0.4041268735430961} | train loss {'Reaction outcome loss': 0.22225068828671193, 'Total loss': 0.22225068828671193}
2022-12-05 21:36:54,142 INFO:     Found new best model at epoch 22
2022-12-05 21:36:54,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:54,143 INFO:     Epoch: 23
2022-12-05 21:36:54,924 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42598920263523277, 'Total loss': 0.42598920263523277} | train loss {'Reaction outcome loss': 0.21523953554388442, 'Total loss': 0.21523953554388442}
2022-12-05 21:36:54,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:54,924 INFO:     Epoch: 24
2022-12-05 21:36:55,711 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4207026899554009, 'Total loss': 0.4207026899554009} | train loss {'Reaction outcome loss': 0.21239625470193682, 'Total loss': 0.21239625470193682}
2022-12-05 21:36:55,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:55,712 INFO:     Epoch: 25
2022-12-05 21:36:56,500 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4128475300101347, 'Total loss': 0.4128475300101347} | train loss {'Reaction outcome loss': 0.20981430358512967, 'Total loss': 0.20981430358512967}
2022-12-05 21:36:56,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:56,500 INFO:     Epoch: 26
2022-12-05 21:36:57,282 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41601298628158345, 'Total loss': 0.41601298628158345} | train loss {'Reaction outcome loss': 0.20389181073205392, 'Total loss': 0.20389181073205392}
2022-12-05 21:36:57,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:57,282 INFO:     Epoch: 27
2022-12-05 21:36:58,066 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4279581492030343, 'Total loss': 0.4279581492030343} | train loss {'Reaction outcome loss': 0.20203454574173102, 'Total loss': 0.20203454574173102}
2022-12-05 21:36:58,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:58,066 INFO:     Epoch: 28
2022-12-05 21:36:58,849 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41211536977180213, 'Total loss': 0.41211536977180213} | train loss {'Reaction outcome loss': 0.1952794095592909, 'Total loss': 0.1952794095592909}
2022-12-05 21:36:58,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:58,849 INFO:     Epoch: 29
2022-12-05 21:36:59,632 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4049898580063221, 'Total loss': 0.4049898580063221} | train loss {'Reaction outcome loss': 0.19387201435070056, 'Total loss': 0.19387201435070056}
2022-12-05 21:36:59,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:36:59,633 INFO:     Epoch: 30
2022-12-05 21:37:00,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41441098323395087, 'Total loss': 0.41441098323395087} | train loss {'Reaction outcome loss': 0.19062418183769847, 'Total loss': 0.19062418183769847}
2022-12-05 21:37:00,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:00,415 INFO:     Epoch: 31
2022-12-05 21:37:01,201 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4250069314310717, 'Total loss': 0.4250069314310717} | train loss {'Reaction outcome loss': 0.18555536243270654, 'Total loss': 0.18555536243270654}
2022-12-05 21:37:01,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:01,201 INFO:     Epoch: 32
2022-12-05 21:37:01,984 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4209279294970424, 'Total loss': 0.4209279294970424} | train loss {'Reaction outcome loss': 0.18634151537582033, 'Total loss': 0.18634151537582033}
2022-12-05 21:37:01,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:01,984 INFO:     Epoch: 33
2022-12-05 21:37:02,765 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40151133111049964, 'Total loss': 0.40151133111049964} | train loss {'Reaction outcome loss': 0.18099680353246142, 'Total loss': 0.18099680353246142}
2022-12-05 21:37:02,765 INFO:     Found new best model at epoch 33
2022-12-05 21:37:02,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:02,766 INFO:     Epoch: 34
2022-12-05 21:37:03,549 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41256793155226595, 'Total loss': 0.41256793155226595} | train loss {'Reaction outcome loss': 0.17957011010253526, 'Total loss': 0.17957011010253526}
2022-12-05 21:37:03,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:03,551 INFO:     Epoch: 35
2022-12-05 21:37:04,335 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4135151987158975, 'Total loss': 0.4135151987158975} | train loss {'Reaction outcome loss': 0.17833546419307345, 'Total loss': 0.17833546419307345}
2022-12-05 21:37:04,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:04,336 INFO:     Epoch: 36
2022-12-05 21:37:05,118 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4297767790944077, 'Total loss': 0.4297767790944077} | train loss {'Reaction outcome loss': 0.17527099637711635, 'Total loss': 0.17527099637711635}
2022-12-05 21:37:05,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:05,118 INFO:     Epoch: 37
2022-12-05 21:37:05,905 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4179399543723395, 'Total loss': 0.4179399543723395} | train loss {'Reaction outcome loss': 0.17283936487663476, 'Total loss': 0.17283936487663476}
2022-12-05 21:37:05,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:05,906 INFO:     Epoch: 38
2022-12-05 21:37:06,689 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41754736179529234, 'Total loss': 0.41754736179529234} | train loss {'Reaction outcome loss': 0.16920053439794994, 'Total loss': 0.16920053439794994}
2022-12-05 21:37:06,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:06,689 INFO:     Epoch: 39
2022-12-05 21:37:07,478 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4433077057433683, 'Total loss': 0.4433077057433683} | train loss {'Reaction outcome loss': 0.1697818164667878, 'Total loss': 0.1697818164667878}
2022-12-05 21:37:07,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:07,478 INFO:     Epoch: 40
2022-12-05 21:37:08,263 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4359687934088152, 'Total loss': 0.4359687934088152} | train loss {'Reaction outcome loss': 0.1643017493341057, 'Total loss': 0.1643017493341057}
2022-12-05 21:37:08,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:08,263 INFO:     Epoch: 41
2022-12-05 21:37:09,044 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.426375572071519, 'Total loss': 0.426375572071519} | train loss {'Reaction outcome loss': 0.16371544390977893, 'Total loss': 0.16371544390977893}
2022-12-05 21:37:09,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:09,044 INFO:     Epoch: 42
2022-12-05 21:37:09,837 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41780721656111786, 'Total loss': 0.41780721656111786} | train loss {'Reaction outcome loss': 0.1610994646936411, 'Total loss': 0.1610994646936411}
2022-12-05 21:37:09,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:09,837 INFO:     Epoch: 43
2022-12-05 21:37:10,623 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42669209768605787, 'Total loss': 0.42669209768605787} | train loss {'Reaction outcome loss': 0.16130780156885013, 'Total loss': 0.16130780156885013}
2022-12-05 21:37:10,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:10,623 INFO:     Epoch: 44
2022-12-05 21:37:11,405 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4267136331561, 'Total loss': 0.4267136331561} | train loss {'Reaction outcome loss': 0.16224794996688602, 'Total loss': 0.16224794996688602}
2022-12-05 21:37:11,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:11,405 INFO:     Epoch: 45
2022-12-05 21:37:12,186 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4157154040281163, 'Total loss': 0.4157154040281163} | train loss {'Reaction outcome loss': 0.15535158526579865, 'Total loss': 0.15535158526579865}
2022-12-05 21:37:12,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:12,187 INFO:     Epoch: 46
2022-12-05 21:37:12,974 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4369599278583083, 'Total loss': 0.4369599278583083} | train loss {'Reaction outcome loss': 0.15538120604135464, 'Total loss': 0.15538120604135464}
2022-12-05 21:37:12,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:12,974 INFO:     Epoch: 47
2022-12-05 21:37:13,762 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43296664554712383, 'Total loss': 0.43296664554712383} | train loss {'Reaction outcome loss': 0.1533780292012408, 'Total loss': 0.1533780292012408}
2022-12-05 21:37:13,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:13,762 INFO:     Epoch: 48
2022-12-05 21:37:14,548 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4174255524263826, 'Total loss': 0.4174255524263826} | train loss {'Reaction outcome loss': 0.1550124288215989, 'Total loss': 0.1550124288215989}
2022-12-05 21:37:14,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:14,548 INFO:     Epoch: 49
2022-12-05 21:37:15,340 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41335268422614696, 'Total loss': 0.41335268422614696} | train loss {'Reaction outcome loss': 0.15091145954659727, 'Total loss': 0.15091145954659727}
2022-12-05 21:37:15,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:15,340 INFO:     Epoch: 50
2022-12-05 21:37:16,128 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4210359847476316, 'Total loss': 0.4210359847476316} | train loss {'Reaction outcome loss': 0.15044941459248057, 'Total loss': 0.15044941459248057}
2022-12-05 21:37:16,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:16,128 INFO:     Epoch: 51
2022-12-05 21:37:16,911 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43143332385739613, 'Total loss': 0.43143332385739613} | train loss {'Reaction outcome loss': 0.144303356194258, 'Total loss': 0.144303356194258}
2022-12-05 21:37:16,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:16,911 INFO:     Epoch: 52
2022-12-05 21:37:17,699 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4313133241132248, 'Total loss': 0.4313133241132248} | train loss {'Reaction outcome loss': 0.1510830038479056, 'Total loss': 0.1510830038479056}
2022-12-05 21:37:17,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:17,700 INFO:     Epoch: 53
2022-12-05 21:37:18,485 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45052689487157865, 'Total loss': 0.45052689487157865} | train loss {'Reaction outcome loss': 0.146171842999451, 'Total loss': 0.146171842999451}
2022-12-05 21:37:18,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:18,485 INFO:     Epoch: 54
2022-12-05 21:37:19,268 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44451331537823346, 'Total loss': 0.44451331537823346} | train loss {'Reaction outcome loss': 0.14447377074021298, 'Total loss': 0.14447377074021298}
2022-12-05 21:37:19,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:19,269 INFO:     Epoch: 55
2022-12-05 21:37:20,051 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4296977107608041, 'Total loss': 0.4296977107608041} | train loss {'Reaction outcome loss': 0.14289347288488854, 'Total loss': 0.14289347288488854}
2022-12-05 21:37:20,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:20,051 INFO:     Epoch: 56
2022-12-05 21:37:20,833 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43504097381996554, 'Total loss': 0.43504097381996554} | train loss {'Reaction outcome loss': 0.1433501946129149, 'Total loss': 0.1433501946129149}
2022-12-05 21:37:20,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:20,834 INFO:     Epoch: 57
2022-12-05 21:37:21,619 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.423319356039513, 'Total loss': 0.423319356039513} | train loss {'Reaction outcome loss': 0.14410363010237695, 'Total loss': 0.14410363010237695}
2022-12-05 21:37:21,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:21,619 INFO:     Epoch: 58
2022-12-05 21:37:22,404 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42278075772662493, 'Total loss': 0.42278075772662493} | train loss {'Reaction outcome loss': 0.14170385498675656, 'Total loss': 0.14170385498675656}
2022-12-05 21:37:22,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:22,405 INFO:     Epoch: 59
2022-12-05 21:37:23,191 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.445646645371304, 'Total loss': 0.445646645371304} | train loss {'Reaction outcome loss': 0.14109582596336354, 'Total loss': 0.14109582596336354}
2022-12-05 21:37:23,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:23,191 INFO:     Epoch: 60
2022-12-05 21:37:23,975 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43167968822080033, 'Total loss': 0.43167968822080033} | train loss {'Reaction outcome loss': 0.13961311996166334, 'Total loss': 0.13961311996166334}
2022-12-05 21:37:23,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:23,975 INFO:     Epoch: 61
2022-12-05 21:37:24,757 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4301534603501475, 'Total loss': 0.4301534603501475} | train loss {'Reaction outcome loss': 0.13796970242878698, 'Total loss': 0.13796970242878698}
2022-12-05 21:37:24,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:24,758 INFO:     Epoch: 62
2022-12-05 21:37:25,540 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4200899309890215, 'Total loss': 0.4200899309890215} | train loss {'Reaction outcome loss': 0.1405484606511891, 'Total loss': 0.1405484606511891}
2022-12-05 21:37:25,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:25,540 INFO:     Epoch: 63
2022-12-05 21:37:26,328 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43101867115081743, 'Total loss': 0.43101867115081743} | train loss {'Reaction outcome loss': 0.13551648455809373, 'Total loss': 0.13551648455809373}
2022-12-05 21:37:26,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:26,328 INFO:     Epoch: 64
2022-12-05 21:37:27,112 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43759992510773416, 'Total loss': 0.43759992510773416} | train loss {'Reaction outcome loss': 0.13929646466782347, 'Total loss': 0.13929646466782347}
2022-12-05 21:37:27,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:27,112 INFO:     Epoch: 65
2022-12-05 21:37:27,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42547787829887035, 'Total loss': 0.42547787829887035} | train loss {'Reaction outcome loss': 0.13795860641498547, 'Total loss': 0.13795860641498547}
2022-12-05 21:37:27,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:27,898 INFO:     Epoch: 66
2022-12-05 21:37:28,688 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4373170684936435, 'Total loss': 0.4373170684936435} | train loss {'Reaction outcome loss': 0.13597507312985474, 'Total loss': 0.13597507312985474}
2022-12-05 21:37:28,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:28,688 INFO:     Epoch: 67
2022-12-05 21:37:29,476 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4368137349916059, 'Total loss': 0.4368137349916059} | train loss {'Reaction outcome loss': 0.13420644705183804, 'Total loss': 0.13420644705183804}
2022-12-05 21:37:29,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:29,476 INFO:     Epoch: 68
2022-12-05 21:37:30,263 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42862330238486446, 'Total loss': 0.42862330238486446} | train loss {'Reaction outcome loss': 0.13429386624646542, 'Total loss': 0.13429386624646542}
2022-12-05 21:37:30,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:30,263 INFO:     Epoch: 69
2022-12-05 21:37:31,048 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4342323993874151, 'Total loss': 0.4342323993874151} | train loss {'Reaction outcome loss': 0.1303822764378713, 'Total loss': 0.1303822764378713}
2022-12-05 21:37:31,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:31,048 INFO:     Epoch: 70
2022-12-05 21:37:31,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4368102678725886, 'Total loss': 0.4368102678725886} | train loss {'Reaction outcome loss': 0.13220600409005753, 'Total loss': 0.13220600409005753}
2022-12-05 21:37:31,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:31,830 INFO:     Epoch: 71
2022-12-05 21:37:32,621 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43217687932557836, 'Total loss': 0.43217687932557836} | train loss {'Reaction outcome loss': 0.12917244018315047, 'Total loss': 0.12917244018315047}
2022-12-05 21:37:32,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:32,621 INFO:     Epoch: 72
2022-12-05 21:37:33,405 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4160133252396833, 'Total loss': 0.4160133252396833} | train loss {'Reaction outcome loss': 0.1286914540210464, 'Total loss': 0.1286914540210464}
2022-12-05 21:37:33,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:33,406 INFO:     Epoch: 73
2022-12-05 21:37:34,190 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.425425176876922, 'Total loss': 0.425425176876922} | train loss {'Reaction outcome loss': 0.13311102774116348, 'Total loss': 0.13311102774116348}
2022-12-05 21:37:34,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:34,192 INFO:     Epoch: 74
2022-12-05 21:37:34,978 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43852996583594833, 'Total loss': 0.43852996583594833} | train loss {'Reaction outcome loss': 0.12965974204822397, 'Total loss': 0.12965974204822397}
2022-12-05 21:37:34,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:34,978 INFO:     Epoch: 75
2022-12-05 21:37:35,768 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4424540036639502, 'Total loss': 0.4424540036639502} | train loss {'Reaction outcome loss': 0.12895950387216737, 'Total loss': 0.12895950387216737}
2022-12-05 21:37:35,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:35,768 INFO:     Epoch: 76
2022-12-05 21:37:36,552 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4292971737856089, 'Total loss': 0.4292971737856089} | train loss {'Reaction outcome loss': 0.1272308924693431, 'Total loss': 0.1272308924693431}
2022-12-05 21:37:36,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:36,552 INFO:     Epoch: 77
2022-12-05 21:37:37,337 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.440909170134123, 'Total loss': 0.440909170134123} | train loss {'Reaction outcome loss': 0.129156956670531, 'Total loss': 0.129156956670531}
2022-12-05 21:37:37,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:37,338 INFO:     Epoch: 78
2022-12-05 21:37:38,119 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4417576685894367, 'Total loss': 0.4417576685894367} | train loss {'Reaction outcome loss': 0.1266139437230762, 'Total loss': 0.1266139437230762}
2022-12-05 21:37:38,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:38,120 INFO:     Epoch: 79
2022-12-05 21:37:38,904 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4306952596403832, 'Total loss': 0.4306952596403832} | train loss {'Reaction outcome loss': 0.1283561742834014, 'Total loss': 0.1283561742834014}
2022-12-05 21:37:38,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:38,905 INFO:     Epoch: 80
2022-12-05 21:37:39,693 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44813111181869064, 'Total loss': 0.44813111181869064} | train loss {'Reaction outcome loss': 0.12571653672570332, 'Total loss': 0.12571653672570332}
2022-12-05 21:37:39,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:39,693 INFO:     Epoch: 81
2022-12-05 21:37:40,476 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44872621498828713, 'Total loss': 0.44872621498828713} | train loss {'Reaction outcome loss': 0.12517727863379433, 'Total loss': 0.12517727863379433}
2022-12-05 21:37:40,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:40,477 INFO:     Epoch: 82
2022-12-05 21:37:41,258 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4519518953423167, 'Total loss': 0.4519518953423167} | train loss {'Reaction outcome loss': 0.12469308727543008, 'Total loss': 0.12469308727543008}
2022-12-05 21:37:41,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:41,258 INFO:     Epoch: 83
2022-12-05 21:37:42,041 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4368880567855613, 'Total loss': 0.4368880567855613} | train loss {'Reaction outcome loss': 0.12602004729837302, 'Total loss': 0.12602004729837302}
2022-12-05 21:37:42,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:42,041 INFO:     Epoch: 84
2022-12-05 21:37:42,826 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4483041427163191, 'Total loss': 0.4483041427163191} | train loss {'Reaction outcome loss': 0.12546505162217578, 'Total loss': 0.12546505162217578}
2022-12-05 21:37:42,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:42,827 INFO:     Epoch: 85
2022-12-05 21:37:43,610 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44911132354375927, 'Total loss': 0.44911132354375927} | train loss {'Reaction outcome loss': 0.12485652186785687, 'Total loss': 0.12485652186785687}
2022-12-05 21:37:43,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:43,610 INFO:     Epoch: 86
2022-12-05 21:37:44,395 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4398984500142031, 'Total loss': 0.4398984500142031} | train loss {'Reaction outcome loss': 0.1252459172907545, 'Total loss': 0.1252459172907545}
2022-12-05 21:37:44,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:44,395 INFO:     Epoch: 87
2022-12-05 21:37:45,182 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4436179014832474, 'Total loss': 0.4436179014832474} | train loss {'Reaction outcome loss': 0.1235215317946477, 'Total loss': 0.1235215317946477}
2022-12-05 21:37:45,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:45,182 INFO:     Epoch: 88
2022-12-05 21:37:45,964 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44960114602432694, 'Total loss': 0.44960114602432694} | train loss {'Reaction outcome loss': 0.12312112422278304, 'Total loss': 0.12312112422278304}
2022-12-05 21:37:45,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:45,965 INFO:     Epoch: 89
2022-12-05 21:37:46,752 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4406277277441912, 'Total loss': 0.4406277277441912} | train loss {'Reaction outcome loss': 0.12116292254144295, 'Total loss': 0.12116292254144295}
2022-12-05 21:37:46,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:46,753 INFO:     Epoch: 90
2022-12-05 21:37:47,532 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44501621362774874, 'Total loss': 0.44501621362774874} | train loss {'Reaction outcome loss': 0.12151542400987056, 'Total loss': 0.12151542400987056}
2022-12-05 21:37:47,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:47,532 INFO:     Epoch: 91
2022-12-05 21:37:48,316 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46322221464888996, 'Total loss': 0.46322221464888996} | train loss {'Reaction outcome loss': 0.12282383462154596, 'Total loss': 0.12282383462154596}
2022-12-05 21:37:48,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:48,317 INFO:     Epoch: 92
2022-12-05 21:37:49,100 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44307231175345047, 'Total loss': 0.44307231175345047} | train loss {'Reaction outcome loss': 0.12207793153165916, 'Total loss': 0.12207793153165916}
2022-12-05 21:37:49,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:49,100 INFO:     Epoch: 93
2022-12-05 21:37:49,880 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4376823370193326, 'Total loss': 0.4376823370193326} | train loss {'Reaction outcome loss': 0.11939236807606382, 'Total loss': 0.11939236807606382}
2022-12-05 21:37:49,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:49,880 INFO:     Epoch: 94
2022-12-05 21:37:50,661 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4385035032796305, 'Total loss': 0.4385035032796305} | train loss {'Reaction outcome loss': 0.1205037662293762, 'Total loss': 0.1205037662293762}
2022-12-05 21:37:50,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:50,661 INFO:     Epoch: 95
2022-12-05 21:37:51,448 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4495640060929365, 'Total loss': 0.4495640060929365} | train loss {'Reaction outcome loss': 0.12232123325639939, 'Total loss': 0.12232123325639939}
2022-12-05 21:37:51,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:51,448 INFO:     Epoch: 96
2022-12-05 21:37:52,231 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44276086189026054, 'Total loss': 0.44276086189026054} | train loss {'Reaction outcome loss': 0.12134886542182477, 'Total loss': 0.12134886542182477}
2022-12-05 21:37:52,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:52,231 INFO:     Epoch: 97
2022-12-05 21:37:53,012 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46249791130770085, 'Total loss': 0.46249791130770085} | train loss {'Reaction outcome loss': 0.11810937052264382, 'Total loss': 0.11810937052264382}
2022-12-05 21:37:53,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:53,013 INFO:     Epoch: 98
2022-12-05 21:37:53,799 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44399776534978735, 'Total loss': 0.44399776534978735} | train loss {'Reaction outcome loss': 0.12096893343860741, 'Total loss': 0.12096893343860741}
2022-12-05 21:37:53,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:53,800 INFO:     Epoch: 99
2022-12-05 21:37:54,579 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4455648497786633, 'Total loss': 0.4455648497786633} | train loss {'Reaction outcome loss': 0.11712715669046538, 'Total loss': 0.11712715669046538}
2022-12-05 21:37:54,579 INFO:     Best model found after epoch 34 of 100.
2022-12-05 21:37:54,580 INFO:   Done with stage: TRAINING
2022-12-05 21:37:54,580 INFO:   Starting stage: EVALUATION
2022-12-05 21:37:54,718 INFO:   Done with stage: EVALUATION
2022-12-05 21:37:54,718 INFO:   Leaving out SEQ value Fold_3
2022-12-05 21:37:54,730 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 21:37:54,731 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:37:55,364 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:37:55,364 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:37:55,432 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:37:55,432 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:37:55,432 INFO:     No hyperparam tuning for this model
2022-12-05 21:37:55,432 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:37:55,432 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:37:55,433 INFO:     None feature selector for col prot
2022-12-05 21:37:55,433 INFO:     None feature selector for col prot
2022-12-05 21:37:55,433 INFO:     None feature selector for col prot
2022-12-05 21:37:55,434 INFO:     None feature selector for col chem
2022-12-05 21:37:55,434 INFO:     None feature selector for col chem
2022-12-05 21:37:55,434 INFO:     None feature selector for col chem
2022-12-05 21:37:55,434 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:37:55,434 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:37:55,436 INFO:     Number of params in model 215821
2022-12-05 21:37:55,439 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:37:55,439 INFO:   Starting stage: TRAINING
2022-12-05 21:37:55,497 INFO:     Val loss before train {'Reaction outcome loss': 1.004180400870567, 'Total loss': 1.004180400870567}
2022-12-05 21:37:55,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:55,498 INFO:     Epoch: 0
2022-12-05 21:37:56,277 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5679788873639218, 'Total loss': 0.5679788873639218} | train loss {'Reaction outcome loss': 0.7916438012947271, 'Total loss': 0.7916438012947271}
2022-12-05 21:37:56,277 INFO:     Found new best model at epoch 0
2022-12-05 21:37:56,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:56,278 INFO:     Epoch: 1
2022-12-05 21:37:57,057 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.49160436627476717, 'Total loss': 0.49160436627476717} | train loss {'Reaction outcome loss': 0.5241975738310519, 'Total loss': 0.5241975738310519}
2022-12-05 21:37:57,057 INFO:     Found new best model at epoch 1
2022-12-05 21:37:57,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:57,058 INFO:     Epoch: 2
2022-12-05 21:37:57,838 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.455406580900037, 'Total loss': 0.455406580900037} | train loss {'Reaction outcome loss': 0.45601565743424766, 'Total loss': 0.45601565743424766}
2022-12-05 21:37:57,838 INFO:     Found new best model at epoch 2
2022-12-05 21:37:57,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:57,839 INFO:     Epoch: 3
2022-12-05 21:37:58,617 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4470291279776152, 'Total loss': 0.4470291279776152} | train loss {'Reaction outcome loss': 0.41673320850717677, 'Total loss': 0.41673320850717677}
2022-12-05 21:37:58,617 INFO:     Found new best model at epoch 3
2022-12-05 21:37:58,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:58,618 INFO:     Epoch: 4
2022-12-05 21:37:59,398 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4354278646236242, 'Total loss': 0.4354278646236242} | train loss {'Reaction outcome loss': 0.3857484352564125, 'Total loss': 0.3857484352564125}
2022-12-05 21:37:59,398 INFO:     Found new best model at epoch 4
2022-12-05 21:37:59,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:37:59,399 INFO:     Epoch: 5
2022-12-05 21:38:00,177 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.40808943607086356, 'Total loss': 0.40808943607086356} | train loss {'Reaction outcome loss': 0.3656851425460337, 'Total loss': 0.3656851425460337}
2022-12-05 21:38:00,177 INFO:     Found new best model at epoch 5
2022-12-05 21:38:00,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:00,178 INFO:     Epoch: 6
2022-12-05 21:38:00,960 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.39654062861619993, 'Total loss': 0.39654062861619993} | train loss {'Reaction outcome loss': 0.34294744052084875, 'Total loss': 0.34294744052084875}
2022-12-05 21:38:00,960 INFO:     Found new best model at epoch 6
2022-12-05 21:38:00,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:00,961 INFO:     Epoch: 7
2022-12-05 21:38:01,743 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4202778516120689, 'Total loss': 0.4202778516120689} | train loss {'Reaction outcome loss': 0.32875676534364745, 'Total loss': 0.32875676534364745}
2022-12-05 21:38:01,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:01,743 INFO:     Epoch: 8
2022-12-05 21:38:02,522 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3905358130848685, 'Total loss': 0.3905358130848685} | train loss {'Reaction outcome loss': 0.3109912989745415, 'Total loss': 0.3109912989745415}
2022-12-05 21:38:02,522 INFO:     Found new best model at epoch 8
2022-12-05 21:38:02,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:02,523 INFO:     Epoch: 9
2022-12-05 21:38:03,303 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3856243598599767, 'Total loss': 0.3856243598599767} | train loss {'Reaction outcome loss': 0.29684611964863516, 'Total loss': 0.29684611964863516}
2022-12-05 21:38:03,303 INFO:     Found new best model at epoch 9
2022-12-05 21:38:03,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:03,304 INFO:     Epoch: 10
2022-12-05 21:38:04,090 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3922202722277752, 'Total loss': 0.3922202722277752} | train loss {'Reaction outcome loss': 0.2813386545964965, 'Total loss': 0.2813386545964965}
2022-12-05 21:38:04,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:04,090 INFO:     Epoch: 11
2022-12-05 21:38:04,870 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3942188495813414, 'Total loss': 0.3942188495813414} | train loss {'Reaction outcome loss': 0.2711245102554928, 'Total loss': 0.2711245102554928}
2022-12-05 21:38:04,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:04,870 INFO:     Epoch: 12
2022-12-05 21:38:05,650 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3997532891672711, 'Total loss': 0.3997532891672711} | train loss {'Reaction outcome loss': 0.2607285737255473, 'Total loss': 0.2607285737255473}
2022-12-05 21:38:05,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:05,650 INFO:     Epoch: 13
2022-12-05 21:38:06,435 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3966175863562628, 'Total loss': 0.3966175863562628} | train loss {'Reaction outcome loss': 0.24941818011395725, 'Total loss': 0.24941818011395725}
2022-12-05 21:38:06,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:06,436 INFO:     Epoch: 14
2022-12-05 21:38:07,223 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39418185606252315, 'Total loss': 0.39418185606252315} | train loss {'Reaction outcome loss': 0.2461227816318779, 'Total loss': 0.2461227816318779}
2022-12-05 21:38:07,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:07,224 INFO:     Epoch: 15
2022-12-05 21:38:08,008 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.38538807907769845, 'Total loss': 0.38538807907769845} | train loss {'Reaction outcome loss': 0.23503365099368762, 'Total loss': 0.23503365099368762}
2022-12-05 21:38:08,008 INFO:     Found new best model at epoch 15
2022-12-05 21:38:08,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:08,009 INFO:     Epoch: 16
2022-12-05 21:38:08,793 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3964519272016924, 'Total loss': 0.3964519272016924} | train loss {'Reaction outcome loss': 0.228721463370593, 'Total loss': 0.228721463370593}
2022-12-05 21:38:08,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:08,794 INFO:     Epoch: 17
2022-12-05 21:38:09,573 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38325124875057576, 'Total loss': 0.38325124875057576} | train loss {'Reaction outcome loss': 0.21734566149520285, 'Total loss': 0.21734566149520285}
2022-12-05 21:38:09,574 INFO:     Found new best model at epoch 17
2022-12-05 21:38:09,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:09,574 INFO:     Epoch: 18
2022-12-05 21:38:10,356 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.39764228497826776, 'Total loss': 0.39764228497826776} | train loss {'Reaction outcome loss': 0.21332073975890997, 'Total loss': 0.21332073975890997}
2022-12-05 21:38:10,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:10,356 INFO:     Epoch: 19
2022-12-05 21:38:11,139 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40480478870314224, 'Total loss': 0.40480478870314224} | train loss {'Reaction outcome loss': 0.20869824290275574, 'Total loss': 0.20869824290275574}
2022-12-05 21:38:11,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:11,140 INFO:     Epoch: 20
2022-12-05 21:38:11,922 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3936526366444521, 'Total loss': 0.3936526366444521} | train loss {'Reaction outcome loss': 0.20087317216359538, 'Total loss': 0.20087317216359538}
2022-12-05 21:38:11,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:11,922 INFO:     Epoch: 21
2022-12-05 21:38:12,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40651241897843604, 'Total loss': 0.40651241897843604} | train loss {'Reaction outcome loss': 0.19699200141577072, 'Total loss': 0.19699200141577072}
2022-12-05 21:38:12,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:12,706 INFO:     Epoch: 22
2022-12-05 21:38:13,492 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4062039644219155, 'Total loss': 0.4062039644219155} | train loss {'Reaction outcome loss': 0.19098948972460664, 'Total loss': 0.19098948972460664}
2022-12-05 21:38:13,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:13,493 INFO:     Epoch: 23
2022-12-05 21:38:14,276 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40882922778295916, 'Total loss': 0.40882922778295916} | train loss {'Reaction outcome loss': 0.1888161502441261, 'Total loss': 0.1888161502441261}
2022-12-05 21:38:14,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:14,276 INFO:     Epoch: 24
2022-12-05 21:38:15,059 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41728469209615576, 'Total loss': 0.41728469209615576} | train loss {'Reaction outcome loss': 0.18873947374369382, 'Total loss': 0.18873947374369382}
2022-12-05 21:38:15,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:15,060 INFO:     Epoch: 25
2022-12-05 21:38:15,842 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4126544833876366, 'Total loss': 0.4126544833876366} | train loss {'Reaction outcome loss': 0.18010098171332245, 'Total loss': 0.18010098171332245}
2022-12-05 21:38:15,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:15,842 INFO:     Epoch: 26
2022-12-05 21:38:16,623 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40318337671978527, 'Total loss': 0.40318337671978527} | train loss {'Reaction outcome loss': 0.17461819039971985, 'Total loss': 0.17461819039971985}
2022-12-05 21:38:16,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:16,623 INFO:     Epoch: 27
2022-12-05 21:38:17,407 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3979763225760571, 'Total loss': 0.3979763225760571} | train loss {'Reaction outcome loss': 0.1756704265152108, 'Total loss': 0.1756704265152108}
2022-12-05 21:38:17,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:17,407 INFO:     Epoch: 28
2022-12-05 21:38:18,192 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4161450377730436, 'Total loss': 0.4161450377730436} | train loss {'Reaction outcome loss': 0.17012208159016484, 'Total loss': 0.17012208159016484}
2022-12-05 21:38:18,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:18,192 INFO:     Epoch: 29
2022-12-05 21:38:18,974 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4127131274273229, 'Total loss': 0.4127131274273229} | train loss {'Reaction outcome loss': 0.1682604876473362, 'Total loss': 0.1682604876473362}
2022-12-05 21:38:18,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:18,974 INFO:     Epoch: 30
2022-12-05 21:38:19,755 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.423061448474263, 'Total loss': 0.423061448474263} | train loss {'Reaction outcome loss': 0.16429997512250524, 'Total loss': 0.16429997512250524}
2022-12-05 21:38:19,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:19,755 INFO:     Epoch: 31
2022-12-05 21:38:20,537 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41808972057215005, 'Total loss': 0.41808972057215005} | train loss {'Reaction outcome loss': 0.16195991967992526, 'Total loss': 0.16195991967992526}
2022-12-05 21:38:20,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:20,537 INFO:     Epoch: 32
2022-12-05 21:38:21,323 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.414946356831595, 'Total loss': 0.414946356831595} | train loss {'Reaction outcome loss': 0.15788605431317057, 'Total loss': 0.15788605431317057}
2022-12-05 21:38:21,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:21,323 INFO:     Epoch: 33
2022-12-05 21:38:22,107 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4199060763037482, 'Total loss': 0.4199060763037482} | train loss {'Reaction outcome loss': 0.1549151463763704, 'Total loss': 0.1549151463763704}
2022-12-05 21:38:22,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:22,107 INFO:     Epoch: 34
2022-12-05 21:38:22,897 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4293472146572069, 'Total loss': 0.4293472146572069} | train loss {'Reaction outcome loss': 0.15654143400551607, 'Total loss': 0.15654143400551607}
2022-12-05 21:38:22,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:22,898 INFO:     Epoch: 35
2022-12-05 21:38:23,684 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4166022643100384, 'Total loss': 0.4166022643100384} | train loss {'Reaction outcome loss': 0.15428765459990304, 'Total loss': 0.15428765459990304}
2022-12-05 21:38:23,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:23,684 INFO:     Epoch: 36
2022-12-05 21:38:24,470 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4109207364015801, 'Total loss': 0.4109207364015801} | train loss {'Reaction outcome loss': 0.15353861487175458, 'Total loss': 0.15353861487175458}
2022-12-05 21:38:24,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:24,470 INFO:     Epoch: 37
2022-12-05 21:38:25,255 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4101231643973395, 'Total loss': 0.4101231643973395} | train loss {'Reaction outcome loss': 0.14655992284861735, 'Total loss': 0.14655992284861735}
2022-12-05 21:38:25,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:25,256 INFO:     Epoch: 38
2022-12-05 21:38:26,045 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41468310875948083, 'Total loss': 0.41468310875948083} | train loss {'Reaction outcome loss': 0.1449970724751, 'Total loss': 0.1449970724751}
2022-12-05 21:38:26,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:26,045 INFO:     Epoch: 39
2022-12-05 21:38:26,832 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4191139825554781, 'Total loss': 0.4191139825554781} | train loss {'Reaction outcome loss': 0.1450832101665897, 'Total loss': 0.1450832101665897}
2022-12-05 21:38:26,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:26,832 INFO:     Epoch: 40
2022-12-05 21:38:27,615 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42517462771299275, 'Total loss': 0.42517462771299275} | train loss {'Reaction outcome loss': 0.14009524204235507, 'Total loss': 0.14009524204235507}
2022-12-05 21:38:27,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:27,615 INFO:     Epoch: 41
2022-12-05 21:38:28,397 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4177535897077516, 'Total loss': 0.4177535897077516} | train loss {'Reaction outcome loss': 0.14267055273684578, 'Total loss': 0.14267055273684578}
2022-12-05 21:38:28,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:28,398 INFO:     Epoch: 42
2022-12-05 21:38:29,183 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41982555146827255, 'Total loss': 0.41982555146827255} | train loss {'Reaction outcome loss': 0.13661680278586752, 'Total loss': 0.13661680278586752}
2022-12-05 21:38:29,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:29,183 INFO:     Epoch: 43
2022-12-05 21:38:29,967 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4312014922846195, 'Total loss': 0.4312014922846195} | train loss {'Reaction outcome loss': 0.13840227876885683, 'Total loss': 0.13840227876885683}
2022-12-05 21:38:29,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:29,967 INFO:     Epoch: 44
2022-12-05 21:38:30,750 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.420704168982284, 'Total loss': 0.420704168982284} | train loss {'Reaction outcome loss': 0.13753949645370123, 'Total loss': 0.13753949645370123}
2022-12-05 21:38:30,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:30,750 INFO:     Epoch: 45
2022-12-05 21:38:31,531 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42433772357397304, 'Total loss': 0.42433772357397304} | train loss {'Reaction outcome loss': 0.1369468669249933, 'Total loss': 0.1369468669249933}
2022-12-05 21:38:31,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:31,531 INFO:     Epoch: 46
2022-12-05 21:38:32,311 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42927019228768903, 'Total loss': 0.42927019228768903} | train loss {'Reaction outcome loss': 0.13480729279740725, 'Total loss': 0.13480729279740725}
2022-12-05 21:38:32,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:32,311 INFO:     Epoch: 47
2022-12-05 21:38:33,095 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4330035163912662, 'Total loss': 0.4330035163912662} | train loss {'Reaction outcome loss': 0.1342464565824518, 'Total loss': 0.1342464565824518}
2022-12-05 21:38:33,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:33,096 INFO:     Epoch: 48
2022-12-05 21:38:33,876 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43220171418993975, 'Total loss': 0.43220171418993975} | train loss {'Reaction outcome loss': 0.1354285161252375, 'Total loss': 0.1354285161252375}
2022-12-05 21:38:33,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:33,877 INFO:     Epoch: 49
2022-12-05 21:38:34,658 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4296442828206129, 'Total loss': 0.4296442828206129} | train loss {'Reaction outcome loss': 0.13049002704613002, 'Total loss': 0.13049002704613002}
2022-12-05 21:38:34,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:34,658 INFO:     Epoch: 50
2022-12-05 21:38:35,440 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43284833396590033, 'Total loss': 0.43284833396590033} | train loss {'Reaction outcome loss': 0.13072406554234373, 'Total loss': 0.13072406554234373}
2022-12-05 21:38:35,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:35,440 INFO:     Epoch: 51
2022-12-05 21:38:36,225 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43654540874237235, 'Total loss': 0.43654540874237235} | train loss {'Reaction outcome loss': 0.12992917883512659, 'Total loss': 0.12992917883512659}
2022-12-05 21:38:36,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:36,225 INFO:     Epoch: 52
2022-12-05 21:38:37,008 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42999527343483857, 'Total loss': 0.42999527343483857} | train loss {'Reaction outcome loss': 0.12626224893448038, 'Total loss': 0.12626224893448038}
2022-12-05 21:38:37,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:37,008 INFO:     Epoch: 53
2022-12-05 21:38:37,792 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43321849890919617, 'Total loss': 0.43321849890919617} | train loss {'Reaction outcome loss': 0.12728527100917733, 'Total loss': 0.12728527100917733}
2022-12-05 21:38:37,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:37,793 INFO:     Epoch: 54
2022-12-05 21:38:38,575 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4433946640685547, 'Total loss': 0.4433946640685547} | train loss {'Reaction outcome loss': 0.12693017551775088, 'Total loss': 0.12693017551775088}
2022-12-05 21:38:38,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:38,575 INFO:     Epoch: 55
2022-12-05 21:38:39,360 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4330742293319037, 'Total loss': 0.4330742293319037} | train loss {'Reaction outcome loss': 0.1270688208272305, 'Total loss': 0.1270688208272305}
2022-12-05 21:38:39,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:39,360 INFO:     Epoch: 56
2022-12-05 21:38:40,143 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.428008665525636, 'Total loss': 0.428008665525636} | train loss {'Reaction outcome loss': 0.12396274827068111, 'Total loss': 0.12396274827068111}
2022-12-05 21:38:40,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:40,143 INFO:     Epoch: 57
2022-12-05 21:38:40,929 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4402865762280863, 'Total loss': 0.4402865762280863} | train loss {'Reaction outcome loss': 0.12506647347453445, 'Total loss': 0.12506647347453445}
2022-12-05 21:38:40,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:40,929 INFO:     Epoch: 58
2022-12-05 21:38:41,713 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43529058836920315, 'Total loss': 0.43529058836920315} | train loss {'Reaction outcome loss': 0.12191910277898788, 'Total loss': 0.12191910277898788}
2022-12-05 21:38:41,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:41,714 INFO:     Epoch: 59
2022-12-05 21:38:42,499 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44176981580811875, 'Total loss': 0.44176981580811875} | train loss {'Reaction outcome loss': 0.12180403510392203, 'Total loss': 0.12180403510392203}
2022-12-05 21:38:42,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:42,499 INFO:     Epoch: 60
2022-12-05 21:38:43,282 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4376606934292372, 'Total loss': 0.4376606934292372} | train loss {'Reaction outcome loss': 0.12038742131917687, 'Total loss': 0.12038742131917687}
2022-12-05 21:38:43,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:43,283 INFO:     Epoch: 61
2022-12-05 21:38:44,067 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43777930701887885, 'Total loss': 0.43777930701887885} | train loss {'Reaction outcome loss': 0.11912664346044323, 'Total loss': 0.11912664346044323}
2022-12-05 21:38:44,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:44,068 INFO:     Epoch: 62
2022-12-05 21:38:44,856 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4341383626641229, 'Total loss': 0.4341383626641229} | train loss {'Reaction outcome loss': 0.12039370286381906, 'Total loss': 0.12039370286381906}
2022-12-05 21:38:44,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:44,856 INFO:     Epoch: 63
2022-12-05 21:38:45,641 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4390192738799162, 'Total loss': 0.4390192738799162} | train loss {'Reaction outcome loss': 0.11677055197304169, 'Total loss': 0.11677055197304169}
2022-12-05 21:38:45,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:45,641 INFO:     Epoch: 64
2022-12-05 21:38:46,426 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4424950736899709, 'Total loss': 0.4424950736899709} | train loss {'Reaction outcome loss': 0.119058345873752, 'Total loss': 0.119058345873752}
2022-12-05 21:38:46,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:46,426 INFO:     Epoch: 65
2022-12-05 21:38:47,214 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42994102731693623, 'Total loss': 0.42994102731693623} | train loss {'Reaction outcome loss': 0.12235882962620798, 'Total loss': 0.12235882962620798}
2022-12-05 21:38:47,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:47,214 INFO:     Epoch: 66
2022-12-05 21:38:47,996 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4334088227776594, 'Total loss': 0.4334088227776594} | train loss {'Reaction outcome loss': 0.11766382472382651, 'Total loss': 0.11766382472382651}
2022-12-05 21:38:47,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:47,996 INFO:     Epoch: 67
2022-12-05 21:38:48,777 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42892127085563747, 'Total loss': 0.42892127085563747} | train loss {'Reaction outcome loss': 0.11823017291586708, 'Total loss': 0.11823017291586708}
2022-12-05 21:38:48,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:48,778 INFO:     Epoch: 68
2022-12-05 21:38:49,563 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45401036981926407, 'Total loss': 0.45401036981926407} | train loss {'Reaction outcome loss': 0.11961416870646883, 'Total loss': 0.11961416870646883}
2022-12-05 21:38:49,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:49,563 INFO:     Epoch: 69
2022-12-05 21:38:50,346 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4280847522408463, 'Total loss': 0.4280847522408463} | train loss {'Reaction outcome loss': 0.11380033637684436, 'Total loss': 0.11380033637684436}
2022-12-05 21:38:50,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:50,347 INFO:     Epoch: 70
2022-12-05 21:38:51,134 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42420503731037296, 'Total loss': 0.42420503731037296} | train loss {'Reaction outcome loss': 0.1144778279476481, 'Total loss': 0.1144778279476481}
2022-12-05 21:38:51,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:51,135 INFO:     Epoch: 71
2022-12-05 21:38:51,923 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4538769846738771, 'Total loss': 0.4538769846738771} | train loss {'Reaction outcome loss': 0.11582265049985652, 'Total loss': 0.11582265049985652}
2022-12-05 21:38:51,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:51,924 INFO:     Epoch: 72
2022-12-05 21:38:52,712 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4379547830930976, 'Total loss': 0.4379547830930976} | train loss {'Reaction outcome loss': 0.11413472447804954, 'Total loss': 0.11413472447804954}
2022-12-05 21:38:52,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:52,712 INFO:     Epoch: 73
2022-12-05 21:38:53,502 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4393331023842789, 'Total loss': 0.4393331023842789} | train loss {'Reaction outcome loss': 0.1159530628372919, 'Total loss': 0.1159530628372919}
2022-12-05 21:38:53,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:53,502 INFO:     Epoch: 74
2022-12-05 21:38:54,287 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43492763298888537, 'Total loss': 0.43492763298888537} | train loss {'Reaction outcome loss': 0.11695676341790844, 'Total loss': 0.11695676341790844}
2022-12-05 21:38:54,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:54,288 INFO:     Epoch: 75
2022-12-05 21:38:55,070 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42392758124096447, 'Total loss': 0.42392758124096447} | train loss {'Reaction outcome loss': 0.11502606263805809, 'Total loss': 0.11502606263805809}
2022-12-05 21:38:55,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:55,070 INFO:     Epoch: 76
2022-12-05 21:38:55,856 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4315726605438909, 'Total loss': 0.4315726605438909} | train loss {'Reaction outcome loss': 0.11187148609279114, 'Total loss': 0.11187148609279114}
2022-12-05 21:38:55,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:55,856 INFO:     Epoch: 77
2022-12-05 21:38:56,647 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4212317480597385, 'Total loss': 0.4212317480597385} | train loss {'Reaction outcome loss': 0.11431933190183016, 'Total loss': 0.11431933190183016}
2022-12-05 21:38:56,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:56,648 INFO:     Epoch: 78
2022-12-05 21:38:57,430 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.423322452015655, 'Total loss': 0.423322452015655} | train loss {'Reaction outcome loss': 0.11113723089397261, 'Total loss': 0.11113723089397261}
2022-12-05 21:38:57,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:57,431 INFO:     Epoch: 79
2022-12-05 21:38:58,213 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4371604595419972, 'Total loss': 0.4371604595419972} | train loss {'Reaction outcome loss': 0.11232089890941303, 'Total loss': 0.11232089890941303}
2022-12-05 21:38:58,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:58,213 INFO:     Epoch: 80
2022-12-05 21:38:58,998 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4153377595682477, 'Total loss': 0.4153377595682477} | train loss {'Reaction outcome loss': 0.11553188782844524, 'Total loss': 0.11553188782844524}
2022-12-05 21:38:58,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:58,999 INFO:     Epoch: 81
2022-12-05 21:38:59,782 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4345640335665193, 'Total loss': 0.4345640335665193} | train loss {'Reaction outcome loss': 0.11065221308450762, 'Total loss': 0.11065221308450762}
2022-12-05 21:38:59,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:38:59,782 INFO:     Epoch: 82
2022-12-05 21:39:00,566 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44633460807245834, 'Total loss': 0.44633460807245834} | train loss {'Reaction outcome loss': 0.11134231223920245, 'Total loss': 0.11134231223920245}
2022-12-05 21:39:00,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:00,566 INFO:     Epoch: 83
2022-12-05 21:39:01,349 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43142786067585615, 'Total loss': 0.43142786067585615} | train loss {'Reaction outcome loss': 0.11168164314525854, 'Total loss': 0.11168164314525854}
2022-12-05 21:39:01,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:01,350 INFO:     Epoch: 84
2022-12-05 21:39:02,134 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4530085602471995, 'Total loss': 0.4530085602471995} | train loss {'Reaction outcome loss': 0.11206533186666576, 'Total loss': 0.11206533186666576}
2022-12-05 21:39:02,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:02,134 INFO:     Epoch: 85
2022-12-05 21:39:02,916 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4478366894777431, 'Total loss': 0.4478366894777431} | train loss {'Reaction outcome loss': 0.11090568792258884, 'Total loss': 0.11090568792258884}
2022-12-05 21:39:02,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:02,916 INFO:     Epoch: 86
2022-12-05 21:39:03,702 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4327672948670942, 'Total loss': 0.4327672948670942} | train loss {'Reaction outcome loss': 0.11167478435308723, 'Total loss': 0.11167478435308723}
2022-12-05 21:39:03,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:03,702 INFO:     Epoch: 87
2022-12-05 21:39:04,486 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43529320317645404, 'Total loss': 0.43529320317645404} | train loss {'Reaction outcome loss': 0.10781350156959192, 'Total loss': 0.10781350156959192}
2022-12-05 21:39:04,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:04,486 INFO:     Epoch: 88
2022-12-05 21:39:05,268 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43387727248807284, 'Total loss': 0.43387727248807284} | train loss {'Reaction outcome loss': 0.1086135753257959, 'Total loss': 0.1086135753257959}
2022-12-05 21:39:05,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:05,268 INFO:     Epoch: 89
2022-12-05 21:39:06,053 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42997384989677473, 'Total loss': 0.42997384989677473} | train loss {'Reaction outcome loss': 0.10707180178245154, 'Total loss': 0.10707180178245154}
2022-12-05 21:39:06,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:06,053 INFO:     Epoch: 90
2022-12-05 21:39:06,838 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4383487015269523, 'Total loss': 0.4383487015269523} | train loss {'Reaction outcome loss': 0.1080841285372038, 'Total loss': 0.1080841285372038}
2022-12-05 21:39:06,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:06,838 INFO:     Epoch: 91
2022-12-05 21:39:07,625 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4339291037515152, 'Total loss': 0.4339291037515152} | train loss {'Reaction outcome loss': 0.11041021153403623, 'Total loss': 0.11041021153403623}
2022-12-05 21:39:07,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:07,625 INFO:     Epoch: 92
2022-12-05 21:39:08,414 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44463550316732986, 'Total loss': 0.44463550316732986} | train loss {'Reaction outcome loss': 0.10678224005916542, 'Total loss': 0.10678224005916542}
2022-12-05 21:39:08,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:08,415 INFO:     Epoch: 93
2022-12-05 21:39:09,202 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.449465477535891, 'Total loss': 0.449465477535891} | train loss {'Reaction outcome loss': 0.10617120390750254, 'Total loss': 0.10617120390750254}
2022-12-05 21:39:09,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:09,202 INFO:     Epoch: 94
2022-12-05 21:39:09,986 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4440342638381692, 'Total loss': 0.4440342638381692} | train loss {'Reaction outcome loss': 0.10758090798777563, 'Total loss': 0.10758090798777563}
2022-12-05 21:39:09,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:09,986 INFO:     Epoch: 95
2022-12-05 21:39:10,772 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4365742920443069, 'Total loss': 0.4365742920443069} | train loss {'Reaction outcome loss': 0.1051763654073294, 'Total loss': 0.1051763654073294}
2022-12-05 21:39:10,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:10,773 INFO:     Epoch: 96
2022-12-05 21:39:11,567 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.456772647624792, 'Total loss': 0.456772647624792} | train loss {'Reaction outcome loss': 0.10433377773182873, 'Total loss': 0.10433377773182873}
2022-12-05 21:39:11,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:11,568 INFO:     Epoch: 97
2022-12-05 21:39:12,353 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43164590243683304, 'Total loss': 0.43164590243683304} | train loss {'Reaction outcome loss': 0.10680471925321706, 'Total loss': 0.10680471925321706}
2022-12-05 21:39:12,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:12,354 INFO:     Epoch: 98
2022-12-05 21:39:13,142 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4385084293262903, 'Total loss': 0.4385084293262903} | train loss {'Reaction outcome loss': 0.1053441730021296, 'Total loss': 0.1053441730021296}
2022-12-05 21:39:13,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:13,143 INFO:     Epoch: 99
2022-12-05 21:39:13,935 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43079590606828067, 'Total loss': 0.43079590606828067} | train loss {'Reaction outcome loss': 0.105492128059268, 'Total loss': 0.105492128059268}
2022-12-05 21:39:13,935 INFO:     Best model found after epoch 18 of 100.
2022-12-05 21:39:13,935 INFO:   Done with stage: TRAINING
2022-12-05 21:39:13,935 INFO:   Starting stage: EVALUATION
2022-12-05 21:39:14,078 INFO:   Done with stage: EVALUATION
2022-12-05 21:39:14,078 INFO:   Leaving out SEQ value Fold_4
2022-12-05 21:39:14,091 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:39:14,091 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:39:14,735 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:39:14,736 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:39:14,805 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:39:14,805 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:39:14,805 INFO:     No hyperparam tuning for this model
2022-12-05 21:39:14,805 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:39:14,805 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:39:14,806 INFO:     None feature selector for col prot
2022-12-05 21:39:14,806 INFO:     None feature selector for col prot
2022-12-05 21:39:14,806 INFO:     None feature selector for col prot
2022-12-05 21:39:14,806 INFO:     None feature selector for col chem
2022-12-05 21:39:14,807 INFO:     None feature selector for col chem
2022-12-05 21:39:14,807 INFO:     None feature selector for col chem
2022-12-05 21:39:14,807 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:39:14,807 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:39:14,808 INFO:     Number of params in model 215821
2022-12-05 21:39:14,811 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:39:14,811 INFO:   Starting stage: TRAINING
2022-12-05 21:39:14,873 INFO:     Val loss before train {'Reaction outcome loss': 1.0110800767486745, 'Total loss': 1.0110800767486745}
2022-12-05 21:39:14,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:14,873 INFO:     Epoch: 0
2022-12-05 21:39:15,672 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5810563530434262, 'Total loss': 0.5810563530434262} | train loss {'Reaction outcome loss': 0.7929768680560927, 'Total loss': 0.7929768680560927}
2022-12-05 21:39:15,672 INFO:     Found new best model at epoch 0
2022-12-05 21:39:15,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:15,673 INFO:     Epoch: 1
2022-12-05 21:39:16,476 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4894212599505078, 'Total loss': 0.4894212599505078} | train loss {'Reaction outcome loss': 0.5481138016410202, 'Total loss': 0.5481138016410202}
2022-12-05 21:39:16,477 INFO:     Found new best model at epoch 1
2022-12-05 21:39:16,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:16,478 INFO:     Epoch: 2
2022-12-05 21:39:17,277 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45798961039293895, 'Total loss': 0.45798961039293895} | train loss {'Reaction outcome loss': 0.4783681698656275, 'Total loss': 0.4783681698656275}
2022-12-05 21:39:17,277 INFO:     Found new best model at epoch 2
2022-12-05 21:39:17,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:17,278 INFO:     Epoch: 3
2022-12-05 21:39:18,078 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4437349404801022, 'Total loss': 0.4437349404801022} | train loss {'Reaction outcome loss': 0.43849984028561395, 'Total loss': 0.43849984028561395}
2022-12-05 21:39:18,078 INFO:     Found new best model at epoch 3
2022-12-05 21:39:18,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:18,079 INFO:     Epoch: 4
2022-12-05 21:39:18,880 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4130922755734487, 'Total loss': 0.4130922755734487} | train loss {'Reaction outcome loss': 0.4186194471502111, 'Total loss': 0.4186194471502111}
2022-12-05 21:39:18,880 INFO:     Found new best model at epoch 4
2022-12-05 21:39:18,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:18,881 INFO:     Epoch: 5
2022-12-05 21:39:19,682 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4162981618534435, 'Total loss': 0.4162981618534435} | train loss {'Reaction outcome loss': 0.38899992904079106, 'Total loss': 0.38899992904079106}
2022-12-05 21:39:19,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:19,683 INFO:     Epoch: 6
2022-12-05 21:39:20,485 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4157611947845329, 'Total loss': 0.4157611947845329} | train loss {'Reaction outcome loss': 0.3694481890354502, 'Total loss': 0.3694481890354502}
2022-12-05 21:39:20,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:20,485 INFO:     Epoch: 7
2022-12-05 21:39:21,285 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4035628160292452, 'Total loss': 0.4035628160292452} | train loss {'Reaction outcome loss': 0.3525328450357383, 'Total loss': 0.3525328450357383}
2022-12-05 21:39:21,285 INFO:     Found new best model at epoch 7
2022-12-05 21:39:21,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:21,286 INFO:     Epoch: 8
2022-12-05 21:39:22,086 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40798888592557475, 'Total loss': 0.40798888592557475} | train loss {'Reaction outcome loss': 0.3435962972974005, 'Total loss': 0.3435962972974005}
2022-12-05 21:39:22,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:22,086 INFO:     Epoch: 9
2022-12-05 21:39:22,883 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3923500562933358, 'Total loss': 0.3923500562933358} | train loss {'Reaction outcome loss': 0.32934862188240777, 'Total loss': 0.32934862188240777}
2022-12-05 21:39:22,883 INFO:     Found new best model at epoch 9
2022-12-05 21:39:22,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:22,884 INFO:     Epoch: 10
2022-12-05 21:39:23,683 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39310639012943616, 'Total loss': 0.39310639012943616} | train loss {'Reaction outcome loss': 0.3135087653647671, 'Total loss': 0.3135087653647671}
2022-12-05 21:39:23,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:23,683 INFO:     Epoch: 11
2022-12-05 21:39:24,476 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3995902904055335, 'Total loss': 0.3995902904055335} | train loss {'Reaction outcome loss': 0.30229701255617836, 'Total loss': 0.30229701255617836}
2022-12-05 21:39:24,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:24,476 INFO:     Epoch: 12
2022-12-05 21:39:25,268 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38874224810437724, 'Total loss': 0.38874224810437724} | train loss {'Reaction outcome loss': 0.2956418901086155, 'Total loss': 0.2956418901086155}
2022-12-05 21:39:25,268 INFO:     Found new best model at epoch 12
2022-12-05 21:39:25,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:25,269 INFO:     Epoch: 13
2022-12-05 21:39:26,059 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3942610685798255, 'Total loss': 0.3942610685798255} | train loss {'Reaction outcome loss': 0.2836568402918244, 'Total loss': 0.2836568402918244}
2022-12-05 21:39:26,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:26,060 INFO:     Epoch: 14
2022-12-05 21:39:26,850 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3891729810698466, 'Total loss': 0.3891729810698466} | train loss {'Reaction outcome loss': 0.27312126668803544, 'Total loss': 0.27312126668803544}
2022-12-05 21:39:26,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:26,851 INFO:     Epoch: 15
2022-12-05 21:39:27,642 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40202187340367923, 'Total loss': 0.40202187340367923} | train loss {'Reaction outcome loss': 0.2639175413651505, 'Total loss': 0.2639175413651505}
2022-12-05 21:39:27,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:27,643 INFO:     Epoch: 16
2022-12-05 21:39:28,433 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3969821618361907, 'Total loss': 0.3969821618361907} | train loss {'Reaction outcome loss': 0.25611080921552926, 'Total loss': 0.25611080921552926}
2022-12-05 21:39:28,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:28,433 INFO:     Epoch: 17
2022-12-05 21:39:29,223 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39921552603217686, 'Total loss': 0.39921552603217686} | train loss {'Reaction outcome loss': 0.25009076875683506, 'Total loss': 0.25009076875683506}
2022-12-05 21:39:29,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:29,223 INFO:     Epoch: 18
2022-12-05 21:39:30,015 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3877853558144786, 'Total loss': 0.3877853558144786} | train loss {'Reaction outcome loss': 0.24016169073278845, 'Total loss': 0.24016169073278845}
2022-12-05 21:39:30,015 INFO:     Found new best model at epoch 18
2022-12-05 21:39:30,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:30,016 INFO:     Epoch: 19
2022-12-05 21:39:30,810 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3831957995214246, 'Total loss': 0.3831957995214246} | train loss {'Reaction outcome loss': 0.23505214054273207, 'Total loss': 0.23505214054273207}
2022-12-05 21:39:30,810 INFO:     Found new best model at epoch 19
2022-12-05 21:39:30,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:30,811 INFO:     Epoch: 20
2022-12-05 21:39:31,608 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40685678544369613, 'Total loss': 0.40685678544369613} | train loss {'Reaction outcome loss': 0.23034780668584923, 'Total loss': 0.23034780668584923}
2022-12-05 21:39:31,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:31,608 INFO:     Epoch: 21
2022-12-05 21:39:32,402 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3938630050556226, 'Total loss': 0.3938630050556226} | train loss {'Reaction outcome loss': 0.22446344112638036, 'Total loss': 0.22446344112638036}
2022-12-05 21:39:32,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:32,403 INFO:     Epoch: 22
2022-12-05 21:39:33,193 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40010720813138917, 'Total loss': 0.40010720813138917} | train loss {'Reaction outcome loss': 0.21847760650189782, 'Total loss': 0.21847760650189782}
2022-12-05 21:39:33,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:33,194 INFO:     Epoch: 23
2022-12-05 21:39:33,989 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40103162977505813, 'Total loss': 0.40103162977505813} | train loss {'Reaction outcome loss': 0.21127513866034536, 'Total loss': 0.21127513866034536}
2022-12-05 21:39:33,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:33,990 INFO:     Epoch: 24
2022-12-05 21:39:34,781 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39714103733951395, 'Total loss': 0.39714103733951395} | train loss {'Reaction outcome loss': 0.21018021945513574, 'Total loss': 0.21018021945513574}
2022-12-05 21:39:34,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:34,782 INFO:     Epoch: 25
2022-12-05 21:39:35,575 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40930983288721606, 'Total loss': 0.40930983288721606} | train loss {'Reaction outcome loss': 0.20377237020392228, 'Total loss': 0.20377237020392228}
2022-12-05 21:39:35,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:35,576 INFO:     Epoch: 26
2022-12-05 21:39:36,370 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39585878259756346, 'Total loss': 0.39585878259756346} | train loss {'Reaction outcome loss': 0.20182824267832344, 'Total loss': 0.20182824267832344}
2022-12-05 21:39:36,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:36,370 INFO:     Epoch: 27
2022-12-05 21:39:37,166 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40603734248063783, 'Total loss': 0.40603734248063783} | train loss {'Reaction outcome loss': 0.19509993491294655, 'Total loss': 0.19509993491294655}
2022-12-05 21:39:37,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:37,167 INFO:     Epoch: 28
2022-12-05 21:39:37,964 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39640984243967314, 'Total loss': 0.39640984243967314} | train loss {'Reaction outcome loss': 0.19476076755446461, 'Total loss': 0.19476076755446461}
2022-12-05 21:39:37,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:37,964 INFO:     Epoch: 29
2022-12-05 21:39:38,759 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4048764258623123, 'Total loss': 0.4048764258623123} | train loss {'Reaction outcome loss': 0.18568350088137847, 'Total loss': 0.18568350088137847}
2022-12-05 21:39:38,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:38,759 INFO:     Epoch: 30
2022-12-05 21:39:39,552 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3996850614520637, 'Total loss': 0.3996850614520637} | train loss {'Reaction outcome loss': 0.18870543173480372, 'Total loss': 0.18870543173480372}
2022-12-05 21:39:39,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:39,552 INFO:     Epoch: 31
2022-12-05 21:39:40,345 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39997068318453705, 'Total loss': 0.39997068318453705} | train loss {'Reaction outcome loss': 0.18407173293382534, 'Total loss': 0.18407173293382534}
2022-12-05 21:39:40,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:40,346 INFO:     Epoch: 32
2022-12-05 21:39:41,140 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.397415739568797, 'Total loss': 0.397415739568797} | train loss {'Reaction outcome loss': 0.17905098326534394, 'Total loss': 0.17905098326534394}
2022-12-05 21:39:41,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:41,140 INFO:     Epoch: 33
2022-12-05 21:39:41,934 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4029876545748927, 'Total loss': 0.4029876545748927} | train loss {'Reaction outcome loss': 0.17935059479011697, 'Total loss': 0.17935059479011697}
2022-12-05 21:39:41,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:41,934 INFO:     Epoch: 34
2022-12-05 21:39:42,730 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4048744458705187, 'Total loss': 0.4048744458705187} | train loss {'Reaction outcome loss': 0.1746701501589834, 'Total loss': 0.1746701501589834}
2022-12-05 21:39:42,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:42,730 INFO:     Epoch: 35
2022-12-05 21:39:43,521 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40409762920303777, 'Total loss': 0.40409762920303777} | train loss {'Reaction outcome loss': 0.17154981203090686, 'Total loss': 0.17154981203090686}
2022-12-05 21:39:43,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:43,521 INFO:     Epoch: 36
2022-12-05 21:39:44,313 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4281354570253329, 'Total loss': 0.4281354570253329} | train loss {'Reaction outcome loss': 0.1687802865588472, 'Total loss': 0.1687802865588472}
2022-12-05 21:39:44,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:44,313 INFO:     Epoch: 37
2022-12-05 21:39:45,104 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3926911973817782, 'Total loss': 0.3926911973817782} | train loss {'Reaction outcome loss': 0.16785291786709053, 'Total loss': 0.16785291786709053}
2022-12-05 21:39:45,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:45,104 INFO:     Epoch: 38
2022-12-05 21:39:45,893 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4051969891244715, 'Total loss': 0.4051969891244715} | train loss {'Reaction outcome loss': 0.16593122226680979, 'Total loss': 0.16593122226680979}
2022-12-05 21:39:45,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:45,893 INFO:     Epoch: 39
2022-12-05 21:39:46,684 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41653944755142386, 'Total loss': 0.41653944755142386} | train loss {'Reaction outcome loss': 0.16393845822466047, 'Total loss': 0.16393845822466047}
2022-12-05 21:39:46,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:46,685 INFO:     Epoch: 40
2022-12-05 21:39:47,475 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39541429348967294, 'Total loss': 0.39541429348967294} | train loss {'Reaction outcome loss': 0.1644617381547144, 'Total loss': 0.1644617381547144}
2022-12-05 21:39:47,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:47,475 INFO:     Epoch: 41
2022-12-05 21:39:48,269 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39942392402074556, 'Total loss': 0.39942392402074556} | train loss {'Reaction outcome loss': 0.16212522888015052, 'Total loss': 0.16212522888015052}
2022-12-05 21:39:48,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:48,269 INFO:     Epoch: 42
2022-12-05 21:39:49,069 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4055536182766611, 'Total loss': 0.4055536182766611} | train loss {'Reaction outcome loss': 0.15905807260800953, 'Total loss': 0.15905807260800953}
2022-12-05 21:39:49,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:49,069 INFO:     Epoch: 43
2022-12-05 21:39:49,870 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3946142887950621, 'Total loss': 0.3946142887950621} | train loss {'Reaction outcome loss': 0.15989528156002522, 'Total loss': 0.15989528156002522}
2022-12-05 21:39:49,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:49,870 INFO:     Epoch: 44
2022-12-05 21:39:50,670 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4108514626595107, 'Total loss': 0.4108514626595107} | train loss {'Reaction outcome loss': 0.1541905796291073, 'Total loss': 0.1541905796291073}
2022-12-05 21:39:50,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:50,671 INFO:     Epoch: 45
2022-12-05 21:39:51,472 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39780679988590156, 'Total loss': 0.39780679988590156} | train loss {'Reaction outcome loss': 0.15165667224539678, 'Total loss': 0.15165667224539678}
2022-12-05 21:39:51,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:51,473 INFO:     Epoch: 46
2022-12-05 21:39:52,273 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40994383123787964, 'Total loss': 0.40994383123787964} | train loss {'Reaction outcome loss': 0.15183317826434908, 'Total loss': 0.15183317826434908}
2022-12-05 21:39:52,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:52,273 INFO:     Epoch: 47
2022-12-05 21:39:53,073 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4059492349624634, 'Total loss': 0.4059492349624634} | train loss {'Reaction outcome loss': 0.15507641059878144, 'Total loss': 0.15507641059878144}
2022-12-05 21:39:53,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:53,073 INFO:     Epoch: 48
2022-12-05 21:39:53,872 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4092328277501193, 'Total loss': 0.4092328277501193} | train loss {'Reaction outcome loss': 0.16227366478155983, 'Total loss': 0.16227366478155983}
2022-12-05 21:39:53,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:53,873 INFO:     Epoch: 49
2022-12-05 21:39:54,671 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40789272500710055, 'Total loss': 0.40789272500710055} | train loss {'Reaction outcome loss': 0.1547918603321922, 'Total loss': 0.1547918603321922}
2022-12-05 21:39:54,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:54,671 INFO:     Epoch: 50
2022-12-05 21:39:55,469 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3881928234953772, 'Total loss': 0.3881928234953772} | train loss {'Reaction outcome loss': 0.15037423201086308, 'Total loss': 0.15037423201086308}
2022-12-05 21:39:55,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:55,470 INFO:     Epoch: 51
2022-12-05 21:39:56,270 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3983373459089886, 'Total loss': 0.3983373459089886} | train loss {'Reaction outcome loss': 0.14423540021907463, 'Total loss': 0.14423540021907463}
2022-12-05 21:39:56,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:56,270 INFO:     Epoch: 52
2022-12-05 21:39:57,066 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42627182992344553, 'Total loss': 0.42627182992344553} | train loss {'Reaction outcome loss': 0.14120261563668743, 'Total loss': 0.14120261563668743}
2022-12-05 21:39:57,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:57,067 INFO:     Epoch: 53
2022-12-05 21:39:57,866 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40689111399379646, 'Total loss': 0.40689111399379646} | train loss {'Reaction outcome loss': 0.1418175430862829, 'Total loss': 0.1418175430862829}
2022-12-05 21:39:57,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:57,866 INFO:     Epoch: 54
2022-12-05 21:39:58,666 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4085327535867691, 'Total loss': 0.4085327535867691} | train loss {'Reaction outcome loss': 0.14321434506128433, 'Total loss': 0.14321434506128433}
2022-12-05 21:39:58,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:58,666 INFO:     Epoch: 55
2022-12-05 21:39:59,468 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4055224531753497, 'Total loss': 0.4055224531753497} | train loss {'Reaction outcome loss': 0.14291155039896503, 'Total loss': 0.14291155039896503}
2022-12-05 21:39:59,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:39:59,469 INFO:     Epoch: 56
2022-12-05 21:40:00,265 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42127758196809073, 'Total loss': 0.42127758196809073} | train loss {'Reaction outcome loss': 0.1409694993951422, 'Total loss': 0.1409694993951422}
2022-12-05 21:40:00,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:00,265 INFO:     Epoch: 57
2022-12-05 21:40:01,065 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4181290594014255, 'Total loss': 0.4181290594014255} | train loss {'Reaction outcome loss': 0.14227129317639087, 'Total loss': 0.14227129317639087}
2022-12-05 21:40:01,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:01,065 INFO:     Epoch: 58
2022-12-05 21:40:01,867 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40681664645671844, 'Total loss': 0.40681664645671844} | train loss {'Reaction outcome loss': 0.14267756645393329, 'Total loss': 0.14267756645393329}
2022-12-05 21:40:01,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:01,867 INFO:     Epoch: 59
2022-12-05 21:40:02,667 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39832252882082353, 'Total loss': 0.39832252882082353} | train loss {'Reaction outcome loss': 0.13674186725878282, 'Total loss': 0.13674186725878282}
2022-12-05 21:40:02,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:02,667 INFO:     Epoch: 60
2022-12-05 21:40:03,465 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39452599022876134, 'Total loss': 0.39452599022876134} | train loss {'Reaction outcome loss': 0.14166628380083604, 'Total loss': 0.14166628380083604}
2022-12-05 21:40:03,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:03,466 INFO:     Epoch: 61
2022-12-05 21:40:04,261 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4022180893543092, 'Total loss': 0.4022180893543092} | train loss {'Reaction outcome loss': 0.13625487885843238, 'Total loss': 0.13625487885843238}
2022-12-05 21:40:04,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:04,261 INFO:     Epoch: 62
2022-12-05 21:40:05,060 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41041622090746055, 'Total loss': 0.41041622090746055} | train loss {'Reaction outcome loss': 0.1339437743349129, 'Total loss': 0.1339437743349129}
2022-12-05 21:40:05,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:05,061 INFO:     Epoch: 63
2022-12-05 21:40:05,853 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40219514309005305, 'Total loss': 0.40219514309005305} | train loss {'Reaction outcome loss': 0.13285966847598107, 'Total loss': 0.13285966847598107}
2022-12-05 21:40:05,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:05,853 INFO:     Epoch: 64
2022-12-05 21:40:06,651 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4259335417300463, 'Total loss': 0.4259335417300463} | train loss {'Reaction outcome loss': 0.13171173241234532, 'Total loss': 0.13171173241234532}
2022-12-05 21:40:06,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:06,651 INFO:     Epoch: 65
2022-12-05 21:40:07,441 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.418843414126472, 'Total loss': 0.418843414126472} | train loss {'Reaction outcome loss': 0.13254654259837576, 'Total loss': 0.13254654259837576}
2022-12-05 21:40:07,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:07,442 INFO:     Epoch: 66
2022-12-05 21:40:08,237 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41860073059797287, 'Total loss': 0.41860073059797287} | train loss {'Reaction outcome loss': 0.134536215830698, 'Total loss': 0.134536215830698}
2022-12-05 21:40:08,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:08,238 INFO:     Epoch: 67
2022-12-05 21:40:09,031 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41082954830066726, 'Total loss': 0.41082954830066726} | train loss {'Reaction outcome loss': 0.13113328448764466, 'Total loss': 0.13113328448764466}
2022-12-05 21:40:09,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:09,032 INFO:     Epoch: 68
2022-12-05 21:40:09,823 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41519917209040036, 'Total loss': 0.41519917209040036} | train loss {'Reaction outcome loss': 0.12882553770203098, 'Total loss': 0.12882553770203098}
2022-12-05 21:40:09,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:09,824 INFO:     Epoch: 69
2022-12-05 21:40:10,618 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40948462418534537, 'Total loss': 0.40948462418534537} | train loss {'Reaction outcome loss': 0.12903759327268433, 'Total loss': 0.12903759327268433}
2022-12-05 21:40:10,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:10,618 INFO:     Epoch: 70
2022-12-05 21:40:11,414 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4100849262692712, 'Total loss': 0.4100849262692712} | train loss {'Reaction outcome loss': 0.13519046985747402, 'Total loss': 0.13519046985747402}
2022-12-05 21:40:11,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:11,415 INFO:     Epoch: 71
2022-12-05 21:40:12,204 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41996548798951233, 'Total loss': 0.41996548798951233} | train loss {'Reaction outcome loss': 0.13454712710912653, 'Total loss': 0.13454712710912653}
2022-12-05 21:40:12,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:12,204 INFO:     Epoch: 72
2022-12-05 21:40:12,995 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41831057518720627, 'Total loss': 0.41831057518720627} | train loss {'Reaction outcome loss': 0.1421068172924492, 'Total loss': 0.1421068172924492}
2022-12-05 21:40:12,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:12,995 INFO:     Epoch: 73
2022-12-05 21:40:13,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4090276011689143, 'Total loss': 0.4090276011689143} | train loss {'Reaction outcome loss': 0.1305865488026427, 'Total loss': 0.1305865488026427}
2022-12-05 21:40:13,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:13,792 INFO:     Epoch: 74
2022-12-05 21:40:14,592 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39149062775752763, 'Total loss': 0.39149062775752763} | train loss {'Reaction outcome loss': 0.1275277592388815, 'Total loss': 0.1275277592388815}
2022-12-05 21:40:14,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:14,592 INFO:     Epoch: 75
2022-12-05 21:40:15,390 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40270590722899546, 'Total loss': 0.40270590722899546} | train loss {'Reaction outcome loss': 0.12466865000861739, 'Total loss': 0.12466865000861739}
2022-12-05 21:40:15,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:15,390 INFO:     Epoch: 76
2022-12-05 21:40:16,190 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4112196124412797, 'Total loss': 0.4112196124412797} | train loss {'Reaction outcome loss': 0.1285023862177408, 'Total loss': 0.1285023862177408}
2022-12-05 21:40:16,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:16,190 INFO:     Epoch: 77
2022-12-05 21:40:16,990 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40851029787551274, 'Total loss': 0.40851029787551274} | train loss {'Reaction outcome loss': 0.12434075555143415, 'Total loss': 0.12434075555143415}
2022-12-05 21:40:16,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:16,990 INFO:     Epoch: 78
2022-12-05 21:40:17,786 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40353151614015753, 'Total loss': 0.40353151614015753} | train loss {'Reaction outcome loss': 0.12318357982510618, 'Total loss': 0.12318357982510618}
2022-12-05 21:40:17,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:17,787 INFO:     Epoch: 79
2022-12-05 21:40:18,588 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40453141487457533, 'Total loss': 0.40453141487457533} | train loss {'Reaction outcome loss': 0.12286121627235283, 'Total loss': 0.12286121627235283}
2022-12-05 21:40:18,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:18,589 INFO:     Epoch: 80
2022-12-05 21:40:19,385 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4141776468604803, 'Total loss': 0.4141776468604803} | train loss {'Reaction outcome loss': 0.1231878967390128, 'Total loss': 0.1231878967390128}
2022-12-05 21:40:19,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:19,385 INFO:     Epoch: 81
2022-12-05 21:40:20,183 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40166201696477155, 'Total loss': 0.40166201696477155} | train loss {'Reaction outcome loss': 0.12332108804601648, 'Total loss': 0.12332108804601648}
2022-12-05 21:40:20,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:20,184 INFO:     Epoch: 82
2022-12-05 21:40:20,986 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4240658374672586, 'Total loss': 0.4240658374672586} | train loss {'Reaction outcome loss': 0.12403380456531368, 'Total loss': 0.12403380456531368}
2022-12-05 21:40:20,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:20,986 INFO:     Epoch: 83
2022-12-05 21:40:21,788 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3952602449465882, 'Total loss': 0.3952602449465882} | train loss {'Reaction outcome loss': 0.12463982897218663, 'Total loss': 0.12463982897218663}
2022-12-05 21:40:21,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:21,789 INFO:     Epoch: 84
2022-12-05 21:40:22,588 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4008990055458112, 'Total loss': 0.4008990055458112} | train loss {'Reaction outcome loss': 0.12369421785150612, 'Total loss': 0.12369421785150612}
2022-12-05 21:40:22,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:22,588 INFO:     Epoch: 85
2022-12-05 21:40:23,384 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4048766238106923, 'Total loss': 0.4048766238106923} | train loss {'Reaction outcome loss': 0.11996740430427587, 'Total loss': 0.11996740430427587}
2022-12-05 21:40:23,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:23,385 INFO:     Epoch: 86
2022-12-05 21:40:24,181 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40763499960303307, 'Total loss': 0.40763499960303307} | train loss {'Reaction outcome loss': 0.11991760457454906, 'Total loss': 0.11991760457454906}
2022-12-05 21:40:24,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:24,181 INFO:     Epoch: 87
2022-12-05 21:40:24,982 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41653313216837967, 'Total loss': 0.41653313216837967} | train loss {'Reaction outcome loss': 0.1210609522727337, 'Total loss': 0.1210609522727337}
2022-12-05 21:40:24,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:24,982 INFO:     Epoch: 88
2022-12-05 21:40:25,782 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41612474010749295, 'Total loss': 0.41612474010749295} | train loss {'Reaction outcome loss': 0.12943414429029232, 'Total loss': 0.12943414429029232}
2022-12-05 21:40:25,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:25,782 INFO:     Epoch: 89
2022-12-05 21:40:26,581 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3998799483207139, 'Total loss': 0.3998799483207139} | train loss {'Reaction outcome loss': 0.12008949178025911, 'Total loss': 0.12008949178025911}
2022-12-05 21:40:26,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:26,581 INFO:     Epoch: 90
2022-12-05 21:40:27,381 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.399415808306499, 'Total loss': 0.399415808306499} | train loss {'Reaction outcome loss': 0.11689359233889028, 'Total loss': 0.11689359233889028}
2022-12-05 21:40:27,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:27,381 INFO:     Epoch: 91
2022-12-05 21:40:28,178 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41332804648713634, 'Total loss': 0.41332804648713634} | train loss {'Reaction outcome loss': 0.11840468726350892, 'Total loss': 0.11840468726350892}
2022-12-05 21:40:28,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:28,179 INFO:     Epoch: 92
2022-12-05 21:40:28,980 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4160412306135351, 'Total loss': 0.4160412306135351} | train loss {'Reaction outcome loss': 0.11828341241548901, 'Total loss': 0.11828341241548901}
2022-12-05 21:40:28,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:28,980 INFO:     Epoch: 93
2022-12-05 21:40:29,780 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40966569022698834, 'Total loss': 0.40966569022698834} | train loss {'Reaction outcome loss': 0.11571485640246398, 'Total loss': 0.11571485640246398}
2022-12-05 21:40:29,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:29,780 INFO:     Epoch: 94
2022-12-05 21:40:30,581 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40672207928516646, 'Total loss': 0.40672207928516646} | train loss {'Reaction outcome loss': 0.11806323117979987, 'Total loss': 0.11806323117979987}
2022-12-05 21:40:30,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:30,582 INFO:     Epoch: 95
2022-12-05 21:40:31,384 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3982552235776728, 'Total loss': 0.3982552235776728} | train loss {'Reaction outcome loss': 0.11514561811296141, 'Total loss': 0.11514561811296141}
2022-12-05 21:40:31,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:31,385 INFO:     Epoch: 96
2022-12-05 21:40:32,187 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41021857326003636, 'Total loss': 0.41021857326003636} | train loss {'Reaction outcome loss': 0.1155606120530712, 'Total loss': 0.1155606120530712}
2022-12-05 21:40:32,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:32,187 INFO:     Epoch: 97
2022-12-05 21:40:32,986 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4125894700939005, 'Total loss': 0.4125894700939005} | train loss {'Reaction outcome loss': 0.12244929115736654, 'Total loss': 0.12244929115736654}
2022-12-05 21:40:32,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:32,986 INFO:     Epoch: 98
2022-12-05 21:40:33,784 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4095738794315945, 'Total loss': 0.4095738794315945} | train loss {'Reaction outcome loss': 0.12598087061535915, 'Total loss': 0.12598087061535915}
2022-12-05 21:40:33,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:33,784 INFO:     Epoch: 99
2022-12-05 21:40:34,589 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39624711430885573, 'Total loss': 0.39624711430885573} | train loss {'Reaction outcome loss': 0.11471806427837172, 'Total loss': 0.11471806427837172}
2022-12-05 21:40:34,589 INFO:     Best model found after epoch 20 of 100.
2022-12-05 21:40:34,589 INFO:   Done with stage: TRAINING
2022-12-05 21:40:34,589 INFO:   Starting stage: EVALUATION
2022-12-05 21:40:34,715 INFO:   Done with stage: EVALUATION
2022-12-05 21:40:34,715 INFO:   Leaving out SEQ value Fold_5
2022-12-05 21:40:34,727 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:40:34,728 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:40:35,390 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:40:35,390 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:40:35,458 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:40:35,459 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:40:35,459 INFO:     No hyperparam tuning for this model
2022-12-05 21:40:35,459 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:40:35,459 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:40:35,459 INFO:     None feature selector for col prot
2022-12-05 21:40:35,460 INFO:     None feature selector for col prot
2022-12-05 21:40:35,460 INFO:     None feature selector for col prot
2022-12-05 21:40:35,460 INFO:     None feature selector for col chem
2022-12-05 21:40:35,460 INFO:     None feature selector for col chem
2022-12-05 21:40:35,460 INFO:     None feature selector for col chem
2022-12-05 21:40:35,460 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:40:35,461 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:40:35,462 INFO:     Number of params in model 215821
2022-12-05 21:40:35,465 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:40:35,465 INFO:   Starting stage: TRAINING
2022-12-05 21:40:35,527 INFO:     Val loss before train {'Reaction outcome loss': 0.9880861369046298, 'Total loss': 0.9880861369046298}
2022-12-05 21:40:35,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:35,527 INFO:     Epoch: 0
2022-12-05 21:40:36,333 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6194458319382234, 'Total loss': 0.6194458319382234} | train loss {'Reaction outcome loss': 0.8160704093182135, 'Total loss': 0.8160704093182135}
2022-12-05 21:40:36,333 INFO:     Found new best model at epoch 0
2022-12-05 21:40:36,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:36,334 INFO:     Epoch: 1
2022-12-05 21:40:37,137 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5312993465499445, 'Total loss': 0.5312993465499445} | train loss {'Reaction outcome loss': 0.5579352790851765, 'Total loss': 0.5579352790851765}
2022-12-05 21:40:37,137 INFO:     Found new best model at epoch 1
2022-12-05 21:40:37,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:37,138 INFO:     Epoch: 2
2022-12-05 21:40:37,937 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48817654766819696, 'Total loss': 0.48817654766819696} | train loss {'Reaction outcome loss': 0.4869717112195637, 'Total loss': 0.4869717112195637}
2022-12-05 21:40:37,937 INFO:     Found new best model at epoch 2
2022-12-05 21:40:37,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:37,938 INFO:     Epoch: 3
2022-12-05 21:40:38,738 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4773417914455587, 'Total loss': 0.4773417914455587} | train loss {'Reaction outcome loss': 0.4420502812032275, 'Total loss': 0.4420502812032275}
2022-12-05 21:40:38,738 INFO:     Found new best model at epoch 3
2022-12-05 21:40:38,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:38,739 INFO:     Epoch: 4
2022-12-05 21:40:39,542 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44921659576621925, 'Total loss': 0.44921659576621925} | train loss {'Reaction outcome loss': 0.41333997887201035, 'Total loss': 0.41333997887201035}
2022-12-05 21:40:39,542 INFO:     Found new best model at epoch 4
2022-12-05 21:40:39,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:39,543 INFO:     Epoch: 5
2022-12-05 21:40:40,349 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43807441131635144, 'Total loss': 0.43807441131635144} | train loss {'Reaction outcome loss': 0.38641244904534056, 'Total loss': 0.38641244904534056}
2022-12-05 21:40:40,349 INFO:     Found new best model at epoch 5
2022-12-05 21:40:40,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:40,350 INFO:     Epoch: 6
2022-12-05 21:40:41,150 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4403599046848037, 'Total loss': 0.4403599046848037} | train loss {'Reaction outcome loss': 0.3662802150193979, 'Total loss': 0.3662802150193979}
2022-12-05 21:40:41,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:41,150 INFO:     Epoch: 7
2022-12-05 21:40:41,952 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4292673092674125, 'Total loss': 0.4292673092674125} | train loss {'Reaction outcome loss': 0.3515791616700439, 'Total loss': 0.3515791616700439}
2022-12-05 21:40:41,952 INFO:     Found new best model at epoch 7
2022-12-05 21:40:41,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:41,953 INFO:     Epoch: 8
2022-12-05 21:40:42,756 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42222705483436584, 'Total loss': 0.42222705483436584} | train loss {'Reaction outcome loss': 0.3393156168009588, 'Total loss': 0.3393156168009588}
2022-12-05 21:40:42,757 INFO:     Found new best model at epoch 8
2022-12-05 21:40:42,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:42,758 INFO:     Epoch: 9
2022-12-05 21:40:43,559 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4522156698459929, 'Total loss': 0.4522156698459929} | train loss {'Reaction outcome loss': 0.3224435058923868, 'Total loss': 0.3224435058923868}
2022-12-05 21:40:43,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:43,559 INFO:     Epoch: 10
2022-12-05 21:40:44,362 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4378693970766934, 'Total loss': 0.4378693970766934} | train loss {'Reaction outcome loss': 0.3088219268058958, 'Total loss': 0.3088219268058958}
2022-12-05 21:40:44,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:44,362 INFO:     Epoch: 11
2022-12-05 21:40:45,163 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43426336720585823, 'Total loss': 0.43426336720585823} | train loss {'Reaction outcome loss': 0.2979222287985719, 'Total loss': 0.2979222287985719}
2022-12-05 21:40:45,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:45,163 INFO:     Epoch: 12
2022-12-05 21:40:45,965 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4472894986922091, 'Total loss': 0.4472894986922091} | train loss {'Reaction outcome loss': 0.2861863042601207, 'Total loss': 0.2861863042601207}
2022-12-05 21:40:45,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:45,965 INFO:     Epoch: 13
2022-12-05 21:40:46,765 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42769641463052144, 'Total loss': 0.42769641463052144} | train loss {'Reaction outcome loss': 0.275267227277582, 'Total loss': 0.275267227277582}
2022-12-05 21:40:46,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:46,765 INFO:     Epoch: 14
2022-12-05 21:40:47,574 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42944413728334685, 'Total loss': 0.42944413728334685} | train loss {'Reaction outcome loss': 0.2654645938561995, 'Total loss': 0.2654645938561995}
2022-12-05 21:40:47,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:47,575 INFO:     Epoch: 15
2022-12-05 21:40:48,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4359093684364449, 'Total loss': 0.4359093684364449} | train loss {'Reaction outcome loss': 0.2572877519888434, 'Total loss': 0.2572877519888434}
2022-12-05 21:40:48,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:48,386 INFO:     Epoch: 16
2022-12-05 21:40:49,187 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43036649613217876, 'Total loss': 0.43036649613217876} | train loss {'Reaction outcome loss': 0.25392652714723035, 'Total loss': 0.25392652714723035}
2022-12-05 21:40:49,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:49,188 INFO:     Epoch: 17
2022-12-05 21:40:49,987 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44752523133700545, 'Total loss': 0.44752523133700545} | train loss {'Reaction outcome loss': 0.2425695445034125, 'Total loss': 0.2425695445034125}
2022-12-05 21:40:49,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:49,988 INFO:     Epoch: 18
2022-12-05 21:40:50,786 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4341028034687042, 'Total loss': 0.4341028034687042} | train loss {'Reaction outcome loss': 0.23691804099239802, 'Total loss': 0.23691804099239802}
2022-12-05 21:40:50,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:50,787 INFO:     Epoch: 19
2022-12-05 21:40:51,588 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4430089992555705, 'Total loss': 0.4430089992555705} | train loss {'Reaction outcome loss': 0.23164289481070663, 'Total loss': 0.23164289481070663}
2022-12-05 21:40:51,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:51,588 INFO:     Epoch: 20
2022-12-05 21:40:52,396 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4403265684165738, 'Total loss': 0.4403265684165738} | train loss {'Reaction outcome loss': 0.225924360185017, 'Total loss': 0.225924360185017}
2022-12-05 21:40:52,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:52,396 INFO:     Epoch: 21
2022-12-05 21:40:53,205 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4416857473552227, 'Total loss': 0.4416857473552227} | train loss {'Reaction outcome loss': 0.2225004107406672, 'Total loss': 0.2225004107406672}
2022-12-05 21:40:53,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:53,205 INFO:     Epoch: 22
2022-12-05 21:40:54,005 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46220615844834934, 'Total loss': 0.46220615844834934} | train loss {'Reaction outcome loss': 0.21379876087668545, 'Total loss': 0.21379876087668545}
2022-12-05 21:40:54,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:54,006 INFO:     Epoch: 23
2022-12-05 21:40:54,805 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44809304110028525, 'Total loss': 0.44809304110028525} | train loss {'Reaction outcome loss': 0.21294175112537045, 'Total loss': 0.21294175112537045}
2022-12-05 21:40:54,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:54,805 INFO:     Epoch: 24
2022-12-05 21:40:55,608 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46026787339625036, 'Total loss': 0.46026787339625036} | train loss {'Reaction outcome loss': 0.208573701712284, 'Total loss': 0.208573701712284}
2022-12-05 21:40:55,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:55,609 INFO:     Epoch: 25
2022-12-05 21:40:56,410 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4574786146933382, 'Total loss': 0.4574786146933382} | train loss {'Reaction outcome loss': 0.19958063153934624, 'Total loss': 0.19958063153934624}
2022-12-05 21:40:56,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:56,410 INFO:     Epoch: 26
2022-12-05 21:40:57,211 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45410185984589835, 'Total loss': 0.45410185984589835} | train loss {'Reaction outcome loss': 0.19851744191547638, 'Total loss': 0.19851744191547638}
2022-12-05 21:40:57,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:57,211 INFO:     Epoch: 27
2022-12-05 21:40:58,011 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4558087263933637, 'Total loss': 0.4558087263933637} | train loss {'Reaction outcome loss': 0.19981663657525772, 'Total loss': 0.19981663657525772}
2022-12-05 21:40:58,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:58,011 INFO:     Epoch: 28
2022-12-05 21:40:58,815 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4513740813867612, 'Total loss': 0.4513740813867612} | train loss {'Reaction outcome loss': 0.19438020387279842, 'Total loss': 0.19438020387279842}
2022-12-05 21:40:58,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:58,816 INFO:     Epoch: 29
2022-12-05 21:40:59,619 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45351469787684356, 'Total loss': 0.45351469787684356} | train loss {'Reaction outcome loss': 0.1924056412674758, 'Total loss': 0.1924056412674758}
2022-12-05 21:40:59,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:40:59,619 INFO:     Epoch: 30
2022-12-05 21:41:00,421 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46002122861417855, 'Total loss': 0.46002122861417855} | train loss {'Reaction outcome loss': 0.18770088829705303, 'Total loss': 0.18770088829705303}
2022-12-05 21:41:00,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:00,421 INFO:     Epoch: 31
2022-12-05 21:41:01,228 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46351494775577023, 'Total loss': 0.46351494775577023} | train loss {'Reaction outcome loss': 0.17916692995752853, 'Total loss': 0.17916692995752853}
2022-12-05 21:41:01,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:01,229 INFO:     Epoch: 32
2022-12-05 21:41:02,029 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4652696278962222, 'Total loss': 0.4652696278962222} | train loss {'Reaction outcome loss': 0.1814424313024169, 'Total loss': 0.1814424313024169}
2022-12-05 21:41:02,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:02,030 INFO:     Epoch: 33
2022-12-05 21:41:02,830 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46576052836396475, 'Total loss': 0.46576052836396475} | train loss {'Reaction outcome loss': 0.17634226281293913, 'Total loss': 0.17634226281293913}
2022-12-05 21:41:02,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:02,830 INFO:     Epoch: 34
2022-12-05 21:41:03,633 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45196872915733943, 'Total loss': 0.45196872915733943} | train loss {'Reaction outcome loss': 0.18021199954032657, 'Total loss': 0.18021199954032657}
2022-12-05 21:41:03,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:03,633 INFO:     Epoch: 35
2022-12-05 21:41:04,432 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4514623748307878, 'Total loss': 0.4514623748307878} | train loss {'Reaction outcome loss': 0.1857575461054447, 'Total loss': 0.1857575461054447}
2022-12-05 21:41:04,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:04,433 INFO:     Epoch: 36
2022-12-05 21:41:05,241 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4659408777952194, 'Total loss': 0.4659408777952194} | train loss {'Reaction outcome loss': 0.16832809457894762, 'Total loss': 0.16832809457894762}
2022-12-05 21:41:05,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:05,241 INFO:     Epoch: 37
2022-12-05 21:41:06,048 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47361086546020076, 'Total loss': 0.47361086546020076} | train loss {'Reaction outcome loss': 0.1744755924441795, 'Total loss': 0.1744755924441795}
2022-12-05 21:41:06,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:06,048 INFO:     Epoch: 38
2022-12-05 21:41:06,856 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4769737549464811, 'Total loss': 0.4769737549464811} | train loss {'Reaction outcome loss': 0.17567251506732845, 'Total loss': 0.17567251506732845}
2022-12-05 21:41:06,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:06,856 INFO:     Epoch: 39
2022-12-05 21:41:07,659 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47740999643098225, 'Total loss': 0.47740999643098225} | train loss {'Reaction outcome loss': 0.16463135366294127, 'Total loss': 0.16463135366294127}
2022-12-05 21:41:07,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:07,659 INFO:     Epoch: 40
2022-12-05 21:41:08,461 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4765074195509607, 'Total loss': 0.4765074195509607} | train loss {'Reaction outcome loss': 0.16548744600590484, 'Total loss': 0.16548744600590484}
2022-12-05 21:41:08,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:08,461 INFO:     Epoch: 41
2022-12-05 21:41:09,270 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46976182101802394, 'Total loss': 0.46976182101802394} | train loss {'Reaction outcome loss': 0.16045620338425703, 'Total loss': 0.16045620338425703}
2022-12-05 21:41:09,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:09,270 INFO:     Epoch: 42
2022-12-05 21:41:10,075 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45931767054240813, 'Total loss': 0.45931767054240813} | train loss {'Reaction outcome loss': 0.16009981317920724, 'Total loss': 0.16009981317920724}
2022-12-05 21:41:10,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:10,075 INFO:     Epoch: 43
2022-12-05 21:41:10,877 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4862399165603248, 'Total loss': 0.4862399165603248} | train loss {'Reaction outcome loss': 0.16133944592193553, 'Total loss': 0.16133944592193553}
2022-12-05 21:41:10,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:10,877 INFO:     Epoch: 44
2022-12-05 21:41:11,681 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47166772694750264, 'Total loss': 0.47166772694750264} | train loss {'Reaction outcome loss': 0.16292201184671418, 'Total loss': 0.16292201184671418}
2022-12-05 21:41:11,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:11,681 INFO:     Epoch: 45
2022-12-05 21:41:12,492 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4766903238540346, 'Total loss': 0.4766903238540346} | train loss {'Reaction outcome loss': 0.16246193896994177, 'Total loss': 0.16246193896994177}
2022-12-05 21:41:12,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:12,492 INFO:     Epoch: 46
2022-12-05 21:41:13,289 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.481499273668636, 'Total loss': 0.481499273668636} | train loss {'Reaction outcome loss': 0.1660667226804413, 'Total loss': 0.1660667226804413}
2022-12-05 21:41:13,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:13,290 INFO:     Epoch: 47
2022-12-05 21:41:14,084 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4701702310280366, 'Total loss': 0.4701702310280366} | train loss {'Reaction outcome loss': 0.15474874572545622, 'Total loss': 0.15474874572545622}
2022-12-05 21:41:14,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:14,085 INFO:     Epoch: 48
2022-12-05 21:41:14,878 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.475663028488105, 'Total loss': 0.475663028488105} | train loss {'Reaction outcome loss': 0.152472515752622, 'Total loss': 0.152472515752622}
2022-12-05 21:41:14,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:14,878 INFO:     Epoch: 49
2022-12-05 21:41:15,680 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4681282216175036, 'Total loss': 0.4681282216175036} | train loss {'Reaction outcome loss': 0.15116610977919356, 'Total loss': 0.15116610977919356}
2022-12-05 21:41:15,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:15,680 INFO:     Epoch: 50
2022-12-05 21:41:16,478 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48471633141691034, 'Total loss': 0.48471633141691034} | train loss {'Reaction outcome loss': 0.15123072093133985, 'Total loss': 0.15123072093133985}
2022-12-05 21:41:16,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:16,478 INFO:     Epoch: 51
2022-12-05 21:41:17,271 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4754291405393319, 'Total loss': 0.4754291405393319} | train loss {'Reaction outcome loss': 0.15227157817889564, 'Total loss': 0.15227157817889564}
2022-12-05 21:41:17,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:17,272 INFO:     Epoch: 52
2022-12-05 21:41:18,068 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47410897859795526, 'Total loss': 0.47410897859795526} | train loss {'Reaction outcome loss': 0.14885437401833562, 'Total loss': 0.14885437401833562}
2022-12-05 21:41:18,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:18,069 INFO:     Epoch: 53
2022-12-05 21:41:18,865 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48406425592574204, 'Total loss': 0.48406425592574204} | train loss {'Reaction outcome loss': 0.14578957403425566, 'Total loss': 0.14578957403425566}
2022-12-05 21:41:18,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:18,865 INFO:     Epoch: 54
2022-12-05 21:41:19,659 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47378129783001816, 'Total loss': 0.47378129783001816} | train loss {'Reaction outcome loss': 0.14314731345455414, 'Total loss': 0.14314731345455414}
2022-12-05 21:41:19,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:19,659 INFO:     Epoch: 55
2022-12-05 21:41:20,454 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46898827769539575, 'Total loss': 0.46898827769539575} | train loss {'Reaction outcome loss': 0.14302220511691352, 'Total loss': 0.14302220511691352}
2022-12-05 21:41:20,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:20,454 INFO:     Epoch: 56
2022-12-05 21:41:21,251 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4623282959854061, 'Total loss': 0.4623282959854061} | train loss {'Reaction outcome loss': 0.14180198570464544, 'Total loss': 0.14180198570464544}
2022-12-05 21:41:21,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:21,251 INFO:     Epoch: 57
2022-12-05 21:41:22,046 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4707381681285121, 'Total loss': 0.4707381681285121} | train loss {'Reaction outcome loss': 0.14255232700671783, 'Total loss': 0.14255232700671783}
2022-12-05 21:41:22,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:22,047 INFO:     Epoch: 58
2022-12-05 21:41:22,840 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48630355908112094, 'Total loss': 0.48630355908112094} | train loss {'Reaction outcome loss': 0.141384159765293, 'Total loss': 0.141384159765293}
2022-12-05 21:41:22,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:22,841 INFO:     Epoch: 59
2022-12-05 21:41:23,634 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4759570654820312, 'Total loss': 0.4759570654820312} | train loss {'Reaction outcome loss': 0.13973934972575802, 'Total loss': 0.13973934972575802}
2022-12-05 21:41:23,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:23,634 INFO:     Epoch: 60
2022-12-05 21:41:24,428 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.48750169880010863, 'Total loss': 0.48750169880010863} | train loss {'Reaction outcome loss': 0.13796987560830318, 'Total loss': 0.13796987560830318}
2022-12-05 21:41:24,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:24,428 INFO:     Epoch: 61
2022-12-05 21:41:25,225 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47502409531311557, 'Total loss': 0.47502409531311557} | train loss {'Reaction outcome loss': 0.13758848557391992, 'Total loss': 0.13758848557391992}
2022-12-05 21:41:25,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:25,225 INFO:     Epoch: 62
2022-12-05 21:41:26,021 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4673520311374556, 'Total loss': 0.4673520311374556} | train loss {'Reaction outcome loss': 0.14316286350249763, 'Total loss': 0.14316286350249763}
2022-12-05 21:41:26,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:26,022 INFO:     Epoch: 63
2022-12-05 21:41:26,814 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46355269239707425, 'Total loss': 0.46355269239707425} | train loss {'Reaction outcome loss': 0.14098280266696503, 'Total loss': 0.14098280266696503}
2022-12-05 21:41:26,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:26,814 INFO:     Epoch: 64
2022-12-05 21:41:27,607 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47220548885789787, 'Total loss': 0.47220548885789787} | train loss {'Reaction outcome loss': 0.1366781462587205, 'Total loss': 0.1366781462587205}
2022-12-05 21:41:27,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:27,608 INFO:     Epoch: 65
2022-12-05 21:41:28,402 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4647981902923096, 'Total loss': 0.4647981902923096} | train loss {'Reaction outcome loss': 0.13756128788929478, 'Total loss': 0.13756128788929478}
2022-12-05 21:41:28,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:28,402 INFO:     Epoch: 66
2022-12-05 21:41:29,196 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4727082685990767, 'Total loss': 0.4727082685990767} | train loss {'Reaction outcome loss': 0.13446885785879756, 'Total loss': 0.13446885785879756}
2022-12-05 21:41:29,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:29,196 INFO:     Epoch: 67
2022-12-05 21:41:29,990 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4667942693287676, 'Total loss': 0.4667942693287676} | train loss {'Reaction outcome loss': 0.13289066509302208, 'Total loss': 0.13289066509302208}
2022-12-05 21:41:29,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:29,991 INFO:     Epoch: 68
2022-12-05 21:41:30,790 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4815357449379834, 'Total loss': 0.4815357449379834} | train loss {'Reaction outcome loss': 0.13565849880065753, 'Total loss': 0.13565849880065753}
2022-12-05 21:41:30,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:30,790 INFO:     Epoch: 69
2022-12-05 21:41:31,587 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47034131633964454, 'Total loss': 0.47034131633964454} | train loss {'Reaction outcome loss': 0.1351066254155224, 'Total loss': 0.1351066254155224}
2022-12-05 21:41:31,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:31,587 INFO:     Epoch: 70
2022-12-05 21:41:32,383 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4715513637797399, 'Total loss': 0.4715513637797399} | train loss {'Reaction outcome loss': 0.13365940646803845, 'Total loss': 0.13365940646803845}
2022-12-05 21:41:32,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:32,383 INFO:     Epoch: 71
2022-12-05 21:41:33,183 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4753032655201175, 'Total loss': 0.4753032655201175} | train loss {'Reaction outcome loss': 0.13155553489145805, 'Total loss': 0.13155553489145805}
2022-12-05 21:41:33,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:33,184 INFO:     Epoch: 72
2022-12-05 21:41:33,979 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47859103537418624, 'Total loss': 0.47859103537418624} | train loss {'Reaction outcome loss': 0.13052419498836176, 'Total loss': 0.13052419498836176}
2022-12-05 21:41:33,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:33,979 INFO:     Epoch: 73
2022-12-05 21:41:34,773 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.478298598731106, 'Total loss': 0.478298598731106} | train loss {'Reaction outcome loss': 0.1278504668848084, 'Total loss': 0.1278504668848084}
2022-12-05 21:41:34,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:34,773 INFO:     Epoch: 74
2022-12-05 21:41:35,568 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47091305391354993, 'Total loss': 0.47091305391354993} | train loss {'Reaction outcome loss': 0.13182450963659326, 'Total loss': 0.13182450963659326}
2022-12-05 21:41:35,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:35,568 INFO:     Epoch: 75
2022-12-05 21:41:36,364 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4720818220891736, 'Total loss': 0.4720818220891736} | train loss {'Reaction outcome loss': 0.13041493271643423, 'Total loss': 0.13041493271643423}
2022-12-05 21:41:36,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:36,365 INFO:     Epoch: 76
2022-12-05 21:41:37,162 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48961365908722987, 'Total loss': 0.48961365908722987} | train loss {'Reaction outcome loss': 0.12555615951602633, 'Total loss': 0.12555615951602633}
2022-12-05 21:41:37,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:37,162 INFO:     Epoch: 77
2022-12-05 21:41:37,957 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4775210028006272, 'Total loss': 0.4775210028006272} | train loss {'Reaction outcome loss': 0.12833454146196968, 'Total loss': 0.12833454146196968}
2022-12-05 21:41:37,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:37,957 INFO:     Epoch: 78
2022-12-05 21:41:38,752 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48759383674372325, 'Total loss': 0.48759383674372325} | train loss {'Reaction outcome loss': 0.13094806455467878, 'Total loss': 0.13094806455467878}
2022-12-05 21:41:38,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:38,752 INFO:     Epoch: 79
2022-12-05 21:41:39,545 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4880120645869862, 'Total loss': 0.4880120645869862} | train loss {'Reaction outcome loss': 0.13471113745997912, 'Total loss': 0.13471113745997912}
2022-12-05 21:41:39,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:39,545 INFO:     Epoch: 80
2022-12-05 21:41:40,343 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49132205004041846, 'Total loss': 0.49132205004041846} | train loss {'Reaction outcome loss': 0.13137296771985074, 'Total loss': 0.13137296771985074}
2022-12-05 21:41:40,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:40,344 INFO:     Epoch: 81
2022-12-05 21:41:41,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47463701699267735, 'Total loss': 0.47463701699267735} | train loss {'Reaction outcome loss': 0.130730459125343, 'Total loss': 0.130730459125343}
2022-12-05 21:41:41,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:41,139 INFO:     Epoch: 82
2022-12-05 21:41:41,938 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48150515217672696, 'Total loss': 0.48150515217672696} | train loss {'Reaction outcome loss': 0.1285199425390616, 'Total loss': 0.1285199425390616}
2022-12-05 21:41:41,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:41,938 INFO:     Epoch: 83
2022-12-05 21:41:42,734 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48128686574372376, 'Total loss': 0.48128686574372376} | train loss {'Reaction outcome loss': 0.1262578540123426, 'Total loss': 0.1262578540123426}
2022-12-05 21:41:42,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:42,734 INFO:     Epoch: 84
2022-12-05 21:41:43,527 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4824883125045083, 'Total loss': 0.4824883125045083} | train loss {'Reaction outcome loss': 0.13321693522878264, 'Total loss': 0.13321693522878264}
2022-12-05 21:41:43,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:43,527 INFO:     Epoch: 85
2022-12-05 21:41:44,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4903806068680503, 'Total loss': 0.4903806068680503} | train loss {'Reaction outcome loss': 0.13520603324192376, 'Total loss': 0.13520603324192376}
2022-12-05 21:41:44,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:44,321 INFO:     Epoch: 86
2022-12-05 21:41:45,117 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48473977246745065, 'Total loss': 0.48473977246745065} | train loss {'Reaction outcome loss': 0.12235362389075913, 'Total loss': 0.12235362389075913}
2022-12-05 21:41:45,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:45,118 INFO:     Epoch: 87
2022-12-05 21:41:45,914 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46353663453324273, 'Total loss': 0.46353663453324273} | train loss {'Reaction outcome loss': 0.12179026410534133, 'Total loss': 0.12179026410534133}
2022-12-05 21:41:45,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:45,915 INFO:     Epoch: 88
2022-12-05 21:41:46,710 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48107661510055716, 'Total loss': 0.48107661510055716} | train loss {'Reaction outcome loss': 0.12131243054227157, 'Total loss': 0.12131243054227157}
2022-12-05 21:41:46,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:46,710 INFO:     Epoch: 89
2022-12-05 21:41:47,507 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4775472510267388, 'Total loss': 0.4775472510267388} | train loss {'Reaction outcome loss': 0.12501031939347504, 'Total loss': 0.12501031939347504}
2022-12-05 21:41:47,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:47,507 INFO:     Epoch: 90
2022-12-05 21:41:48,301 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49786627055569127, 'Total loss': 0.49786627055569127} | train loss {'Reaction outcome loss': 0.12433357451955679, 'Total loss': 0.12433357451955679}
2022-12-05 21:41:48,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:48,302 INFO:     Epoch: 91
2022-12-05 21:41:49,097 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.495687730779702, 'Total loss': 0.495687730779702} | train loss {'Reaction outcome loss': 0.11958048212142126, 'Total loss': 0.11958048212142126}
2022-12-05 21:41:49,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:49,097 INFO:     Epoch: 92
2022-12-05 21:41:49,895 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47112600979479874, 'Total loss': 0.47112600979479874} | train loss {'Reaction outcome loss': 0.12275562167397666, 'Total loss': 0.12275562167397666}
2022-12-05 21:41:49,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:49,895 INFO:     Epoch: 93
2022-12-05 21:41:50,692 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47406529846855183, 'Total loss': 0.47406529846855183} | train loss {'Reaction outcome loss': 0.12324960915907192, 'Total loss': 0.12324960915907192}
2022-12-05 21:41:50,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:50,692 INFO:     Epoch: 94
2022-12-05 21:41:51,490 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4858740354803475, 'Total loss': 0.4858740354803475} | train loss {'Reaction outcome loss': 0.1269183021702385, 'Total loss': 0.1269183021702385}
2022-12-05 21:41:51,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:51,491 INFO:     Epoch: 95
2022-12-05 21:41:52,285 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47218188880519435, 'Total loss': 0.47218188880519435} | train loss {'Reaction outcome loss': 0.12059152525612096, 'Total loss': 0.12059152525612096}
2022-12-05 21:41:52,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:52,286 INFO:     Epoch: 96
2022-12-05 21:41:53,080 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4928084466267716, 'Total loss': 0.4928084466267716} | train loss {'Reaction outcome loss': 0.1227279346575772, 'Total loss': 0.1227279346575772}
2022-12-05 21:41:53,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:53,080 INFO:     Epoch: 97
2022-12-05 21:41:53,876 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48405913212759927, 'Total loss': 0.48405913212759927} | train loss {'Reaction outcome loss': 0.11834507769346991, 'Total loss': 0.11834507769346991}
2022-12-05 21:41:53,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:53,877 INFO:     Epoch: 98
2022-12-05 21:41:54,670 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4644591784612699, 'Total loss': 0.4644591784612699} | train loss {'Reaction outcome loss': 0.1215687746800452, 'Total loss': 0.1215687746800452}
2022-12-05 21:41:54,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:54,670 INFO:     Epoch: 99
2022-12-05 21:41:55,464 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48269788040356204, 'Total loss': 0.48269788040356204} | train loss {'Reaction outcome loss': 0.12155746252887302, 'Total loss': 0.12155746252887302}
2022-12-05 21:41:55,464 INFO:     Best model found after epoch 9 of 100.
2022-12-05 21:41:55,464 INFO:   Done with stage: TRAINING
2022-12-05 21:41:55,465 INFO:   Starting stage: EVALUATION
2022-12-05 21:41:55,590 INFO:   Done with stage: EVALUATION
2022-12-05 21:41:55,590 INFO:   Leaving out SEQ value Fold_6
2022-12-05 21:41:55,603 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:41:55,603 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:41:56,257 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:41:56,257 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:41:56,327 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:41:56,327 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:41:56,327 INFO:     No hyperparam tuning for this model
2022-12-05 21:41:56,327 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:41:56,327 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:41:56,328 INFO:     None feature selector for col prot
2022-12-05 21:41:56,328 INFO:     None feature selector for col prot
2022-12-05 21:41:56,328 INFO:     None feature selector for col prot
2022-12-05 21:41:56,328 INFO:     None feature selector for col chem
2022-12-05 21:41:56,329 INFO:     None feature selector for col chem
2022-12-05 21:41:56,329 INFO:     None feature selector for col chem
2022-12-05 21:41:56,329 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:41:56,329 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:41:56,330 INFO:     Number of params in model 215821
2022-12-05 21:41:56,334 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:41:56,334 INFO:   Starting stage: TRAINING
2022-12-05 21:41:56,395 INFO:     Val loss before train {'Reaction outcome loss': 1.0188711407509716, 'Total loss': 1.0188711407509716}
2022-12-05 21:41:56,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:56,395 INFO:     Epoch: 0
2022-12-05 21:41:57,198 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5906563360582698, 'Total loss': 0.5906563360582698} | train loss {'Reaction outcome loss': 0.7915933861607506, 'Total loss': 0.7915933861607506}
2022-12-05 21:41:57,198 INFO:     Found new best model at epoch 0
2022-12-05 21:41:57,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:57,199 INFO:     Epoch: 1
2022-12-05 21:41:57,993 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5196080289103768, 'Total loss': 0.5196080289103768} | train loss {'Reaction outcome loss': 0.540883949507148, 'Total loss': 0.540883949507148}
2022-12-05 21:41:57,993 INFO:     Found new best model at epoch 1
2022-12-05 21:41:57,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:57,994 INFO:     Epoch: 2
2022-12-05 21:41:58,789 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48610567166046664, 'Total loss': 0.48610567166046664} | train loss {'Reaction outcome loss': 0.47352988236854154, 'Total loss': 0.47352988236854154}
2022-12-05 21:41:58,789 INFO:     Found new best model at epoch 2
2022-12-05 21:41:58,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:58,790 INFO:     Epoch: 3
2022-12-05 21:41:59,587 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4576616067100655, 'Total loss': 0.4576616067100655} | train loss {'Reaction outcome loss': 0.43483394997254493, 'Total loss': 0.43483394997254493}
2022-12-05 21:41:59,587 INFO:     Found new best model at epoch 3
2022-12-05 21:41:59,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:41:59,588 INFO:     Epoch: 4
2022-12-05 21:42:00,388 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44433987377719447, 'Total loss': 0.44433987377719447} | train loss {'Reaction outcome loss': 0.4037346372440938, 'Total loss': 0.4037346372440938}
2022-12-05 21:42:00,388 INFO:     Found new best model at epoch 4
2022-12-05 21:42:00,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:00,389 INFO:     Epoch: 5
2022-12-05 21:42:01,184 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44111742959781125, 'Total loss': 0.44111742959781125} | train loss {'Reaction outcome loss': 0.3832062931671258, 'Total loss': 0.3832062931671258}
2022-12-05 21:42:01,184 INFO:     Found new best model at epoch 5
2022-12-05 21:42:01,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:01,185 INFO:     Epoch: 6
2022-12-05 21:42:01,980 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4491708188910376, 'Total loss': 0.4491708188910376} | train loss {'Reaction outcome loss': 0.3621023516921747, 'Total loss': 0.3621023516921747}
2022-12-05 21:42:01,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:01,981 INFO:     Epoch: 7
2022-12-05 21:42:02,781 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4222228527069092, 'Total loss': 0.4222228527069092} | train loss {'Reaction outcome loss': 0.3455759326536809, 'Total loss': 0.3455759326536809}
2022-12-05 21:42:02,781 INFO:     Found new best model at epoch 7
2022-12-05 21:42:02,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:02,782 INFO:     Epoch: 8
2022-12-05 21:42:03,577 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4278989525681192, 'Total loss': 0.4278989525681192} | train loss {'Reaction outcome loss': 0.3274139583771748, 'Total loss': 0.3274139583771748}
2022-12-05 21:42:03,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:03,578 INFO:     Epoch: 9
2022-12-05 21:42:04,373 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4324114566499537, 'Total loss': 0.4324114566499537} | train loss {'Reaction outcome loss': 0.3183546685763905, 'Total loss': 0.3183546685763905}
2022-12-05 21:42:04,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:04,373 INFO:     Epoch: 10
2022-12-05 21:42:05,168 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4185651605102149, 'Total loss': 0.4185651605102149} | train loss {'Reaction outcome loss': 0.30455093555933527, 'Total loss': 0.30455093555933527}
2022-12-05 21:42:05,168 INFO:     Found new best model at epoch 10
2022-12-05 21:42:05,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:05,169 INFO:     Epoch: 11
2022-12-05 21:42:05,963 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4475642510435798, 'Total loss': 0.4475642510435798} | train loss {'Reaction outcome loss': 0.29140346109746923, 'Total loss': 0.29140346109746923}
2022-12-05 21:42:05,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:05,963 INFO:     Epoch: 12
2022-12-05 21:42:06,764 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43672324446114624, 'Total loss': 0.43672324446114624} | train loss {'Reaction outcome loss': 0.28303118186792536, 'Total loss': 0.28303118186792536}
2022-12-05 21:42:06,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:06,764 INFO:     Epoch: 13
2022-12-05 21:42:07,565 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4293105923994021, 'Total loss': 0.4293105923994021} | train loss {'Reaction outcome loss': 0.27274704015543383, 'Total loss': 0.27274704015543383}
2022-12-05 21:42:07,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:07,565 INFO:     Epoch: 14
2022-12-05 21:42:08,369 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4241428039968014, 'Total loss': 0.4241428039968014} | train loss {'Reaction outcome loss': 0.26359107117018393, 'Total loss': 0.26359107117018393}
2022-12-05 21:42:08,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:08,369 INFO:     Epoch: 15
2022-12-05 21:42:09,166 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4336990419436585, 'Total loss': 0.4336990419436585} | train loss {'Reaction outcome loss': 0.25796294790662583, 'Total loss': 0.25796294790662583}
2022-12-05 21:42:09,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:09,166 INFO:     Epoch: 16
2022-12-05 21:42:09,962 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4308783147822727, 'Total loss': 0.4308783147822727} | train loss {'Reaction outcome loss': 0.2507740084021803, 'Total loss': 0.2507740084021803}
2022-12-05 21:42:09,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:09,962 INFO:     Epoch: 17
2022-12-05 21:42:10,761 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44771820069714025, 'Total loss': 0.44771820069714025} | train loss {'Reaction outcome loss': 0.24581656058228785, 'Total loss': 0.24581656058228785}
2022-12-05 21:42:10,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:10,761 INFO:     Epoch: 18
2022-12-05 21:42:11,560 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44876195287162607, 'Total loss': 0.44876195287162607} | train loss {'Reaction outcome loss': 0.23648267819155608, 'Total loss': 0.23648267819155608}
2022-12-05 21:42:11,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:11,560 INFO:     Epoch: 19
2022-12-05 21:42:12,364 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4465014985339208, 'Total loss': 0.4465014985339208} | train loss {'Reaction outcome loss': 0.23224023576345174, 'Total loss': 0.23224023576345174}
2022-12-05 21:42:12,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:12,364 INFO:     Epoch: 20
2022-12-05 21:42:13,163 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4380209439180114, 'Total loss': 0.4380209439180114} | train loss {'Reaction outcome loss': 0.2272562372438129, 'Total loss': 0.2272562372438129}
2022-12-05 21:42:13,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:13,163 INFO:     Epoch: 21
2022-12-05 21:42:13,962 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44179168106480077, 'Total loss': 0.44179168106480077} | train loss {'Reaction outcome loss': 0.2208897105658487, 'Total loss': 0.2208897105658487}
2022-12-05 21:42:13,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:13,963 INFO:     Epoch: 22
2022-12-05 21:42:14,758 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4341738180003383, 'Total loss': 0.4341738180003383} | train loss {'Reaction outcome loss': 0.21759934504065784, 'Total loss': 0.21759934504065784}
2022-12-05 21:42:14,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:14,759 INFO:     Epoch: 23
2022-12-05 21:42:15,554 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4359605051577091, 'Total loss': 0.4359605051577091} | train loss {'Reaction outcome loss': 0.2127864631493726, 'Total loss': 0.2127864631493726}
2022-12-05 21:42:15,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:15,554 INFO:     Epoch: 24
2022-12-05 21:42:16,345 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4504719054834409, 'Total loss': 0.4504719054834409} | train loss {'Reaction outcome loss': 0.2089741070935082, 'Total loss': 0.2089741070935082}
2022-12-05 21:42:16,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:16,346 INFO:     Epoch: 25
2022-12-05 21:42:17,138 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.427350223233754, 'Total loss': 0.427350223233754} | train loss {'Reaction outcome loss': 0.20197069588597985, 'Total loss': 0.20197069588597985}
2022-12-05 21:42:17,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:17,138 INFO:     Epoch: 26
2022-12-05 21:42:17,931 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43663327023386955, 'Total loss': 0.43663327023386955} | train loss {'Reaction outcome loss': 0.20083208951438147, 'Total loss': 0.20083208951438147}
2022-12-05 21:42:17,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:17,931 INFO:     Epoch: 27
2022-12-05 21:42:18,729 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44119504365054046, 'Total loss': 0.44119504365054046} | train loss {'Reaction outcome loss': 0.2002464286201904, 'Total loss': 0.2002464286201904}
2022-12-05 21:42:18,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:18,729 INFO:     Epoch: 28
2022-12-05 21:42:19,526 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4605504003438083, 'Total loss': 0.4605504003438083} | train loss {'Reaction outcome loss': 0.1965769796121505, 'Total loss': 0.1965769796121505}
2022-12-05 21:42:19,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:19,526 INFO:     Epoch: 29
2022-12-05 21:42:20,321 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46170216697183525, 'Total loss': 0.46170216697183525} | train loss {'Reaction outcome loss': 0.1943700689401838, 'Total loss': 0.1943700689401838}
2022-12-05 21:42:20,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:20,322 INFO:     Epoch: 30
2022-12-05 21:42:21,119 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43924453583630646, 'Total loss': 0.43924453583630646} | train loss {'Reaction outcome loss': 0.1899765499326731, 'Total loss': 0.1899765499326731}
2022-12-05 21:42:21,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:21,120 INFO:     Epoch: 31
2022-12-05 21:42:21,910 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46624532071026886, 'Total loss': 0.46624532071026886} | train loss {'Reaction outcome loss': 0.1856609275864978, 'Total loss': 0.1856609275864978}
2022-12-05 21:42:21,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:21,910 INFO:     Epoch: 32
2022-12-05 21:42:22,705 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4404880912466483, 'Total loss': 0.4404880912466483} | train loss {'Reaction outcome loss': 0.18297683065306516, 'Total loss': 0.18297683065306516}
2022-12-05 21:42:22,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:22,706 INFO:     Epoch: 33
2022-12-05 21:42:23,496 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.457028482447971, 'Total loss': 0.457028482447971} | train loss {'Reaction outcome loss': 0.1804751793012744, 'Total loss': 0.1804751793012744}
2022-12-05 21:42:23,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:23,496 INFO:     Epoch: 34
2022-12-05 21:42:24,287 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4452500580386682, 'Total loss': 0.4452500580386682} | train loss {'Reaction outcome loss': 0.17797109412570153, 'Total loss': 0.17797109412570153}
2022-12-05 21:42:24,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:24,287 INFO:     Epoch: 35
2022-12-05 21:42:25,078 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4511925842274319, 'Total loss': 0.4511925842274319} | train loss {'Reaction outcome loss': 0.17823561232897542, 'Total loss': 0.17823561232897542}
2022-12-05 21:42:25,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:25,078 INFO:     Epoch: 36
2022-12-05 21:42:25,869 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.441993561996655, 'Total loss': 0.441993561996655} | train loss {'Reaction outcome loss': 0.17486655729402217, 'Total loss': 0.17486655729402217}
2022-12-05 21:42:25,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:25,870 INFO:     Epoch: 37
2022-12-05 21:42:26,664 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45267772539095447, 'Total loss': 0.45267772539095447} | train loss {'Reaction outcome loss': 0.16900488929522614, 'Total loss': 0.16900488929522614}
2022-12-05 21:42:26,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:26,664 INFO:     Epoch: 38
2022-12-05 21:42:27,455 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4560113970867612, 'Total loss': 0.4560113970867612} | train loss {'Reaction outcome loss': 0.1707593744861022, 'Total loss': 0.1707593744861022}
2022-12-05 21:42:27,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:27,456 INFO:     Epoch: 39
2022-12-05 21:42:28,252 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45116046054119413, 'Total loss': 0.45116046054119413} | train loss {'Reaction outcome loss': 0.17043277157110073, 'Total loss': 0.17043277157110073}
2022-12-05 21:42:28,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:28,253 INFO:     Epoch: 40
2022-12-05 21:42:29,051 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4538575925610282, 'Total loss': 0.4538575925610282} | train loss {'Reaction outcome loss': 0.1664243900863033, 'Total loss': 0.1664243900863033}
2022-12-05 21:42:29,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:29,051 INFO:     Epoch: 41
2022-12-05 21:42:29,842 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46449399096044625, 'Total loss': 0.46449399096044625} | train loss {'Reaction outcome loss': 0.16600217643914925, 'Total loss': 0.16600217643914925}
2022-12-05 21:42:29,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:29,842 INFO:     Epoch: 42
2022-12-05 21:42:30,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4490012167529626, 'Total loss': 0.4490012167529626} | train loss {'Reaction outcome loss': 0.1646541465344208, 'Total loss': 0.1646541465344208}
2022-12-05 21:42:30,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:30,633 INFO:     Epoch: 43
2022-12-05 21:42:31,426 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45527780191464856, 'Total loss': 0.45527780191464856} | train loss {'Reaction outcome loss': 0.16056437205312954, 'Total loss': 0.16056437205312954}
2022-12-05 21:42:31,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:31,426 INFO:     Epoch: 44
2022-12-05 21:42:32,221 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44002956727688963, 'Total loss': 0.44002956727688963} | train loss {'Reaction outcome loss': 0.16075675648396776, 'Total loss': 0.16075675648396776}
2022-12-05 21:42:32,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:32,222 INFO:     Epoch: 45
2022-12-05 21:42:33,014 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4431731497699564, 'Total loss': 0.4431731497699564} | train loss {'Reaction outcome loss': 0.15766535668949327, 'Total loss': 0.15766535668949327}
2022-12-05 21:42:33,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:33,014 INFO:     Epoch: 46
2022-12-05 21:42:33,807 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4449324943125248, 'Total loss': 0.4449324943125248} | train loss {'Reaction outcome loss': 0.15827687006939442, 'Total loss': 0.15827687006939442}
2022-12-05 21:42:33,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:33,807 INFO:     Epoch: 47
2022-12-05 21:42:34,601 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4696987481279807, 'Total loss': 0.4696987481279807} | train loss {'Reaction outcome loss': 0.1563411020193129, 'Total loss': 0.1563411020193129}
2022-12-05 21:42:34,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:34,602 INFO:     Epoch: 48
2022-12-05 21:42:35,400 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49427383596246893, 'Total loss': 0.49427383596246893} | train loss {'Reaction outcome loss': 0.1565061559930684, 'Total loss': 0.1565061559930684}
2022-12-05 21:42:35,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:35,401 INFO:     Epoch: 49
2022-12-05 21:42:36,192 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4441518316214735, 'Total loss': 0.4441518316214735} | train loss {'Reaction outcome loss': 0.1564386050186811, 'Total loss': 0.1564386050186811}
2022-12-05 21:42:36,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:36,192 INFO:     Epoch: 50
2022-12-05 21:42:36,985 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44114285842938855, 'Total loss': 0.44114285842938855} | train loss {'Reaction outcome loss': 0.15306267463001272, 'Total loss': 0.15306267463001272}
2022-12-05 21:42:36,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:36,986 INFO:     Epoch: 51
2022-12-05 21:42:37,776 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4776660105721517, 'Total loss': 0.4776660105721517} | train loss {'Reaction outcome loss': 0.1507880579935567, 'Total loss': 0.1507880579935567}
2022-12-05 21:42:37,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:37,776 INFO:     Epoch: 52
2022-12-05 21:42:38,566 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4613551036878066, 'Total loss': 0.4613551036878066} | train loss {'Reaction outcome loss': 0.1514540309867551, 'Total loss': 0.1514540309867551}
2022-12-05 21:42:38,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:38,566 INFO:     Epoch: 53
2022-12-05 21:42:39,361 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46823177114129066, 'Total loss': 0.46823177114129066} | train loss {'Reaction outcome loss': 0.14922881182733802, 'Total loss': 0.14922881182733802}
2022-12-05 21:42:39,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:39,361 INFO:     Epoch: 54
2022-12-05 21:42:40,159 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44648712094534526, 'Total loss': 0.44648712094534526} | train loss {'Reaction outcome loss': 0.1471489432958826, 'Total loss': 0.1471489432958826}
2022-12-05 21:42:40,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:40,159 INFO:     Epoch: 55
2022-12-05 21:42:40,957 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45008630948987877, 'Total loss': 0.45008630948987877} | train loss {'Reaction outcome loss': 0.14641259819449437, 'Total loss': 0.14641259819449437}
2022-12-05 21:42:40,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:40,957 INFO:     Epoch: 56
2022-12-05 21:42:41,752 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4721995449878953, 'Total loss': 0.4721995449878953} | train loss {'Reaction outcome loss': 0.14709253180321427, 'Total loss': 0.14709253180321427}
2022-12-05 21:42:41,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:41,752 INFO:     Epoch: 57
2022-12-05 21:42:42,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.453916216946461, 'Total loss': 0.453916216946461} | train loss {'Reaction outcome loss': 0.1479643552841979, 'Total loss': 0.1479643552841979}
2022-12-05 21:42:42,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:42,544 INFO:     Epoch: 58
2022-12-05 21:42:43,341 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4720685349946672, 'Total loss': 0.4720685349946672} | train loss {'Reaction outcome loss': 0.14318947763662906, 'Total loss': 0.14318947763662906}
2022-12-05 21:42:43,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:43,341 INFO:     Epoch: 59
2022-12-05 21:42:44,133 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45711668174375186, 'Total loss': 0.45711668174375186} | train loss {'Reaction outcome loss': 0.14021252987966423, 'Total loss': 0.14021252987966423}
2022-12-05 21:42:44,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:44,133 INFO:     Epoch: 60
2022-12-05 21:42:44,924 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4617240537296642, 'Total loss': 0.4617240537296642} | train loss {'Reaction outcome loss': 0.14262939861134416, 'Total loss': 0.14262939861134416}
2022-12-05 21:42:44,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:44,925 INFO:     Epoch: 61
2022-12-05 21:42:45,718 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45739318057894707, 'Total loss': 0.45739318057894707} | train loss {'Reaction outcome loss': 0.14036463379799838, 'Total loss': 0.14036463379799838}
2022-12-05 21:42:45,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:45,718 INFO:     Epoch: 62
2022-12-05 21:42:46,516 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4483747976747426, 'Total loss': 0.4483747976747426} | train loss {'Reaction outcome loss': 0.13822426379568153, 'Total loss': 0.13822426379568153}
2022-12-05 21:42:46,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:46,516 INFO:     Epoch: 63
2022-12-05 21:42:47,308 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4633783081715757, 'Total loss': 0.4633783081715757} | train loss {'Reaction outcome loss': 0.13902629054932586, 'Total loss': 0.13902629054932586}
2022-12-05 21:42:47,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:47,309 INFO:     Epoch: 64
2022-12-05 21:42:48,102 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4672826223752715, 'Total loss': 0.4672826223752715} | train loss {'Reaction outcome loss': 0.14049752483955555, 'Total loss': 0.14049752483955555}
2022-12-05 21:42:48,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:48,102 INFO:     Epoch: 65
2022-12-05 21:42:48,901 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4581613814966245, 'Total loss': 0.4581613814966245} | train loss {'Reaction outcome loss': 0.13838835768101196, 'Total loss': 0.13838835768101196}
2022-12-05 21:42:48,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:48,901 INFO:     Epoch: 66
2022-12-05 21:42:49,695 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4665481062097983, 'Total loss': 0.4665481062097983} | train loss {'Reaction outcome loss': 0.13823697331827134, 'Total loss': 0.13823697331827134}
2022-12-05 21:42:49,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:49,696 INFO:     Epoch: 67
2022-12-05 21:42:50,487 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4806261898272417, 'Total loss': 0.4806261898272417} | train loss {'Reaction outcome loss': 0.13586525988930295, 'Total loss': 0.13586525988930295}
2022-12-05 21:42:50,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:50,487 INFO:     Epoch: 68
2022-12-05 21:42:51,278 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46116127784956584, 'Total loss': 0.46116127784956584} | train loss {'Reaction outcome loss': 0.13412623275672236, 'Total loss': 0.13412623275672236}
2022-12-05 21:42:51,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:51,279 INFO:     Epoch: 69
2022-12-05 21:42:52,075 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46367473392324016, 'Total loss': 0.46367473392324016} | train loss {'Reaction outcome loss': 0.13648600619466555, 'Total loss': 0.13648600619466555}
2022-12-05 21:42:52,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:52,075 INFO:     Epoch: 70
2022-12-05 21:42:52,875 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4724787456745451, 'Total loss': 0.4724787456745451} | train loss {'Reaction outcome loss': 0.1345225580021619, 'Total loss': 0.1345225580021619}
2022-12-05 21:42:52,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:52,875 INFO:     Epoch: 71
2022-12-05 21:42:53,673 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47390928356484935, 'Total loss': 0.47390928356484935} | train loss {'Reaction outcome loss': 0.136024507960575, 'Total loss': 0.136024507960575}
2022-12-05 21:42:53,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:53,674 INFO:     Epoch: 72
2022-12-05 21:42:54,469 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4603193351490931, 'Total loss': 0.4603193351490931} | train loss {'Reaction outcome loss': 0.13350575528438052, 'Total loss': 0.13350575528438052}
2022-12-05 21:42:54,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:54,469 INFO:     Epoch: 73
2022-12-05 21:42:55,261 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4776305326006629, 'Total loss': 0.4776305326006629} | train loss {'Reaction outcome loss': 0.13541961379063827, 'Total loss': 0.13541961379063827}
2022-12-05 21:42:55,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:55,261 INFO:     Epoch: 74
2022-12-05 21:42:56,055 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46673676473173226, 'Total loss': 0.46673676473173226} | train loss {'Reaction outcome loss': 0.13369698585536813, 'Total loss': 0.13369698585536813}
2022-12-05 21:42:56,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:56,056 INFO:     Epoch: 75
2022-12-05 21:42:56,848 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46756166558374057, 'Total loss': 0.46756166558374057} | train loss {'Reaction outcome loss': 0.1324152102498638, 'Total loss': 0.1324152102498638}
2022-12-05 21:42:56,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:56,848 INFO:     Epoch: 76
2022-12-05 21:42:57,643 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47511308335445146, 'Total loss': 0.47511308335445146} | train loss {'Reaction outcome loss': 0.128138184453541, 'Total loss': 0.128138184453541}
2022-12-05 21:42:57,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:57,643 INFO:     Epoch: 77
2022-12-05 21:42:58,437 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45407284288243815, 'Total loss': 0.45407284288243815} | train loss {'Reaction outcome loss': 0.13027025402087958, 'Total loss': 0.13027025402087958}
2022-12-05 21:42:58,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:58,437 INFO:     Epoch: 78
2022-12-05 21:42:59,229 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.464031539180062, 'Total loss': 0.464031539180062} | train loss {'Reaction outcome loss': 0.12880260905160779, 'Total loss': 0.12880260905160779}
2022-12-05 21:42:59,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:42:59,229 INFO:     Epoch: 79
2022-12-05 21:43:00,023 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4674917832016945, 'Total loss': 0.4674917832016945} | train loss {'Reaction outcome loss': 0.1286802175191922, 'Total loss': 0.1286802175191922}
2022-12-05 21:43:00,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:00,023 INFO:     Epoch: 80
2022-12-05 21:43:00,819 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4476930553262884, 'Total loss': 0.4476930553262884} | train loss {'Reaction outcome loss': 0.13087551816246443, 'Total loss': 0.13087551816246443}
2022-12-05 21:43:00,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:00,820 INFO:     Epoch: 81
2022-12-05 21:43:01,613 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4784201251512224, 'Total loss': 0.4784201251512224} | train loss {'Reaction outcome loss': 0.12755572475538018, 'Total loss': 0.12755572475538018}
2022-12-05 21:43:01,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:01,613 INFO:     Epoch: 82
2022-12-05 21:43:02,410 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4663992886516181, 'Total loss': 0.4663992886516181} | train loss {'Reaction outcome loss': 0.12810652880298515, 'Total loss': 0.12810652880298515}
2022-12-05 21:43:02,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:02,411 INFO:     Epoch: 83
2022-12-05 21:43:03,209 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47152536210011353, 'Total loss': 0.47152536210011353} | train loss {'Reaction outcome loss': 0.12699575367714128, 'Total loss': 0.12699575367714128}
2022-12-05 21:43:03,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:03,210 INFO:     Epoch: 84
2022-12-05 21:43:04,008 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4720363942059604, 'Total loss': 0.4720363942059604} | train loss {'Reaction outcome loss': 0.12391761264147898, 'Total loss': 0.12391761264147898}
2022-12-05 21:43:04,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:04,008 INFO:     Epoch: 85
2022-12-05 21:43:04,804 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4497483516619964, 'Total loss': 0.4497483516619964} | train loss {'Reaction outcome loss': 0.12539755507943132, 'Total loss': 0.12539755507943132}
2022-12-05 21:43:04,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:04,804 INFO:     Epoch: 86
2022-12-05 21:43:05,604 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45915870571678336, 'Total loss': 0.45915870571678336} | train loss {'Reaction outcome loss': 0.1234092002531754, 'Total loss': 0.1234092002531754}
2022-12-05 21:43:05,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:05,604 INFO:     Epoch: 87
2022-12-05 21:43:06,402 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4619469703598456, 'Total loss': 0.4619469703598456} | train loss {'Reaction outcome loss': 0.12574315584459972, 'Total loss': 0.12574315584459972}
2022-12-05 21:43:06,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:06,403 INFO:     Epoch: 88
2022-12-05 21:43:07,195 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4607306508855386, 'Total loss': 0.4607306508855386} | train loss {'Reaction outcome loss': 0.12407369827551226, 'Total loss': 0.12407369827551226}
2022-12-05 21:43:07,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:07,196 INFO:     Epoch: 89
2022-12-05 21:43:07,987 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.489098248495297, 'Total loss': 0.489098248495297} | train loss {'Reaction outcome loss': 0.12523876968020153, 'Total loss': 0.12523876968020153}
2022-12-05 21:43:07,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:07,987 INFO:     Epoch: 90
2022-12-05 21:43:08,789 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4726323275403543, 'Total loss': 0.4726323275403543} | train loss {'Reaction outcome loss': 0.12473199699607287, 'Total loss': 0.12473199699607287}
2022-12-05 21:43:08,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:08,789 INFO:     Epoch: 91
2022-12-05 21:43:09,583 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.454054594039917, 'Total loss': 0.454054594039917} | train loss {'Reaction outcome loss': 0.1233531996615291, 'Total loss': 0.1233531996615291}
2022-12-05 21:43:09,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:09,584 INFO:     Epoch: 92
2022-12-05 21:43:10,378 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4626872041686015, 'Total loss': 0.4626872041686015} | train loss {'Reaction outcome loss': 0.12165256340297, 'Total loss': 0.12165256340297}
2022-12-05 21:43:10,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:10,379 INFO:     Epoch: 93
2022-12-05 21:43:11,173 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46607929408888926, 'Total loss': 0.46607929408888926} | train loss {'Reaction outcome loss': 0.12369613492891433, 'Total loss': 0.12369613492891433}
2022-12-05 21:43:11,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:11,173 INFO:     Epoch: 94
2022-12-05 21:43:11,971 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4545967314730991, 'Total loss': 0.4545967314730991} | train loss {'Reaction outcome loss': 0.12218454415579477, 'Total loss': 0.12218454415579477}
2022-12-05 21:43:11,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:11,971 INFO:     Epoch: 95
2022-12-05 21:43:12,764 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44785371964628046, 'Total loss': 0.44785371964628046} | train loss {'Reaction outcome loss': 0.12196602732611579, 'Total loss': 0.12196602732611579}
2022-12-05 21:43:12,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:12,764 INFO:     Epoch: 96
2022-12-05 21:43:13,556 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45023456486788666, 'Total loss': 0.45023456486788666} | train loss {'Reaction outcome loss': 0.12016671021363788, 'Total loss': 0.12016671021363788}
2022-12-05 21:43:13,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:13,556 INFO:     Epoch: 97
2022-12-05 21:43:14,350 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.465617893433029, 'Total loss': 0.465617893433029} | train loss {'Reaction outcome loss': 0.12038269390036622, 'Total loss': 0.12038269390036622}
2022-12-05 21:43:14,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:14,350 INFO:     Epoch: 98
2022-12-05 21:43:15,142 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4428606866435571, 'Total loss': 0.4428606866435571} | train loss {'Reaction outcome loss': 0.11941732053885297, 'Total loss': 0.11941732053885297}
2022-12-05 21:43:15,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:15,142 INFO:     Epoch: 99
2022-12-05 21:43:15,936 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45595341988585214, 'Total loss': 0.45595341988585214} | train loss {'Reaction outcome loss': 0.12093315742188884, 'Total loss': 0.12093315742188884}
2022-12-05 21:43:15,936 INFO:     Best model found after epoch 11 of 100.
2022-12-05 21:43:15,936 INFO:   Done with stage: TRAINING
2022-12-05 21:43:15,936 INFO:   Starting stage: EVALUATION
2022-12-05 21:43:16,056 INFO:   Done with stage: EVALUATION
2022-12-05 21:43:16,056 INFO:   Leaving out SEQ value Fold_7
2022-12-05 21:43:16,070 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:43:16,070 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:43:16,717 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:43:16,717 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:43:16,787 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:43:16,787 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:43:16,787 INFO:     No hyperparam tuning for this model
2022-12-05 21:43:16,787 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:43:16,787 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:43:16,788 INFO:     None feature selector for col prot
2022-12-05 21:43:16,788 INFO:     None feature selector for col prot
2022-12-05 21:43:16,788 INFO:     None feature selector for col prot
2022-12-05 21:43:16,788 INFO:     None feature selector for col chem
2022-12-05 21:43:16,788 INFO:     None feature selector for col chem
2022-12-05 21:43:16,789 INFO:     None feature selector for col chem
2022-12-05 21:43:16,789 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:43:16,789 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:43:16,790 INFO:     Number of params in model 215821
2022-12-05 21:43:16,793 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:43:16,794 INFO:   Starting stage: TRAINING
2022-12-05 21:43:16,854 INFO:     Val loss before train {'Reaction outcome loss': 1.040403034199368, 'Total loss': 1.040403034199368}
2022-12-05 21:43:16,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:16,855 INFO:     Epoch: 0
2022-12-05 21:43:17,643 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6450020704757083, 'Total loss': 0.6450020704757083} | train loss {'Reaction outcome loss': 0.7847163850961909, 'Total loss': 0.7847163850961909}
2022-12-05 21:43:17,643 INFO:     Found new best model at epoch 0
2022-12-05 21:43:17,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:17,644 INFO:     Epoch: 1
2022-12-05 21:43:18,431 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5377442890947516, 'Total loss': 0.5377442890947516} | train loss {'Reaction outcome loss': 0.5350269688225469, 'Total loss': 0.5350269688225469}
2022-12-05 21:43:18,432 INFO:     Found new best model at epoch 1
2022-12-05 21:43:18,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:18,433 INFO:     Epoch: 2
2022-12-05 21:43:19,225 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5010218884457242, 'Total loss': 0.5010218884457242} | train loss {'Reaction outcome loss': 0.46571848230805957, 'Total loss': 0.46571848230805957}
2022-12-05 21:43:19,225 INFO:     Found new best model at epoch 2
2022-12-05 21:43:19,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:19,226 INFO:     Epoch: 3
2022-12-05 21:43:20,023 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4735389670187777, 'Total loss': 0.4735389670187777} | train loss {'Reaction outcome loss': 0.4295607929001091, 'Total loss': 0.4295607929001091}
2022-12-05 21:43:20,023 INFO:     Found new best model at epoch 3
2022-12-05 21:43:20,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:20,024 INFO:     Epoch: 4
2022-12-05 21:43:20,815 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4600547423416918, 'Total loss': 0.4600547423416918} | train loss {'Reaction outcome loss': 0.4019792297711739, 'Total loss': 0.4019792297711739}
2022-12-05 21:43:20,815 INFO:     Found new best model at epoch 4
2022-12-05 21:43:20,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:20,816 INFO:     Epoch: 5
2022-12-05 21:43:21,606 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4587806056846272, 'Total loss': 0.4587806056846272} | train loss {'Reaction outcome loss': 0.3774017090739509, 'Total loss': 0.3774017090739509}
2022-12-05 21:43:21,606 INFO:     Found new best model at epoch 5
2022-12-05 21:43:21,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:21,607 INFO:     Epoch: 6
2022-12-05 21:43:22,395 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44365657290274446, 'Total loss': 0.44365657290274446} | train loss {'Reaction outcome loss': 0.359166559842434, 'Total loss': 0.359166559842434}
2022-12-05 21:43:22,395 INFO:     Found new best model at epoch 6
2022-12-05 21:43:22,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:22,396 INFO:     Epoch: 7
2022-12-05 21:43:23,187 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44645990295843646, 'Total loss': 0.44645990295843646} | train loss {'Reaction outcome loss': 0.3475983738899231, 'Total loss': 0.3475983738899231}
2022-12-05 21:43:23,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:23,187 INFO:     Epoch: 8
2022-12-05 21:43:23,982 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44892752983353357, 'Total loss': 0.44892752983353357} | train loss {'Reaction outcome loss': 0.3354500377275472, 'Total loss': 0.3354500377275472}
2022-12-05 21:43:23,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:23,982 INFO:     Epoch: 9
2022-12-05 21:43:24,777 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44603181731971825, 'Total loss': 0.44603181731971825} | train loss {'Reaction outcome loss': 0.31803327150311067, 'Total loss': 0.31803327150311067}
2022-12-05 21:43:24,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:24,778 INFO:     Epoch: 10
2022-12-05 21:43:25,576 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45206101543524047, 'Total loss': 0.45206101543524047} | train loss {'Reaction outcome loss': 0.30635152819758726, 'Total loss': 0.30635152819758726}
2022-12-05 21:43:25,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:25,576 INFO:     Epoch: 11
2022-12-05 21:43:26,367 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42953798682852223, 'Total loss': 0.42953798682852223} | train loss {'Reaction outcome loss': 0.2938853962580685, 'Total loss': 0.2938853962580685}
2022-12-05 21:43:26,367 INFO:     Found new best model at epoch 11
2022-12-05 21:43:26,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:26,368 INFO:     Epoch: 12
2022-12-05 21:43:27,156 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43014384738423606, 'Total loss': 0.43014384738423606} | train loss {'Reaction outcome loss': 0.28516544983816533, 'Total loss': 0.28516544983816533}
2022-12-05 21:43:27,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:27,156 INFO:     Epoch: 13
2022-12-05 21:43:27,947 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4340666596862403, 'Total loss': 0.4340666596862403} | train loss {'Reaction outcome loss': 0.27177328115653415, 'Total loss': 0.27177328115653415}
2022-12-05 21:43:27,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:27,948 INFO:     Epoch: 14
2022-12-05 21:43:28,738 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45304555513642053, 'Total loss': 0.45304555513642053} | train loss {'Reaction outcome loss': 0.2681788343348001, 'Total loss': 0.2681788343348001}
2022-12-05 21:43:28,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:28,738 INFO:     Epoch: 15
2022-12-05 21:43:29,526 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44684128564867104, 'Total loss': 0.44684128564867104} | train loss {'Reaction outcome loss': 0.25688992205419037, 'Total loss': 0.25688992205419037}
2022-12-05 21:43:29,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:29,526 INFO:     Epoch: 16
2022-12-05 21:43:30,314 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43814705396917736, 'Total loss': 0.43814705396917736} | train loss {'Reaction outcome loss': 0.24905362159677363, 'Total loss': 0.24905362159677363}
2022-12-05 21:43:30,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:30,314 INFO:     Epoch: 17
2022-12-05 21:43:31,108 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4564185301688584, 'Total loss': 0.4564185301688584} | train loss {'Reaction outcome loss': 0.24172479678925715, 'Total loss': 0.24172479678925715}
2022-12-05 21:43:31,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:31,108 INFO:     Epoch: 18
2022-12-05 21:43:31,898 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4683436612513932, 'Total loss': 0.4683436612513932} | train loss {'Reaction outcome loss': 0.23774525360298543, 'Total loss': 0.23774525360298543}
2022-12-05 21:43:31,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:31,899 INFO:     Epoch: 19
2022-12-05 21:43:32,694 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4510487233373252, 'Total loss': 0.4510487233373252} | train loss {'Reaction outcome loss': 0.23292668706733688, 'Total loss': 0.23292668706733688}
2022-12-05 21:43:32,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:32,694 INFO:     Epoch: 20
2022-12-05 21:43:33,491 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45301254161379556, 'Total loss': 0.45301254161379556} | train loss {'Reaction outcome loss': 0.22630454649628415, 'Total loss': 0.22630454649628415}
2022-12-05 21:43:33,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:33,492 INFO:     Epoch: 21
2022-12-05 21:43:34,285 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4517627290704034, 'Total loss': 0.4517627290704034} | train loss {'Reaction outcome loss': 0.2179293917786134, 'Total loss': 0.2179293917786134}
2022-12-05 21:43:34,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:34,286 INFO:     Epoch: 22
2022-12-05 21:43:35,076 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4456966874951666, 'Total loss': 0.4456966874951666} | train loss {'Reaction outcome loss': 0.21920893312646791, 'Total loss': 0.21920893312646791}
2022-12-05 21:43:35,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:35,077 INFO:     Epoch: 23
2022-12-05 21:43:35,866 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44758422960611904, 'Total loss': 0.44758422960611904} | train loss {'Reaction outcome loss': 0.20717188860723365, 'Total loss': 0.20717188860723365}
2022-12-05 21:43:35,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:35,867 INFO:     Epoch: 24
2022-12-05 21:43:36,657 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46741353144699876, 'Total loss': 0.46741353144699876} | train loss {'Reaction outcome loss': 0.2070752607907361, 'Total loss': 0.2070752607907361}
2022-12-05 21:43:36,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:36,657 INFO:     Epoch: 25
2022-12-05 21:43:37,453 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4571218761530789, 'Total loss': 0.4571218761530789} | train loss {'Reaction outcome loss': 0.20268458208806345, 'Total loss': 0.20268458208806345}
2022-12-05 21:43:37,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:37,454 INFO:     Epoch: 26
2022-12-05 21:43:38,246 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4566101699390195, 'Total loss': 0.4566101699390195} | train loss {'Reaction outcome loss': 0.19715307357340206, 'Total loss': 0.19715307357340206}
2022-12-05 21:43:38,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:38,246 INFO:     Epoch: 27
2022-12-05 21:43:39,038 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48852317119863903, 'Total loss': 0.48852317119863903} | train loss {'Reaction outcome loss': 0.19159333923688301, 'Total loss': 0.19159333923688301}
2022-12-05 21:43:39,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:39,038 INFO:     Epoch: 28
2022-12-05 21:43:39,836 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4709304039451209, 'Total loss': 0.4709304039451209} | train loss {'Reaction outcome loss': 0.2008364439794892, 'Total loss': 0.2008364439794892}
2022-12-05 21:43:39,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:39,836 INFO:     Epoch: 29
2022-12-05 21:43:40,629 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47178097848187794, 'Total loss': 0.47178097848187794} | train loss {'Reaction outcome loss': 0.18628041559325056, 'Total loss': 0.18628041559325056}
2022-12-05 21:43:40,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:40,629 INFO:     Epoch: 30
2022-12-05 21:43:41,420 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4618633690882813, 'Total loss': 0.4618633690882813} | train loss {'Reaction outcome loss': 0.1862525476014566, 'Total loss': 0.1862525476014566}
2022-12-05 21:43:41,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:41,420 INFO:     Epoch: 31
2022-12-05 21:43:42,210 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4592692854560234, 'Total loss': 0.4592692854560234} | train loss {'Reaction outcome loss': 0.18216371861746466, 'Total loss': 0.18216371861746466}
2022-12-05 21:43:42,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:42,210 INFO:     Epoch: 32
2022-12-05 21:43:43,004 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4605061557482589, 'Total loss': 0.4605061557482589} | train loss {'Reaction outcome loss': 0.1785337502619455, 'Total loss': 0.1785337502619455}
2022-12-05 21:43:43,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:43,004 INFO:     Epoch: 33
2022-12-05 21:43:43,795 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46196413751352916, 'Total loss': 0.46196413751352916} | train loss {'Reaction outcome loss': 0.18380908399579013, 'Total loss': 0.18380908399579013}
2022-12-05 21:43:43,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:43,795 INFO:     Epoch: 34
2022-12-05 21:43:44,587 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4628596498884938, 'Total loss': 0.4628596498884938} | train loss {'Reaction outcome loss': 0.17542736480382048, 'Total loss': 0.17542736480382048}
2022-12-05 21:43:44,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:44,587 INFO:     Epoch: 35
2022-12-05 21:43:45,388 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4632096216082573, 'Total loss': 0.4632096216082573} | train loss {'Reaction outcome loss': 0.17105594414629435, 'Total loss': 0.17105594414629435}
2022-12-05 21:43:45,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:45,388 INFO:     Epoch: 36
2022-12-05 21:43:46,180 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4656617756594311, 'Total loss': 0.4656617756594311} | train loss {'Reaction outcome loss': 0.16975962544078768, 'Total loss': 0.16975962544078768}
2022-12-05 21:43:46,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:46,180 INFO:     Epoch: 37
2022-12-05 21:43:46,969 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4517777741632678, 'Total loss': 0.4517777741632678} | train loss {'Reaction outcome loss': 0.16749250752331032, 'Total loss': 0.16749250752331032}
2022-12-05 21:43:46,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:46,969 INFO:     Epoch: 38
2022-12-05 21:43:47,762 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46980913914740086, 'Total loss': 0.46980913914740086} | train loss {'Reaction outcome loss': 0.16436123645106548, 'Total loss': 0.16436123645106548}
2022-12-05 21:43:47,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:47,763 INFO:     Epoch: 39
2022-12-05 21:43:48,555 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4806267923929475, 'Total loss': 0.4806267923929475} | train loss {'Reaction outcome loss': 0.16638941079121733, 'Total loss': 0.16638941079121733}
2022-12-05 21:43:48,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:48,555 INFO:     Epoch: 40
2022-12-05 21:43:49,350 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4765004383569414, 'Total loss': 0.4765004383569414} | train loss {'Reaction outcome loss': 0.16491778583269612, 'Total loss': 0.16491778583269612}
2022-12-05 21:43:49,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:49,351 INFO:     Epoch: 41
2022-12-05 21:43:50,146 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4778259565884417, 'Total loss': 0.4778259565884417} | train loss {'Reaction outcome loss': 0.16105718154324453, 'Total loss': 0.16105718154324453}
2022-12-05 21:43:50,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:50,147 INFO:     Epoch: 42
2022-12-05 21:43:50,940 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47154745764353057, 'Total loss': 0.47154745764353057} | train loss {'Reaction outcome loss': 0.1607537292064684, 'Total loss': 0.1607537292064684}
2022-12-05 21:43:50,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:50,941 INFO:     Epoch: 43
2022-12-05 21:43:51,737 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47138174961913715, 'Total loss': 0.47138174961913715} | train loss {'Reaction outcome loss': 0.1574891404086641, 'Total loss': 0.1574891404086641}
2022-12-05 21:43:51,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:51,737 INFO:     Epoch: 44
2022-12-05 21:43:52,533 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47916450012813916, 'Total loss': 0.47916450012813916} | train loss {'Reaction outcome loss': 0.1563978091877723, 'Total loss': 0.1563978091877723}
2022-12-05 21:43:52,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:52,533 INFO:     Epoch: 45
2022-12-05 21:43:53,325 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4733100083063949, 'Total loss': 0.4733100083063949} | train loss {'Reaction outcome loss': 0.15463370232661877, 'Total loss': 0.15463370232661877}
2022-12-05 21:43:53,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:53,325 INFO:     Epoch: 46
2022-12-05 21:43:54,115 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4853285464712165, 'Total loss': 0.4853285464712165} | train loss {'Reaction outcome loss': 0.15663108172324988, 'Total loss': 0.15663108172324988}
2022-12-05 21:43:54,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:54,115 INFO:     Epoch: 47
2022-12-05 21:43:54,906 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4896044141866944, 'Total loss': 0.4896044141866944} | train loss {'Reaction outcome loss': 0.15842759998718858, 'Total loss': 0.15842759998718858}
2022-12-05 21:43:54,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:54,907 INFO:     Epoch: 48
2022-12-05 21:43:55,701 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4904645105654543, 'Total loss': 0.4904645105654543} | train loss {'Reaction outcome loss': 0.1527293266178022, 'Total loss': 0.1527293266178022}
2022-12-05 21:43:55,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:55,702 INFO:     Epoch: 49
2022-12-05 21:43:56,500 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.477191241288727, 'Total loss': 0.477191241288727} | train loss {'Reaction outcome loss': 0.15267710091719622, 'Total loss': 0.15267710091719622}
2022-12-05 21:43:56,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:56,500 INFO:     Epoch: 50
2022-12-05 21:43:57,293 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47643247551538725, 'Total loss': 0.47643247551538725} | train loss {'Reaction outcome loss': 0.155255806379714, 'Total loss': 0.155255806379714}
2022-12-05 21:43:57,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:57,293 INFO:     Epoch: 51
2022-12-05 21:43:58,086 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49481768533587456, 'Total loss': 0.49481768533587456} | train loss {'Reaction outcome loss': 0.15467792072970615, 'Total loss': 0.15467792072970615}
2022-12-05 21:43:58,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:58,086 INFO:     Epoch: 52
2022-12-05 21:43:58,879 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48514917628331616, 'Total loss': 0.48514917628331616} | train loss {'Reaction outcome loss': 0.1471052413979764, 'Total loss': 0.1471052413979764}
2022-12-05 21:43:58,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:58,879 INFO:     Epoch: 53
2022-12-05 21:43:59,674 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49522159180857916, 'Total loss': 0.49522159180857916} | train loss {'Reaction outcome loss': 0.1471206519332326, 'Total loss': 0.1471206519332326}
2022-12-05 21:43:59,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:43:59,674 INFO:     Epoch: 54
2022-12-05 21:44:00,472 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4858227453448556, 'Total loss': 0.4858227453448556} | train loss {'Reaction outcome loss': 0.14303882703607382, 'Total loss': 0.14303882703607382}
2022-12-05 21:44:00,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:00,472 INFO:     Epoch: 55
2022-12-05 21:44:01,269 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47319690307432954, 'Total loss': 0.47319690307432954} | train loss {'Reaction outcome loss': 0.14307209932309414, 'Total loss': 0.14307209932309414}
2022-12-05 21:44:01,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:01,270 INFO:     Epoch: 56
2022-12-05 21:44:02,071 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47745493122122507, 'Total loss': 0.47745493122122507} | train loss {'Reaction outcome loss': 0.1435770852649622, 'Total loss': 0.1435770852649622}
2022-12-05 21:44:02,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:02,071 INFO:     Epoch: 57
2022-12-05 21:44:02,868 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4810717102478851, 'Total loss': 0.4810717102478851} | train loss {'Reaction outcome loss': 0.14612530411017477, 'Total loss': 0.14612530411017477}
2022-12-05 21:44:02,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:02,869 INFO:     Epoch: 58
2022-12-05 21:44:03,671 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5057059644975446, 'Total loss': 0.5057059644975446} | train loss {'Reaction outcome loss': 0.1405521104572273, 'Total loss': 0.1405521104572273}
2022-12-05 21:44:03,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:03,672 INFO:     Epoch: 59
2022-12-05 21:44:04,477 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48039948804812, 'Total loss': 0.48039948804812} | train loss {'Reaction outcome loss': 0.14262266333407236, 'Total loss': 0.14262266333407236}
2022-12-05 21:44:04,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:04,477 INFO:     Epoch: 60
2022-12-05 21:44:05,274 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4779926182871515, 'Total loss': 0.4779926182871515} | train loss {'Reaction outcome loss': 0.1484648391664752, 'Total loss': 0.1484648391664752}
2022-12-05 21:44:05,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:05,274 INFO:     Epoch: 61
2022-12-05 21:44:06,072 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4813805439255454, 'Total loss': 0.4813805439255454} | train loss {'Reaction outcome loss': 0.14097025796680557, 'Total loss': 0.14097025796680557}
2022-12-05 21:44:06,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:06,072 INFO:     Epoch: 62
2022-12-05 21:44:06,879 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.498344805768945, 'Total loss': 0.498344805768945} | train loss {'Reaction outcome loss': 0.1380273137234061, 'Total loss': 0.1380273137234061}
2022-12-05 21:44:06,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:06,879 INFO:     Epoch: 63
2022-12-05 21:44:07,682 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49297523363070056, 'Total loss': 0.49297523363070056} | train loss {'Reaction outcome loss': 0.13556844786729527, 'Total loss': 0.13556844786729527}
2022-12-05 21:44:07,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:07,683 INFO:     Epoch: 64
2022-12-05 21:44:08,482 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47679494795474137, 'Total loss': 0.47679494795474137} | train loss {'Reaction outcome loss': 0.13839553627619136, 'Total loss': 0.13839553627619136}
2022-12-05 21:44:08,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:08,483 INFO:     Epoch: 65
2022-12-05 21:44:09,282 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.476227212019942, 'Total loss': 0.476227212019942} | train loss {'Reaction outcome loss': 0.138617799553251, 'Total loss': 0.138617799553251}
2022-12-05 21:44:09,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:09,282 INFO:     Epoch: 66
2022-12-05 21:44:10,081 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4914867275140502, 'Total loss': 0.4914867275140502} | train loss {'Reaction outcome loss': 0.14092701114619882, 'Total loss': 0.14092701114619882}
2022-12-05 21:44:10,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:10,082 INFO:     Epoch: 67
2022-12-05 21:44:10,883 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4933834465389902, 'Total loss': 0.4933834465389902} | train loss {'Reaction outcome loss': 0.13579849820010936, 'Total loss': 0.13579849820010936}
2022-12-05 21:44:10,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:10,884 INFO:     Epoch: 68
2022-12-05 21:44:11,683 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.486226752739061, 'Total loss': 0.486226752739061} | train loss {'Reaction outcome loss': 0.14205907945811508, 'Total loss': 0.14205907945811508}
2022-12-05 21:44:11,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:11,683 INFO:     Epoch: 69
2022-12-05 21:44:12,489 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4854950105602091, 'Total loss': 0.4854950105602091} | train loss {'Reaction outcome loss': 0.13655062716337382, 'Total loss': 0.13655062716337382}
2022-12-05 21:44:12,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:12,489 INFO:     Epoch: 70
2022-12-05 21:44:13,290 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47443163936788385, 'Total loss': 0.47443163936788385} | train loss {'Reaction outcome loss': 0.13498680976781285, 'Total loss': 0.13498680976781285}
2022-12-05 21:44:13,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:13,291 INFO:     Epoch: 71
2022-12-05 21:44:14,089 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49645834450017323, 'Total loss': 0.49645834450017323} | train loss {'Reaction outcome loss': 0.13260859892013585, 'Total loss': 0.13260859892013585}
2022-12-05 21:44:14,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:14,089 INFO:     Epoch: 72
2022-12-05 21:44:14,889 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49066024544564163, 'Total loss': 0.49066024544564163} | train loss {'Reaction outcome loss': 0.1364242386219925, 'Total loss': 0.1364242386219925}
2022-12-05 21:44:14,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:14,889 INFO:     Epoch: 73
2022-12-05 21:44:15,690 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4873730293051763, 'Total loss': 0.4873730293051763} | train loss {'Reaction outcome loss': 0.1325212758683, 'Total loss': 0.1325212758683}
2022-12-05 21:44:15,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:15,691 INFO:     Epoch: 74
2022-12-05 21:44:16,491 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4885508231818676, 'Total loss': 0.4885508231818676} | train loss {'Reaction outcome loss': 0.13096264623075363, 'Total loss': 0.13096264623075363}
2022-12-05 21:44:16,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:16,491 INFO:     Epoch: 75
2022-12-05 21:44:17,295 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49942636489868164, 'Total loss': 0.49942636489868164} | train loss {'Reaction outcome loss': 0.1313874029633608, 'Total loss': 0.1313874029633608}
2022-12-05 21:44:17,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:17,295 INFO:     Epoch: 76
2022-12-05 21:44:18,095 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.497310167347843, 'Total loss': 0.497310167347843} | train loss {'Reaction outcome loss': 0.13412725981626555, 'Total loss': 0.13412725981626555}
2022-12-05 21:44:18,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:18,095 INFO:     Epoch: 77
2022-12-05 21:44:18,900 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4698467496782541, 'Total loss': 0.4698467496782541} | train loss {'Reaction outcome loss': 0.1349767769539827, 'Total loss': 0.1349767769539827}
2022-12-05 21:44:18,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:18,900 INFO:     Epoch: 78
2022-12-05 21:44:19,704 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.482991892167113, 'Total loss': 0.482991892167113} | train loss {'Reaction outcome loss': 0.1298156524329684, 'Total loss': 0.1298156524329684}
2022-12-05 21:44:19,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:19,704 INFO:     Epoch: 79
2022-12-05 21:44:20,508 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5032473267479376, 'Total loss': 0.5032473267479376} | train loss {'Reaction outcome loss': 0.12915480970159957, 'Total loss': 0.12915480970159957}
2022-12-05 21:44:20,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:20,509 INFO:     Epoch: 80
2022-12-05 21:44:21,309 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4901615224609321, 'Total loss': 0.4901615224609321} | train loss {'Reaction outcome loss': 0.12943777560373307, 'Total loss': 0.12943777560373307}
2022-12-05 21:44:21,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:21,309 INFO:     Epoch: 81
2022-12-05 21:44:22,113 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5009563639760017, 'Total loss': 0.5009563639760017} | train loss {'Reaction outcome loss': 0.12750346493730058, 'Total loss': 0.12750346493730058}
2022-12-05 21:44:22,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:22,113 INFO:     Epoch: 82
2022-12-05 21:44:22,919 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5057254982265559, 'Total loss': 0.5057254982265559} | train loss {'Reaction outcome loss': 0.13009375269309834, 'Total loss': 0.13009375269309834}
2022-12-05 21:44:22,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:22,920 INFO:     Epoch: 83
2022-12-05 21:44:23,724 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4992976410483772, 'Total loss': 0.4992976410483772} | train loss {'Reaction outcome loss': 0.13602856813594397, 'Total loss': 0.13602856813594397}
2022-12-05 21:44:23,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:23,724 INFO:     Epoch: 84
2022-12-05 21:44:24,529 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4955041811547496, 'Total loss': 0.4955041811547496} | train loss {'Reaction outcome loss': 0.12756488218843212, 'Total loss': 0.12756488218843212}
2022-12-05 21:44:24,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:24,529 INFO:     Epoch: 85
2022-12-05 21:44:25,336 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5125771947205067, 'Total loss': 0.5125771947205067} | train loss {'Reaction outcome loss': 0.12960364754021408, 'Total loss': 0.12960364754021408}
2022-12-05 21:44:25,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:25,336 INFO:     Epoch: 86
2022-12-05 21:44:26,137 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4872959654100917, 'Total loss': 0.4872959654100917} | train loss {'Reaction outcome loss': 0.1369684896232025, 'Total loss': 0.1369684896232025}
2022-12-05 21:44:26,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:26,137 INFO:     Epoch: 87
2022-12-05 21:44:26,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5027180744165723, 'Total loss': 0.5027180744165723} | train loss {'Reaction outcome loss': 0.1278476855842027, 'Total loss': 0.1278476855842027}
2022-12-05 21:44:26,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:26,941 INFO:     Epoch: 88
2022-12-05 21:44:27,741 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5055691213770346, 'Total loss': 0.5055691213770346} | train loss {'Reaction outcome loss': 0.1307366212173874, 'Total loss': 0.1307366212173874}
2022-12-05 21:44:27,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:27,742 INFO:     Epoch: 89
2022-12-05 21:44:28,548 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5031550032171336, 'Total loss': 0.5031550032171336} | train loss {'Reaction outcome loss': 0.1242706702422607, 'Total loss': 0.1242706702422607}
2022-12-05 21:44:28,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:28,548 INFO:     Epoch: 90
2022-12-05 21:44:29,346 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4987011897293004, 'Total loss': 0.4987011897293004} | train loss {'Reaction outcome loss': 0.12557018319001564, 'Total loss': 0.12557018319001564}
2022-12-05 21:44:29,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:29,346 INFO:     Epoch: 91
2022-12-05 21:44:30,147 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4827797988598997, 'Total loss': 0.4827797988598997} | train loss {'Reaction outcome loss': 0.13055909682170824, 'Total loss': 0.13055909682170824}
2022-12-05 21:44:30,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:30,147 INFO:     Epoch: 92
2022-12-05 21:44:30,947 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4922128448432142, 'Total loss': 0.4922128448432142} | train loss {'Reaction outcome loss': 0.13108404995760453, 'Total loss': 0.13108404995760453}
2022-12-05 21:44:30,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:30,947 INFO:     Epoch: 93
2022-12-05 21:44:31,742 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4901093049821528, 'Total loss': 0.4901093049821528} | train loss {'Reaction outcome loss': 0.13021351637456355, 'Total loss': 0.13021351637456355}
2022-12-05 21:44:31,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:31,743 INFO:     Epoch: 94
2022-12-05 21:44:32,538 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49025242267684505, 'Total loss': 0.49025242267684505} | train loss {'Reaction outcome loss': 0.128186696009175, 'Total loss': 0.128186696009175}
2022-12-05 21:44:32,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:32,538 INFO:     Epoch: 95
2022-12-05 21:44:33,335 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49886278698051517, 'Total loss': 0.49886278698051517} | train loss {'Reaction outcome loss': 0.12909884317608378, 'Total loss': 0.12909884317608378}
2022-12-05 21:44:33,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:33,335 INFO:     Epoch: 96
2022-12-05 21:44:34,137 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49137731912461197, 'Total loss': 0.49137731912461197} | train loss {'Reaction outcome loss': 0.1261780624228873, 'Total loss': 0.1261780624228873}
2022-12-05 21:44:34,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:34,138 INFO:     Epoch: 97
2022-12-05 21:44:34,937 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5155630159107122, 'Total loss': 0.5155630159107122} | train loss {'Reaction outcome loss': 0.12860875502077915, 'Total loss': 0.12860875502077915}
2022-12-05 21:44:34,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:34,938 INFO:     Epoch: 98
2022-12-05 21:44:35,737 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49042542346499185, 'Total loss': 0.49042542346499185} | train loss {'Reaction outcome loss': 0.13480561455195159, 'Total loss': 0.13480561455195159}
2022-12-05 21:44:35,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:35,737 INFO:     Epoch: 99
2022-12-05 21:44:36,536 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4919279217720032, 'Total loss': 0.4919279217720032} | train loss {'Reaction outcome loss': 0.12319323146359444, 'Total loss': 0.12319323146359444}
2022-12-05 21:44:36,536 INFO:     Best model found after epoch 12 of 100.
2022-12-05 21:44:36,536 INFO:   Done with stage: TRAINING
2022-12-05 21:44:36,536 INFO:   Starting stage: EVALUATION
2022-12-05 21:44:36,661 INFO:   Done with stage: EVALUATION
2022-12-05 21:44:36,662 INFO:   Leaving out SEQ value Fold_8
2022-12-05 21:44:36,674 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:44:36,674 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:44:37,321 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:44:37,321 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:44:37,390 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:44:37,390 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:44:37,390 INFO:     No hyperparam tuning for this model
2022-12-05 21:44:37,390 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:44:37,390 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:44:37,391 INFO:     None feature selector for col prot
2022-12-05 21:44:37,391 INFO:     None feature selector for col prot
2022-12-05 21:44:37,391 INFO:     None feature selector for col prot
2022-12-05 21:44:37,392 INFO:     None feature selector for col chem
2022-12-05 21:44:37,392 INFO:     None feature selector for col chem
2022-12-05 21:44:37,392 INFO:     None feature selector for col chem
2022-12-05 21:44:37,392 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:44:37,392 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:44:37,394 INFO:     Number of params in model 215821
2022-12-05 21:44:37,397 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:44:37,397 INFO:   Starting stage: TRAINING
2022-12-05 21:44:37,458 INFO:     Val loss before train {'Reaction outcome loss': 0.9928302873264659, 'Total loss': 0.9928302873264659}
2022-12-05 21:44:37,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:37,458 INFO:     Epoch: 0
2022-12-05 21:44:38,262 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6067305410450156, 'Total loss': 0.6067305410450156} | train loss {'Reaction outcome loss': 0.7763652495679355, 'Total loss': 0.7763652495679355}
2022-12-05 21:44:38,262 INFO:     Found new best model at epoch 0
2022-12-05 21:44:38,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:38,263 INFO:     Epoch: 1
2022-12-05 21:44:39,062 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5151686824180863, 'Total loss': 0.5151686824180863} | train loss {'Reaction outcome loss': 0.5244604386990109, 'Total loss': 0.5244604386990109}
2022-12-05 21:44:39,063 INFO:     Found new best model at epoch 1
2022-12-05 21:44:39,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:39,064 INFO:     Epoch: 2
2022-12-05 21:44:39,864 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4800898215987466, 'Total loss': 0.4800898215987466} | train loss {'Reaction outcome loss': 0.45607660620683627, 'Total loss': 0.45607660620683627}
2022-12-05 21:44:39,864 INFO:     Found new best model at epoch 2
2022-12-05 21:44:39,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:39,865 INFO:     Epoch: 3
2022-12-05 21:44:40,662 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4766521833159707, 'Total loss': 0.4766521833159707} | train loss {'Reaction outcome loss': 0.41815838674383776, 'Total loss': 0.41815838674383776}
2022-12-05 21:44:40,662 INFO:     Found new best model at epoch 3
2022-12-05 21:44:40,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:40,663 INFO:     Epoch: 4
2022-12-05 21:44:41,458 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46352211656895553, 'Total loss': 0.46352211656895553} | train loss {'Reaction outcome loss': 0.3879354440216576, 'Total loss': 0.3879354440216576}
2022-12-05 21:44:41,459 INFO:     Found new best model at epoch 4
2022-12-05 21:44:41,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:41,459 INFO:     Epoch: 5
2022-12-05 21:44:42,253 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4434222362258218, 'Total loss': 0.4434222362258218} | train loss {'Reaction outcome loss': 0.3651168579235673, 'Total loss': 0.3651168579235673}
2022-12-05 21:44:42,253 INFO:     Found new best model at epoch 5
2022-12-05 21:44:42,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:42,254 INFO:     Epoch: 6
2022-12-05 21:44:43,053 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4438635229387067, 'Total loss': 0.4438635229387067} | train loss {'Reaction outcome loss': 0.348016778067235, 'Total loss': 0.348016778067235}
2022-12-05 21:44:43,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:43,053 INFO:     Epoch: 7
2022-12-05 21:44:43,858 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4359597851606933, 'Total loss': 0.4359597851606933} | train loss {'Reaction outcome loss': 0.3270906423849444, 'Total loss': 0.3270906423849444}
2022-12-05 21:44:43,859 INFO:     Found new best model at epoch 7
2022-12-05 21:44:43,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:43,859 INFO:     Epoch: 8
2022-12-05 21:44:44,662 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43608117950233544, 'Total loss': 0.43608117950233544} | train loss {'Reaction outcome loss': 0.3141316031856883, 'Total loss': 0.3141316031856883}
2022-12-05 21:44:44,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:44,663 INFO:     Epoch: 9
2022-12-05 21:44:45,465 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4347837922925299, 'Total loss': 0.4347837922925299} | train loss {'Reaction outcome loss': 0.2988242272648119, 'Total loss': 0.2988242272648119}
2022-12-05 21:44:45,465 INFO:     Found new best model at epoch 9
2022-12-05 21:44:45,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:45,466 INFO:     Epoch: 10
2022-12-05 21:44:46,263 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4492838470773263, 'Total loss': 0.4492838470773263} | train loss {'Reaction outcome loss': 0.2876088426358277, 'Total loss': 0.2876088426358277}
2022-12-05 21:44:46,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:46,264 INFO:     Epoch: 11
2022-12-05 21:44:47,059 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4497340050610629, 'Total loss': 0.4497340050610629} | train loss {'Reaction outcome loss': 0.27243198953088255, 'Total loss': 0.27243198953088255}
2022-12-05 21:44:47,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:47,059 INFO:     Epoch: 12
2022-12-05 21:44:47,855 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4357396045869047, 'Total loss': 0.4357396045869047} | train loss {'Reaction outcome loss': 0.26648855152269524, 'Total loss': 0.26648855152269524}
2022-12-05 21:44:47,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:47,855 INFO:     Epoch: 13
2022-12-05 21:44:48,647 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44863770698959177, 'Total loss': 0.44863770698959177} | train loss {'Reaction outcome loss': 0.2548237868975247, 'Total loss': 0.2548237868975247}
2022-12-05 21:44:48,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:48,647 INFO:     Epoch: 14
2022-12-05 21:44:49,438 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4418435733426701, 'Total loss': 0.4418435733426701} | train loss {'Reaction outcome loss': 0.246220851824018, 'Total loss': 0.246220851824018}
2022-12-05 21:44:49,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:49,438 INFO:     Epoch: 15
2022-12-05 21:44:50,231 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4429230066862973, 'Total loss': 0.4429230066862973} | train loss {'Reaction outcome loss': 0.23990759623026656, 'Total loss': 0.23990759623026656}
2022-12-05 21:44:50,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:50,231 INFO:     Epoch: 16
2022-12-05 21:44:51,024 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4576269408518618, 'Total loss': 0.4576269408518618} | train loss {'Reaction outcome loss': 0.22815198613510979, 'Total loss': 0.22815198613510979}
2022-12-05 21:44:51,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:51,025 INFO:     Epoch: 17
2022-12-05 21:44:51,819 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44906187091361394, 'Total loss': 0.44906187091361394} | train loss {'Reaction outcome loss': 0.22648975735289917, 'Total loss': 0.22648975735289917}
2022-12-05 21:44:51,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:51,820 INFO:     Epoch: 18
2022-12-05 21:44:52,618 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.445786579427394, 'Total loss': 0.445786579427394} | train loss {'Reaction outcome loss': 0.22057949969424837, 'Total loss': 0.22057949969424837}
2022-12-05 21:44:52,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:52,618 INFO:     Epoch: 19
2022-12-05 21:44:53,413 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44674863666296005, 'Total loss': 0.44674863666296005} | train loss {'Reaction outcome loss': 0.21506952351680206, 'Total loss': 0.21506952351680206}
2022-12-05 21:44:53,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:53,413 INFO:     Epoch: 20
2022-12-05 21:44:54,207 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4510752040554177, 'Total loss': 0.4510752040554177} | train loss {'Reaction outcome loss': 0.20957603556434473, 'Total loss': 0.20957603556434473}
2022-12-05 21:44:54,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:54,207 INFO:     Epoch: 21
2022-12-05 21:44:55,002 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4618275033479387, 'Total loss': 0.4618275033479387} | train loss {'Reaction outcome loss': 0.20454426246484922, 'Total loss': 0.20454426246484922}
2022-12-05 21:44:55,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:55,002 INFO:     Epoch: 22
2022-12-05 21:44:55,802 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4580543025989424, 'Total loss': 0.4580543025989424} | train loss {'Reaction outcome loss': 0.19528223458497274, 'Total loss': 0.19528223458497274}
2022-12-05 21:44:55,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:55,803 INFO:     Epoch: 23
2022-12-05 21:44:56,601 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45510253039273346, 'Total loss': 0.45510253039273346} | train loss {'Reaction outcome loss': 0.19336381526814111, 'Total loss': 0.19336381526814111}
2022-12-05 21:44:56,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:56,602 INFO:     Epoch: 24
2022-12-05 21:44:57,400 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4769940437241034, 'Total loss': 0.4769940437241034} | train loss {'Reaction outcome loss': 0.18933144299643895, 'Total loss': 0.18933144299643895}
2022-12-05 21:44:57,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:57,401 INFO:     Epoch: 25
2022-12-05 21:44:58,200 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4728413860906254, 'Total loss': 0.4728413860906254} | train loss {'Reaction outcome loss': 0.18678838118249852, 'Total loss': 0.18678838118249852}
2022-12-05 21:44:58,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:58,200 INFO:     Epoch: 26
2022-12-05 21:44:58,998 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47138508476994256, 'Total loss': 0.47138508476994256} | train loss {'Reaction outcome loss': 0.18643747762806953, 'Total loss': 0.18643747762806953}
2022-12-05 21:44:58,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:58,999 INFO:     Epoch: 27
2022-12-05 21:44:59,794 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.466739030724222, 'Total loss': 0.466739030724222} | train loss {'Reaction outcome loss': 0.18107201720798208, 'Total loss': 0.18107201720798208}
2022-12-05 21:44:59,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:44:59,794 INFO:     Epoch: 28
2022-12-05 21:45:00,591 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4744266945530068, 'Total loss': 0.4744266945530068} | train loss {'Reaction outcome loss': 0.17828878802397558, 'Total loss': 0.17828878802397558}
2022-12-05 21:45:00,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:00,591 INFO:     Epoch: 29
2022-12-05 21:45:01,384 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4789381961930882, 'Total loss': 0.4789381961930882} | train loss {'Reaction outcome loss': 0.17601610550416574, 'Total loss': 0.17601610550416574}
2022-12-05 21:45:01,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:01,384 INFO:     Epoch: 30
2022-12-05 21:45:02,180 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4789465615017848, 'Total loss': 0.4789465615017848} | train loss {'Reaction outcome loss': 0.17261385310801766, 'Total loss': 0.17261385310801766}
2022-12-05 21:45:02,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:02,180 INFO:     Epoch: 31
2022-12-05 21:45:02,974 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4974200458011844, 'Total loss': 0.4974200458011844} | train loss {'Reaction outcome loss': 0.16622462861179824, 'Total loss': 0.16622462861179824}
2022-12-05 21:45:02,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:02,974 INFO:     Epoch: 32
2022-12-05 21:45:03,772 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4695235946300355, 'Total loss': 0.4695235946300355} | train loss {'Reaction outcome loss': 0.16702190613854798, 'Total loss': 0.16702190613854798}
2022-12-05 21:45:03,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:03,773 INFO:     Epoch: 33
2022-12-05 21:45:04,567 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4762698310342702, 'Total loss': 0.4762698310342702} | train loss {'Reaction outcome loss': 0.1645915627464532, 'Total loss': 0.1645915627464532}
2022-12-05 21:45:04,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:04,567 INFO:     Epoch: 34
2022-12-05 21:45:05,365 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4864678301594474, 'Total loss': 0.4864678301594474} | train loss {'Reaction outcome loss': 0.16276927062520577, 'Total loss': 0.16276927062520577}
2022-12-05 21:45:05,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:05,365 INFO:     Epoch: 35
2022-12-05 21:45:06,160 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4798480936072089, 'Total loss': 0.4798480936072089} | train loss {'Reaction outcome loss': 0.16161046643561172, 'Total loss': 0.16161046643561172}
2022-12-05 21:45:06,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:06,160 INFO:     Epoch: 36
2022-12-05 21:45:06,959 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49257504161108623, 'Total loss': 0.49257504161108623} | train loss {'Reaction outcome loss': 0.15810246516259446, 'Total loss': 0.15810246516259446}
2022-12-05 21:45:06,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:06,959 INFO:     Epoch: 37
2022-12-05 21:45:07,756 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48804100027138536, 'Total loss': 0.48804100027138536} | train loss {'Reaction outcome loss': 0.15499877373147156, 'Total loss': 0.15499877373147156}
2022-12-05 21:45:07,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:07,756 INFO:     Epoch: 38
2022-12-05 21:45:08,553 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48936513337222015, 'Total loss': 0.48936513337222015} | train loss {'Reaction outcome loss': 0.15430143723384507, 'Total loss': 0.15430143723384507}
2022-12-05 21:45:08,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:08,553 INFO:     Epoch: 39
2022-12-05 21:45:09,350 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49241654066876933, 'Total loss': 0.49241654066876933} | train loss {'Reaction outcome loss': 0.15225310459162197, 'Total loss': 0.15225310459162197}
2022-12-05 21:45:09,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:09,350 INFO:     Epoch: 40
2022-12-05 21:45:10,144 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48474892702969635, 'Total loss': 0.48474892702969635} | train loss {'Reaction outcome loss': 0.15285590072462876, 'Total loss': 0.15285590072462876}
2022-12-05 21:45:10,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:10,145 INFO:     Epoch: 41
2022-12-05 21:45:10,939 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48414767093279143, 'Total loss': 0.48414767093279143} | train loss {'Reaction outcome loss': 0.146976453492478, 'Total loss': 0.146976453492478}
2022-12-05 21:45:10,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:10,939 INFO:     Epoch: 42
2022-12-05 21:45:11,737 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4993201263926246, 'Total loss': 0.4993201263926246} | train loss {'Reaction outcome loss': 0.1485449619996812, 'Total loss': 0.1485449619996812}
2022-12-05 21:45:11,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:11,737 INFO:     Epoch: 43
2022-12-05 21:45:12,530 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4900199564343149, 'Total loss': 0.4900199564343149} | train loss {'Reaction outcome loss': 0.14538856419629506, 'Total loss': 0.14538856419629506}
2022-12-05 21:45:12,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:12,531 INFO:     Epoch: 44
2022-12-05 21:45:13,327 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4991378035735, 'Total loss': 0.4991378035735} | train loss {'Reaction outcome loss': 0.1472103704938725, 'Total loss': 0.1472103704938725}
2022-12-05 21:45:13,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:13,327 INFO:     Epoch: 45
2022-12-05 21:45:14,120 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5168380474841053, 'Total loss': 0.5168380474841053} | train loss {'Reaction outcome loss': 0.1465827914540686, 'Total loss': 0.1465827914540686}
2022-12-05 21:45:14,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:14,121 INFO:     Epoch: 46
2022-12-05 21:45:14,914 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4967792376198552, 'Total loss': 0.4967792376198552} | train loss {'Reaction outcome loss': 0.14449078267470242, 'Total loss': 0.14449078267470242}
2022-12-05 21:45:14,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:14,914 INFO:     Epoch: 47
2022-12-05 21:45:15,714 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.495632664385167, 'Total loss': 0.495632664385167} | train loss {'Reaction outcome loss': 0.14104097828479303, 'Total loss': 0.14104097828479303}
2022-12-05 21:45:15,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:15,714 INFO:     Epoch: 48
2022-12-05 21:45:16,507 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4945633926174857, 'Total loss': 0.4945633926174857} | train loss {'Reaction outcome loss': 0.14167951225423284, 'Total loss': 0.14167951225423284}
2022-12-05 21:45:16,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:16,507 INFO:     Epoch: 49
2022-12-05 21:45:17,301 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4855912459844893, 'Total loss': 0.4855912459844893} | train loss {'Reaction outcome loss': 0.14125762428081926, 'Total loss': 0.14125762428081926}
2022-12-05 21:45:17,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:17,301 INFO:     Epoch: 50
2022-12-05 21:45:18,094 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4959933778101748, 'Total loss': 0.4959933778101748} | train loss {'Reaction outcome loss': 0.13843014009387022, 'Total loss': 0.13843014009387022}
2022-12-05 21:45:18,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:18,094 INFO:     Epoch: 51
2022-12-05 21:45:18,892 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5005820234390822, 'Total loss': 0.5005820234390822} | train loss {'Reaction outcome loss': 0.1388184192943417, 'Total loss': 0.1388184192943417}
2022-12-05 21:45:18,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:18,892 INFO:     Epoch: 52
2022-12-05 21:45:19,691 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5021492354571819, 'Total loss': 0.5021492354571819} | train loss {'Reaction outcome loss': 0.13689140107993397, 'Total loss': 0.13689140107993397}
2022-12-05 21:45:19,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:19,691 INFO:     Epoch: 53
2022-12-05 21:45:20,489 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5040483869273554, 'Total loss': 0.5040483869273554} | train loss {'Reaction outcome loss': 0.14041646981176228, 'Total loss': 0.14041646981176228}
2022-12-05 21:45:20,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:20,489 INFO:     Epoch: 54
2022-12-05 21:45:21,282 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49581232091242616, 'Total loss': 0.49581232091242616} | train loss {'Reaction outcome loss': 0.13581811800418842, 'Total loss': 0.13581811800418842}
2022-12-05 21:45:21,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:21,282 INFO:     Epoch: 55
2022-12-05 21:45:22,082 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5032395500351082, 'Total loss': 0.5032395500351082} | train loss {'Reaction outcome loss': 0.13669955995658623, 'Total loss': 0.13669955995658623}
2022-12-05 21:45:22,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:22,083 INFO:     Epoch: 56
2022-12-05 21:45:22,881 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5051979144865816, 'Total loss': 0.5051979144865816} | train loss {'Reaction outcome loss': 0.13545867860797914, 'Total loss': 0.13545867860797914}
2022-12-05 21:45:22,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:22,883 INFO:     Epoch: 57
2022-12-05 21:45:23,680 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5123164528472857, 'Total loss': 0.5123164528472857} | train loss {'Reaction outcome loss': 0.1325226843116745, 'Total loss': 0.1325226843116745}
2022-12-05 21:45:23,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:23,681 INFO:     Epoch: 58
2022-12-05 21:45:24,477 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.512910839847543, 'Total loss': 0.512910839847543} | train loss {'Reaction outcome loss': 0.13203918442670856, 'Total loss': 0.13203918442670856}
2022-12-05 21:45:24,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:24,477 INFO:     Epoch: 59
2022-12-05 21:45:25,271 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4957998496564952, 'Total loss': 0.4957998496564952} | train loss {'Reaction outcome loss': 0.13242777171469625, 'Total loss': 0.13242777171469625}
2022-12-05 21:45:25,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:25,271 INFO:     Epoch: 60
2022-12-05 21:45:26,067 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4889922436665405, 'Total loss': 0.4889922436665405} | train loss {'Reaction outcome loss': 0.13189219952290576, 'Total loss': 0.13189219952290576}
2022-12-05 21:45:26,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:26,067 INFO:     Epoch: 61
2022-12-05 21:45:26,862 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49941571801900864, 'Total loss': 0.49941571801900864} | train loss {'Reaction outcome loss': 0.13113380792821128, 'Total loss': 0.13113380792821128}
2022-12-05 21:45:26,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:26,863 INFO:     Epoch: 62
2022-12-05 21:45:27,655 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48854543844407256, 'Total loss': 0.48854543844407256} | train loss {'Reaction outcome loss': 0.1297387621560765, 'Total loss': 0.1297387621560765}
2022-12-05 21:45:27,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:27,655 INFO:     Epoch: 63
2022-12-05 21:45:28,448 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4883158571002158, 'Total loss': 0.4883158571002158} | train loss {'Reaction outcome loss': 0.1292701672477227, 'Total loss': 0.1292701672477227}
2022-12-05 21:45:28,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:28,448 INFO:     Epoch: 64
2022-12-05 21:45:29,240 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49241846495053987, 'Total loss': 0.49241846495053987} | train loss {'Reaction outcome loss': 0.12968489410911477, 'Total loss': 0.12968489410911477}
2022-12-05 21:45:29,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:29,240 INFO:     Epoch: 65
2022-12-05 21:45:30,037 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5037129660221663, 'Total loss': 0.5037129660221663} | train loss {'Reaction outcome loss': 0.12984734220850852, 'Total loss': 0.12984734220850852}
2022-12-05 21:45:30,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:30,037 INFO:     Epoch: 66
2022-12-05 21:45:30,837 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5030728063800118, 'Total loss': 0.5030728063800118} | train loss {'Reaction outcome loss': 0.12843128184848016, 'Total loss': 0.12843128184848016}
2022-12-05 21:45:30,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:30,837 INFO:     Epoch: 67
2022-12-05 21:45:31,633 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4995123451067643, 'Total loss': 0.4995123451067643} | train loss {'Reaction outcome loss': 0.1286105801832051, 'Total loss': 0.1286105801832051}
2022-12-05 21:45:31,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:31,633 INFO:     Epoch: 68
2022-12-05 21:45:32,431 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5274910930205475, 'Total loss': 0.5274910930205475} | train loss {'Reaction outcome loss': 0.1267475530039519, 'Total loss': 0.1267475530039519}
2022-12-05 21:45:32,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:32,431 INFO:     Epoch: 69
2022-12-05 21:45:33,234 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5027642619203437, 'Total loss': 0.5027642619203437} | train loss {'Reaction outcome loss': 0.12647186389808812, 'Total loss': 0.12647186389808812}
2022-12-05 21:45:33,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:33,234 INFO:     Epoch: 70
2022-12-05 21:45:34,034 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.503821945833889, 'Total loss': 0.503821945833889} | train loss {'Reaction outcome loss': 0.12605356380733992, 'Total loss': 0.12605356380733992}
2022-12-05 21:45:34,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:34,034 INFO:     Epoch: 71
2022-12-05 21:45:34,830 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5180847031826322, 'Total loss': 0.5180847031826322} | train loss {'Reaction outcome loss': 0.12526896112174127, 'Total loss': 0.12526896112174127}
2022-12-05 21:45:34,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:34,830 INFO:     Epoch: 72
2022-12-05 21:45:35,625 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5246932553974065, 'Total loss': 0.5246932553974065} | train loss {'Reaction outcome loss': 0.12554740560271085, 'Total loss': 0.12554740560271085}
2022-12-05 21:45:35,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:35,625 INFO:     Epoch: 73
2022-12-05 21:45:36,427 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5215682363645597, 'Total loss': 0.5215682363645597} | train loss {'Reaction outcome loss': 0.12389853791589098, 'Total loss': 0.12389853791589098}
2022-12-05 21:45:36,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:36,427 INFO:     Epoch: 74
2022-12-05 21:45:37,231 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4944188090210611, 'Total loss': 0.4944188090210611} | train loss {'Reaction outcome loss': 0.12596521181084455, 'Total loss': 0.12596521181084455}
2022-12-05 21:45:37,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:37,232 INFO:     Epoch: 75
2022-12-05 21:45:38,028 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5080608945678581, 'Total loss': 0.5080608945678581} | train loss {'Reaction outcome loss': 0.1233482743207846, 'Total loss': 0.1233482743207846}
2022-12-05 21:45:38,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:38,028 INFO:     Epoch: 76
2022-12-05 21:45:38,821 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5114866637370803, 'Total loss': 0.5114866637370803} | train loss {'Reaction outcome loss': 0.12400101907851716, 'Total loss': 0.12400101907851716}
2022-12-05 21:45:38,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:38,821 INFO:     Epoch: 77
2022-12-05 21:45:39,614 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5194957078519192, 'Total loss': 0.5194957078519192} | train loss {'Reaction outcome loss': 0.12251594814194006, 'Total loss': 0.12251594814194006}
2022-12-05 21:45:39,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:39,614 INFO:     Epoch: 78
2022-12-05 21:45:40,409 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5300871409814466, 'Total loss': 0.5300871409814466} | train loss {'Reaction outcome loss': 0.12342379589174543, 'Total loss': 0.12342379589174543}
2022-12-05 21:45:40,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:40,409 INFO:     Epoch: 79
2022-12-05 21:45:41,210 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5068275276571512, 'Total loss': 0.5068275276571512} | train loss {'Reaction outcome loss': 0.12139689161877838, 'Total loss': 0.12139689161877838}
2022-12-05 21:45:41,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:41,211 INFO:     Epoch: 80
2022-12-05 21:45:42,006 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4936403401873328, 'Total loss': 0.4936403401873328} | train loss {'Reaction outcome loss': 0.11978190548102101, 'Total loss': 0.11978190548102101}
2022-12-05 21:45:42,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:42,007 INFO:     Epoch: 81
2022-12-05 21:45:42,801 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.513282372192903, 'Total loss': 0.513282372192903} | train loss {'Reaction outcome loss': 0.12102925344445412, 'Total loss': 0.12102925344445412}
2022-12-05 21:45:42,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:42,801 INFO:     Epoch: 82
2022-12-05 21:45:43,599 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5130954533815384, 'Total loss': 0.5130954533815384} | train loss {'Reaction outcome loss': 0.12089929201136974, 'Total loss': 0.12089929201136974}
2022-12-05 21:45:43,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:43,599 INFO:     Epoch: 83
2022-12-05 21:45:44,400 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5054270716553385, 'Total loss': 0.5054270716553385} | train loss {'Reaction outcome loss': 0.11952629057134712, 'Total loss': 0.11952629057134712}
2022-12-05 21:45:44,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:44,400 INFO:     Epoch: 84
2022-12-05 21:45:45,195 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5020240152424033, 'Total loss': 0.5020240152424033} | train loss {'Reaction outcome loss': 0.12082103874173857, 'Total loss': 0.12082103874173857}
2022-12-05 21:45:45,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:45,195 INFO:     Epoch: 85
2022-12-05 21:45:45,990 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5019100528549064, 'Total loss': 0.5019100528549064} | train loss {'Reaction outcome loss': 0.11921447381797817, 'Total loss': 0.11921447381797817}
2022-12-05 21:45:45,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:45,991 INFO:     Epoch: 86
2022-12-05 21:45:46,784 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5071165920658545, 'Total loss': 0.5071165920658545} | train loss {'Reaction outcome loss': 0.11916561257995424, 'Total loss': 0.11916561257995424}
2022-12-05 21:45:46,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:46,784 INFO:     Epoch: 87
2022-12-05 21:45:47,579 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5187812840396707, 'Total loss': 0.5187812840396707} | train loss {'Reaction outcome loss': 0.12203686118816896, 'Total loss': 0.12203686118816896}
2022-12-05 21:45:47,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:47,579 INFO:     Epoch: 88
2022-12-05 21:45:48,372 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.505534746938131, 'Total loss': 0.505534746938131} | train loss {'Reaction outcome loss': 0.11899467920058317, 'Total loss': 0.11899467920058317}
2022-12-05 21:45:48,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:48,372 INFO:     Epoch: 89
2022-12-05 21:45:49,166 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5033162608742714, 'Total loss': 0.5033162608742714} | train loss {'Reaction outcome loss': 0.11754268982293715, 'Total loss': 0.11754268982293715}
2022-12-05 21:45:49,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:49,167 INFO:     Epoch: 90
2022-12-05 21:45:49,958 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.507436412979256, 'Total loss': 0.507436412979256} | train loss {'Reaction outcome loss': 0.11926545066789034, 'Total loss': 0.11926545066789034}
2022-12-05 21:45:49,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:49,959 INFO:     Epoch: 91
2022-12-05 21:45:50,756 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5137571595947851, 'Total loss': 0.5137571595947851} | train loss {'Reaction outcome loss': 0.1191438001790835, 'Total loss': 0.1191438001790835}
2022-12-05 21:45:50,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:50,756 INFO:     Epoch: 92
2022-12-05 21:45:51,552 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5163964077152989, 'Total loss': 0.5163964077152989} | train loss {'Reaction outcome loss': 0.11568714511550722, 'Total loss': 0.11568714511550722}
2022-12-05 21:45:51,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:51,552 INFO:     Epoch: 93
2022-12-05 21:45:52,349 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4953792386434295, 'Total loss': 0.4953792386434295} | train loss {'Reaction outcome loss': 0.11784534638882765, 'Total loss': 0.11784534638882765}
2022-12-05 21:45:52,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:52,349 INFO:     Epoch: 94
2022-12-05 21:45:53,150 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5110925591804765, 'Total loss': 0.5110925591804765} | train loss {'Reaction outcome loss': 0.11756549349370142, 'Total loss': 0.11756549349370142}
2022-12-05 21:45:53,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:53,150 INFO:     Epoch: 95
2022-12-05 21:45:53,947 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5066821204329078, 'Total loss': 0.5066821204329078} | train loss {'Reaction outcome loss': 0.11587308228556667, 'Total loss': 0.11587308228556667}
2022-12-05 21:45:53,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:53,948 INFO:     Epoch: 96
2022-12-05 21:45:54,745 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5085770975459706, 'Total loss': 0.5085770975459706} | train loss {'Reaction outcome loss': 0.11561147606135497, 'Total loss': 0.11561147606135497}
2022-12-05 21:45:54,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:54,745 INFO:     Epoch: 97
2022-12-05 21:45:55,538 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49345663189888, 'Total loss': 0.49345663189888} | train loss {'Reaction outcome loss': 0.1183445222390395, 'Total loss': 0.1183445222390395}
2022-12-05 21:45:55,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:55,538 INFO:     Epoch: 98
2022-12-05 21:45:56,331 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5012740746817805, 'Total loss': 0.5012740746817805} | train loss {'Reaction outcome loss': 0.1179609584937533, 'Total loss': 0.1179609584937533}
2022-12-05 21:45:56,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:56,331 INFO:     Epoch: 99
2022-12-05 21:45:57,123 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4974670843644576, 'Total loss': 0.4974670843644576} | train loss {'Reaction outcome loss': 0.1179751614484215, 'Total loss': 0.1179751614484215}
2022-12-05 21:45:57,124 INFO:     Best model found after epoch 10 of 100.
2022-12-05 21:45:57,124 INFO:   Done with stage: TRAINING
2022-12-05 21:45:57,124 INFO:   Starting stage: EVALUATION
2022-12-05 21:45:57,243 INFO:   Done with stage: EVALUATION
2022-12-05 21:45:57,243 INFO:   Leaving out SEQ value Fold_9
2022-12-05 21:45:57,256 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:45:57,256 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:45:57,904 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:45:57,905 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:45:57,974 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:45:57,974 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:45:57,974 INFO:     No hyperparam tuning for this model
2022-12-05 21:45:57,974 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:45:57,974 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:45:57,975 INFO:     None feature selector for col prot
2022-12-05 21:45:57,975 INFO:     None feature selector for col prot
2022-12-05 21:45:57,975 INFO:     None feature selector for col prot
2022-12-05 21:45:57,975 INFO:     None feature selector for col chem
2022-12-05 21:45:57,975 INFO:     None feature selector for col chem
2022-12-05 21:45:57,975 INFO:     None feature selector for col chem
2022-12-05 21:45:57,976 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:45:57,976 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:45:57,977 INFO:     Number of params in model 215821
2022-12-05 21:45:57,980 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:45:57,980 INFO:   Starting stage: TRAINING
2022-12-05 21:45:58,040 INFO:     Val loss before train {'Reaction outcome loss': 0.898369743742726, 'Total loss': 0.898369743742726}
2022-12-05 21:45:58,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:58,041 INFO:     Epoch: 0
2022-12-05 21:45:58,831 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5239936682310972, 'Total loss': 0.5239936682310972} | train loss {'Reaction outcome loss': 0.8023880625203732, 'Total loss': 0.8023880625203732}
2022-12-05 21:45:58,832 INFO:     Found new best model at epoch 0
2022-12-05 21:45:58,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:58,832 INFO:     Epoch: 1
2022-12-05 21:45:59,625 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47192358191717754, 'Total loss': 0.47192358191717754} | train loss {'Reaction outcome loss': 0.5374099805710777, 'Total loss': 0.5374099805710777}
2022-12-05 21:45:59,625 INFO:     Found new best model at epoch 1
2022-12-05 21:45:59,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:45:59,626 INFO:     Epoch: 2
2022-12-05 21:46:00,425 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4387488720769232, 'Total loss': 0.4387488720769232} | train loss {'Reaction outcome loss': 0.4714762182726014, 'Total loss': 0.4714762182726014}
2022-12-05 21:46:00,426 INFO:     Found new best model at epoch 2
2022-12-05 21:46:00,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:00,427 INFO:     Epoch: 3
2022-12-05 21:46:01,226 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4156842434948141, 'Total loss': 0.4156842434948141} | train loss {'Reaction outcome loss': 0.4324251048026546, 'Total loss': 0.4324251048026546}
2022-12-05 21:46:01,227 INFO:     Found new best model at epoch 3
2022-12-05 21:46:01,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:01,227 INFO:     Epoch: 4
2022-12-05 21:46:02,022 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.406831815500151, 'Total loss': 0.406831815500151} | train loss {'Reaction outcome loss': 0.4032213105669906, 'Total loss': 0.4032213105669906}
2022-12-05 21:46:02,022 INFO:     Found new best model at epoch 4
2022-12-05 21:46:02,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:02,023 INFO:     Epoch: 5
2022-12-05 21:46:02,814 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.39835637265985663, 'Total loss': 0.39835637265985663} | train loss {'Reaction outcome loss': 0.3810287890655379, 'Total loss': 0.3810287890655379}
2022-12-05 21:46:02,815 INFO:     Found new best model at epoch 5
2022-12-05 21:46:02,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:02,815 INFO:     Epoch: 6
2022-12-05 21:46:03,606 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.38429330560294067, 'Total loss': 0.38429330560294067} | train loss {'Reaction outcome loss': 0.36177927874509364, 'Total loss': 0.36177927874509364}
2022-12-05 21:46:03,606 INFO:     Found new best model at epoch 6
2022-12-05 21:46:03,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:03,607 INFO:     Epoch: 7
2022-12-05 21:46:04,399 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38677789558741177, 'Total loss': 0.38677789558741177} | train loss {'Reaction outcome loss': 0.3445169572387972, 'Total loss': 0.3445169572387972}
2022-12-05 21:46:04,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:04,400 INFO:     Epoch: 8
2022-12-05 21:46:05,194 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3860045542771166, 'Total loss': 0.3860045542771166} | train loss {'Reaction outcome loss': 0.3270384442481783, 'Total loss': 0.3270384442481783}
2022-12-05 21:46:05,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:05,194 INFO:     Epoch: 9
2022-12-05 21:46:05,990 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3794169497083534, 'Total loss': 0.3794169497083534} | train loss {'Reaction outcome loss': 0.31412638585653996, 'Total loss': 0.31412638585653996}
2022-12-05 21:46:05,990 INFO:     Found new best model at epoch 9
2022-12-05 21:46:05,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:05,991 INFO:     Epoch: 10
2022-12-05 21:46:06,785 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.38421212610873307, 'Total loss': 0.38421212610873307} | train loss {'Reaction outcome loss': 0.30131733420515255, 'Total loss': 0.30131733420515255}
2022-12-05 21:46:06,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:06,786 INFO:     Epoch: 11
2022-12-05 21:46:07,576 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3828523785553195, 'Total loss': 0.3828523785553195} | train loss {'Reaction outcome loss': 0.2890887895538922, 'Total loss': 0.2890887895538922}
2022-12-05 21:46:07,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:07,576 INFO:     Epoch: 12
2022-12-05 21:46:08,371 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38326501507650723, 'Total loss': 0.38326501507650723} | train loss {'Reaction outcome loss': 0.2738462520402766, 'Total loss': 0.2738462520402766}
2022-12-05 21:46:08,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:08,372 INFO:     Epoch: 13
2022-12-05 21:46:09,163 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3762674294412136, 'Total loss': 0.3762674294412136} | train loss {'Reaction outcome loss': 0.2665065638120136, 'Total loss': 0.2665065638120136}
2022-12-05 21:46:09,163 INFO:     Found new best model at epoch 13
2022-12-05 21:46:09,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:09,164 INFO:     Epoch: 14
2022-12-05 21:46:09,962 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37898725034161046, 'Total loss': 0.37898725034161046} | train loss {'Reaction outcome loss': 0.25962926007266485, 'Total loss': 0.25962926007266485}
2022-12-05 21:46:09,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:09,963 INFO:     Epoch: 15
2022-12-05 21:46:10,763 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3735513478856195, 'Total loss': 0.3735513478856195} | train loss {'Reaction outcome loss': 0.24738855350522265, 'Total loss': 0.24738855350522265}
2022-12-05 21:46:10,763 INFO:     Found new best model at epoch 15
2022-12-05 21:46:10,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:10,764 INFO:     Epoch: 16
2022-12-05 21:46:11,557 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.37209087661044166, 'Total loss': 0.37209087661044166} | train loss {'Reaction outcome loss': 0.24067287768928275, 'Total loss': 0.24067287768928275}
2022-12-05 21:46:11,557 INFO:     Found new best model at epoch 16
2022-12-05 21:46:11,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:11,558 INFO:     Epoch: 17
2022-12-05 21:46:12,351 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.379504184153947, 'Total loss': 0.379504184153947} | train loss {'Reaction outcome loss': 0.23309033155261027, 'Total loss': 0.23309033155261027}
2022-12-05 21:46:12,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:12,351 INFO:     Epoch: 18
2022-12-05 21:46:13,144 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3827331845055927, 'Total loss': 0.3827331845055927} | train loss {'Reaction outcome loss': 0.2246050819334003, 'Total loss': 0.2246050819334003}
2022-12-05 21:46:13,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:13,145 INFO:     Epoch: 19
2022-12-05 21:46:13,937 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38652810555967415, 'Total loss': 0.38652810555967415} | train loss {'Reaction outcome loss': 0.2197773066319285, 'Total loss': 0.2197773066319285}
2022-12-05 21:46:13,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:13,937 INFO:     Epoch: 20
2022-12-05 21:46:14,734 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3930081247606061, 'Total loss': 0.3930081247606061} | train loss {'Reaction outcome loss': 0.213233970511224, 'Total loss': 0.213233970511224}
2022-12-05 21:46:14,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:14,734 INFO:     Epoch: 21
2022-12-05 21:46:15,526 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38094906508922577, 'Total loss': 0.38094906508922577} | train loss {'Reaction outcome loss': 0.21071012095818598, 'Total loss': 0.21071012095818598}
2022-12-05 21:46:15,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:15,526 INFO:     Epoch: 22
2022-12-05 21:46:16,317 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39115408494729886, 'Total loss': 0.39115408494729886} | train loss {'Reaction outcome loss': 0.2026275062422839, 'Total loss': 0.2026275062422839}
2022-12-05 21:46:16,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:16,318 INFO:     Epoch: 23
2022-12-05 21:46:17,114 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39655185727910564, 'Total loss': 0.39655185727910564} | train loss {'Reaction outcome loss': 0.20232891321422591, 'Total loss': 0.20232891321422591}
2022-12-05 21:46:17,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:17,114 INFO:     Epoch: 24
2022-12-05 21:46:17,908 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3821674207733436, 'Total loss': 0.3821674207733436} | train loss {'Reaction outcome loss': 0.20027429111782583, 'Total loss': 0.20027429111782583}
2022-12-05 21:46:17,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:17,908 INFO:     Epoch: 25
2022-12-05 21:46:18,705 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3914897204800086, 'Total loss': 0.3914897204800086} | train loss {'Reaction outcome loss': 0.19379089080217865, 'Total loss': 0.19379089080217865}
2022-12-05 21:46:18,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:18,705 INFO:     Epoch: 26
2022-12-05 21:46:19,504 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39648779413916846, 'Total loss': 0.39648779413916846} | train loss {'Reaction outcome loss': 0.18871148216778472, 'Total loss': 0.18871148216778472}
2022-12-05 21:46:19,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:19,505 INFO:     Epoch: 27
2022-12-05 21:46:20,296 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40085768936709926, 'Total loss': 0.40085768936709926} | train loss {'Reaction outcome loss': 0.18652917543846753, 'Total loss': 0.18652917543846753}
2022-12-05 21:46:20,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:20,296 INFO:     Epoch: 28
2022-12-05 21:46:21,088 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41126703132282605, 'Total loss': 0.41126703132282605} | train loss {'Reaction outcome loss': 0.18458163003707606, 'Total loss': 0.18458163003707606}
2022-12-05 21:46:21,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:21,088 INFO:     Epoch: 29
2022-12-05 21:46:21,881 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4044535275210034, 'Total loss': 0.4044535275210034} | train loss {'Reaction outcome loss': 0.18358867113748867, 'Total loss': 0.18358867113748867}
2022-12-05 21:46:21,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:21,881 INFO:     Epoch: 30
2022-12-05 21:46:22,675 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3958375829864632, 'Total loss': 0.3958375829864632} | train loss {'Reaction outcome loss': 0.18294471485029545, 'Total loss': 0.18294471485029545}
2022-12-05 21:46:22,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:22,675 INFO:     Epoch: 31
2022-12-05 21:46:23,467 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4039453224024989, 'Total loss': 0.4039453224024989} | train loss {'Reaction outcome loss': 0.1753523744071924, 'Total loss': 0.1753523744071924}
2022-12-05 21:46:23,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:23,468 INFO:     Epoch: 32
2022-12-05 21:46:24,262 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40361569821834564, 'Total loss': 0.40361569821834564} | train loss {'Reaction outcome loss': 0.1750261174935487, 'Total loss': 0.1750261174935487}
2022-12-05 21:46:24,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:24,262 INFO:     Epoch: 33
2022-12-05 21:46:25,057 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39425087601623754, 'Total loss': 0.39425087601623754} | train loss {'Reaction outcome loss': 0.17204796576932554, 'Total loss': 0.17204796576932554}
2022-12-05 21:46:25,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:25,058 INFO:     Epoch: 34
2022-12-05 21:46:25,851 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38712302747775207, 'Total loss': 0.38712302747775207} | train loss {'Reaction outcome loss': 0.1684481618295033, 'Total loss': 0.1684481618295033}
2022-12-05 21:46:25,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:25,851 INFO:     Epoch: 35
2022-12-05 21:46:26,648 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4121651210906831, 'Total loss': 0.4121651210906831} | train loss {'Reaction outcome loss': 0.16701743280094478, 'Total loss': 0.16701743280094478}
2022-12-05 21:46:26,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:26,648 INFO:     Epoch: 36
2022-12-05 21:46:27,446 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3964169650253924, 'Total loss': 0.3964169650253924} | train loss {'Reaction outcome loss': 0.1649517919117164, 'Total loss': 0.1649517919117164}
2022-12-05 21:46:27,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:27,446 INFO:     Epoch: 37
2022-12-05 21:46:28,238 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40187905593351886, 'Total loss': 0.40187905593351886} | train loss {'Reaction outcome loss': 0.1628897688614445, 'Total loss': 0.1628897688614445}
2022-12-05 21:46:28,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:28,239 INFO:     Epoch: 38
2022-12-05 21:46:29,033 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39206085489554837, 'Total loss': 0.39206085489554837} | train loss {'Reaction outcome loss': 0.1618753392624879, 'Total loss': 0.1618753392624879}
2022-12-05 21:46:29,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:29,033 INFO:     Epoch: 39
2022-12-05 21:46:29,828 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4123461425981738, 'Total loss': 0.4123461425981738} | train loss {'Reaction outcome loss': 0.16338980070600706, 'Total loss': 0.16338980070600706}
2022-12-05 21:46:29,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:29,829 INFO:     Epoch: 40
2022-12-05 21:46:30,625 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4084712774916129, 'Total loss': 0.4084712774916129} | train loss {'Reaction outcome loss': 0.16195394108898095, 'Total loss': 0.16195394108898095}
2022-12-05 21:46:30,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:30,625 INFO:     Epoch: 41
2022-12-05 21:46:31,424 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41947436874563043, 'Total loss': 0.41947436874563043} | train loss {'Reaction outcome loss': 0.15717458495149209, 'Total loss': 0.15717458495149209}
2022-12-05 21:46:31,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:31,425 INFO:     Epoch: 42
2022-12-05 21:46:32,223 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4130679778754711, 'Total loss': 0.4130679778754711} | train loss {'Reaction outcome loss': 0.15807216084231773, 'Total loss': 0.15807216084231773}
2022-12-05 21:46:32,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:32,223 INFO:     Epoch: 43
2022-12-05 21:46:33,022 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4190636778419668, 'Total loss': 0.4190636778419668} | train loss {'Reaction outcome loss': 0.15482615544310502, 'Total loss': 0.15482615544310502}
2022-12-05 21:46:33,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:33,022 INFO:     Epoch: 44
2022-12-05 21:46:33,824 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40920176526362245, 'Total loss': 0.40920176526362245} | train loss {'Reaction outcome loss': 0.15671006669741003, 'Total loss': 0.15671006669741003}
2022-12-05 21:46:33,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:33,824 INFO:     Epoch: 45
2022-12-05 21:46:34,626 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40369414538145065, 'Total loss': 0.40369414538145065} | train loss {'Reaction outcome loss': 0.1517133436300942, 'Total loss': 0.1517133436300942}
2022-12-05 21:46:34,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:34,627 INFO:     Epoch: 46
2022-12-05 21:46:35,431 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4009468550370498, 'Total loss': 0.4009468550370498} | train loss {'Reaction outcome loss': 0.15101139586148482, 'Total loss': 0.15101139586148482}
2022-12-05 21:46:35,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:35,432 INFO:     Epoch: 47
2022-12-05 21:46:36,233 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40263518555597827, 'Total loss': 0.40263518555597827} | train loss {'Reaction outcome loss': 0.15053219314675867, 'Total loss': 0.15053219314675867}
2022-12-05 21:46:36,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:36,233 INFO:     Epoch: 48
2022-12-05 21:46:37,038 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4087045067413287, 'Total loss': 0.4087045067413287} | train loss {'Reaction outcome loss': 0.1489062179969023, 'Total loss': 0.1489062179969023}
2022-12-05 21:46:37,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:37,038 INFO:     Epoch: 49
2022-12-05 21:46:37,840 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39239700798961247, 'Total loss': 0.39239700798961247} | train loss {'Reaction outcome loss': 0.1504251520457347, 'Total loss': 0.1504251520457347}
2022-12-05 21:46:37,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:37,840 INFO:     Epoch: 50
2022-12-05 21:46:38,643 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4090383357622407, 'Total loss': 0.4090383357622407} | train loss {'Reaction outcome loss': 0.15102584733282245, 'Total loss': 0.15102584733282245}
2022-12-05 21:46:38,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:38,644 INFO:     Epoch: 51
2022-12-05 21:46:39,447 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4079328931190751, 'Total loss': 0.4079328931190751} | train loss {'Reaction outcome loss': 0.14730823196981463, 'Total loss': 0.14730823196981463}
2022-12-05 21:46:39,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:39,447 INFO:     Epoch: 52
2022-12-05 21:46:40,248 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39635096151720395, 'Total loss': 0.39635096151720395} | train loss {'Reaction outcome loss': 0.14490636364151274, 'Total loss': 0.14490636364151274}
2022-12-05 21:46:40,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:40,248 INFO:     Epoch: 53
2022-12-05 21:46:41,047 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41353137587959116, 'Total loss': 0.41353137587959116} | train loss {'Reaction outcome loss': 0.14051433340195688, 'Total loss': 0.14051433340195688}
2022-12-05 21:46:41,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:41,047 INFO:     Epoch: 54
2022-12-05 21:46:41,848 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39497408304702153, 'Total loss': 0.39497408304702153} | train loss {'Reaction outcome loss': 0.14436500195804383, 'Total loss': 0.14436500195804383}
2022-12-05 21:46:41,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:41,848 INFO:     Epoch: 55
2022-12-05 21:46:42,652 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39938507008958946, 'Total loss': 0.39938507008958946} | train loss {'Reaction outcome loss': 0.14723525459938233, 'Total loss': 0.14723525459938233}
2022-12-05 21:46:42,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:42,652 INFO:     Epoch: 56
2022-12-05 21:46:43,456 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40220157124779443, 'Total loss': 0.40220157124779443} | train loss {'Reaction outcome loss': 0.14389015780761838, 'Total loss': 0.14389015780761838}
2022-12-05 21:46:43,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:43,457 INFO:     Epoch: 57
2022-12-05 21:46:44,259 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.403342508118261, 'Total loss': 0.403342508118261} | train loss {'Reaction outcome loss': 0.140687191930239, 'Total loss': 0.140687191930239}
2022-12-05 21:46:44,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:44,259 INFO:     Epoch: 58
2022-12-05 21:46:45,062 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3958157483826984, 'Total loss': 0.3958157483826984} | train loss {'Reaction outcome loss': 0.14196202888964646, 'Total loss': 0.14196202888964646}
2022-12-05 21:46:45,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:45,062 INFO:     Epoch: 59
2022-12-05 21:46:45,861 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39026906222782354, 'Total loss': 0.39026906222782354} | train loss {'Reaction outcome loss': 0.140459522522325, 'Total loss': 0.140459522522325}
2022-12-05 21:46:45,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:45,861 INFO:     Epoch: 60
2022-12-05 21:46:46,661 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41079201617024164, 'Total loss': 0.41079201617024164} | train loss {'Reaction outcome loss': 0.1404447649275103, 'Total loss': 0.1404447649275103}
2022-12-05 21:46:46,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:46,661 INFO:     Epoch: 61
2022-12-05 21:46:47,463 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3929978826675903, 'Total loss': 0.3929978826675903} | train loss {'Reaction outcome loss': 0.13736276266225164, 'Total loss': 0.13736276266225164}
2022-12-05 21:46:47,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:47,463 INFO:     Epoch: 62
2022-12-05 21:46:48,263 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40838596563447604, 'Total loss': 0.40838596563447604} | train loss {'Reaction outcome loss': 0.13535788278621172, 'Total loss': 0.13535788278621172}
2022-12-05 21:46:48,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:48,263 INFO:     Epoch: 63
2022-12-05 21:46:49,067 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40271398492834787, 'Total loss': 0.40271398492834787} | train loss {'Reaction outcome loss': 0.13940426791011687, 'Total loss': 0.13940426791011687}
2022-12-05 21:46:49,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:49,067 INFO:     Epoch: 64
2022-12-05 21:46:49,867 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40713435055857355, 'Total loss': 0.40713435055857355} | train loss {'Reaction outcome loss': 0.1365229609167023, 'Total loss': 0.1365229609167023}
2022-12-05 21:46:49,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:49,868 INFO:     Epoch: 65
2022-12-05 21:46:50,672 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3921336965127425, 'Total loss': 0.3921336965127425} | train loss {'Reaction outcome loss': 0.1381266633942423, 'Total loss': 0.1381266633942423}
2022-12-05 21:46:50,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:50,672 INFO:     Epoch: 66
2022-12-05 21:46:51,474 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3955626284534281, 'Total loss': 0.3955626284534281} | train loss {'Reaction outcome loss': 0.13495985758227988, 'Total loss': 0.13495985758227988}
2022-12-05 21:46:51,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:51,474 INFO:     Epoch: 67
2022-12-05 21:46:52,273 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39365827156738803, 'Total loss': 0.39365827156738803} | train loss {'Reaction outcome loss': 0.1334761211182922, 'Total loss': 0.1334761211182922}
2022-12-05 21:46:52,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:52,273 INFO:     Epoch: 68
2022-12-05 21:46:53,075 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4014487043869766, 'Total loss': 0.4014487043869766} | train loss {'Reaction outcome loss': 0.1356129019986838, 'Total loss': 0.1356129019986838}
2022-12-05 21:46:53,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:53,075 INFO:     Epoch: 69
2022-12-05 21:46:53,875 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4039255434816534, 'Total loss': 0.4039255434816534} | train loss {'Reaction outcome loss': 0.13203553372858873, 'Total loss': 0.13203553372858873}
2022-12-05 21:46:53,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:53,875 INFO:     Epoch: 70
2022-12-05 21:46:54,673 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.405168327587572, 'Total loss': 0.405168327587572} | train loss {'Reaction outcome loss': 0.13055552396502706, 'Total loss': 0.13055552396502706}
2022-12-05 21:46:54,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:54,673 INFO:     Epoch: 71
2022-12-05 21:46:55,475 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4088869733227925, 'Total loss': 0.4088869733227925} | train loss {'Reaction outcome loss': 0.1337396795974083, 'Total loss': 0.1337396795974083}
2022-12-05 21:46:55,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:55,475 INFO:     Epoch: 72
2022-12-05 21:46:56,274 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39010549658401444, 'Total loss': 0.39010549658401444} | train loss {'Reaction outcome loss': 0.1337101352288418, 'Total loss': 0.1337101352288418}
2022-12-05 21:46:56,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:56,275 INFO:     Epoch: 73
2022-12-05 21:46:57,074 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39643503522331064, 'Total loss': 0.39643503522331064} | train loss {'Reaction outcome loss': 0.13086471217684448, 'Total loss': 0.13086471217684448}
2022-12-05 21:46:57,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:57,074 INFO:     Epoch: 74
2022-12-05 21:46:57,873 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4003288806839423, 'Total loss': 0.4003288806839423} | train loss {'Reaction outcome loss': 0.1324595928026904, 'Total loss': 0.1324595928026904}
2022-12-05 21:46:57,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:57,873 INFO:     Epoch: 75
2022-12-05 21:46:58,674 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39584943042560056, 'Total loss': 0.39584943042560056} | train loss {'Reaction outcome loss': 0.13026001072684001, 'Total loss': 0.13026001072684001}
2022-12-05 21:46:58,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:58,675 INFO:     Epoch: 76
2022-12-05 21:46:59,477 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39366533573378215, 'Total loss': 0.39366533573378215} | train loss {'Reaction outcome loss': 0.12980074967227637, 'Total loss': 0.12980074967227637}
2022-12-05 21:46:59,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:46:59,477 INFO:     Epoch: 77
2022-12-05 21:47:00,279 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40439206835898484, 'Total loss': 0.40439206835898484} | train loss {'Reaction outcome loss': 0.13071995629598537, 'Total loss': 0.13071995629598537}
2022-12-05 21:47:00,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:00,280 INFO:     Epoch: 78
2022-12-05 21:47:01,084 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3992720405486497, 'Total loss': 0.3992720405486497} | train loss {'Reaction outcome loss': 0.12801240691764942, 'Total loss': 0.12801240691764942}
2022-12-05 21:47:01,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:01,084 INFO:     Epoch: 79
2022-12-05 21:47:01,888 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4042186638848348, 'Total loss': 0.4042186638848348} | train loss {'Reaction outcome loss': 0.1271805958296623, 'Total loss': 0.1271805958296623}
2022-12-05 21:47:01,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:01,888 INFO:     Epoch: 80
2022-12-05 21:47:02,691 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3929773243990811, 'Total loss': 0.3929773243990811} | train loss {'Reaction outcome loss': 0.12845464247549254, 'Total loss': 0.12845464247549254}
2022-12-05 21:47:02,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:02,692 INFO:     Epoch: 81
2022-12-05 21:47:03,492 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.400485903701999, 'Total loss': 0.400485903701999} | train loss {'Reaction outcome loss': 0.12639063018591953, 'Total loss': 0.12639063018591953}
2022-12-05 21:47:03,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:03,492 INFO:     Epoch: 82
2022-12-05 21:47:04,291 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4100231596014716, 'Total loss': 0.4100231596014716} | train loss {'Reaction outcome loss': 0.12606158269749534, 'Total loss': 0.12606158269749534}
2022-12-05 21:47:04,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:04,291 INFO:     Epoch: 83
2022-12-05 21:47:05,090 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40407583117485046, 'Total loss': 0.40407583117485046} | train loss {'Reaction outcome loss': 0.1260161135916508, 'Total loss': 0.1260161135916508}
2022-12-05 21:47:05,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:05,090 INFO:     Epoch: 84
2022-12-05 21:47:05,889 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4015287959270857, 'Total loss': 0.4015287959270857} | train loss {'Reaction outcome loss': 0.12501473736859137, 'Total loss': 0.12501473736859137}
2022-12-05 21:47:05,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:05,889 INFO:     Epoch: 85
2022-12-05 21:47:06,688 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3947528986768289, 'Total loss': 0.3947528986768289} | train loss {'Reaction outcome loss': 0.12507591000007046, 'Total loss': 0.12507591000007046}
2022-12-05 21:47:06,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:06,688 INFO:     Epoch: 86
2022-12-05 21:47:07,487 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4220762616870078, 'Total loss': 0.4220762616870078} | train loss {'Reaction outcome loss': 0.12403296488299666, 'Total loss': 0.12403296488299666}
2022-12-05 21:47:07,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:07,487 INFO:     Epoch: 87
2022-12-05 21:47:08,293 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4019105195660483, 'Total loss': 0.4019105195660483} | train loss {'Reaction outcome loss': 0.12559565300527478, 'Total loss': 0.12559565300527478}
2022-12-05 21:47:08,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:08,293 INFO:     Epoch: 88
2022-12-05 21:47:09,096 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4007286500524391, 'Total loss': 0.4007286500524391} | train loss {'Reaction outcome loss': 0.12458560328494998, 'Total loss': 0.12458560328494998}
2022-12-05 21:47:09,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:09,097 INFO:     Epoch: 89
2022-12-05 21:47:09,896 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4031134102154862, 'Total loss': 0.4031134102154862} | train loss {'Reaction outcome loss': 0.1238797599554903, 'Total loss': 0.1238797599554903}
2022-12-05 21:47:09,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:09,896 INFO:     Epoch: 90
2022-12-05 21:47:10,697 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3989384147253903, 'Total loss': 0.3989384147253903} | train loss {'Reaction outcome loss': 0.12250072353955117, 'Total loss': 0.12250072353955117}
2022-12-05 21:47:10,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:10,698 INFO:     Epoch: 91
2022-12-05 21:47:11,502 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3958912728862329, 'Total loss': 0.3958912728862329} | train loss {'Reaction outcome loss': 0.12303955023432331, 'Total loss': 0.12303955023432331}
2022-12-05 21:47:11,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:11,502 INFO:     Epoch: 92
2022-12-05 21:47:12,301 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39688367142596026, 'Total loss': 0.39688367142596026} | train loss {'Reaction outcome loss': 0.12195891499774711, 'Total loss': 0.12195891499774711}
2022-12-05 21:47:12,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:12,301 INFO:     Epoch: 93
2022-12-05 21:47:13,108 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3941900391470302, 'Total loss': 0.3941900391470302} | train loss {'Reaction outcome loss': 0.12275282776118407, 'Total loss': 0.12275282776118407}
2022-12-05 21:47:13,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:13,108 INFO:     Epoch: 94
2022-12-05 21:47:13,908 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3973265417258848, 'Total loss': 0.3973265417258848} | train loss {'Reaction outcome loss': 0.11926520882069223, 'Total loss': 0.11926520882069223}
2022-12-05 21:47:13,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:13,909 INFO:     Epoch: 95
2022-12-05 21:47:14,709 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39748350818726147, 'Total loss': 0.39748350818726147} | train loss {'Reaction outcome loss': 0.11898055885948482, 'Total loss': 0.11898055885948482}
2022-12-05 21:47:14,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:14,710 INFO:     Epoch: 96
2022-12-05 21:47:15,512 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41088123619556427, 'Total loss': 0.41088123619556427} | train loss {'Reaction outcome loss': 0.12092163693159819, 'Total loss': 0.12092163693159819}
2022-12-05 21:47:15,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:15,512 INFO:     Epoch: 97
2022-12-05 21:47:16,311 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41101559353145684, 'Total loss': 0.41101559353145684} | train loss {'Reaction outcome loss': 0.12376028597505102, 'Total loss': 0.12376028597505102}
2022-12-05 21:47:16,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:16,312 INFO:     Epoch: 98
2022-12-05 21:47:17,111 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3937631334093484, 'Total loss': 0.3937631334093484} | train loss {'Reaction outcome loss': 0.12330503019339015, 'Total loss': 0.12330503019339015}
2022-12-05 21:47:17,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:17,112 INFO:     Epoch: 99
2022-12-05 21:47:17,913 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3907985056496479, 'Total loss': 0.3907985056496479} | train loss {'Reaction outcome loss': 0.11949273525181436, 'Total loss': 0.11949273525181436}
2022-12-05 21:47:17,913 INFO:     Best model found after epoch 17 of 100.
2022-12-05 21:47:17,913 INFO:   Done with stage: TRAINING
2022-12-05 21:47:17,913 INFO:   Starting stage: EVALUATION
2022-12-05 21:47:18,033 INFO:   Done with stage: EVALUATION
2022-12-05 21:47:18,041 INFO:   Leaving out SEQ value Fold_0
2022-12-05 21:47:18,053 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:47:18,053 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:47:18,690 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:47:18,690 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:47:18,759 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:47:18,759 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:47:18,759 INFO:     No hyperparam tuning for this model
2022-12-05 21:47:18,759 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:47:18,759 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:47:18,760 INFO:     None feature selector for col prot
2022-12-05 21:47:18,760 INFO:     None feature selector for col prot
2022-12-05 21:47:18,760 INFO:     None feature selector for col prot
2022-12-05 21:47:18,761 INFO:     None feature selector for col chem
2022-12-05 21:47:18,761 INFO:     None feature selector for col chem
2022-12-05 21:47:18,761 INFO:     None feature selector for col chem
2022-12-05 21:47:18,761 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:47:18,761 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:47:18,762 INFO:     Number of params in model 215821
2022-12-05 21:47:18,765 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:47:18,766 INFO:   Starting stage: TRAINING
2022-12-05 21:47:18,826 INFO:     Val loss before train {'Reaction outcome loss': 0.9510838660326871, 'Total loss': 0.9510838660326871}
2022-12-05 21:47:18,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:18,826 INFO:     Epoch: 0
2022-12-05 21:47:19,615 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5808213244784962, 'Total loss': 0.5808213244784962} | train loss {'Reaction outcome loss': 0.7915159003466976, 'Total loss': 0.7915159003466976}
2022-12-05 21:47:19,615 INFO:     Found new best model at epoch 0
2022-12-05 21:47:19,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:19,616 INFO:     Epoch: 1
2022-12-05 21:47:20,408 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5016090216284449, 'Total loss': 0.5016090216284449} | train loss {'Reaction outcome loss': 0.5295198559761047, 'Total loss': 0.5295198559761047}
2022-12-05 21:47:20,408 INFO:     Found new best model at epoch 1
2022-12-05 21:47:20,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:20,409 INFO:     Epoch: 2
2022-12-05 21:47:21,199 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47202476452697406, 'Total loss': 0.47202476452697406} | train loss {'Reaction outcome loss': 0.4647851451927302, 'Total loss': 0.4647851451927302}
2022-12-05 21:47:21,199 INFO:     Found new best model at epoch 2
2022-12-05 21:47:21,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:21,200 INFO:     Epoch: 3
2022-12-05 21:47:21,998 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4576388821005821, 'Total loss': 0.4576388821005821} | train loss {'Reaction outcome loss': 0.4231295099672006, 'Total loss': 0.4231295099672006}
2022-12-05 21:47:21,998 INFO:     Found new best model at epoch 3
2022-12-05 21:47:21,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:21,999 INFO:     Epoch: 4
2022-12-05 21:47:22,791 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44803994690830057, 'Total loss': 0.44803994690830057} | train loss {'Reaction outcome loss': 0.39691095181873864, 'Total loss': 0.39691095181873864}
2022-12-05 21:47:22,791 INFO:     Found new best model at epoch 4
2022-12-05 21:47:22,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:22,792 INFO:     Epoch: 5
2022-12-05 21:47:23,587 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4248700307851488, 'Total loss': 0.4248700307851488} | train loss {'Reaction outcome loss': 0.3765380314722353, 'Total loss': 0.3765380314722353}
2022-12-05 21:47:23,588 INFO:     Found new best model at epoch 5
2022-12-05 21:47:23,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:23,588 INFO:     Epoch: 6
2022-12-05 21:47:24,383 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4168388951908458, 'Total loss': 0.4168388951908458} | train loss {'Reaction outcome loss': 0.3591629854878601, 'Total loss': 0.3591629854878601}
2022-12-05 21:47:24,383 INFO:     Found new best model at epoch 6
2022-12-05 21:47:24,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:24,384 INFO:     Epoch: 7
2022-12-05 21:47:25,173 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3984301676127044, 'Total loss': 0.3984301676127044} | train loss {'Reaction outcome loss': 0.3410853739295687, 'Total loss': 0.3410853739295687}
2022-12-05 21:47:25,173 INFO:     Found new best model at epoch 7
2022-12-05 21:47:25,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:25,174 INFO:     Epoch: 8
2022-12-05 21:47:25,970 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4130515076897361, 'Total loss': 0.4130515076897361} | train loss {'Reaction outcome loss': 0.32697911149993236, 'Total loss': 0.32697911149993236}
2022-12-05 21:47:25,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:25,971 INFO:     Epoch: 9
2022-12-05 21:47:26,763 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4074354683133689, 'Total loss': 0.4074354683133689} | train loss {'Reaction outcome loss': 0.3119544392033499, 'Total loss': 0.3119544392033499}
2022-12-05 21:47:26,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:26,764 INFO:     Epoch: 10
2022-12-05 21:47:27,555 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3962618053192273, 'Total loss': 0.3962618053192273} | train loss {'Reaction outcome loss': 0.30222206882068087, 'Total loss': 0.30222206882068087}
2022-12-05 21:47:27,556 INFO:     Found new best model at epoch 10
2022-12-05 21:47:27,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:27,557 INFO:     Epoch: 11
2022-12-05 21:47:28,349 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40276048704981804, 'Total loss': 0.40276048704981804} | train loss {'Reaction outcome loss': 0.29205761316175366, 'Total loss': 0.29205761316175366}
2022-12-05 21:47:28,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:28,349 INFO:     Epoch: 12
2022-12-05 21:47:29,138 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40250684828920796, 'Total loss': 0.40250684828920796} | train loss {'Reaction outcome loss': 0.28056324762957435, 'Total loss': 0.28056324762957435}
2022-12-05 21:47:29,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:29,139 INFO:     Epoch: 13
2022-12-05 21:47:29,927 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4011905802921815, 'Total loss': 0.4011905802921815} | train loss {'Reaction outcome loss': 0.27406046451354515, 'Total loss': 0.27406046451354515}
2022-12-05 21:47:29,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:29,927 INFO:     Epoch: 14
2022-12-05 21:47:30,718 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3952555787876587, 'Total loss': 0.3952555787876587} | train loss {'Reaction outcome loss': 0.2627912785629837, 'Total loss': 0.2627912785629837}
2022-12-05 21:47:30,718 INFO:     Found new best model at epoch 14
2022-12-05 21:47:30,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:30,719 INFO:     Epoch: 15
2022-12-05 21:47:31,507 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4065194343301383, 'Total loss': 0.4065194343301383} | train loss {'Reaction outcome loss': 0.25584977862178065, 'Total loss': 0.25584977862178065}
2022-12-05 21:47:31,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:31,508 INFO:     Epoch: 16
2022-12-05 21:47:32,296 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41223457354036247, 'Total loss': 0.41223457354036247} | train loss {'Reaction outcome loss': 0.24892017430796914, 'Total loss': 0.24892017430796914}
2022-12-05 21:47:32,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:32,297 INFO:     Epoch: 17
2022-12-05 21:47:33,088 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40236757492477243, 'Total loss': 0.40236757492477243} | train loss {'Reaction outcome loss': 0.2436545574847533, 'Total loss': 0.2436545574847533}
2022-12-05 21:47:33,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:33,088 INFO:     Epoch: 18
2022-12-05 21:47:33,882 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4130641001869332, 'Total loss': 0.4130641001869332} | train loss {'Reaction outcome loss': 0.2355357573652754, 'Total loss': 0.2355357573652754}
2022-12-05 21:47:33,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:33,883 INFO:     Epoch: 19
2022-12-05 21:47:34,679 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42105795883319597, 'Total loss': 0.42105795883319597} | train loss {'Reaction outcome loss': 0.2308613678934623, 'Total loss': 0.2308613678934623}
2022-12-05 21:47:34,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:34,679 INFO:     Epoch: 20
2022-12-05 21:47:35,470 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40953919901089236, 'Total loss': 0.40953919901089236} | train loss {'Reaction outcome loss': 0.22530572320125541, 'Total loss': 0.22530572320125541}
2022-12-05 21:47:35,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:35,470 INFO:     Epoch: 21
2022-12-05 21:47:36,264 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40691169385205617, 'Total loss': 0.40691169385205617} | train loss {'Reaction outcome loss': 0.22083389783392146, 'Total loss': 0.22083389783392146}
2022-12-05 21:47:36,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:36,265 INFO:     Epoch: 22
2022-12-05 21:47:37,060 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40417765063995664, 'Total loss': 0.40417765063995664} | train loss {'Reaction outcome loss': 0.21607070460307354, 'Total loss': 0.21607070460307354}
2022-12-05 21:47:37,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:37,060 INFO:     Epoch: 23
2022-12-05 21:47:37,852 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4084232486784458, 'Total loss': 0.4084232486784458} | train loss {'Reaction outcome loss': 0.20877559154617542, 'Total loss': 0.20877559154617542}
2022-12-05 21:47:37,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:37,852 INFO:     Epoch: 24
2022-12-05 21:47:38,643 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4006247168237513, 'Total loss': 0.4006247168237513} | train loss {'Reaction outcome loss': 0.20699337065523984, 'Total loss': 0.20699337065523984}
2022-12-05 21:47:38,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:38,643 INFO:     Epoch: 25
2022-12-05 21:47:39,437 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42094687363979494, 'Total loss': 0.42094687363979494} | train loss {'Reaction outcome loss': 0.20077569375232773, 'Total loss': 0.20077569375232773}
2022-12-05 21:47:39,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:39,438 INFO:     Epoch: 26
2022-12-05 21:47:40,231 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4103693718259985, 'Total loss': 0.4103693718259985} | train loss {'Reaction outcome loss': 0.19424684541870135, 'Total loss': 0.19424684541870135}
2022-12-05 21:47:40,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:40,231 INFO:     Epoch: 27
2022-12-05 21:47:41,021 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40778872048990294, 'Total loss': 0.40778872048990294} | train loss {'Reaction outcome loss': 0.19417029725653784, 'Total loss': 0.19417029725653784}
2022-12-05 21:47:41,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:41,021 INFO:     Epoch: 28
2022-12-05 21:47:41,813 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42238736034116964, 'Total loss': 0.42238736034116964} | train loss {'Reaction outcome loss': 0.1891689079376508, 'Total loss': 0.1891689079376508}
2022-12-05 21:47:41,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:41,813 INFO:     Epoch: 29
2022-12-05 21:47:42,606 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42352173545143823, 'Total loss': 0.42352173545143823} | train loss {'Reaction outcome loss': 0.18779486024714245, 'Total loss': 0.18779486024714245}
2022-12-05 21:47:42,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:42,607 INFO:     Epoch: 30
2022-12-05 21:47:43,397 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4230510819364678, 'Total loss': 0.4230510819364678} | train loss {'Reaction outcome loss': 0.18552343363360482, 'Total loss': 0.18552343363360482}
2022-12-05 21:47:43,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:43,397 INFO:     Epoch: 31
2022-12-05 21:47:44,190 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4235020764172077, 'Total loss': 0.4235020764172077} | train loss {'Reaction outcome loss': 0.18273288909421892, 'Total loss': 0.18273288909421892}
2022-12-05 21:47:44,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:44,190 INFO:     Epoch: 32
2022-12-05 21:47:44,980 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41756313802166417, 'Total loss': 0.41756313802166417} | train loss {'Reaction outcome loss': 0.1799668026365796, 'Total loss': 0.1799668026365796}
2022-12-05 21:47:44,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:44,980 INFO:     Epoch: 33
2022-12-05 21:47:45,772 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4157238035378131, 'Total loss': 0.4157238035378131} | train loss {'Reaction outcome loss': 0.1756081825768461, 'Total loss': 0.1756081825768461}
2022-12-05 21:47:45,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:45,772 INFO:     Epoch: 34
2022-12-05 21:47:46,562 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41629583659497177, 'Total loss': 0.41629583659497177} | train loss {'Reaction outcome loss': 0.17546592576011102, 'Total loss': 0.17546592576011102}
2022-12-05 21:47:46,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:46,563 INFO:     Epoch: 35
2022-12-05 21:47:47,359 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4254115931689739, 'Total loss': 0.4254115931689739} | train loss {'Reaction outcome loss': 0.16982665503283545, 'Total loss': 0.16982665503283545}
2022-12-05 21:47:47,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:47,359 INFO:     Epoch: 36
2022-12-05 21:47:48,150 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43299487233161926, 'Total loss': 0.43299487233161926} | train loss {'Reaction outcome loss': 0.1687505267560482, 'Total loss': 0.1687505267560482}
2022-12-05 21:47:48,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:48,150 INFO:     Epoch: 37
2022-12-05 21:47:48,939 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44515469060702756, 'Total loss': 0.44515469060702756} | train loss {'Reaction outcome loss': 0.16770821062429828, 'Total loss': 0.16770821062429828}
2022-12-05 21:47:48,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:48,940 INFO:     Epoch: 38
2022-12-05 21:47:49,730 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43073455413634126, 'Total loss': 0.43073455413634126} | train loss {'Reaction outcome loss': 0.16513186719040482, 'Total loss': 0.16513186719040482}
2022-12-05 21:47:49,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:49,730 INFO:     Epoch: 39
2022-12-05 21:47:50,522 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4305525293404406, 'Total loss': 0.4305525293404406} | train loss {'Reaction outcome loss': 0.16466507309933706, 'Total loss': 0.16466507309933706}
2022-12-05 21:47:50,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:50,523 INFO:     Epoch: 40
2022-12-05 21:47:51,316 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41661864620718086, 'Total loss': 0.41661864620718086} | train loss {'Reaction outcome loss': 0.15980071726502204, 'Total loss': 0.15980071726502204}
2022-12-05 21:47:51,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:51,317 INFO:     Epoch: 41
2022-12-05 21:47:52,107 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4271990348669616, 'Total loss': 0.4271990348669616} | train loss {'Reaction outcome loss': 0.158361737049964, 'Total loss': 0.158361737049964}
2022-12-05 21:47:52,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:52,107 INFO:     Epoch: 42
2022-12-05 21:47:52,903 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4325078045102683, 'Total loss': 0.4325078045102683} | train loss {'Reaction outcome loss': 0.15697877797849324, 'Total loss': 0.15697877797849324}
2022-12-05 21:47:52,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:52,903 INFO:     Epoch: 43
2022-12-05 21:47:53,693 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4248264952224087, 'Total loss': 0.4248264952224087} | train loss {'Reaction outcome loss': 0.1575823969036645, 'Total loss': 0.1575823969036645}
2022-12-05 21:47:53,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:53,694 INFO:     Epoch: 44
2022-12-05 21:47:54,488 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4239110655405305, 'Total loss': 0.4239110655405305} | train loss {'Reaction outcome loss': 0.15167781961511592, 'Total loss': 0.15167781961511592}
2022-12-05 21:47:54,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:54,488 INFO:     Epoch: 45
2022-12-05 21:47:55,278 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42057353867725894, 'Total loss': 0.42057353867725894} | train loss {'Reaction outcome loss': 0.15216931957675486, 'Total loss': 0.15216931957675486}
2022-12-05 21:47:55,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:55,279 INFO:     Epoch: 46
2022-12-05 21:47:56,074 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44146373673257505, 'Total loss': 0.44146373673257505} | train loss {'Reaction outcome loss': 0.15093032471379456, 'Total loss': 0.15093032471379456}
2022-12-05 21:47:56,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:56,074 INFO:     Epoch: 47
2022-12-05 21:47:56,872 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42682479813017626, 'Total loss': 0.42682479813017626} | train loss {'Reaction outcome loss': 0.14805219002372147, 'Total loss': 0.14805219002372147}
2022-12-05 21:47:56,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:56,872 INFO:     Epoch: 48
2022-12-05 21:47:57,667 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42846007621847093, 'Total loss': 0.42846007621847093} | train loss {'Reaction outcome loss': 0.15038818612846794, 'Total loss': 0.15038818612846794}
2022-12-05 21:47:57,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:57,667 INFO:     Epoch: 49
2022-12-05 21:47:58,457 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4335098334334113, 'Total loss': 0.4335098334334113} | train loss {'Reaction outcome loss': 0.14369739451426633, 'Total loss': 0.14369739451426633}
2022-12-05 21:47:58,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:58,459 INFO:     Epoch: 50
2022-12-05 21:47:59,251 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44643625955690036, 'Total loss': 0.44643625955690036} | train loss {'Reaction outcome loss': 0.14356302524707756, 'Total loss': 0.14356302524707756}
2022-12-05 21:47:59,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:47:59,252 INFO:     Epoch: 51
2022-12-05 21:48:00,043 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.426402476023544, 'Total loss': 0.426402476023544} | train loss {'Reaction outcome loss': 0.14438854492440514, 'Total loss': 0.14438854492440514}
2022-12-05 21:48:00,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:00,043 INFO:     Epoch: 52
2022-12-05 21:48:00,836 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4261098365214738, 'Total loss': 0.4261098365214738} | train loss {'Reaction outcome loss': 0.14624956250570867, 'Total loss': 0.14624956250570867}
2022-12-05 21:48:00,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:00,836 INFO:     Epoch: 53
2022-12-05 21:48:01,625 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4244072742082856, 'Total loss': 0.4244072742082856} | train loss {'Reaction outcome loss': 0.14294631099898597, 'Total loss': 0.14294631099898597}
2022-12-05 21:48:01,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:01,625 INFO:     Epoch: 54
2022-12-05 21:48:02,422 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42584821818904445, 'Total loss': 0.42584821818904445} | train loss {'Reaction outcome loss': 0.14074988594392732, 'Total loss': 0.14074988594392732}
2022-12-05 21:48:02,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:02,423 INFO:     Epoch: 55
2022-12-05 21:48:03,217 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4452043319628997, 'Total loss': 0.4452043319628997} | train loss {'Reaction outcome loss': 0.1416986589871195, 'Total loss': 0.1416986589871195}
2022-12-05 21:48:03,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:03,217 INFO:     Epoch: 56
2022-12-05 21:48:04,012 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43890339440920134, 'Total loss': 0.43890339440920134} | train loss {'Reaction outcome loss': 0.13770778687024604, 'Total loss': 0.13770778687024604}
2022-12-05 21:48:04,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:04,012 INFO:     Epoch: 57
2022-12-05 21:48:04,801 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4442229612984441, 'Total loss': 0.4442229612984441} | train loss {'Reaction outcome loss': 0.13937933124145682, 'Total loss': 0.13937933124145682}
2022-12-05 21:48:04,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:04,802 INFO:     Epoch: 58
2022-12-05 21:48:05,595 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4578866796060042, 'Total loss': 0.4578866796060042} | train loss {'Reaction outcome loss': 0.13677999693520215, 'Total loss': 0.13677999693520215}
2022-12-05 21:48:05,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:05,595 INFO:     Epoch: 59
2022-12-05 21:48:06,387 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43402481993491, 'Total loss': 0.43402481993491} | train loss {'Reaction outcome loss': 0.13663746599792218, 'Total loss': 0.13663746599792218}
2022-12-05 21:48:06,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:06,387 INFO:     Epoch: 60
2022-12-05 21:48:07,177 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45388540938835253, 'Total loss': 0.45388540938835253} | train loss {'Reaction outcome loss': 0.13428500936727744, 'Total loss': 0.13428500936727744}
2022-12-05 21:48:07,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:07,177 INFO:     Epoch: 61
2022-12-05 21:48:07,970 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44371797381476924, 'Total loss': 0.44371797381476924} | train loss {'Reaction outcome loss': 0.13183665793313057, 'Total loss': 0.13183665793313057}
2022-12-05 21:48:07,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:07,971 INFO:     Epoch: 62
2022-12-05 21:48:08,768 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4329910230907527, 'Total loss': 0.4329910230907527} | train loss {'Reaction outcome loss': 0.13409354056478764, 'Total loss': 0.13409354056478764}
2022-12-05 21:48:08,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:08,768 INFO:     Epoch: 63
2022-12-05 21:48:09,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4322667467323216, 'Total loss': 0.4322667467323216} | train loss {'Reaction outcome loss': 0.1341822056213812, 'Total loss': 0.1341822056213812}
2022-12-05 21:48:09,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:09,557 INFO:     Epoch: 64
2022-12-05 21:48:10,350 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45523247766223823, 'Total loss': 0.45523247766223823} | train loss {'Reaction outcome loss': 0.1336439148731986, 'Total loss': 0.1336439148731986}
2022-12-05 21:48:10,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:10,350 INFO:     Epoch: 65
2022-12-05 21:48:11,144 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4281441399996931, 'Total loss': 0.4281441399996931} | train loss {'Reaction outcome loss': 0.13356628181526856, 'Total loss': 0.13356628181526856}
2022-12-05 21:48:11,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:11,144 INFO:     Epoch: 66
2022-12-05 21:48:11,937 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4370565035126426, 'Total loss': 0.4370565035126426} | train loss {'Reaction outcome loss': 0.13229700683102924, 'Total loss': 0.13229700683102924}
2022-12-05 21:48:11,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:11,937 INFO:     Epoch: 67
2022-12-05 21:48:12,730 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43414756520227954, 'Total loss': 0.43414756520227954} | train loss {'Reaction outcome loss': 0.12853318268471225, 'Total loss': 0.12853318268471225}
2022-12-05 21:48:12,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:12,730 INFO:     Epoch: 68
2022-12-05 21:48:13,518 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42613507400859485, 'Total loss': 0.42613507400859485} | train loss {'Reaction outcome loss': 0.12919886702177477, 'Total loss': 0.12919886702177477}
2022-12-05 21:48:13,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:13,519 INFO:     Epoch: 69
2022-12-05 21:48:14,309 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42088776031001046, 'Total loss': 0.42088776031001046} | train loss {'Reaction outcome loss': 0.13163171535623924, 'Total loss': 0.13163171535623924}
2022-12-05 21:48:14,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:14,310 INFO:     Epoch: 70
2022-12-05 21:48:15,105 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.417699455876242, 'Total loss': 0.417699455876242} | train loss {'Reaction outcome loss': 0.129662155306765, 'Total loss': 0.129662155306765}
2022-12-05 21:48:15,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:15,105 INFO:     Epoch: 71
2022-12-05 21:48:15,901 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4456114194948565, 'Total loss': 0.4456114194948565} | train loss {'Reaction outcome loss': 0.13055992634700878, 'Total loss': 0.13055992634700878}
2022-12-05 21:48:15,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:15,901 INFO:     Epoch: 72
2022-12-05 21:48:16,697 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43490068953145633, 'Total loss': 0.43490068953145633} | train loss {'Reaction outcome loss': 0.12929169952261205, 'Total loss': 0.12929169952261205}
2022-12-05 21:48:16,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:16,697 INFO:     Epoch: 73
2022-12-05 21:48:17,493 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4285344821824269, 'Total loss': 0.4285344821824269} | train loss {'Reaction outcome loss': 0.12512235278073622, 'Total loss': 0.12512235278073622}
2022-12-05 21:48:17,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:17,494 INFO:     Epoch: 74
2022-12-05 21:48:18,291 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4145695616448806, 'Total loss': 0.4145695616448806} | train loss {'Reaction outcome loss': 0.12332024800458125, 'Total loss': 0.12332024800458125}
2022-12-05 21:48:18,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:18,291 INFO:     Epoch: 75
2022-12-05 21:48:19,082 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4216489218683405, 'Total loss': 0.4216489218683405} | train loss {'Reaction outcome loss': 0.12656262579697128, 'Total loss': 0.12656262579697128}
2022-12-05 21:48:19,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:19,082 INFO:     Epoch: 76
2022-12-05 21:48:19,876 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4096717138520696, 'Total loss': 0.4096717138520696} | train loss {'Reaction outcome loss': 0.12431249504490774, 'Total loss': 0.12431249504490774}
2022-12-05 21:48:19,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:19,876 INFO:     Epoch: 77
2022-12-05 21:48:20,675 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4370753668587316, 'Total loss': 0.4370753668587316} | train loss {'Reaction outcome loss': 0.1223690105336053, 'Total loss': 0.1223690105336053}
2022-12-05 21:48:20,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:20,675 INFO:     Epoch: 78
2022-12-05 21:48:21,466 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44332107647576113, 'Total loss': 0.44332107647576113} | train loss {'Reaction outcome loss': 0.1236487920757155, 'Total loss': 0.1236487920757155}
2022-12-05 21:48:21,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:21,466 INFO:     Epoch: 79
2022-12-05 21:48:22,259 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.416861453178254, 'Total loss': 0.416861453178254} | train loss {'Reaction outcome loss': 0.12293840738735637, 'Total loss': 0.12293840738735637}
2022-12-05 21:48:22,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:22,260 INFO:     Epoch: 80
2022-12-05 21:48:23,052 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40479810027913615, 'Total loss': 0.40479810027913615} | train loss {'Reaction outcome loss': 0.12355440228569264, 'Total loss': 0.12355440228569264}
2022-12-05 21:48:23,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:23,052 INFO:     Epoch: 81
2022-12-05 21:48:23,847 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4507804492657835, 'Total loss': 0.4507804492657835} | train loss {'Reaction outcome loss': 0.12393846633863084, 'Total loss': 0.12393846633863084}
2022-12-05 21:48:23,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:23,847 INFO:     Epoch: 82
2022-12-05 21:48:24,638 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4511946825818582, 'Total loss': 0.4511946825818582} | train loss {'Reaction outcome loss': 0.12028725292837741, 'Total loss': 0.12028725292837741}
2022-12-05 21:48:24,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:24,638 INFO:     Epoch: 83
2022-12-05 21:48:25,432 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43805787644603034, 'Total loss': 0.43805787644603034} | train loss {'Reaction outcome loss': 0.12151985938223649, 'Total loss': 0.12151985938223649}
2022-12-05 21:48:25,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:25,433 INFO:     Epoch: 84
2022-12-05 21:48:26,224 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4188593775033951, 'Total loss': 0.4188593775033951} | train loss {'Reaction outcome loss': 0.12210866751111284, 'Total loss': 0.12210866751111284}
2022-12-05 21:48:26,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:26,224 INFO:     Epoch: 85
2022-12-05 21:48:27,018 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43935035973448644, 'Total loss': 0.43935035973448644} | train loss {'Reaction outcome loss': 0.11843764091252672, 'Total loss': 0.11843764091252672}
2022-12-05 21:48:27,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:27,018 INFO:     Epoch: 86
2022-12-05 21:48:27,812 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41471589398993686, 'Total loss': 0.41471589398993686} | train loss {'Reaction outcome loss': 0.11679902656041846, 'Total loss': 0.11679902656041846}
2022-12-05 21:48:27,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:27,812 INFO:     Epoch: 87
2022-12-05 21:48:28,602 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4224733996459029, 'Total loss': 0.4224733996459029} | train loss {'Reaction outcome loss': 0.11979162814665814, 'Total loss': 0.11979162814665814}
2022-12-05 21:48:28,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:28,602 INFO:     Epoch: 88
2022-12-05 21:48:29,395 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42453143919225445, 'Total loss': 0.42453143919225445} | train loss {'Reaction outcome loss': 0.11940965553251456, 'Total loss': 0.11940965553251456}
2022-12-05 21:48:29,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:29,397 INFO:     Epoch: 89
2022-12-05 21:48:30,193 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45391910506243055, 'Total loss': 0.45391910506243055} | train loss {'Reaction outcome loss': 0.12080800581191267, 'Total loss': 0.12080800581191267}
2022-12-05 21:48:30,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:30,194 INFO:     Epoch: 90
2022-12-05 21:48:30,989 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43748451870950783, 'Total loss': 0.43748451870950783} | train loss {'Reaction outcome loss': 0.12104850936757058, 'Total loss': 0.12104850936757058}
2022-12-05 21:48:30,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:30,989 INFO:     Epoch: 91
2022-12-05 21:48:31,785 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4252120360324625, 'Total loss': 0.4252120360324625} | train loss {'Reaction outcome loss': 0.11795715140748997, 'Total loss': 0.11795715140748997}
2022-12-05 21:48:31,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:31,785 INFO:     Epoch: 92
2022-12-05 21:48:32,577 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4198363106697798, 'Total loss': 0.4198363106697798} | train loss {'Reaction outcome loss': 0.11897517142399233, 'Total loss': 0.11897517142399233}
2022-12-05 21:48:32,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:32,577 INFO:     Epoch: 93
2022-12-05 21:48:33,370 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.440146560526707, 'Total loss': 0.440146560526707} | train loss {'Reaction outcome loss': 0.11708227737559652, 'Total loss': 0.11708227737559652}
2022-12-05 21:48:33,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:33,371 INFO:     Epoch: 94
2022-12-05 21:48:34,162 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43734927560118114, 'Total loss': 0.43734927560118114} | train loss {'Reaction outcome loss': 0.11446080112411659, 'Total loss': 0.11446080112411659}
2022-12-05 21:48:34,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:34,163 INFO:     Epoch: 95
2022-12-05 21:48:34,957 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4578655551780354, 'Total loss': 0.4578655551780354} | train loss {'Reaction outcome loss': 0.11560030219582271, 'Total loss': 0.11560030219582271}
2022-12-05 21:48:34,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:34,957 INFO:     Epoch: 96
2022-12-05 21:48:35,757 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4301786151799289, 'Total loss': 0.4301786151799289} | train loss {'Reaction outcome loss': 0.11626903290043072, 'Total loss': 0.11626903290043072}
2022-12-05 21:48:35,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:35,758 INFO:     Epoch: 97
2022-12-05 21:48:36,551 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4360847551036965, 'Total loss': 0.4360847551036965} | train loss {'Reaction outcome loss': 0.1155911240194525, 'Total loss': 0.1155911240194525}
2022-12-05 21:48:36,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:36,551 INFO:     Epoch: 98
2022-12-05 21:48:37,341 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4340379878201268, 'Total loss': 0.4340379878201268} | train loss {'Reaction outcome loss': 0.11763405976246814, 'Total loss': 0.11763405976246814}
2022-12-05 21:48:37,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:37,341 INFO:     Epoch: 99
2022-12-05 21:48:38,133 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4249723626708146, 'Total loss': 0.4249723626708146} | train loss {'Reaction outcome loss': 0.11454452390459423, 'Total loss': 0.11454452390459423}
2022-12-05 21:48:38,133 INFO:     Best model found after epoch 15 of 100.
2022-12-05 21:48:38,134 INFO:   Done with stage: TRAINING
2022-12-05 21:48:38,134 INFO:   Starting stage: EVALUATION
2022-12-05 21:48:38,266 INFO:   Done with stage: EVALUATION
2022-12-05 21:48:38,266 INFO:   Leaving out SEQ value Fold_1
2022-12-05 21:48:38,279 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 21:48:38,279 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:48:38,933 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:48:38,933 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:48:39,001 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:48:39,002 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:48:39,002 INFO:     No hyperparam tuning for this model
2022-12-05 21:48:39,002 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:48:39,002 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:48:39,002 INFO:     None feature selector for col prot
2022-12-05 21:48:39,003 INFO:     None feature selector for col prot
2022-12-05 21:48:39,003 INFO:     None feature selector for col prot
2022-12-05 21:48:39,003 INFO:     None feature selector for col chem
2022-12-05 21:48:39,003 INFO:     None feature selector for col chem
2022-12-05 21:48:39,003 INFO:     None feature selector for col chem
2022-12-05 21:48:39,003 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:48:39,003 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:48:39,005 INFO:     Number of params in model 215821
2022-12-05 21:48:39,008 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:48:39,008 INFO:   Starting stage: TRAINING
2022-12-05 21:48:39,069 INFO:     Val loss before train {'Reaction outcome loss': 1.0239785408431834, 'Total loss': 1.0239785408431834}
2022-12-05 21:48:39,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:39,069 INFO:     Epoch: 0
2022-12-05 21:48:39,858 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6245904659683054, 'Total loss': 0.6245904659683054} | train loss {'Reaction outcome loss': 0.7823877096176147, 'Total loss': 0.7823877096176147}
2022-12-05 21:48:39,858 INFO:     Found new best model at epoch 0
2022-12-05 21:48:39,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:39,859 INFO:     Epoch: 1
2022-12-05 21:48:40,649 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5398993614045057, 'Total loss': 0.5398993614045057} | train loss {'Reaction outcome loss': 0.5348789790455176, 'Total loss': 0.5348789790455176}
2022-12-05 21:48:40,649 INFO:     Found new best model at epoch 1
2022-12-05 21:48:40,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:40,650 INFO:     Epoch: 2
2022-12-05 21:48:41,440 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5164061584933237, 'Total loss': 0.5164061584933237} | train loss {'Reaction outcome loss': 0.4664046683481761, 'Total loss': 0.4664046683481761}
2022-12-05 21:48:41,440 INFO:     Found new best model at epoch 2
2022-12-05 21:48:41,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:41,441 INFO:     Epoch: 3
2022-12-05 21:48:42,234 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.484382877972993, 'Total loss': 0.484382877972993} | train loss {'Reaction outcome loss': 0.4282219786425026, 'Total loss': 0.4282219786425026}
2022-12-05 21:48:42,234 INFO:     Found new best model at epoch 3
2022-12-05 21:48:42,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:42,235 INFO:     Epoch: 4
2022-12-05 21:48:43,027 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47311835329640994, 'Total loss': 0.47311835329640994} | train loss {'Reaction outcome loss': 0.39798363377245105, 'Total loss': 0.39798363377245105}
2022-12-05 21:48:43,027 INFO:     Found new best model at epoch 4
2022-12-05 21:48:43,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:43,028 INFO:     Epoch: 5
2022-12-05 21:48:43,819 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45059842040592973, 'Total loss': 0.45059842040592973} | train loss {'Reaction outcome loss': 0.37747817574715126, 'Total loss': 0.37747817574715126}
2022-12-05 21:48:43,819 INFO:     Found new best model at epoch 5
2022-12-05 21:48:43,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:43,820 INFO:     Epoch: 6
2022-12-05 21:48:44,610 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45924440161748364, 'Total loss': 0.45924440161748364} | train loss {'Reaction outcome loss': 0.35658015581418057, 'Total loss': 0.35658015581418057}
2022-12-05 21:48:44,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:44,610 INFO:     Epoch: 7
2022-12-05 21:48:45,407 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4535702192647891, 'Total loss': 0.4535702192647891} | train loss {'Reaction outcome loss': 0.34090972865114405, 'Total loss': 0.34090972865114405}
2022-12-05 21:48:45,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:45,407 INFO:     Epoch: 8
2022-12-05 21:48:46,199 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44340040839531203, 'Total loss': 0.44340040839531203} | train loss {'Reaction outcome loss': 0.3267916078014033, 'Total loss': 0.3267916078014033}
2022-12-05 21:48:46,199 INFO:     Found new best model at epoch 8
2022-12-05 21:48:46,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:46,200 INFO:     Epoch: 9
2022-12-05 21:48:46,989 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43249928019940853, 'Total loss': 0.43249928019940853} | train loss {'Reaction outcome loss': 0.31519553120038946, 'Total loss': 0.31519553120038946}
2022-12-05 21:48:46,990 INFO:     Found new best model at epoch 9
2022-12-05 21:48:46,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:46,990 INFO:     Epoch: 10
2022-12-05 21:48:47,783 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44665941325100983, 'Total loss': 0.44665941325100983} | train loss {'Reaction outcome loss': 0.30109453788217233, 'Total loss': 0.30109453788217233}
2022-12-05 21:48:47,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:47,783 INFO:     Epoch: 11
2022-12-05 21:48:48,579 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.436880596998063, 'Total loss': 0.436880596998063} | train loss {'Reaction outcome loss': 0.2894420640048932, 'Total loss': 0.2894420640048932}
2022-12-05 21:48:48,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:48,579 INFO:     Epoch: 12
2022-12-05 21:48:49,375 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4445638158781962, 'Total loss': 0.4445638158781962} | train loss {'Reaction outcome loss': 0.2796882558842095, 'Total loss': 0.2796882558842095}
2022-12-05 21:48:49,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:49,376 INFO:     Epoch: 13
2022-12-05 21:48:50,171 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42740306359800423, 'Total loss': 0.42740306359800423} | train loss {'Reaction outcome loss': 0.2706515899726323, 'Total loss': 0.2706515899726323}
2022-12-05 21:48:50,171 INFO:     Found new best model at epoch 13
2022-12-05 21:48:50,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:50,172 INFO:     Epoch: 14
2022-12-05 21:48:50,966 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45270466787571256, 'Total loss': 0.45270466787571256} | train loss {'Reaction outcome loss': 0.26460162595826753, 'Total loss': 0.26460162595826753}
2022-12-05 21:48:50,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:50,966 INFO:     Epoch: 15
2022-12-05 21:48:51,761 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44057501209053124, 'Total loss': 0.44057501209053124} | train loss {'Reaction outcome loss': 0.25754259748726477, 'Total loss': 0.25754259748726477}
2022-12-05 21:48:51,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:51,761 INFO:     Epoch: 16
2022-12-05 21:48:52,558 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4374645206738602, 'Total loss': 0.4374645206738602} | train loss {'Reaction outcome loss': 0.24606117587916704, 'Total loss': 0.24606117587916704}
2022-12-05 21:48:52,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:52,558 INFO:     Epoch: 17
2022-12-05 21:48:53,354 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4465259364382787, 'Total loss': 0.4465259364382787} | train loss {'Reaction outcome loss': 0.2386424385011196, 'Total loss': 0.2386424385011196}
2022-12-05 21:48:53,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:53,355 INFO:     Epoch: 18
2022-12-05 21:48:54,154 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4316948557441885, 'Total loss': 0.4316948557441885} | train loss {'Reaction outcome loss': 0.2333587982672818, 'Total loss': 0.2333587982672818}
2022-12-05 21:48:54,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:54,154 INFO:     Epoch: 19
2022-12-05 21:48:54,955 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4399651385505091, 'Total loss': 0.4399651385505091} | train loss {'Reaction outcome loss': 0.22871977352366155, 'Total loss': 0.22871977352366155}
2022-12-05 21:48:54,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:54,955 INFO:     Epoch: 20
2022-12-05 21:48:55,750 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4338729406960986, 'Total loss': 0.4338729406960986} | train loss {'Reaction outcome loss': 0.2229777738756063, 'Total loss': 0.2229777738756063}
2022-12-05 21:48:55,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:55,751 INFO:     Epoch: 21
2022-12-05 21:48:56,547 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42308418825268745, 'Total loss': 0.42308418825268745} | train loss {'Reaction outcome loss': 0.2199576755871578, 'Total loss': 0.2199576755871578}
2022-12-05 21:48:56,547 INFO:     Found new best model at epoch 21
2022-12-05 21:48:56,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:56,548 INFO:     Epoch: 22
2022-12-05 21:48:57,346 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44581579146060074, 'Total loss': 0.44581579146060074} | train loss {'Reaction outcome loss': 0.21111224678402044, 'Total loss': 0.21111224678402044}
2022-12-05 21:48:57,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:57,346 INFO:     Epoch: 23
2022-12-05 21:48:58,144 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4267319794744253, 'Total loss': 0.4267319794744253} | train loss {'Reaction outcome loss': 0.2058206987700292, 'Total loss': 0.2058206987700292}
2022-12-05 21:48:58,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:58,144 INFO:     Epoch: 24
2022-12-05 21:48:58,942 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42362753267992626, 'Total loss': 0.42362753267992626} | train loss {'Reaction outcome loss': 0.20286928223712103, 'Total loss': 0.20286928223712103}
2022-12-05 21:48:58,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:58,942 INFO:     Epoch: 25
2022-12-05 21:48:59,747 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42833904786543414, 'Total loss': 0.42833904786543414} | train loss {'Reaction outcome loss': 0.19841626050825023, 'Total loss': 0.19841626050825023}
2022-12-05 21:48:59,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:48:59,747 INFO:     Epoch: 26
2022-12-05 21:49:00,549 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4248343243856322, 'Total loss': 0.4248343243856322} | train loss {'Reaction outcome loss': 0.19284924889097407, 'Total loss': 0.19284924889097407}
2022-12-05 21:49:00,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:00,551 INFO:     Epoch: 27
2022-12-05 21:49:01,349 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44487356483428314, 'Total loss': 0.44487356483428314} | train loss {'Reaction outcome loss': 0.18583991377025236, 'Total loss': 0.18583991377025236}
2022-12-05 21:49:01,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:01,350 INFO:     Epoch: 28
2022-12-05 21:49:02,147 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4306230677969076, 'Total loss': 0.4306230677969076} | train loss {'Reaction outcome loss': 0.18719011707877625, 'Total loss': 0.18719011707877625}
2022-12-05 21:49:02,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:02,147 INFO:     Epoch: 29
2022-12-05 21:49:02,941 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4377592351626266, 'Total loss': 0.4377592351626266} | train loss {'Reaction outcome loss': 0.18561037527207208, 'Total loss': 0.18561037527207208}
2022-12-05 21:49:02,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:02,941 INFO:     Epoch: 30
2022-12-05 21:49:03,736 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44045123186978424, 'Total loss': 0.44045123186978424} | train loss {'Reaction outcome loss': 0.18306962932859147, 'Total loss': 0.18306962932859147}
2022-12-05 21:49:03,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:03,737 INFO:     Epoch: 31
2022-12-05 21:49:04,536 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4550591708922928, 'Total loss': 0.4550591708922928} | train loss {'Reaction outcome loss': 0.17769226929058834, 'Total loss': 0.17769226929058834}
2022-12-05 21:49:04,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:04,536 INFO:     Epoch: 32
2022-12-05 21:49:05,331 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46424039656465704, 'Total loss': 0.46424039656465704} | train loss {'Reaction outcome loss': 0.17582522568349934, 'Total loss': 0.17582522568349934}
2022-12-05 21:49:05,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:05,331 INFO:     Epoch: 33
2022-12-05 21:49:06,126 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4303680363703858, 'Total loss': 0.4303680363703858} | train loss {'Reaction outcome loss': 0.17227470791157412, 'Total loss': 0.17227470791157412}
2022-12-05 21:49:06,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:06,126 INFO:     Epoch: 34
2022-12-05 21:49:06,923 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44150375490161503, 'Total loss': 0.44150375490161503} | train loss {'Reaction outcome loss': 0.1716449807188949, 'Total loss': 0.1716449807188949}
2022-12-05 21:49:06,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:06,924 INFO:     Epoch: 35
2022-12-05 21:49:07,719 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4469711492684754, 'Total loss': 0.4469711492684754} | train loss {'Reaction outcome loss': 0.16698610995497024, 'Total loss': 0.16698610995497024}
2022-12-05 21:49:07,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:07,719 INFO:     Epoch: 36
2022-12-05 21:49:08,514 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4380680823867971, 'Total loss': 0.4380680823867971} | train loss {'Reaction outcome loss': 0.16703450223621058, 'Total loss': 0.16703450223621058}
2022-12-05 21:49:08,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:08,514 INFO:     Epoch: 37
2022-12-05 21:49:09,308 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43655841306529264, 'Total loss': 0.43655841306529264} | train loss {'Reaction outcome loss': 0.1642891705644374, 'Total loss': 0.1642891705644374}
2022-12-05 21:49:09,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:09,308 INFO:     Epoch: 38
2022-12-05 21:49:10,100 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46922360292889853, 'Total loss': 0.46922360292889853} | train loss {'Reaction outcome loss': 0.16089971963392227, 'Total loss': 0.16089971963392227}
2022-12-05 21:49:10,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:10,100 INFO:     Epoch: 39
2022-12-05 21:49:10,893 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4693150730295615, 'Total loss': 0.4693150730295615} | train loss {'Reaction outcome loss': 0.161838174694959, 'Total loss': 0.161838174694959}
2022-12-05 21:49:10,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:10,893 INFO:     Epoch: 40
2022-12-05 21:49:11,686 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45853870463642205, 'Total loss': 0.45853870463642205} | train loss {'Reaction outcome loss': 0.15784272096138827, 'Total loss': 0.15784272096138827}
2022-12-05 21:49:11,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:11,686 INFO:     Epoch: 41
2022-12-05 21:49:12,478 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46317591789093887, 'Total loss': 0.46317591789093887} | train loss {'Reaction outcome loss': 0.15981140026480567, 'Total loss': 0.15981140026480567}
2022-12-05 21:49:12,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:12,478 INFO:     Epoch: 42
2022-12-05 21:49:13,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4537905691699548, 'Total loss': 0.4537905691699548} | train loss {'Reaction outcome loss': 0.15532633126998435, 'Total loss': 0.15532633126998435}
2022-12-05 21:49:13,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:13,269 INFO:     Epoch: 43
2022-12-05 21:49:14,061 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4299484884197062, 'Total loss': 0.4299484884197062} | train loss {'Reaction outcome loss': 0.1494721850950499, 'Total loss': 0.1494721850950499}
2022-12-05 21:49:14,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:14,061 INFO:     Epoch: 44
2022-12-05 21:49:14,852 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44173817573623225, 'Total loss': 0.44173817573623225} | train loss {'Reaction outcome loss': 0.15067780669398453, 'Total loss': 0.15067780669398453}
2022-12-05 21:49:14,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:14,852 INFO:     Epoch: 45
2022-12-05 21:49:15,645 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45354544162083504, 'Total loss': 0.45354544162083504} | train loss {'Reaction outcome loss': 0.15230169772949753, 'Total loss': 0.15230169772949753}
2022-12-05 21:49:15,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:15,645 INFO:     Epoch: 46
2022-12-05 21:49:16,440 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4572310657663779, 'Total loss': 0.4572310657663779} | train loss {'Reaction outcome loss': 0.14852714378918921, 'Total loss': 0.14852714378918921}
2022-12-05 21:49:16,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:16,440 INFO:     Epoch: 47
2022-12-05 21:49:17,238 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44609361853111873, 'Total loss': 0.44609361853111873} | train loss {'Reaction outcome loss': 0.1474850882528996, 'Total loss': 0.1474850882528996}
2022-12-05 21:49:17,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:17,238 INFO:     Epoch: 48
2022-12-05 21:49:18,033 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43890517712994054, 'Total loss': 0.43890517712994054} | train loss {'Reaction outcome loss': 0.14971325848327607, 'Total loss': 0.14971325848327607}
2022-12-05 21:49:18,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:18,034 INFO:     Epoch: 49
2022-12-05 21:49:18,828 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45117864419113507, 'Total loss': 0.45117864419113507} | train loss {'Reaction outcome loss': 0.1446766853636625, 'Total loss': 0.1446766853636625}
2022-12-05 21:49:18,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:18,828 INFO:     Epoch: 50
2022-12-05 21:49:19,626 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.440709524364634, 'Total loss': 0.440709524364634} | train loss {'Reaction outcome loss': 0.14300096743569082, 'Total loss': 0.14300096743569082}
2022-12-05 21:49:19,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:19,627 INFO:     Epoch: 51
2022-12-05 21:49:20,421 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4487707508643242, 'Total loss': 0.4487707508643242} | train loss {'Reaction outcome loss': 0.14282384676364612, 'Total loss': 0.14282384676364612}
2022-12-05 21:49:20,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:20,421 INFO:     Epoch: 52
2022-12-05 21:49:21,212 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47217399830167944, 'Total loss': 0.47217399830167944} | train loss {'Reaction outcome loss': 0.1404532588106029, 'Total loss': 0.1404532588106029}
2022-12-05 21:49:21,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:21,212 INFO:     Epoch: 53
2022-12-05 21:49:22,007 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4580412564629858, 'Total loss': 0.4580412564629858} | train loss {'Reaction outcome loss': 0.14058141799985754, 'Total loss': 0.14058141799985754}
2022-12-05 21:49:22,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:22,008 INFO:     Epoch: 54
2022-12-05 21:49:22,801 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4472102236680009, 'Total loss': 0.4472102236680009} | train loss {'Reaction outcome loss': 0.13928548275512093, 'Total loss': 0.13928548275512093}
2022-12-05 21:49:22,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:22,802 INFO:     Epoch: 55
2022-12-05 21:49:23,593 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.460810185494748, 'Total loss': 0.460810185494748} | train loss {'Reaction outcome loss': 0.13784532854143455, 'Total loss': 0.13784532854143455}
2022-12-05 21:49:23,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:23,593 INFO:     Epoch: 56
2022-12-05 21:49:24,390 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4577938270839778, 'Total loss': 0.4577938270839778} | train loss {'Reaction outcome loss': 0.13763400044444266, 'Total loss': 0.13763400044444266}
2022-12-05 21:49:24,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:24,391 INFO:     Epoch: 57
2022-12-05 21:49:25,180 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45841837183318357, 'Total loss': 0.45841837183318357} | train loss {'Reaction outcome loss': 0.13611032446960405, 'Total loss': 0.13611032446960405}
2022-12-05 21:49:25,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:25,180 INFO:     Epoch: 58
2022-12-05 21:49:25,969 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46295121108943765, 'Total loss': 0.46295121108943765} | train loss {'Reaction outcome loss': 0.1355540403678101, 'Total loss': 0.1355540403678101}
2022-12-05 21:49:25,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:25,969 INFO:     Epoch: 59
2022-12-05 21:49:26,762 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4449096674268896, 'Total loss': 0.4449096674268896} | train loss {'Reaction outcome loss': 0.13486364204056409, 'Total loss': 0.13486364204056409}
2022-12-05 21:49:26,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:26,762 INFO:     Epoch: 60
2022-12-05 21:49:27,552 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4556147722019391, 'Total loss': 0.4556147722019391} | train loss {'Reaction outcome loss': 0.1317049084117218, 'Total loss': 0.1317049084117218}
2022-12-05 21:49:27,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:27,552 INFO:     Epoch: 61
2022-12-05 21:49:28,343 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4575618894940073, 'Total loss': 0.4575618894940073} | train loss {'Reaction outcome loss': 0.1326037244909272, 'Total loss': 0.1326037244909272}
2022-12-05 21:49:28,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:28,344 INFO:     Epoch: 62
2022-12-05 21:49:29,138 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45244360105557874, 'Total loss': 0.45244360105557874} | train loss {'Reaction outcome loss': 0.13071481967154813, 'Total loss': 0.13071481967154813}
2022-12-05 21:49:29,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:29,138 INFO:     Epoch: 63
2022-12-05 21:49:29,928 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45779105970128015, 'Total loss': 0.45779105970128015} | train loss {'Reaction outcome loss': 0.13209678359633806, 'Total loss': 0.13209678359633806}
2022-12-05 21:49:29,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:29,928 INFO:     Epoch: 64
2022-12-05 21:49:30,719 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45133366232568567, 'Total loss': 0.45133366232568567} | train loss {'Reaction outcome loss': 0.1282296238201005, 'Total loss': 0.1282296238201005}
2022-12-05 21:49:30,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:30,719 INFO:     Epoch: 65
2022-12-05 21:49:31,511 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46985704214735463, 'Total loss': 0.46985704214735463} | train loss {'Reaction outcome loss': 0.12782518932101677, 'Total loss': 0.12782518932101677}
2022-12-05 21:49:31,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:31,513 INFO:     Epoch: 66
2022-12-05 21:49:32,306 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46016122807155957, 'Total loss': 0.46016122807155957} | train loss {'Reaction outcome loss': 0.1290011801091688, 'Total loss': 0.1290011801091688}
2022-12-05 21:49:32,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:32,306 INFO:     Epoch: 67
2022-12-05 21:49:33,095 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4544765783304518, 'Total loss': 0.4544765783304518} | train loss {'Reaction outcome loss': 0.1252334888340259, 'Total loss': 0.1252334888340259}
2022-12-05 21:49:33,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:33,095 INFO:     Epoch: 68
2022-12-05 21:49:33,884 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4805391065099023, 'Total loss': 0.4805391065099023} | train loss {'Reaction outcome loss': 0.12995758214395264, 'Total loss': 0.12995758214395264}
2022-12-05 21:49:33,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:33,884 INFO:     Epoch: 69
2022-12-05 21:49:34,675 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4480068710717288, 'Total loss': 0.4480068710717288} | train loss {'Reaction outcome loss': 0.12817425660941065, 'Total loss': 0.12817425660941065}
2022-12-05 21:49:34,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:34,676 INFO:     Epoch: 70
2022-12-05 21:49:35,472 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46573850072242995, 'Total loss': 0.46573850072242995} | train loss {'Reaction outcome loss': 0.12733145446649619, 'Total loss': 0.12733145446649619}
2022-12-05 21:49:35,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:35,472 INFO:     Epoch: 71
2022-12-05 21:49:36,266 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44876567799259315, 'Total loss': 0.44876567799259315} | train loss {'Reaction outcome loss': 0.1264059230029507, 'Total loss': 0.1264059230029507}
2022-12-05 21:49:36,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:36,266 INFO:     Epoch: 72
2022-12-05 21:49:37,059 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45773186737840826, 'Total loss': 0.45773186737840826} | train loss {'Reaction outcome loss': 0.12477471005475643, 'Total loss': 0.12477471005475643}
2022-12-05 21:49:37,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:37,059 INFO:     Epoch: 73
2022-12-05 21:49:37,851 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4788602621040561, 'Total loss': 0.4788602621040561} | train loss {'Reaction outcome loss': 0.12655300336832903, 'Total loss': 0.12655300336832903}
2022-12-05 21:49:37,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:37,852 INFO:     Epoch: 74
2022-12-05 21:49:38,643 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4606447040357373, 'Total loss': 0.4606447040357373} | train loss {'Reaction outcome loss': 0.12271223978652637, 'Total loss': 0.12271223978652637}
2022-12-05 21:49:38,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:38,643 INFO:     Epoch: 75
2022-12-05 21:49:39,434 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4560146138749339, 'Total loss': 0.4560146138749339} | train loss {'Reaction outcome loss': 0.12252285996718067, 'Total loss': 0.12252285996718067}
2022-12-05 21:49:39,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:39,435 INFO:     Epoch: 76
2022-12-05 21:49:40,226 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47453562779860065, 'Total loss': 0.47453562779860065} | train loss {'Reaction outcome loss': 0.12476115252594558, 'Total loss': 0.12476115252594558}
2022-12-05 21:49:40,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:40,226 INFO:     Epoch: 77
2022-12-05 21:49:41,017 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45479690279303625, 'Total loss': 0.45479690279303625} | train loss {'Reaction outcome loss': 0.12300473317427903, 'Total loss': 0.12300473317427903}
2022-12-05 21:49:41,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:41,017 INFO:     Epoch: 78
2022-12-05 21:49:41,809 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45212619710417296, 'Total loss': 0.45212619710417296} | train loss {'Reaction outcome loss': 0.12307546995200065, 'Total loss': 0.12307546995200065}
2022-12-05 21:49:41,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:41,809 INFO:     Epoch: 79
2022-12-05 21:49:42,602 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.441234886307608, 'Total loss': 0.441234886307608} | train loss {'Reaction outcome loss': 0.12175191381604088, 'Total loss': 0.12175191381604088}
2022-12-05 21:49:42,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:42,602 INFO:     Epoch: 80
2022-12-05 21:49:43,396 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4483996551822532, 'Total loss': 0.4483996551822532} | train loss {'Reaction outcome loss': 0.12169579430198182, 'Total loss': 0.12169579430198182}
2022-12-05 21:49:43,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:43,396 INFO:     Epoch: 81
2022-12-05 21:49:44,184 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4516487433151765, 'Total loss': 0.4516487433151765} | train loss {'Reaction outcome loss': 0.12304779142141342, 'Total loss': 0.12304779142141342}
2022-12-05 21:49:44,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:44,185 INFO:     Epoch: 82
2022-12-05 21:49:44,974 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4609560990198092, 'Total loss': 0.4609560990198092} | train loss {'Reaction outcome loss': 0.12019538039303555, 'Total loss': 0.12019538039303555}
2022-12-05 21:49:44,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:44,975 INFO:     Epoch: 83
2022-12-05 21:49:45,765 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44470050135119393, 'Total loss': 0.44470050135119393} | train loss {'Reaction outcome loss': 0.11970609324242995, 'Total loss': 0.11970609324242995}
2022-12-05 21:49:45,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:45,766 INFO:     Epoch: 84
2022-12-05 21:49:46,558 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4762623445554213, 'Total loss': 0.4762623445554213} | train loss {'Reaction outcome loss': 0.11888936544027255, 'Total loss': 0.11888936544027255}
2022-12-05 21:49:46,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:46,559 INFO:     Epoch: 85
2022-12-05 21:49:47,347 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4511692233552987, 'Total loss': 0.4511692233552987} | train loss {'Reaction outcome loss': 0.11847377891215134, 'Total loss': 0.11847377891215134}
2022-12-05 21:49:47,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:47,347 INFO:     Epoch: 86
2022-12-05 21:49:48,140 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44440961188890715, 'Total loss': 0.44440961188890715} | train loss {'Reaction outcome loss': 0.12118273646741802, 'Total loss': 0.12118273646741802}
2022-12-05 21:49:48,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:48,141 INFO:     Epoch: 87
2022-12-05 21:49:48,932 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46187971566211095, 'Total loss': 0.46187971566211095} | train loss {'Reaction outcome loss': 0.12028690759016543, 'Total loss': 0.12028690759016543}
2022-12-05 21:49:48,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:48,933 INFO:     Epoch: 88
2022-12-05 21:49:49,723 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4644973816519434, 'Total loss': 0.4644973816519434} | train loss {'Reaction outcome loss': 0.11653838650304443, 'Total loss': 0.11653838650304443}
2022-12-05 21:49:49,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:49,723 INFO:     Epoch: 89
2022-12-05 21:49:50,514 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4569635868749835, 'Total loss': 0.4569635868749835} | train loss {'Reaction outcome loss': 0.11759347689090943, 'Total loss': 0.11759347689090943}
2022-12-05 21:49:50,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:50,515 INFO:     Epoch: 90
2022-12-05 21:49:51,308 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45208353583108296, 'Total loss': 0.45208353583108296} | train loss {'Reaction outcome loss': 0.11631857013063772, 'Total loss': 0.11631857013063772}
2022-12-05 21:49:51,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:51,308 INFO:     Epoch: 91
2022-12-05 21:49:52,098 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4454628259620883, 'Total loss': 0.4454628259620883} | train loss {'Reaction outcome loss': 0.11674169158677057, 'Total loss': 0.11674169158677057}
2022-12-05 21:49:52,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:52,098 INFO:     Epoch: 92
2022-12-05 21:49:52,889 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45112659748304973, 'Total loss': 0.45112659748304973} | train loss {'Reaction outcome loss': 0.11750184153111613, 'Total loss': 0.11750184153111613}
2022-12-05 21:49:52,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:52,889 INFO:     Epoch: 93
2022-12-05 21:49:53,677 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46685216372663324, 'Total loss': 0.46685216372663324} | train loss {'Reaction outcome loss': 0.11764921154256681, 'Total loss': 0.11764921154256681}
2022-12-05 21:49:53,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:53,677 INFO:     Epoch: 94
2022-12-05 21:49:54,467 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4532416293566877, 'Total loss': 0.4532416293566877} | train loss {'Reaction outcome loss': 0.11547689374194157, 'Total loss': 0.11547689374194157}
2022-12-05 21:49:54,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:54,468 INFO:     Epoch: 95
2022-12-05 21:49:55,258 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44730538553134963, 'Total loss': 0.44730538553134963} | train loss {'Reaction outcome loss': 0.11578575677561517, 'Total loss': 0.11578575677561517}
2022-12-05 21:49:55,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:55,258 INFO:     Epoch: 96
2022-12-05 21:49:56,049 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45959063043648546, 'Total loss': 0.45959063043648546} | train loss {'Reaction outcome loss': 0.11425650094122607, 'Total loss': 0.11425650094122607}
2022-12-05 21:49:56,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:56,049 INFO:     Epoch: 97
2022-12-05 21:49:56,843 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4526043317534707, 'Total loss': 0.4526043317534707} | train loss {'Reaction outcome loss': 0.11303029773490769, 'Total loss': 0.11303029773490769}
2022-12-05 21:49:56,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:56,843 INFO:     Epoch: 98
2022-12-05 21:49:57,633 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4764259565960277, 'Total loss': 0.4764259565960277} | train loss {'Reaction outcome loss': 0.11530702632604813, 'Total loss': 0.11530702632604813}
2022-12-05 21:49:57,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:57,634 INFO:     Epoch: 99
2022-12-05 21:49:58,421 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45661687038161536, 'Total loss': 0.45661687038161536} | train loss {'Reaction outcome loss': 0.11573663384140451, 'Total loss': 0.11573663384140451}
2022-12-05 21:49:58,421 INFO:     Best model found after epoch 22 of 100.
2022-12-05 21:49:58,422 INFO:   Done with stage: TRAINING
2022-12-05 21:49:58,422 INFO:   Starting stage: EVALUATION
2022-12-05 21:49:58,553 INFO:   Done with stage: EVALUATION
2022-12-05 21:49:58,554 INFO:   Leaving out SEQ value Fold_2
2022-12-05 21:49:58,567 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 21:49:58,567 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:49:59,211 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:49:59,212 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:49:59,280 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:49:59,280 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:49:59,280 INFO:     No hyperparam tuning for this model
2022-12-05 21:49:59,280 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:49:59,280 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:49:59,281 INFO:     None feature selector for col prot
2022-12-05 21:49:59,281 INFO:     None feature selector for col prot
2022-12-05 21:49:59,281 INFO:     None feature selector for col prot
2022-12-05 21:49:59,282 INFO:     None feature selector for col chem
2022-12-05 21:49:59,282 INFO:     None feature selector for col chem
2022-12-05 21:49:59,282 INFO:     None feature selector for col chem
2022-12-05 21:49:59,282 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:49:59,282 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:49:59,284 INFO:     Number of params in model 215821
2022-12-05 21:49:59,287 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:49:59,287 INFO:   Starting stage: TRAINING
2022-12-05 21:49:59,347 INFO:     Val loss before train {'Reaction outcome loss': 0.9768277351246324, 'Total loss': 0.9768277351246324}
2022-12-05 21:49:59,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:49:59,347 INFO:     Epoch: 0
2022-12-05 21:50:00,136 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5783733046332071, 'Total loss': 0.5783733046332071} | train loss {'Reaction outcome loss': 0.7979568432344765, 'Total loss': 0.7979568432344765}
2022-12-05 21:50:00,136 INFO:     Found new best model at epoch 0
2022-12-05 21:50:00,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:00,137 INFO:     Epoch: 1
2022-12-05 21:50:00,920 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5143398025701212, 'Total loss': 0.5143398025701212} | train loss {'Reaction outcome loss': 0.537635656165295, 'Total loss': 0.537635656165295}
2022-12-05 21:50:00,920 INFO:     Found new best model at epoch 1
2022-12-05 21:50:00,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:00,921 INFO:     Epoch: 2
2022-12-05 21:50:01,708 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49544898299283757, 'Total loss': 0.49544898299283757} | train loss {'Reaction outcome loss': 0.46356207785792036, 'Total loss': 0.46356207785792036}
2022-12-05 21:50:01,708 INFO:     Found new best model at epoch 2
2022-12-05 21:50:01,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:01,709 INFO:     Epoch: 3
2022-12-05 21:50:02,492 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4796187201904696, 'Total loss': 0.4796187201904696} | train loss {'Reaction outcome loss': 0.425640199272359, 'Total loss': 0.425640199272359}
2022-12-05 21:50:02,494 INFO:     Found new best model at epoch 3
2022-12-05 21:50:02,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:02,495 INFO:     Epoch: 4
2022-12-05 21:50:03,283 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45778192233207615, 'Total loss': 0.45778192233207615} | train loss {'Reaction outcome loss': 0.394929989775429, 'Total loss': 0.394929989775429}
2022-12-05 21:50:03,283 INFO:     Found new best model at epoch 4
2022-12-05 21:50:03,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:03,284 INFO:     Epoch: 5
2022-12-05 21:50:04,076 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4460732198731844, 'Total loss': 0.4460732198731844} | train loss {'Reaction outcome loss': 0.37389591226323704, 'Total loss': 0.37389591226323704}
2022-12-05 21:50:04,076 INFO:     Found new best model at epoch 5
2022-12-05 21:50:04,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:04,077 INFO:     Epoch: 6
2022-12-05 21:50:04,865 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44327620642129767, 'Total loss': 0.44327620642129767} | train loss {'Reaction outcome loss': 0.35382472934415105, 'Total loss': 0.35382472934415105}
2022-12-05 21:50:04,865 INFO:     Found new best model at epoch 6
2022-12-05 21:50:04,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:04,866 INFO:     Epoch: 7
2022-12-05 21:50:05,657 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4354650475258051, 'Total loss': 0.4354650475258051} | train loss {'Reaction outcome loss': 0.33457175837677033, 'Total loss': 0.33457175837677033}
2022-12-05 21:50:05,657 INFO:     Found new best model at epoch 7
2022-12-05 21:50:05,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:05,658 INFO:     Epoch: 8
2022-12-05 21:50:06,447 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4277755576510762, 'Total loss': 0.4277755576510762} | train loss {'Reaction outcome loss': 0.32005092678744285, 'Total loss': 0.32005092678744285}
2022-12-05 21:50:06,447 INFO:     Found new best model at epoch 8
2022-12-05 21:50:06,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:06,448 INFO:     Epoch: 9
2022-12-05 21:50:07,233 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4463607405507287, 'Total loss': 0.4463607405507287} | train loss {'Reaction outcome loss': 0.3038662379821304, 'Total loss': 0.3038662379821304}
2022-12-05 21:50:07,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:07,234 INFO:     Epoch: 10
2022-12-05 21:50:08,021 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4347704278175221, 'Total loss': 0.4347704278175221} | train loss {'Reaction outcome loss': 0.2895787043771783, 'Total loss': 0.2895787043771783}
2022-12-05 21:50:08,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:08,021 INFO:     Epoch: 11
2022-12-05 21:50:08,811 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4328995471776918, 'Total loss': 0.4328995471776918} | train loss {'Reaction outcome loss': 0.28064673717637534, 'Total loss': 0.28064673717637534}
2022-12-05 21:50:08,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:08,812 INFO:     Epoch: 12
2022-12-05 21:50:09,602 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4286718351203342, 'Total loss': 0.4286718351203342} | train loss {'Reaction outcome loss': 0.2709054304744865, 'Total loss': 0.2709054304744865}
2022-12-05 21:50:09,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:09,603 INFO:     Epoch: 13
2022-12-05 21:50:10,392 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42153763147287593, 'Total loss': 0.42153763147287593} | train loss {'Reaction outcome loss': 0.26092636902801325, 'Total loss': 0.26092636902801325}
2022-12-05 21:50:10,392 INFO:     Found new best model at epoch 13
2022-12-05 21:50:10,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:10,393 INFO:     Epoch: 14
2022-12-05 21:50:11,181 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4295284547084986, 'Total loss': 0.4295284547084986} | train loss {'Reaction outcome loss': 0.25084955626946004, 'Total loss': 0.25084955626946004}
2022-12-05 21:50:11,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:11,181 INFO:     Epoch: 15
2022-12-05 21:50:11,968 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4214832824329997, 'Total loss': 0.4214832824329997} | train loss {'Reaction outcome loss': 0.24288636201717814, 'Total loss': 0.24288636201717814}
2022-12-05 21:50:11,969 INFO:     Found new best model at epoch 15
2022-12-05 21:50:11,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:11,969 INFO:     Epoch: 16
2022-12-05 21:50:12,759 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4184745737286501, 'Total loss': 0.4184745737286501} | train loss {'Reaction outcome loss': 0.23596433507370168, 'Total loss': 0.23596433507370168}
2022-12-05 21:50:12,759 INFO:     Found new best model at epoch 16
2022-12-05 21:50:12,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:12,760 INFO:     Epoch: 17
2022-12-05 21:50:13,553 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4241345309933951, 'Total loss': 0.4241345309933951} | train loss {'Reaction outcome loss': 0.2281257404533566, 'Total loss': 0.2281257404533566}
2022-12-05 21:50:13,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:13,553 INFO:     Epoch: 18
2022-12-05 21:50:14,344 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42853717090085497, 'Total loss': 0.42853717090085497} | train loss {'Reaction outcome loss': 0.2245564559230306, 'Total loss': 0.2245564559230306}
2022-12-05 21:50:14,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:14,344 INFO:     Epoch: 19
2022-12-05 21:50:15,140 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4346321024173914, 'Total loss': 0.4346321024173914} | train loss {'Reaction outcome loss': 0.21815573033250746, 'Total loss': 0.21815573033250746}
2022-12-05 21:50:15,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:15,140 INFO:     Epoch: 20
2022-12-05 21:50:15,935 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42224540855995446, 'Total loss': 0.42224540855995446} | train loss {'Reaction outcome loss': 0.21316533278460142, 'Total loss': 0.21316533278460142}
2022-12-05 21:50:15,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:15,935 INFO:     Epoch: 21
2022-12-05 21:50:16,720 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4351131181384242, 'Total loss': 0.4351131181384242} | train loss {'Reaction outcome loss': 0.2085734995112556, 'Total loss': 0.2085734995112556}
2022-12-05 21:50:16,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:16,720 INFO:     Epoch: 22
2022-12-05 21:50:17,508 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4371508533178374, 'Total loss': 0.4371508533178374} | train loss {'Reaction outcome loss': 0.20438991543516272, 'Total loss': 0.20438991543516272}
2022-12-05 21:50:17,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:17,508 INFO:     Epoch: 23
2022-12-05 21:50:18,292 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43921158064243404, 'Total loss': 0.43921158064243404} | train loss {'Reaction outcome loss': 0.20081746631653094, 'Total loss': 0.20081746631653094}
2022-12-05 21:50:18,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:18,292 INFO:     Epoch: 24
2022-12-05 21:50:19,077 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42835255036520403, 'Total loss': 0.42835255036520403} | train loss {'Reaction outcome loss': 0.1965778540422926, 'Total loss': 0.1965778540422926}
2022-12-05 21:50:19,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:19,078 INFO:     Epoch: 25
2022-12-05 21:50:19,860 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4426541480907174, 'Total loss': 0.4426541480907174} | train loss {'Reaction outcome loss': 0.19135249964892864, 'Total loss': 0.19135249964892864}
2022-12-05 21:50:19,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:19,860 INFO:     Epoch: 26
2022-12-05 21:50:20,643 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45588052896566167, 'Total loss': 0.45588052896566167} | train loss {'Reaction outcome loss': 0.19086229230170368, 'Total loss': 0.19086229230170368}
2022-12-05 21:50:20,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:20,644 INFO:     Epoch: 27
2022-12-05 21:50:21,429 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45221326101657955, 'Total loss': 0.45221326101657955} | train loss {'Reaction outcome loss': 0.18748941035849637, 'Total loss': 0.18748941035849637}
2022-12-05 21:50:21,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:21,430 INFO:     Epoch: 28
2022-12-05 21:50:22,217 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4441006658382194, 'Total loss': 0.4441006658382194} | train loss {'Reaction outcome loss': 0.18446403671605666, 'Total loss': 0.18446403671605666}
2022-12-05 21:50:22,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:22,217 INFO:     Epoch: 29
2022-12-05 21:50:23,006 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4403292914462644, 'Total loss': 0.4403292914462644} | train loss {'Reaction outcome loss': 0.18012061287633707, 'Total loss': 0.18012061287633707}
2022-12-05 21:50:23,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:23,007 INFO:     Epoch: 30
2022-12-05 21:50:23,792 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4412075055893077, 'Total loss': 0.4412075055893077} | train loss {'Reaction outcome loss': 0.17915032790271473, 'Total loss': 0.17915032790271473}
2022-12-05 21:50:23,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:23,792 INFO:     Epoch: 31
2022-12-05 21:50:24,584 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4583488713170207, 'Total loss': 0.4583488713170207} | train loss {'Reaction outcome loss': 0.17954722531597878, 'Total loss': 0.17954722531597878}
2022-12-05 21:50:24,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:24,584 INFO:     Epoch: 32
2022-12-05 21:50:25,367 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45373185810654665, 'Total loss': 0.45373185810654665} | train loss {'Reaction outcome loss': 0.17725428638094273, 'Total loss': 0.17725428638094273}
2022-12-05 21:50:25,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:25,368 INFO:     Epoch: 33
2022-12-05 21:50:26,150 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45316729140143064, 'Total loss': 0.45316729140143064} | train loss {'Reaction outcome loss': 0.17178972263163964, 'Total loss': 0.17178972263163964}
2022-12-05 21:50:26,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:26,150 INFO:     Epoch: 34
2022-12-05 21:50:26,936 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47249034861492556, 'Total loss': 0.47249034861492556} | train loss {'Reaction outcome loss': 0.16984285137112268, 'Total loss': 0.16984285137112268}
2022-12-05 21:50:26,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:26,936 INFO:     Epoch: 35
2022-12-05 21:50:27,723 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4594083109567332, 'Total loss': 0.4594083109567332} | train loss {'Reaction outcome loss': 0.167219952260312, 'Total loss': 0.167219952260312}
2022-12-05 21:50:27,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:27,723 INFO:     Epoch: 36
2022-12-05 21:50:28,512 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4652734017649362, 'Total loss': 0.4652734017649362} | train loss {'Reaction outcome loss': 0.16504927236800554, 'Total loss': 0.16504927236800554}
2022-12-05 21:50:28,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:28,512 INFO:     Epoch: 37
2022-12-05 21:50:29,296 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4566438787205275, 'Total loss': 0.4566438787205275} | train loss {'Reaction outcome loss': 0.16397424967440424, 'Total loss': 0.16397424967440424}
2022-12-05 21:50:29,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:29,296 INFO:     Epoch: 38
2022-12-05 21:50:30,080 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45922434018101804, 'Total loss': 0.45922434018101804} | train loss {'Reaction outcome loss': 0.16454532299740393, 'Total loss': 0.16454532299740393}
2022-12-05 21:50:30,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:30,080 INFO:     Epoch: 39
2022-12-05 21:50:30,863 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46144180173097654, 'Total loss': 0.46144180173097654} | train loss {'Reaction outcome loss': 0.16308072227679316, 'Total loss': 0.16308072227679316}
2022-12-05 21:50:30,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:30,863 INFO:     Epoch: 40
2022-12-05 21:50:31,647 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4582307643668596, 'Total loss': 0.4582307643668596} | train loss {'Reaction outcome loss': 0.16076493606765252, 'Total loss': 0.16076493606765252}
2022-12-05 21:50:31,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:31,647 INFO:     Epoch: 41
2022-12-05 21:50:32,433 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45521479888364325, 'Total loss': 0.45521479888364325} | train loss {'Reaction outcome loss': 0.1560156186126539, 'Total loss': 0.1560156186126539}
2022-12-05 21:50:32,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:32,433 INFO:     Epoch: 42
2022-12-05 21:50:33,218 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4724004341419353, 'Total loss': 0.4724004341419353} | train loss {'Reaction outcome loss': 0.1548915532356525, 'Total loss': 0.1548915532356525}
2022-12-05 21:50:33,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:33,220 INFO:     Epoch: 43
2022-12-05 21:50:34,006 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.46021492779254913, 'Total loss': 0.46021492779254913} | train loss {'Reaction outcome loss': 0.1562395877067427, 'Total loss': 0.1562395877067427}
2022-12-05 21:50:34,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:34,006 INFO:     Epoch: 44
2022-12-05 21:50:34,795 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45393538059190264, 'Total loss': 0.45393538059190264} | train loss {'Reaction outcome loss': 0.15434508558484863, 'Total loss': 0.15434508558484863}
2022-12-05 21:50:34,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:34,795 INFO:     Epoch: 45
2022-12-05 21:50:35,582 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.449663772485977, 'Total loss': 0.449663772485977} | train loss {'Reaction outcome loss': 0.15323281543115613, 'Total loss': 0.15323281543115613}
2022-12-05 21:50:35,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:35,582 INFO:     Epoch: 46
2022-12-05 21:50:36,364 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4751128616721131, 'Total loss': 0.4751128616721131} | train loss {'Reaction outcome loss': 0.15374711629186497, 'Total loss': 0.15374711629186497}
2022-12-05 21:50:36,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:36,365 INFO:     Epoch: 47
2022-12-05 21:50:37,148 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4693798280732576, 'Total loss': 0.4693798280732576} | train loss {'Reaction outcome loss': 0.14975542608709608, 'Total loss': 0.14975542608709608}
2022-12-05 21:50:37,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:37,148 INFO:     Epoch: 48
2022-12-05 21:50:37,934 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4782597692899926, 'Total loss': 0.4782597692899926} | train loss {'Reaction outcome loss': 0.1516735976882523, 'Total loss': 0.1516735976882523}
2022-12-05 21:50:37,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:37,935 INFO:     Epoch: 49
2022-12-05 21:50:38,721 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46201479876803797, 'Total loss': 0.46201479876803797} | train loss {'Reaction outcome loss': 0.14846827923396572, 'Total loss': 0.14846827923396572}
2022-12-05 21:50:38,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:38,721 INFO:     Epoch: 50
2022-12-05 21:50:39,506 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46001412182353263, 'Total loss': 0.46001412182353263} | train loss {'Reaction outcome loss': 0.14820259223600513, 'Total loss': 0.14820259223600513}
2022-12-05 21:50:39,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:39,507 INFO:     Epoch: 51
2022-12-05 21:50:40,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4813300936028015, 'Total loss': 0.4813300936028015} | train loss {'Reaction outcome loss': 0.145549152084611, 'Total loss': 0.145549152084611}
2022-12-05 21:50:40,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:40,291 INFO:     Epoch: 52
2022-12-05 21:50:41,076 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47328062494133794, 'Total loss': 0.47328062494133794} | train loss {'Reaction outcome loss': 0.14839660179358524, 'Total loss': 0.14839660179358524}
2022-12-05 21:50:41,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:41,076 INFO:     Epoch: 53
2022-12-05 21:50:41,863 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4657903743344684, 'Total loss': 0.4657903743344684} | train loss {'Reaction outcome loss': 0.1470405740709212, 'Total loss': 0.1470405740709212}
2022-12-05 21:50:41,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:41,864 INFO:     Epoch: 54
2022-12-05 21:50:42,646 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4571703660280205, 'Total loss': 0.4571703660280205} | train loss {'Reaction outcome loss': 0.14194438708793433, 'Total loss': 0.14194438708793433}
2022-12-05 21:50:42,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:42,646 INFO:     Epoch: 55
2022-12-05 21:50:43,436 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4670681541049203, 'Total loss': 0.4670681541049203} | train loss {'Reaction outcome loss': 0.14100158601602325, 'Total loss': 0.14100158601602325}
2022-12-05 21:50:43,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:43,436 INFO:     Epoch: 56
2022-12-05 21:50:44,221 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4603674306079399, 'Total loss': 0.4603674306079399} | train loss {'Reaction outcome loss': 0.14227905587797038, 'Total loss': 0.14227905587797038}
2022-12-05 21:50:44,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:44,222 INFO:     Epoch: 57
2022-12-05 21:50:45,007 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45882458413063093, 'Total loss': 0.45882458413063093} | train loss {'Reaction outcome loss': 0.14269585883031127, 'Total loss': 0.14269585883031127}
2022-12-05 21:50:45,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:45,008 INFO:     Epoch: 58
2022-12-05 21:50:45,798 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46133692423964656, 'Total loss': 0.46133692423964656} | train loss {'Reaction outcome loss': 0.1419904020798133, 'Total loss': 0.1419904020798133}
2022-12-05 21:50:45,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:45,798 INFO:     Epoch: 59
2022-12-05 21:50:46,583 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45517446239327275, 'Total loss': 0.45517446239327275} | train loss {'Reaction outcome loss': 0.1422471099411, 'Total loss': 0.1422471099411}
2022-12-05 21:50:46,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:46,583 INFO:     Epoch: 60
2022-12-05 21:50:47,366 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46373489083245745, 'Total loss': 0.46373489083245745} | train loss {'Reaction outcome loss': 0.14169226921942146, 'Total loss': 0.14169226921942146}
2022-12-05 21:50:47,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:47,366 INFO:     Epoch: 61
2022-12-05 21:50:48,152 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45602762248626977, 'Total loss': 0.45602762248626977} | train loss {'Reaction outcome loss': 0.13603153604189636, 'Total loss': 0.13603153604189636}
2022-12-05 21:50:48,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:48,153 INFO:     Epoch: 62
2022-12-05 21:50:48,940 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4727114225889361, 'Total loss': 0.4727114225889361} | train loss {'Reaction outcome loss': 0.13675427433775098, 'Total loss': 0.13675427433775098}
2022-12-05 21:50:48,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:48,940 INFO:     Epoch: 63
2022-12-05 21:50:49,726 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4538539783206097, 'Total loss': 0.4538539783206097} | train loss {'Reaction outcome loss': 0.13602886382933158, 'Total loss': 0.13602886382933158}
2022-12-05 21:50:49,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:49,726 INFO:     Epoch: 64
2022-12-05 21:50:50,509 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46093738910763765, 'Total loss': 0.46093738910763765} | train loss {'Reaction outcome loss': 0.13628824633454567, 'Total loss': 0.13628824633454567}
2022-12-05 21:50:50,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:50,510 INFO:     Epoch: 65
2022-12-05 21:50:51,293 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4676972679620565, 'Total loss': 0.4676972679620565} | train loss {'Reaction outcome loss': 0.13509843825194678, 'Total loss': 0.13509843825194678}
2022-12-05 21:50:51,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:51,293 INFO:     Epoch: 66
2022-12-05 21:50:52,079 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4787930239771688, 'Total loss': 0.4787930239771688} | train loss {'Reaction outcome loss': 0.13531653202886954, 'Total loss': 0.13531653202886954}
2022-12-05 21:50:52,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:52,080 INFO:     Epoch: 67
2022-12-05 21:50:52,869 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46431161047414293, 'Total loss': 0.46431161047414293} | train loss {'Reaction outcome loss': 0.13529311245704284, 'Total loss': 0.13529311245704284}
2022-12-05 21:50:52,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:52,869 INFO:     Epoch: 68
2022-12-05 21:50:53,653 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4631185198939124, 'Total loss': 0.4631185198939124} | train loss {'Reaction outcome loss': 0.13411208243704723, 'Total loss': 0.13411208243704723}
2022-12-05 21:50:53,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:53,653 INFO:     Epoch: 69
2022-12-05 21:50:54,436 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4598561390194782, 'Total loss': 0.4598561390194782} | train loss {'Reaction outcome loss': 0.13437576758385192, 'Total loss': 0.13437576758385192}
2022-12-05 21:50:54,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:54,437 INFO:     Epoch: 70
2022-12-05 21:50:55,223 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46094718090323517, 'Total loss': 0.46094718090323517} | train loss {'Reaction outcome loss': 0.13267336969004304, 'Total loss': 0.13267336969004304}
2022-12-05 21:50:55,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:55,223 INFO:     Epoch: 71
2022-12-05 21:50:56,012 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4576099497634311, 'Total loss': 0.4576099497634311} | train loss {'Reaction outcome loss': 0.13369476339077485, 'Total loss': 0.13369476339077485}
2022-12-05 21:50:56,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:56,012 INFO:     Epoch: 72
2022-12-05 21:50:56,799 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4695314855076546, 'Total loss': 0.4695314855076546} | train loss {'Reaction outcome loss': 0.1304565354853441, 'Total loss': 0.1304565354853441}
2022-12-05 21:50:56,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:56,799 INFO:     Epoch: 73
2022-12-05 21:50:57,583 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4657681080144505, 'Total loss': 0.4657681080144505} | train loss {'Reaction outcome loss': 0.13087124011067094, 'Total loss': 0.13087124011067094}
2022-12-05 21:50:57,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:57,583 INFO:     Epoch: 74
2022-12-05 21:50:58,366 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45675809438838516, 'Total loss': 0.45675809438838516} | train loss {'Reaction outcome loss': 0.1292900531400056, 'Total loss': 0.1292900531400056}
2022-12-05 21:50:58,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:58,366 INFO:     Epoch: 75
2022-12-05 21:50:59,149 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46646293651225956, 'Total loss': 0.46646293651225956} | train loss {'Reaction outcome loss': 0.13097511253655567, 'Total loss': 0.13097511253655567}
2022-12-05 21:50:59,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:59,150 INFO:     Epoch: 76
2022-12-05 21:50:59,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46282697451669114, 'Total loss': 0.46282697451669114} | train loss {'Reaction outcome loss': 0.13175360275218723, 'Total loss': 0.13175360275218723}
2022-12-05 21:50:59,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:50:59,937 INFO:     Epoch: 77
2022-12-05 21:51:00,730 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44870232184265935, 'Total loss': 0.44870232184265935} | train loss {'Reaction outcome loss': 0.13081829766666547, 'Total loss': 0.13081829766666547}
2022-12-05 21:51:00,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:00,730 INFO:     Epoch: 78
2022-12-05 21:51:01,517 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46130287751208904, 'Total loss': 0.46130287751208904} | train loss {'Reaction outcome loss': 0.13154611329273244, 'Total loss': 0.13154611329273244}
2022-12-05 21:51:01,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:01,518 INFO:     Epoch: 79
2022-12-05 21:51:02,301 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4740541456050651, 'Total loss': 0.4740541456050651} | train loss {'Reaction outcome loss': 0.12632948680032716, 'Total loss': 0.12632948680032716}
2022-12-05 21:51:02,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:02,301 INFO:     Epoch: 80
2022-12-05 21:51:03,087 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4502144757398339, 'Total loss': 0.4502144757398339} | train loss {'Reaction outcome loss': 0.12735073147036258, 'Total loss': 0.12735073147036258}
2022-12-05 21:51:03,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:03,087 INFO:     Epoch: 81
2022-12-05 21:51:03,877 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46466767718625623, 'Total loss': 0.46466767718625623} | train loss {'Reaction outcome loss': 0.12962613512044313, 'Total loss': 0.12962613512044313}
2022-12-05 21:51:03,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:03,877 INFO:     Epoch: 82
2022-12-05 21:51:04,667 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4491300156643224, 'Total loss': 0.4491300156643224} | train loss {'Reaction outcome loss': 0.12645224497088645, 'Total loss': 0.12645224497088645}
2022-12-05 21:51:04,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:04,669 INFO:     Epoch: 83
2022-12-05 21:51:05,458 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4584942667983299, 'Total loss': 0.4584942667983299} | train loss {'Reaction outcome loss': 0.12778483307920396, 'Total loss': 0.12778483307920396}
2022-12-05 21:51:05,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:05,458 INFO:     Epoch: 84
2022-12-05 21:51:06,245 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45880781391332315, 'Total loss': 0.45880781391332315} | train loss {'Reaction outcome loss': 0.12594270501972832, 'Total loss': 0.12594270501972832}
2022-12-05 21:51:06,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:06,245 INFO:     Epoch: 85
2022-12-05 21:51:07,038 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46868418261062267, 'Total loss': 0.46868418261062267} | train loss {'Reaction outcome loss': 0.12586109868449266, 'Total loss': 0.12586109868449266}
2022-12-05 21:51:07,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:07,038 INFO:     Epoch: 86
2022-12-05 21:51:07,826 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46527809459109637, 'Total loss': 0.46527809459109637} | train loss {'Reaction outcome loss': 0.1253074326315803, 'Total loss': 0.1253074326315803}
2022-12-05 21:51:07,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:07,826 INFO:     Epoch: 87
2022-12-05 21:51:08,614 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4724411484460498, 'Total loss': 0.4724411484460498} | train loss {'Reaction outcome loss': 0.12723351459660123, 'Total loss': 0.12723351459660123}
2022-12-05 21:51:08,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:08,614 INFO:     Epoch: 88
2022-12-05 21:51:09,398 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4650243409844332, 'Total loss': 0.4650243409844332} | train loss {'Reaction outcome loss': 0.1272971956631871, 'Total loss': 0.1272971956631871}
2022-12-05 21:51:09,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:09,398 INFO:     Epoch: 89
2022-12-05 21:51:10,187 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47351596937623136, 'Total loss': 0.47351596937623136} | train loss {'Reaction outcome loss': 0.12534747342960756, 'Total loss': 0.12534747342960756}
2022-12-05 21:51:10,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:10,188 INFO:     Epoch: 90
2022-12-05 21:51:10,973 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46397435769092205, 'Total loss': 0.46397435769092205} | train loss {'Reaction outcome loss': 0.1233821264849823, 'Total loss': 0.1233821264849823}
2022-12-05 21:51:10,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:10,974 INFO:     Epoch: 91
2022-12-05 21:51:11,758 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4594795859830324, 'Total loss': 0.4594795859830324} | train loss {'Reaction outcome loss': 0.12552571461200104, 'Total loss': 0.12552571461200104}
2022-12-05 21:51:11,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:11,758 INFO:     Epoch: 92
2022-12-05 21:51:12,541 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45812358429958655, 'Total loss': 0.45812358429958655} | train loss {'Reaction outcome loss': 0.12645521082487873, 'Total loss': 0.12645521082487873}
2022-12-05 21:51:12,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:12,542 INFO:     Epoch: 93
2022-12-05 21:51:13,332 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4546918169010517, 'Total loss': 0.4546918169010517} | train loss {'Reaction outcome loss': 0.12316940781721449, 'Total loss': 0.12316940781721449}
2022-12-05 21:51:13,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:13,332 INFO:     Epoch: 94
2022-12-05 21:51:14,121 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4647766050211219, 'Total loss': 0.4647766050211219} | train loss {'Reaction outcome loss': 0.12357514648179173, 'Total loss': 0.12357514648179173}
2022-12-05 21:51:14,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:14,121 INFO:     Epoch: 95
2022-12-05 21:51:14,906 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46048968649187755, 'Total loss': 0.46048968649187755} | train loss {'Reaction outcome loss': 0.12253265326735793, 'Total loss': 0.12253265326735793}
2022-12-05 21:51:14,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:14,906 INFO:     Epoch: 96
2022-12-05 21:51:15,692 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47310814885206, 'Total loss': 0.47310814885206} | train loss {'Reaction outcome loss': 0.12320425809498449, 'Total loss': 0.12320425809498449}
2022-12-05 21:51:15,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:15,693 INFO:     Epoch: 97
2022-12-05 21:51:16,477 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46478426213874374, 'Total loss': 0.46478426213874374} | train loss {'Reaction outcome loss': 0.12402706374185252, 'Total loss': 0.12402706374185252}
2022-12-05 21:51:16,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:16,477 INFO:     Epoch: 98
2022-12-05 21:51:17,263 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.461595288542814, 'Total loss': 0.461595288542814} | train loss {'Reaction outcome loss': 0.12118281103808005, 'Total loss': 0.12118281103808005}
2022-12-05 21:51:17,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:17,264 INFO:     Epoch: 99
2022-12-05 21:51:18,048 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46025378568920977, 'Total loss': 0.46025378568920977} | train loss {'Reaction outcome loss': 0.11981625488356183, 'Total loss': 0.11981625488356183}
2022-12-05 21:51:18,048 INFO:     Best model found after epoch 17 of 100.
2022-12-05 21:51:18,048 INFO:   Done with stage: TRAINING
2022-12-05 21:51:18,048 INFO:   Starting stage: EVALUATION
2022-12-05 21:51:18,185 INFO:   Done with stage: EVALUATION
2022-12-05 21:51:18,185 INFO:   Leaving out SEQ value Fold_3
2022-12-05 21:51:18,198 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 21:51:18,198 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:51:18,829 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:51:18,829 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:51:18,898 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:51:18,898 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:51:18,898 INFO:     No hyperparam tuning for this model
2022-12-05 21:51:18,898 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:51:18,898 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:51:18,899 INFO:     None feature selector for col prot
2022-12-05 21:51:18,899 INFO:     None feature selector for col prot
2022-12-05 21:51:18,899 INFO:     None feature selector for col prot
2022-12-05 21:51:18,899 INFO:     None feature selector for col chem
2022-12-05 21:51:18,900 INFO:     None feature selector for col chem
2022-12-05 21:51:18,900 INFO:     None feature selector for col chem
2022-12-05 21:51:18,900 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:51:18,900 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:51:18,901 INFO:     Number of params in model 215821
2022-12-05 21:51:18,905 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:51:18,905 INFO:   Starting stage: TRAINING
2022-12-05 21:51:18,964 INFO:     Val loss before train {'Reaction outcome loss': 0.9958935878997626, 'Total loss': 0.9958935878997626}
2022-12-05 21:51:18,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:18,965 INFO:     Epoch: 0
2022-12-05 21:51:19,757 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5737582133259884, 'Total loss': 0.5737582133259884} | train loss {'Reaction outcome loss': 0.7669071704149246, 'Total loss': 0.7669071704149246}
2022-12-05 21:51:19,757 INFO:     Found new best model at epoch 0
2022-12-05 21:51:19,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:19,758 INFO:     Epoch: 1
2022-12-05 21:51:20,550 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4905351192452187, 'Total loss': 0.4905351192452187} | train loss {'Reaction outcome loss': 0.5160664231440083, 'Total loss': 0.5160664231440083}
2022-12-05 21:51:20,550 INFO:     Found new best model at epoch 1
2022-12-05 21:51:20,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:20,551 INFO:     Epoch: 2
2022-12-05 21:51:21,338 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4550420239914295, 'Total loss': 0.4550420239914295} | train loss {'Reaction outcome loss': 0.4452311087582932, 'Total loss': 0.4452311087582932}
2022-12-05 21:51:21,338 INFO:     Found new best model at epoch 2
2022-12-05 21:51:21,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:21,339 INFO:     Epoch: 3
2022-12-05 21:51:22,125 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4314030914805656, 'Total loss': 0.4314030914805656} | train loss {'Reaction outcome loss': 0.40522041361107203, 'Total loss': 0.40522041361107203}
2022-12-05 21:51:22,125 INFO:     Found new best model at epoch 3
2022-12-05 21:51:22,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:22,126 INFO:     Epoch: 4
2022-12-05 21:51:22,911 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4218787291022234, 'Total loss': 0.4218787291022234} | train loss {'Reaction outcome loss': 0.3786616895164623, 'Total loss': 0.3786616895164623}
2022-12-05 21:51:22,911 INFO:     Found new best model at epoch 4
2022-12-05 21:51:22,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:22,912 INFO:     Epoch: 5
2022-12-05 21:51:23,700 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4152724382489227, 'Total loss': 0.4152724382489227} | train loss {'Reaction outcome loss': 0.35327316191597063, 'Total loss': 0.35327316191597063}
2022-12-05 21:51:23,701 INFO:     Found new best model at epoch 5
2022-12-05 21:51:23,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:23,702 INFO:     Epoch: 6
2022-12-05 21:51:24,488 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4087735220443371, 'Total loss': 0.4087735220443371} | train loss {'Reaction outcome loss': 0.33537271939462326, 'Total loss': 0.33537271939462326}
2022-12-05 21:51:24,488 INFO:     Found new best model at epoch 6
2022-12-05 21:51:24,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:24,489 INFO:     Epoch: 7
2022-12-05 21:51:25,276 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40545725060063736, 'Total loss': 0.40545725060063736} | train loss {'Reaction outcome loss': 0.3178082284380178, 'Total loss': 0.3178082284380178}
2022-12-05 21:51:25,276 INFO:     Found new best model at epoch 7
2022-12-05 21:51:25,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:25,277 INFO:     Epoch: 8
2022-12-05 21:51:26,064 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40511411497759264, 'Total loss': 0.40511411497759264} | train loss {'Reaction outcome loss': 0.3030495914157297, 'Total loss': 0.3030495914157297}
2022-12-05 21:51:26,064 INFO:     Found new best model at epoch 8
2022-12-05 21:51:26,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:26,065 INFO:     Epoch: 9
2022-12-05 21:51:26,852 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4026205484257188, 'Total loss': 0.4026205484257188} | train loss {'Reaction outcome loss': 0.29396400887702334, 'Total loss': 0.29396400887702334}
2022-12-05 21:51:26,852 INFO:     Found new best model at epoch 9
2022-12-05 21:51:26,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:26,853 INFO:     Epoch: 10
2022-12-05 21:51:27,636 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4129211864499159, 'Total loss': 0.4129211864499159} | train loss {'Reaction outcome loss': 0.28106968462100773, 'Total loss': 0.28106968462100773}
2022-12-05 21:51:27,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:27,637 INFO:     Epoch: 11
2022-12-05 21:51:28,423 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4151086557743161, 'Total loss': 0.4151086557743161} | train loss {'Reaction outcome loss': 0.271894243042, 'Total loss': 0.271894243042}
2022-12-05 21:51:28,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:28,423 INFO:     Epoch: 12
2022-12-05 21:51:29,208 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4020329010347987, 'Total loss': 0.4020329010347987} | train loss {'Reaction outcome loss': 0.26211124901339167, 'Total loss': 0.26211124901339167}
2022-12-05 21:51:29,208 INFO:     Found new best model at epoch 12
2022-12-05 21:51:29,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:29,209 INFO:     Epoch: 13
2022-12-05 21:51:29,993 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39944336043540823, 'Total loss': 0.39944336043540823} | train loss {'Reaction outcome loss': 0.2507809441933622, 'Total loss': 0.2507809441933622}
2022-12-05 21:51:29,993 INFO:     Found new best model at epoch 13
2022-12-05 21:51:29,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:29,994 INFO:     Epoch: 14
2022-12-05 21:51:30,777 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40154549999292505, 'Total loss': 0.40154549999292505} | train loss {'Reaction outcome loss': 0.2460582405023399, 'Total loss': 0.2460582405023399}
2022-12-05 21:51:30,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:30,777 INFO:     Epoch: 15
2022-12-05 21:51:31,560 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4095649535572806, 'Total loss': 0.4095649535572806} | train loss {'Reaction outcome loss': 0.23683098699042543, 'Total loss': 0.23683098699042543}
2022-12-05 21:51:31,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:31,560 INFO:     Epoch: 16
2022-12-05 21:51:32,346 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40426274544970936, 'Total loss': 0.40426274544970936} | train loss {'Reaction outcome loss': 0.22630624874632377, 'Total loss': 0.22630624874632377}
2022-12-05 21:51:32,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:32,347 INFO:     Epoch: 17
2022-12-05 21:51:33,138 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40768685087908146, 'Total loss': 0.40768685087908146} | train loss {'Reaction outcome loss': 0.22412277547428844, 'Total loss': 0.22412277547428844}
2022-12-05 21:51:33,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:33,139 INFO:     Epoch: 18
2022-12-05 21:51:33,921 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40586640010046404, 'Total loss': 0.40586640010046404} | train loss {'Reaction outcome loss': 0.21504952822674495, 'Total loss': 0.21504952822674495}
2022-12-05 21:51:33,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:33,921 INFO:     Epoch: 19
2022-12-05 21:51:34,705 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4120557173046955, 'Total loss': 0.4120557173046955} | train loss {'Reaction outcome loss': 0.20957275338043443, 'Total loss': 0.20957275338043443}
2022-12-05 21:51:34,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:34,705 INFO:     Epoch: 20
2022-12-05 21:51:35,492 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4103255635777185, 'Total loss': 0.4103255635777185} | train loss {'Reaction outcome loss': 0.20726062026119135, 'Total loss': 0.20726062026119135}
2022-12-05 21:51:35,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:35,493 INFO:     Epoch: 21
2022-12-05 21:51:36,278 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41507094058879584, 'Total loss': 0.41507094058879584} | train loss {'Reaction outcome loss': 0.20107264149949322, 'Total loss': 0.20107264149949322}
2022-12-05 21:51:36,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:36,278 INFO:     Epoch: 22
2022-12-05 21:51:37,061 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.412318270220313, 'Total loss': 0.412318270220313} | train loss {'Reaction outcome loss': 0.1976345561780646, 'Total loss': 0.1976345561780646}
2022-12-05 21:51:37,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:37,061 INFO:     Epoch: 23
2022-12-05 21:51:37,845 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41200118702511457, 'Total loss': 0.41200118702511457} | train loss {'Reaction outcome loss': 0.19027946312285837, 'Total loss': 0.19027946312285837}
2022-12-05 21:51:37,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:37,845 INFO:     Epoch: 24
2022-12-05 21:51:38,628 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4090012131735336, 'Total loss': 0.4090012131735336} | train loss {'Reaction outcome loss': 0.18610724794571518, 'Total loss': 0.18610724794571518}
2022-12-05 21:51:38,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:38,628 INFO:     Epoch: 25
2022-12-05 21:51:39,417 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4087518822661666, 'Total loss': 0.4087518822661666} | train loss {'Reaction outcome loss': 0.18483848879724496, 'Total loss': 0.18483848879724496}
2022-12-05 21:51:39,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:39,418 INFO:     Epoch: 26
2022-12-05 21:51:40,211 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4105860705292502, 'Total loss': 0.4105860705292502} | train loss {'Reaction outcome loss': 0.18209322850357312, 'Total loss': 0.18209322850357312}
2022-12-05 21:51:40,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:40,212 INFO:     Epoch: 27
2022-12-05 21:51:40,997 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42125000700701115, 'Total loss': 0.42125000700701115} | train loss {'Reaction outcome loss': 0.17742072929796138, 'Total loss': 0.17742072929796138}
2022-12-05 21:51:40,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:40,997 INFO:     Epoch: 28
2022-12-05 21:51:41,785 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4091113424578378, 'Total loss': 0.4091113424578378} | train loss {'Reaction outcome loss': 0.17446929456849322, 'Total loss': 0.17446929456849322}
2022-12-05 21:51:41,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:41,786 INFO:     Epoch: 29
2022-12-05 21:51:42,576 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4212411066820455, 'Total loss': 0.4212411066820455} | train loss {'Reaction outcome loss': 0.16944418578088039, 'Total loss': 0.16944418578088039}
2022-12-05 21:51:42,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:42,577 INFO:     Epoch: 30
2022-12-05 21:51:43,363 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4207771008097848, 'Total loss': 0.4207771008097848} | train loss {'Reaction outcome loss': 0.16873164297860177, 'Total loss': 0.16873164297860177}
2022-12-05 21:51:43,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:43,363 INFO:     Epoch: 31
2022-12-05 21:51:44,150 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43547907402349073, 'Total loss': 0.43547907402349073} | train loss {'Reaction outcome loss': 0.1638540354496265, 'Total loss': 0.1638540354496265}
2022-12-05 21:51:44,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:44,150 INFO:     Epoch: 32
2022-12-05 21:51:44,937 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4328042764303296, 'Total loss': 0.4328042764303296} | train loss {'Reaction outcome loss': 0.16425427655521474, 'Total loss': 0.16425427655521474}
2022-12-05 21:51:44,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:44,938 INFO:     Epoch: 33
2022-12-05 21:51:45,726 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4235417101272317, 'Total loss': 0.4235417101272317} | train loss {'Reaction outcome loss': 0.16211371037528896, 'Total loss': 0.16211371037528896}
2022-12-05 21:51:45,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:45,726 INFO:     Epoch: 34
2022-12-05 21:51:46,514 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42475942193075666, 'Total loss': 0.42475942193075666} | train loss {'Reaction outcome loss': 0.1582792817889789, 'Total loss': 0.1582792817889789}
2022-12-05 21:51:46,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:46,514 INFO:     Epoch: 35
2022-12-05 21:51:47,300 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4461971299592839, 'Total loss': 0.4461971299592839} | train loss {'Reaction outcome loss': 0.15870630305993264, 'Total loss': 0.15870630305993264}
2022-12-05 21:51:47,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:47,300 INFO:     Epoch: 36
2022-12-05 21:51:48,083 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4374371621497842, 'Total loss': 0.4374371621497842} | train loss {'Reaction outcome loss': 0.15424287466897216, 'Total loss': 0.15424287466897216}
2022-12-05 21:51:48,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:48,084 INFO:     Epoch: 37
2022-12-05 21:51:48,867 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42546908280184104, 'Total loss': 0.42546908280184104} | train loss {'Reaction outcome loss': 0.1516870581315922, 'Total loss': 0.1516870581315922}
2022-12-05 21:51:48,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:48,867 INFO:     Epoch: 38
2022-12-05 21:51:49,650 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43695251227811327, 'Total loss': 0.43695251227811327} | train loss {'Reaction outcome loss': 0.15069852327378314, 'Total loss': 0.15069852327378314}
2022-12-05 21:51:49,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:49,650 INFO:     Epoch: 39
2022-12-05 21:51:50,434 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4287698282751926, 'Total loss': 0.4287698282751926} | train loss {'Reaction outcome loss': 0.15097018530531253, 'Total loss': 0.15097018530531253}
2022-12-05 21:51:50,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:50,434 INFO:     Epoch: 40
2022-12-05 21:51:51,218 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43054650827895763, 'Total loss': 0.43054650827895763} | train loss {'Reaction outcome loss': 0.14800737790580168, 'Total loss': 0.14800737790580168}
2022-12-05 21:51:51,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:51,218 INFO:     Epoch: 41
2022-12-05 21:51:52,003 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4397059048331061, 'Total loss': 0.4397059048331061} | train loss {'Reaction outcome loss': 0.14724555634511788, 'Total loss': 0.14724555634511788}
2022-12-05 21:51:52,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:52,003 INFO:     Epoch: 42
2022-12-05 21:51:52,787 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4280400369749513, 'Total loss': 0.4280400369749513} | train loss {'Reaction outcome loss': 0.14489934454122405, 'Total loss': 0.14489934454122405}
2022-12-05 21:51:52,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:52,787 INFO:     Epoch: 43
2022-12-05 21:51:53,570 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4300912994631501, 'Total loss': 0.4300912994631501} | train loss {'Reaction outcome loss': 0.1422937210099619, 'Total loss': 0.1422937210099619}
2022-12-05 21:51:53,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:53,571 INFO:     Epoch: 44
2022-12-05 21:51:54,356 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4416814548678176, 'Total loss': 0.4416814548678176} | train loss {'Reaction outcome loss': 0.13863147443282556, 'Total loss': 0.13863147443282556}
2022-12-05 21:51:54,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:54,357 INFO:     Epoch: 45
2022-12-05 21:51:55,141 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43111827380435414, 'Total loss': 0.43111827380435414} | train loss {'Reaction outcome loss': 0.13762823922071057, 'Total loss': 0.13762823922071057}
2022-12-05 21:51:55,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:55,142 INFO:     Epoch: 46
2022-12-05 21:51:55,928 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43076958247395447, 'Total loss': 0.43076958247395447} | train loss {'Reaction outcome loss': 0.1373393877722384, 'Total loss': 0.1373393877722384}
2022-12-05 21:51:55,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:55,928 INFO:     Epoch: 47
2022-12-05 21:51:56,719 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4378382982902749, 'Total loss': 0.4378382982902749} | train loss {'Reaction outcome loss': 0.13510879880336465, 'Total loss': 0.13510879880336465}
2022-12-05 21:51:56,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:56,719 INFO:     Epoch: 48
2022-12-05 21:51:57,514 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4289243207421414, 'Total loss': 0.4289243207421414} | train loss {'Reaction outcome loss': 0.1359660736911121, 'Total loss': 0.1359660736911121}
2022-12-05 21:51:57,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:57,514 INFO:     Epoch: 49
2022-12-05 21:51:58,301 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4339371687451074, 'Total loss': 0.4339371687451074} | train loss {'Reaction outcome loss': 0.1315077989911813, 'Total loss': 0.1315077989911813}
2022-12-05 21:51:58,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:58,301 INFO:     Epoch: 50
2022-12-05 21:51:59,084 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44406364234380946, 'Total loss': 0.44406364234380946} | train loss {'Reaction outcome loss': 0.1318973092759242, 'Total loss': 0.1318973092759242}
2022-12-05 21:51:59,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:59,085 INFO:     Epoch: 51
2022-12-05 21:51:59,868 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4399564938489781, 'Total loss': 0.4399564938489781} | train loss {'Reaction outcome loss': 0.1314954909068517, 'Total loss': 0.1314954909068517}
2022-12-05 21:51:59,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:51:59,868 INFO:     Epoch: 52
2022-12-05 21:52:00,651 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44646637661512506, 'Total loss': 0.44646637661512506} | train loss {'Reaction outcome loss': 0.13325272334861707, 'Total loss': 0.13325272334861707}
2022-12-05 21:52:00,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:00,651 INFO:     Epoch: 53
2022-12-05 21:52:01,435 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4433138325463894, 'Total loss': 0.4433138325463894} | train loss {'Reaction outcome loss': 0.13114478265423876, 'Total loss': 0.13114478265423876}
2022-12-05 21:52:01,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:01,435 INFO:     Epoch: 54
2022-12-05 21:52:02,224 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44709235429763794, 'Total loss': 0.44709235429763794} | train loss {'Reaction outcome loss': 0.12984866865330422, 'Total loss': 0.12984866865330422}
2022-12-05 21:52:02,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:02,225 INFO:     Epoch: 55
2022-12-05 21:52:03,015 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44791047933489775, 'Total loss': 0.44791047933489775} | train loss {'Reaction outcome loss': 0.12882659469013574, 'Total loss': 0.12882659469013574}
2022-12-05 21:52:03,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:03,015 INFO:     Epoch: 56
2022-12-05 21:52:03,800 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44746724117633907, 'Total loss': 0.44746724117633907} | train loss {'Reaction outcome loss': 0.12673291772390244, 'Total loss': 0.12673291772390244}
2022-12-05 21:52:03,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:03,801 INFO:     Epoch: 57
2022-12-05 21:52:04,586 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4502271708360938, 'Total loss': 0.4502271708360938} | train loss {'Reaction outcome loss': 0.1286043123739054, 'Total loss': 0.1286043123739054}
2022-12-05 21:52:04,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:04,586 INFO:     Epoch: 58
2022-12-05 21:52:05,375 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4624692000621973, 'Total loss': 0.4624692000621973} | train loss {'Reaction outcome loss': 0.12320119882246754, 'Total loss': 0.12320119882246754}
2022-12-05 21:52:05,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:05,375 INFO:     Epoch: 59
2022-12-05 21:52:06,163 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44607703976852947, 'Total loss': 0.44607703976852947} | train loss {'Reaction outcome loss': 0.12422685464462419, 'Total loss': 0.12422685464462419}
2022-12-05 21:52:06,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:06,164 INFO:     Epoch: 60
2022-12-05 21:52:06,956 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4457632334426392, 'Total loss': 0.4457632334426392} | train loss {'Reaction outcome loss': 0.12509074333871975, 'Total loss': 0.12509074333871975}
2022-12-05 21:52:06,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:06,956 INFO:     Epoch: 61
2022-12-05 21:52:07,742 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44627743231695755, 'Total loss': 0.44627743231695755} | train loss {'Reaction outcome loss': 0.12627377543506807, 'Total loss': 0.12627377543506807}
2022-12-05 21:52:07,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:07,742 INFO:     Epoch: 62
2022-12-05 21:52:08,530 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4524563133370045, 'Total loss': 0.4524563133370045} | train loss {'Reaction outcome loss': 0.12339341498483888, 'Total loss': 0.12339341498483888}
2022-12-05 21:52:08,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:08,530 INFO:     Epoch: 63
2022-12-05 21:52:09,315 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44524830718373143, 'Total loss': 0.44524830718373143} | train loss {'Reaction outcome loss': 0.12207146098867791, 'Total loss': 0.12207146098867791}
2022-12-05 21:52:09,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:09,315 INFO:     Epoch: 64
2022-12-05 21:52:10,100 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44488452548204466, 'Total loss': 0.44488452548204466} | train loss {'Reaction outcome loss': 0.12059378337122684, 'Total loss': 0.12059378337122684}
2022-12-05 21:52:10,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:10,101 INFO:     Epoch: 65
2022-12-05 21:52:10,886 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4420493040667024, 'Total loss': 0.4420493040667024} | train loss {'Reaction outcome loss': 0.12218068863387357, 'Total loss': 0.12218068863387357}
2022-12-05 21:52:10,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:10,886 INFO:     Epoch: 66
2022-12-05 21:52:11,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4614475955103719, 'Total loss': 0.4614475955103719} | train loss {'Reaction outcome loss': 0.11849047109240392, 'Total loss': 0.11849047109240392}
2022-12-05 21:52:11,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:11,677 INFO:     Epoch: 67
2022-12-05 21:52:12,462 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4491520286646, 'Total loss': 0.4491520286646} | train loss {'Reaction outcome loss': 0.11951663619914993, 'Total loss': 0.11951663619914993}
2022-12-05 21:52:12,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:12,463 INFO:     Epoch: 68
2022-12-05 21:52:13,251 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4439032105512397, 'Total loss': 0.4439032105512397} | train loss {'Reaction outcome loss': 0.11929920724150343, 'Total loss': 0.11929920724150343}
2022-12-05 21:52:13,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:13,251 INFO:     Epoch: 69
2022-12-05 21:52:14,042 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.450287795690603, 'Total loss': 0.450287795690603} | train loss {'Reaction outcome loss': 0.11498425732992712, 'Total loss': 0.11498425732992712}
2022-12-05 21:52:14,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:14,043 INFO:     Epoch: 70
2022-12-05 21:52:14,834 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4600008989489356, 'Total loss': 0.4600008989489356} | train loss {'Reaction outcome loss': 0.11771993442117924, 'Total loss': 0.11771993442117924}
2022-12-05 21:52:14,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:14,834 INFO:     Epoch: 71
2022-12-05 21:52:15,619 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4379334286894909, 'Total loss': 0.4379334286894909} | train loss {'Reaction outcome loss': 0.11728570803801422, 'Total loss': 0.11728570803801422}
2022-12-05 21:52:15,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:15,619 INFO:     Epoch: 72
2022-12-05 21:52:16,404 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44931937546231027, 'Total loss': 0.44931937546231027} | train loss {'Reaction outcome loss': 0.11513486912580909, 'Total loss': 0.11513486912580909}
2022-12-05 21:52:16,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:16,404 INFO:     Epoch: 73
2022-12-05 21:52:17,191 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44815329306347423, 'Total loss': 0.44815329306347423} | train loss {'Reaction outcome loss': 0.1148308700820828, 'Total loss': 0.1148308700820828}
2022-12-05 21:52:17,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:17,191 INFO:     Epoch: 74
2022-12-05 21:52:17,983 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46499730369379355, 'Total loss': 0.46499730369379355} | train loss {'Reaction outcome loss': 0.11454995416226935, 'Total loss': 0.11454995416226935}
2022-12-05 21:52:17,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:17,983 INFO:     Epoch: 75
2022-12-05 21:52:18,772 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44039949445530424, 'Total loss': 0.44039949445530424} | train loss {'Reaction outcome loss': 0.11556847655733467, 'Total loss': 0.11556847655733467}
2022-12-05 21:52:18,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:18,772 INFO:     Epoch: 76
2022-12-05 21:52:19,560 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4552044331334358, 'Total loss': 0.4552044331334358} | train loss {'Reaction outcome loss': 0.11697700288391015, 'Total loss': 0.11697700288391015}
2022-12-05 21:52:19,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:19,561 INFO:     Epoch: 77
2022-12-05 21:52:20,345 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.454162007500959, 'Total loss': 0.454162007500959} | train loss {'Reaction outcome loss': 0.1142599293046066, 'Total loss': 0.1142599293046066}
2022-12-05 21:52:20,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:20,346 INFO:     Epoch: 78
2022-12-05 21:52:21,131 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46107535982547804, 'Total loss': 0.46107535982547804} | train loss {'Reaction outcome loss': 0.11232590740622922, 'Total loss': 0.11232590740622922}
2022-12-05 21:52:21,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:21,131 INFO:     Epoch: 79
2022-12-05 21:52:21,916 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4571754124968551, 'Total loss': 0.4571754124968551} | train loss {'Reaction outcome loss': 0.11179944025886962, 'Total loss': 0.11179944025886962}
2022-12-05 21:52:21,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:21,916 INFO:     Epoch: 80
2022-12-05 21:52:22,709 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45926146486470865, 'Total loss': 0.45926146486470865} | train loss {'Reaction outcome loss': 0.11194281706769692, 'Total loss': 0.11194281706769692}
2022-12-05 21:52:22,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:22,709 INFO:     Epoch: 81
2022-12-05 21:52:23,497 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.436153183149737, 'Total loss': 0.436153183149737} | train loss {'Reaction outcome loss': 0.11389417357773321, 'Total loss': 0.11389417357773321}
2022-12-05 21:52:23,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:23,497 INFO:     Epoch: 82
2022-12-05 21:52:24,290 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44584761265405387, 'Total loss': 0.44584761265405387} | train loss {'Reaction outcome loss': 0.11214362784597992, 'Total loss': 0.11214362784597992}
2022-12-05 21:52:24,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:24,291 INFO:     Epoch: 83
2022-12-05 21:52:25,080 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4484551011822944, 'Total loss': 0.4484551011822944} | train loss {'Reaction outcome loss': 0.11282969318849385, 'Total loss': 0.11282969318849385}
2022-12-05 21:52:25,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:25,081 INFO:     Epoch: 84
2022-12-05 21:52:25,866 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4519455866065136, 'Total loss': 0.4519455866065136} | train loss {'Reaction outcome loss': 0.11207987998467182, 'Total loss': 0.11207987998467182}
2022-12-05 21:52:25,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:25,866 INFO:     Epoch: 85
2022-12-05 21:52:26,652 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4588051053673722, 'Total loss': 0.4588051053673722} | train loss {'Reaction outcome loss': 0.11025645046830788, 'Total loss': 0.11025645046830788}
2022-12-05 21:52:26,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:26,652 INFO:     Epoch: 86
2022-12-05 21:52:27,442 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44094090648861817, 'Total loss': 0.44094090648861817} | train loss {'Reaction outcome loss': 0.1129569068902218, 'Total loss': 0.1129569068902218}
2022-12-05 21:52:27,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:27,442 INFO:     Epoch: 87
2022-12-05 21:52:28,226 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4625438368597696, 'Total loss': 0.4625438368597696} | train loss {'Reaction outcome loss': 0.11163016926062094, 'Total loss': 0.11163016926062094}
2022-12-05 21:52:28,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:28,226 INFO:     Epoch: 88
2022-12-05 21:52:29,012 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44704636272995973, 'Total loss': 0.44704636272995973} | train loss {'Reaction outcome loss': 0.11240866399354867, 'Total loss': 0.11240866399354867}
2022-12-05 21:52:29,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:29,012 INFO:     Epoch: 89
2022-12-05 21:52:29,803 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4543888924080272, 'Total loss': 0.4543888924080272} | train loss {'Reaction outcome loss': 0.11118902761458618, 'Total loss': 0.11118902761458618}
2022-12-05 21:52:29,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:29,803 INFO:     Epoch: 90
2022-12-05 21:52:30,593 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.451703010603439, 'Total loss': 0.451703010603439} | train loss {'Reaction outcome loss': 0.1090847359680128, 'Total loss': 0.1090847359680128}
2022-12-05 21:52:30,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:30,593 INFO:     Epoch: 91
2022-12-05 21:52:31,387 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.47527513479770617, 'Total loss': 0.47527513479770617} | train loss {'Reaction outcome loss': 0.10896373137862223, 'Total loss': 0.10896373137862223}
2022-12-05 21:52:31,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:31,387 INFO:     Epoch: 92
2022-12-05 21:52:32,179 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44056682808454645, 'Total loss': 0.44056682808454645} | train loss {'Reaction outcome loss': 0.10743456507926105, 'Total loss': 0.10743456507926105}
2022-12-05 21:52:32,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:32,179 INFO:     Epoch: 93
2022-12-05 21:52:32,965 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45163479655287986, 'Total loss': 0.45163479655287986} | train loss {'Reaction outcome loss': 0.10876774713473364, 'Total loss': 0.10876774713473364}
2022-12-05 21:52:32,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:32,965 INFO:     Epoch: 94
2022-12-05 21:52:33,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.445370604132497, 'Total loss': 0.445370604132497} | train loss {'Reaction outcome loss': 0.10800029316794921, 'Total loss': 0.10800029316794921}
2022-12-05 21:52:33,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:33,754 INFO:     Epoch: 95
2022-12-05 21:52:34,542 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45707998823287876, 'Total loss': 0.45707998823287876} | train loss {'Reaction outcome loss': 0.10547391194697531, 'Total loss': 0.10547391194697531}
2022-12-05 21:52:34,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:34,542 INFO:     Epoch: 96
2022-12-05 21:52:35,334 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4572480535784433, 'Total loss': 0.4572480535784433} | train loss {'Reaction outcome loss': 0.10865560083527911, 'Total loss': 0.10865560083527911}
2022-12-05 21:52:35,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:35,334 INFO:     Epoch: 97
2022-12-05 21:52:36,123 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4627186208963394, 'Total loss': 0.4627186208963394} | train loss {'Reaction outcome loss': 0.10837216894371343, 'Total loss': 0.10837216894371343}
2022-12-05 21:52:36,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:36,123 INFO:     Epoch: 98
2022-12-05 21:52:36,913 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4535130380198013, 'Total loss': 0.4535130380198013} | train loss {'Reaction outcome loss': 0.10588404594836603, 'Total loss': 0.10588404594836603}
2022-12-05 21:52:36,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:36,913 INFO:     Epoch: 99
2022-12-05 21:52:37,698 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.467621287980745, 'Total loss': 0.467621287980745} | train loss {'Reaction outcome loss': 0.10799778313910374, 'Total loss': 0.10799778313910374}
2022-12-05 21:52:37,699 INFO:     Best model found after epoch 14 of 100.
2022-12-05 21:52:37,699 INFO:   Done with stage: TRAINING
2022-12-05 21:52:37,699 INFO:   Starting stage: EVALUATION
2022-12-05 21:52:37,836 INFO:   Done with stage: EVALUATION
2022-12-05 21:52:37,836 INFO:   Leaving out SEQ value Fold_4
2022-12-05 21:52:37,848 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:52:37,848 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:52:38,501 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:52:38,501 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:52:38,571 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:52:38,571 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:52:38,571 INFO:     No hyperparam tuning for this model
2022-12-05 21:52:38,571 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:52:38,571 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:52:38,572 INFO:     None feature selector for col prot
2022-12-05 21:52:38,572 INFO:     None feature selector for col prot
2022-12-05 21:52:38,572 INFO:     None feature selector for col prot
2022-12-05 21:52:38,573 INFO:     None feature selector for col chem
2022-12-05 21:52:38,573 INFO:     None feature selector for col chem
2022-12-05 21:52:38,573 INFO:     None feature selector for col chem
2022-12-05 21:52:38,573 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:52:38,573 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:52:38,575 INFO:     Number of params in model 215821
2022-12-05 21:52:38,578 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:52:38,578 INFO:   Starting stage: TRAINING
2022-12-05 21:52:38,639 INFO:     Val loss before train {'Reaction outcome loss': 0.9852126498113979, 'Total loss': 0.9852126498113979}
2022-12-05 21:52:38,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:38,640 INFO:     Epoch: 0
2022-12-05 21:52:39,436 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6285141537135298, 'Total loss': 0.6285141537135298} | train loss {'Reaction outcome loss': 0.7843697301832288, 'Total loss': 0.7843697301832288}
2022-12-05 21:52:39,436 INFO:     Found new best model at epoch 0
2022-12-05 21:52:39,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:39,437 INFO:     Epoch: 1
2022-12-05 21:52:40,231 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5341151437976144, 'Total loss': 0.5341151437976144} | train loss {'Reaction outcome loss': 0.5502394234482576, 'Total loss': 0.5502394234482576}
2022-12-05 21:52:40,231 INFO:     Found new best model at epoch 1
2022-12-05 21:52:40,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:40,232 INFO:     Epoch: 2
2022-12-05 21:52:41,028 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4929770827293396, 'Total loss': 0.4929770827293396} | train loss {'Reaction outcome loss': 0.4754848819271273, 'Total loss': 0.4754848819271273}
2022-12-05 21:52:41,028 INFO:     Found new best model at epoch 2
2022-12-05 21:52:41,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:41,029 INFO:     Epoch: 3
2022-12-05 21:52:41,823 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4865059202367609, 'Total loss': 0.4865059202367609} | train loss {'Reaction outcome loss': 0.43569711628011787, 'Total loss': 0.43569711628011787}
2022-12-05 21:52:41,823 INFO:     Found new best model at epoch 3
2022-12-05 21:52:41,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:41,824 INFO:     Epoch: 4
2022-12-05 21:52:42,619 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4585128179328008, 'Total loss': 0.4585128179328008} | train loss {'Reaction outcome loss': 0.4058629512666208, 'Total loss': 0.4058629512666208}
2022-12-05 21:52:42,619 INFO:     Found new best model at epoch 4
2022-12-05 21:52:42,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:42,620 INFO:     Epoch: 5
2022-12-05 21:52:43,413 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45972582934932277, 'Total loss': 0.45972582934932277} | train loss {'Reaction outcome loss': 0.38547168288998274, 'Total loss': 0.38547168288998274}
2022-12-05 21:52:43,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:43,413 INFO:     Epoch: 6
2022-12-05 21:52:44,208 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4444163680415262, 'Total loss': 0.4444163680415262} | train loss {'Reaction outcome loss': 0.36180303779690853, 'Total loss': 0.36180303779690853}
2022-12-05 21:52:44,209 INFO:     Found new best model at epoch 6
2022-12-05 21:52:44,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:44,210 INFO:     Epoch: 7
2022-12-05 21:52:45,006 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4257619261572307, 'Total loss': 0.4257619261572307} | train loss {'Reaction outcome loss': 0.3458810198282906, 'Total loss': 0.3458810198282906}
2022-12-05 21:52:45,006 INFO:     Found new best model at epoch 7
2022-12-05 21:52:45,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:45,007 INFO:     Epoch: 8
2022-12-05 21:52:45,806 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43723477524789894, 'Total loss': 0.43723477524789894} | train loss {'Reaction outcome loss': 0.32913981114894997, 'Total loss': 0.32913981114894997}
2022-12-05 21:52:45,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:45,806 INFO:     Epoch: 9
2022-12-05 21:52:46,599 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4258272045037963, 'Total loss': 0.4258272045037963} | train loss {'Reaction outcome loss': 0.3141044621857313, 'Total loss': 0.3141044621857313}
2022-12-05 21:52:46,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:46,599 INFO:     Epoch: 10
2022-12-05 21:52:47,394 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4435756355524063, 'Total loss': 0.4435756355524063} | train loss {'Reaction outcome loss': 0.30359746947100286, 'Total loss': 0.30359746947100286}
2022-12-05 21:52:47,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:47,395 INFO:     Epoch: 11
2022-12-05 21:52:48,193 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4279007281769406, 'Total loss': 0.4279007281769406} | train loss {'Reaction outcome loss': 0.29389597418216556, 'Total loss': 0.29389597418216556}
2022-12-05 21:52:48,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:48,194 INFO:     Epoch: 12
2022-12-05 21:52:48,988 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4251949421384118, 'Total loss': 0.4251949421384118} | train loss {'Reaction outcome loss': 0.2827793458092068, 'Total loss': 0.2827793458092068}
2022-12-05 21:52:48,988 INFO:     Found new best model at epoch 12
2022-12-05 21:52:48,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:48,989 INFO:     Epoch: 13
2022-12-05 21:52:49,787 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4285365336320617, 'Total loss': 0.4285365336320617} | train loss {'Reaction outcome loss': 0.2769199345517255, 'Total loss': 0.2769199345517255}
2022-12-05 21:52:49,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:49,787 INFO:     Epoch: 14
2022-12-05 21:52:50,591 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41808461330153723, 'Total loss': 0.41808461330153723} | train loss {'Reaction outcome loss': 0.2652738206541007, 'Total loss': 0.2652738206541007}
2022-12-05 21:52:50,591 INFO:     Found new best model at epoch 14
2022-12-05 21:52:50,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:50,592 INFO:     Epoch: 15
2022-12-05 21:52:51,389 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42584488286890765, 'Total loss': 0.42584488286890765} | train loss {'Reaction outcome loss': 0.256448324528421, 'Total loss': 0.256448324528421}
2022-12-05 21:52:51,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:51,390 INFO:     Epoch: 16
2022-12-05 21:52:52,186 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42898512089794333, 'Total loss': 0.42898512089794333} | train loss {'Reaction outcome loss': 0.24810294837121538, 'Total loss': 0.24810294837121538}
2022-12-05 21:52:52,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:52,186 INFO:     Epoch: 17
2022-12-05 21:52:52,981 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4285512139851397, 'Total loss': 0.4285512139851397} | train loss {'Reaction outcome loss': 0.24184748788292593, 'Total loss': 0.24184748788292593}
2022-12-05 21:52:52,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:52,981 INFO:     Epoch: 18
2022-12-05 21:52:53,778 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4291558749973774, 'Total loss': 0.4291558749973774} | train loss {'Reaction outcome loss': 0.23724327438514725, 'Total loss': 0.23724327438514725}
2022-12-05 21:52:53,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:53,778 INFO:     Epoch: 19
2022-12-05 21:52:54,577 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4307152225889943, 'Total loss': 0.4307152225889943} | train loss {'Reaction outcome loss': 0.2327733531647064, 'Total loss': 0.2327733531647064}
2022-12-05 21:52:54,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:54,577 INFO:     Epoch: 20
2022-12-05 21:52:55,369 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4234762462702664, 'Total loss': 0.4234762462702664} | train loss {'Reaction outcome loss': 0.22317356308582822, 'Total loss': 0.22317356308582822}
2022-12-05 21:52:55,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:55,370 INFO:     Epoch: 21
2022-12-05 21:52:56,162 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.421733078292825, 'Total loss': 0.421733078292825} | train loss {'Reaction outcome loss': 0.21889521247944851, 'Total loss': 0.21889521247944851}
2022-12-05 21:52:56,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:56,162 INFO:     Epoch: 22
2022-12-05 21:52:56,954 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4127179548483003, 'Total loss': 0.4127179548483003} | train loss {'Reaction outcome loss': 0.20928194932262545, 'Total loss': 0.20928194932262545}
2022-12-05 21:52:56,955 INFO:     Found new best model at epoch 22
2022-12-05 21:52:56,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:56,956 INFO:     Epoch: 23
2022-12-05 21:52:57,753 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4500267864628272, 'Total loss': 0.4500267864628272} | train loss {'Reaction outcome loss': 0.20772961128940468, 'Total loss': 0.20772961128940468}
2022-12-05 21:52:57,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:57,754 INFO:     Epoch: 24
2022-12-05 21:52:58,546 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4246087795631452, 'Total loss': 0.4246087795631452} | train loss {'Reaction outcome loss': 0.2020094823393865, 'Total loss': 0.2020094823393865}
2022-12-05 21:52:58,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:58,547 INFO:     Epoch: 25
2022-12-05 21:52:59,338 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4299691393971443, 'Total loss': 0.4299691393971443} | train loss {'Reaction outcome loss': 0.1980890295645486, 'Total loss': 0.1980890295645486}
2022-12-05 21:52:59,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:52:59,338 INFO:     Epoch: 26
2022-12-05 21:53:00,133 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44009673900224944, 'Total loss': 0.44009673900224944} | train loss {'Reaction outcome loss': 0.19280658280740864, 'Total loss': 0.19280658280740864}
2022-12-05 21:53:00,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:00,133 INFO:     Epoch: 27
2022-12-05 21:53:00,928 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4272903789850799, 'Total loss': 0.4272903789850799} | train loss {'Reaction outcome loss': 0.1923984254631195, 'Total loss': 0.1923984254631195}
2022-12-05 21:53:00,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:00,928 INFO:     Epoch: 28
2022-12-05 21:53:01,721 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4419387345286933, 'Total loss': 0.4419387345286933} | train loss {'Reaction outcome loss': 0.18922274237732414, 'Total loss': 0.18922274237732414}
2022-12-05 21:53:01,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:01,721 INFO:     Epoch: 29
2022-12-05 21:53:02,514 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4264368628236381, 'Total loss': 0.4264368628236381} | train loss {'Reaction outcome loss': 0.18147995285991475, 'Total loss': 0.18147995285991475}
2022-12-05 21:53:02,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:02,515 INFO:     Epoch: 30
2022-12-05 21:53:03,310 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43956905298612337, 'Total loss': 0.43956905298612337} | train loss {'Reaction outcome loss': 0.17985563587231435, 'Total loss': 0.17985563587231435}
2022-12-05 21:53:03,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:03,311 INFO:     Epoch: 31
2022-12-05 21:53:04,104 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44216822798956523, 'Total loss': 0.44216822798956523} | train loss {'Reaction outcome loss': 0.18136827448601664, 'Total loss': 0.18136827448601664}
2022-12-05 21:53:04,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:04,104 INFO:     Epoch: 32
2022-12-05 21:53:04,902 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4554418850351464, 'Total loss': 0.4554418850351464} | train loss {'Reaction outcome loss': 0.18041733345431596, 'Total loss': 0.18041733345431596}
2022-12-05 21:53:04,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:04,903 INFO:     Epoch: 33
2022-12-05 21:53:05,698 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44757690229876473, 'Total loss': 0.44757690229876473} | train loss {'Reaction outcome loss': 0.17155825307494715, 'Total loss': 0.17155825307494715}
2022-12-05 21:53:05,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:05,698 INFO:     Epoch: 34
2022-12-05 21:53:06,495 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45558654787865555, 'Total loss': 0.45558654787865555} | train loss {'Reaction outcome loss': 0.1672943333118611, 'Total loss': 0.1672943333118611}
2022-12-05 21:53:06,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:06,495 INFO:     Epoch: 35
2022-12-05 21:53:07,288 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4442561424591325, 'Total loss': 0.4442561424591325} | train loss {'Reaction outcome loss': 0.16587018900313358, 'Total loss': 0.16587018900313358}
2022-12-05 21:53:07,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:07,288 INFO:     Epoch: 36
2022-12-05 21:53:08,084 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.461777714504437, 'Total loss': 0.461777714504437} | train loss {'Reaction outcome loss': 0.16183333318333634, 'Total loss': 0.16183333318333634}
2022-12-05 21:53:08,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:08,084 INFO:     Epoch: 37
2022-12-05 21:53:08,884 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45550707016478886, 'Total loss': 0.45550707016478886} | train loss {'Reaction outcome loss': 0.15972895234840195, 'Total loss': 0.15972895234840195}
2022-12-05 21:53:08,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:08,884 INFO:     Epoch: 38
2022-12-05 21:53:09,687 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.459915662353689, 'Total loss': 0.459915662353689} | train loss {'Reaction outcome loss': 0.15962963423084633, 'Total loss': 0.15962963423084633}
2022-12-05 21:53:09,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:09,688 INFO:     Epoch: 39
2022-12-05 21:53:10,483 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46547753702510486, 'Total loss': 0.46547753702510486} | train loss {'Reaction outcome loss': 0.15636335188515393, 'Total loss': 0.15636335188515393}
2022-12-05 21:53:10,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:10,483 INFO:     Epoch: 40
2022-12-05 21:53:11,280 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4573253750462424, 'Total loss': 0.4573253750462424} | train loss {'Reaction outcome loss': 0.15852553687465606, 'Total loss': 0.15852553687465606}
2022-12-05 21:53:11,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:11,280 INFO:     Epoch: 41
2022-12-05 21:53:12,077 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4612153223292394, 'Total loss': 0.4612153223292394} | train loss {'Reaction outcome loss': 0.15177058353869297, 'Total loss': 0.15177058353869297}
2022-12-05 21:53:12,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:12,078 INFO:     Epoch: 42
2022-12-05 21:53:12,870 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4719029502435164, 'Total loss': 0.4719029502435164} | train loss {'Reaction outcome loss': 0.1528929502699479, 'Total loss': 0.1528929502699479}
2022-12-05 21:53:12,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:12,871 INFO:     Epoch: 43
2022-12-05 21:53:13,664 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4691237741234628, 'Total loss': 0.4691237741234628} | train loss {'Reaction outcome loss': 0.15087670013157703, 'Total loss': 0.15087670013157703}
2022-12-05 21:53:13,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:13,665 INFO:     Epoch: 44
2022-12-05 21:53:14,463 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4634620137512684, 'Total loss': 0.4634620137512684} | train loss {'Reaction outcome loss': 0.15238596014075192, 'Total loss': 0.15238596014075192}
2022-12-05 21:53:14,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:14,463 INFO:     Epoch: 45
2022-12-05 21:53:15,259 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4735796424475583, 'Total loss': 0.4735796424475583} | train loss {'Reaction outcome loss': 0.14676652158712328, 'Total loss': 0.14676652158712328}
2022-12-05 21:53:15,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:15,260 INFO:     Epoch: 46
2022-12-05 21:53:16,053 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47725528038360854, 'Total loss': 0.47725528038360854} | train loss {'Reaction outcome loss': 0.14774630802046312, 'Total loss': 0.14774630802046312}
2022-12-05 21:53:16,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:16,054 INFO:     Epoch: 47
2022-12-05 21:53:16,852 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.469115784899755, 'Total loss': 0.469115784899755} | train loss {'Reaction outcome loss': 0.14267096826090261, 'Total loss': 0.14267096826090261}
2022-12-05 21:53:16,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:16,852 INFO:     Epoch: 48
2022-12-05 21:53:17,648 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46861676431515, 'Total loss': 0.46861676431515} | train loss {'Reaction outcome loss': 0.1422770729576905, 'Total loss': 0.1422770729576905}
2022-12-05 21:53:17,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:17,648 INFO:     Epoch: 49
2022-12-05 21:53:18,441 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4656887457452037, 'Total loss': 0.4656887457452037} | train loss {'Reaction outcome loss': 0.14496946306182787, 'Total loss': 0.14496946306182787}
2022-12-05 21:53:18,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:18,441 INFO:     Epoch: 50
2022-12-05 21:53:19,233 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46657454256306996, 'Total loss': 0.46657454256306996} | train loss {'Reaction outcome loss': 0.14499137276097349, 'Total loss': 0.14499137276097349}
2022-12-05 21:53:19,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:19,234 INFO:     Epoch: 51
2022-12-05 21:53:20,029 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47633638165213843, 'Total loss': 0.47633638165213843} | train loss {'Reaction outcome loss': 0.14013609557076986, 'Total loss': 0.14013609557076986}
2022-12-05 21:53:20,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:20,029 INFO:     Epoch: 52
2022-12-05 21:53:20,822 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47023238326338207, 'Total loss': 0.47023238326338207} | train loss {'Reaction outcome loss': 0.13682864518904012, 'Total loss': 0.13682864518904012}
2022-12-05 21:53:20,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:20,823 INFO:     Epoch: 53
2022-12-05 21:53:21,621 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48925517533313145, 'Total loss': 0.48925517533313145} | train loss {'Reaction outcome loss': 0.135725293138351, 'Total loss': 0.135725293138351}
2022-12-05 21:53:21,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:21,622 INFO:     Epoch: 54
2022-12-05 21:53:22,418 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4813870719887994, 'Total loss': 0.4813870719887994} | train loss {'Reaction outcome loss': 0.13494350578304123, 'Total loss': 0.13494350578304123}
2022-12-05 21:53:22,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:22,418 INFO:     Epoch: 55
2022-12-05 21:53:23,217 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4699613939632069, 'Total loss': 0.4699613939632069} | train loss {'Reaction outcome loss': 0.13352900053476274, 'Total loss': 0.13352900053476274}
2022-12-05 21:53:23,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:23,217 INFO:     Epoch: 56
2022-12-05 21:53:24,012 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46219310266050423, 'Total loss': 0.46219310266050423} | train loss {'Reaction outcome loss': 0.13729664952558304, 'Total loss': 0.13729664952558304}
2022-12-05 21:53:24,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:24,012 INFO:     Epoch: 57
2022-12-05 21:53:24,810 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47797986594113434, 'Total loss': 0.47797986594113434} | train loss {'Reaction outcome loss': 0.13371878052846745, 'Total loss': 0.13371878052846745}
2022-12-05 21:53:24,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:24,810 INFO:     Epoch: 58
2022-12-05 21:53:25,606 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.466635965149511, 'Total loss': 0.466635965149511} | train loss {'Reaction outcome loss': 0.1324150286735552, 'Total loss': 0.1324150286735552}
2022-12-05 21:53:25,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:25,606 INFO:     Epoch: 59
2022-12-05 21:53:26,399 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4760489599271254, 'Total loss': 0.4760489599271254} | train loss {'Reaction outcome loss': 0.13250042579932372, 'Total loss': 0.13250042579932372}
2022-12-05 21:53:26,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:26,399 INFO:     Epoch: 60
2022-12-05 21:53:27,196 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4767281954938715, 'Total loss': 0.4767281954938715} | train loss {'Reaction outcome loss': 0.13138768745789886, 'Total loss': 0.13138768745789886}
2022-12-05 21:53:27,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:27,196 INFO:     Epoch: 61
2022-12-05 21:53:27,996 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4673051393844865, 'Total loss': 0.4673051393844865} | train loss {'Reaction outcome loss': 0.12951050280510384, 'Total loss': 0.12951050280510384}
2022-12-05 21:53:27,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:27,997 INFO:     Epoch: 62
2022-12-05 21:53:28,792 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47224682332439855, 'Total loss': 0.47224682332439855} | train loss {'Reaction outcome loss': 0.1279709503914301, 'Total loss': 0.1279709503914301}
2022-12-05 21:53:28,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:28,793 INFO:     Epoch: 63
2022-12-05 21:53:29,586 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4617610424757004, 'Total loss': 0.4617610424757004} | train loss {'Reaction outcome loss': 0.12827342756560095, 'Total loss': 0.12827342756560095}
2022-12-05 21:53:29,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:29,586 INFO:     Epoch: 64
2022-12-05 21:53:30,383 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5017505450682207, 'Total loss': 0.5017505450682207} | train loss {'Reaction outcome loss': 0.12757980045843642, 'Total loss': 0.12757980045843642}
2022-12-05 21:53:30,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:30,383 INFO:     Epoch: 65
2022-12-05 21:53:31,181 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4923599748448892, 'Total loss': 0.4923599748448892} | train loss {'Reaction outcome loss': 0.13092052340055044, 'Total loss': 0.13092052340055044}
2022-12-05 21:53:31,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:31,181 INFO:     Epoch: 66
2022-12-05 21:53:31,976 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4718504991721023, 'Total loss': 0.4718504991721023} | train loss {'Reaction outcome loss': 0.1338062433126243, 'Total loss': 0.1338062433126243}
2022-12-05 21:53:31,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:31,977 INFO:     Epoch: 67
2022-12-05 21:53:32,776 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4957500051029704, 'Total loss': 0.4957500051029704} | train loss {'Reaction outcome loss': 0.12779642463575008, 'Total loss': 0.12779642463575008}
2022-12-05 21:53:32,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:32,776 INFO:     Epoch: 68
2022-12-05 21:53:33,571 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4682927243411541, 'Total loss': 0.4682927243411541} | train loss {'Reaction outcome loss': 0.12569048545070685, 'Total loss': 0.12569048545070685}
2022-12-05 21:53:33,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:33,571 INFO:     Epoch: 69
2022-12-05 21:53:34,364 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4855842651291327, 'Total loss': 0.4855842651291327} | train loss {'Reaction outcome loss': 0.127567288424322, 'Total loss': 0.127567288424322}
2022-12-05 21:53:34,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:34,364 INFO:     Epoch: 70
2022-12-05 21:53:35,157 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48256472464312206, 'Total loss': 0.48256472464312206} | train loss {'Reaction outcome loss': 0.12817911369733603, 'Total loss': 0.12817911369733603}
2022-12-05 21:53:35,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:35,158 INFO:     Epoch: 71
2022-12-05 21:53:35,951 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47860228371891106, 'Total loss': 0.47860228371891106} | train loss {'Reaction outcome loss': 0.12219942030770259, 'Total loss': 0.12219942030770259}
2022-12-05 21:53:35,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:35,952 INFO:     Epoch: 72
2022-12-05 21:53:36,744 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4806226192211563, 'Total loss': 0.4806226192211563} | train loss {'Reaction outcome loss': 0.11956491800183468, 'Total loss': 0.11956491800183468}
2022-12-05 21:53:36,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:36,745 INFO:     Epoch: 73
2022-12-05 21:53:37,540 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48412094671617856, 'Total loss': 0.48412094671617856} | train loss {'Reaction outcome loss': 0.11792789799677819, 'Total loss': 0.11792789799677819}
2022-12-05 21:53:37,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:37,540 INFO:     Epoch: 74
2022-12-05 21:53:38,340 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48630882562561467, 'Total loss': 0.48630882562561467} | train loss {'Reaction outcome loss': 0.12150915879152926, 'Total loss': 0.12150915879152926}
2022-12-05 21:53:38,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:38,341 INFO:     Epoch: 75
2022-12-05 21:53:39,140 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.488494600084695, 'Total loss': 0.488494600084695} | train loss {'Reaction outcome loss': 0.12156800168230827, 'Total loss': 0.12156800168230827}
2022-12-05 21:53:39,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:39,141 INFO:     Epoch: 76
2022-12-05 21:53:39,936 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4743603996255181, 'Total loss': 0.4743603996255181} | train loss {'Reaction outcome loss': 0.11959514650799002, 'Total loss': 0.11959514650799002}
2022-12-05 21:53:39,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:39,936 INFO:     Epoch: 77
2022-12-05 21:53:40,730 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47981675240126526, 'Total loss': 0.47981675240126526} | train loss {'Reaction outcome loss': 0.12216838132514644, 'Total loss': 0.12216838132514644}
2022-12-05 21:53:40,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:40,731 INFO:     Epoch: 78
2022-12-05 21:53:41,527 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4776568880135363, 'Total loss': 0.4776568880135363} | train loss {'Reaction outcome loss': 0.1239225153551109, 'Total loss': 0.1239225153551109}
2022-12-05 21:53:41,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:41,527 INFO:     Epoch: 79
2022-12-05 21:53:42,329 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4831402569331906, 'Total loss': 0.4831402569331906} | train loss {'Reaction outcome loss': 0.11957320929900837, 'Total loss': 0.11957320929900837}
2022-12-05 21:53:42,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:42,330 INFO:     Epoch: 80
2022-12-05 21:53:43,129 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.475811082361774, 'Total loss': 0.475811082361774} | train loss {'Reaction outcome loss': 0.12578991929499003, 'Total loss': 0.12578991929499003}
2022-12-05 21:53:43,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:43,129 INFO:     Epoch: 81
2022-12-05 21:53:43,923 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4750169566409154, 'Total loss': 0.4750169566409154} | train loss {'Reaction outcome loss': 0.12119839337809003, 'Total loss': 0.12119839337809003}
2022-12-05 21:53:43,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:43,923 INFO:     Epoch: 82
2022-12-05 21:53:44,716 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.48845879293300887, 'Total loss': 0.48845879293300887} | train loss {'Reaction outcome loss': 0.11773271670542386, 'Total loss': 0.11773271670542386}
2022-12-05 21:53:44,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:44,716 INFO:     Epoch: 83
2022-12-05 21:53:45,510 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49141333252191544, 'Total loss': 0.49141333252191544} | train loss {'Reaction outcome loss': 0.12020350369786927, 'Total loss': 0.12020350369786927}
2022-12-05 21:53:45,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:45,510 INFO:     Epoch: 84
2022-12-05 21:53:46,313 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4877731623974713, 'Total loss': 0.4877731623974713} | train loss {'Reaction outcome loss': 0.11566265935817288, 'Total loss': 0.11566265935817288}
2022-12-05 21:53:46,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:46,314 INFO:     Epoch: 85
2022-12-05 21:53:47,107 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4806701855903322, 'Total loss': 0.4806701855903322} | train loss {'Reaction outcome loss': 0.1149981258237199, 'Total loss': 0.1149981258237199}
2022-12-05 21:53:47,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:47,108 INFO:     Epoch: 86
2022-12-05 21:53:47,902 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.48158461160280486, 'Total loss': 0.48158461160280486} | train loss {'Reaction outcome loss': 0.11463389011016983, 'Total loss': 0.11463389011016983}
2022-12-05 21:53:47,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:47,902 INFO:     Epoch: 87
2022-12-05 21:53:48,694 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4832824549891732, 'Total loss': 0.4832824549891732} | train loss {'Reaction outcome loss': 0.11535079046887786, 'Total loss': 0.11535079046887786}
2022-12-05 21:53:48,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:48,695 INFO:     Epoch: 88
2022-12-05 21:53:49,492 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49912548302249476, 'Total loss': 0.49912548302249476} | train loss {'Reaction outcome loss': 0.11456933189635939, 'Total loss': 0.11456933189635939}
2022-12-05 21:53:49,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:49,492 INFO:     Epoch: 89
2022-12-05 21:53:50,287 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4788902500136332, 'Total loss': 0.4788902500136332} | train loss {'Reaction outcome loss': 0.11362109635296741, 'Total loss': 0.11362109635296741}
2022-12-05 21:53:50,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:50,287 INFO:     Epoch: 90
2022-12-05 21:53:51,079 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4824028391052376, 'Total loss': 0.4824028391052376} | train loss {'Reaction outcome loss': 0.11327424903894183, 'Total loss': 0.11327424903894183}
2022-12-05 21:53:51,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:51,079 INFO:     Epoch: 91
2022-12-05 21:53:51,871 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4762856255878102, 'Total loss': 0.4762856255878102} | train loss {'Reaction outcome loss': 0.12197102530885805, 'Total loss': 0.12197102530885805}
2022-12-05 21:53:51,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:51,871 INFO:     Epoch: 92
2022-12-05 21:53:52,665 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47508401508358394, 'Total loss': 0.47508401508358394} | train loss {'Reaction outcome loss': 0.12296465447979417, 'Total loss': 0.12296465447979417}
2022-12-05 21:53:52,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:52,665 INFO:     Epoch: 93
2022-12-05 21:53:53,462 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4734347543933175, 'Total loss': 0.4734347543933175} | train loss {'Reaction outcome loss': 0.11254863374629001, 'Total loss': 0.11254863374629001}
2022-12-05 21:53:53,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:53,462 INFO:     Epoch: 94
2022-12-05 21:53:54,255 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48857062513178046, 'Total loss': 0.48857062513178046} | train loss {'Reaction outcome loss': 0.11160611740298389, 'Total loss': 0.11160611740298389}
2022-12-05 21:53:54,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:54,255 INFO:     Epoch: 95
2022-12-05 21:53:55,052 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47148504717783496, 'Total loss': 0.47148504717783496} | train loss {'Reaction outcome loss': 0.11048055237332578, 'Total loss': 0.11048055237332578}
2022-12-05 21:53:55,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:55,052 INFO:     Epoch: 96
2022-12-05 21:53:55,846 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47822325490415096, 'Total loss': 0.47822325490415096} | train loss {'Reaction outcome loss': 0.11169869556781734, 'Total loss': 0.11169869556781734}
2022-12-05 21:53:55,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:55,846 INFO:     Epoch: 97
2022-12-05 21:53:56,646 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47573149102655327, 'Total loss': 0.47573149102655327} | train loss {'Reaction outcome loss': 0.11339525347160787, 'Total loss': 0.11339525347160787}
2022-12-05 21:53:56,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:56,646 INFO:     Epoch: 98
2022-12-05 21:53:57,446 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4717824205078862, 'Total loss': 0.4717824205078862} | train loss {'Reaction outcome loss': 0.11062983217600145, 'Total loss': 0.11062983217600145}
2022-12-05 21:53:57,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:57,446 INFO:     Epoch: 99
2022-12-05 21:53:58,248 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4866302457045425, 'Total loss': 0.4866302457045425} | train loss {'Reaction outcome loss': 0.1097105546945872, 'Total loss': 0.1097105546945872}
2022-12-05 21:53:58,248 INFO:     Best model found after epoch 23 of 100.
2022-12-05 21:53:58,248 INFO:   Done with stage: TRAINING
2022-12-05 21:53:58,248 INFO:   Starting stage: EVALUATION
2022-12-05 21:53:58,375 INFO:   Done with stage: EVALUATION
2022-12-05 21:53:58,375 INFO:   Leaving out SEQ value Fold_5
2022-12-05 21:53:58,387 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:53:58,388 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:53:59,027 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:53:59,027 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:53:59,096 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:53:59,096 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:53:59,096 INFO:     No hyperparam tuning for this model
2022-12-05 21:53:59,096 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:53:59,096 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:53:59,097 INFO:     None feature selector for col prot
2022-12-05 21:53:59,097 INFO:     None feature selector for col prot
2022-12-05 21:53:59,097 INFO:     None feature selector for col prot
2022-12-05 21:53:59,098 INFO:     None feature selector for col chem
2022-12-05 21:53:59,098 INFO:     None feature selector for col chem
2022-12-05 21:53:59,098 INFO:     None feature selector for col chem
2022-12-05 21:53:59,098 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:53:59,098 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:53:59,100 INFO:     Number of params in model 215821
2022-12-05 21:53:59,103 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:53:59,103 INFO:   Starting stage: TRAINING
2022-12-05 21:53:59,163 INFO:     Val loss before train {'Reaction outcome loss': 1.0017985586415639, 'Total loss': 1.0017985586415639}
2022-12-05 21:53:59,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:59,164 INFO:     Epoch: 0
2022-12-05 21:53:59,954 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5936518162488937, 'Total loss': 0.5936518162488937} | train loss {'Reaction outcome loss': 0.7850254514077415, 'Total loss': 0.7850254514077415}
2022-12-05 21:53:59,954 INFO:     Found new best model at epoch 0
2022-12-05 21:53:59,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:53:59,955 INFO:     Epoch: 1
2022-12-05 21:54:00,749 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5130898735739968, 'Total loss': 0.5130898735739968} | train loss {'Reaction outcome loss': 0.5432248108300121, 'Total loss': 0.5432248108300121}
2022-12-05 21:54:00,749 INFO:     Found new best model at epoch 1
2022-12-05 21:54:00,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:00,750 INFO:     Epoch: 2
2022-12-05 21:54:01,543 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4889976592226462, 'Total loss': 0.4889976592226462} | train loss {'Reaction outcome loss': 0.46910121406500155, 'Total loss': 0.46910121406500155}
2022-12-05 21:54:01,543 INFO:     Found new best model at epoch 2
2022-12-05 21:54:01,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:01,544 INFO:     Epoch: 3
2022-12-05 21:54:02,335 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46234465864571656, 'Total loss': 0.46234465864571656} | train loss {'Reaction outcome loss': 0.4273178593485582, 'Total loss': 0.4273178593485582}
2022-12-05 21:54:02,335 INFO:     Found new best model at epoch 3
2022-12-05 21:54:02,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:02,336 INFO:     Epoch: 4
2022-12-05 21:54:03,126 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4398063536394726, 'Total loss': 0.4398063536394726} | train loss {'Reaction outcome loss': 0.3969733274809503, 'Total loss': 0.3969733274809503}
2022-12-05 21:54:03,126 INFO:     Found new best model at epoch 4
2022-12-05 21:54:03,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:03,127 INFO:     Epoch: 5
2022-12-05 21:54:03,917 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4431303140114654, 'Total loss': 0.4431303140114654} | train loss {'Reaction outcome loss': 0.3737144679253401, 'Total loss': 0.3737144679253401}
2022-12-05 21:54:03,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:03,917 INFO:     Epoch: 6
2022-12-05 21:54:04,709 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42490645802833815, 'Total loss': 0.42490645802833815} | train loss {'Reaction outcome loss': 0.35228841402662187, 'Total loss': 0.35228841402662187}
2022-12-05 21:54:04,709 INFO:     Found new best model at epoch 6
2022-12-05 21:54:04,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:04,710 INFO:     Epoch: 7
2022-12-05 21:54:05,500 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4260219745337963, 'Total loss': 0.4260219745337963} | train loss {'Reaction outcome loss': 0.3352645653628024, 'Total loss': 0.3352645653628024}
2022-12-05 21:54:05,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:05,500 INFO:     Epoch: 8
2022-12-05 21:54:06,291 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4163538877936927, 'Total loss': 0.4163538877936927} | train loss {'Reaction outcome loss': 0.32140032648436934, 'Total loss': 0.32140032648436934}
2022-12-05 21:54:06,291 INFO:     Found new best model at epoch 8
2022-12-05 21:54:06,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:06,292 INFO:     Epoch: 9
2022-12-05 21:54:07,087 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4109981036321683, 'Total loss': 0.4109981036321683} | train loss {'Reaction outcome loss': 0.30616883656032656, 'Total loss': 0.30616883656032656}
2022-12-05 21:54:07,087 INFO:     Found new best model at epoch 9
2022-12-05 21:54:07,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:07,088 INFO:     Epoch: 10
2022-12-05 21:54:07,882 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4067009518092329, 'Total loss': 0.4067009518092329} | train loss {'Reaction outcome loss': 0.2982947038795784, 'Total loss': 0.2982947038795784}
2022-12-05 21:54:07,882 INFO:     Found new best model at epoch 10
2022-12-05 21:54:07,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:07,883 INFO:     Epoch: 11
2022-12-05 21:54:08,673 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42130600728771905, 'Total loss': 0.42130600728771905} | train loss {'Reaction outcome loss': 0.2860498445538374, 'Total loss': 0.2860498445538374}
2022-12-05 21:54:08,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:08,673 INFO:     Epoch: 12
2022-12-05 21:54:09,463 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40182677520947024, 'Total loss': 0.40182677520947024} | train loss {'Reaction outcome loss': 0.2714534453493411, 'Total loss': 0.2714534453493411}
2022-12-05 21:54:09,463 INFO:     Found new best model at epoch 12
2022-12-05 21:54:09,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:09,464 INFO:     Epoch: 13
2022-12-05 21:54:10,254 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40768529881130566, 'Total loss': 0.40768529881130566} | train loss {'Reaction outcome loss': 0.2618645156624346, 'Total loss': 0.2618645156624346}
2022-12-05 21:54:10,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:10,255 INFO:     Epoch: 14
2022-12-05 21:54:11,045 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41695868223905563, 'Total loss': 0.41695868223905563} | train loss {'Reaction outcome loss': 0.25202733712263314, 'Total loss': 0.25202733712263314}
2022-12-05 21:54:11,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:11,045 INFO:     Epoch: 15
2022-12-05 21:54:11,836 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4209202944555066, 'Total loss': 0.4209202944555066} | train loss {'Reaction outcome loss': 0.24560187808294529, 'Total loss': 0.24560187808294529}
2022-12-05 21:54:11,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:11,837 INFO:     Epoch: 16
2022-12-05 21:54:12,637 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4114893822168762, 'Total loss': 0.4114893822168762} | train loss {'Reaction outcome loss': 0.23928184605199798, 'Total loss': 0.23928184605199798}
2022-12-05 21:54:12,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:12,637 INFO:     Epoch: 17
2022-12-05 21:54:13,434 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40847492895343085, 'Total loss': 0.40847492895343085} | train loss {'Reaction outcome loss': 0.23336449855191987, 'Total loss': 0.23336449855191987}
2022-12-05 21:54:13,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:13,435 INFO:     Epoch: 18
2022-12-05 21:54:14,234 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41503520987250586, 'Total loss': 0.41503520987250586} | train loss {'Reaction outcome loss': 0.2259285102639845, 'Total loss': 0.2259285102639845}
2022-12-05 21:54:14,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:14,234 INFO:     Epoch: 19
2022-12-05 21:54:15,034 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.411788902499459, 'Total loss': 0.411788902499459} | train loss {'Reaction outcome loss': 0.216547728780099, 'Total loss': 0.216547728780099}
2022-12-05 21:54:15,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:15,034 INFO:     Epoch: 20
2022-12-05 21:54:15,832 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4155908817933364, 'Total loss': 0.4155908817933364} | train loss {'Reaction outcome loss': 0.2130898601914707, 'Total loss': 0.2130898601914707}
2022-12-05 21:54:15,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:15,832 INFO:     Epoch: 21
2022-12-05 21:54:16,638 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43355023352937266, 'Total loss': 0.43355023352937266} | train loss {'Reaction outcome loss': 0.20959539869837915, 'Total loss': 0.20959539869837915}
2022-12-05 21:54:16,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:16,639 INFO:     Epoch: 22
2022-12-05 21:54:17,437 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42309883575547824, 'Total loss': 0.42309883575547824} | train loss {'Reaction outcome loss': 0.2013636944355511, 'Total loss': 0.2013636944355511}
2022-12-05 21:54:17,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:17,437 INFO:     Epoch: 23
2022-12-05 21:54:18,240 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4121931273151528, 'Total loss': 0.4121931273151528} | train loss {'Reaction outcome loss': 0.19588530803596985, 'Total loss': 0.19588530803596985}
2022-12-05 21:54:18,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:18,241 INFO:     Epoch: 24
2022-12-05 21:54:19,039 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44303557954051276, 'Total loss': 0.44303557954051276} | train loss {'Reaction outcome loss': 0.19055257575503487, 'Total loss': 0.19055257575503487}
2022-12-05 21:54:19,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:19,039 INFO:     Epoch: 25
2022-12-05 21:54:19,838 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43033131008798425, 'Total loss': 0.43033131008798425} | train loss {'Reaction outcome loss': 0.19276707564378798, 'Total loss': 0.19276707564378798}
2022-12-05 21:54:19,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:19,838 INFO:     Epoch: 26
2022-12-05 21:54:20,642 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43211858855052426, 'Total loss': 0.43211858855052426} | train loss {'Reaction outcome loss': 0.1873084283641234, 'Total loss': 0.1873084283641234}
2022-12-05 21:54:20,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:20,642 INFO:     Epoch: 27
2022-12-05 21:54:21,449 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43040304529395973, 'Total loss': 0.43040304529395973} | train loss {'Reaction outcome loss': 0.18286302834296758, 'Total loss': 0.18286302834296758}
2022-12-05 21:54:21,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:21,449 INFO:     Epoch: 28
2022-12-05 21:54:22,244 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4367074389010668, 'Total loss': 0.4367074389010668} | train loss {'Reaction outcome loss': 0.18639136523551303, 'Total loss': 0.18639136523551303}
2022-12-05 21:54:22,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:22,244 INFO:     Epoch: 29
2022-12-05 21:54:23,041 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42976477335799823, 'Total loss': 0.42976477335799823} | train loss {'Reaction outcome loss': 0.1797034801992584, 'Total loss': 0.1797034801992584}
2022-12-05 21:54:23,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:23,041 INFO:     Epoch: 30
2022-12-05 21:54:23,838 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44187280688096175, 'Total loss': 0.44187280688096175} | train loss {'Reaction outcome loss': 0.1732502391162189, 'Total loss': 0.1732502391162189}
2022-12-05 21:54:23,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:23,838 INFO:     Epoch: 31
2022-12-05 21:54:24,632 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.448941921307282, 'Total loss': 0.448941921307282} | train loss {'Reaction outcome loss': 0.17032884111107602, 'Total loss': 0.17032884111107602}
2022-12-05 21:54:24,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:24,633 INFO:     Epoch: 32
2022-12-05 21:54:25,430 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4349162903699008, 'Total loss': 0.4349162903699008} | train loss {'Reaction outcome loss': 0.16946884392956763, 'Total loss': 0.16946884392956763}
2022-12-05 21:54:25,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:25,430 INFO:     Epoch: 33
2022-12-05 21:54:26,229 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4419668462042781, 'Total loss': 0.4419668462042781} | train loss {'Reaction outcome loss': 0.16848201856680728, 'Total loss': 0.16848201856680728}
2022-12-05 21:54:26,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:26,229 INFO:     Epoch: 34
2022-12-05 21:54:27,029 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43542319849472155, 'Total loss': 0.43542319849472155} | train loss {'Reaction outcome loss': 0.16814463464203874, 'Total loss': 0.16814463464203874}
2022-12-05 21:54:27,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:27,029 INFO:     Epoch: 35
2022-12-05 21:54:27,829 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4560126117007299, 'Total loss': 0.4560126117007299} | train loss {'Reaction outcome loss': 0.16659002659864997, 'Total loss': 0.16659002659864997}
2022-12-05 21:54:27,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:27,829 INFO:     Epoch: 36
2022-12-05 21:54:28,630 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4369772103699771, 'Total loss': 0.4369772103699771} | train loss {'Reaction outcome loss': 0.1626598832804544, 'Total loss': 0.1626598832804544}
2022-12-05 21:54:28,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:28,630 INFO:     Epoch: 37
2022-12-05 21:54:29,431 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.455172369425947, 'Total loss': 0.455172369425947} | train loss {'Reaction outcome loss': 0.1650710165621298, 'Total loss': 0.1650710165621298}
2022-12-05 21:54:29,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:29,431 INFO:     Epoch: 38
2022-12-05 21:54:30,228 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4443920576436953, 'Total loss': 0.4443920576436953} | train loss {'Reaction outcome loss': 0.15992035880413374, 'Total loss': 0.15992035880413374}
2022-12-05 21:54:30,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:30,229 INFO:     Epoch: 39
2022-12-05 21:54:31,027 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4525011835450476, 'Total loss': 0.4525011835450476} | train loss {'Reaction outcome loss': 0.15326538519850869, 'Total loss': 0.15326538519850869}
2022-12-05 21:54:31,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:31,027 INFO:     Epoch: 40
2022-12-05 21:54:31,830 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4417895987968553, 'Total loss': 0.4417895987968553} | train loss {'Reaction outcome loss': 0.15637089720802752, 'Total loss': 0.15637089720802752}
2022-12-05 21:54:31,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:31,830 INFO:     Epoch: 41
2022-12-05 21:54:32,634 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45381134765392, 'Total loss': 0.45381134765392} | train loss {'Reaction outcome loss': 0.1554139519264914, 'Total loss': 0.1554139519264914}
2022-12-05 21:54:32,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:32,634 INFO:     Epoch: 42
2022-12-05 21:54:33,434 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44027834419499745, 'Total loss': 0.44027834419499745} | train loss {'Reaction outcome loss': 0.15355769532020033, 'Total loss': 0.15355769532020033}
2022-12-05 21:54:33,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:33,434 INFO:     Epoch: 43
2022-12-05 21:54:34,236 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4449339559809728, 'Total loss': 0.4449339559809728} | train loss {'Reaction outcome loss': 0.1563635551283958, 'Total loss': 0.1563635551283958}
2022-12-05 21:54:34,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:34,236 INFO:     Epoch: 44
2022-12-05 21:54:35,038 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4589933715760708, 'Total loss': 0.4589933715760708} | train loss {'Reaction outcome loss': 0.15067758170608808, 'Total loss': 0.15067758170608808}
2022-12-05 21:54:35,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:35,038 INFO:     Epoch: 45
2022-12-05 21:54:35,838 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4694456776434725, 'Total loss': 0.4694456776434725} | train loss {'Reaction outcome loss': 0.14507960215934856, 'Total loss': 0.14507960215934856}
2022-12-05 21:54:35,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:35,838 INFO:     Epoch: 46
2022-12-05 21:54:36,638 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44265907833522017, 'Total loss': 0.44265907833522017} | train loss {'Reaction outcome loss': 0.14475586282670017, 'Total loss': 0.14475586282670017}
2022-12-05 21:54:36,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:36,639 INFO:     Epoch: 47
2022-12-05 21:54:37,443 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4541232538494197, 'Total loss': 0.4541232538494197} | train loss {'Reaction outcome loss': 0.14372933682371006, 'Total loss': 0.14372933682371006}
2022-12-05 21:54:37,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:37,443 INFO:     Epoch: 48
2022-12-05 21:54:38,241 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4760630266232924, 'Total loss': 0.4760630266232924} | train loss {'Reaction outcome loss': 0.14108527239283872, 'Total loss': 0.14108527239283872}
2022-12-05 21:54:38,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:38,241 INFO:     Epoch: 49
2022-12-05 21:54:39,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45604187791997736, 'Total loss': 0.45604187791997736} | train loss {'Reaction outcome loss': 0.14253013481495352, 'Total loss': 0.14253013481495352}
2022-12-05 21:54:39,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:39,039 INFO:     Epoch: 50
2022-12-05 21:54:39,838 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4579676870595325, 'Total loss': 0.4579676870595325} | train loss {'Reaction outcome loss': 0.1401801194301863, 'Total loss': 0.1401801194301863}
2022-12-05 21:54:39,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:39,838 INFO:     Epoch: 51
2022-12-05 21:54:40,642 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4599314525046132, 'Total loss': 0.4599314525046132} | train loss {'Reaction outcome loss': 0.1411637714592672, 'Total loss': 0.1411637714592672}
2022-12-05 21:54:40,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:40,643 INFO:     Epoch: 52
2022-12-05 21:54:41,444 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4504637611521916, 'Total loss': 0.4504637611521916} | train loss {'Reaction outcome loss': 0.1395134312903833, 'Total loss': 0.1395134312903833}
2022-12-05 21:54:41,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:41,444 INFO:     Epoch: 53
2022-12-05 21:54:42,247 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44933551651510323, 'Total loss': 0.44933551651510323} | train loss {'Reaction outcome loss': 0.1415716470501985, 'Total loss': 0.1415716470501985}
2022-12-05 21:54:42,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:42,247 INFO:     Epoch: 54
2022-12-05 21:54:43,053 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4586699019101533, 'Total loss': 0.4586699019101533} | train loss {'Reaction outcome loss': 0.14064862214496382, 'Total loss': 0.14064862214496382}
2022-12-05 21:54:43,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:43,055 INFO:     Epoch: 55
2022-12-05 21:54:43,857 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46359527889977803, 'Total loss': 0.46359527889977803} | train loss {'Reaction outcome loss': 0.13544573109250077, 'Total loss': 0.13544573109250077}
2022-12-05 21:54:43,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:43,857 INFO:     Epoch: 56
2022-12-05 21:54:44,658 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46418544091284275, 'Total loss': 0.46418544091284275} | train loss {'Reaction outcome loss': 0.13499215644169674, 'Total loss': 0.13499215644169674}
2022-12-05 21:54:44,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:44,659 INFO:     Epoch: 57
2022-12-05 21:54:45,458 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47224290431900456, 'Total loss': 0.47224290431900456} | train loss {'Reaction outcome loss': 0.13215809532625955, 'Total loss': 0.13215809532625955}
2022-12-05 21:54:45,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:45,458 INFO:     Epoch: 58
2022-12-05 21:54:46,258 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4651793839240616, 'Total loss': 0.4651793839240616} | train loss {'Reaction outcome loss': 0.13406383028246371, 'Total loss': 0.13406383028246371}
2022-12-05 21:54:46,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:46,258 INFO:     Epoch: 59
2022-12-05 21:54:47,064 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46201385523785243, 'Total loss': 0.46201385523785243} | train loss {'Reaction outcome loss': 0.13654328124439305, 'Total loss': 0.13654328124439305}
2022-12-05 21:54:47,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:47,064 INFO:     Epoch: 60
2022-12-05 21:54:47,863 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4680001871152358, 'Total loss': 0.4680001871152358} | train loss {'Reaction outcome loss': 0.13546815376939922, 'Total loss': 0.13546815376939922}
2022-12-05 21:54:47,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:47,864 INFO:     Epoch: 61
2022-12-05 21:54:48,664 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44771395725282753, 'Total loss': 0.44771395725282753} | train loss {'Reaction outcome loss': 0.13561733653354138, 'Total loss': 0.13561733653354138}
2022-12-05 21:54:48,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:48,664 INFO:     Epoch: 62
2022-12-05 21:54:49,466 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46892166239294136, 'Total loss': 0.46892166239294136} | train loss {'Reaction outcome loss': 0.1313123583476915, 'Total loss': 0.1313123583476915}
2022-12-05 21:54:49,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:49,467 INFO:     Epoch: 63
2022-12-05 21:54:50,269 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4739543968303637, 'Total loss': 0.4739543968303637} | train loss {'Reaction outcome loss': 0.1342543359239763, 'Total loss': 0.1342543359239763}
2022-12-05 21:54:50,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:50,269 INFO:     Epoch: 64
2022-12-05 21:54:51,074 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4660419552502307, 'Total loss': 0.4660419552502307} | train loss {'Reaction outcome loss': 0.12709424458396987, 'Total loss': 0.12709424458396987}
2022-12-05 21:54:51,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:51,074 INFO:     Epoch: 65
2022-12-05 21:54:51,879 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4840033396401189, 'Total loss': 0.4840033396401189} | train loss {'Reaction outcome loss': 0.12749625314856589, 'Total loss': 0.12749625314856589}
2022-12-05 21:54:51,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:51,879 INFO:     Epoch: 66
2022-12-05 21:54:52,681 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48126930269328033, 'Total loss': 0.48126930269328033} | train loss {'Reaction outcome loss': 0.12573873919061562, 'Total loss': 0.12573873919061562}
2022-12-05 21:54:52,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:52,681 INFO:     Epoch: 67
2022-12-05 21:54:53,483 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46531063893979246, 'Total loss': 0.46531063893979246} | train loss {'Reaction outcome loss': 0.12604544882998173, 'Total loss': 0.12604544882998173}
2022-12-05 21:54:53,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:53,483 INFO:     Epoch: 68
2022-12-05 21:54:54,289 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46782608635046263, 'Total loss': 0.46782608635046263} | train loss {'Reaction outcome loss': 0.12649967252966846, 'Total loss': 0.12649967252966846}
2022-12-05 21:54:54,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:54,289 INFO:     Epoch: 69
2022-12-05 21:54:55,093 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4691871106624603, 'Total loss': 0.4691871106624603} | train loss {'Reaction outcome loss': 0.12535024899612313, 'Total loss': 0.12535024899612313}
2022-12-05 21:54:55,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:55,094 INFO:     Epoch: 70
2022-12-05 21:54:55,895 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4718615600669926, 'Total loss': 0.4718615600669926} | train loss {'Reaction outcome loss': 0.12268401425603309, 'Total loss': 0.12268401425603309}
2022-12-05 21:54:55,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:55,896 INFO:     Epoch: 71
2022-12-05 21:54:56,697 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46256308731707657, 'Total loss': 0.46256308731707657} | train loss {'Reaction outcome loss': 0.12438007861918766, 'Total loss': 0.12438007861918766}
2022-12-05 21:54:56,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:56,697 INFO:     Epoch: 72
2022-12-05 21:54:57,498 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48555330220948567, 'Total loss': 0.48555330220948567} | train loss {'Reaction outcome loss': 0.12228118361686525, 'Total loss': 0.12228118361686525}
2022-12-05 21:54:57,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:57,499 INFO:     Epoch: 73
2022-12-05 21:54:58,297 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4636931818994609, 'Total loss': 0.4636931818994609} | train loss {'Reaction outcome loss': 0.12455196853214309, 'Total loss': 0.12455196853214309}
2022-12-05 21:54:58,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:58,297 INFO:     Epoch: 74
2022-12-05 21:54:59,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47924885018305347, 'Total loss': 0.47924885018305347} | train loss {'Reaction outcome loss': 0.12193554297451548, 'Total loss': 0.12193554297451548}
2022-12-05 21:54:59,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:59,099 INFO:     Epoch: 75
2022-12-05 21:54:59,900 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47298860075798904, 'Total loss': 0.47298860075798904} | train loss {'Reaction outcome loss': 0.12910835399303722, 'Total loss': 0.12910835399303722}
2022-12-05 21:54:59,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:54:59,900 INFO:     Epoch: 76
2022-12-05 21:55:00,698 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4822251180356199, 'Total loss': 0.4822251180356199} | train loss {'Reaction outcome loss': 0.11906270740878003, 'Total loss': 0.11906270740878003}
2022-12-05 21:55:00,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:00,698 INFO:     Epoch: 77
2022-12-05 21:55:01,500 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48406326804648747, 'Total loss': 0.48406326804648747} | train loss {'Reaction outcome loss': 0.12095609912648797, 'Total loss': 0.12095609912648797}
2022-12-05 21:55:01,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:01,501 INFO:     Epoch: 78
2022-12-05 21:55:02,300 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4703130505301736, 'Total loss': 0.4703130505301736} | train loss {'Reaction outcome loss': 0.12346030084740536, 'Total loss': 0.12346030084740536}
2022-12-05 21:55:02,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:02,300 INFO:     Epoch: 79
2022-12-05 21:55:03,100 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4657749797810208, 'Total loss': 0.4657749797810208} | train loss {'Reaction outcome loss': 0.12305423651816255, 'Total loss': 0.12305423651816255}
2022-12-05 21:55:03,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:03,100 INFO:     Epoch: 80
2022-12-05 21:55:03,900 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4839867922392758, 'Total loss': 0.4839867922392758} | train loss {'Reaction outcome loss': 0.12018193744560364, 'Total loss': 0.12018193744560364}
2022-12-05 21:55:03,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:03,900 INFO:     Epoch: 81
2022-12-05 21:55:04,700 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4719536074183204, 'Total loss': 0.4719536074183204} | train loss {'Reaction outcome loss': 0.12057831422081745, 'Total loss': 0.12057831422081745}
2022-12-05 21:55:04,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:04,701 INFO:     Epoch: 82
2022-12-05 21:55:05,505 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47777035188945854, 'Total loss': 0.47777035188945854} | train loss {'Reaction outcome loss': 0.11951821469720679, 'Total loss': 0.11951821469720679}
2022-12-05 21:55:05,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:05,506 INFO:     Epoch: 83
2022-12-05 21:55:06,304 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47843982448632066, 'Total loss': 0.47843982448632066} | train loss {'Reaction outcome loss': 0.12074872378923511, 'Total loss': 0.12074872378923511}
2022-12-05 21:55:06,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:06,304 INFO:     Epoch: 84
2022-12-05 21:55:07,105 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.467111641371792, 'Total loss': 0.467111641371792} | train loss {'Reaction outcome loss': 0.12062495946884155, 'Total loss': 0.12062495946884155}
2022-12-05 21:55:07,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:07,105 INFO:     Epoch: 85
2022-12-05 21:55:07,906 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4645525233989412, 'Total loss': 0.4645525233989412} | train loss {'Reaction outcome loss': 0.12274032040698989, 'Total loss': 0.12274032040698989}
2022-12-05 21:55:07,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:07,906 INFO:     Epoch: 86
2022-12-05 21:55:08,712 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4721912419931455, 'Total loss': 0.4721912419931455} | train loss {'Reaction outcome loss': 0.12772814670826502, 'Total loss': 0.12772814670826502}
2022-12-05 21:55:08,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:08,712 INFO:     Epoch: 87
2022-12-05 21:55:09,511 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4681654911149632, 'Total loss': 0.4681654911149632} | train loss {'Reaction outcome loss': 0.12015516580146575, 'Total loss': 0.12015516580146575}
2022-12-05 21:55:09,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:09,511 INFO:     Epoch: 88
2022-12-05 21:55:10,310 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4820514030077241, 'Total loss': 0.4820514030077241} | train loss {'Reaction outcome loss': 0.11519909409904167, 'Total loss': 0.11519909409904167}
2022-12-05 21:55:10,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:10,311 INFO:     Epoch: 89
2022-12-05 21:55:11,117 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4755937736481428, 'Total loss': 0.4755937736481428} | train loss {'Reaction outcome loss': 0.11632761217442601, 'Total loss': 0.11632761217442601}
2022-12-05 21:55:11,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:11,118 INFO:     Epoch: 90
2022-12-05 21:55:11,917 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47547574002634396, 'Total loss': 0.47547574002634396} | train loss {'Reaction outcome loss': 0.11567508174023527, 'Total loss': 0.11567508174023527}
2022-12-05 21:55:11,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:11,917 INFO:     Epoch: 91
2022-12-05 21:55:12,718 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4766078821637414, 'Total loss': 0.4766078821637414} | train loss {'Reaction outcome loss': 0.11447368384110798, 'Total loss': 0.11447368384110798}
2022-12-05 21:55:12,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:12,718 INFO:     Epoch: 92
2022-12-05 21:55:13,518 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48253832723606715, 'Total loss': 0.48253832723606715} | train loss {'Reaction outcome loss': 0.11575889662153234, 'Total loss': 0.11575889662153234}
2022-12-05 21:55:13,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:13,519 INFO:     Epoch: 93
2022-12-05 21:55:14,318 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46514592827721074, 'Total loss': 0.46514592827721074} | train loss {'Reaction outcome loss': 0.11489378282920974, 'Total loss': 0.11489378282920974}
2022-12-05 21:55:14,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:14,318 INFO:     Epoch: 94
2022-12-05 21:55:15,119 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46858284690163354, 'Total loss': 0.46858284690163354} | train loss {'Reaction outcome loss': 0.11257459338648841, 'Total loss': 0.11257459338648841}
2022-12-05 21:55:15,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:15,119 INFO:     Epoch: 95
2022-12-05 21:55:15,919 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47767609053037385, 'Total loss': 0.47767609053037385} | train loss {'Reaction outcome loss': 0.11535609422274205, 'Total loss': 0.11535609422274205}
2022-12-05 21:55:15,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:15,919 INFO:     Epoch: 96
2022-12-05 21:55:16,716 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4668506766584786, 'Total loss': 0.4668506766584786} | train loss {'Reaction outcome loss': 0.12266537380830841, 'Total loss': 0.12266537380830841}
2022-12-05 21:55:16,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:16,716 INFO:     Epoch: 97
2022-12-05 21:55:17,515 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4653450618074699, 'Total loss': 0.4653450618074699} | train loss {'Reaction outcome loss': 0.11823407916148544, 'Total loss': 0.11823407916148544}
2022-12-05 21:55:17,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:17,515 INFO:     Epoch: 98
2022-12-05 21:55:18,318 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5070681663399393, 'Total loss': 0.5070681663399393} | train loss {'Reaction outcome loss': 0.114356405716314, 'Total loss': 0.114356405716314}
2022-12-05 21:55:18,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:18,319 INFO:     Epoch: 99
2022-12-05 21:55:19,118 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48062732172283257, 'Total loss': 0.48062732172283257} | train loss {'Reaction outcome loss': 0.11574456236100858, 'Total loss': 0.11574456236100858}
2022-12-05 21:55:19,118 INFO:     Best model found after epoch 13 of 100.
2022-12-05 21:55:19,119 INFO:   Done with stage: TRAINING
2022-12-05 21:55:19,119 INFO:   Starting stage: EVALUATION
2022-12-05 21:55:19,244 INFO:   Done with stage: EVALUATION
2022-12-05 21:55:19,245 INFO:   Leaving out SEQ value Fold_6
2022-12-05 21:55:19,257 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:55:19,257 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:55:19,905 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:55:19,905 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:55:19,975 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:55:19,975 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:55:19,975 INFO:     No hyperparam tuning for this model
2022-12-05 21:55:19,975 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:55:19,975 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:55:19,976 INFO:     None feature selector for col prot
2022-12-05 21:55:19,976 INFO:     None feature selector for col prot
2022-12-05 21:55:19,976 INFO:     None feature selector for col prot
2022-12-05 21:55:19,976 INFO:     None feature selector for col chem
2022-12-05 21:55:19,977 INFO:     None feature selector for col chem
2022-12-05 21:55:19,977 INFO:     None feature selector for col chem
2022-12-05 21:55:19,977 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:55:19,977 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:55:19,978 INFO:     Number of params in model 215821
2022-12-05 21:55:19,982 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:55:19,982 INFO:   Starting stage: TRAINING
2022-12-05 21:55:20,043 INFO:     Val loss before train {'Reaction outcome loss': 1.0162994658405131, 'Total loss': 1.0162994658405131}
2022-12-05 21:55:20,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:20,043 INFO:     Epoch: 0
2022-12-05 21:55:20,843 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6265332725915042, 'Total loss': 0.6265332725915042} | train loss {'Reaction outcome loss': 0.7978203127220753, 'Total loss': 0.7978203127220753}
2022-12-05 21:55:20,843 INFO:     Found new best model at epoch 0
2022-12-05 21:55:20,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:20,844 INFO:     Epoch: 1
2022-12-05 21:55:21,643 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5438896993344481, 'Total loss': 0.5438896993344481} | train loss {'Reaction outcome loss': 0.553351663293377, 'Total loss': 0.553351663293377}
2022-12-05 21:55:21,643 INFO:     Found new best model at epoch 1
2022-12-05 21:55:21,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:21,644 INFO:     Epoch: 2
2022-12-05 21:55:22,448 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5074619657614015, 'Total loss': 0.5074619657614015} | train loss {'Reaction outcome loss': 0.48462685780419457, 'Total loss': 0.48462685780419457}
2022-12-05 21:55:22,448 INFO:     Found new best model at epoch 2
2022-12-05 21:55:22,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:22,449 INFO:     Epoch: 3
2022-12-05 21:55:23,250 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4748408909548413, 'Total loss': 0.4748408909548413} | train loss {'Reaction outcome loss': 0.4455335157052163, 'Total loss': 0.4455335157052163}
2022-12-05 21:55:23,250 INFO:     Found new best model at epoch 3
2022-12-05 21:55:23,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:23,251 INFO:     Epoch: 4
2022-12-05 21:55:24,052 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46360983699560165, 'Total loss': 0.46360983699560165} | train loss {'Reaction outcome loss': 0.4166735088632953, 'Total loss': 0.4166735088632953}
2022-12-05 21:55:24,053 INFO:     Found new best model at epoch 4
2022-12-05 21:55:24,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:24,053 INFO:     Epoch: 5
2022-12-05 21:55:24,858 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45340885865417396, 'Total loss': 0.45340885865417396} | train loss {'Reaction outcome loss': 0.3922986866485688, 'Total loss': 0.3922986866485688}
2022-12-05 21:55:24,858 INFO:     Found new best model at epoch 5
2022-12-05 21:55:24,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:24,859 INFO:     Epoch: 6
2022-12-05 21:55:25,666 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43681551583788614, 'Total loss': 0.43681551583788614} | train loss {'Reaction outcome loss': 0.37257086269317136, 'Total loss': 0.37257086269317136}
2022-12-05 21:55:25,667 INFO:     Found new best model at epoch 6
2022-12-05 21:55:25,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:25,667 INFO:     Epoch: 7
2022-12-05 21:55:26,473 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42993333224545827, 'Total loss': 0.42993333224545827} | train loss {'Reaction outcome loss': 0.35272497963160276, 'Total loss': 0.35272497963160276}
2022-12-05 21:55:26,473 INFO:     Found new best model at epoch 7
2022-12-05 21:55:26,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:26,474 INFO:     Epoch: 8
2022-12-05 21:55:27,274 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43100855160843243, 'Total loss': 0.43100855160843243} | train loss {'Reaction outcome loss': 0.3397477618268421, 'Total loss': 0.3397477618268421}
2022-12-05 21:55:27,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:27,275 INFO:     Epoch: 9
2022-12-05 21:55:28,086 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4332099563696168, 'Total loss': 0.4332099563696168} | train loss {'Reaction outcome loss': 0.32558302124661787, 'Total loss': 0.32558302124661787}
2022-12-05 21:55:28,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:28,087 INFO:     Epoch: 10
2022-12-05 21:55:28,889 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42833594673059205, 'Total loss': 0.42833594673059205} | train loss {'Reaction outcome loss': 0.3104126495759814, 'Total loss': 0.3104126495759814}
2022-12-05 21:55:28,890 INFO:     Found new best model at epoch 10
2022-12-05 21:55:28,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:28,890 INFO:     Epoch: 11
2022-12-05 21:55:29,692 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41948180103843863, 'Total loss': 0.41948180103843863} | train loss {'Reaction outcome loss': 0.29802792212895807, 'Total loss': 0.29802792212895807}
2022-12-05 21:55:29,693 INFO:     Found new best model at epoch 11
2022-12-05 21:55:29,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:29,693 INFO:     Epoch: 12
2022-12-05 21:55:30,495 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42397885566407983, 'Total loss': 0.42397885566407983} | train loss {'Reaction outcome loss': 0.2870368880009459, 'Total loss': 0.2870368880009459}
2022-12-05 21:55:30,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:30,495 INFO:     Epoch: 13
2022-12-05 21:55:31,300 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4236410217867656, 'Total loss': 0.4236410217867656} | train loss {'Reaction outcome loss': 0.27933688801262646, 'Total loss': 0.27933688801262646}
2022-12-05 21:55:31,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:31,300 INFO:     Epoch: 14
2022-12-05 21:55:32,101 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40937422385269945, 'Total loss': 0.40937422385269945} | train loss {'Reaction outcome loss': 0.2712807776706834, 'Total loss': 0.2712807776706834}
2022-12-05 21:55:32,102 INFO:     Found new best model at epoch 14
2022-12-05 21:55:32,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:32,103 INFO:     Epoch: 15
2022-12-05 21:55:32,906 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.412301086566665, 'Total loss': 0.412301086566665} | train loss {'Reaction outcome loss': 0.26235298274625696, 'Total loss': 0.26235298274625696}
2022-12-05 21:55:32,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:32,907 INFO:     Epoch: 16
2022-12-05 21:55:33,712 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40860709006136114, 'Total loss': 0.40860709006136114} | train loss {'Reaction outcome loss': 0.25314667703764093, 'Total loss': 0.25314667703764093}
2022-12-05 21:55:33,713 INFO:     Found new best model at epoch 16
2022-12-05 21:55:33,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:33,713 INFO:     Epoch: 17
2022-12-05 21:55:34,516 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4367751722986048, 'Total loss': 0.4367751722986048} | train loss {'Reaction outcome loss': 0.2457742989063263, 'Total loss': 0.2457742989063263}
2022-12-05 21:55:34,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:34,517 INFO:     Epoch: 18
2022-12-05 21:55:35,319 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4260348057882352, 'Total loss': 0.4260348057882352} | train loss {'Reaction outcome loss': 0.23914694104103312, 'Total loss': 0.23914694104103312}
2022-12-05 21:55:35,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:35,319 INFO:     Epoch: 19
2022-12-05 21:55:36,130 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4002274748953906, 'Total loss': 0.4002274748953906} | train loss {'Reaction outcome loss': 0.23509896510551054, 'Total loss': 0.23509896510551054}
2022-12-05 21:55:36,130 INFO:     Found new best model at epoch 19
2022-12-05 21:55:36,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:36,131 INFO:     Epoch: 20
2022-12-05 21:55:36,938 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4373663162643259, 'Total loss': 0.4373663162643259} | train loss {'Reaction outcome loss': 0.22954190765026836, 'Total loss': 0.22954190765026836}
2022-12-05 21:55:36,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:36,938 INFO:     Epoch: 21
2022-12-05 21:55:37,740 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.410515166988427, 'Total loss': 0.410515166988427} | train loss {'Reaction outcome loss': 0.22318731916828022, 'Total loss': 0.22318731916828022}
2022-12-05 21:55:37,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:37,741 INFO:     Epoch: 22
2022-12-05 21:55:38,542 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4147139763967557, 'Total loss': 0.4147139763967557} | train loss {'Reaction outcome loss': 0.2217571725468001, 'Total loss': 0.2217571725468001}
2022-12-05 21:55:38,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:38,542 INFO:     Epoch: 23
2022-12-05 21:55:39,343 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41416355256329884, 'Total loss': 0.41416355256329884} | train loss {'Reaction outcome loss': 0.21581003404853324, 'Total loss': 0.21581003404853324}
2022-12-05 21:55:39,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:39,344 INFO:     Epoch: 24
2022-12-05 21:55:40,146 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4209787341004068, 'Total loss': 0.4209787341004068} | train loss {'Reaction outcome loss': 0.21073960544421308, 'Total loss': 0.21073960544421308}
2022-12-05 21:55:40,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:40,146 INFO:     Epoch: 25
2022-12-05 21:55:40,948 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.407330029390075, 'Total loss': 0.407330029390075} | train loss {'Reaction outcome loss': 0.20605886177790741, 'Total loss': 0.20605886177790741}
2022-12-05 21:55:40,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:40,948 INFO:     Epoch: 26
2022-12-05 21:55:41,750 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.408778367056088, 'Total loss': 0.408778367056088} | train loss {'Reaction outcome loss': 0.20452237267407677, 'Total loss': 0.20452237267407677}
2022-12-05 21:55:41,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:41,750 INFO:     Epoch: 27
2022-12-05 21:55:42,555 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4240906968374144, 'Total loss': 0.4240906968374144} | train loss {'Reaction outcome loss': 0.19968886966366442, 'Total loss': 0.19968886966366442}
2022-12-05 21:55:42,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:42,555 INFO:     Epoch: 28
2022-12-05 21:55:43,363 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41313695247200405, 'Total loss': 0.41313695247200405} | train loss {'Reaction outcome loss': 0.1949051963465829, 'Total loss': 0.1949051963465829}
2022-12-05 21:55:43,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:43,363 INFO:     Epoch: 29
2022-12-05 21:55:44,170 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42638463425365364, 'Total loss': 0.42638463425365364} | train loss {'Reaction outcome loss': 0.19404102946000715, 'Total loss': 0.19404102946000715}
2022-12-05 21:55:44,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:44,170 INFO:     Epoch: 30
2022-12-05 21:55:44,974 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4246667626906525, 'Total loss': 0.4246667626906525} | train loss {'Reaction outcome loss': 0.18857413109752438, 'Total loss': 0.18857413109752438}
2022-12-05 21:55:44,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:44,975 INFO:     Epoch: 31
2022-12-05 21:55:45,777 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4121560789644718, 'Total loss': 0.4121560789644718} | train loss {'Reaction outcome loss': 0.1880770738597118, 'Total loss': 0.1880770738597118}
2022-12-05 21:55:45,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:45,777 INFO:     Epoch: 32
2022-12-05 21:55:46,584 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41468253630128776, 'Total loss': 0.41468253630128776} | train loss {'Reaction outcome loss': 0.18444662940718473, 'Total loss': 0.18444662940718473}
2022-12-05 21:55:46,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:46,584 INFO:     Epoch: 33
2022-12-05 21:55:47,390 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42355333776636556, 'Total loss': 0.42355333776636556} | train loss {'Reaction outcome loss': 0.1814807835936306, 'Total loss': 0.1814807835936306}
2022-12-05 21:55:47,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:47,391 INFO:     Epoch: 34
2022-12-05 21:55:48,196 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41872491958466446, 'Total loss': 0.41872491958466446} | train loss {'Reaction outcome loss': 0.18115582507133723, 'Total loss': 0.18115582507133723}
2022-12-05 21:55:48,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:48,196 INFO:     Epoch: 35
2022-12-05 21:55:48,997 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.438298916274851, 'Total loss': 0.438298916274851} | train loss {'Reaction outcome loss': 0.1744711198994229, 'Total loss': 0.1744711198994229}
2022-12-05 21:55:48,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:48,998 INFO:     Epoch: 36
2022-12-05 21:55:49,799 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4231515144082633, 'Total loss': 0.4231515144082633} | train loss {'Reaction outcome loss': 0.17546426564184647, 'Total loss': 0.17546426564184647}
2022-12-05 21:55:49,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:49,800 INFO:     Epoch: 37
2022-12-05 21:55:50,604 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4298231009055268, 'Total loss': 0.4298231009055268} | train loss {'Reaction outcome loss': 0.17140852947599225, 'Total loss': 0.17140852947599225}
2022-12-05 21:55:50,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:50,604 INFO:     Epoch: 38
2022-12-05 21:55:51,411 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4292182319543578, 'Total loss': 0.4292182319543578} | train loss {'Reaction outcome loss': 0.17289430764503777, 'Total loss': 0.17289430764503777}
2022-12-05 21:55:51,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:51,412 INFO:     Epoch: 39
2022-12-05 21:55:52,216 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4299066351218657, 'Total loss': 0.4299066351218657} | train loss {'Reaction outcome loss': 0.17005410758147557, 'Total loss': 0.17005410758147557}
2022-12-05 21:55:52,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:52,216 INFO:     Epoch: 40
2022-12-05 21:55:53,025 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4212678493085233, 'Total loss': 0.4212678493085233} | train loss {'Reaction outcome loss': 0.1655397963289532, 'Total loss': 0.1655397963289532}
2022-12-05 21:55:53,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:53,025 INFO:     Epoch: 41
2022-12-05 21:55:53,831 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44032740728421643, 'Total loss': 0.44032740728421643} | train loss {'Reaction outcome loss': 0.16611328261393693, 'Total loss': 0.16611328261393693}
2022-12-05 21:55:53,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:53,832 INFO:     Epoch: 42
2022-12-05 21:55:54,641 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4498172388835387, 'Total loss': 0.4498172388835387} | train loss {'Reaction outcome loss': 0.1645976854187827, 'Total loss': 0.1645976854187827}
2022-12-05 21:55:54,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:54,641 INFO:     Epoch: 43
2022-12-05 21:55:55,445 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4263556193221699, 'Total loss': 0.4263556193221699} | train loss {'Reaction outcome loss': 0.16407032489716525, 'Total loss': 0.16407032489716525}
2022-12-05 21:55:55,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:55,445 INFO:     Epoch: 44
2022-12-05 21:55:56,250 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43785656649958005, 'Total loss': 0.43785656649958005} | train loss {'Reaction outcome loss': 0.16026412506377505, 'Total loss': 0.16026412506377505}
2022-12-05 21:55:56,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:56,250 INFO:     Epoch: 45
2022-12-05 21:55:57,056 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4382605224170468, 'Total loss': 0.4382605224170468} | train loss {'Reaction outcome loss': 0.1606017859998129, 'Total loss': 0.1606017859998129}
2022-12-05 21:55:57,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:57,056 INFO:     Epoch: 46
2022-12-05 21:55:57,860 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42770430547269905, 'Total loss': 0.42770430547269905} | train loss {'Reaction outcome loss': 0.15813402731662557, 'Total loss': 0.15813402731662557}
2022-12-05 21:55:57,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:57,860 INFO:     Epoch: 47
2022-12-05 21:55:58,670 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43485152315009723, 'Total loss': 0.43485152315009723} | train loss {'Reaction outcome loss': 0.15733702359871277, 'Total loss': 0.15733702359871277}
2022-12-05 21:55:58,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:58,671 INFO:     Epoch: 48
2022-12-05 21:55:59,479 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42645362358201633, 'Total loss': 0.42645362358201633} | train loss {'Reaction outcome loss': 0.15564740571613994, 'Total loss': 0.15564740571613994}
2022-12-05 21:55:59,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:55:59,479 INFO:     Epoch: 49
2022-12-05 21:56:00,283 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44421755454756995, 'Total loss': 0.44421755454756995} | train loss {'Reaction outcome loss': 0.15309665608595335, 'Total loss': 0.15309665608595335}
2022-12-05 21:56:00,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:00,284 INFO:     Epoch: 50
2022-12-05 21:56:01,092 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42715068432417785, 'Total loss': 0.42715068432417785} | train loss {'Reaction outcome loss': 0.15089017257935577, 'Total loss': 0.15089017257935577}
2022-12-05 21:56:01,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:01,093 INFO:     Epoch: 51
2022-12-05 21:56:01,912 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4284220705316825, 'Total loss': 0.4284220705316825} | train loss {'Reaction outcome loss': 0.15323524961187954, 'Total loss': 0.15323524961187954}
2022-12-05 21:56:01,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:01,913 INFO:     Epoch: 52
2022-12-05 21:56:02,731 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4349380418319594, 'Total loss': 0.4349380418319594} | train loss {'Reaction outcome loss': 0.15134189883247018, 'Total loss': 0.15134189883247018}
2022-12-05 21:56:02,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:02,731 INFO:     Epoch: 53
2022-12-05 21:56:03,540 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43600766970352695, 'Total loss': 0.43600766970352695} | train loss {'Reaction outcome loss': 0.1493095502617859, 'Total loss': 0.1493095502617859}
2022-12-05 21:56:03,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:03,541 INFO:     Epoch: 54
2022-12-05 21:56:04,342 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4307834248651158, 'Total loss': 0.4307834248651158} | train loss {'Reaction outcome loss': 0.15229936267790053, 'Total loss': 0.15229936267790053}
2022-12-05 21:56:04,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:04,342 INFO:     Epoch: 55
2022-12-05 21:56:05,142 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43018515137108887, 'Total loss': 0.43018515137108887} | train loss {'Reaction outcome loss': 0.14952077164555028, 'Total loss': 0.14952077164555028}
2022-12-05 21:56:05,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:05,142 INFO:     Epoch: 56
2022-12-05 21:56:05,943 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4347146519205787, 'Total loss': 0.4347146519205787} | train loss {'Reaction outcome loss': 0.1454137597841421, 'Total loss': 0.1454137597841421}
2022-12-05 21:56:05,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:05,943 INFO:     Epoch: 57
2022-12-05 21:56:06,743 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4469155323776332, 'Total loss': 0.4469155323776332} | train loss {'Reaction outcome loss': 0.14410645491068041, 'Total loss': 0.14410645491068041}
2022-12-05 21:56:06,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:06,743 INFO:     Epoch: 58
2022-12-05 21:56:07,545 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44103346494111145, 'Total loss': 0.44103346494111145} | train loss {'Reaction outcome loss': 0.14354062717663305, 'Total loss': 0.14354062717663305}
2022-12-05 21:56:07,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:07,545 INFO:     Epoch: 59
2022-12-05 21:56:08,352 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4333401471376419, 'Total loss': 0.4333401471376419} | train loss {'Reaction outcome loss': 0.1431482974571296, 'Total loss': 0.1431482974571296}
2022-12-05 21:56:08,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:08,352 INFO:     Epoch: 60
2022-12-05 21:56:09,153 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4525694223967465, 'Total loss': 0.4525694223967465} | train loss {'Reaction outcome loss': 0.14243023802391103, 'Total loss': 0.14243023802391103}
2022-12-05 21:56:09,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:09,153 INFO:     Epoch: 61
2022-12-05 21:56:09,953 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4365694292566993, 'Total loss': 0.4365694292566993} | train loss {'Reaction outcome loss': 0.14232856894452725, 'Total loss': 0.14232856894452725}
2022-12-05 21:56:09,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:09,954 INFO:     Epoch: 62
2022-12-05 21:56:10,757 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.428461571986025, 'Total loss': 0.428461571986025} | train loss {'Reaction outcome loss': 0.14048710267149633, 'Total loss': 0.14048710267149633}
2022-12-05 21:56:10,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:10,757 INFO:     Epoch: 63
2022-12-05 21:56:11,561 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4304028349843892, 'Total loss': 0.4304028349843892} | train loss {'Reaction outcome loss': 0.13952344387108762, 'Total loss': 0.13952344387108762}
2022-12-05 21:56:11,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:11,561 INFO:     Epoch: 64
2022-12-05 21:56:12,369 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43038519539616327, 'Total loss': 0.43038519539616327} | train loss {'Reaction outcome loss': 0.1427589215097889, 'Total loss': 0.1427589215097889}
2022-12-05 21:56:12,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:12,370 INFO:     Epoch: 65
2022-12-05 21:56:13,173 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4306144412945617, 'Total loss': 0.4306144412945617} | train loss {'Reaction outcome loss': 0.14218165356320359, 'Total loss': 0.14218165356320359}
2022-12-05 21:56:13,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:13,174 INFO:     Epoch: 66
2022-12-05 21:56:13,977 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4393447817049243, 'Total loss': 0.4393447817049243} | train loss {'Reaction outcome loss': 0.1398041326357352, 'Total loss': 0.1398041326357352}
2022-12-05 21:56:13,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:13,977 INFO:     Epoch: 67
2022-12-05 21:56:14,778 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4353720430623401, 'Total loss': 0.4353720430623401} | train loss {'Reaction outcome loss': 0.13773658794290836, 'Total loss': 0.13773658794290836}
2022-12-05 21:56:14,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:14,778 INFO:     Epoch: 68
2022-12-05 21:56:15,583 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4307041520422155, 'Total loss': 0.4307041520422155} | train loss {'Reaction outcome loss': 0.1366374545895885, 'Total loss': 0.1366374545895885}
2022-12-05 21:56:15,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:15,584 INFO:     Epoch: 69
2022-12-05 21:56:16,388 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43855017152699555, 'Total loss': 0.43855017152699555} | train loss {'Reaction outcome loss': 0.13692065713656765, 'Total loss': 0.13692065713656765}
2022-12-05 21:56:16,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:16,388 INFO:     Epoch: 70
2022-12-05 21:56:17,189 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43650542030280287, 'Total loss': 0.43650542030280287} | train loss {'Reaction outcome loss': 0.13976968084311775, 'Total loss': 0.13976968084311775}
2022-12-05 21:56:17,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:17,189 INFO:     Epoch: 71
2022-12-05 21:56:17,990 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43341919034719467, 'Total loss': 0.43341919034719467} | train loss {'Reaction outcome loss': 0.13548213094773312, 'Total loss': 0.13548213094773312}
2022-12-05 21:56:17,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:17,990 INFO:     Epoch: 72
2022-12-05 21:56:18,795 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4312905144285072, 'Total loss': 0.4312905144285072} | train loss {'Reaction outcome loss': 0.1349170828095427, 'Total loss': 0.1349170828095427}
2022-12-05 21:56:18,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:18,795 INFO:     Epoch: 73
2022-12-05 21:56:19,601 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4454885236918926, 'Total loss': 0.4454885236918926} | train loss {'Reaction outcome loss': 0.13341830342617486, 'Total loss': 0.13341830342617486}
2022-12-05 21:56:19,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:19,602 INFO:     Epoch: 74
2022-12-05 21:56:20,403 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44440486519174144, 'Total loss': 0.44440486519174144} | train loss {'Reaction outcome loss': 0.13391355914439285, 'Total loss': 0.13391355914439285}
2022-12-05 21:56:20,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:20,403 INFO:     Epoch: 75
2022-12-05 21:56:21,209 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4396689659492536, 'Total loss': 0.4396689659492536} | train loss {'Reaction outcome loss': 0.1340744597612009, 'Total loss': 0.1340744597612009}
2022-12-05 21:56:21,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:21,209 INFO:     Epoch: 76
2022-12-05 21:56:22,011 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44328201799230144, 'Total loss': 0.44328201799230144} | train loss {'Reaction outcome loss': 0.13554478354091126, 'Total loss': 0.13554478354091126}
2022-12-05 21:56:22,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:22,012 INFO:     Epoch: 77
2022-12-05 21:56:22,817 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42340904677456076, 'Total loss': 0.42340904677456076} | train loss {'Reaction outcome loss': 0.13404307601177284, 'Total loss': 0.13404307601177284}
2022-12-05 21:56:22,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:22,817 INFO:     Epoch: 78
2022-12-05 21:56:23,617 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4284226091747934, 'Total loss': 0.4284226091747934} | train loss {'Reaction outcome loss': 0.13200544469779538, 'Total loss': 0.13200544469779538}
2022-12-05 21:56:23,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:23,617 INFO:     Epoch: 79
2022-12-05 21:56:24,420 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42766936986961146, 'Total loss': 0.42766936986961146} | train loss {'Reaction outcome loss': 0.12951829095724068, 'Total loss': 0.12951829095724068}
2022-12-05 21:56:24,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:24,421 INFO:     Epoch: 80
2022-12-05 21:56:25,225 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42367637292905286, 'Total loss': 0.42367637292905286} | train loss {'Reaction outcome loss': 0.12953544124930857, 'Total loss': 0.12953544124930857}
2022-12-05 21:56:25,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:25,225 INFO:     Epoch: 81
2022-12-05 21:56:26,030 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4299384883858941, 'Total loss': 0.4299384883858941} | train loss {'Reaction outcome loss': 0.13064725779657882, 'Total loss': 0.13064725779657882}
2022-12-05 21:56:26,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:26,031 INFO:     Epoch: 82
2022-12-05 21:56:26,832 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43178972686556255, 'Total loss': 0.43178972686556255} | train loss {'Reaction outcome loss': 0.12821541262805583, 'Total loss': 0.12821541262805583}
2022-12-05 21:56:26,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:26,832 INFO:     Epoch: 83
2022-12-05 21:56:27,633 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4331015819175677, 'Total loss': 0.4331015819175677} | train loss {'Reaction outcome loss': 0.12886370910752204, 'Total loss': 0.12886370910752204}
2022-12-05 21:56:27,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:27,633 INFO:     Epoch: 84
2022-12-05 21:56:28,433 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4327968484298749, 'Total loss': 0.4327968484298749} | train loss {'Reaction outcome loss': 0.12826767561566685, 'Total loss': 0.12826767561566685}
2022-12-05 21:56:28,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:28,434 INFO:     Epoch: 85
2022-12-05 21:56:29,234 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4315992234782739, 'Total loss': 0.4315992234782739} | train loss {'Reaction outcome loss': 0.1299703949611754, 'Total loss': 0.1299703949611754}
2022-12-05 21:56:29,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:29,234 INFO:     Epoch: 86
2022-12-05 21:56:30,040 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4292844351042401, 'Total loss': 0.4292844351042401} | train loss {'Reaction outcome loss': 0.12736435947308858, 'Total loss': 0.12736435947308858}
2022-12-05 21:56:30,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:30,040 INFO:     Epoch: 87
2022-12-05 21:56:30,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4465169968845492, 'Total loss': 0.4465169968845492} | train loss {'Reaction outcome loss': 0.12694145350777095, 'Total loss': 0.12694145350777095}
2022-12-05 21:56:30,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:30,843 INFO:     Epoch: 88
2022-12-05 21:56:31,643 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42722550373185764, 'Total loss': 0.42722550373185764} | train loss {'Reaction outcome loss': 0.12584761885415402, 'Total loss': 0.12584761885415402}
2022-12-05 21:56:31,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:31,644 INFO:     Epoch: 89
2022-12-05 21:56:32,449 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4404892941767519, 'Total loss': 0.4404892941767519} | train loss {'Reaction outcome loss': 0.12209956886457099, 'Total loss': 0.12209956886457099}
2022-12-05 21:56:32,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:32,449 INFO:     Epoch: 90
2022-12-05 21:56:33,250 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43781164423985913, 'Total loss': 0.43781164423985913} | train loss {'Reaction outcome loss': 0.1264836044095817, 'Total loss': 0.1264836044095817}
2022-12-05 21:56:33,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:33,250 INFO:     Epoch: 91
2022-12-05 21:56:34,053 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4379729653962634, 'Total loss': 0.4379729653962634} | train loss {'Reaction outcome loss': 0.1265332326105225, 'Total loss': 0.1265332326105225}
2022-12-05 21:56:34,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:34,054 INFO:     Epoch: 92
2022-12-05 21:56:34,857 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44804144159636716, 'Total loss': 0.44804144159636716} | train loss {'Reaction outcome loss': 0.12518779785492487, 'Total loss': 0.12518779785492487}
2022-12-05 21:56:34,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:34,857 INFO:     Epoch: 93
2022-12-05 21:56:35,659 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4305384169248017, 'Total loss': 0.4305384169248017} | train loss {'Reaction outcome loss': 0.1253865867395014, 'Total loss': 0.1253865867395014}
2022-12-05 21:56:35,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:35,659 INFO:     Epoch: 94
2022-12-05 21:56:36,459 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44399898702448065, 'Total loss': 0.44399898702448065} | train loss {'Reaction outcome loss': 0.12508590495394123, 'Total loss': 0.12508590495394123}
2022-12-05 21:56:36,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:36,459 INFO:     Epoch: 95
2022-12-05 21:56:37,262 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44060206514867867, 'Total loss': 0.44060206514867867} | train loss {'Reaction outcome loss': 0.12462445083750232, 'Total loss': 0.12462445083750232}
2022-12-05 21:56:37,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:37,263 INFO:     Epoch: 96
2022-12-05 21:56:38,063 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4312882509759881, 'Total loss': 0.4312882509759881} | train loss {'Reaction outcome loss': 0.12275678405327903, 'Total loss': 0.12275678405327903}
2022-12-05 21:56:38,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:38,063 INFO:     Epoch: 97
2022-12-05 21:56:38,864 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4300035305998542, 'Total loss': 0.4300035305998542} | train loss {'Reaction outcome loss': 0.12454463798372496, 'Total loss': 0.12454463798372496}
2022-12-05 21:56:38,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:38,865 INFO:     Epoch: 98
2022-12-05 21:56:39,670 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4239327843216332, 'Total loss': 0.4239327843216332} | train loss {'Reaction outcome loss': 0.12158363034963728, 'Total loss': 0.12158363034963728}
2022-12-05 21:56:39,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:39,670 INFO:     Epoch: 99
2022-12-05 21:56:40,478 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4535406514663588, 'Total loss': 0.4535406514663588} | train loss {'Reaction outcome loss': 0.12188237974600445, 'Total loss': 0.12188237974600445}
2022-12-05 21:56:40,479 INFO:     Best model found after epoch 20 of 100.
2022-12-05 21:56:40,479 INFO:   Done with stage: TRAINING
2022-12-05 21:56:40,479 INFO:   Starting stage: EVALUATION
2022-12-05 21:56:40,599 INFO:   Done with stage: EVALUATION
2022-12-05 21:56:40,599 INFO:   Leaving out SEQ value Fold_7
2022-12-05 21:56:40,612 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 21:56:40,612 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:56:41,260 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:56:41,260 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:56:41,330 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:56:41,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:56:41,330 INFO:     No hyperparam tuning for this model
2022-12-05 21:56:41,330 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:56:41,330 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:56:41,331 INFO:     None feature selector for col prot
2022-12-05 21:56:41,331 INFO:     None feature selector for col prot
2022-12-05 21:56:41,331 INFO:     None feature selector for col prot
2022-12-05 21:56:41,332 INFO:     None feature selector for col chem
2022-12-05 21:56:41,332 INFO:     None feature selector for col chem
2022-12-05 21:56:41,332 INFO:     None feature selector for col chem
2022-12-05 21:56:41,332 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:56:41,332 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:56:41,334 INFO:     Number of params in model 215821
2022-12-05 21:56:41,337 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:56:41,337 INFO:   Starting stage: TRAINING
2022-12-05 21:56:41,398 INFO:     Val loss before train {'Reaction outcome loss': 1.0398894358764996, 'Total loss': 1.0398894358764996}
2022-12-05 21:56:41,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:41,398 INFO:     Epoch: 0
2022-12-05 21:56:42,201 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6834005943753503, 'Total loss': 0.6834005943753503} | train loss {'Reaction outcome loss': 0.7920887834362446, 'Total loss': 0.7920887834362446}
2022-12-05 21:56:42,201 INFO:     Found new best model at epoch 0
2022-12-05 21:56:42,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:42,202 INFO:     Epoch: 1
2022-12-05 21:56:42,999 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.57060914283449, 'Total loss': 0.57060914283449} | train loss {'Reaction outcome loss': 0.5549294938363375, 'Total loss': 0.5549294938363375}
2022-12-05 21:56:42,999 INFO:     Found new best model at epoch 1
2022-12-05 21:56:43,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:43,000 INFO:     Epoch: 2
2022-12-05 21:56:43,801 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5236575867642056, 'Total loss': 0.5236575867642056} | train loss {'Reaction outcome loss': 0.4807429768505596, 'Total loss': 0.4807429768505596}
2022-12-05 21:56:43,801 INFO:     Found new best model at epoch 2
2022-12-05 21:56:43,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:43,802 INFO:     Epoch: 3
2022-12-05 21:56:44,602 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5014261843805964, 'Total loss': 0.5014261843805964} | train loss {'Reaction outcome loss': 0.44024293707503426, 'Total loss': 0.44024293707503426}
2022-12-05 21:56:44,602 INFO:     Found new best model at epoch 3
2022-12-05 21:56:44,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:44,603 INFO:     Epoch: 4
2022-12-05 21:56:45,403 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47168593565848743, 'Total loss': 0.47168593565848743} | train loss {'Reaction outcome loss': 0.40870193761563106, 'Total loss': 0.40870193761563106}
2022-12-05 21:56:45,403 INFO:     Found new best model at epoch 4
2022-12-05 21:56:45,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:45,404 INFO:     Epoch: 5
2022-12-05 21:56:46,203 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4709292711182074, 'Total loss': 0.4709292711182074} | train loss {'Reaction outcome loss': 0.38366603671062377, 'Total loss': 0.38366603671062377}
2022-12-05 21:56:46,203 INFO:     Found new best model at epoch 5
2022-12-05 21:56:46,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:46,204 INFO:     Epoch: 6
2022-12-05 21:56:47,003 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4593958536332304, 'Total loss': 0.4593958536332304} | train loss {'Reaction outcome loss': 0.3621798562066209, 'Total loss': 0.3621798562066209}
2022-12-05 21:56:47,004 INFO:     Found new best model at epoch 6
2022-12-05 21:56:47,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:47,005 INFO:     Epoch: 7
2022-12-05 21:56:47,808 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46338863975622435, 'Total loss': 0.46338863975622435} | train loss {'Reaction outcome loss': 0.3442248218662797, 'Total loss': 0.3442248218662797}
2022-12-05 21:56:47,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:47,808 INFO:     Epoch: 8
2022-12-05 21:56:48,611 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4545151489702138, 'Total loss': 0.4545151489702138} | train loss {'Reaction outcome loss': 0.3288811823172915, 'Total loss': 0.3288811823172915}
2022-12-05 21:56:48,611 INFO:     Found new best model at epoch 8
2022-12-05 21:56:48,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:48,612 INFO:     Epoch: 9
2022-12-05 21:56:49,414 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4467910599302162, 'Total loss': 0.4467910599302162} | train loss {'Reaction outcome loss': 0.31477564975859657, 'Total loss': 0.31477564975859657}
2022-12-05 21:56:49,415 INFO:     Found new best model at epoch 9
2022-12-05 21:56:49,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:49,415 INFO:     Epoch: 10
2022-12-05 21:56:50,224 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44741376861929893, 'Total loss': 0.44741376861929893} | train loss {'Reaction outcome loss': 0.29907954614909904, 'Total loss': 0.29907954614909904}
2022-12-05 21:56:50,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:50,224 INFO:     Epoch: 11
2022-12-05 21:56:51,023 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4487127722664313, 'Total loss': 0.4487127722664313} | train loss {'Reaction outcome loss': 0.28780610937504997, 'Total loss': 0.28780610937504997}
2022-12-05 21:56:51,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:51,023 INFO:     Epoch: 12
2022-12-05 21:56:51,825 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4429733451794494, 'Total loss': 0.4429733451794494} | train loss {'Reaction outcome loss': 0.28254416687113626, 'Total loss': 0.28254416687113626}
2022-12-05 21:56:51,826 INFO:     Found new best model at epoch 12
2022-12-05 21:56:51,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:51,826 INFO:     Epoch: 13
2022-12-05 21:56:52,628 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4609099856831811, 'Total loss': 0.4609099856831811} | train loss {'Reaction outcome loss': 0.266149049820078, 'Total loss': 0.266149049820078}
2022-12-05 21:56:52,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:52,629 INFO:     Epoch: 14
2022-12-05 21:56:53,431 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45048457790504803, 'Total loss': 0.45048457790504803} | train loss {'Reaction outcome loss': 0.2592165654435033, 'Total loss': 0.2592165654435033}
2022-12-05 21:56:53,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:53,432 INFO:     Epoch: 15
2022-12-05 21:56:54,236 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44240793348713353, 'Total loss': 0.44240793348713353} | train loss {'Reaction outcome loss': 0.2509510790057961, 'Total loss': 0.2509510790057961}
2022-12-05 21:56:54,237 INFO:     Found new best model at epoch 15
2022-12-05 21:56:54,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:54,237 INFO:     Epoch: 16
2022-12-05 21:56:55,037 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.453951049934734, 'Total loss': 0.453951049934734} | train loss {'Reaction outcome loss': 0.24342554714530706, 'Total loss': 0.24342554714530706}
2022-12-05 21:56:55,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:55,037 INFO:     Epoch: 17
2022-12-05 21:56:55,843 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4549135152589191, 'Total loss': 0.4549135152589191} | train loss {'Reaction outcome loss': 0.23971013819438317, 'Total loss': 0.23971013819438317}
2022-12-05 21:56:55,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:55,843 INFO:     Epoch: 18
2022-12-05 21:56:56,647 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4481708759611303, 'Total loss': 0.4481708759611303} | train loss {'Reaction outcome loss': 0.23408175004465925, 'Total loss': 0.23408175004465925}
2022-12-05 21:56:56,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:56,648 INFO:     Epoch: 19
2022-12-05 21:56:57,448 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4596974932673303, 'Total loss': 0.4596974932673303} | train loss {'Reaction outcome loss': 0.22774948729502578, 'Total loss': 0.22774948729502578}
2022-12-05 21:56:57,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:57,448 INFO:     Epoch: 20
2022-12-05 21:56:58,251 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4538788416168906, 'Total loss': 0.4538788416168906} | train loss {'Reaction outcome loss': 0.22135499816748402, 'Total loss': 0.22135499816748402}
2022-12-05 21:56:58,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:58,251 INFO:     Epoch: 21
2022-12-05 21:56:59,051 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47008882462978363, 'Total loss': 0.47008882462978363} | train loss {'Reaction outcome loss': 0.2152807792017777, 'Total loss': 0.2152807792017777}
2022-12-05 21:56:59,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:59,051 INFO:     Epoch: 22
2022-12-05 21:56:59,855 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45982678640972485, 'Total loss': 0.45982678640972485} | train loss {'Reaction outcome loss': 0.21265058634021589, 'Total loss': 0.21265058634021589}
2022-12-05 21:56:59,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:56:59,856 INFO:     Epoch: 23
2022-12-05 21:57:00,655 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45991504327817395, 'Total loss': 0.45991504327817395} | train loss {'Reaction outcome loss': 0.20695445862328332, 'Total loss': 0.20695445862328332}
2022-12-05 21:57:00,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:00,655 INFO:     Epoch: 24
2022-12-05 21:57:01,456 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46024039455435495, 'Total loss': 0.46024039455435495} | train loss {'Reaction outcome loss': 0.20367149634647272, 'Total loss': 0.20367149634647272}
2022-12-05 21:57:01,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:01,456 INFO:     Epoch: 25
2022-12-05 21:57:02,257 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.463276572864164, 'Total loss': 0.463276572864164} | train loss {'Reaction outcome loss': 0.19866645481858042, 'Total loss': 0.19866645481858042}
2022-12-05 21:57:02,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:02,258 INFO:     Epoch: 26
2022-12-05 21:57:03,063 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45397098464044655, 'Total loss': 0.45397098464044655} | train loss {'Reaction outcome loss': 0.19616023798082624, 'Total loss': 0.19616023798082624}
2022-12-05 21:57:03,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:03,063 INFO:     Epoch: 27
2022-12-05 21:57:03,873 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46940427070314233, 'Total loss': 0.46940427070314233} | train loss {'Reaction outcome loss': 0.19175524164682195, 'Total loss': 0.19175524164682195}
2022-12-05 21:57:03,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:03,873 INFO:     Epoch: 28
2022-12-05 21:57:04,681 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.474966017360037, 'Total loss': 0.474966017360037} | train loss {'Reaction outcome loss': 0.1891415831182272, 'Total loss': 0.1891415831182272}
2022-12-05 21:57:04,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:04,681 INFO:     Epoch: 29
2022-12-05 21:57:05,482 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46655008146031335, 'Total loss': 0.46655008146031335} | train loss {'Reaction outcome loss': 0.187629297600999, 'Total loss': 0.187629297600999}
2022-12-05 21:57:05,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:05,483 INFO:     Epoch: 30
2022-12-05 21:57:06,285 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4696464514867826, 'Total loss': 0.4696464514867826} | train loss {'Reaction outcome loss': 0.1858280862741653, 'Total loss': 0.1858280862741653}
2022-12-05 21:57:06,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:06,285 INFO:     Epoch: 31
2022-12-05 21:57:07,091 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4801730064844543, 'Total loss': 0.4801730064844543} | train loss {'Reaction outcome loss': 0.18084071472948116, 'Total loss': 0.18084071472948116}
2022-12-05 21:57:07,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:07,091 INFO:     Epoch: 32
2022-12-05 21:57:07,896 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4700690170919353, 'Total loss': 0.4700690170919353} | train loss {'Reaction outcome loss': 0.1795554687719672, 'Total loss': 0.1795554687719672}
2022-12-05 21:57:07,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:07,897 INFO:     Epoch: 33
2022-12-05 21:57:08,701 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47067333961075003, 'Total loss': 0.47067333961075003} | train loss {'Reaction outcome loss': 0.17540262367636447, 'Total loss': 0.17540262367636447}
2022-12-05 21:57:08,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:08,701 INFO:     Epoch: 34
2022-12-05 21:57:09,510 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48538185317407956, 'Total loss': 0.48538185317407956} | train loss {'Reaction outcome loss': 0.17474344108373888, 'Total loss': 0.17474344108373888}
2022-12-05 21:57:09,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:09,510 INFO:     Epoch: 35
2022-12-05 21:57:10,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4712911613962867, 'Total loss': 0.4712911613962867} | train loss {'Reaction outcome loss': 0.17256628967551213, 'Total loss': 0.17256628967551213}
2022-12-05 21:57:10,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:10,322 INFO:     Epoch: 36
2022-12-05 21:57:11,129 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4862297356806018, 'Total loss': 0.4862297356806018} | train loss {'Reaction outcome loss': 0.16939608365177147, 'Total loss': 0.16939608365177147}
2022-12-05 21:57:11,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:11,129 INFO:     Epoch: 37
2022-12-05 21:57:11,932 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4787966355004094, 'Total loss': 0.4787966355004094} | train loss {'Reaction outcome loss': 0.16657969553113705, 'Total loss': 0.16657969553113705}
2022-12-05 21:57:11,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:11,932 INFO:     Epoch: 38
2022-12-05 21:57:12,736 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46990172717381606, 'Total loss': 0.46990172717381606} | train loss {'Reaction outcome loss': 0.16802286110337702, 'Total loss': 0.16802286110337702}
2022-12-05 21:57:12,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:12,736 INFO:     Epoch: 39
2022-12-05 21:57:13,546 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48230910064144566, 'Total loss': 0.48230910064144566} | train loss {'Reaction outcome loss': 0.16560936037961754, 'Total loss': 0.16560936037961754}
2022-12-05 21:57:13,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:13,546 INFO:     Epoch: 40
2022-12-05 21:57:14,356 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4767129668457942, 'Total loss': 0.4767129668457942} | train loss {'Reaction outcome loss': 0.16430569346994162, 'Total loss': 0.16430569346994162}
2022-12-05 21:57:14,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:14,357 INFO:     Epoch: 41
2022-12-05 21:57:15,165 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4890430268238891, 'Total loss': 0.4890430268238891} | train loss {'Reaction outcome loss': 0.16025231255879324, 'Total loss': 0.16025231255879324}
2022-12-05 21:57:15,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:15,166 INFO:     Epoch: 42
2022-12-05 21:57:15,969 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4857676605778662, 'Total loss': 0.4857676605778662} | train loss {'Reaction outcome loss': 0.15902518245932315, 'Total loss': 0.15902518245932315}
2022-12-05 21:57:15,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:15,969 INFO:     Epoch: 43
2022-12-05 21:57:16,770 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4888286478817463, 'Total loss': 0.4888286478817463} | train loss {'Reaction outcome loss': 0.15655995461518965, 'Total loss': 0.15655995461518965}
2022-12-05 21:57:16,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:16,771 INFO:     Epoch: 44
2022-12-05 21:57:17,576 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4858184422958981, 'Total loss': 0.4858184422958981} | train loss {'Reaction outcome loss': 0.15684356665118568, 'Total loss': 0.15684356665118568}
2022-12-05 21:57:17,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:17,576 INFO:     Epoch: 45
2022-12-05 21:57:18,376 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48238688097758725, 'Total loss': 0.48238688097758725} | train loss {'Reaction outcome loss': 0.15738903203107898, 'Total loss': 0.15738903203107898}
2022-12-05 21:57:18,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:18,377 INFO:     Epoch: 46
2022-12-05 21:57:19,178 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.478437014432116, 'Total loss': 0.478437014432116} | train loss {'Reaction outcome loss': 0.1503049355233088, 'Total loss': 0.1503049355233088}
2022-12-05 21:57:19,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:19,179 INFO:     Epoch: 47
2022-12-05 21:57:19,981 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48472384973005816, 'Total loss': 0.48472384973005816} | train loss {'Reaction outcome loss': 0.1511024636772251, 'Total loss': 0.1511024636772251}
2022-12-05 21:57:19,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:19,981 INFO:     Epoch: 48
2022-12-05 21:57:20,780 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48278889127753, 'Total loss': 0.48278889127753} | train loss {'Reaction outcome loss': 0.150978175389971, 'Total loss': 0.150978175389971}
2022-12-05 21:57:20,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:20,780 INFO:     Epoch: 49
2022-12-05 21:57:21,582 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.49817084571854636, 'Total loss': 0.49817084571854636} | train loss {'Reaction outcome loss': 0.150234914257101, 'Total loss': 0.150234914257101}
2022-12-05 21:57:21,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:21,582 INFO:     Epoch: 50
2022-12-05 21:57:22,381 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4897676614875143, 'Total loss': 0.4897676614875143} | train loss {'Reaction outcome loss': 0.14995684248635605, 'Total loss': 0.14995684248635605}
2022-12-05 21:57:22,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:22,381 INFO:     Epoch: 51
2022-12-05 21:57:23,181 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48269903896884486, 'Total loss': 0.48269903896884486} | train loss {'Reaction outcome loss': 0.14827092131599784, 'Total loss': 0.14827092131599784}
2022-12-05 21:57:23,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:23,181 INFO:     Epoch: 52
2022-12-05 21:57:23,981 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4886811819266189, 'Total loss': 0.4886811819266189} | train loss {'Reaction outcome loss': 0.1474342249679349, 'Total loss': 0.1474342249679349}
2022-12-05 21:57:23,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:23,982 INFO:     Epoch: 53
2022-12-05 21:57:24,786 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49446951597929, 'Total loss': 0.49446951597929} | train loss {'Reaction outcome loss': 0.14685583477389189, 'Total loss': 0.14685583477389189}
2022-12-05 21:57:24,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:24,786 INFO:     Epoch: 54
2022-12-05 21:57:25,592 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48257866027680313, 'Total loss': 0.48257866027680313} | train loss {'Reaction outcome loss': 0.14684452866804937, 'Total loss': 0.14684452866804937}
2022-12-05 21:57:25,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:25,593 INFO:     Epoch: 55
2022-12-05 21:57:26,389 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4755346007983793, 'Total loss': 0.4755346007983793} | train loss {'Reaction outcome loss': 0.14281957372722606, 'Total loss': 0.14281957372722606}
2022-12-05 21:57:26,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:26,389 INFO:     Epoch: 56
2022-12-05 21:57:27,186 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4936619578776034, 'Total loss': 0.4936619578776034} | train loss {'Reaction outcome loss': 0.14162214597566955, 'Total loss': 0.14162214597566955}
2022-12-05 21:57:27,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:27,186 INFO:     Epoch: 57
2022-12-05 21:57:27,982 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49501418830318883, 'Total loss': 0.49501418830318883} | train loss {'Reaction outcome loss': 0.14132194009594498, 'Total loss': 0.14132194009594498}
2022-12-05 21:57:27,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:27,982 INFO:     Epoch: 58
2022-12-05 21:57:28,776 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48802484368736093, 'Total loss': 0.48802484368736093} | train loss {'Reaction outcome loss': 0.14294792560770386, 'Total loss': 0.14294792560770386}
2022-12-05 21:57:28,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:28,776 INFO:     Epoch: 59
2022-12-05 21:57:29,571 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49241430244662543, 'Total loss': 0.49241430244662543} | train loss {'Reaction outcome loss': 0.14164221233072422, 'Total loss': 0.14164221233072422}
2022-12-05 21:57:29,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:29,571 INFO:     Epoch: 60
2022-12-05 21:57:30,373 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49869302761825646, 'Total loss': 0.49869302761825646} | train loss {'Reaction outcome loss': 0.14383237050365535, 'Total loss': 0.14383237050365535}
2022-12-05 21:57:30,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:30,373 INFO:     Epoch: 61
2022-12-05 21:57:31,173 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4864154735749418, 'Total loss': 0.4864154735749418} | train loss {'Reaction outcome loss': 0.14078615272357578, 'Total loss': 0.14078615272357578}
2022-12-05 21:57:31,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:31,173 INFO:     Epoch: 62
2022-12-05 21:57:31,970 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.48338526182553987, 'Total loss': 0.48338526182553987} | train loss {'Reaction outcome loss': 0.1379428883458698, 'Total loss': 0.1379428883458698}
2022-12-05 21:57:31,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:31,971 INFO:     Epoch: 63
2022-12-05 21:57:32,767 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.494074709713459, 'Total loss': 0.494074709713459} | train loss {'Reaction outcome loss': 0.13938722070757179, 'Total loss': 0.13938722070757179}
2022-12-05 21:57:32,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:32,767 INFO:     Epoch: 64
2022-12-05 21:57:33,564 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4855468285016038, 'Total loss': 0.4855468285016038} | train loss {'Reaction outcome loss': 0.1378924673490767, 'Total loss': 0.1378924673490767}
2022-12-05 21:57:33,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:33,564 INFO:     Epoch: 65
2022-12-05 21:57:34,359 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.500002726235173, 'Total loss': 0.500002726235173} | train loss {'Reaction outcome loss': 0.13725944096973586, 'Total loss': 0.13725944096973586}
2022-12-05 21:57:34,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:34,359 INFO:     Epoch: 66
2022-12-05 21:57:35,159 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4855847782032056, 'Total loss': 0.4855847782032056} | train loss {'Reaction outcome loss': 0.13494730571795616, 'Total loss': 0.13494730571795616}
2022-12-05 21:57:35,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:35,159 INFO:     Epoch: 67
2022-12-05 21:57:35,955 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4878029498186978, 'Total loss': 0.4878029498186978} | train loss {'Reaction outcome loss': 0.13726819299101348, 'Total loss': 0.13726819299101348}
2022-12-05 21:57:35,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:35,955 INFO:     Epoch: 68
2022-12-05 21:57:36,754 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.479446258734573, 'Total loss': 0.479446258734573} | train loss {'Reaction outcome loss': 0.1339452370678285, 'Total loss': 0.1339452370678285}
2022-12-05 21:57:36,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:36,754 INFO:     Epoch: 69
2022-12-05 21:57:37,549 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48423424041406676, 'Total loss': 0.48423424041406676} | train loss {'Reaction outcome loss': 0.1338163615024138, 'Total loss': 0.1338163615024138}
2022-12-05 21:57:37,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:37,549 INFO:     Epoch: 70
2022-12-05 21:57:38,348 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4895408370278098, 'Total loss': 0.4895408370278098} | train loss {'Reaction outcome loss': 0.13470644053191907, 'Total loss': 0.13470644053191907}
2022-12-05 21:57:38,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:38,349 INFO:     Epoch: 71
2022-12-05 21:57:39,144 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4850816557353193, 'Total loss': 0.4850816557353193} | train loss {'Reaction outcome loss': 0.13189512351903343, 'Total loss': 0.13189512351903343}
2022-12-05 21:57:39,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:39,144 INFO:     Epoch: 72
2022-12-05 21:57:39,939 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4869385097514499, 'Total loss': 0.4869385097514499} | train loss {'Reaction outcome loss': 0.13207832333676878, 'Total loss': 0.13207832333676878}
2022-12-05 21:57:39,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:39,939 INFO:     Epoch: 73
2022-12-05 21:57:40,735 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4838317327878692, 'Total loss': 0.4838317327878692} | train loss {'Reaction outcome loss': 0.1355972680518584, 'Total loss': 0.1355972680518584}
2022-12-05 21:57:40,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:40,736 INFO:     Epoch: 74
2022-12-05 21:57:41,530 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4901964583180167, 'Total loss': 0.4901964583180167} | train loss {'Reaction outcome loss': 0.1321712959775581, 'Total loss': 0.1321712959775581}
2022-12-05 21:57:41,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:41,531 INFO:     Epoch: 75
2022-12-05 21:57:42,327 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48779282651164313, 'Total loss': 0.48779282651164313} | train loss {'Reaction outcome loss': 0.12983233269093739, 'Total loss': 0.12983233269093739}
2022-12-05 21:57:42,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:42,327 INFO:     Epoch: 76
2022-12-05 21:57:43,123 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48010771586136386, 'Total loss': 0.48010771586136386} | train loss {'Reaction outcome loss': 0.13031559015413927, 'Total loss': 0.13031559015413927}
2022-12-05 21:57:43,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:43,123 INFO:     Epoch: 77
2022-12-05 21:57:43,918 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4889324917034669, 'Total loss': 0.4889324917034669} | train loss {'Reaction outcome loss': 0.12803015115505625, 'Total loss': 0.12803015115505625}
2022-12-05 21:57:43,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:43,918 INFO:     Epoch: 78
2022-12-05 21:57:44,717 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46883638558739965, 'Total loss': 0.46883638558739965} | train loss {'Reaction outcome loss': 0.1319457290416223, 'Total loss': 0.1319457290416223}
2022-12-05 21:57:44,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:44,717 INFO:     Epoch: 79
2022-12-05 21:57:45,516 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4857637980444865, 'Total loss': 0.4857637980444865} | train loss {'Reaction outcome loss': 0.1282561493947381, 'Total loss': 0.1282561493947381}
2022-12-05 21:57:45,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:45,516 INFO:     Epoch: 80
2022-12-05 21:57:46,312 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49246788600629027, 'Total loss': 0.49246788600629027} | train loss {'Reaction outcome loss': 0.1300549589833545, 'Total loss': 0.1300549589833545}
2022-12-05 21:57:46,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:46,312 INFO:     Epoch: 81
2022-12-05 21:57:47,109 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4807300256057219, 'Total loss': 0.4807300256057219} | train loss {'Reaction outcome loss': 0.1268259810937208, 'Total loss': 0.1268259810937208}
2022-12-05 21:57:47,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:47,109 INFO:     Epoch: 82
2022-12-05 21:57:47,908 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4884465441785075, 'Total loss': 0.4884465441785075} | train loss {'Reaction outcome loss': 0.1284441345957138, 'Total loss': 0.1284441345957138}
2022-12-05 21:57:47,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:47,908 INFO:     Epoch: 83
2022-12-05 21:57:48,710 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49319191175428306, 'Total loss': 0.49319191175428306} | train loss {'Reaction outcome loss': 0.13274497006298794, 'Total loss': 0.13274497006298794}
2022-12-05 21:57:48,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:48,710 INFO:     Epoch: 84
2022-12-05 21:57:49,508 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47662698045711627, 'Total loss': 0.47662698045711627} | train loss {'Reaction outcome loss': 0.12996145889854, 'Total loss': 0.12996145889854}
2022-12-05 21:57:49,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:49,508 INFO:     Epoch: 85
2022-12-05 21:57:50,306 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4803253598511219, 'Total loss': 0.4803253598511219} | train loss {'Reaction outcome loss': 0.12668366648346907, 'Total loss': 0.12668366648346907}
2022-12-05 21:57:50,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:50,307 INFO:     Epoch: 86
2022-12-05 21:57:51,107 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.484981948340481, 'Total loss': 0.484981948340481} | train loss {'Reaction outcome loss': 0.1255783478188659, 'Total loss': 0.1255783478188659}
2022-12-05 21:57:51,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:51,108 INFO:     Epoch: 87
2022-12-05 21:57:51,910 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4703700765967369, 'Total loss': 0.4703700765967369} | train loss {'Reaction outcome loss': 0.1259968803234158, 'Total loss': 0.1259968803234158}
2022-12-05 21:57:51,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:51,910 INFO:     Epoch: 88
2022-12-05 21:57:52,707 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.480238947678696, 'Total loss': 0.480238947678696} | train loss {'Reaction outcome loss': 0.12607553688013146, 'Total loss': 0.12607553688013146}
2022-12-05 21:57:52,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:52,707 INFO:     Epoch: 89
2022-12-05 21:57:53,505 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48380052603103896, 'Total loss': 0.48380052603103896} | train loss {'Reaction outcome loss': 0.12282451974686175, 'Total loss': 0.12282451974686175}
2022-12-05 21:57:53,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:53,506 INFO:     Epoch: 90
2022-12-05 21:57:54,301 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4807802005247636, 'Total loss': 0.4807802005247636} | train loss {'Reaction outcome loss': 0.12722985935397446, 'Total loss': 0.12722985935397446}
2022-12-05 21:57:54,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:54,301 INFO:     Epoch: 91
2022-12-05 21:57:55,100 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4818417534909465, 'Total loss': 0.4818417534909465} | train loss {'Reaction outcome loss': 0.12632810729630892, 'Total loss': 0.12632810729630892}
2022-12-05 21:57:55,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:55,100 INFO:     Epoch: 92
2022-12-05 21:57:55,898 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4756387583911419, 'Total loss': 0.4756387583911419} | train loss {'Reaction outcome loss': 0.12288671055237853, 'Total loss': 0.12288671055237853}
2022-12-05 21:57:55,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:55,898 INFO:     Epoch: 93
2022-12-05 21:57:56,702 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4811193174259229, 'Total loss': 0.4811193174259229} | train loss {'Reaction outcome loss': 0.12338204793782244, 'Total loss': 0.12338204793782244}
2022-12-05 21:57:56,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:56,703 INFO:     Epoch: 94
2022-12-05 21:57:57,497 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.484880225055597, 'Total loss': 0.484880225055597} | train loss {'Reaction outcome loss': 0.12580499271937315, 'Total loss': 0.12580499271937315}
2022-12-05 21:57:57,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:57,498 INFO:     Epoch: 95
2022-12-05 21:57:58,293 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4859596016732129, 'Total loss': 0.4859596016732129} | train loss {'Reaction outcome loss': 0.12319304303251087, 'Total loss': 0.12319304303251087}
2022-12-05 21:57:58,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:58,293 INFO:     Epoch: 96
2022-12-05 21:57:59,088 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4798134362155741, 'Total loss': 0.4798134362155741} | train loss {'Reaction outcome loss': 0.12057181920916323, 'Total loss': 0.12057181920916323}
2022-12-05 21:57:59,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:59,088 INFO:     Epoch: 97
2022-12-05 21:57:59,883 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4871043142947284, 'Total loss': 0.4871043142947284} | train loss {'Reaction outcome loss': 0.12216444910999628, 'Total loss': 0.12216444910999628}
2022-12-05 21:57:59,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:57:59,884 INFO:     Epoch: 98
2022-12-05 21:58:00,679 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.494633316824382, 'Total loss': 0.494633316824382} | train loss {'Reaction outcome loss': 0.1236414099788113, 'Total loss': 0.1236414099788113}
2022-12-05 21:58:00,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:00,679 INFO:     Epoch: 99
2022-12-05 21:58:01,475 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4804352091794664, 'Total loss': 0.4804352091794664} | train loss {'Reaction outcome loss': 0.12201658402374314, 'Total loss': 0.12201658402374314}
2022-12-05 21:58:01,475 INFO:     Best model found after epoch 16 of 100.
2022-12-05 21:58:01,475 INFO:   Done with stage: TRAINING
2022-12-05 21:58:01,475 INFO:   Starting stage: EVALUATION
2022-12-05 21:58:01,594 INFO:   Done with stage: EVALUATION
2022-12-05 21:58:01,595 INFO:   Leaving out SEQ value Fold_8
2022-12-05 21:58:01,607 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:58:01,607 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:58:02,266 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:58:02,267 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:58:02,337 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:58:02,337 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:58:02,337 INFO:     No hyperparam tuning for this model
2022-12-05 21:58:02,337 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:58:02,337 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:58:02,338 INFO:     None feature selector for col prot
2022-12-05 21:58:02,338 INFO:     None feature selector for col prot
2022-12-05 21:58:02,338 INFO:     None feature selector for col prot
2022-12-05 21:58:02,339 INFO:     None feature selector for col chem
2022-12-05 21:58:02,339 INFO:     None feature selector for col chem
2022-12-05 21:58:02,339 INFO:     None feature selector for col chem
2022-12-05 21:58:02,339 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:58:02,339 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:58:02,341 INFO:     Number of params in model 215821
2022-12-05 21:58:02,344 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:58:02,344 INFO:   Starting stage: TRAINING
2022-12-05 21:58:02,405 INFO:     Val loss before train {'Reaction outcome loss': 0.944435482675379, 'Total loss': 0.944435482675379}
2022-12-05 21:58:02,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:02,405 INFO:     Epoch: 0
2022-12-05 21:58:03,200 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5806714099916545, 'Total loss': 0.5806714099916545} | train loss {'Reaction outcome loss': 0.8101996048259349, 'Total loss': 0.8101996048259349}
2022-12-05 21:58:03,200 INFO:     Found new best model at epoch 0
2022-12-05 21:58:03,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:03,201 INFO:     Epoch: 1
2022-12-05 21:58:03,997 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5045046989213336, 'Total loss': 0.5045046989213336} | train loss {'Reaction outcome loss': 0.5486959298612618, 'Total loss': 0.5486959298612618}
2022-12-05 21:58:03,997 INFO:     Found new best model at epoch 1
2022-12-05 21:58:03,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:03,998 INFO:     Epoch: 2
2022-12-05 21:58:04,792 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4605406830933961, 'Total loss': 0.4605406830933961} | train loss {'Reaction outcome loss': 0.4826481881653249, 'Total loss': 0.4826481881653249}
2022-12-05 21:58:04,792 INFO:     Found new best model at epoch 2
2022-12-05 21:58:04,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:04,793 INFO:     Epoch: 3
2022-12-05 21:58:05,590 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.44764276153661986, 'Total loss': 0.44764276153661986} | train loss {'Reaction outcome loss': 0.4313540056739983, 'Total loss': 0.4313540056739983}
2022-12-05 21:58:05,590 INFO:     Found new best model at epoch 3
2022-12-05 21:58:05,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:05,591 INFO:     Epoch: 4
2022-12-05 21:58:06,385 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4378616593100808, 'Total loss': 0.4378616593100808} | train loss {'Reaction outcome loss': 0.40093340579163933, 'Total loss': 0.40093340579163933}
2022-12-05 21:58:06,385 INFO:     Found new best model at epoch 4
2022-12-05 21:58:06,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:06,386 INFO:     Epoch: 5
2022-12-05 21:58:07,187 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4258519041944634, 'Total loss': 0.4258519041944634} | train loss {'Reaction outcome loss': 0.3774932334237253, 'Total loss': 0.3774932334237253}
2022-12-05 21:58:07,187 INFO:     Found new best model at epoch 5
2022-12-05 21:58:07,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:07,188 INFO:     Epoch: 6
2022-12-05 21:58:07,980 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4297068491578102, 'Total loss': 0.4297068491578102} | train loss {'Reaction outcome loss': 0.3587890057428646, 'Total loss': 0.3587890057428646}
2022-12-05 21:58:07,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:07,980 INFO:     Epoch: 7
2022-12-05 21:58:08,772 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4250496741045605, 'Total loss': 0.4250496741045605} | train loss {'Reaction outcome loss': 0.34099458637628477, 'Total loss': 0.34099458637628477}
2022-12-05 21:58:08,773 INFO:     Found new best model at epoch 7
2022-12-05 21:58:08,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:08,774 INFO:     Epoch: 8
2022-12-05 21:58:09,565 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.431253855201331, 'Total loss': 0.431253855201331} | train loss {'Reaction outcome loss': 0.32366335506622607, 'Total loss': 0.32366335506622607}
2022-12-05 21:58:09,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:09,565 INFO:     Epoch: 9
2022-12-05 21:58:10,359 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4185243486003442, 'Total loss': 0.4185243486003442} | train loss {'Reaction outcome loss': 0.30427162623059323, 'Total loss': 0.30427162623059323}
2022-12-05 21:58:10,360 INFO:     Found new best model at epoch 9
2022-12-05 21:58:10,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:10,360 INFO:     Epoch: 10
2022-12-05 21:58:11,154 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4078346480700103, 'Total loss': 0.4078346480700103} | train loss {'Reaction outcome loss': 0.2954886807241903, 'Total loss': 0.2954886807241903}
2022-12-05 21:58:11,154 INFO:     Found new best model at epoch 10
2022-12-05 21:58:11,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:11,155 INFO:     Epoch: 11
2022-12-05 21:58:11,950 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4197696354240179, 'Total loss': 0.4197696354240179} | train loss {'Reaction outcome loss': 0.28864816205221633, 'Total loss': 0.28864816205221633}
2022-12-05 21:58:11,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:11,950 INFO:     Epoch: 12
2022-12-05 21:58:12,746 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43541661920872604, 'Total loss': 0.43541661920872604} | train loss {'Reaction outcome loss': 0.27004539364617064, 'Total loss': 0.27004539364617064}
2022-12-05 21:58:12,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:12,746 INFO:     Epoch: 13
2022-12-05 21:58:13,542 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4206606237725778, 'Total loss': 0.4206606237725778} | train loss {'Reaction outcome loss': 0.2606016192698346, 'Total loss': 0.2606016192698346}
2022-12-05 21:58:13,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:13,543 INFO:     Epoch: 14
2022-12-05 21:58:14,340 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4177735908464952, 'Total loss': 0.4177735908464952} | train loss {'Reaction outcome loss': 0.25561652791041595, 'Total loss': 0.25561652791041595}
2022-12-05 21:58:14,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:14,341 INFO:     Epoch: 15
2022-12-05 21:58:15,138 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.424881023439494, 'Total loss': 0.424881023439494} | train loss {'Reaction outcome loss': 0.24706669534115414, 'Total loss': 0.24706669534115414}
2022-12-05 21:58:15,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:15,138 INFO:     Epoch: 16
2022-12-05 21:58:15,936 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.428194441578605, 'Total loss': 0.428194441578605} | train loss {'Reaction outcome loss': 0.238979223074942, 'Total loss': 0.238979223074942}
2022-12-05 21:58:15,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:15,937 INFO:     Epoch: 17
2022-12-05 21:58:16,734 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41938897798007185, 'Total loss': 0.41938897798007185} | train loss {'Reaction outcome loss': 0.23046892310911224, 'Total loss': 0.23046892310911224}
2022-12-05 21:58:16,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:16,735 INFO:     Epoch: 18
2022-12-05 21:58:17,532 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42153075439008797, 'Total loss': 0.42153075439008797} | train loss {'Reaction outcome loss': 0.22761420349058833, 'Total loss': 0.22761420349058833}
2022-12-05 21:58:17,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:17,532 INFO:     Epoch: 19
2022-12-05 21:58:18,328 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4158521976999261, 'Total loss': 0.4158521976999261} | train loss {'Reaction outcome loss': 0.21807256473703424, 'Total loss': 0.21807256473703424}
2022-12-05 21:58:18,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:18,328 INFO:     Epoch: 20
2022-12-05 21:58:19,121 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4345071806826375, 'Total loss': 0.4345071806826375} | train loss {'Reaction outcome loss': 0.21411816991473498, 'Total loss': 0.21411816991473498}
2022-12-05 21:58:19,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:19,121 INFO:     Epoch: 21
2022-12-05 21:58:19,924 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4206871505488049, 'Total loss': 0.4206871505488049} | train loss {'Reaction outcome loss': 0.20827032649995164, 'Total loss': 0.20827032649995164}
2022-12-05 21:58:19,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:19,925 INFO:     Epoch: 22
2022-12-05 21:58:20,722 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4208540792830966, 'Total loss': 0.4208540792830966} | train loss {'Reaction outcome loss': 0.20481211914179417, 'Total loss': 0.20481211914179417}
2022-12-05 21:58:20,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:20,722 INFO:     Epoch: 23
2022-12-05 21:58:21,524 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44867595386776055, 'Total loss': 0.44867595386776055} | train loss {'Reaction outcome loss': 0.20175397295037262, 'Total loss': 0.20175397295037262}
2022-12-05 21:58:21,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:21,525 INFO:     Epoch: 24
2022-12-05 21:58:22,323 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4624454402788119, 'Total loss': 0.4624454402788119} | train loss {'Reaction outcome loss': 0.2012454562552786, 'Total loss': 0.2012454562552786}
2022-12-05 21:58:22,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:22,323 INFO:     Epoch: 25
2022-12-05 21:58:23,120 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4237544299526648, 'Total loss': 0.4237544299526648} | train loss {'Reaction outcome loss': 0.19346446950584348, 'Total loss': 0.19346446950584348}
2022-12-05 21:58:23,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:23,121 INFO:     Epoch: 26
2022-12-05 21:58:23,918 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4433056178756736, 'Total loss': 0.4433056178756736} | train loss {'Reaction outcome loss': 0.18797107321410045, 'Total loss': 0.18797107321410045}
2022-12-05 21:58:23,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:23,918 INFO:     Epoch: 27
2022-12-05 21:58:24,713 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43852047554471274, 'Total loss': 0.43852047554471274} | train loss {'Reaction outcome loss': 0.18618954544668256, 'Total loss': 0.18618954544668256}
2022-12-05 21:58:24,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:24,713 INFO:     Epoch: 28
2022-12-05 21:58:25,512 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.446048956703056, 'Total loss': 0.446048956703056} | train loss {'Reaction outcome loss': 0.18260873518582538, 'Total loss': 0.18260873518582538}
2022-12-05 21:58:25,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:25,513 INFO:     Epoch: 29
2022-12-05 21:58:26,307 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42582014558667486, 'Total loss': 0.42582014558667486} | train loss {'Reaction outcome loss': 0.18006675825704094, 'Total loss': 0.18006675825704094}
2022-12-05 21:58:26,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:26,307 INFO:     Epoch: 30
2022-12-05 21:58:27,101 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42674761824309826, 'Total loss': 0.42674761824309826} | train loss {'Reaction outcome loss': 0.17415484148435867, 'Total loss': 0.17415484148435867}
2022-12-05 21:58:27,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:27,101 INFO:     Epoch: 31
2022-12-05 21:58:27,895 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4364911158653823, 'Total loss': 0.4364911158653823} | train loss {'Reaction outcome loss': 0.17040642321124855, 'Total loss': 0.17040642321124855}
2022-12-05 21:58:27,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:27,896 INFO:     Epoch: 32
2022-12-05 21:58:28,690 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4343558985062621, 'Total loss': 0.4343558985062621} | train loss {'Reaction outcome loss': 0.16855144904179853, 'Total loss': 0.16855144904179853}
2022-12-05 21:58:28,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:28,691 INFO:     Epoch: 33
2022-12-05 21:58:29,490 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.454438695514744, 'Total loss': 0.454438695514744} | train loss {'Reaction outcome loss': 0.16854431362104363, 'Total loss': 0.16854431362104363}
2022-12-05 21:58:29,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:29,490 INFO:     Epoch: 34
2022-12-05 21:58:30,289 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45019764893434266, 'Total loss': 0.45019764893434266} | train loss {'Reaction outcome loss': 0.16921496330213692, 'Total loss': 0.16921496330213692}
2022-12-05 21:58:30,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:30,289 INFO:     Epoch: 35
2022-12-05 21:58:31,087 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4377042153342204, 'Total loss': 0.4377042153342204} | train loss {'Reaction outcome loss': 0.1694194020831633, 'Total loss': 0.1694194020831633}
2022-12-05 21:58:31,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:31,088 INFO:     Epoch: 36
2022-12-05 21:58:31,885 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4313034035942771, 'Total loss': 0.4313034035942771} | train loss {'Reaction outcome loss': 0.16662310206365247, 'Total loss': 0.16662310206365247}
2022-12-05 21:58:31,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:31,885 INFO:     Epoch: 37
2022-12-05 21:58:32,687 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45020927454937587, 'Total loss': 0.45020927454937587} | train loss {'Reaction outcome loss': 0.1597753570222782, 'Total loss': 0.1597753570222782}
2022-12-05 21:58:32,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:32,688 INFO:     Epoch: 38
2022-12-05 21:58:33,481 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4452209807932377, 'Total loss': 0.4452209807932377} | train loss {'Reaction outcome loss': 0.15741942129531492, 'Total loss': 0.15741942129531492}
2022-12-05 21:58:33,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:33,482 INFO:     Epoch: 39
2022-12-05 21:58:34,279 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4505564607679844, 'Total loss': 0.4505564607679844} | train loss {'Reaction outcome loss': 0.15677923051949574, 'Total loss': 0.15677923051949574}
2022-12-05 21:58:34,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:34,279 INFO:     Epoch: 40
2022-12-05 21:58:35,076 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.440874016081745, 'Total loss': 0.440874016081745} | train loss {'Reaction outcome loss': 0.15251979629248985, 'Total loss': 0.15251979629248985}
2022-12-05 21:58:35,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:35,076 INFO:     Epoch: 41
2022-12-05 21:58:35,872 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44363652779297397, 'Total loss': 0.44363652779297397} | train loss {'Reaction outcome loss': 0.1515343672735428, 'Total loss': 0.1515343672735428}
2022-12-05 21:58:35,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:35,873 INFO:     Epoch: 42
2022-12-05 21:58:36,668 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4717219502411105, 'Total loss': 0.4717219502411105} | train loss {'Reaction outcome loss': 0.1542043962349987, 'Total loss': 0.1542043962349987}
2022-12-05 21:58:36,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:36,669 INFO:     Epoch: 43
2022-12-05 21:58:37,466 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45131971483880823, 'Total loss': 0.45131971483880823} | train loss {'Reaction outcome loss': 0.15798441194721802, 'Total loss': 0.15798441194721802}
2022-12-05 21:58:37,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:37,467 INFO:     Epoch: 44
2022-12-05 21:58:38,264 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46695834635333583, 'Total loss': 0.46695834635333583} | train loss {'Reaction outcome loss': 0.15460522210429073, 'Total loss': 0.15460522210429073}
2022-12-05 21:58:38,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:38,265 INFO:     Epoch: 45
2022-12-05 21:58:39,060 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44471922516822815, 'Total loss': 0.44471922516822815} | train loss {'Reaction outcome loss': 0.15005631598564778, 'Total loss': 0.15005631598564778}
2022-12-05 21:58:39,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:39,060 INFO:     Epoch: 46
2022-12-05 21:58:39,856 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4495455101132393, 'Total loss': 0.4495455101132393} | train loss {'Reaction outcome loss': 0.14902437894571166, 'Total loss': 0.14902437894571166}
2022-12-05 21:58:39,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:39,856 INFO:     Epoch: 47
2022-12-05 21:58:40,652 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4521699141372334, 'Total loss': 0.4521699141372334} | train loss {'Reaction outcome loss': 0.14452513409137485, 'Total loss': 0.14452513409137485}
2022-12-05 21:58:40,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:40,653 INFO:     Epoch: 48
2022-12-05 21:58:41,451 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4566859311678193, 'Total loss': 0.4566859311678193} | train loss {'Reaction outcome loss': 0.14476825234287904, 'Total loss': 0.14476825234287904}
2022-12-05 21:58:41,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:41,451 INFO:     Epoch: 49
2022-12-05 21:58:42,247 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44364402239972894, 'Total loss': 0.44364402239972894} | train loss {'Reaction outcome loss': 0.14258107812349358, 'Total loss': 0.14258107812349358}
2022-12-05 21:58:42,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:42,247 INFO:     Epoch: 50
2022-12-05 21:58:43,040 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4602010957050053, 'Total loss': 0.4602010957050053} | train loss {'Reaction outcome loss': 0.13992070187230102, 'Total loss': 0.13992070187230102}
2022-12-05 21:58:43,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:43,041 INFO:     Epoch: 51
2022-12-05 21:58:43,841 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4771188643168319, 'Total loss': 0.4771188643168319} | train loss {'Reaction outcome loss': 0.1398735989730236, 'Total loss': 0.1398735989730236}
2022-12-05 21:58:43,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:43,841 INFO:     Epoch: 52
2022-12-05 21:58:44,644 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4726546684449369, 'Total loss': 0.4726546684449369} | train loss {'Reaction outcome loss': 0.14009380849103747, 'Total loss': 0.14009380849103747}
2022-12-05 21:58:44,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:44,644 INFO:     Epoch: 53
2022-12-05 21:58:45,444 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45334680209105666, 'Total loss': 0.45334680209105666} | train loss {'Reaction outcome loss': 0.14057491059878818, 'Total loss': 0.14057491059878818}
2022-12-05 21:58:45,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:45,444 INFO:     Epoch: 54
2022-12-05 21:58:46,244 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.474305695430799, 'Total loss': 0.474305695430799} | train loss {'Reaction outcome loss': 0.14081980620213003, 'Total loss': 0.14081980620213003}
2022-12-05 21:58:46,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:46,244 INFO:     Epoch: 55
2022-12-05 21:58:47,050 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45428101989355957, 'Total loss': 0.45428101989355957} | train loss {'Reaction outcome loss': 0.136804132282815, 'Total loss': 0.136804132282815}
2022-12-05 21:58:47,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:47,050 INFO:     Epoch: 56
2022-12-05 21:58:47,849 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4554761712524024, 'Total loss': 0.4554761712524024} | train loss {'Reaction outcome loss': 0.13413282804500296, 'Total loss': 0.13413282804500296}
2022-12-05 21:58:47,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:47,849 INFO:     Epoch: 57
2022-12-05 21:58:48,648 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4775283912366087, 'Total loss': 0.4775283912366087} | train loss {'Reaction outcome loss': 0.1330168467667331, 'Total loss': 0.1330168467667331}
2022-12-05 21:58:48,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:48,648 INFO:     Epoch: 58
2022-12-05 21:58:49,447 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4439590135589242, 'Total loss': 0.4439590135589242} | train loss {'Reaction outcome loss': 0.13414848980452368, 'Total loss': 0.13414848980452368}
2022-12-05 21:58:49,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:49,447 INFO:     Epoch: 59
2022-12-05 21:58:50,248 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4568579081784595, 'Total loss': 0.4568579081784595} | train loss {'Reaction outcome loss': 0.13358816739430024, 'Total loss': 0.13358816739430024}
2022-12-05 21:58:50,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:50,248 INFO:     Epoch: 60
2022-12-05 21:58:51,049 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4542175188914619, 'Total loss': 0.4542175188914619} | train loss {'Reaction outcome loss': 0.13258615112109373, 'Total loss': 0.13258615112109373}
2022-12-05 21:58:51,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:51,049 INFO:     Epoch: 61
2022-12-05 21:58:51,852 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45514725284142926, 'Total loss': 0.45514725284142926} | train loss {'Reaction outcome loss': 0.1305681285957395, 'Total loss': 0.1305681285957395}
2022-12-05 21:58:51,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:51,852 INFO:     Epoch: 62
2022-12-05 21:58:52,654 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4391351167789914, 'Total loss': 0.4391351167789914} | train loss {'Reaction outcome loss': 0.1357935551584129, 'Total loss': 0.1357935551584129}
2022-12-05 21:58:52,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:52,655 INFO:     Epoch: 63
2022-12-05 21:58:53,458 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4638903242620555, 'Total loss': 0.4638903242620555} | train loss {'Reaction outcome loss': 0.13294761587567777, 'Total loss': 0.13294761587567777}
2022-12-05 21:58:53,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:53,458 INFO:     Epoch: 64
2022-12-05 21:58:54,256 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4684316067194397, 'Total loss': 0.4684316067194397} | train loss {'Reaction outcome loss': 0.12895213642161385, 'Total loss': 0.12895213642161385}
2022-12-05 21:58:54,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:54,256 INFO:     Epoch: 65
2022-12-05 21:58:55,059 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47288255935365503, 'Total loss': 0.47288255935365503} | train loss {'Reaction outcome loss': 0.1338411730861193, 'Total loss': 0.1338411730861193}
2022-12-05 21:58:55,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:55,060 INFO:     Epoch: 66
2022-12-05 21:58:55,859 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46705055609345436, 'Total loss': 0.46705055609345436} | train loss {'Reaction outcome loss': 0.12839044901252034, 'Total loss': 0.12839044901252034}
2022-12-05 21:58:55,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:55,859 INFO:     Epoch: 67
2022-12-05 21:58:56,662 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45966396954926575, 'Total loss': 0.45966396954926575} | train loss {'Reaction outcome loss': 0.13100802048150947, 'Total loss': 0.13100802048150947}
2022-12-05 21:58:56,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:56,662 INFO:     Epoch: 68
2022-12-05 21:58:57,462 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45389253917065536, 'Total loss': 0.45389253917065536} | train loss {'Reaction outcome loss': 0.13633127945290524, 'Total loss': 0.13633127945290524}
2022-12-05 21:58:57,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:57,462 INFO:     Epoch: 69
2022-12-05 21:58:58,258 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4622448647225445, 'Total loss': 0.4622448647225445} | train loss {'Reaction outcome loss': 0.12599557266393413, 'Total loss': 0.12599557266393413}
2022-12-05 21:58:58,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:58,258 INFO:     Epoch: 70
2022-12-05 21:58:59,056 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47200688448819245, 'Total loss': 0.47200688448819245} | train loss {'Reaction outcome loss': 0.12355210141562536, 'Total loss': 0.12355210141562536}
2022-12-05 21:58:59,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:59,058 INFO:     Epoch: 71
2022-12-05 21:58:59,856 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4447390597990968, 'Total loss': 0.4447390597990968} | train loss {'Reaction outcome loss': 0.12546574806809607, 'Total loss': 0.12546574806809607}
2022-12-05 21:58:59,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:58:59,856 INFO:     Epoch: 72
2022-12-05 21:59:00,659 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46288659423589706, 'Total loss': 0.46288659423589706} | train loss {'Reaction outcome loss': 0.12609005235286377, 'Total loss': 0.12609005235286377}
2022-12-05 21:59:00,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:00,659 INFO:     Epoch: 73
2022-12-05 21:59:01,456 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46062409810044547, 'Total loss': 0.46062409810044547} | train loss {'Reaction outcome loss': 0.12473509300062773, 'Total loss': 0.12473509300062773}
2022-12-05 21:59:01,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:01,456 INFO:     Epoch: 74
2022-12-05 21:59:02,252 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4560452570969408, 'Total loss': 0.4560452570969408} | train loss {'Reaction outcome loss': 0.12684200786672503, 'Total loss': 0.12684200786672503}
2022-12-05 21:59:02,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:02,252 INFO:     Epoch: 75
2022-12-05 21:59:03,051 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44531884349205275, 'Total loss': 0.44531884349205275} | train loss {'Reaction outcome loss': 0.12453855835052155, 'Total loss': 0.12453855835052155}
2022-12-05 21:59:03,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:03,051 INFO:     Epoch: 76
2022-12-05 21:59:03,850 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4662437900498679, 'Total loss': 0.4662437900498679} | train loss {'Reaction outcome loss': 0.12874574386910628, 'Total loss': 0.12874574386910628}
2022-12-05 21:59:03,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:03,850 INFO:     Epoch: 77
2022-12-05 21:59:04,645 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46927673471244896, 'Total loss': 0.46927673471244896} | train loss {'Reaction outcome loss': 0.12773411345445676, 'Total loss': 0.12773411345445676}
2022-12-05 21:59:04,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:04,646 INFO:     Epoch: 78
2022-12-05 21:59:05,441 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4614455723627047, 'Total loss': 0.4614455723627047} | train loss {'Reaction outcome loss': 0.13116220864354206, 'Total loss': 0.13116220864354206}
2022-12-05 21:59:05,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:05,441 INFO:     Epoch: 79
2022-12-05 21:59:06,239 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45303100753914227, 'Total loss': 0.45303100753914227} | train loss {'Reaction outcome loss': 0.12216704705285157, 'Total loss': 0.12216704705285157}
2022-12-05 21:59:06,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:06,239 INFO:     Epoch: 80
2022-12-05 21:59:07,035 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4648155512457544, 'Total loss': 0.4648155512457544} | train loss {'Reaction outcome loss': 0.12222421417523718, 'Total loss': 0.12222421417523718}
2022-12-05 21:59:07,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:07,035 INFO:     Epoch: 81
2022-12-05 21:59:07,832 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4654452705925161, 'Total loss': 0.4654452705925161} | train loss {'Reaction outcome loss': 0.1269874514838462, 'Total loss': 0.1269874514838462}
2022-12-05 21:59:07,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:07,832 INFO:     Epoch: 82
2022-12-05 21:59:08,630 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46750926124778663, 'Total loss': 0.46750926124778663} | train loss {'Reaction outcome loss': 0.12660027895809003, 'Total loss': 0.12660027895809003}
2022-12-05 21:59:08,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:08,630 INFO:     Epoch: 83
2022-12-05 21:59:09,429 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4570744044401429, 'Total loss': 0.4570744044401429} | train loss {'Reaction outcome loss': 0.11793726907858271, 'Total loss': 0.11793726907858271}
2022-12-05 21:59:09,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:09,429 INFO:     Epoch: 84
2022-12-05 21:59:10,230 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4446975819089196, 'Total loss': 0.4446975819089196} | train loss {'Reaction outcome loss': 0.11897060491506628, 'Total loss': 0.11897060491506628}
2022-12-05 21:59:10,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:10,230 INFO:     Epoch: 85
2022-12-05 21:59:11,032 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44626263732259924, 'Total loss': 0.44626263732259924} | train loss {'Reaction outcome loss': 0.1180881925091253, 'Total loss': 0.1180881925091253}
2022-12-05 21:59:11,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:11,032 INFO:     Epoch: 86
2022-12-05 21:59:11,828 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4608658499677073, 'Total loss': 0.4608658499677073} | train loss {'Reaction outcome loss': 0.12029778603690597, 'Total loss': 0.12029778603690597}
2022-12-05 21:59:11,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:11,829 INFO:     Epoch: 87
2022-12-05 21:59:12,630 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.447880380871621, 'Total loss': 0.447880380871621} | train loss {'Reaction outcome loss': 0.1191070620135521, 'Total loss': 0.1191070620135521}
2022-12-05 21:59:12,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:12,630 INFO:     Epoch: 88
2022-12-05 21:59:13,442 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.468455278060653, 'Total loss': 0.468455278060653} | train loss {'Reaction outcome loss': 0.11758193363028348, 'Total loss': 0.11758193363028348}
2022-12-05 21:59:13,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:13,443 INFO:     Epoch: 89
2022-12-05 21:59:14,252 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46097846337678755, 'Total loss': 0.46097846337678755} | train loss {'Reaction outcome loss': 0.11739843406220558, 'Total loss': 0.11739843406220558}
2022-12-05 21:59:14,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:14,253 INFO:     Epoch: 90
2022-12-05 21:59:15,062 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44848223572427576, 'Total loss': 0.44848223572427576} | train loss {'Reaction outcome loss': 0.11833221971355228, 'Total loss': 0.11833221971355228}
2022-12-05 21:59:15,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:15,062 INFO:     Epoch: 91
2022-12-05 21:59:15,873 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44662311309101904, 'Total loss': 0.44662311309101904} | train loss {'Reaction outcome loss': 0.11778314047406319, 'Total loss': 0.11778314047406319}
2022-12-05 21:59:15,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:15,873 INFO:     Epoch: 92
2022-12-05 21:59:16,689 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4660612717270851, 'Total loss': 0.4660612717270851} | train loss {'Reaction outcome loss': 0.11514094819103628, 'Total loss': 0.11514094819103628}
2022-12-05 21:59:16,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:16,690 INFO:     Epoch: 93
2022-12-05 21:59:17,505 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46838345514102414, 'Total loss': 0.46838345514102414} | train loss {'Reaction outcome loss': 0.1195508403258647, 'Total loss': 0.1195508403258647}
2022-12-05 21:59:17,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:17,505 INFO:     Epoch: 94
2022-12-05 21:59:18,314 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4520076701248234, 'Total loss': 0.4520076701248234} | train loss {'Reaction outcome loss': 0.12831134260877183, 'Total loss': 0.12831134260877183}
2022-12-05 21:59:18,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:18,315 INFO:     Epoch: 95
2022-12-05 21:59:19,125 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4344098860905929, 'Total loss': 0.4344098860905929} | train loss {'Reaction outcome loss': 0.12036899005172223, 'Total loss': 0.12036899005172223}
2022-12-05 21:59:19,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:19,125 INFO:     Epoch: 96
2022-12-05 21:59:19,935 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44262970865450124, 'Total loss': 0.44262970865450124} | train loss {'Reaction outcome loss': 0.11510042044492476, 'Total loss': 0.11510042044492476}
2022-12-05 21:59:19,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:19,936 INFO:     Epoch: 97
2022-12-05 21:59:20,746 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45022560469806194, 'Total loss': 0.45022560469806194} | train loss {'Reaction outcome loss': 0.1125959845029783, 'Total loss': 0.1125959845029783}
2022-12-05 21:59:20,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:20,747 INFO:     Epoch: 98
2022-12-05 21:59:21,559 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43912174992940645, 'Total loss': 0.43912174992940645} | train loss {'Reaction outcome loss': 0.11687420843629098, 'Total loss': 0.11687420843629098}
2022-12-05 21:59:21,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:21,559 INFO:     Epoch: 99
2022-12-05 21:59:22,375 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4558222005990418, 'Total loss': 0.4558222005990418} | train loss {'Reaction outcome loss': 0.12137000034996855, 'Total loss': 0.12137000034996855}
2022-12-05 21:59:22,375 INFO:     Best model found after epoch 11 of 100.
2022-12-05 21:59:22,375 INFO:   Done with stage: TRAINING
2022-12-05 21:59:22,375 INFO:   Starting stage: EVALUATION
2022-12-05 21:59:22,502 INFO:   Done with stage: EVALUATION
2022-12-05 21:59:22,503 INFO:   Leaving out SEQ value Fold_9
2022-12-05 21:59:22,515 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 21:59:22,516 INFO:   Starting stage: FEATURE SCALING
2022-12-05 21:59:23,170 INFO:   Done with stage: FEATURE SCALING
2022-12-05 21:59:23,172 INFO:   Starting stage: SCALING TARGETS
2022-12-05 21:59:23,242 INFO:   Done with stage: SCALING TARGETS
2022-12-05 21:59:23,242 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:59:23,243 INFO:     No hyperparam tuning for this model
2022-12-05 21:59:23,243 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 21:59:23,243 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 21:59:23,243 INFO:     None feature selector for col prot
2022-12-05 21:59:23,244 INFO:     None feature selector for col prot
2022-12-05 21:59:23,244 INFO:     None feature selector for col prot
2022-12-05 21:59:23,244 INFO:     None feature selector for col chem
2022-12-05 21:59:23,244 INFO:     None feature selector for col chem
2022-12-05 21:59:23,244 INFO:     None feature selector for col chem
2022-12-05 21:59:23,244 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 21:59:23,244 INFO:   Starting stage: BUILD MODEL
2022-12-05 21:59:23,246 INFO:     Number of params in model 215821
2022-12-05 21:59:23,249 INFO:   Done with stage: BUILD MODEL
2022-12-05 21:59:23,249 INFO:   Starting stage: TRAINING
2022-12-05 21:59:23,310 INFO:     Val loss before train {'Reaction outcome loss': 1.002778635783629, 'Total loss': 1.002778635783629}
2022-12-05 21:59:23,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:23,311 INFO:     Epoch: 0
2022-12-05 21:59:24,126 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6061746379868551, 'Total loss': 0.6061746379868551} | train loss {'Reaction outcome loss': 0.819089746547614, 'Total loss': 0.819089746547614}
2022-12-05 21:59:24,126 INFO:     Found new best model at epoch 0
2022-12-05 21:59:24,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:24,127 INFO:     Epoch: 1
2022-12-05 21:59:24,936 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48749196461655875, 'Total loss': 0.48749196461655875} | train loss {'Reaction outcome loss': 0.5676233729852839, 'Total loss': 0.5676233729852839}
2022-12-05 21:59:24,936 INFO:     Found new best model at epoch 1
2022-12-05 21:59:24,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:24,937 INFO:     Epoch: 2
2022-12-05 21:59:25,749 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4719239022921432, 'Total loss': 0.4719239022921432} | train loss {'Reaction outcome loss': 0.49058968993092356, 'Total loss': 0.49058968993092356}
2022-12-05 21:59:25,749 INFO:     Found new best model at epoch 2
2022-12-05 21:59:25,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:25,750 INFO:     Epoch: 3
2022-12-05 21:59:26,564 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.434924967079, 'Total loss': 0.434924967079} | train loss {'Reaction outcome loss': 0.4462696045999102, 'Total loss': 0.4462696045999102}
2022-12-05 21:59:26,564 INFO:     Found new best model at epoch 3
2022-12-05 21:59:26,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:26,565 INFO:     Epoch: 4
2022-12-05 21:59:27,377 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4257948567921465, 'Total loss': 0.4257948567921465} | train loss {'Reaction outcome loss': 0.4146041265021452, 'Total loss': 0.4146041265021452}
2022-12-05 21:59:27,377 INFO:     Found new best model at epoch 4
2022-12-05 21:59:27,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:27,378 INFO:     Epoch: 5
2022-12-05 21:59:28,193 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4116829085079106, 'Total loss': 0.4116829085079106} | train loss {'Reaction outcome loss': 0.39511171266858874, 'Total loss': 0.39511171266858874}
2022-12-05 21:59:28,193 INFO:     Found new best model at epoch 5
2022-12-05 21:59:28,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:28,194 INFO:     Epoch: 6
2022-12-05 21:59:29,008 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41074574806473474, 'Total loss': 0.41074574806473474} | train loss {'Reaction outcome loss': 0.3784157599394138, 'Total loss': 0.3784157599394138}
2022-12-05 21:59:29,009 INFO:     Found new best model at epoch 6
2022-12-05 21:59:29,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:29,010 INFO:     Epoch: 7
2022-12-05 21:59:29,821 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4099299995736642, 'Total loss': 0.4099299995736642} | train loss {'Reaction outcome loss': 0.35925954311844793, 'Total loss': 0.35925954311844793}
2022-12-05 21:59:29,822 INFO:     Found new best model at epoch 7
2022-12-05 21:59:29,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:29,823 INFO:     Epoch: 8
2022-12-05 21:59:30,634 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.397920042953708, 'Total loss': 0.397920042953708} | train loss {'Reaction outcome loss': 0.3499404488184191, 'Total loss': 0.3499404488184191}
2022-12-05 21:59:30,635 INFO:     Found new best model at epoch 8
2022-12-05 21:59:30,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:30,635 INFO:     Epoch: 9
2022-12-05 21:59:31,446 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40922852300784807, 'Total loss': 0.40922852300784807} | train loss {'Reaction outcome loss': 0.33031566032709986, 'Total loss': 0.33031566032709986}
2022-12-05 21:59:31,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:31,446 INFO:     Epoch: 10
2022-12-05 21:59:32,257 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3885225487703627, 'Total loss': 0.3885225487703627} | train loss {'Reaction outcome loss': 0.3147860706938423, 'Total loss': 0.3147860706938423}
2022-12-05 21:59:32,257 INFO:     Found new best model at epoch 10
2022-12-05 21:59:32,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:32,258 INFO:     Epoch: 11
2022-12-05 21:59:33,069 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.39647202989594504, 'Total loss': 0.39647202989594504} | train loss {'Reaction outcome loss': 0.30313511578901575, 'Total loss': 0.30313511578901575}
2022-12-05 21:59:33,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:33,070 INFO:     Epoch: 12
2022-12-05 21:59:33,885 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42374861087988724, 'Total loss': 0.42374861087988724} | train loss {'Reaction outcome loss': 0.2947837805096437, 'Total loss': 0.2947837805096437}
2022-12-05 21:59:33,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:33,885 INFO:     Epoch: 13
2022-12-05 21:59:34,695 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.38746338473124936, 'Total loss': 0.38746338473124936} | train loss {'Reaction outcome loss': 0.28871865772645966, 'Total loss': 0.28871865772645966}
2022-12-05 21:59:34,695 INFO:     Found new best model at epoch 13
2022-12-05 21:59:34,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:34,696 INFO:     Epoch: 14
2022-12-05 21:59:35,506 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.394500944763422, 'Total loss': 0.394500944763422} | train loss {'Reaction outcome loss': 0.2722400445132874, 'Total loss': 0.2722400445132874}
2022-12-05 21:59:35,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:35,506 INFO:     Epoch: 15
2022-12-05 21:59:36,320 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3993852050466971, 'Total loss': 0.3993852050466971} | train loss {'Reaction outcome loss': 0.2620076893070931, 'Total loss': 0.2620076893070931}
2022-12-05 21:59:36,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:36,320 INFO:     Epoch: 16
2022-12-05 21:59:37,136 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3924094421619719, 'Total loss': 0.3924094421619719} | train loss {'Reaction outcome loss': 0.25992388750317125, 'Total loss': 0.25992388750317125}
2022-12-05 21:59:37,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:37,136 INFO:     Epoch: 17
2022-12-05 21:59:37,948 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39218008010224864, 'Total loss': 0.39218008010224864} | train loss {'Reaction outcome loss': 0.251285550655865, 'Total loss': 0.251285550655865}
2022-12-05 21:59:37,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:37,949 INFO:     Epoch: 18
2022-12-05 21:59:38,758 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3950146316466006, 'Total loss': 0.3950146316466006} | train loss {'Reaction outcome loss': 0.24173749690717047, 'Total loss': 0.24173749690717047}
2022-12-05 21:59:38,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:38,758 INFO:     Epoch: 19
2022-12-05 21:59:39,569 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40045554157007823, 'Total loss': 0.40045554157007823} | train loss {'Reaction outcome loss': 0.23503599576802872, 'Total loss': 0.23503599576802872}
2022-12-05 21:59:39,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:39,570 INFO:     Epoch: 20
2022-12-05 21:59:40,383 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3781081578609618, 'Total loss': 0.3781081578609618} | train loss {'Reaction outcome loss': 0.22888679485598407, 'Total loss': 0.22888679485598407}
2022-12-05 21:59:40,383 INFO:     Found new best model at epoch 20
2022-12-05 21:59:40,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:40,384 INFO:     Epoch: 21
2022-12-05 21:59:41,196 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4075993992049586, 'Total loss': 0.4075993992049586} | train loss {'Reaction outcome loss': 0.22255826678111967, 'Total loss': 0.22255826678111967}
2022-12-05 21:59:41,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:41,196 INFO:     Epoch: 22
2022-12-05 21:59:42,010 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39732401276176627, 'Total loss': 0.39732401276176627} | train loss {'Reaction outcome loss': 0.2222363659103405, 'Total loss': 0.2222363659103405}
2022-12-05 21:59:42,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:42,011 INFO:     Epoch: 23
2022-12-05 21:59:42,822 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39238252727822825, 'Total loss': 0.39238252727822825} | train loss {'Reaction outcome loss': 0.2149887355836297, 'Total loss': 0.2149887355836297}
2022-12-05 21:59:42,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:42,822 INFO:     Epoch: 24
2022-12-05 21:59:43,631 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3974499289285053, 'Total loss': 0.3974499289285053} | train loss {'Reaction outcome loss': 0.20622376461140057, 'Total loss': 0.20622376461140057}
2022-12-05 21:59:43,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:43,631 INFO:     Epoch: 25
2022-12-05 21:59:44,440 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40023034176027233, 'Total loss': 0.40023034176027233} | train loss {'Reaction outcome loss': 0.20744893509095255, 'Total loss': 0.20744893509095255}
2022-12-05 21:59:44,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:44,441 INFO:     Epoch: 26
2022-12-05 21:59:45,252 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40211207775229757, 'Total loss': 0.40211207775229757} | train loss {'Reaction outcome loss': 0.20438173472097046, 'Total loss': 0.20438173472097046}
2022-12-05 21:59:45,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:45,253 INFO:     Epoch: 27
2022-12-05 21:59:46,063 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41145924072373996, 'Total loss': 0.41145924072373996} | train loss {'Reaction outcome loss': 0.20158046190645773, 'Total loss': 0.20158046190645773}
2022-12-05 21:59:46,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:46,063 INFO:     Epoch: 28
2022-12-05 21:59:46,875 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40377876230261545, 'Total loss': 0.40377876230261545} | train loss {'Reaction outcome loss': 0.19458049515390444, 'Total loss': 0.19458049515390444}
2022-12-05 21:59:46,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:46,876 INFO:     Epoch: 29
2022-12-05 21:59:47,690 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3964066439392892, 'Total loss': 0.3964066439392892} | train loss {'Reaction outcome loss': 0.19277785968050543, 'Total loss': 0.19277785968050543}
2022-12-05 21:59:47,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:47,690 INFO:     Epoch: 30
2022-12-05 21:59:48,505 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4087314788590778, 'Total loss': 0.4087314788590778} | train loss {'Reaction outcome loss': 0.1959737523907592, 'Total loss': 0.1959737523907592}
2022-12-05 21:59:48,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:48,505 INFO:     Epoch: 31
2022-12-05 21:59:49,320 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4036019684916193, 'Total loss': 0.4036019684916193} | train loss {'Reaction outcome loss': 0.19023902983798718, 'Total loss': 0.19023902983798718}
2022-12-05 21:59:49,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:49,320 INFO:     Epoch: 32
2022-12-05 21:59:50,128 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4037800176407803, 'Total loss': 0.4037800176407803} | train loss {'Reaction outcome loss': 0.18342713476158679, 'Total loss': 0.18342713476158679}
2022-12-05 21:59:50,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:50,128 INFO:     Epoch: 33
2022-12-05 21:59:50,923 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.425600586628372, 'Total loss': 0.425600586628372} | train loss {'Reaction outcome loss': 0.1801136900210821, 'Total loss': 0.1801136900210821}
2022-12-05 21:59:50,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:50,923 INFO:     Epoch: 34
2022-12-05 21:59:51,724 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40716080655428494, 'Total loss': 0.40716080655428494} | train loss {'Reaction outcome loss': 0.18086271560072206, 'Total loss': 0.18086271560072206}
2022-12-05 21:59:51,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:51,724 INFO:     Epoch: 35
2022-12-05 21:59:52,517 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41893188147382304, 'Total loss': 0.41893188147382304} | train loss {'Reaction outcome loss': 0.17720619963127593, 'Total loss': 0.17720619963127593}
2022-12-05 21:59:52,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:52,517 INFO:     Epoch: 36
2022-12-05 21:59:53,313 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3944682482291352, 'Total loss': 0.3944682482291352} | train loss {'Reaction outcome loss': 0.1762489068514181, 'Total loss': 0.1762489068514181}
2022-12-05 21:59:53,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:53,313 INFO:     Epoch: 37
2022-12-05 21:59:54,107 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.40333567796783015, 'Total loss': 0.40333567796783015} | train loss {'Reaction outcome loss': 0.16873636086252689, 'Total loss': 0.16873636086252689}
2022-12-05 21:59:54,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:54,107 INFO:     Epoch: 38
2022-12-05 21:59:54,908 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4097234024242921, 'Total loss': 0.4097234024242921} | train loss {'Reaction outcome loss': 0.17151039974530216, 'Total loss': 0.17151039974530216}
2022-12-05 21:59:54,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:54,910 INFO:     Epoch: 39
2022-12-05 21:59:55,704 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4093657478012822, 'Total loss': 0.4093657478012822} | train loss {'Reaction outcome loss': 0.16945491339785126, 'Total loss': 0.16945491339785126}
2022-12-05 21:59:55,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:55,704 INFO:     Epoch: 40
2022-12-05 21:59:56,498 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4388756223700263, 'Total loss': 0.4388756223700263} | train loss {'Reaction outcome loss': 0.1695263066483654, 'Total loss': 0.1695263066483654}
2022-12-05 21:59:56,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:56,498 INFO:     Epoch: 41
2022-12-05 21:59:57,291 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40578477372500027, 'Total loss': 0.40578477372500027} | train loss {'Reaction outcome loss': 0.16556793087853028, 'Total loss': 0.16556793087853028}
2022-12-05 21:59:57,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:57,291 INFO:     Epoch: 42
2022-12-05 21:59:58,084 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4046963822435249, 'Total loss': 0.4046963822435249} | train loss {'Reaction outcome loss': 0.16478420156883716, 'Total loss': 0.16478420156883716}
2022-12-05 21:59:58,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:58,085 INFO:     Epoch: 43
2022-12-05 21:59:58,877 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39756329933350737, 'Total loss': 0.39756329933350737} | train loss {'Reaction outcome loss': 0.16336790457186912, 'Total loss': 0.16336790457186912}
2022-12-05 21:59:58,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:58,878 INFO:     Epoch: 44
2022-12-05 21:59:59,670 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41332228583368386, 'Total loss': 0.41332228583368386} | train loss {'Reaction outcome loss': 0.16098148843296145, 'Total loss': 0.16098148843296145}
2022-12-05 21:59:59,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 21:59:59,670 INFO:     Epoch: 45
2022-12-05 22:00:00,464 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4238806058737365, 'Total loss': 0.4238806058737365} | train loss {'Reaction outcome loss': 0.1589884731205942, 'Total loss': 0.1589884731205942}
2022-12-05 22:00:00,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:00,464 INFO:     Epoch: 46
2022-12-05 22:00:01,274 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40707353536378255, 'Total loss': 0.40707353536378255} | train loss {'Reaction outcome loss': 0.15965788487084814, 'Total loss': 0.15965788487084814}
2022-12-05 22:00:01,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:01,275 INFO:     Epoch: 47
2022-12-05 22:00:02,078 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4016478932039304, 'Total loss': 0.4016478932039304} | train loss {'Reaction outcome loss': 0.15719510861842134, 'Total loss': 0.15719510861842134}
2022-12-05 22:00:02,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:02,079 INFO:     Epoch: 48
2022-12-05 22:00:02,873 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41597900234840135, 'Total loss': 0.41597900234840135} | train loss {'Reaction outcome loss': 0.15786172487541583, 'Total loss': 0.15786172487541583}
2022-12-05 22:00:02,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:02,873 INFO:     Epoch: 49
2022-12-05 22:00:03,666 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4041728587313132, 'Total loss': 0.4041728587313132} | train loss {'Reaction outcome loss': 0.15644794907270052, 'Total loss': 0.15644794907270052}
2022-12-05 22:00:03,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:03,666 INFO:     Epoch: 50
2022-12-05 22:00:04,459 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4070615980096839, 'Total loss': 0.4070615980096839} | train loss {'Reaction outcome loss': 0.1515862302409734, 'Total loss': 0.1515862302409734}
2022-12-05 22:00:04,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:04,460 INFO:     Epoch: 51
2022-12-05 22:00:05,258 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4346750873056325, 'Total loss': 0.4346750873056325} | train loss {'Reaction outcome loss': 0.15235058677303587, 'Total loss': 0.15235058677303587}
2022-12-05 22:00:05,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:05,258 INFO:     Epoch: 52
2022-12-05 22:00:06,061 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4193596348843791, 'Total loss': 0.4193596348843791} | train loss {'Reaction outcome loss': 0.15109244978379624, 'Total loss': 0.15109244978379624}
2022-12-05 22:00:06,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:06,061 INFO:     Epoch: 53
2022-12-05 22:00:06,859 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3968421299518509, 'Total loss': 0.3968421299518509} | train loss {'Reaction outcome loss': 0.15105513913127092, 'Total loss': 0.15105513913127092}
2022-12-05 22:00:06,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:06,859 INFO:     Epoch: 54
2022-12-05 22:00:07,660 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40759274786846206, 'Total loss': 0.40759274786846206} | train loss {'Reaction outcome loss': 0.15133467219347654, 'Total loss': 0.15133467219347654}
2022-12-05 22:00:07,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:07,661 INFO:     Epoch: 55
2022-12-05 22:00:08,454 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4147467626766725, 'Total loss': 0.4147467626766725} | train loss {'Reaction outcome loss': 0.15097046618138701, 'Total loss': 0.15097046618138701}
2022-12-05 22:00:08,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:08,454 INFO:     Epoch: 56
2022-12-05 22:00:09,246 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40830648047002877, 'Total loss': 0.40830648047002877} | train loss {'Reaction outcome loss': 0.14700182027519051, 'Total loss': 0.14700182027519051}
2022-12-05 22:00:09,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:09,246 INFO:     Epoch: 57
2022-12-05 22:00:10,039 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40697984160347417, 'Total loss': 0.40697984160347417} | train loss {'Reaction outcome loss': 0.14949677468311448, 'Total loss': 0.14949677468311448}
2022-12-05 22:00:10,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:10,039 INFO:     Epoch: 58
2022-12-05 22:00:10,832 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4123533276671713, 'Total loss': 0.4123533276671713} | train loss {'Reaction outcome loss': 0.14702420679075637, 'Total loss': 0.14702420679075637}
2022-12-05 22:00:10,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:10,832 INFO:     Epoch: 59
2022-12-05 22:00:11,624 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4187034545466304, 'Total loss': 0.4187034545466304} | train loss {'Reaction outcome loss': 0.14613671371947054, 'Total loss': 0.14613671371947054}
2022-12-05 22:00:11,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:11,625 INFO:     Epoch: 60
2022-12-05 22:00:12,418 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41702707585963333, 'Total loss': 0.41702707585963333} | train loss {'Reaction outcome loss': 0.14577990922009806, 'Total loss': 0.14577990922009806}
2022-12-05 22:00:12,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:12,418 INFO:     Epoch: 61
2022-12-05 22:00:13,210 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40349762395701627, 'Total loss': 0.40349762395701627} | train loss {'Reaction outcome loss': 0.14244661315792967, 'Total loss': 0.14244661315792967}
2022-12-05 22:00:13,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:13,211 INFO:     Epoch: 62
2022-12-05 22:00:14,003 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4134274111552672, 'Total loss': 0.4134274111552672} | train loss {'Reaction outcome loss': 0.14964147041050288, 'Total loss': 0.14964147041050288}
2022-12-05 22:00:14,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:14,004 INFO:     Epoch: 63
2022-12-05 22:00:14,798 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40991930731318216, 'Total loss': 0.40991930731318216} | train loss {'Reaction outcome loss': 0.15374481618434552, 'Total loss': 0.15374481618434552}
2022-12-05 22:00:14,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:14,798 INFO:     Epoch: 64
2022-12-05 22:00:15,593 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4012720307165926, 'Total loss': 0.4012720307165926} | train loss {'Reaction outcome loss': 0.13969439209668863, 'Total loss': 0.13969439209668863}
2022-12-05 22:00:15,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:15,593 INFO:     Epoch: 65
2022-12-05 22:00:16,386 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4072120833125981, 'Total loss': 0.4072120833125981} | train loss {'Reaction outcome loss': 0.13814917391897574, 'Total loss': 0.13814917391897574}
2022-12-05 22:00:16,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:16,386 INFO:     Epoch: 66
2022-12-05 22:00:17,184 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4072001806714318, 'Total loss': 0.4072001806714318} | train loss {'Reaction outcome loss': 0.14038132232150086, 'Total loss': 0.14038132232150086}
2022-12-05 22:00:17,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:17,185 INFO:     Epoch: 67
2022-12-05 22:00:17,980 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4175254431637851, 'Total loss': 0.4175254431637851} | train loss {'Reaction outcome loss': 0.13696842929084413, 'Total loss': 0.13696842929084413}
2022-12-05 22:00:17,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:17,980 INFO:     Epoch: 68
2022-12-05 22:00:18,778 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4142731184309179, 'Total loss': 0.4142731184309179} | train loss {'Reaction outcome loss': 0.1390467453370934, 'Total loss': 0.1390467453370934}
2022-12-05 22:00:18,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:18,779 INFO:     Epoch: 69
2022-12-05 22:00:19,574 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4058489389717579, 'Total loss': 0.4058489389717579} | train loss {'Reaction outcome loss': 0.13821018849940678, 'Total loss': 0.13821018849940678}
2022-12-05 22:00:19,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:19,575 INFO:     Epoch: 70
2022-12-05 22:00:20,381 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40486108765683393, 'Total loss': 0.40486108765683393} | train loss {'Reaction outcome loss': 0.13632136621033614, 'Total loss': 0.13632136621033614}
2022-12-05 22:00:20,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:20,381 INFO:     Epoch: 71
2022-12-05 22:00:21,183 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42133420147001743, 'Total loss': 0.42133420147001743} | train loss {'Reaction outcome loss': 0.13663089920875998, 'Total loss': 0.13663089920875998}
2022-12-05 22:00:21,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:21,184 INFO:     Epoch: 72
2022-12-05 22:00:21,978 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43900930881500244, 'Total loss': 0.43900930881500244} | train loss {'Reaction outcome loss': 0.1365618073411648, 'Total loss': 0.1365618073411648}
2022-12-05 22:00:21,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:21,978 INFO:     Epoch: 73
2022-12-05 22:00:22,771 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40654282949187537, 'Total loss': 0.40654282949187537} | train loss {'Reaction outcome loss': 0.14224631361180712, 'Total loss': 0.14224631361180712}
2022-12-05 22:00:22,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:22,771 INFO:     Epoch: 74
2022-12-05 22:00:23,562 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41687250713055785, 'Total loss': 0.41687250713055785} | train loss {'Reaction outcome loss': 0.13534434648751006, 'Total loss': 0.13534434648751006}
2022-12-05 22:00:23,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:23,563 INFO:     Epoch: 75
2022-12-05 22:00:24,354 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4039478652517904, 'Total loss': 0.4039478652517904} | train loss {'Reaction outcome loss': 0.13555574897480638, 'Total loss': 0.13555574897480638}
2022-12-05 22:00:24,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:24,355 INFO:     Epoch: 76
2022-12-05 22:00:25,148 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4078064528717236, 'Total loss': 0.4078064528717236} | train loss {'Reaction outcome loss': 0.13253210002352833, 'Total loss': 0.13253210002352833}
2022-12-05 22:00:25,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:25,148 INFO:     Epoch: 77
2022-12-05 22:00:25,940 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4068260314789685, 'Total loss': 0.4068260314789685} | train loss {'Reaction outcome loss': 0.13197529241928138, 'Total loss': 0.13197529241928138}
2022-12-05 22:00:25,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:25,941 INFO:     Epoch: 78
2022-12-05 22:00:26,736 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41223283505744557, 'Total loss': 0.41223283505744557} | train loss {'Reaction outcome loss': 0.13261608406312214, 'Total loss': 0.13261608406312214}
2022-12-05 22:00:26,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:26,737 INFO:     Epoch: 79
2022-12-05 22:00:27,538 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4128201939165592, 'Total loss': 0.4128201939165592} | train loss {'Reaction outcome loss': 0.13175252366147422, 'Total loss': 0.13175252366147422}
2022-12-05 22:00:27,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:27,538 INFO:     Epoch: 80
2022-12-05 22:00:28,335 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41206172785975714, 'Total loss': 0.41206172785975714} | train loss {'Reaction outcome loss': 0.1297492257692674, 'Total loss': 0.1297492257692674}
2022-12-05 22:00:28,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:28,336 INFO:     Epoch: 81
2022-12-05 22:00:29,130 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4105085649273612, 'Total loss': 0.4105085649273612} | train loss {'Reaction outcome loss': 0.1386292482790375, 'Total loss': 0.1386292482790375}
2022-12-05 22:00:29,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:29,130 INFO:     Epoch: 82
2022-12-05 22:00:29,930 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4098837968300689, 'Total loss': 0.4098837968300689} | train loss {'Reaction outcome loss': 0.1411505626092254, 'Total loss': 0.1411505626092254}
2022-12-05 22:00:29,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:29,931 INFO:     Epoch: 83
2022-12-05 22:00:30,724 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4281643561341546, 'Total loss': 0.4281643561341546} | train loss {'Reaction outcome loss': 0.13045240545019446, 'Total loss': 0.13045240545019446}
2022-12-05 22:00:30,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:30,724 INFO:     Epoch: 84
2022-12-05 22:00:31,522 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41529299318790436, 'Total loss': 0.41529299318790436} | train loss {'Reaction outcome loss': 0.12759683231412158, 'Total loss': 0.12759683231412158}
2022-12-05 22:00:31,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:31,522 INFO:     Epoch: 85
2022-12-05 22:00:32,320 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4177890767089345, 'Total loss': 0.4177890767089345} | train loss {'Reaction outcome loss': 0.1301247055363287, 'Total loss': 0.1301247055363287}
2022-12-05 22:00:32,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:32,321 INFO:     Epoch: 86
2022-12-05 22:00:33,116 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41011837700551207, 'Total loss': 0.41011837700551207} | train loss {'Reaction outcome loss': 0.12945063628241238, 'Total loss': 0.12945063628241238}
2022-12-05 22:00:33,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:33,117 INFO:     Epoch: 87
2022-12-05 22:00:33,909 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40131591294299473, 'Total loss': 0.40131591294299473} | train loss {'Reaction outcome loss': 0.12657446190073846, 'Total loss': 0.12657446190073846}
2022-12-05 22:00:33,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:33,909 INFO:     Epoch: 88
2022-12-05 22:00:34,709 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4082248745994134, 'Total loss': 0.4082248745994134} | train loss {'Reaction outcome loss': 0.1297446252982724, 'Total loss': 0.1297446252982724}
2022-12-05 22:00:34,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:34,709 INFO:     Epoch: 89
2022-12-05 22:00:35,506 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4251788112927567, 'Total loss': 0.4251788112927567} | train loss {'Reaction outcome loss': 0.12843476429672135, 'Total loss': 0.12843476429672135}
2022-12-05 22:00:35,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:35,506 INFO:     Epoch: 90
2022-12-05 22:00:36,304 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4040344980630008, 'Total loss': 0.4040344980630008} | train loss {'Reaction outcome loss': 0.12869769932517428, 'Total loss': 0.12869769932517428}
2022-12-05 22:00:36,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:36,304 INFO:     Epoch: 91
2022-12-05 22:00:37,100 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4176539240235632, 'Total loss': 0.4176539240235632} | train loss {'Reaction outcome loss': 0.1266924628746594, 'Total loss': 0.1266924628746594}
2022-12-05 22:00:37,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:37,100 INFO:     Epoch: 92
2022-12-05 22:00:37,893 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41094591333107516, 'Total loss': 0.41094591333107516} | train loss {'Reaction outcome loss': 0.12594859554434218, 'Total loss': 0.12594859554434218}
2022-12-05 22:00:37,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:37,893 INFO:     Epoch: 93
2022-12-05 22:00:38,687 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42068953575058415, 'Total loss': 0.42068953575058415} | train loss {'Reaction outcome loss': 0.12508774148903576, 'Total loss': 0.12508774148903576}
2022-12-05 22:00:38,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:38,687 INFO:     Epoch: 94
2022-12-05 22:00:39,482 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.406097397970205, 'Total loss': 0.406097397970205} | train loss {'Reaction outcome loss': 0.12321383509641656, 'Total loss': 0.12321383509641656}
2022-12-05 22:00:39,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:39,482 INFO:     Epoch: 95
2022-12-05 22:00:40,275 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44172914360057225, 'Total loss': 0.44172914360057225} | train loss {'Reaction outcome loss': 0.12633798553453765, 'Total loss': 0.12633798553453765}
2022-12-05 22:00:40,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:40,275 INFO:     Epoch: 96
2022-12-05 22:00:41,071 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4309025284918872, 'Total loss': 0.4309025284918872} | train loss {'Reaction outcome loss': 0.13520190654405456, 'Total loss': 0.13520190654405456}
2022-12-05 22:00:41,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:41,071 INFO:     Epoch: 97
2022-12-05 22:00:41,869 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4168268215249885, 'Total loss': 0.4168268215249885} | train loss {'Reaction outcome loss': 0.13409989234814157, 'Total loss': 0.13409989234814157}
2022-12-05 22:00:41,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:41,869 INFO:     Epoch: 98
2022-12-05 22:00:42,664 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4086823043498126, 'Total loss': 0.4086823043498126} | train loss {'Reaction outcome loss': 0.13007614998569192, 'Total loss': 0.13007614998569192}
2022-12-05 22:00:42,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:42,664 INFO:     Epoch: 99
2022-12-05 22:00:43,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4009904573586854, 'Total loss': 0.4009904573586854} | train loss {'Reaction outcome loss': 0.12275034023320627, 'Total loss': 0.12275034023320627}
2022-12-05 22:00:43,455 INFO:     Best model found after epoch 21 of 100.
2022-12-05 22:00:43,456 INFO:   Done with stage: TRAINING
2022-12-05 22:00:43,456 INFO:   Starting stage: EVALUATION
2022-12-05 22:00:43,581 INFO:   Done with stage: EVALUATION
2022-12-05 22:00:43,590 INFO:   Leaving out SEQ value Fold_0
2022-12-05 22:00:43,602 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:00:43,602 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:00:44,236 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:00:44,236 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:00:44,304 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:00:44,304 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:00:44,305 INFO:     No hyperparam tuning for this model
2022-12-05 22:00:44,305 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:00:44,305 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:00:44,305 INFO:     None feature selector for col prot
2022-12-05 22:00:44,305 INFO:     None feature selector for col prot
2022-12-05 22:00:44,306 INFO:     None feature selector for col prot
2022-12-05 22:00:44,306 INFO:     None feature selector for col chem
2022-12-05 22:00:44,306 INFO:     None feature selector for col chem
2022-12-05 22:00:44,306 INFO:     None feature selector for col chem
2022-12-05 22:00:44,306 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:00:44,306 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:00:44,308 INFO:     Number of params in model 215821
2022-12-05 22:00:44,311 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:00:44,311 INFO:   Starting stage: TRAINING
2022-12-05 22:00:44,372 INFO:     Val loss before train {'Reaction outcome loss': 0.9432724070819941, 'Total loss': 0.9432724070819941}
2022-12-05 22:00:44,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:44,373 INFO:     Epoch: 0
2022-12-05 22:00:45,159 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5889623205770146, 'Total loss': 0.5889623205770146} | train loss {'Reaction outcome loss': 0.7868645888202045, 'Total loss': 0.7868645888202045}
2022-12-05 22:00:45,159 INFO:     Found new best model at epoch 0
2022-12-05 22:00:45,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:45,160 INFO:     Epoch: 1
2022-12-05 22:00:45,947 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5171032053503123, 'Total loss': 0.5171032053503123} | train loss {'Reaction outcome loss': 0.5395564428397588, 'Total loss': 0.5395564428397588}
2022-12-05 22:00:45,947 INFO:     Found new best model at epoch 1
2022-12-05 22:00:45,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:45,948 INFO:     Epoch: 2
2022-12-05 22:00:46,737 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48175231367349625, 'Total loss': 0.48175231367349625} | train loss {'Reaction outcome loss': 0.46972229413840233, 'Total loss': 0.46972229413840233}
2022-12-05 22:00:46,738 INFO:     Found new best model at epoch 2
2022-12-05 22:00:46,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:46,738 INFO:     Epoch: 3
2022-12-05 22:00:47,529 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4578396793116223, 'Total loss': 0.4578396793116223} | train loss {'Reaction outcome loss': 0.4291743802781008, 'Total loss': 0.4291743802781008}
2022-12-05 22:00:47,529 INFO:     Found new best model at epoch 3
2022-12-05 22:00:47,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:47,530 INFO:     Epoch: 4
2022-12-05 22:00:48,315 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4553232971917499, 'Total loss': 0.4553232971917499} | train loss {'Reaction outcome loss': 0.398404994850256, 'Total loss': 0.398404994850256}
2022-12-05 22:00:48,315 INFO:     Found new best model at epoch 4
2022-12-05 22:00:48,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:48,316 INFO:     Epoch: 5
2022-12-05 22:00:49,104 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4389493384144523, 'Total loss': 0.4389493384144523} | train loss {'Reaction outcome loss': 0.3788778184019789, 'Total loss': 0.3788778184019789}
2022-12-05 22:00:49,104 INFO:     Found new best model at epoch 5
2022-12-05 22:00:49,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:49,105 INFO:     Epoch: 6
2022-12-05 22:00:49,897 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43878313729708845, 'Total loss': 0.43878313729708845} | train loss {'Reaction outcome loss': 0.35604195451858095, 'Total loss': 0.35604195451858095}
2022-12-05 22:00:49,897 INFO:     Found new best model at epoch 6
2022-12-05 22:00:49,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:49,898 INFO:     Epoch: 7
2022-12-05 22:00:50,688 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4284394220872359, 'Total loss': 0.4284394220872359} | train loss {'Reaction outcome loss': 0.338531654221671, 'Total loss': 0.338531654221671}
2022-12-05 22:00:50,688 INFO:     Found new best model at epoch 7
2022-12-05 22:00:50,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:50,689 INFO:     Epoch: 8
2022-12-05 22:00:51,477 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42298817668448796, 'Total loss': 0.42298817668448796} | train loss {'Reaction outcome loss': 0.32189677448905246, 'Total loss': 0.32189677448905246}
2022-12-05 22:00:51,477 INFO:     Found new best model at epoch 8
2022-12-05 22:00:51,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:51,478 INFO:     Epoch: 9
2022-12-05 22:00:52,265 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41164281947368925, 'Total loss': 0.41164281947368925} | train loss {'Reaction outcome loss': 0.3083168520002949, 'Total loss': 0.3083168520002949}
2022-12-05 22:00:52,266 INFO:     Found new best model at epoch 9
2022-12-05 22:00:52,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:52,266 INFO:     Epoch: 10
2022-12-05 22:00:53,058 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4169594631953673, 'Total loss': 0.4169594631953673} | train loss {'Reaction outcome loss': 0.2946725296122687, 'Total loss': 0.2946725296122687}
2022-12-05 22:00:53,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:53,058 INFO:     Epoch: 11
2022-12-05 22:00:53,842 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42664146287874744, 'Total loss': 0.42664146287874744} | train loss {'Reaction outcome loss': 0.28157494539509015, 'Total loss': 0.28157494539509015}
2022-12-05 22:00:53,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:53,842 INFO:     Epoch: 12
2022-12-05 22:00:54,626 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4249630966647105, 'Total loss': 0.4249630966647105} | train loss {'Reaction outcome loss': 0.2746404698612739, 'Total loss': 0.2746404698612739}
2022-12-05 22:00:54,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:54,626 INFO:     Epoch: 13
2022-12-05 22:00:55,410 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40953682646663353, 'Total loss': 0.40953682646663353} | train loss {'Reaction outcome loss': 0.26250235818478523, 'Total loss': 0.26250235818478523}
2022-12-05 22:00:55,410 INFO:     Found new best model at epoch 13
2022-12-05 22:00:55,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:55,411 INFO:     Epoch: 14
2022-12-05 22:00:56,193 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4170081579888409, 'Total loss': 0.4170081579888409} | train loss {'Reaction outcome loss': 0.2531796183665188, 'Total loss': 0.2531796183665188}
2022-12-05 22:00:56,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:56,193 INFO:     Epoch: 15
2022-12-05 22:00:56,977 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4231644078073176, 'Total loss': 0.4231644078073176} | train loss {'Reaction outcome loss': 0.24366103048835483, 'Total loss': 0.24366103048835483}
2022-12-05 22:00:56,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:56,978 INFO:     Epoch: 16
2022-12-05 22:00:57,762 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41738223179709166, 'Total loss': 0.41738223179709166} | train loss {'Reaction outcome loss': 0.23925045803189277, 'Total loss': 0.23925045803189277}
2022-12-05 22:00:57,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:57,762 INFO:     Epoch: 17
2022-12-05 22:00:58,545 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4298677380112084, 'Total loss': 0.4298677380112084} | train loss {'Reaction outcome loss': 0.23466082817437697, 'Total loss': 0.23466082817437697}
2022-12-05 22:00:58,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:58,545 INFO:     Epoch: 18
2022-12-05 22:00:59,332 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4307241179049015, 'Total loss': 0.4307241179049015} | train loss {'Reaction outcome loss': 0.2259204321369833, 'Total loss': 0.2259204321369833}
2022-12-05 22:00:59,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:00:59,333 INFO:     Epoch: 19
2022-12-05 22:01:00,116 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43525117297064175, 'Total loss': 0.43525117297064175} | train loss {'Reaction outcome loss': 0.2185320112131992, 'Total loss': 0.2185320112131992}
2022-12-05 22:01:00,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:00,117 INFO:     Epoch: 20
2022-12-05 22:01:00,899 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4319236505437981, 'Total loss': 0.4319236505437981} | train loss {'Reaction outcome loss': 0.21462903734372588, 'Total loss': 0.21462903734372588}
2022-12-05 22:01:00,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:00,900 INFO:     Epoch: 21
2022-12-05 22:01:01,686 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43402767621658067, 'Total loss': 0.43402767621658067} | train loss {'Reaction outcome loss': 0.20864685728233687, 'Total loss': 0.20864685728233687}
2022-12-05 22:01:01,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:01,686 INFO:     Epoch: 22
2022-12-05 22:01:02,473 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4235289818183942, 'Total loss': 0.4235289818183942} | train loss {'Reaction outcome loss': 0.20512393247716282, 'Total loss': 0.20512393247716282}
2022-12-05 22:01:02,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:02,474 INFO:     Epoch: 23
2022-12-05 22:01:03,258 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.435990782962604, 'Total loss': 0.435990782962604} | train loss {'Reaction outcome loss': 0.19859330427585817, 'Total loss': 0.19859330427585817}
2022-12-05 22:01:03,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:03,259 INFO:     Epoch: 24
2022-12-05 22:01:04,044 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4216342263601043, 'Total loss': 0.4216342263601043} | train loss {'Reaction outcome loss': 0.1969752598781975, 'Total loss': 0.1969752598781975}
2022-12-05 22:01:04,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:04,044 INFO:     Epoch: 25
2022-12-05 22:01:04,833 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4473402202129364, 'Total loss': 0.4473402202129364} | train loss {'Reaction outcome loss': 0.1908656165535961, 'Total loss': 0.1908656165535961}
2022-12-05 22:01:04,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:04,833 INFO:     Epoch: 26
2022-12-05 22:01:05,622 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43357595564289525, 'Total loss': 0.43357595564289525} | train loss {'Reaction outcome loss': 0.18859949863078643, 'Total loss': 0.18859949863078643}
2022-12-05 22:01:05,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:05,623 INFO:     Epoch: 27
2022-12-05 22:01:06,407 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4364860577043146, 'Total loss': 0.4364860577043146} | train loss {'Reaction outcome loss': 0.18310850285449806, 'Total loss': 0.18310850285449806}
2022-12-05 22:01:06,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:06,408 INFO:     Epoch: 28
2022-12-05 22:01:07,195 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42991645058447664, 'Total loss': 0.42991645058447664} | train loss {'Reaction outcome loss': 0.1814270335648741, 'Total loss': 0.1814270335648741}
2022-12-05 22:01:07,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:07,195 INFO:     Epoch: 29
2022-12-05 22:01:07,981 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43515102192759514, 'Total loss': 0.43515102192759514} | train loss {'Reaction outcome loss': 0.1771007178389296, 'Total loss': 0.1771007178389296}
2022-12-05 22:01:07,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:07,981 INFO:     Epoch: 30
2022-12-05 22:01:08,769 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42168661528690293, 'Total loss': 0.42168661528690293} | train loss {'Reaction outcome loss': 0.17726814099112337, 'Total loss': 0.17726814099112337}
2022-12-05 22:01:08,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:08,770 INFO:     Epoch: 31
2022-12-05 22:01:09,557 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43900521912358026, 'Total loss': 0.43900521912358026} | train loss {'Reaction outcome loss': 0.1727139690624816, 'Total loss': 0.1727139690624816}
2022-12-05 22:01:09,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:09,557 INFO:     Epoch: 32
2022-12-05 22:01:10,341 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4360691701824015, 'Total loss': 0.4360691701824015} | train loss {'Reaction outcome loss': 0.17193128092556584, 'Total loss': 0.17193128092556584}
2022-12-05 22:01:10,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:10,341 INFO:     Epoch: 33
2022-12-05 22:01:11,130 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4503821490163153, 'Total loss': 0.4503821490163153} | train loss {'Reaction outcome loss': 0.16730983381216624, 'Total loss': 0.16730983381216624}
2022-12-05 22:01:11,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:11,130 INFO:     Epoch: 34
2022-12-05 22:01:11,918 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42882811972363427, 'Total loss': 0.42882811972363427} | train loss {'Reaction outcome loss': 0.16710322352544385, 'Total loss': 0.16710322352544385}
2022-12-05 22:01:11,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:11,918 INFO:     Epoch: 35
2022-12-05 22:01:12,709 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4204519231888381, 'Total loss': 0.4204519231888381} | train loss {'Reaction outcome loss': 0.16518153430399846, 'Total loss': 0.16518153430399846}
2022-12-05 22:01:12,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:12,709 INFO:     Epoch: 36
2022-12-05 22:01:13,496 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4396579516204921, 'Total loss': 0.4396579516204921} | train loss {'Reaction outcome loss': 0.16394751523526346, 'Total loss': 0.16394751523526346}
2022-12-05 22:01:13,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:13,496 INFO:     Epoch: 37
2022-12-05 22:01:14,280 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4522992833094163, 'Total loss': 0.4522992833094163} | train loss {'Reaction outcome loss': 0.1588529807952594, 'Total loss': 0.1588529807952594}
2022-12-05 22:01:14,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:14,280 INFO:     Epoch: 38
2022-12-05 22:01:15,068 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4505139487710866, 'Total loss': 0.4505139487710866} | train loss {'Reaction outcome loss': 0.1621419741791122, 'Total loss': 0.1621419741791122}
2022-12-05 22:01:15,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:15,068 INFO:     Epoch: 39
2022-12-05 22:01:15,858 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45286153290759434, 'Total loss': 0.45286153290759434} | train loss {'Reaction outcome loss': 0.1570249434940669, 'Total loss': 0.1570249434940669}
2022-12-05 22:01:15,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:15,859 INFO:     Epoch: 40
2022-12-05 22:01:16,645 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4456882039931687, 'Total loss': 0.4456882039931687} | train loss {'Reaction outcome loss': 0.1539283142330087, 'Total loss': 0.1539283142330087}
2022-12-05 22:01:16,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:16,646 INFO:     Epoch: 41
2022-12-05 22:01:17,432 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4399051256477833, 'Total loss': 0.4399051256477833} | train loss {'Reaction outcome loss': 0.1534401949228985, 'Total loss': 0.1534401949228985}
2022-12-05 22:01:17,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:17,432 INFO:     Epoch: 42
2022-12-05 22:01:18,217 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4368369254198941, 'Total loss': 0.4368369254198941} | train loss {'Reaction outcome loss': 0.15128517099181, 'Total loss': 0.15128517099181}
2022-12-05 22:01:18,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:18,217 INFO:     Epoch: 43
2022-12-05 22:01:19,006 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44947751001878217, 'Total loss': 0.44947751001878217} | train loss {'Reaction outcome loss': 0.15160846212232598, 'Total loss': 0.15160846212232598}
2022-12-05 22:01:19,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:19,007 INFO:     Epoch: 44
2022-12-05 22:01:19,792 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4276922990313985, 'Total loss': 0.4276922990313985} | train loss {'Reaction outcome loss': 0.1495248571912549, 'Total loss': 0.1495248571912549}
2022-12-05 22:01:19,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:19,793 INFO:     Epoch: 45
2022-12-05 22:01:20,578 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42933017845180904, 'Total loss': 0.42933017845180904} | train loss {'Reaction outcome loss': 0.1484122729271042, 'Total loss': 0.1484122729271042}
2022-12-05 22:01:20,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:20,579 INFO:     Epoch: 46
2022-12-05 22:01:21,364 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44195354052565317, 'Total loss': 0.44195354052565317} | train loss {'Reaction outcome loss': 0.14860699507502878, 'Total loss': 0.14860699507502878}
2022-12-05 22:01:21,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:21,365 INFO:     Epoch: 47
2022-12-05 22:01:22,153 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4474813189696182, 'Total loss': 0.4474813189696182} | train loss {'Reaction outcome loss': 0.14676833515796733, 'Total loss': 0.14676833515796733}
2022-12-05 22:01:22,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:22,153 INFO:     Epoch: 48
2022-12-05 22:01:22,940 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4372042657130144, 'Total loss': 0.4372042657130144} | train loss {'Reaction outcome loss': 0.14511166452905352, 'Total loss': 0.14511166452905352}
2022-12-05 22:01:22,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:22,940 INFO:     Epoch: 49
2022-12-05 22:01:23,724 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4472821331159635, 'Total loss': 0.4472821331159635} | train loss {'Reaction outcome loss': 0.1440010371104795, 'Total loss': 0.1440010371104795}
2022-12-05 22:01:23,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:23,724 INFO:     Epoch: 50
2022-12-05 22:01:24,507 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4423617877235467, 'Total loss': 0.4423617877235467} | train loss {'Reaction outcome loss': 0.14266752222818987, 'Total loss': 0.14266752222818987}
2022-12-05 22:01:24,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:24,508 INFO:     Epoch: 51
2022-12-05 22:01:25,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4542183303697543, 'Total loss': 0.4542183303697543} | train loss {'Reaction outcome loss': 0.1418882181829944, 'Total loss': 0.1418882181829944}
2022-12-05 22:01:25,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:25,292 INFO:     Epoch: 52
2022-12-05 22:01:26,078 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45701850882985373, 'Total loss': 0.45701850882985373} | train loss {'Reaction outcome loss': 0.14135713144680676, 'Total loss': 0.14135713144680676}
2022-12-05 22:01:26,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:26,079 INFO:     Epoch: 53
2022-12-05 22:01:26,868 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4452173069796779, 'Total loss': 0.4452173069796779} | train loss {'Reaction outcome loss': 0.13971432793353286, 'Total loss': 0.13971432793353286}
2022-12-05 22:01:26,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:26,869 INFO:     Epoch: 54
2022-12-05 22:01:27,654 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4362567158585245, 'Total loss': 0.4362567158585245} | train loss {'Reaction outcome loss': 0.13977786459180774, 'Total loss': 0.13977786459180774}
2022-12-05 22:01:27,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:27,655 INFO:     Epoch: 55
2022-12-05 22:01:28,442 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43172876740043814, 'Total loss': 0.43172876740043814} | train loss {'Reaction outcome loss': 0.14022343237029047, 'Total loss': 0.14022343237029047}
2022-12-05 22:01:28,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:28,442 INFO:     Epoch: 56
2022-12-05 22:01:29,227 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.447878140786832, 'Total loss': 0.447878140786832} | train loss {'Reaction outcome loss': 0.13876612650952777, 'Total loss': 0.13876612650952777}
2022-12-05 22:01:29,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:29,227 INFO:     Epoch: 57
2022-12-05 22:01:30,014 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43810067330063746, 'Total loss': 0.43810067330063746} | train loss {'Reaction outcome loss': 0.13738668566303594, 'Total loss': 0.13738668566303594}
2022-12-05 22:01:30,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:30,014 INFO:     Epoch: 58
2022-12-05 22:01:30,803 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43756945498965005, 'Total loss': 0.43756945498965005} | train loss {'Reaction outcome loss': 0.13529391671169777, 'Total loss': 0.13529391671169777}
2022-12-05 22:01:30,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:30,803 INFO:     Epoch: 59
2022-12-05 22:01:31,592 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4581152463162487, 'Total loss': 0.4581152463162487} | train loss {'Reaction outcome loss': 0.13500771404681158, 'Total loss': 0.13500771404681158}
2022-12-05 22:01:31,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:31,592 INFO:     Epoch: 60
2022-12-05 22:01:32,376 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45147341557524423, 'Total loss': 0.45147341557524423} | train loss {'Reaction outcome loss': 0.1352353102014381, 'Total loss': 0.1352353102014381}
2022-12-05 22:01:32,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:32,376 INFO:     Epoch: 61
2022-12-05 22:01:33,165 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42927892065861006, 'Total loss': 0.42927892065861006} | train loss {'Reaction outcome loss': 0.1371677830055052, 'Total loss': 0.1371677830055052}
2022-12-05 22:01:33,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:33,165 INFO:     Epoch: 62
2022-12-05 22:01:33,953 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.439594375138933, 'Total loss': 0.439594375138933} | train loss {'Reaction outcome loss': 0.1330918507498442, 'Total loss': 0.1330918507498442}
2022-12-05 22:01:33,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:33,954 INFO:     Epoch: 63
2022-12-05 22:01:34,742 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46217657591808925, 'Total loss': 0.46217657591808925} | train loss {'Reaction outcome loss': 0.13250718135766837, 'Total loss': 0.13250718135766837}
2022-12-05 22:01:34,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:34,742 INFO:     Epoch: 64
2022-12-05 22:01:35,529 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4445493827489289, 'Total loss': 0.4445493827489289} | train loss {'Reaction outcome loss': 0.13241710029542447, 'Total loss': 0.13241710029542447}
2022-12-05 22:01:35,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:35,529 INFO:     Epoch: 65
2022-12-05 22:01:36,316 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44886062836105173, 'Total loss': 0.44886062836105173} | train loss {'Reaction outcome loss': 0.13159474215033104, 'Total loss': 0.13159474215033104}
2022-12-05 22:01:36,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:36,316 INFO:     Epoch: 66
2022-12-05 22:01:37,100 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4442110584032806, 'Total loss': 0.4442110584032806} | train loss {'Reaction outcome loss': 0.1303405508741128, 'Total loss': 0.1303405508741128}
2022-12-05 22:01:37,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:37,100 INFO:     Epoch: 67
2022-12-05 22:01:37,891 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4529966287187893, 'Total loss': 0.4529966287187893} | train loss {'Reaction outcome loss': 0.13066802608723543, 'Total loss': 0.13066802608723543}
2022-12-05 22:01:37,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:37,892 INFO:     Epoch: 68
2022-12-05 22:01:38,675 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45094865120270033, 'Total loss': 0.45094865120270033} | train loss {'Reaction outcome loss': 0.1280457813558834, 'Total loss': 0.1280457813558834}
2022-12-05 22:01:38,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:38,675 INFO:     Epoch: 69
2022-12-05 22:01:39,459 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4404776811769063, 'Total loss': 0.4404776811769063} | train loss {'Reaction outcome loss': 0.12867882568389177, 'Total loss': 0.12867882568389177}
2022-12-05 22:01:39,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:39,460 INFO:     Epoch: 70
2022-12-05 22:01:40,252 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4459638048640706, 'Total loss': 0.4459638048640706} | train loss {'Reaction outcome loss': 0.1292846318980565, 'Total loss': 0.1292846318980565}
2022-12-05 22:01:40,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:40,252 INFO:     Epoch: 71
2022-12-05 22:01:41,042 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46159825033762236, 'Total loss': 0.46159825033762236} | train loss {'Reaction outcome loss': 0.12815137462006235, 'Total loss': 0.12815137462006235}
2022-12-05 22:01:41,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:41,042 INFO:     Epoch: 72
2022-12-05 22:01:41,826 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4565604081885381, 'Total loss': 0.4565604081885381} | train loss {'Reaction outcome loss': 0.13027923035302333, 'Total loss': 0.13027923035302333}
2022-12-05 22:01:41,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:41,826 INFO:     Epoch: 73
2022-12-05 22:01:42,610 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4419368233701045, 'Total loss': 0.4419368233701045} | train loss {'Reaction outcome loss': 0.1276494509179373, 'Total loss': 0.1276494509179373}
2022-12-05 22:01:42,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:42,611 INFO:     Epoch: 74
2022-12-05 22:01:43,402 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4465588256716728, 'Total loss': 0.4465588256716728} | train loss {'Reaction outcome loss': 0.12727893295944953, 'Total loss': 0.12727893295944953}
2022-12-05 22:01:43,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:43,402 INFO:     Epoch: 75
2022-12-05 22:01:44,186 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45816237530247733, 'Total loss': 0.45816237530247733} | train loss {'Reaction outcome loss': 0.12829724218772381, 'Total loss': 0.12829724218772381}
2022-12-05 22:01:44,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:44,187 INFO:     Epoch: 76
2022-12-05 22:01:44,976 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4592396369711919, 'Total loss': 0.4592396369711919} | train loss {'Reaction outcome loss': 0.12702759768509744, 'Total loss': 0.12702759768509744}
2022-12-05 22:01:44,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:44,976 INFO:     Epoch: 77
2022-12-05 22:01:45,763 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4527132837948474, 'Total loss': 0.4527132837948474} | train loss {'Reaction outcome loss': 0.12452274091465741, 'Total loss': 0.12452274091465741}
2022-12-05 22:01:45,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:45,763 INFO:     Epoch: 78
2022-12-05 22:01:46,549 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4701512032611804, 'Total loss': 0.4701512032611804} | train loss {'Reaction outcome loss': 0.12656236200080234, 'Total loss': 0.12656236200080234}
2022-12-05 22:01:46,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:46,550 INFO:     Epoch: 79
2022-12-05 22:01:47,336 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4617113589563153, 'Total loss': 0.4617113589563153} | train loss {'Reaction outcome loss': 0.1251362242983008, 'Total loss': 0.1251362242983008}
2022-12-05 22:01:47,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:47,336 INFO:     Epoch: 80
2022-12-05 22:01:48,122 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4704595912586559, 'Total loss': 0.4704595912586559} | train loss {'Reaction outcome loss': 0.12679068078952177, 'Total loss': 0.12679068078952177}
2022-12-05 22:01:48,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:48,123 INFO:     Epoch: 81
2022-12-05 22:01:48,908 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46365615082058037, 'Total loss': 0.46365615082058037} | train loss {'Reaction outcome loss': 0.12173181827731279, 'Total loss': 0.12173181827731279}
2022-12-05 22:01:48,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:48,908 INFO:     Epoch: 82
2022-12-05 22:01:49,694 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4638525565916842, 'Total loss': 0.4638525565916842} | train loss {'Reaction outcome loss': 0.12347790030192356, 'Total loss': 0.12347790030192356}
2022-12-05 22:01:49,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:49,694 INFO:     Epoch: 83
2022-12-05 22:01:50,484 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43934747407382185, 'Total loss': 0.43934747407382185} | train loss {'Reaction outcome loss': 0.12508239167153226, 'Total loss': 0.12508239167153226}
2022-12-05 22:01:50,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:50,485 INFO:     Epoch: 84
2022-12-05 22:01:51,276 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44359521025961096, 'Total loss': 0.44359521025961096} | train loss {'Reaction outcome loss': 0.12297149628628881, 'Total loss': 0.12297149628628881}
2022-12-05 22:01:51,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:51,276 INFO:     Epoch: 85
2022-12-05 22:01:52,066 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46048440445553174, 'Total loss': 0.46048440445553174} | train loss {'Reaction outcome loss': 0.1220157493552079, 'Total loss': 0.1220157493552079}
2022-12-05 22:01:52,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:52,066 INFO:     Epoch: 86
2022-12-05 22:01:52,864 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44902663644064555, 'Total loss': 0.44902663644064555} | train loss {'Reaction outcome loss': 0.1235518456835832, 'Total loss': 0.1235518456835832}
2022-12-05 22:01:52,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:52,864 INFO:     Epoch: 87
2022-12-05 22:01:53,656 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4442998449879021, 'Total loss': 0.4442998449879021} | train loss {'Reaction outcome loss': 0.11989559103563732, 'Total loss': 0.11989559103563732}
2022-12-05 22:01:53,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:53,656 INFO:     Epoch: 88
2022-12-05 22:01:54,445 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4573670791631395, 'Total loss': 0.4573670791631395} | train loss {'Reaction outcome loss': 0.1251484415436886, 'Total loss': 0.1251484415436886}
2022-12-05 22:01:54,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:54,445 INFO:     Epoch: 89
2022-12-05 22:01:55,232 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4404526369815523, 'Total loss': 0.4404526369815523} | train loss {'Reaction outcome loss': 0.1209309824191186, 'Total loss': 0.1209309824191186}
2022-12-05 22:01:55,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:55,232 INFO:     Epoch: 90
2022-12-05 22:01:56,021 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45475445670837705, 'Total loss': 0.45475445670837705} | train loss {'Reaction outcome loss': 0.12223915578797459, 'Total loss': 0.12223915578797459}
2022-12-05 22:01:56,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:56,021 INFO:     Epoch: 91
2022-12-05 22:01:56,808 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4627526680176908, 'Total loss': 0.4627526680176908} | train loss {'Reaction outcome loss': 0.12056977632550561, 'Total loss': 0.12056977632550561}
2022-12-05 22:01:56,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:56,808 INFO:     Epoch: 92
2022-12-05 22:01:57,601 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4515803561291911, 'Total loss': 0.4515803561291911} | train loss {'Reaction outcome loss': 0.1237581895816387, 'Total loss': 0.1237581895816387}
2022-12-05 22:01:57,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:57,601 INFO:     Epoch: 93
2022-12-05 22:01:58,388 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46001994440501387, 'Total loss': 0.46001994440501387} | train loss {'Reaction outcome loss': 0.12032646746659766, 'Total loss': 0.12032646746659766}
2022-12-05 22:01:58,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:58,388 INFO:     Epoch: 94
2022-12-05 22:01:59,175 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45448266562413087, 'Total loss': 0.45448266562413087} | train loss {'Reaction outcome loss': 0.12306572348639673, 'Total loss': 0.12306572348639673}
2022-12-05 22:01:59,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:59,176 INFO:     Epoch: 95
2022-12-05 22:01:59,963 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4795109856535088, 'Total loss': 0.4795109856535088} | train loss {'Reaction outcome loss': 0.12065892892376501, 'Total loss': 0.12065892892376501}
2022-12-05 22:01:59,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:01:59,964 INFO:     Epoch: 96
2022-12-05 22:02:00,750 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43984406303868373, 'Total loss': 0.43984406303868373} | train loss {'Reaction outcome loss': 0.11936417780436423, 'Total loss': 0.11936417780436423}
2022-12-05 22:02:00,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:00,750 INFO:     Epoch: 97
2022-12-05 22:02:01,540 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45239454778757965, 'Total loss': 0.45239454778757965} | train loss {'Reaction outcome loss': 0.12125586570829762, 'Total loss': 0.12125586570829762}
2022-12-05 22:02:01,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:01,540 INFO:     Epoch: 98
2022-12-05 22:02:02,326 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4422141987491738, 'Total loss': 0.4422141987491738} | train loss {'Reaction outcome loss': 0.11911299018835535, 'Total loss': 0.11911299018835535}
2022-12-05 22:02:02,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:02,326 INFO:     Epoch: 99
2022-12-05 22:02:03,114 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4584058921106837, 'Total loss': 0.4584058921106837} | train loss {'Reaction outcome loss': 0.11759782351021256, 'Total loss': 0.11759782351021256}
2022-12-05 22:02:03,115 INFO:     Best model found after epoch 14 of 100.
2022-12-05 22:02:03,115 INFO:   Done with stage: TRAINING
2022-12-05 22:02:03,115 INFO:   Starting stage: EVALUATION
2022-12-05 22:02:03,246 INFO:   Done with stage: EVALUATION
2022-12-05 22:02:03,246 INFO:   Leaving out SEQ value Fold_1
2022-12-05 22:02:03,259 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 22:02:03,259 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:02:03,891 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:02:03,891 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:02:03,960 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:02:03,960 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:02:03,960 INFO:     No hyperparam tuning for this model
2022-12-05 22:02:03,960 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:02:03,960 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:02:03,961 INFO:     None feature selector for col prot
2022-12-05 22:02:03,961 INFO:     None feature selector for col prot
2022-12-05 22:02:03,961 INFO:     None feature selector for col prot
2022-12-05 22:02:03,962 INFO:     None feature selector for col chem
2022-12-05 22:02:03,962 INFO:     None feature selector for col chem
2022-12-05 22:02:03,962 INFO:     None feature selector for col chem
2022-12-05 22:02:03,962 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:02:03,962 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:02:03,964 INFO:     Number of params in model 215821
2022-12-05 22:02:03,967 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:02:03,967 INFO:   Starting stage: TRAINING
2022-12-05 22:02:04,026 INFO:     Val loss before train {'Reaction outcome loss': 0.9219615445580593, 'Total loss': 0.9219615445580593}
2022-12-05 22:02:04,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:04,026 INFO:     Epoch: 0
2022-12-05 22:02:04,808 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5462883218776348, 'Total loss': 0.5462883218776348} | train loss {'Reaction outcome loss': 0.8024887734504996, 'Total loss': 0.8024887734504996}
2022-12-05 22:02:04,808 INFO:     Found new best model at epoch 0
2022-12-05 22:02:04,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:04,809 INFO:     Epoch: 1
2022-12-05 22:02:05,589 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47240309798440266, 'Total loss': 0.47240309798440266} | train loss {'Reaction outcome loss': 0.5395713822885615, 'Total loss': 0.5395713822885615}
2022-12-05 22:02:05,589 INFO:     Found new best model at epoch 1
2022-12-05 22:02:05,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:05,590 INFO:     Epoch: 2
2022-12-05 22:02:06,377 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44369058518908744, 'Total loss': 0.44369058518908744} | train loss {'Reaction outcome loss': 0.47128976405155465, 'Total loss': 0.47128976405155465}
2022-12-05 22:02:06,377 INFO:     Found new best model at epoch 2
2022-12-05 22:02:06,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:06,378 INFO:     Epoch: 3
2022-12-05 22:02:07,163 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4308019280433655, 'Total loss': 0.4308019280433655} | train loss {'Reaction outcome loss': 0.43526643661201975, 'Total loss': 0.43526643661201975}
2022-12-05 22:02:07,163 INFO:     Found new best model at epoch 3
2022-12-05 22:02:07,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:07,164 INFO:     Epoch: 4
2022-12-05 22:02:07,948 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42557139833306157, 'Total loss': 0.42557139833306157} | train loss {'Reaction outcome loss': 0.4065714705674375, 'Total loss': 0.4065714705674375}
2022-12-05 22:02:07,949 INFO:     Found new best model at epoch 4
2022-12-05 22:02:07,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:07,950 INFO:     Epoch: 5
2022-12-05 22:02:08,738 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4117952782747357, 'Total loss': 0.4117952782747357} | train loss {'Reaction outcome loss': 0.3844834981089244, 'Total loss': 0.3844834981089244}
2022-12-05 22:02:08,738 INFO:     Found new best model at epoch 5
2022-12-05 22:02:08,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:08,739 INFO:     Epoch: 6
2022-12-05 22:02:09,522 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4180554955504661, 'Total loss': 0.4180554955504661} | train loss {'Reaction outcome loss': 0.36493553831929065, 'Total loss': 0.36493553831929065}
2022-12-05 22:02:09,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:09,522 INFO:     Epoch: 7
2022-12-05 22:02:10,312 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4140018699474113, 'Total loss': 0.4140018699474113} | train loss {'Reaction outcome loss': 0.34832635937166995, 'Total loss': 0.34832635937166995}
2022-12-05 22:02:10,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:10,313 INFO:     Epoch: 8
2022-12-05 22:02:11,098 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4035705532445464, 'Total loss': 0.4035705532445464} | train loss {'Reaction outcome loss': 0.33622056645814513, 'Total loss': 0.33622056645814513}
2022-12-05 22:02:11,098 INFO:     Found new best model at epoch 8
2022-12-05 22:02:11,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:11,099 INFO:     Epoch: 9
2022-12-05 22:02:11,881 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.39719754561435344, 'Total loss': 0.39719754561435344} | train loss {'Reaction outcome loss': 0.32317249544087, 'Total loss': 0.32317249544087}
2022-12-05 22:02:11,881 INFO:     Found new best model at epoch 9
2022-12-05 22:02:11,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:11,882 INFO:     Epoch: 10
2022-12-05 22:02:12,666 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3982179509692414, 'Total loss': 0.3982179509692414} | train loss {'Reaction outcome loss': 0.31076468093717685, 'Total loss': 0.31076468093717685}
2022-12-05 22:02:12,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:12,666 INFO:     Epoch: 11
2022-12-05 22:02:13,455 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3998433410428291, 'Total loss': 0.3998433410428291} | train loss {'Reaction outcome loss': 0.29795717637314173, 'Total loss': 0.29795717637314173}
2022-12-05 22:02:13,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:13,455 INFO:     Epoch: 12
2022-12-05 22:02:14,246 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.393647862728252, 'Total loss': 0.393647862728252} | train loss {'Reaction outcome loss': 0.28627271205186844, 'Total loss': 0.28627271205186844}
2022-12-05 22:02:14,246 INFO:     Found new best model at epoch 12
2022-12-05 22:02:14,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:14,247 INFO:     Epoch: 13
2022-12-05 22:02:15,033 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3879617560048436, 'Total loss': 0.3879617560048436} | train loss {'Reaction outcome loss': 0.2766500042873572, 'Total loss': 0.2766500042873572}
2022-12-05 22:02:15,033 INFO:     Found new best model at epoch 13
2022-12-05 22:02:15,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:15,034 INFO:     Epoch: 14
2022-12-05 22:02:15,818 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3919632046721702, 'Total loss': 0.3919632046721702} | train loss {'Reaction outcome loss': 0.2669859768089945, 'Total loss': 0.2669859768089945}
2022-12-05 22:02:15,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:15,818 INFO:     Epoch: 15
2022-12-05 22:02:16,605 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.405059183752814, 'Total loss': 0.405059183752814} | train loss {'Reaction outcome loss': 0.25942576701035264, 'Total loss': 0.25942576701035264}
2022-12-05 22:02:16,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:16,605 INFO:     Epoch: 16
2022-12-05 22:02:17,391 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4016815926446471, 'Total loss': 0.4016815926446471} | train loss {'Reaction outcome loss': 0.2521659606365395, 'Total loss': 0.2521659606365395}
2022-12-05 22:02:17,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:17,391 INFO:     Epoch: 17
2022-12-05 22:02:18,177 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40659044821595036, 'Total loss': 0.40659044821595036} | train loss {'Reaction outcome loss': 0.24215320143543306, 'Total loss': 0.24215320143543306}
2022-12-05 22:02:18,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:18,178 INFO:     Epoch: 18
2022-12-05 22:02:18,960 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3995731032864992, 'Total loss': 0.3995731032864992} | train loss {'Reaction outcome loss': 0.23528675692247564, 'Total loss': 0.23528675692247564}
2022-12-05 22:02:18,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:18,960 INFO:     Epoch: 19
2022-12-05 22:02:19,748 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40282119568004165, 'Total loss': 0.40282119568004165} | train loss {'Reaction outcome loss': 0.23008332178607338, 'Total loss': 0.23008332178607338}
2022-12-05 22:02:19,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:19,748 INFO:     Epoch: 20
2022-12-05 22:02:20,533 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42278456895850425, 'Total loss': 0.42278456895850425} | train loss {'Reaction outcome loss': 0.223974176163434, 'Total loss': 0.223974176163434}
2022-12-05 22:02:20,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:20,533 INFO:     Epoch: 21
2022-12-05 22:02:21,320 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.38951932517595067, 'Total loss': 0.38951932517595067} | train loss {'Reaction outcome loss': 0.21746335492362498, 'Total loss': 0.21746335492362498}
2022-12-05 22:02:21,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:21,320 INFO:     Epoch: 22
2022-12-05 22:02:22,108 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40871667861938477, 'Total loss': 0.40871667861938477} | train loss {'Reaction outcome loss': 0.21211610412316734, 'Total loss': 0.21211610412316734}
2022-12-05 22:02:22,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:22,109 INFO:     Epoch: 23
2022-12-05 22:02:22,892 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40854083209536796, 'Total loss': 0.40854083209536796} | train loss {'Reaction outcome loss': 0.20812722802406453, 'Total loss': 0.20812722802406453}
2022-12-05 22:02:22,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:22,892 INFO:     Epoch: 24
2022-12-05 22:02:23,677 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4032203619216764, 'Total loss': 0.4032203619216764} | train loss {'Reaction outcome loss': 0.20354540235378216, 'Total loss': 0.20354540235378216}
2022-12-05 22:02:23,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:23,678 INFO:     Epoch: 25
2022-12-05 22:02:24,462 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42332380351632143, 'Total loss': 0.42332380351632143} | train loss {'Reaction outcome loss': 0.2000401689991599, 'Total loss': 0.2000401689991599}
2022-12-05 22:02:24,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:24,462 INFO:     Epoch: 26
2022-12-05 22:02:25,245 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4177114246196525, 'Total loss': 0.4177114246196525} | train loss {'Reaction outcome loss': 0.19461151492613993, 'Total loss': 0.19461151492613993}
2022-12-05 22:02:25,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:25,245 INFO:     Epoch: 27
2022-12-05 22:02:26,030 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4228465118727019, 'Total loss': 0.4228465118727019} | train loss {'Reaction outcome loss': 0.19433887750215706, 'Total loss': 0.19433887750215706}
2022-12-05 22:02:26,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:26,030 INFO:     Epoch: 28
2022-12-05 22:02:26,814 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.405293244088805, 'Total loss': 0.405293244088805} | train loss {'Reaction outcome loss': 0.1884399376519513, 'Total loss': 0.1884399376519513}
2022-12-05 22:02:26,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:26,814 INFO:     Epoch: 29
2022-12-05 22:02:27,597 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4211544980143392, 'Total loss': 0.4211544980143392} | train loss {'Reaction outcome loss': 0.18636429569775576, 'Total loss': 0.18636429569775576}
2022-12-05 22:02:27,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:27,597 INFO:     Epoch: 30
2022-12-05 22:02:28,380 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42230248676483023, 'Total loss': 0.42230248676483023} | train loss {'Reaction outcome loss': 0.18264570568123314, 'Total loss': 0.18264570568123314}
2022-12-05 22:02:28,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:28,380 INFO:     Epoch: 31
2022-12-05 22:02:29,166 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41019531010195265, 'Total loss': 0.41019531010195265} | train loss {'Reaction outcome loss': 0.17963072202611166, 'Total loss': 0.17963072202611166}
2022-12-05 22:02:29,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:29,167 INFO:     Epoch: 32
2022-12-05 22:02:29,950 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4258024020250453, 'Total loss': 0.4258024020250453} | train loss {'Reaction outcome loss': 0.18088276001823242, 'Total loss': 0.18088276001823242}
2022-12-05 22:02:29,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:29,951 INFO:     Epoch: 33
2022-12-05 22:02:30,734 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43147278299858405, 'Total loss': 0.43147278299858405} | train loss {'Reaction outcome loss': 0.17519678070866426, 'Total loss': 0.17519678070866426}
2022-12-05 22:02:30,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:30,734 INFO:     Epoch: 34
2022-12-05 22:02:31,520 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4227498346983, 'Total loss': 0.4227498346983} | train loss {'Reaction outcome loss': 0.17360122074357798, 'Total loss': 0.17360122074357798}
2022-12-05 22:02:31,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:31,520 INFO:     Epoch: 35
2022-12-05 22:02:32,304 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42261533231236215, 'Total loss': 0.42261533231236215} | train loss {'Reaction outcome loss': 0.16994282445244369, 'Total loss': 0.16994282445244369}
2022-12-05 22:02:32,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:32,304 INFO:     Epoch: 36
2022-12-05 22:02:33,088 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.408422724105591, 'Total loss': 0.408422724105591} | train loss {'Reaction outcome loss': 0.16723616013578216, 'Total loss': 0.16723616013578216}
2022-12-05 22:02:33,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:33,088 INFO:     Epoch: 37
2022-12-05 22:02:33,870 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4246938263261041, 'Total loss': 0.4246938263261041} | train loss {'Reaction outcome loss': 0.16666717604413384, 'Total loss': 0.16666717604413384}
2022-12-05 22:02:33,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:33,871 INFO:     Epoch: 38
2022-12-05 22:02:34,655 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4087728927301806, 'Total loss': 0.4087728927301806} | train loss {'Reaction outcome loss': 0.1632807877632316, 'Total loss': 0.1632807877632316}
2022-12-05 22:02:34,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:34,655 INFO:     Epoch: 39
2022-12-05 22:02:35,440 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41831740286461144, 'Total loss': 0.41831740286461144} | train loss {'Reaction outcome loss': 0.16165951051611882, 'Total loss': 0.16165951051611882}
2022-12-05 22:02:35,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:35,440 INFO:     Epoch: 40
2022-12-05 22:02:36,222 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42124023063238275, 'Total loss': 0.42124023063238275} | train loss {'Reaction outcome loss': 0.1605053520227065, 'Total loss': 0.1605053520227065}
2022-12-05 22:02:36,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:36,223 INFO:     Epoch: 41
2022-12-05 22:02:37,004 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4281279449892599, 'Total loss': 0.4281279449892599} | train loss {'Reaction outcome loss': 0.16001752688412052, 'Total loss': 0.16001752688412052}
2022-12-05 22:02:37,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:37,004 INFO:     Epoch: 42
2022-12-05 22:02:37,790 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4254848494432693, 'Total loss': 0.4254848494432693} | train loss {'Reaction outcome loss': 0.1601996111194985, 'Total loss': 0.1601996111194985}
2022-12-05 22:02:37,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:37,791 INFO:     Epoch: 43
2022-12-05 22:02:38,578 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4292534714521364, 'Total loss': 0.4292534714521364} | train loss {'Reaction outcome loss': 0.15805321291363875, 'Total loss': 0.15805321291363875}
2022-12-05 22:02:38,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:38,578 INFO:     Epoch: 44
2022-12-05 22:02:39,358 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4267627182741498, 'Total loss': 0.4267627182741498} | train loss {'Reaction outcome loss': 0.1566984326822958, 'Total loss': 0.1566984326822958}
2022-12-05 22:02:39,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:39,359 INFO:     Epoch: 45
2022-12-05 22:02:40,144 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4193441458912783, 'Total loss': 0.4193441458912783} | train loss {'Reaction outcome loss': 0.15492181626499676, 'Total loss': 0.15492181626499676}
2022-12-05 22:02:40,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:40,144 INFO:     Epoch: 46
2022-12-05 22:02:40,927 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42727820384641024, 'Total loss': 0.42727820384641024} | train loss {'Reaction outcome loss': 0.15185874672301236, 'Total loss': 0.15185874672301236}
2022-12-05 22:02:40,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:40,927 INFO:     Epoch: 47
2022-12-05 22:02:41,712 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4405005997003511, 'Total loss': 0.4405005997003511} | train loss {'Reaction outcome loss': 0.15232198216692835, 'Total loss': 0.15232198216692835}
2022-12-05 22:02:41,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:41,712 INFO:     Epoch: 48
2022-12-05 22:02:42,499 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43545034233220786, 'Total loss': 0.43545034233220786} | train loss {'Reaction outcome loss': 0.15080160780458665, 'Total loss': 0.15080160780458665}
2022-12-05 22:02:42,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:42,499 INFO:     Epoch: 49
2022-12-05 22:02:43,281 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42386099626851637, 'Total loss': 0.42386099626851637} | train loss {'Reaction outcome loss': 0.14912413756103546, 'Total loss': 0.14912413756103546}
2022-12-05 22:02:43,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:43,281 INFO:     Epoch: 50
2022-12-05 22:02:44,071 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.427299807584563, 'Total loss': 0.427299807584563} | train loss {'Reaction outcome loss': 0.14875580720053833, 'Total loss': 0.14875580720053833}
2022-12-05 22:02:44,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:44,071 INFO:     Epoch: 51
2022-12-05 22:02:44,862 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42590688099694807, 'Total loss': 0.42590688099694807} | train loss {'Reaction outcome loss': 0.14589472686047436, 'Total loss': 0.14589472686047436}
2022-12-05 22:02:44,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:44,862 INFO:     Epoch: 52
2022-12-05 22:02:45,652 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41885160533494725, 'Total loss': 0.41885160533494725} | train loss {'Reaction outcome loss': 0.14914731270648907, 'Total loss': 0.14914731270648907}
2022-12-05 22:02:45,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:45,652 INFO:     Epoch: 53
2022-12-05 22:02:46,439 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45192329239013584, 'Total loss': 0.45192329239013584} | train loss {'Reaction outcome loss': 0.1482234582320222, 'Total loss': 0.1482234582320222}
2022-12-05 22:02:46,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:46,439 INFO:     Epoch: 54
2022-12-05 22:02:47,224 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4239963137133177, 'Total loss': 0.4239963137133177} | train loss {'Reaction outcome loss': 0.14350540111543703, 'Total loss': 0.14350540111543703}
2022-12-05 22:02:47,224 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:47,224 INFO:     Epoch: 55
2022-12-05 22:02:48,013 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4454462368820989, 'Total loss': 0.4454462368820989} | train loss {'Reaction outcome loss': 0.14333604636113542, 'Total loss': 0.14333604636113542}
2022-12-05 22:02:48,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:48,014 INFO:     Epoch: 56
2022-12-05 22:02:48,798 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4290641303672347, 'Total loss': 0.4290641303672347} | train loss {'Reaction outcome loss': 0.14256052290410048, 'Total loss': 0.14256052290410048}
2022-12-05 22:02:48,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:48,799 INFO:     Epoch: 57
2022-12-05 22:02:49,582 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4285328204548636, 'Total loss': 0.4285328204548636} | train loss {'Reaction outcome loss': 0.14221862298970828, 'Total loss': 0.14221862298970828}
2022-12-05 22:02:49,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:49,582 INFO:     Epoch: 58
2022-12-05 22:02:50,373 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42703643943681274, 'Total loss': 0.42703643943681274} | train loss {'Reaction outcome loss': 0.1430763836614177, 'Total loss': 0.1430763836614177}
2022-12-05 22:02:50,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:50,373 INFO:     Epoch: 59
2022-12-05 22:02:51,162 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4400014459740284, 'Total loss': 0.4400014459740284} | train loss {'Reaction outcome loss': 0.14063387689348616, 'Total loss': 0.14063387689348616}
2022-12-05 22:02:51,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:51,162 INFO:     Epoch: 60
2022-12-05 22:02:51,945 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4247924907262935, 'Total loss': 0.4247924907262935} | train loss {'Reaction outcome loss': 0.13630685377408003, 'Total loss': 0.13630685377408003}
2022-12-05 22:02:51,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:51,945 INFO:     Epoch: 61
2022-12-05 22:02:52,728 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42861454708631647, 'Total loss': 0.42861454708631647} | train loss {'Reaction outcome loss': 0.1374860357752711, 'Total loss': 0.1374860357752711}
2022-12-05 22:02:52,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:52,728 INFO:     Epoch: 62
2022-12-05 22:02:53,512 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4362511912057566, 'Total loss': 0.4362511912057566} | train loss {'Reaction outcome loss': 0.13950942616268505, 'Total loss': 0.13950942616268505}
2022-12-05 22:02:53,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:53,512 INFO:     Epoch: 63
2022-12-05 22:02:54,301 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4341308576769607, 'Total loss': 0.4341308576769607} | train loss {'Reaction outcome loss': 0.13846938844510645, 'Total loss': 0.13846938844510645}
2022-12-05 22:02:54,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:54,301 INFO:     Epoch: 64
2022-12-05 22:02:55,084 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4268106707306795, 'Total loss': 0.4268106707306795} | train loss {'Reaction outcome loss': 0.13763321307487786, 'Total loss': 0.13763321307487786}
2022-12-05 22:02:55,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:55,085 INFO:     Epoch: 65
2022-12-05 22:02:55,867 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.437310580943906, 'Total loss': 0.437310580943906} | train loss {'Reaction outcome loss': 0.13572685545707336, 'Total loss': 0.13572685545707336}
2022-12-05 22:02:55,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:55,867 INFO:     Epoch: 66
2022-12-05 22:02:56,651 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45292189578677333, 'Total loss': 0.45292189578677333} | train loss {'Reaction outcome loss': 0.13610970522048044, 'Total loss': 0.13610970522048044}
2022-12-05 22:02:56,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:56,652 INFO:     Epoch: 67
2022-12-05 22:02:57,433 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42979783027671103, 'Total loss': 0.42979783027671103} | train loss {'Reaction outcome loss': 0.1364619333457324, 'Total loss': 0.1364619333457324}
2022-12-05 22:02:57,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:57,433 INFO:     Epoch: 68
2022-12-05 22:02:58,217 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41194467974263566, 'Total loss': 0.41194467974263566} | train loss {'Reaction outcome loss': 0.1325100907926127, 'Total loss': 0.1325100907926127}
2022-12-05 22:02:58,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:58,218 INFO:     Epoch: 69
2022-12-05 22:02:58,999 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4302015813977219, 'Total loss': 0.4302015813977219} | train loss {'Reaction outcome loss': 0.13414334273729167, 'Total loss': 0.13414334273729167}
2022-12-05 22:02:58,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:58,999 INFO:     Epoch: 70
2022-12-05 22:02:59,785 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4346186530797981, 'Total loss': 0.4346186530797981} | train loss {'Reaction outcome loss': 0.1333171970852208, 'Total loss': 0.1333171970852208}
2022-12-05 22:02:59,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:02:59,786 INFO:     Epoch: 71
2022-12-05 22:03:00,570 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44375656475854475, 'Total loss': 0.44375656475854475} | train loss {'Reaction outcome loss': 0.13065763097256422, 'Total loss': 0.13065763097256422}
2022-12-05 22:03:00,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:00,572 INFO:     Epoch: 72
2022-12-05 22:03:01,358 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4433094516049984, 'Total loss': 0.4433094516049984} | train loss {'Reaction outcome loss': 0.13023590309484329, 'Total loss': 0.13023590309484329}
2022-12-05 22:03:01,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:01,359 INFO:     Epoch: 73
2022-12-05 22:03:02,149 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4416519481428834, 'Total loss': 0.4416519481428834} | train loss {'Reaction outcome loss': 0.13176552242920048, 'Total loss': 0.13176552242920048}
2022-12-05 22:03:02,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:02,149 INFO:     Epoch: 74
2022-12-05 22:03:02,940 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4317840348149455, 'Total loss': 0.4317840348149455} | train loss {'Reaction outcome loss': 0.13041806160701347, 'Total loss': 0.13041806160701347}
2022-12-05 22:03:02,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:02,940 INFO:     Epoch: 75
2022-12-05 22:03:03,724 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4344010063728621, 'Total loss': 0.4344010063728621} | train loss {'Reaction outcome loss': 0.12726412724978367, 'Total loss': 0.12726412724978367}
2022-12-05 22:03:03,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:03,724 INFO:     Epoch: 76
2022-12-05 22:03:04,505 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43337967957175055, 'Total loss': 0.43337967957175055} | train loss {'Reaction outcome loss': 0.13126197145282306, 'Total loss': 0.13126197145282306}
2022-12-05 22:03:04,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:04,505 INFO:     Epoch: 77
2022-12-05 22:03:05,294 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.426434766068015, 'Total loss': 0.426434766068015} | train loss {'Reaction outcome loss': 0.1302968768983102, 'Total loss': 0.1302968768983102}
2022-12-05 22:03:05,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:05,294 INFO:     Epoch: 78
2022-12-05 22:03:06,080 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41893887935682783, 'Total loss': 0.41893887935682783} | train loss {'Reaction outcome loss': 0.13024531851034063, 'Total loss': 0.13024531851034063}
2022-12-05 22:03:06,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:06,080 INFO:     Epoch: 79
2022-12-05 22:03:06,868 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43075945592203807, 'Total loss': 0.43075945592203807} | train loss {'Reaction outcome loss': 0.12759746740129393, 'Total loss': 0.12759746740129393}
2022-12-05 22:03:06,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:06,869 INFO:     Epoch: 80
2022-12-05 22:03:07,651 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4291414576907491, 'Total loss': 0.4291414576907491} | train loss {'Reaction outcome loss': 0.12773656309200604, 'Total loss': 0.12773656309200604}
2022-12-05 22:03:07,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:07,652 INFO:     Epoch: 81
2022-12-05 22:03:08,437 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44989003691562385, 'Total loss': 0.44989003691562385} | train loss {'Reaction outcome loss': 0.1294292361383922, 'Total loss': 0.1294292361383922}
2022-12-05 22:03:08,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:08,437 INFO:     Epoch: 82
2022-12-05 22:03:09,223 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4402819327836813, 'Total loss': 0.4402819327836813} | train loss {'Reaction outcome loss': 0.12437051951457731, 'Total loss': 0.12437051951457731}
2022-12-05 22:03:09,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:09,223 INFO:     Epoch: 83
2022-12-05 22:03:10,005 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42913766413234, 'Total loss': 0.42913766413234} | train loss {'Reaction outcome loss': 0.12626999196573543, 'Total loss': 0.12626999196573543}
2022-12-05 22:03:10,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:10,005 INFO:     Epoch: 84
2022-12-05 22:03:10,787 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4285499824340953, 'Total loss': 0.4285499824340953} | train loss {'Reaction outcome loss': 0.12362302512648042, 'Total loss': 0.12362302512648042}
2022-12-05 22:03:10,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:10,787 INFO:     Epoch: 85
2022-12-05 22:03:11,570 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43164303275041804, 'Total loss': 0.43164303275041804} | train loss {'Reaction outcome loss': 0.1236467983069845, 'Total loss': 0.1236467983069845}
2022-12-05 22:03:11,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:11,570 INFO:     Epoch: 86
2022-12-05 22:03:12,357 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4291364956040715, 'Total loss': 0.4291364956040715} | train loss {'Reaction outcome loss': 0.12446387428943007, 'Total loss': 0.12446387428943007}
2022-12-05 22:03:12,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:12,357 INFO:     Epoch: 87
2022-12-05 22:03:13,141 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4191440193112506, 'Total loss': 0.4191440193112506} | train loss {'Reaction outcome loss': 0.12558480985386328, 'Total loss': 0.12558480985386328}
2022-12-05 22:03:13,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:13,141 INFO:     Epoch: 88
2022-12-05 22:03:13,922 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4285107426518618, 'Total loss': 0.4285107426518618} | train loss {'Reaction outcome loss': 0.1256266264760195, 'Total loss': 0.1256266264760195}
2022-12-05 22:03:13,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:13,922 INFO:     Epoch: 89
2022-12-05 22:03:14,703 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4293861292129339, 'Total loss': 0.4293861292129339} | train loss {'Reaction outcome loss': 0.12510788180392052, 'Total loss': 0.12510788180392052}
2022-12-05 22:03:14,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:14,704 INFO:     Epoch: 90
2022-12-05 22:03:15,486 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4355723145742749, 'Total loss': 0.4355723145742749} | train loss {'Reaction outcome loss': 0.1228116579987414, 'Total loss': 0.1228116579987414}
2022-12-05 22:03:15,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:15,486 INFO:     Epoch: 91
2022-12-05 22:03:16,272 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43919436772202336, 'Total loss': 0.43919436772202336} | train loss {'Reaction outcome loss': 0.12286425536674005, 'Total loss': 0.12286425536674005}
2022-12-05 22:03:16,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:16,272 INFO:     Epoch: 92
2022-12-05 22:03:17,054 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4272871478352436, 'Total loss': 0.4272871478352436} | train loss {'Reaction outcome loss': 0.12187727919749183, 'Total loss': 0.12187727919749183}
2022-12-05 22:03:17,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:17,054 INFO:     Epoch: 93
2022-12-05 22:03:17,843 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4382736041795376, 'Total loss': 0.4382736041795376} | train loss {'Reaction outcome loss': 0.12094876839641909, 'Total loss': 0.12094876839641909}
2022-12-05 22:03:17,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:17,843 INFO:     Epoch: 94
2022-12-05 22:03:18,624 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4424893221882887, 'Total loss': 0.4424893221882887} | train loss {'Reaction outcome loss': 0.1223101826293058, 'Total loss': 0.1223101826293058}
2022-12-05 22:03:18,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:18,624 INFO:     Epoch: 95
2022-12-05 22:03:19,406 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4265952512275341, 'Total loss': 0.4265952512275341} | train loss {'Reaction outcome loss': 0.1215476591682031, 'Total loss': 0.1215476591682031}
2022-12-05 22:03:19,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:19,407 INFO:     Epoch: 96
2022-12-05 22:03:20,189 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4345284357320431, 'Total loss': 0.4345284357320431} | train loss {'Reaction outcome loss': 0.12056450747510754, 'Total loss': 0.12056450747510754}
2022-12-05 22:03:20,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:20,189 INFO:     Epoch: 97
2022-12-05 22:03:20,971 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4399502374405085, 'Total loss': 0.4399502374405085} | train loss {'Reaction outcome loss': 0.12151269792563847, 'Total loss': 0.12151269792563847}
2022-12-05 22:03:20,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:20,971 INFO:     Epoch: 98
2022-12-05 22:03:21,754 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4326339169990185, 'Total loss': 0.4326339169990185} | train loss {'Reaction outcome loss': 0.12061505366620592, 'Total loss': 0.12061505366620592}
2022-12-05 22:03:21,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:21,755 INFO:     Epoch: 99
2022-12-05 22:03:22,540 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44664157528516857, 'Total loss': 0.44664157528516857} | train loss {'Reaction outcome loss': 0.12117607703768328, 'Total loss': 0.12117607703768328}
2022-12-05 22:03:22,540 INFO:     Best model found after epoch 14 of 100.
2022-12-05 22:03:22,540 INFO:   Done with stage: TRAINING
2022-12-05 22:03:22,540 INFO:   Starting stage: EVALUATION
2022-12-05 22:03:22,678 INFO:   Done with stage: EVALUATION
2022-12-05 22:03:22,678 INFO:   Leaving out SEQ value Fold_2
2022-12-05 22:03:22,691 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 22:03:22,691 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:03:23,334 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:03:23,334 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:03:23,402 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:03:23,403 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:03:23,403 INFO:     No hyperparam tuning for this model
2022-12-05 22:03:23,403 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:03:23,403 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:03:23,403 INFO:     None feature selector for col prot
2022-12-05 22:03:23,404 INFO:     None feature selector for col prot
2022-12-05 22:03:23,404 INFO:     None feature selector for col prot
2022-12-05 22:03:23,404 INFO:     None feature selector for col chem
2022-12-05 22:03:23,404 INFO:     None feature selector for col chem
2022-12-05 22:03:23,404 INFO:     None feature selector for col chem
2022-12-05 22:03:23,404 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:03:23,404 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:03:23,406 INFO:     Number of params in model 215821
2022-12-05 22:03:23,409 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:03:23,409 INFO:   Starting stage: TRAINING
2022-12-05 22:03:23,468 INFO:     Val loss before train {'Reaction outcome loss': 0.9970232192860093, 'Total loss': 0.9970232192860093}
2022-12-05 22:03:23,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:23,468 INFO:     Epoch: 0
2022-12-05 22:03:24,248 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5975688782542251, 'Total loss': 0.5975688782542251} | train loss {'Reaction outcome loss': 0.7987106912175324, 'Total loss': 0.7987106912175324}
2022-12-05 22:03:24,248 INFO:     Found new best model at epoch 0
2022-12-05 22:03:24,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:24,249 INFO:     Epoch: 1
2022-12-05 22:03:25,026 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5142478284447692, 'Total loss': 0.5142478284447692} | train loss {'Reaction outcome loss': 0.5511683255066107, 'Total loss': 0.5511683255066107}
2022-12-05 22:03:25,026 INFO:     Found new best model at epoch 1
2022-12-05 22:03:25,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:25,027 INFO:     Epoch: 2
2022-12-05 22:03:25,811 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4789866240218628, 'Total loss': 0.4789866240218628} | train loss {'Reaction outcome loss': 0.4759096166601888, 'Total loss': 0.4759096166601888}
2022-12-05 22:03:25,811 INFO:     Found new best model at epoch 2
2022-12-05 22:03:25,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:25,812 INFO:     Epoch: 3
2022-12-05 22:03:26,593 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45895956352699635, 'Total loss': 0.45895956352699635} | train loss {'Reaction outcome loss': 0.4364847171085852, 'Total loss': 0.4364847171085852}
2022-12-05 22:03:26,593 INFO:     Found new best model at epoch 3
2022-12-05 22:03:26,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:26,594 INFO:     Epoch: 4
2022-12-05 22:03:27,377 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43898451051046683, 'Total loss': 0.43898451051046683} | train loss {'Reaction outcome loss': 0.4105486624525408, 'Total loss': 0.4105486624525408}
2022-12-05 22:03:27,377 INFO:     Found new best model at epoch 4
2022-12-05 22:03:27,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:27,378 INFO:     Epoch: 5
2022-12-05 22:03:28,159 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4317916409913884, 'Total loss': 0.4317916409913884} | train loss {'Reaction outcome loss': 0.38486023823665494, 'Total loss': 0.38486023823665494}
2022-12-05 22:03:28,159 INFO:     Found new best model at epoch 5
2022-12-05 22:03:28,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:28,160 INFO:     Epoch: 6
2022-12-05 22:03:28,938 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4268359701300776, 'Total loss': 0.4268359701300776} | train loss {'Reaction outcome loss': 0.3702347973982493, 'Total loss': 0.3702347973982493}
2022-12-05 22:03:28,938 INFO:     Found new best model at epoch 6
2022-12-05 22:03:28,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:28,939 INFO:     Epoch: 7
2022-12-05 22:03:29,721 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4144042525873628, 'Total loss': 0.4144042525873628} | train loss {'Reaction outcome loss': 0.35303941037919784, 'Total loss': 0.35303941037919784}
2022-12-05 22:03:29,721 INFO:     Found new best model at epoch 7
2022-12-05 22:03:29,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:29,722 INFO:     Epoch: 8
2022-12-05 22:03:30,501 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4115337653215541, 'Total loss': 0.4115337653215541} | train loss {'Reaction outcome loss': 0.3366903685063982, 'Total loss': 0.3366903685063982}
2022-12-05 22:03:30,501 INFO:     Found new best model at epoch 8
2022-12-05 22:03:30,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:30,502 INFO:     Epoch: 9
2022-12-05 22:03:31,287 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40684927618780803, 'Total loss': 0.40684927618780803} | train loss {'Reaction outcome loss': 0.3188367180311631, 'Total loss': 0.3188367180311631}
2022-12-05 22:03:31,287 INFO:     Found new best model at epoch 9
2022-12-05 22:03:31,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:31,288 INFO:     Epoch: 10
2022-12-05 22:03:32,073 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4090533419403919, 'Total loss': 0.4090533419403919} | train loss {'Reaction outcome loss': 0.30917635888106537, 'Total loss': 0.30917635888106537}
2022-12-05 22:03:32,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:32,074 INFO:     Epoch: 11
2022-12-05 22:03:32,854 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4126156409119451, 'Total loss': 0.4126156409119451} | train loss {'Reaction outcome loss': 0.2950016212316207, 'Total loss': 0.2950016212316207}
2022-12-05 22:03:32,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:32,854 INFO:     Epoch: 12
2022-12-05 22:03:33,632 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40095468246659566, 'Total loss': 0.40095468246659566} | train loss {'Reaction outcome loss': 0.281704988008664, 'Total loss': 0.281704988008664}
2022-12-05 22:03:33,633 INFO:     Found new best model at epoch 12
2022-12-05 22:03:33,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:33,634 INFO:     Epoch: 13
2022-12-05 22:03:34,420 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4053376945991849, 'Total loss': 0.4053376945991849} | train loss {'Reaction outcome loss': 0.27422492383929437, 'Total loss': 0.27422492383929437}
2022-12-05 22:03:34,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:34,420 INFO:     Epoch: 14
2022-12-05 22:03:35,199 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4020969276857931, 'Total loss': 0.4020969276857931} | train loss {'Reaction outcome loss': 0.26243413437479807, 'Total loss': 0.26243413437479807}
2022-12-05 22:03:35,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:35,199 INFO:     Epoch: 15
2022-12-05 22:03:35,985 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39612450814524364, 'Total loss': 0.39612450814524364} | train loss {'Reaction outcome loss': 0.25748987071246765, 'Total loss': 0.25748987071246765}
2022-12-05 22:03:35,985 INFO:     Found new best model at epoch 15
2022-12-05 22:03:35,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:35,986 INFO:     Epoch: 16
2022-12-05 22:03:36,769 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4029529115488363, 'Total loss': 0.4029529115488363} | train loss {'Reaction outcome loss': 0.24816673886751442, 'Total loss': 0.24816673886751442}
2022-12-05 22:03:36,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:36,769 INFO:     Epoch: 17
2022-12-05 22:03:37,559 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3991366933251536, 'Total loss': 0.3991366933251536} | train loss {'Reaction outcome loss': 0.23730820083201176, 'Total loss': 0.23730820083201176}
2022-12-05 22:03:37,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:37,559 INFO:     Epoch: 18
2022-12-05 22:03:38,341 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4077016950346703, 'Total loss': 0.4077016950346703} | train loss {'Reaction outcome loss': 0.2304615139531991, 'Total loss': 0.2304615139531991}
2022-12-05 22:03:38,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:38,342 INFO:     Epoch: 19
2022-12-05 22:03:39,123 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40268109461595847, 'Total loss': 0.40268109461595847} | train loss {'Reaction outcome loss': 0.22460348077823597, 'Total loss': 0.22460348077823597}
2022-12-05 22:03:39,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:39,123 INFO:     Epoch: 20
2022-12-05 22:03:39,910 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.415684541644052, 'Total loss': 0.415684541644052} | train loss {'Reaction outcome loss': 0.22137366903662192, 'Total loss': 0.22137366903662192}
2022-12-05 22:03:39,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:39,910 INFO:     Epoch: 21
2022-12-05 22:03:40,689 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41906946810872053, 'Total loss': 0.41906946810872053} | train loss {'Reaction outcome loss': 0.21311622146716333, 'Total loss': 0.21311622146716333}
2022-12-05 22:03:40,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:40,689 INFO:     Epoch: 22
2022-12-05 22:03:41,469 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41218390506367353, 'Total loss': 0.41218390506367353} | train loss {'Reaction outcome loss': 0.20939683845197712, 'Total loss': 0.20939683845197712}
2022-12-05 22:03:41,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:41,470 INFO:     Epoch: 23
2022-12-05 22:03:42,247 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4082229788913283, 'Total loss': 0.4082229788913283} | train loss {'Reaction outcome loss': 0.20839769557241059, 'Total loss': 0.20839769557241059}
2022-12-05 22:03:42,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:42,248 INFO:     Epoch: 24
2022-12-05 22:03:43,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41752461603907653, 'Total loss': 0.41752461603907653} | train loss {'Reaction outcome loss': 0.20105862471853755, 'Total loss': 0.20105862471853755}
2022-12-05 22:03:43,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:43,028 INFO:     Epoch: 25
2022-12-05 22:03:43,825 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4173971029908158, 'Total loss': 0.4173971029908158} | train loss {'Reaction outcome loss': 0.1974559652277962, 'Total loss': 0.1974559652277962}
2022-12-05 22:03:43,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:43,825 INFO:     Epoch: 26
2022-12-05 22:03:44,621 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4139703796353451, 'Total loss': 0.4139703796353451} | train loss {'Reaction outcome loss': 0.1925374718321633, 'Total loss': 0.1925374718321633}
2022-12-05 22:03:44,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:44,621 INFO:     Epoch: 27
2022-12-05 22:03:45,415 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4313511501911075, 'Total loss': 0.4313511501911075} | train loss {'Reaction outcome loss': 0.18682479807808075, 'Total loss': 0.18682479807808075}
2022-12-05 22:03:45,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:45,416 INFO:     Epoch: 28
2022-12-05 22:03:46,211 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4288696095693943, 'Total loss': 0.4288696095693943} | train loss {'Reaction outcome loss': 0.18415735514811526, 'Total loss': 0.18415735514811526}
2022-12-05 22:03:46,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:46,211 INFO:     Epoch: 29
2022-12-05 22:03:47,007 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42214424752218777, 'Total loss': 0.42214424752218777} | train loss {'Reaction outcome loss': 0.18284581186165536, 'Total loss': 0.18284581186165536}
2022-12-05 22:03:47,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:47,008 INFO:     Epoch: 30
2022-12-05 22:03:47,805 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41982287272464397, 'Total loss': 0.41982287272464397} | train loss {'Reaction outcome loss': 0.178995402169571, 'Total loss': 0.178995402169571}
2022-12-05 22:03:47,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:47,805 INFO:     Epoch: 31
2022-12-05 22:03:48,603 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43292804512866706, 'Total loss': 0.43292804512866706} | train loss {'Reaction outcome loss': 0.17647701590762707, 'Total loss': 0.17647701590762707}
2022-12-05 22:03:48,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:48,604 INFO:     Epoch: 32
2022-12-05 22:03:49,402 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44890685448812884, 'Total loss': 0.44890685448812884} | train loss {'Reaction outcome loss': 0.17647724085843858, 'Total loss': 0.17647724085843858}
2022-12-05 22:03:49,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:49,402 INFO:     Epoch: 33
2022-12-05 22:03:50,200 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44466501405072767, 'Total loss': 0.44466501405072767} | train loss {'Reaction outcome loss': 0.17209596318717846, 'Total loss': 0.17209596318717846}
2022-12-05 22:03:50,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:50,200 INFO:     Epoch: 34
2022-12-05 22:03:50,994 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42843565448772075, 'Total loss': 0.42843565448772075} | train loss {'Reaction outcome loss': 0.16901741813055773, 'Total loss': 0.16901741813055773}
2022-12-05 22:03:50,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:50,995 INFO:     Epoch: 35
2022-12-05 22:03:51,789 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4344693110432736, 'Total loss': 0.4344693110432736} | train loss {'Reaction outcome loss': 0.16864320474826258, 'Total loss': 0.16864320474826258}
2022-12-05 22:03:51,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:51,790 INFO:     Epoch: 36
2022-12-05 22:03:52,586 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4288689934237059, 'Total loss': 0.4288689934237059} | train loss {'Reaction outcome loss': 0.16140153786405123, 'Total loss': 0.16140153786405123}
2022-12-05 22:03:52,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:52,586 INFO:     Epoch: 37
2022-12-05 22:03:53,382 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44085093691598537, 'Total loss': 0.44085093691598537} | train loss {'Reaction outcome loss': 0.16082757942899756, 'Total loss': 0.16082757942899756}
2022-12-05 22:03:53,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:53,382 INFO:     Epoch: 38
2022-12-05 22:03:54,176 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4354131772767666, 'Total loss': 0.4354131772767666} | train loss {'Reaction outcome loss': 0.16040672163321892, 'Total loss': 0.16040672163321892}
2022-12-05 22:03:54,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:54,177 INFO:     Epoch: 39
2022-12-05 22:03:54,971 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43596688190171884, 'Total loss': 0.43596688190171884} | train loss {'Reaction outcome loss': 0.15546442270125627, 'Total loss': 0.15546442270125627}
2022-12-05 22:03:54,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:54,972 INFO:     Epoch: 40
2022-12-05 22:03:55,770 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4292125473188799, 'Total loss': 0.4292125473188799} | train loss {'Reaction outcome loss': 0.15568367313639617, 'Total loss': 0.15568367313639617}
2022-12-05 22:03:55,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:55,771 INFO:     Epoch: 41
2022-12-05 22:03:56,570 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44071048602115276, 'Total loss': 0.44071048602115276} | train loss {'Reaction outcome loss': 0.1535534527566698, 'Total loss': 0.1535534527566698}
2022-12-05 22:03:56,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:56,570 INFO:     Epoch: 42
2022-12-05 22:03:57,368 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4333691787581111, 'Total loss': 0.4333691787581111} | train loss {'Reaction outcome loss': 0.150819706542747, 'Total loss': 0.150819706542747}
2022-12-05 22:03:57,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:57,368 INFO:     Epoch: 43
2022-12-05 22:03:58,168 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4295591608036396, 'Total loss': 0.4295591608036396} | train loss {'Reaction outcome loss': 0.1488585497785375, 'Total loss': 0.1488585497785375}
2022-12-05 22:03:58,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:58,168 INFO:     Epoch: 44
2022-12-05 22:03:58,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4433645436237025, 'Total loss': 0.4433645436237025} | train loss {'Reaction outcome loss': 0.14735785511096197, 'Total loss': 0.14735785511096197}
2022-12-05 22:03:58,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:58,965 INFO:     Epoch: 45
2022-12-05 22:03:59,769 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4334112447361613, 'Total loss': 0.4334112447361613} | train loss {'Reaction outcome loss': 0.14384084233991157, 'Total loss': 0.14384084233991157}
2022-12-05 22:03:59,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:03:59,769 INFO:     Epoch: 46
2022-12-05 22:04:00,569 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43723290292329564, 'Total loss': 0.43723290292329564} | train loss {'Reaction outcome loss': 0.14258122443003052, 'Total loss': 0.14258122443003052}
2022-12-05 22:04:00,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:00,570 INFO:     Epoch: 47
2022-12-05 22:04:01,368 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4453072381574054, 'Total loss': 0.4453072381574054} | train loss {'Reaction outcome loss': 0.144936214503928, 'Total loss': 0.144936214503928}
2022-12-05 22:04:01,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:01,368 INFO:     Epoch: 48
2022-12-05 22:04:02,166 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4508002908077351, 'Total loss': 0.4508002908077351} | train loss {'Reaction outcome loss': 0.14127746467390423, 'Total loss': 0.14127746467390423}
2022-12-05 22:04:02,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:02,166 INFO:     Epoch: 49
2022-12-05 22:04:02,964 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44017509734907817, 'Total loss': 0.44017509734907817} | train loss {'Reaction outcome loss': 0.1409028490982306, 'Total loss': 0.1409028490982306}
2022-12-05 22:04:02,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:02,965 INFO:     Epoch: 50
2022-12-05 22:04:03,760 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44964742036752925, 'Total loss': 0.44964742036752925} | train loss {'Reaction outcome loss': 0.14035886330645025, 'Total loss': 0.14035886330645025}
2022-12-05 22:04:03,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:03,760 INFO:     Epoch: 51
2022-12-05 22:04:04,555 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43953864016505173, 'Total loss': 0.43953864016505173} | train loss {'Reaction outcome loss': 0.13810392870058003, 'Total loss': 0.13810392870058003}
2022-12-05 22:04:04,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:04,556 INFO:     Epoch: 52
2022-12-05 22:04:05,352 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44187992152779604, 'Total loss': 0.44187992152779604} | train loss {'Reaction outcome loss': 0.1374232608809638, 'Total loss': 0.1374232608809638}
2022-12-05 22:04:05,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:05,352 INFO:     Epoch: 53
2022-12-05 22:04:06,148 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44245355732219166, 'Total loss': 0.44245355732219166} | train loss {'Reaction outcome loss': 0.1403197020736864, 'Total loss': 0.1403197020736864}
2022-12-05 22:04:06,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:06,148 INFO:     Epoch: 54
2022-12-05 22:04:06,946 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4323903398458348, 'Total loss': 0.4323903398458348} | train loss {'Reaction outcome loss': 0.13753762421937882, 'Total loss': 0.13753762421937882}
2022-12-05 22:04:06,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:06,946 INFO:     Epoch: 55
2022-12-05 22:04:07,742 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4458587117666422, 'Total loss': 0.4458587117666422} | train loss {'Reaction outcome loss': 0.13244052011320376, 'Total loss': 0.13244052011320376}
2022-12-05 22:04:07,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:07,742 INFO:     Epoch: 56
2022-12-05 22:04:08,542 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43847862093947654, 'Total loss': 0.43847862093947654} | train loss {'Reaction outcome loss': 0.13568681437108251, 'Total loss': 0.13568681437108251}
2022-12-05 22:04:08,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:08,542 INFO:     Epoch: 57
2022-12-05 22:04:09,336 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4497092697162961, 'Total loss': 0.4497092697162961} | train loss {'Reaction outcome loss': 0.13237232934882856, 'Total loss': 0.13237232934882856}
2022-12-05 22:04:09,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:09,337 INFO:     Epoch: 58
2022-12-05 22:04:10,132 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4521305392994437, 'Total loss': 0.4521305392994437} | train loss {'Reaction outcome loss': 0.13097105742865262, 'Total loss': 0.13097105742865262}
2022-12-05 22:04:10,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:10,133 INFO:     Epoch: 59
2022-12-05 22:04:10,927 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43884313019902205, 'Total loss': 0.43884313019902205} | train loss {'Reaction outcome loss': 0.13331928487422534, 'Total loss': 0.13331928487422534}
2022-12-05 22:04:10,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:10,927 INFO:     Epoch: 60
2022-12-05 22:04:11,724 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4443448428497758, 'Total loss': 0.4443448428497758} | train loss {'Reaction outcome loss': 0.12999691740214947, 'Total loss': 0.12999691740214947}
2022-12-05 22:04:11,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:11,724 INFO:     Epoch: 61
2022-12-05 22:04:12,522 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43197543815124867, 'Total loss': 0.43197543815124867} | train loss {'Reaction outcome loss': 0.130406339129686, 'Total loss': 0.130406339129686}
2022-12-05 22:04:12,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:12,522 INFO:     Epoch: 62
2022-12-05 22:04:13,316 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45580410957336426, 'Total loss': 0.45580410957336426} | train loss {'Reaction outcome loss': 0.13167139983624834, 'Total loss': 0.13167139983624834}
2022-12-05 22:04:13,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:13,316 INFO:     Epoch: 63
2022-12-05 22:04:14,111 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44783858123213743, 'Total loss': 0.44783858123213743} | train loss {'Reaction outcome loss': 0.13026134676679416, 'Total loss': 0.13026134676679416}
2022-12-05 22:04:14,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:14,111 INFO:     Epoch: 64
2022-12-05 22:04:14,908 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4526086830815604, 'Total loss': 0.4526086830815604} | train loss {'Reaction outcome loss': 0.12694498137360125, 'Total loss': 0.12694498137360125}
2022-12-05 22:04:14,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:14,908 INFO:     Epoch: 65
2022-12-05 22:04:15,703 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4536763935588127, 'Total loss': 0.4536763935588127} | train loss {'Reaction outcome loss': 0.12417540891640226, 'Total loss': 0.12417540891640226}
2022-12-05 22:04:15,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:15,704 INFO:     Epoch: 66
2022-12-05 22:04:16,498 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4491200985950093, 'Total loss': 0.4491200985950093} | train loss {'Reaction outcome loss': 0.12507986867562734, 'Total loss': 0.12507986867562734}
2022-12-05 22:04:16,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:16,499 INFO:     Epoch: 67
2022-12-05 22:04:17,292 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44339093115440636, 'Total loss': 0.44339093115440636} | train loss {'Reaction outcome loss': 0.12562011239413984, 'Total loss': 0.12562011239413984}
2022-12-05 22:04:17,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:17,293 INFO:     Epoch: 68
2022-12-05 22:04:18,090 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4603741581356803, 'Total loss': 0.4603741581356803} | train loss {'Reaction outcome loss': 0.12386198031022348, 'Total loss': 0.12386198031022348}
2022-12-05 22:04:18,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:18,090 INFO:     Epoch: 69
2022-12-05 22:04:18,892 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4408976522295974, 'Total loss': 0.4408976522295974} | train loss {'Reaction outcome loss': 0.12254292804387555, 'Total loss': 0.12254292804387555}
2022-12-05 22:04:18,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:18,893 INFO:     Epoch: 70
2022-12-05 22:04:19,693 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4486757288145464, 'Total loss': 0.4486757288145464} | train loss {'Reaction outcome loss': 0.12507332715018052, 'Total loss': 0.12507332715018052}
2022-12-05 22:04:19,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:19,693 INFO:     Epoch: 71
2022-12-05 22:04:20,496 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4579121224408926, 'Total loss': 0.4579121224408926} | train loss {'Reaction outcome loss': 0.11839051910296634, 'Total loss': 0.11839051910296634}
2022-12-05 22:04:20,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:20,497 INFO:     Epoch: 72
2022-12-05 22:04:21,291 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4514335490936457, 'Total loss': 0.4514335490936457} | train loss {'Reaction outcome loss': 0.12141261530327208, 'Total loss': 0.12141261530327208}
2022-12-05 22:04:21,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:21,291 INFO:     Epoch: 73
2022-12-05 22:04:22,092 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45755892472211707, 'Total loss': 0.45755892472211707} | train loss {'Reaction outcome loss': 0.11828352898022029, 'Total loss': 0.11828352898022029}
2022-12-05 22:04:22,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:22,092 INFO:     Epoch: 74
2022-12-05 22:04:22,892 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44956483622623045, 'Total loss': 0.44956483622623045} | train loss {'Reaction outcome loss': 0.11740850389708953, 'Total loss': 0.11740850389708953}
2022-12-05 22:04:22,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:22,892 INFO:     Epoch: 75
2022-12-05 22:04:23,689 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43431666285492654, 'Total loss': 0.43431666285492654} | train loss {'Reaction outcome loss': 0.11813840689329208, 'Total loss': 0.11813840689329208}
2022-12-05 22:04:23,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:23,689 INFO:     Epoch: 76
2022-12-05 22:04:24,486 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4412866884539294, 'Total loss': 0.4412866884539294} | train loss {'Reaction outcome loss': 0.11817250623839137, 'Total loss': 0.11817250623839137}
2022-12-05 22:04:24,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:24,486 INFO:     Epoch: 77
2022-12-05 22:04:25,284 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44372211535309636, 'Total loss': 0.44372211535309636} | train loss {'Reaction outcome loss': 0.11604898276551025, 'Total loss': 0.11604898276551025}
2022-12-05 22:04:25,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:25,284 INFO:     Epoch: 78
2022-12-05 22:04:26,079 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4401011827380158, 'Total loss': 0.4401011827380158} | train loss {'Reaction outcome loss': 0.11656814086952327, 'Total loss': 0.11656814086952327}
2022-12-05 22:04:26,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:26,079 INFO:     Epoch: 79
2022-12-05 22:04:26,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4593839631524197, 'Total loss': 0.4593839631524197} | train loss {'Reaction outcome loss': 0.113528796977559, 'Total loss': 0.113528796977559}
2022-12-05 22:04:26,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:26,877 INFO:     Epoch: 80
2022-12-05 22:04:27,675 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45434245051339617, 'Total loss': 0.45434245051339617} | train loss {'Reaction outcome loss': 0.11559771740456483, 'Total loss': 0.11559771740456483}
2022-12-05 22:04:27,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:27,675 INFO:     Epoch: 81
2022-12-05 22:04:28,471 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45408611796623055, 'Total loss': 0.45408611796623055} | train loss {'Reaction outcome loss': 0.11822197700892824, 'Total loss': 0.11822197700892824}
2022-12-05 22:04:28,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:28,471 INFO:     Epoch: 82
2022-12-05 22:04:29,270 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45663778241290603, 'Total loss': 0.45663778241290603} | train loss {'Reaction outcome loss': 0.11477124109603618, 'Total loss': 0.11477124109603618}
2022-12-05 22:04:29,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:29,270 INFO:     Epoch: 83
2022-12-05 22:04:30,069 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4503073720044868, 'Total loss': 0.4503073720044868} | train loss {'Reaction outcome loss': 0.11290609330866379, 'Total loss': 0.11290609330866379}
2022-12-05 22:04:30,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:30,070 INFO:     Epoch: 84
2022-12-05 22:04:30,864 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4420917009891466, 'Total loss': 0.4420917009891466} | train loss {'Reaction outcome loss': 0.11491659843964587, 'Total loss': 0.11491659843964587}
2022-12-05 22:04:30,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:30,864 INFO:     Epoch: 85
2022-12-05 22:04:31,664 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4549225246490434, 'Total loss': 0.4549225246490434} | train loss {'Reaction outcome loss': 0.11343210863539711, 'Total loss': 0.11343210863539711}
2022-12-05 22:04:31,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:31,664 INFO:     Epoch: 86
2022-12-05 22:04:32,461 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4598986887654593, 'Total loss': 0.4598986887654593} | train loss {'Reaction outcome loss': 0.112221648038936, 'Total loss': 0.112221648038936}
2022-12-05 22:04:32,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:32,462 INFO:     Epoch: 87
2022-12-05 22:04:33,258 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4526881599842116, 'Total loss': 0.4526881599842116} | train loss {'Reaction outcome loss': 0.1138963653157952, 'Total loss': 0.1138963653157952}
2022-12-05 22:04:33,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:33,258 INFO:     Epoch: 88
2022-12-05 22:04:34,052 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46021514819111936, 'Total loss': 0.46021514819111936} | train loss {'Reaction outcome loss': 0.1133490280313379, 'Total loss': 0.1133490280313379}
2022-12-05 22:04:34,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:34,054 INFO:     Epoch: 89
2022-12-05 22:04:34,851 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4426083841989207, 'Total loss': 0.4426083841989207} | train loss {'Reaction outcome loss': 0.11146172518945402, 'Total loss': 0.11146172518945402}
2022-12-05 22:04:34,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:34,852 INFO:     Epoch: 90
2022-12-05 22:04:35,649 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44846835108690486, 'Total loss': 0.44846835108690486} | train loss {'Reaction outcome loss': 0.11241127753921558, 'Total loss': 0.11241127753921558}
2022-12-05 22:04:35,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:35,649 INFO:     Epoch: 91
2022-12-05 22:04:36,444 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4599892864393633, 'Total loss': 0.4599892864393633} | train loss {'Reaction outcome loss': 0.113738711168338, 'Total loss': 0.113738711168338}
2022-12-05 22:04:36,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:36,445 INFO:     Epoch: 92
2022-12-05 22:04:37,238 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4379271608452464, 'Total loss': 0.4379271608452464} | train loss {'Reaction outcome loss': 0.10981768075714018, 'Total loss': 0.10981768075714018}
2022-12-05 22:04:37,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:37,238 INFO:     Epoch: 93
2022-12-05 22:04:38,033 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43939930096615193, 'Total loss': 0.43939930096615193} | train loss {'Reaction outcome loss': 0.10991608927126038, 'Total loss': 0.10991608927126038}
2022-12-05 22:04:38,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:38,033 INFO:     Epoch: 94
2022-12-05 22:04:38,834 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45293906642947085, 'Total loss': 0.45293906642947085} | train loss {'Reaction outcome loss': 0.10879288307379609, 'Total loss': 0.10879288307379609}
2022-12-05 22:04:38,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:38,834 INFO:     Epoch: 95
2022-12-05 22:04:39,631 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45540407750495643, 'Total loss': 0.45540407750495643} | train loss {'Reaction outcome loss': 0.10834363072443708, 'Total loss': 0.10834363072443708}
2022-12-05 22:04:39,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:39,632 INFO:     Epoch: 96
2022-12-05 22:04:40,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4425640820070755, 'Total loss': 0.4425640820070755} | train loss {'Reaction outcome loss': 0.11152529334381162, 'Total loss': 0.11152529334381162}
2022-12-05 22:04:40,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:40,429 INFO:     Epoch: 97
2022-12-05 22:04:41,227 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43946106385353, 'Total loss': 0.43946106385353} | train loss {'Reaction outcome loss': 0.10827270404477853, 'Total loss': 0.10827270404477853}
2022-12-05 22:04:41,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:41,227 INFO:     Epoch: 98
2022-12-05 22:04:42,024 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44919049705183783, 'Total loss': 0.44919049705183783} | train loss {'Reaction outcome loss': 0.10893661495482113, 'Total loss': 0.10893661495482113}
2022-12-05 22:04:42,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:42,024 INFO:     Epoch: 99
2022-12-05 22:04:42,820 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44325172537288, 'Total loss': 0.44325172537288} | train loss {'Reaction outcome loss': 0.11231282309709507, 'Total loss': 0.11231282309709507}
2022-12-05 22:04:42,820 INFO:     Best model found after epoch 16 of 100.
2022-12-05 22:04:42,820 INFO:   Done with stage: TRAINING
2022-12-05 22:04:42,820 INFO:   Starting stage: EVALUATION
2022-12-05 22:04:42,963 INFO:   Done with stage: EVALUATION
2022-12-05 22:04:42,963 INFO:   Leaving out SEQ value Fold_3
2022-12-05 22:04:42,976 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:04:42,976 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:04:43,618 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:04:43,618 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:04:43,686 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:04:43,686 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:04:43,686 INFO:     No hyperparam tuning for this model
2022-12-05 22:04:43,686 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:04:43,686 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:04:43,687 INFO:     None feature selector for col prot
2022-12-05 22:04:43,687 INFO:     None feature selector for col prot
2022-12-05 22:04:43,687 INFO:     None feature selector for col prot
2022-12-05 22:04:43,688 INFO:     None feature selector for col chem
2022-12-05 22:04:43,688 INFO:     None feature selector for col chem
2022-12-05 22:04:43,688 INFO:     None feature selector for col chem
2022-12-05 22:04:43,688 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:04:43,688 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:04:43,690 INFO:     Number of params in model 215821
2022-12-05 22:04:43,693 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:04:43,693 INFO:   Starting stage: TRAINING
2022-12-05 22:04:43,753 INFO:     Val loss before train {'Reaction outcome loss': 1.0546675913713195, 'Total loss': 1.0546675913713195}
2022-12-05 22:04:43,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:43,753 INFO:     Epoch: 0
2022-12-05 22:04:44,562 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6382258578457616, 'Total loss': 0.6382258578457616} | train loss {'Reaction outcome loss': 0.7977636384720705, 'Total loss': 0.7977636384720705}
2022-12-05 22:04:44,562 INFO:     Found new best model at epoch 0
2022-12-05 22:04:44,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:44,563 INFO:     Epoch: 1
2022-12-05 22:04:45,368 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5315800248221918, 'Total loss': 0.5315800248221918} | train loss {'Reaction outcome loss': 0.545431205204555, 'Total loss': 0.545431205204555}
2022-12-05 22:04:45,369 INFO:     Found new best model at epoch 1
2022-12-05 22:04:45,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:45,369 INFO:     Epoch: 2
2022-12-05 22:04:46,178 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48494250124151056, 'Total loss': 0.48494250124151056} | train loss {'Reaction outcome loss': 0.46999861646671687, 'Total loss': 0.46999861646671687}
2022-12-05 22:04:46,178 INFO:     Found new best model at epoch 2
2022-12-05 22:04:46,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:46,179 INFO:     Epoch: 3
2022-12-05 22:04:46,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4500352545556697, 'Total loss': 0.4500352545556697} | train loss {'Reaction outcome loss': 0.42535417840188866, 'Total loss': 0.42535417840188866}
2022-12-05 22:04:46,975 INFO:     Found new best model at epoch 3
2022-12-05 22:04:46,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:46,976 INFO:     Epoch: 4
2022-12-05 22:04:47,765 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4416787163777785, 'Total loss': 0.4416787163777785} | train loss {'Reaction outcome loss': 0.3990721903893412, 'Total loss': 0.3990721903893412}
2022-12-05 22:04:47,765 INFO:     Found new best model at epoch 4
2022-12-05 22:04:47,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:47,766 INFO:     Epoch: 5
2022-12-05 22:04:48,556 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44125627929514105, 'Total loss': 0.44125627929514105} | train loss {'Reaction outcome loss': 0.37253980429805056, 'Total loss': 0.37253980429805056}
2022-12-05 22:04:48,556 INFO:     Found new best model at epoch 5
2022-12-05 22:04:48,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:48,557 INFO:     Epoch: 6
2022-12-05 22:04:49,347 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4377489970488982, 'Total loss': 0.4377489970488982} | train loss {'Reaction outcome loss': 0.3565981985659015, 'Total loss': 0.3565981985659015}
2022-12-05 22:04:49,347 INFO:     Found new best model at epoch 6
2022-12-05 22:04:49,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:49,348 INFO:     Epoch: 7
2022-12-05 22:04:50,135 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41557427326386626, 'Total loss': 0.41557427326386626} | train loss {'Reaction outcome loss': 0.33636269414303255, 'Total loss': 0.33636269414303255}
2022-12-05 22:04:50,136 INFO:     Found new best model at epoch 7
2022-12-05 22:04:50,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:50,136 INFO:     Epoch: 8
2022-12-05 22:04:50,924 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.417497858743776, 'Total loss': 0.417497858743776} | train loss {'Reaction outcome loss': 0.3194830702275646, 'Total loss': 0.3194830702275646}
2022-12-05 22:04:50,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:50,924 INFO:     Epoch: 9
2022-12-05 22:04:51,717 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41092582724311133, 'Total loss': 0.41092582724311133} | train loss {'Reaction outcome loss': 0.31130740143814867, 'Total loss': 0.31130740143814867}
2022-12-05 22:04:51,718 INFO:     Found new best model at epoch 9
2022-12-05 22:04:51,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:51,719 INFO:     Epoch: 10
2022-12-05 22:04:52,513 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4175390279428525, 'Total loss': 0.4175390279428525} | train loss {'Reaction outcome loss': 0.29748003005373236, 'Total loss': 0.29748003005373236}
2022-12-05 22:04:52,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:52,514 INFO:     Epoch: 11
2022-12-05 22:04:53,301 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3969163815067573, 'Total loss': 0.3969163815067573} | train loss {'Reaction outcome loss': 0.2858157429159904, 'Total loss': 0.2858157429159904}
2022-12-05 22:04:53,301 INFO:     Found new best model at epoch 11
2022-12-05 22:04:53,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:53,302 INFO:     Epoch: 12
2022-12-05 22:04:54,088 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40433153239163483, 'Total loss': 0.40433153239163483} | train loss {'Reaction outcome loss': 0.27492606673313646, 'Total loss': 0.27492606673313646}
2022-12-05 22:04:54,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:54,088 INFO:     Epoch: 13
2022-12-05 22:04:54,882 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3938514734195037, 'Total loss': 0.3938514734195037} | train loss {'Reaction outcome loss': 0.26769073105284147, 'Total loss': 0.26769073105284147}
2022-12-05 22:04:54,882 INFO:     Found new best model at epoch 13
2022-12-05 22:04:54,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:54,883 INFO:     Epoch: 14
2022-12-05 22:04:55,671 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40120148760351265, 'Total loss': 0.40120148760351265} | train loss {'Reaction outcome loss': 0.2594547770765363, 'Total loss': 0.2594547770765363}
2022-12-05 22:04:55,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:55,671 INFO:     Epoch: 15
2022-12-05 22:04:56,459 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4002185757906938, 'Total loss': 0.4002185757906938} | train loss {'Reaction outcome loss': 0.24990167438375707, 'Total loss': 0.24990167438375707}
2022-12-05 22:04:56,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:56,459 INFO:     Epoch: 16
2022-12-05 22:04:57,248 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.38792535120790655, 'Total loss': 0.38792535120790655} | train loss {'Reaction outcome loss': 0.24371824164171607, 'Total loss': 0.24371824164171607}
2022-12-05 22:04:57,248 INFO:     Found new best model at epoch 16
2022-12-05 22:04:57,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:57,249 INFO:     Epoch: 17
2022-12-05 22:04:58,039 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4061391102996739, 'Total loss': 0.4061391102996739} | train loss {'Reaction outcome loss': 0.23310615374725693, 'Total loss': 0.23310615374725693}
2022-12-05 22:04:58,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:58,039 INFO:     Epoch: 18
2022-12-05 22:04:58,837 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40611460737206717, 'Total loss': 0.40611460737206717} | train loss {'Reaction outcome loss': 0.2312423048122805, 'Total loss': 0.2312423048122805}
2022-12-05 22:04:58,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:58,838 INFO:     Epoch: 19
2022-12-05 22:04:59,628 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4246855608441613, 'Total loss': 0.4246855608441613} | train loss {'Reaction outcome loss': 0.2230337125154174, 'Total loss': 0.2230337125154174}
2022-12-05 22:04:59,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:04:59,628 INFO:     Epoch: 20
2022-12-05 22:05:00,418 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38993829962882126, 'Total loss': 0.38993829962882126} | train loss {'Reaction outcome loss': 0.21882750556177022, 'Total loss': 0.21882750556177022}
2022-12-05 22:05:00,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:00,419 INFO:     Epoch: 21
2022-12-05 22:05:01,207 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39142519066279585, 'Total loss': 0.39142519066279585} | train loss {'Reaction outcome loss': 0.21355331664790914, 'Total loss': 0.21355331664790914}
2022-12-05 22:05:01,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:01,207 INFO:     Epoch: 22
2022-12-05 22:05:02,006 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3912008546970107, 'Total loss': 0.3912008546970107} | train loss {'Reaction outcome loss': 0.2092123033744948, 'Total loss': 0.2092123033744948}
2022-12-05 22:05:02,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:02,006 INFO:     Epoch: 23
2022-12-05 22:05:02,795 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4029542228037661, 'Total loss': 0.4029542228037661} | train loss {'Reaction outcome loss': 0.2066297704924126, 'Total loss': 0.2066297704924126}
2022-12-05 22:05:02,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:02,796 INFO:     Epoch: 24
2022-12-05 22:05:03,584 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40226774451333436, 'Total loss': 0.40226774451333436} | train loss {'Reaction outcome loss': 0.2014184094965458, 'Total loss': 0.2014184094965458}
2022-12-05 22:05:03,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:03,584 INFO:     Epoch: 25
2022-12-05 22:05:04,374 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41257928777486086, 'Total loss': 0.41257928777486086} | train loss {'Reaction outcome loss': 0.19528788429285798, 'Total loss': 0.19528788429285798}
2022-12-05 22:05:04,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:04,374 INFO:     Epoch: 26
2022-12-05 22:05:05,164 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4014531025155024, 'Total loss': 0.4014531025155024} | train loss {'Reaction outcome loss': 0.19174678725551586, 'Total loss': 0.19174678725551586}
2022-12-05 22:05:05,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:05,165 INFO:     Epoch: 27
2022-12-05 22:05:05,957 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40823558548634703, 'Total loss': 0.40823558548634703} | train loss {'Reaction outcome loss': 0.18791880203144892, 'Total loss': 0.18791880203144892}
2022-12-05 22:05:05,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:05,958 INFO:     Epoch: 28
2022-12-05 22:05:06,750 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41162869266488333, 'Total loss': 0.41162869266488333} | train loss {'Reaction outcome loss': 0.18342221630166988, 'Total loss': 0.18342221630166988}
2022-12-05 22:05:06,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:06,750 INFO:     Epoch: 29
2022-12-05 22:05:07,538 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4041841507635333, 'Total loss': 0.4041841507635333} | train loss {'Reaction outcome loss': 0.18144803761827702, 'Total loss': 0.18144803761827702}
2022-12-05 22:05:07,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:07,538 INFO:     Epoch: 30
2022-12-05 22:05:08,331 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39988562098534947, 'Total loss': 0.39988562098534947} | train loss {'Reaction outcome loss': 0.17725433326345316, 'Total loss': 0.17725433326345316}
2022-12-05 22:05:08,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:08,332 INFO:     Epoch: 31
2022-12-05 22:05:09,127 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4147279868749055, 'Total loss': 0.4147279868749055} | train loss {'Reaction outcome loss': 0.1767462774807093, 'Total loss': 0.1767462774807093}
2022-12-05 22:05:09,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:09,128 INFO:     Epoch: 32
2022-12-05 22:05:09,919 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42300949415022676, 'Total loss': 0.42300949415022676} | train loss {'Reaction outcome loss': 0.17411409855193022, 'Total loss': 0.17411409855193022}
2022-12-05 22:05:09,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:09,919 INFO:     Epoch: 33
2022-12-05 22:05:10,705 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4105054463513873, 'Total loss': 0.4105054463513873} | train loss {'Reaction outcome loss': 0.17078088523477924, 'Total loss': 0.17078088523477924}
2022-12-05 22:05:10,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:10,706 INFO:     Epoch: 34
2022-12-05 22:05:11,495 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4324545025486838, 'Total loss': 0.4324545025486838} | train loss {'Reaction outcome loss': 0.1682310464354802, 'Total loss': 0.1682310464354802}
2022-12-05 22:05:11,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:11,496 INFO:     Epoch: 35
2022-12-05 22:05:12,289 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4036028121005405, 'Total loss': 0.4036028121005405} | train loss {'Reaction outcome loss': 0.1646985645500981, 'Total loss': 0.1646985645500981}
2022-12-05 22:05:12,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:12,289 INFO:     Epoch: 36
2022-12-05 22:05:13,078 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4130306667224927, 'Total loss': 0.4130306667224927} | train loss {'Reaction outcome loss': 0.16323077857722434, 'Total loss': 0.16323077857722434}
2022-12-05 22:05:13,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:13,078 INFO:     Epoch: 37
2022-12-05 22:05:13,865 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41747182268988003, 'Total loss': 0.41747182268988003} | train loss {'Reaction outcome loss': 0.1625127880244839, 'Total loss': 0.1625127880244839}
2022-12-05 22:05:13,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:13,865 INFO:     Epoch: 38
2022-12-05 22:05:14,657 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41898557069626724, 'Total loss': 0.41898557069626724} | train loss {'Reaction outcome loss': 0.1591304107664191, 'Total loss': 0.1591304107664191}
2022-12-05 22:05:14,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:14,657 INFO:     Epoch: 39
2022-12-05 22:05:15,446 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40630342675880954, 'Total loss': 0.40630342675880954} | train loss {'Reaction outcome loss': 0.15831827517522842, 'Total loss': 0.15831827517522842}
2022-12-05 22:05:15,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:15,446 INFO:     Epoch: 40
2022-12-05 22:05:16,231 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4193615134466778, 'Total loss': 0.4193615134466778} | train loss {'Reaction outcome loss': 0.15369430129625358, 'Total loss': 0.15369430129625358}
2022-12-05 22:05:16,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:16,231 INFO:     Epoch: 41
2022-12-05 22:05:17,018 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4130026044493372, 'Total loss': 0.4130026044493372} | train loss {'Reaction outcome loss': 0.15096926788742446, 'Total loss': 0.15096926788742446}
2022-12-05 22:05:17,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:17,018 INFO:     Epoch: 42
2022-12-05 22:05:17,806 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40833680738102307, 'Total loss': 0.40833680738102307} | train loss {'Reaction outcome loss': 0.15223095698320135, 'Total loss': 0.15223095698320135}
2022-12-05 22:05:17,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:17,807 INFO:     Epoch: 43
2022-12-05 22:05:18,593 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42381629754196515, 'Total loss': 0.42381629754196515} | train loss {'Reaction outcome loss': 0.15126886027960146, 'Total loss': 0.15126886027960146}
2022-12-05 22:05:18,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:18,593 INFO:     Epoch: 44
2022-12-05 22:05:19,379 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4174559417773377, 'Total loss': 0.4174559417773377} | train loss {'Reaction outcome loss': 0.14851520172491364, 'Total loss': 0.14851520172491364}
2022-12-05 22:05:19,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:19,380 INFO:     Epoch: 45
2022-12-05 22:05:20,169 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4288886704228141, 'Total loss': 0.4288886704228141} | train loss {'Reaction outcome loss': 0.14887143844852643, 'Total loss': 0.14887143844852643}
2022-12-05 22:05:20,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:20,169 INFO:     Epoch: 46
2022-12-05 22:05:20,955 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4246871463150125, 'Total loss': 0.4246871463150125} | train loss {'Reaction outcome loss': 0.14753207713365554, 'Total loss': 0.14753207713365554}
2022-12-05 22:05:20,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:20,955 INFO:     Epoch: 47
2022-12-05 22:05:21,743 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41846152919937263, 'Total loss': 0.41846152919937263} | train loss {'Reaction outcome loss': 0.1480980379620985, 'Total loss': 0.1480980379620985}
2022-12-05 22:05:21,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:21,744 INFO:     Epoch: 48
2022-12-05 22:05:22,529 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.423146554692225, 'Total loss': 0.423146554692225} | train loss {'Reaction outcome loss': 0.1444118081839109, 'Total loss': 0.1444118081839109}
2022-12-05 22:05:22,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:22,529 INFO:     Epoch: 49
2022-12-05 22:05:23,314 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4286108233711936, 'Total loss': 0.4286108233711936} | train loss {'Reaction outcome loss': 0.14127573059225568, 'Total loss': 0.14127573059225568}
2022-12-05 22:05:23,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:23,315 INFO:     Epoch: 50
2022-12-05 22:05:24,102 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4314100972630761, 'Total loss': 0.4314100972630761} | train loss {'Reaction outcome loss': 0.1408475293644837, 'Total loss': 0.1408475293644837}
2022-12-05 22:05:24,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:24,103 INFO:     Epoch: 51
2022-12-05 22:05:24,888 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4229206449606202, 'Total loss': 0.4229206449606202} | train loss {'Reaction outcome loss': 0.14121789063269996, 'Total loss': 0.14121789063269996}
2022-12-05 22:05:24,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:24,888 INFO:     Epoch: 52
2022-12-05 22:05:25,672 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4305311377075585, 'Total loss': 0.4305311377075585} | train loss {'Reaction outcome loss': 0.14150468213673756, 'Total loss': 0.14150468213673756}
2022-12-05 22:05:25,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:25,673 INFO:     Epoch: 53
2022-12-05 22:05:26,457 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4170934595167637, 'Total loss': 0.4170934595167637} | train loss {'Reaction outcome loss': 0.13908627846715402, 'Total loss': 0.13908627846715402}
2022-12-05 22:05:26,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:26,457 INFO:     Epoch: 54
2022-12-05 22:05:27,242 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.440534133464098, 'Total loss': 0.440534133464098} | train loss {'Reaction outcome loss': 0.13785182969758705, 'Total loss': 0.13785182969758705}
2022-12-05 22:05:27,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:27,243 INFO:     Epoch: 55
2022-12-05 22:05:28,027 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42353719676082785, 'Total loss': 0.42353719676082785} | train loss {'Reaction outcome loss': 0.13553591175955168, 'Total loss': 0.13553591175955168}
2022-12-05 22:05:28,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:28,028 INFO:     Epoch: 56
2022-12-05 22:05:28,812 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4150846397334879, 'Total loss': 0.4150846397334879} | train loss {'Reaction outcome loss': 0.1343655557048564, 'Total loss': 0.1343655557048564}
2022-12-05 22:05:28,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:28,812 INFO:     Epoch: 57
2022-12-05 22:05:29,600 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4232009072703394, 'Total loss': 0.4232009072703394} | train loss {'Reaction outcome loss': 0.13548293373718553, 'Total loss': 0.13548293373718553}
2022-12-05 22:05:29,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:29,600 INFO:     Epoch: 58
2022-12-05 22:05:30,384 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42367008641700854, 'Total loss': 0.42367008641700854} | train loss {'Reaction outcome loss': 0.13169757680093147, 'Total loss': 0.13169757680093147}
2022-12-05 22:05:30,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:30,385 INFO:     Epoch: 59
2022-12-05 22:05:31,186 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4298452064394951, 'Total loss': 0.4298452064394951} | train loss {'Reaction outcome loss': 0.13118407216911412, 'Total loss': 0.13118407216911412}
2022-12-05 22:05:31,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:31,187 INFO:     Epoch: 60
2022-12-05 22:05:31,990 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4310994635928761, 'Total loss': 0.4310994635928761} | train loss {'Reaction outcome loss': 0.13315628283486075, 'Total loss': 0.13315628283486075}
2022-12-05 22:05:31,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:31,990 INFO:     Epoch: 61
2022-12-05 22:05:32,794 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4353939247402278, 'Total loss': 0.4353939247402278} | train loss {'Reaction outcome loss': 0.12960730868828843, 'Total loss': 0.12960730868828843}
2022-12-05 22:05:32,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:32,794 INFO:     Epoch: 62
2022-12-05 22:05:33,595 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41396687007297506, 'Total loss': 0.41396687007297506} | train loss {'Reaction outcome loss': 0.13070682325989616, 'Total loss': 0.13070682325989616}
2022-12-05 22:05:33,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:33,596 INFO:     Epoch: 63
2022-12-05 22:05:34,399 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41888664764436806, 'Total loss': 0.41888664764436806} | train loss {'Reaction outcome loss': 0.12724971943059746, 'Total loss': 0.12724971943059746}
2022-12-05 22:05:34,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:34,399 INFO:     Epoch: 64
2022-12-05 22:05:35,205 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43785265359011566, 'Total loss': 0.43785265359011566} | train loss {'Reaction outcome loss': 0.12819284567115258, 'Total loss': 0.12819284567115258}
2022-12-05 22:05:35,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:35,205 INFO:     Epoch: 65
2022-12-05 22:05:36,014 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45411076938564127, 'Total loss': 0.45411076938564127} | train loss {'Reaction outcome loss': 0.13124386961666906, 'Total loss': 0.13124386961666906}
2022-12-05 22:05:36,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:36,015 INFO:     Epoch: 66
2022-12-05 22:05:36,822 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42201110381971707, 'Total loss': 0.42201110381971707} | train loss {'Reaction outcome loss': 0.12685787762914386, 'Total loss': 0.12685787762914386}
2022-12-05 22:05:36,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:36,822 INFO:     Epoch: 67
2022-12-05 22:05:37,630 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.419887021607296, 'Total loss': 0.419887021607296} | train loss {'Reaction outcome loss': 0.12544452212750912, 'Total loss': 0.12544452212750912}
2022-12-05 22:05:37,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:37,630 INFO:     Epoch: 68
2022-12-05 22:05:38,432 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43173327263106, 'Total loss': 0.43173327263106} | train loss {'Reaction outcome loss': 0.1261850558677498, 'Total loss': 0.1261850558677498}
2022-12-05 22:05:38,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:38,433 INFO:     Epoch: 69
2022-12-05 22:05:39,235 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42636249476874416, 'Total loss': 0.42636249476874416} | train loss {'Reaction outcome loss': 0.12601315202001406, 'Total loss': 0.12601315202001406}
2022-12-05 22:05:39,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:39,235 INFO:     Epoch: 70
2022-12-05 22:05:40,044 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4186626242643053, 'Total loss': 0.4186626242643053} | train loss {'Reaction outcome loss': 0.126965201315375, 'Total loss': 0.126965201315375}
2022-12-05 22:05:40,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:40,044 INFO:     Epoch: 71
2022-12-05 22:05:40,852 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43794891238212585, 'Total loss': 0.43794891238212585} | train loss {'Reaction outcome loss': 0.1249397692593689, 'Total loss': 0.1249397692593689}
2022-12-05 22:05:40,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:40,852 INFO:     Epoch: 72
2022-12-05 22:05:41,664 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4090603312308138, 'Total loss': 0.4090603312308138} | train loss {'Reaction outcome loss': 0.123852433233845, 'Total loss': 0.123852433233845}
2022-12-05 22:05:41,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:41,665 INFO:     Epoch: 73
2022-12-05 22:05:42,472 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42181362702765246, 'Total loss': 0.42181362702765246} | train loss {'Reaction outcome loss': 0.12409658577977395, 'Total loss': 0.12409658577977395}
2022-12-05 22:05:42,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:42,473 INFO:     Epoch: 74
2022-12-05 22:05:43,281 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42958006262779236, 'Total loss': 0.42958006262779236} | train loss {'Reaction outcome loss': 0.1229074605227429, 'Total loss': 0.1229074605227429}
2022-12-05 22:05:43,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:43,281 INFO:     Epoch: 75
2022-12-05 22:05:44,086 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41601850939067925, 'Total loss': 0.41601850939067925} | train loss {'Reaction outcome loss': 0.1210652413188803, 'Total loss': 0.1210652413188803}
2022-12-05 22:05:44,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:44,087 INFO:     Epoch: 76
2022-12-05 22:05:44,892 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4489016485485164, 'Total loss': 0.4489016485485164} | train loss {'Reaction outcome loss': 0.12073100714431126, 'Total loss': 0.12073100714431126}
2022-12-05 22:05:44,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:44,892 INFO:     Epoch: 77
2022-12-05 22:05:45,697 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4396785856647925, 'Total loss': 0.4396785856647925} | train loss {'Reaction outcome loss': 0.12203416388329803, 'Total loss': 0.12203416388329803}
2022-12-05 22:05:45,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:45,697 INFO:     Epoch: 78
2022-12-05 22:05:46,492 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4667981206016107, 'Total loss': 0.4667981206016107} | train loss {'Reaction outcome loss': 0.1218999951279589, 'Total loss': 0.1218999951279589}
2022-12-05 22:05:46,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:46,492 INFO:     Epoch: 79
2022-12-05 22:05:47,280 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43852820941670373, 'Total loss': 0.43852820941670373} | train loss {'Reaction outcome loss': 0.11819874405176664, 'Total loss': 0.11819874405176664}
2022-12-05 22:05:47,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:47,280 INFO:     Epoch: 80
2022-12-05 22:05:48,066 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43098635565150867, 'Total loss': 0.43098635565150867} | train loss {'Reaction outcome loss': 0.11841835682185328, 'Total loss': 0.11841835682185328}
2022-12-05 22:05:48,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:48,066 INFO:     Epoch: 81
2022-12-05 22:05:48,851 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4298385227607055, 'Total loss': 0.4298385227607055} | train loss {'Reaction outcome loss': 0.11900321891037177, 'Total loss': 0.11900321891037177}
2022-12-05 22:05:48,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:48,851 INFO:     Epoch: 82
2022-12-05 22:05:49,639 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4234003864906051, 'Total loss': 0.4234003864906051} | train loss {'Reaction outcome loss': 0.11908160762823358, 'Total loss': 0.11908160762823358}
2022-12-05 22:05:49,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:49,640 INFO:     Epoch: 83
2022-12-05 22:05:50,432 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4323128052055836, 'Total loss': 0.4323128052055836} | train loss {'Reaction outcome loss': 0.11632991194801064, 'Total loss': 0.11632991194801064}
2022-12-05 22:05:50,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:50,432 INFO:     Epoch: 84
2022-12-05 22:05:51,223 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43042019415985455, 'Total loss': 0.43042019415985455} | train loss {'Reaction outcome loss': 0.11704358406821076, 'Total loss': 0.11704358406821076}
2022-12-05 22:05:51,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:51,223 INFO:     Epoch: 85
2022-12-05 22:05:52,012 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4447595715861429, 'Total loss': 0.4447595715861429} | train loss {'Reaction outcome loss': 0.1180710025283755, 'Total loss': 0.1180710025283755}
2022-12-05 22:05:52,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:52,013 INFO:     Epoch: 86
2022-12-05 22:05:52,803 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41324878006840166, 'Total loss': 0.41324878006840166} | train loss {'Reaction outcome loss': 0.11981149274779826, 'Total loss': 0.11981149274779826}
2022-12-05 22:05:52,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:52,803 INFO:     Epoch: 87
2022-12-05 22:05:53,597 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41957347840070724, 'Total loss': 0.41957347840070724} | train loss {'Reaction outcome loss': 0.1154626571212192, 'Total loss': 0.1154626571212192}
2022-12-05 22:05:53,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:53,598 INFO:     Epoch: 88
2022-12-05 22:05:54,385 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4278947524726391, 'Total loss': 0.4278947524726391} | train loss {'Reaction outcome loss': 0.11633865536779774, 'Total loss': 0.11633865536779774}
2022-12-05 22:05:54,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:54,386 INFO:     Epoch: 89
2022-12-05 22:05:55,172 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4171868432313204, 'Total loss': 0.4171868432313204} | train loss {'Reaction outcome loss': 0.11534981130793387, 'Total loss': 0.11534981130793387}
2022-12-05 22:05:55,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:55,173 INFO:     Epoch: 90
2022-12-05 22:05:55,962 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4238399629565803, 'Total loss': 0.4238399629565803} | train loss {'Reaction outcome loss': 0.11686836157602315, 'Total loss': 0.11686836157602315}
2022-12-05 22:05:55,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:55,962 INFO:     Epoch: 91
2022-12-05 22:05:56,747 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42974116890267894, 'Total loss': 0.42974116890267894} | train loss {'Reaction outcome loss': 0.11458042061754635, 'Total loss': 0.11458042061754635}
2022-12-05 22:05:56,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:56,747 INFO:     Epoch: 92
2022-12-05 22:05:57,536 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4277322944253683, 'Total loss': 0.4277322944253683} | train loss {'Reaction outcome loss': 0.11452632495487222, 'Total loss': 0.11452632495487222}
2022-12-05 22:05:57,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:57,537 INFO:     Epoch: 93
2022-12-05 22:05:58,323 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.438889719884504, 'Total loss': 0.438889719884504} | train loss {'Reaction outcome loss': 0.11592072273547552, 'Total loss': 0.11592072273547552}
2022-12-05 22:05:58,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:58,323 INFO:     Epoch: 94
2022-12-05 22:05:59,108 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43343840895051305, 'Total loss': 0.43343840895051305} | train loss {'Reaction outcome loss': 0.11322647417154239, 'Total loss': 0.11322647417154239}
2022-12-05 22:05:59,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:59,108 INFO:     Epoch: 95
2022-12-05 22:05:59,893 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4245616891844706, 'Total loss': 0.4245616891844706} | train loss {'Reaction outcome loss': 0.11635839998417971, 'Total loss': 0.11635839998417971}
2022-12-05 22:05:59,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:05:59,894 INFO:     Epoch: 96
2022-12-05 22:06:00,681 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42836006290533324, 'Total loss': 0.42836006290533324} | train loss {'Reaction outcome loss': 0.11731306629217401, 'Total loss': 0.11731306629217401}
2022-12-05 22:06:00,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:00,681 INFO:     Epoch: 97
2022-12-05 22:06:01,469 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4321177075193687, 'Total loss': 0.4321177075193687} | train loss {'Reaction outcome loss': 0.11268292107828418, 'Total loss': 0.11268292107828418}
2022-12-05 22:06:01,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:01,469 INFO:     Epoch: 98
2022-12-05 22:06:02,254 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4315307733010162, 'Total loss': 0.4315307733010162} | train loss {'Reaction outcome loss': 0.11656637158701007, 'Total loss': 0.11656637158701007}
2022-12-05 22:06:02,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:02,254 INFO:     Epoch: 99
2022-12-05 22:06:03,041 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41819521683183586, 'Total loss': 0.41819521683183586} | train loss {'Reaction outcome loss': 0.11180317523528119, 'Total loss': 0.11180317523528119}
2022-12-05 22:06:03,041 INFO:     Best model found after epoch 17 of 100.
2022-12-05 22:06:03,041 INFO:   Done with stage: TRAINING
2022-12-05 22:06:03,041 INFO:   Starting stage: EVALUATION
2022-12-05 22:06:03,173 INFO:   Done with stage: EVALUATION
2022-12-05 22:06:03,173 INFO:   Leaving out SEQ value Fold_4
2022-12-05 22:06:03,186 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:06:03,186 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:06:03,844 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:06:03,844 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:06:03,913 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:06:03,913 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:06:03,913 INFO:     No hyperparam tuning for this model
2022-12-05 22:06:03,913 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:06:03,913 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:06:03,914 INFO:     None feature selector for col prot
2022-12-05 22:06:03,914 INFO:     None feature selector for col prot
2022-12-05 22:06:03,914 INFO:     None feature selector for col prot
2022-12-05 22:06:03,915 INFO:     None feature selector for col chem
2022-12-05 22:06:03,915 INFO:     None feature selector for col chem
2022-12-05 22:06:03,915 INFO:     None feature selector for col chem
2022-12-05 22:06:03,915 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:06:03,915 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:06:03,917 INFO:     Number of params in model 215821
2022-12-05 22:06:03,920 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:06:03,920 INFO:   Starting stage: TRAINING
2022-12-05 22:06:03,981 INFO:     Val loss before train {'Reaction outcome loss': 1.0278239128264515, 'Total loss': 1.0278239128264515}
2022-12-05 22:06:03,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:03,981 INFO:     Epoch: 0
2022-12-05 22:06:04,778 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6268704730001363, 'Total loss': 0.6268704730001363} | train loss {'Reaction outcome loss': 0.8025570779798492, 'Total loss': 0.8025570779798492}
2022-12-05 22:06:04,778 INFO:     Found new best model at epoch 0
2022-12-05 22:06:04,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:04,779 INFO:     Epoch: 1
2022-12-05 22:06:05,573 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5257990224794908, 'Total loss': 0.5257990224794908} | train loss {'Reaction outcome loss': 0.5461212511985533, 'Total loss': 0.5461212511985533}
2022-12-05 22:06:05,573 INFO:     Found new best model at epoch 1
2022-12-05 22:06:05,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:05,574 INFO:     Epoch: 2
2022-12-05 22:06:06,372 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.488682724874128, 'Total loss': 0.488682724874128} | train loss {'Reaction outcome loss': 0.4765777563255641, 'Total loss': 0.4765777563255641}
2022-12-05 22:06:06,372 INFO:     Found new best model at epoch 2
2022-12-05 22:06:06,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:06,373 INFO:     Epoch: 3
2022-12-05 22:06:07,168 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4883953034877777, 'Total loss': 0.4883953034877777} | train loss {'Reaction outcome loss': 0.43294557784834214, 'Total loss': 0.43294557784834214}
2022-12-05 22:06:07,169 INFO:     Found new best model at epoch 3
2022-12-05 22:06:07,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:07,169 INFO:     Epoch: 4
2022-12-05 22:06:07,968 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46244504912333056, 'Total loss': 0.46244504912333056} | train loss {'Reaction outcome loss': 0.4053649365180923, 'Total loss': 0.4053649365180923}
2022-12-05 22:06:07,970 INFO:     Found new best model at epoch 4
2022-12-05 22:06:07,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:07,970 INFO:     Epoch: 5
2022-12-05 22:06:08,767 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4542835659601472, 'Total loss': 0.4542835659601472} | train loss {'Reaction outcome loss': 0.3835203946838456, 'Total loss': 0.3835203946838456}
2022-12-05 22:06:08,768 INFO:     Found new best model at epoch 5
2022-12-05 22:06:08,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:08,768 INFO:     Epoch: 6
2022-12-05 22:06:09,563 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4506943764334375, 'Total loss': 0.4506943764334375} | train loss {'Reaction outcome loss': 0.36163571582085663, 'Total loss': 0.36163571582085663}
2022-12-05 22:06:09,564 INFO:     Found new best model at epoch 6
2022-12-05 22:06:09,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:09,564 INFO:     Epoch: 7
2022-12-05 22:06:10,363 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44943521154875105, 'Total loss': 0.44943521154875105} | train loss {'Reaction outcome loss': 0.3436883123170945, 'Total loss': 0.3436883123170945}
2022-12-05 22:06:10,363 INFO:     Found new best model at epoch 7
2022-12-05 22:06:10,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:10,364 INFO:     Epoch: 8
2022-12-05 22:06:11,165 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4305258994414048, 'Total loss': 0.4305258994414048} | train loss {'Reaction outcome loss': 0.32723009457150776, 'Total loss': 0.32723009457150776}
2022-12-05 22:06:11,165 INFO:     Found new best model at epoch 8
2022-12-05 22:06:11,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:11,166 INFO:     Epoch: 9
2022-12-05 22:06:11,963 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4289330169558525, 'Total loss': 0.4289330169558525} | train loss {'Reaction outcome loss': 0.315894958112509, 'Total loss': 0.315894958112509}
2022-12-05 22:06:11,963 INFO:     Found new best model at epoch 9
2022-12-05 22:06:11,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:11,964 INFO:     Epoch: 10
2022-12-05 22:06:12,764 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4302864487875592, 'Total loss': 0.4302864487875592} | train loss {'Reaction outcome loss': 0.29897210879191277, 'Total loss': 0.29897210879191277}
2022-12-05 22:06:12,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:12,764 INFO:     Epoch: 11
2022-12-05 22:06:13,558 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42950778115879407, 'Total loss': 0.42950778115879407} | train loss {'Reaction outcome loss': 0.2898744063812398, 'Total loss': 0.2898744063812398}
2022-12-05 22:06:13,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:13,559 INFO:     Epoch: 12
2022-12-05 22:06:14,353 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41761381043629214, 'Total loss': 0.41761381043629214} | train loss {'Reaction outcome loss': 0.28388292447573715, 'Total loss': 0.28388292447573715}
2022-12-05 22:06:14,354 INFO:     Found new best model at epoch 12
2022-12-05 22:06:14,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:14,355 INFO:     Epoch: 13
2022-12-05 22:06:15,153 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4195471988482909, 'Total loss': 0.4195471988482909} | train loss {'Reaction outcome loss': 0.2686642615965778, 'Total loss': 0.2686642615965778}
2022-12-05 22:06:15,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:15,153 INFO:     Epoch: 14
2022-12-05 22:06:15,950 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4306370196017352, 'Total loss': 0.4306370196017352} | train loss {'Reaction outcome loss': 0.2621691287645409, 'Total loss': 0.2621691287645409}
2022-12-05 22:06:15,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:15,950 INFO:     Epoch: 15
2022-12-05 22:06:16,746 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4183946583758701, 'Total loss': 0.4183946583758701} | train loss {'Reaction outcome loss': 0.2549997112984138, 'Total loss': 0.2549997112984138}
2022-12-05 22:06:16,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:16,746 INFO:     Epoch: 16
2022-12-05 22:06:17,544 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43128899417140265, 'Total loss': 0.43128899417140265} | train loss {'Reaction outcome loss': 0.24462521765681525, 'Total loss': 0.24462521765681525}
2022-12-05 22:06:17,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:17,544 INFO:     Epoch: 17
2022-12-05 22:06:18,347 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43305654518983583, 'Total loss': 0.43305654518983583} | train loss {'Reaction outcome loss': 0.2426872573372337, 'Total loss': 0.2426872573372337}
2022-12-05 22:06:18,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:18,348 INFO:     Epoch: 18
2022-12-05 22:06:19,143 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44095347212119534, 'Total loss': 0.44095347212119534} | train loss {'Reaction outcome loss': 0.2317809265767855, 'Total loss': 0.2317809265767855}
2022-12-05 22:06:19,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:19,143 INFO:     Epoch: 19
2022-12-05 22:06:19,938 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4380984790623188, 'Total loss': 0.4380984790623188} | train loss {'Reaction outcome loss': 0.22618086726194428, 'Total loss': 0.22618086726194428}
2022-12-05 22:06:19,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:19,938 INFO:     Epoch: 20
2022-12-05 22:06:20,739 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42774012413891876, 'Total loss': 0.42774012413891876} | train loss {'Reaction outcome loss': 0.21912082691015977, 'Total loss': 0.21912082691015977}
2022-12-05 22:06:20,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:20,739 INFO:     Epoch: 21
2022-12-05 22:06:21,536 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4172057866711508, 'Total loss': 0.4172057866711508} | train loss {'Reaction outcome loss': 0.21599345044383117, 'Total loss': 0.21599345044383117}
2022-12-05 22:06:21,536 INFO:     Found new best model at epoch 21
2022-12-05 22:06:21,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:21,537 INFO:     Epoch: 22
2022-12-05 22:06:22,333 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4386360760439526, 'Total loss': 0.4386360760439526} | train loss {'Reaction outcome loss': 0.2096403399782796, 'Total loss': 0.2096403399782796}
2022-12-05 22:06:22,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:22,333 INFO:     Epoch: 23
2022-12-05 22:06:23,132 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43810408731753175, 'Total loss': 0.43810408731753175} | train loss {'Reaction outcome loss': 0.20816031702223323, 'Total loss': 0.20816031702223323}
2022-12-05 22:06:23,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:23,132 INFO:     Epoch: 24
2022-12-05 22:06:23,934 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4340167275883935, 'Total loss': 0.4340167275883935} | train loss {'Reaction outcome loss': 0.2034354631849114, 'Total loss': 0.2034354631849114}
2022-12-05 22:06:23,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:23,934 INFO:     Epoch: 25
2022-12-05 22:06:24,728 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4466037933122028, 'Total loss': 0.4466037933122028} | train loss {'Reaction outcome loss': 0.19849042073192616, 'Total loss': 0.19849042073192616}
2022-12-05 22:06:24,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:24,728 INFO:     Epoch: 26
2022-12-05 22:06:25,526 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4653093818236481, 'Total loss': 0.4653093818236481} | train loss {'Reaction outcome loss': 0.19341658202991371, 'Total loss': 0.19341658202991371}
2022-12-05 22:06:25,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:25,526 INFO:     Epoch: 27
2022-12-05 22:06:26,327 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44264092872088606, 'Total loss': 0.44264092872088606} | train loss {'Reaction outcome loss': 0.19161673944683805, 'Total loss': 0.19161673944683805}
2022-12-05 22:06:26,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:26,327 INFO:     Epoch: 28
2022-12-05 22:06:27,125 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4512673626569184, 'Total loss': 0.4512673626569184} | train loss {'Reaction outcome loss': 0.18653151941215318, 'Total loss': 0.18653151941215318}
2022-12-05 22:06:27,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:27,126 INFO:     Epoch: 29
2022-12-05 22:06:27,922 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45306607098741963, 'Total loss': 0.45306607098741963} | train loss {'Reaction outcome loss': 0.1821530986156675, 'Total loss': 0.1821530986156675}
2022-12-05 22:06:27,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:27,922 INFO:     Epoch: 30
2022-12-05 22:06:28,718 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45421403883533046, 'Total loss': 0.45421403883533046} | train loss {'Reaction outcome loss': 0.18050619938801374, 'Total loss': 0.18050619938801374}
2022-12-05 22:06:28,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:28,718 INFO:     Epoch: 31
2022-12-05 22:06:29,515 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4618758750571446, 'Total loss': 0.4618758750571446} | train loss {'Reaction outcome loss': 0.17349139622022067, 'Total loss': 0.17349139622022067}
2022-12-05 22:06:29,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:29,515 INFO:     Epoch: 32
2022-12-05 22:06:30,312 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4573676017197696, 'Total loss': 0.4573676017197696} | train loss {'Reaction outcome loss': 0.17654863165150728, 'Total loss': 0.17654863165150728}
2022-12-05 22:06:30,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:30,312 INFO:     Epoch: 33
2022-12-05 22:06:31,109 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46395607597448607, 'Total loss': 0.46395607597448607} | train loss {'Reaction outcome loss': 0.1705898852838624, 'Total loss': 0.1705898852838624}
2022-12-05 22:06:31,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:31,109 INFO:     Epoch: 34
2022-12-05 22:06:31,907 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45090044967152854, 'Total loss': 0.45090044967152854} | train loss {'Reaction outcome loss': 0.16802329230572907, 'Total loss': 0.16802329230572907}
2022-12-05 22:06:31,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:31,907 INFO:     Epoch: 35
2022-12-05 22:06:32,707 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4518472867255861, 'Total loss': 0.4518472867255861} | train loss {'Reaction outcome loss': 0.16909887898533094, 'Total loss': 0.16909887898533094}
2022-12-05 22:06:32,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:32,708 INFO:     Epoch: 36
2022-12-05 22:06:33,503 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4680370746011084, 'Total loss': 0.4680370746011084} | train loss {'Reaction outcome loss': 0.1646052833511344, 'Total loss': 0.1646052833511344}
2022-12-05 22:06:33,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:33,503 INFO:     Epoch: 37
2022-12-05 22:06:34,299 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4736309718679298, 'Total loss': 0.4736309718679298} | train loss {'Reaction outcome loss': 0.1620568222396316, 'Total loss': 0.1620568222396316}
2022-12-05 22:06:34,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:34,299 INFO:     Epoch: 38
2022-12-05 22:06:35,095 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4528913281180642, 'Total loss': 0.4528913281180642} | train loss {'Reaction outcome loss': 0.1629121101258563, 'Total loss': 0.1629121101258563}
2022-12-05 22:06:35,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:35,095 INFO:     Epoch: 39
2022-12-05 22:06:35,891 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4648141468113119, 'Total loss': 0.4648141468113119} | train loss {'Reaction outcome loss': 0.1604448631255617, 'Total loss': 0.1604448631255617}
2022-12-05 22:06:35,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:35,892 INFO:     Epoch: 40
2022-12-05 22:06:36,692 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4588226401670413, 'Total loss': 0.4588226401670413} | train loss {'Reaction outcome loss': 0.1569879506939962, 'Total loss': 0.1569879506939962}
2022-12-05 22:06:36,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:36,692 INFO:     Epoch: 41
2022-12-05 22:06:37,490 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46216127039356664, 'Total loss': 0.46216127039356664} | train loss {'Reaction outcome loss': 0.15702756060918252, 'Total loss': 0.15702756060918252}
2022-12-05 22:06:37,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:37,490 INFO:     Epoch: 42
2022-12-05 22:06:38,288 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46433026309717784, 'Total loss': 0.46433026309717784} | train loss {'Reaction outcome loss': 0.15521154799799045, 'Total loss': 0.15521154799799045}
2022-12-05 22:06:38,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:38,289 INFO:     Epoch: 43
2022-12-05 22:06:39,089 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4678591110489585, 'Total loss': 0.4678591110489585} | train loss {'Reaction outcome loss': 0.1529871015659263, 'Total loss': 0.1529871015659263}
2022-12-05 22:06:39,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:39,090 INFO:     Epoch: 44
2022-12-05 22:06:39,889 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47587310658259824, 'Total loss': 0.47587310658259824} | train loss {'Reaction outcome loss': 0.14973950147959253, 'Total loss': 0.14973950147959253}
2022-12-05 22:06:39,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:39,889 INFO:     Epoch: 45
2022-12-05 22:06:40,688 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47493898597630585, 'Total loss': 0.47493898597630585} | train loss {'Reaction outcome loss': 0.15056526128412975, 'Total loss': 0.15056526128412975}
2022-12-05 22:06:40,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:40,688 INFO:     Epoch: 46
2022-12-05 22:06:41,489 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4700320701707493, 'Total loss': 0.4700320701707493} | train loss {'Reaction outcome loss': 0.14884057523111902, 'Total loss': 0.14884057523111902}
2022-12-05 22:06:41,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:41,489 INFO:     Epoch: 47
2022-12-05 22:06:42,287 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4670140655203299, 'Total loss': 0.4670140655203299} | train loss {'Reaction outcome loss': 0.14799203326354823, 'Total loss': 0.14799203326354823}
2022-12-05 22:06:42,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:42,287 INFO:     Epoch: 48
2022-12-05 22:06:43,085 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47653943892907014, 'Total loss': 0.47653943892907014} | train loss {'Reaction outcome loss': 0.1467985501738205, 'Total loss': 0.1467985501738205}
2022-12-05 22:06:43,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:43,085 INFO:     Epoch: 49
2022-12-05 22:06:43,881 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4821659221567891, 'Total loss': 0.4821659221567891} | train loss {'Reaction outcome loss': 0.14637465297334618, 'Total loss': 0.14637465297334618}
2022-12-05 22:06:43,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:43,881 INFO:     Epoch: 50
2022-12-05 22:06:44,681 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47127431292425503, 'Total loss': 0.47127431292425503} | train loss {'Reaction outcome loss': 0.14373702779712696, 'Total loss': 0.14373702779712696}
2022-12-05 22:06:44,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:44,682 INFO:     Epoch: 51
2022-12-05 22:06:45,482 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47559629448435525, 'Total loss': 0.47559629448435525} | train loss {'Reaction outcome loss': 0.14560986272690277, 'Total loss': 0.14560986272690277}
2022-12-05 22:06:45,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:45,483 INFO:     Epoch: 52
2022-12-05 22:06:46,280 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.466114014048468, 'Total loss': 0.466114014048468} | train loss {'Reaction outcome loss': 0.1436972931034923, 'Total loss': 0.1436972931034923}
2022-12-05 22:06:46,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:46,280 INFO:     Epoch: 53
2022-12-05 22:06:47,075 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48127670179713855, 'Total loss': 0.48127670179713855} | train loss {'Reaction outcome loss': 0.14175416947522712, 'Total loss': 0.14175416947522712}
2022-12-05 22:06:47,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:47,075 INFO:     Epoch: 54
2022-12-05 22:06:47,873 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4690251611173153, 'Total loss': 0.4690251611173153} | train loss {'Reaction outcome loss': 0.14213519777742126, 'Total loss': 0.14213519777742126}
2022-12-05 22:06:47,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:47,873 INFO:     Epoch: 55
2022-12-05 22:06:48,672 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48053766126659786, 'Total loss': 0.48053766126659786} | train loss {'Reaction outcome loss': 0.14008302054548216, 'Total loss': 0.14008302054548216}
2022-12-05 22:06:48,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:48,672 INFO:     Epoch: 56
2022-12-05 22:06:49,469 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48055909540165553, 'Total loss': 0.48055909540165553} | train loss {'Reaction outcome loss': 0.1392616969683478, 'Total loss': 0.1392616969683478}
2022-12-05 22:06:49,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:49,469 INFO:     Epoch: 57
2022-12-05 22:06:50,267 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4743075054138899, 'Total loss': 0.4743075054138899} | train loss {'Reaction outcome loss': 0.13690921544818388, 'Total loss': 0.13690921544818388}
2022-12-05 22:06:50,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:50,267 INFO:     Epoch: 58
2022-12-05 22:06:51,065 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49781469933011313, 'Total loss': 0.49781469933011313} | train loss {'Reaction outcome loss': 0.13786138377092297, 'Total loss': 0.13786138377092297}
2022-12-05 22:06:51,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:51,065 INFO:     Epoch: 59
2022-12-05 22:06:51,860 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46336215700615535, 'Total loss': 0.46336215700615535} | train loss {'Reaction outcome loss': 0.1372997991800789, 'Total loss': 0.1372997991800789}
2022-12-05 22:06:51,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:51,860 INFO:     Epoch: 60
2022-12-05 22:06:52,663 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4763767184181647, 'Total loss': 0.4763767184181647} | train loss {'Reaction outcome loss': 0.1370211110840882, 'Total loss': 0.1370211110840882}
2022-12-05 22:06:52,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:52,663 INFO:     Epoch: 61
2022-12-05 22:06:53,461 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48191922767595813, 'Total loss': 0.48191922767595813} | train loss {'Reaction outcome loss': 0.13796517348307516, 'Total loss': 0.13796517348307516}
2022-12-05 22:06:53,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:53,461 INFO:     Epoch: 62
2022-12-05 22:06:54,262 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4751614995978095, 'Total loss': 0.4751614995978095} | train loss {'Reaction outcome loss': 0.13304638597107823, 'Total loss': 0.13304638597107823}
2022-12-05 22:06:54,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:54,262 INFO:     Epoch: 63
2022-12-05 22:06:55,061 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47081946615468373, 'Total loss': 0.47081946615468373} | train loss {'Reaction outcome loss': 0.1362840214503869, 'Total loss': 0.1362840214503869}
2022-12-05 22:06:55,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:55,061 INFO:     Epoch: 64
2022-12-05 22:06:55,858 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.475093487650156, 'Total loss': 0.475093487650156} | train loss {'Reaction outcome loss': 0.13631355736945425, 'Total loss': 0.13631355736945425}
2022-12-05 22:06:55,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:55,859 INFO:     Epoch: 65
2022-12-05 22:06:56,663 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49383787709203636, 'Total loss': 0.49383787709203636} | train loss {'Reaction outcome loss': 0.1329682694725512, 'Total loss': 0.1329682694725512}
2022-12-05 22:06:56,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:56,663 INFO:     Epoch: 66
2022-12-05 22:06:57,461 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4861969568512656, 'Total loss': 0.4861969568512656} | train loss {'Reaction outcome loss': 0.13459800821428577, 'Total loss': 0.13459800821428577}
2022-12-05 22:06:57,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:57,462 INFO:     Epoch: 67
2022-12-05 22:06:58,262 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47115630825812166, 'Total loss': 0.47115630825812166} | train loss {'Reaction outcome loss': 0.13049195945307973, 'Total loss': 0.13049195945307973}
2022-12-05 22:06:58,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:58,263 INFO:     Epoch: 68
2022-12-05 22:06:59,061 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4761910798366774, 'Total loss': 0.4761910798366774} | train loss {'Reaction outcome loss': 0.13086081427642174, 'Total loss': 0.13086081427642174}
2022-12-05 22:06:59,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:59,061 INFO:     Epoch: 69
2022-12-05 22:06:59,864 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47815142097798263, 'Total loss': 0.47815142097798263} | train loss {'Reaction outcome loss': 0.1291222470444477, 'Total loss': 0.1291222470444477}
2022-12-05 22:06:59,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:06:59,864 INFO:     Epoch: 70
2022-12-05 22:07:00,662 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49197281219742517, 'Total loss': 0.49197281219742517} | train loss {'Reaction outcome loss': 0.1309080584154975, 'Total loss': 0.1309080584154975}
2022-12-05 22:07:00,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:00,662 INFO:     Epoch: 71
2022-12-05 22:07:01,461 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49214201318946754, 'Total loss': 0.49214201318946754} | train loss {'Reaction outcome loss': 0.13019999605603516, 'Total loss': 0.13019999605603516}
2022-12-05 22:07:01,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:01,461 INFO:     Epoch: 72
2022-12-05 22:07:02,261 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47843549332835456, 'Total loss': 0.47843549332835456} | train loss {'Reaction outcome loss': 0.12843712142127897, 'Total loss': 0.12843712142127897}
2022-12-05 22:07:02,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:02,261 INFO:     Epoch: 73
2022-12-05 22:07:03,060 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4797054200687192, 'Total loss': 0.4797054200687192} | train loss {'Reaction outcome loss': 0.12634681348478602, 'Total loss': 0.12634681348478602}
2022-12-05 22:07:03,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:03,061 INFO:     Epoch: 74
2022-12-05 22:07:03,860 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47181704200126906, 'Total loss': 0.47181704200126906} | train loss {'Reaction outcome loss': 0.12896058472594427, 'Total loss': 0.12896058472594427}
2022-12-05 22:07:03,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:03,860 INFO:     Epoch: 75
2022-12-05 22:07:04,660 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47647071595896373, 'Total loss': 0.47647071595896373} | train loss {'Reaction outcome loss': 0.12929737288129306, 'Total loss': 0.12929737288129306}
2022-12-05 22:07:04,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:04,661 INFO:     Epoch: 76
2022-12-05 22:07:05,458 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4696266715499488, 'Total loss': 0.4696266715499488} | train loss {'Reaction outcome loss': 0.13034270069141302, 'Total loss': 0.13034270069141302}
2022-12-05 22:07:05,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:05,458 INFO:     Epoch: 77
2022-12-05 22:07:06,257 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46546133302829484, 'Total loss': 0.46546133302829484} | train loss {'Reaction outcome loss': 0.1299864660024703, 'Total loss': 0.1299864660024703}
2022-12-05 22:07:06,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:06,257 INFO:     Epoch: 78
2022-12-05 22:07:07,055 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4742655066603964, 'Total loss': 0.4742655066603964} | train loss {'Reaction outcome loss': 0.12627455041248112, 'Total loss': 0.12627455041248112}
2022-12-05 22:07:07,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:07,056 INFO:     Epoch: 79
2022-12-05 22:07:07,859 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4710174636407332, 'Total loss': 0.4710174636407332} | train loss {'Reaction outcome loss': 0.12706149560249141, 'Total loss': 0.12706149560249141}
2022-12-05 22:07:07,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:07,859 INFO:     Epoch: 80
2022-12-05 22:07:08,662 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4811354160986163, 'Total loss': 0.4811354160986163} | train loss {'Reaction outcome loss': 0.127674299649023, 'Total loss': 0.127674299649023}
2022-12-05 22:07:08,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:08,663 INFO:     Epoch: 81
2022-12-05 22:07:09,462 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4828265333040194, 'Total loss': 0.4828265333040194} | train loss {'Reaction outcome loss': 0.12774980679574993, 'Total loss': 0.12774980679574993}
2022-12-05 22:07:09,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:09,463 INFO:     Epoch: 82
2022-12-05 22:07:10,262 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46564938737587497, 'Total loss': 0.46564938737587497} | train loss {'Reaction outcome loss': 0.12368407620740454, 'Total loss': 0.12368407620740454}
2022-12-05 22:07:10,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:10,263 INFO:     Epoch: 83
2022-12-05 22:07:11,063 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49604428153146396, 'Total loss': 0.49604428153146396} | train loss {'Reaction outcome loss': 0.12441220852891885, 'Total loss': 0.12441220852891885}
2022-12-05 22:07:11,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:11,063 INFO:     Epoch: 84
2022-12-05 22:07:11,865 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4793290600857951, 'Total loss': 0.4793290600857951} | train loss {'Reaction outcome loss': 0.12463812606649534, 'Total loss': 0.12463812606649534}
2022-12-05 22:07:11,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:11,865 INFO:     Epoch: 85
2022-12-05 22:07:12,666 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.485199283469807, 'Total loss': 0.485199283469807} | train loss {'Reaction outcome loss': 0.12333216879051179, 'Total loss': 0.12333216879051179}
2022-12-05 22:07:12,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:12,666 INFO:     Epoch: 86
2022-12-05 22:07:13,468 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47291832891377533, 'Total loss': 0.47291832891377533} | train loss {'Reaction outcome loss': 0.12277344995058112, 'Total loss': 0.12277344995058112}
2022-12-05 22:07:13,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:13,468 INFO:     Epoch: 87
2022-12-05 22:07:14,273 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4911616739224304, 'Total loss': 0.4911616739224304} | train loss {'Reaction outcome loss': 0.12148305294930094, 'Total loss': 0.12148305294930094}
2022-12-05 22:07:14,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:14,273 INFO:     Epoch: 88
2022-12-05 22:07:15,075 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48165512626821344, 'Total loss': 0.48165512626821344} | train loss {'Reaction outcome loss': 0.12331379670649767, 'Total loss': 0.12331379670649767}
2022-12-05 22:07:15,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:15,075 INFO:     Epoch: 89
2022-12-05 22:07:15,877 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4929031719538299, 'Total loss': 0.4929031719538299} | train loss {'Reaction outcome loss': 0.12298723455939081, 'Total loss': 0.12298723455939081}
2022-12-05 22:07:15,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:15,877 INFO:     Epoch: 90
2022-12-05 22:07:16,676 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48136240658773616, 'Total loss': 0.48136240658773616} | train loss {'Reaction outcome loss': 0.12171461321263304, 'Total loss': 0.12171461321263304}
2022-12-05 22:07:16,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:16,677 INFO:     Epoch: 91
2022-12-05 22:07:17,479 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.478061520409855, 'Total loss': 0.478061520409855} | train loss {'Reaction outcome loss': 0.12025542461103009, 'Total loss': 0.12025542461103009}
2022-12-05 22:07:17,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:17,479 INFO:     Epoch: 92
2022-12-05 22:07:18,282 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48026809705929324, 'Total loss': 0.48026809705929324} | train loss {'Reaction outcome loss': 0.12394225159134235, 'Total loss': 0.12394225159134235}
2022-12-05 22:07:18,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:18,282 INFO:     Epoch: 93
2022-12-05 22:07:19,089 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47818144715645095, 'Total loss': 0.47818144715645095} | train loss {'Reaction outcome loss': 0.12118750048290577, 'Total loss': 0.12118750048290577}
2022-12-05 22:07:19,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:19,090 INFO:     Epoch: 94
2022-12-05 22:07:19,893 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4830593710595911, 'Total loss': 0.4830593710595911} | train loss {'Reaction outcome loss': 0.12222385582619257, 'Total loss': 0.12222385582619257}
2022-12-05 22:07:19,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:19,894 INFO:     Epoch: 95
2022-12-05 22:07:20,697 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4749662632291967, 'Total loss': 0.4749662632291967} | train loss {'Reaction outcome loss': 0.11951973486406307, 'Total loss': 0.11951973486406307}
2022-12-05 22:07:20,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:20,698 INFO:     Epoch: 96
2022-12-05 22:07:21,503 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4771807754242962, 'Total loss': 0.4771807754242962} | train loss {'Reaction outcome loss': 0.12109243884427293, 'Total loss': 0.12109243884427293}
2022-12-05 22:07:21,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:21,503 INFO:     Epoch: 97
2022-12-05 22:07:22,312 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4815893132578243, 'Total loss': 0.4815893132578243} | train loss {'Reaction outcome loss': 0.11863660117265798, 'Total loss': 0.11863660117265798}
2022-12-05 22:07:22,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:22,312 INFO:     Epoch: 98
2022-12-05 22:07:23,119 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4740948070856658, 'Total loss': 0.4740948070856658} | train loss {'Reaction outcome loss': 0.12111495649291863, 'Total loss': 0.12111495649291863}
2022-12-05 22:07:23,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:23,119 INFO:     Epoch: 99
2022-12-05 22:07:23,921 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4826588711955331, 'Total loss': 0.4826588711955331} | train loss {'Reaction outcome loss': 0.11920914546616616, 'Total loss': 0.11920914546616616}
2022-12-05 22:07:23,921 INFO:     Best model found after epoch 22 of 100.
2022-12-05 22:07:23,921 INFO:   Done with stage: TRAINING
2022-12-05 22:07:23,921 INFO:   Starting stage: EVALUATION
2022-12-05 22:07:24,041 INFO:   Done with stage: EVALUATION
2022-12-05 22:07:24,041 INFO:   Leaving out SEQ value Fold_5
2022-12-05 22:07:24,053 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:07:24,053 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:07:24,696 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:07:24,696 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:07:24,767 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:07:24,767 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:07:24,767 INFO:     No hyperparam tuning for this model
2022-12-05 22:07:24,767 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:07:24,767 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:07:24,768 INFO:     None feature selector for col prot
2022-12-05 22:07:24,768 INFO:     None feature selector for col prot
2022-12-05 22:07:24,768 INFO:     None feature selector for col prot
2022-12-05 22:07:24,769 INFO:     None feature selector for col chem
2022-12-05 22:07:24,769 INFO:     None feature selector for col chem
2022-12-05 22:07:24,769 INFO:     None feature selector for col chem
2022-12-05 22:07:24,769 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:07:24,769 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:07:24,771 INFO:     Number of params in model 215821
2022-12-05 22:07:24,774 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:07:24,774 INFO:   Starting stage: TRAINING
2022-12-05 22:07:24,836 INFO:     Val loss before train {'Reaction outcome loss': 0.9002176008441232, 'Total loss': 0.9002176008441232}
2022-12-05 22:07:24,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:24,837 INFO:     Epoch: 0
2022-12-05 22:07:25,642 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5402396697212349, 'Total loss': 0.5402396697212349} | train loss {'Reaction outcome loss': 0.8065750349553362, 'Total loss': 0.8065750349553362}
2022-12-05 22:07:25,642 INFO:     Found new best model at epoch 0
2022-12-05 22:07:25,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:25,643 INFO:     Epoch: 1
2022-12-05 22:07:26,446 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.45159429785880173, 'Total loss': 0.45159429785880173} | train loss {'Reaction outcome loss': 0.549149607398337, 'Total loss': 0.549149607398337}
2022-12-05 22:07:26,446 INFO:     Found new best model at epoch 1
2022-12-05 22:07:26,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:26,447 INFO:     Epoch: 2
2022-12-05 22:07:27,250 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4163888631896539, 'Total loss': 0.4163888631896539} | train loss {'Reaction outcome loss': 0.4745264491967617, 'Total loss': 0.4745264491967617}
2022-12-05 22:07:27,250 INFO:     Found new best model at epoch 2
2022-12-05 22:07:27,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:27,251 INFO:     Epoch: 3
2022-12-05 22:07:28,052 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4098075039007447, 'Total loss': 0.4098075039007447} | train loss {'Reaction outcome loss': 0.42792217409418476, 'Total loss': 0.42792217409418476}
2022-12-05 22:07:28,052 INFO:     Found new best model at epoch 3
2022-12-05 22:07:28,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:28,053 INFO:     Epoch: 4
2022-12-05 22:07:28,858 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.39381102032282134, 'Total loss': 0.39381102032282134} | train loss {'Reaction outcome loss': 0.4006575666247837, 'Total loss': 0.4006575666247837}
2022-12-05 22:07:28,859 INFO:     Found new best model at epoch 4
2022-12-05 22:07:28,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:28,860 INFO:     Epoch: 5
2022-12-05 22:07:29,667 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.37874526327306574, 'Total loss': 0.37874526327306574} | train loss {'Reaction outcome loss': 0.37713429295728285, 'Total loss': 0.37713429295728285}
2022-12-05 22:07:29,667 INFO:     Found new best model at epoch 5
2022-12-05 22:07:29,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:29,668 INFO:     Epoch: 6
2022-12-05 22:07:30,478 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3799742731181058, 'Total loss': 0.3799742731181058} | train loss {'Reaction outcome loss': 0.362437479288107, 'Total loss': 0.362437479288107}
2022-12-05 22:07:30,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:30,478 INFO:     Epoch: 7
2022-12-05 22:07:31,281 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.37719222937117924, 'Total loss': 0.37719222937117924} | train loss {'Reaction outcome loss': 0.3455513694113301, 'Total loss': 0.3455513694113301}
2022-12-05 22:07:31,281 INFO:     Found new best model at epoch 7
2022-12-05 22:07:31,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:31,282 INFO:     Epoch: 8
2022-12-05 22:07:32,086 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.3713044339621609, 'Total loss': 0.3713044339621609} | train loss {'Reaction outcome loss': 0.3307551981941346, 'Total loss': 0.3307551981941346}
2022-12-05 22:07:32,086 INFO:     Found new best model at epoch 8
2022-12-05 22:07:32,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:32,087 INFO:     Epoch: 9
2022-12-05 22:07:32,897 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3749966645105319, 'Total loss': 0.3749966645105319} | train loss {'Reaction outcome loss': 0.315946975813037, 'Total loss': 0.315946975813037}
2022-12-05 22:07:32,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:32,897 INFO:     Epoch: 10
2022-12-05 22:07:33,701 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3648293702439828, 'Total loss': 0.3648293702439828} | train loss {'Reaction outcome loss': 0.3052539434434185, 'Total loss': 0.3052539434434185}
2022-12-05 22:07:33,701 INFO:     Found new best model at epoch 10
2022-12-05 22:07:33,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:33,702 INFO:     Epoch: 11
2022-12-05 22:07:34,502 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3730414401401173, 'Total loss': 0.3730414401401173} | train loss {'Reaction outcome loss': 0.2944446677161801, 'Total loss': 0.2944446677161801}
2022-12-05 22:07:34,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:34,502 INFO:     Epoch: 12
2022-12-05 22:07:35,306 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.36339471980252047, 'Total loss': 0.36339471980252047} | train loss {'Reaction outcome loss': 0.2857273170994895, 'Total loss': 0.2857273170994895}
2022-12-05 22:07:35,306 INFO:     Found new best model at epoch 12
2022-12-05 22:07:35,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:35,307 INFO:     Epoch: 13
2022-12-05 22:07:36,112 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.35713462937961926, 'Total loss': 0.35713462937961926} | train loss {'Reaction outcome loss': 0.27694264958582576, 'Total loss': 0.27694264958582576}
2022-12-05 22:07:36,112 INFO:     Found new best model at epoch 13
2022-12-05 22:07:36,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:36,113 INFO:     Epoch: 14
2022-12-05 22:07:36,917 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.38012470372698526, 'Total loss': 0.38012470372698526} | train loss {'Reaction outcome loss': 0.26967861785763697, 'Total loss': 0.26967861785763697}
2022-12-05 22:07:36,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:36,917 INFO:     Epoch: 15
2022-12-05 22:07:37,720 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3559526506472718, 'Total loss': 0.3559526506472718} | train loss {'Reaction outcome loss': 0.26358456296786187, 'Total loss': 0.26358456296786187}
2022-12-05 22:07:37,721 INFO:     Found new best model at epoch 15
2022-12-05 22:07:37,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:37,721 INFO:     Epoch: 16
2022-12-05 22:07:38,533 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.36629871041937306, 'Total loss': 0.36629871041937306} | train loss {'Reaction outcome loss': 0.256426329649384, 'Total loss': 0.256426329649384}
2022-12-05 22:07:38,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:38,533 INFO:     Epoch: 17
2022-12-05 22:07:39,340 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3590230955318971, 'Total loss': 0.3590230955318971} | train loss {'Reaction outcome loss': 0.24728100028850378, 'Total loss': 0.24728100028850378}
2022-12-05 22:07:39,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:39,340 INFO:     Epoch: 18
2022-12-05 22:07:40,143 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.36835629865527153, 'Total loss': 0.36835629865527153} | train loss {'Reaction outcome loss': 0.24446226073609245, 'Total loss': 0.24446226073609245}
2022-12-05 22:07:40,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:40,143 INFO:     Epoch: 19
2022-12-05 22:07:40,951 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3697074328295209, 'Total loss': 0.3697074328295209} | train loss {'Reaction outcome loss': 0.23799772782912176, 'Total loss': 0.23799772782912176}
2022-12-05 22:07:40,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:40,952 INFO:     Epoch: 20
2022-12-05 22:07:41,758 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3765113584019921, 'Total loss': 0.3765113584019921} | train loss {'Reaction outcome loss': 0.2307294638181526, 'Total loss': 0.2307294638181526}
2022-12-05 22:07:41,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:41,759 INFO:     Epoch: 21
2022-12-05 22:07:42,560 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.36836586045947944, 'Total loss': 0.36836586045947944} | train loss {'Reaction outcome loss': 0.2289878284378398, 'Total loss': 0.2289878284378398}
2022-12-05 22:07:42,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:42,560 INFO:     Epoch: 22
2022-12-05 22:07:43,364 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.35755015300078824, 'Total loss': 0.35755015300078824} | train loss {'Reaction outcome loss': 0.2225421812355278, 'Total loss': 0.2225421812355278}
2022-12-05 22:07:43,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:43,364 INFO:     Epoch: 23
2022-12-05 22:07:44,172 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.37116494876417244, 'Total loss': 0.37116494876417244} | train loss {'Reaction outcome loss': 0.21790845822843333, 'Total loss': 0.21790845822843333}
2022-12-05 22:07:44,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:44,172 INFO:     Epoch: 24
2022-12-05 22:07:44,973 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38120955254205247, 'Total loss': 0.38120955254205247} | train loss {'Reaction outcome loss': 0.21279900804943136, 'Total loss': 0.21279900804943136}
2022-12-05 22:07:44,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:44,973 INFO:     Epoch: 25
2022-12-05 22:07:45,774 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3872652585533532, 'Total loss': 0.3872652585533532} | train loss {'Reaction outcome loss': 0.2094739520952346, 'Total loss': 0.2094739520952346}
2022-12-05 22:07:45,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:45,774 INFO:     Epoch: 26
2022-12-05 22:07:46,579 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.369590477001938, 'Total loss': 0.369590477001938} | train loss {'Reaction outcome loss': 0.20642779776526074, 'Total loss': 0.20642779776526074}
2022-12-05 22:07:46,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:46,579 INFO:     Epoch: 27
2022-12-05 22:07:47,385 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3779679706150835, 'Total loss': 0.3779679706150835} | train loss {'Reaction outcome loss': 0.20256527320992562, 'Total loss': 0.20256527320992562}
2022-12-05 22:07:47,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:47,386 INFO:     Epoch: 28
2022-12-05 22:07:48,190 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3873135836964304, 'Total loss': 0.3873135836964304} | train loss {'Reaction outcome loss': 0.20000905394854565, 'Total loss': 0.20000905394854565}
2022-12-05 22:07:48,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:48,191 INFO:     Epoch: 29
2022-12-05 22:07:48,994 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.38392751900987193, 'Total loss': 0.38392751900987193} | train loss {'Reaction outcome loss': 0.19460765198774396, 'Total loss': 0.19460765198774396}
2022-12-05 22:07:48,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:48,994 INFO:     Epoch: 30
2022-12-05 22:07:49,799 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38739349015734414, 'Total loss': 0.38739349015734414} | train loss {'Reaction outcome loss': 0.19382149162852474, 'Total loss': 0.19382149162852474}
2022-12-05 22:07:49,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:49,800 INFO:     Epoch: 31
2022-12-05 22:07:50,607 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.387604258954525, 'Total loss': 0.387604258954525} | train loss {'Reaction outcome loss': 0.1909248122134276, 'Total loss': 0.1909248122134276}
2022-12-05 22:07:50,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:50,607 INFO:     Epoch: 32
2022-12-05 22:07:51,409 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3748439374295148, 'Total loss': 0.3748439374295148} | train loss {'Reaction outcome loss': 0.18881527725006303, 'Total loss': 0.18881527725006303}
2022-12-05 22:07:51,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:51,410 INFO:     Epoch: 33
2022-12-05 22:07:52,211 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38403944264758716, 'Total loss': 0.38403944264758716} | train loss {'Reaction outcome loss': 0.18517612999365216, 'Total loss': 0.18517612999365216}
2022-12-05 22:07:52,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:52,211 INFO:     Epoch: 34
2022-12-05 22:07:53,015 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3822449943558736, 'Total loss': 0.3822449943558736} | train loss {'Reaction outcome loss': 0.1848215038828071, 'Total loss': 0.1848215038828071}
2022-12-05 22:07:53,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:53,015 INFO:     Epoch: 35
2022-12-05 22:07:53,820 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3911340720951557, 'Total loss': 0.3911340720951557} | train loss {'Reaction outcome loss': 0.18127467830274854, 'Total loss': 0.18127467830274854}
2022-12-05 22:07:53,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:53,820 INFO:     Epoch: 36
2022-12-05 22:07:54,622 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.376912261782722, 'Total loss': 0.376912261782722} | train loss {'Reaction outcome loss': 0.17967066062133638, 'Total loss': 0.17967066062133638}
2022-12-05 22:07:54,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:54,622 INFO:     Epoch: 37
2022-12-05 22:07:55,441 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.374181116507812, 'Total loss': 0.374181116507812} | train loss {'Reaction outcome loss': 0.17495010341066988, 'Total loss': 0.17495010341066988}
2022-12-05 22:07:55,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:55,441 INFO:     Epoch: 38
2022-12-05 22:07:56,240 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3816256516359069, 'Total loss': 0.3816256516359069} | train loss {'Reaction outcome loss': 0.17552017678146162, 'Total loss': 0.17552017678146162}
2022-12-05 22:07:56,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:56,241 INFO:     Epoch: 39
2022-12-05 22:07:57,036 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39719677005301823, 'Total loss': 0.39719677005301823} | train loss {'Reaction outcome loss': 0.17323117781310313, 'Total loss': 0.17323117781310313}
2022-12-05 22:07:57,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:57,036 INFO:     Epoch: 40
2022-12-05 22:07:57,842 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4018005674535578, 'Total loss': 0.4018005674535578} | train loss {'Reaction outcome loss': 0.1721997072830075, 'Total loss': 0.1721997072830075}
2022-12-05 22:07:57,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:57,842 INFO:     Epoch: 41
2022-12-05 22:07:58,647 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39125419848344545, 'Total loss': 0.39125419848344545} | train loss {'Reaction outcome loss': 0.1699150584472884, 'Total loss': 0.1699150584472884}
2022-12-05 22:07:58,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:58,647 INFO:     Epoch: 42
2022-12-05 22:07:59,443 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3894318416714668, 'Total loss': 0.3894318416714668} | train loss {'Reaction outcome loss': 0.16385087925159642, 'Total loss': 0.16385087925159642}
2022-12-05 22:07:59,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:07:59,443 INFO:     Epoch: 43
2022-12-05 22:08:00,240 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3938442167233337, 'Total loss': 0.3938442167233337} | train loss {'Reaction outcome loss': 0.16350767213190276, 'Total loss': 0.16350767213190276}
2022-12-05 22:08:00,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:00,241 INFO:     Epoch: 44
2022-12-05 22:08:01,036 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3783952727575194, 'Total loss': 0.3783952727575194} | train loss {'Reaction outcome loss': 0.16409391126475267, 'Total loss': 0.16409391126475267}
2022-12-05 22:08:01,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:01,036 INFO:     Epoch: 45
2022-12-05 22:08:01,833 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38418326645412226, 'Total loss': 0.38418326645412226} | train loss {'Reaction outcome loss': 0.16354801010100112, 'Total loss': 0.16354801010100112}
2022-12-05 22:08:01,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:01,833 INFO:     Epoch: 46
2022-12-05 22:08:02,626 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3895582167262381, 'Total loss': 0.3895582167262381} | train loss {'Reaction outcome loss': 0.16168927875227265, 'Total loss': 0.16168927875227265}
2022-12-05 22:08:02,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:02,627 INFO:     Epoch: 47
2022-12-05 22:08:03,425 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3947865581986579, 'Total loss': 0.3947865581986579} | train loss {'Reaction outcome loss': 0.15988812050331505, 'Total loss': 0.15988812050331505}
2022-12-05 22:08:03,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:03,425 INFO:     Epoch: 48
2022-12-05 22:08:04,222 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37419655614278535, 'Total loss': 0.37419655614278535} | train loss {'Reaction outcome loss': 0.15794233537669625, 'Total loss': 0.15794233537669625}
2022-12-05 22:08:04,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:04,222 INFO:     Epoch: 49
2022-12-05 22:08:05,025 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38028464872728696, 'Total loss': 0.38028464872728696} | train loss {'Reaction outcome loss': 0.15712593043703707, 'Total loss': 0.15712593043703707}
2022-12-05 22:08:05,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:05,026 INFO:     Epoch: 50
2022-12-05 22:08:05,822 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38505362075838173, 'Total loss': 0.38505362075838173} | train loss {'Reaction outcome loss': 0.15430346557179525, 'Total loss': 0.15430346557179525}
2022-12-05 22:08:05,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:05,822 INFO:     Epoch: 51
2022-12-05 22:08:06,616 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39580239965157077, 'Total loss': 0.39580239965157077} | train loss {'Reaction outcome loss': 0.15781161162040888, 'Total loss': 0.15781161162040888}
2022-12-05 22:08:06,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:06,617 INFO:     Epoch: 52
2022-12-05 22:08:07,411 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39746490628881886, 'Total loss': 0.39746490628881886} | train loss {'Reaction outcome loss': 0.15468018287943014, 'Total loss': 0.15468018287943014}
2022-12-05 22:08:07,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:07,411 INFO:     Epoch: 53
2022-12-05 22:08:08,208 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38491660356521606, 'Total loss': 0.38491660356521606} | train loss {'Reaction outcome loss': 0.15305342610114284, 'Total loss': 0.15305342610114284}
2022-12-05 22:08:08,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:08,208 INFO:     Epoch: 54
2022-12-05 22:08:09,003 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40398158403960144, 'Total loss': 0.40398158403960144} | train loss {'Reaction outcome loss': 0.151582304515966, 'Total loss': 0.151582304515966}
2022-12-05 22:08:09,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:09,003 INFO:     Epoch: 55
2022-12-05 22:08:09,798 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39356109652329574, 'Total loss': 0.39356109652329574} | train loss {'Reaction outcome loss': 0.1536331346799289, 'Total loss': 0.1536331346799289}
2022-12-05 22:08:09,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:09,798 INFO:     Epoch: 56
2022-12-05 22:08:10,592 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.40298564291813155, 'Total loss': 0.40298564291813155} | train loss {'Reaction outcome loss': 0.15092319497583254, 'Total loss': 0.15092319497583254}
2022-12-05 22:08:10,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:10,593 INFO:     Epoch: 57
2022-12-05 22:08:11,390 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3928548651324077, 'Total loss': 0.3928548651324077} | train loss {'Reaction outcome loss': 0.1484122363429877, 'Total loss': 0.1484122363429877}
2022-12-05 22:08:11,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:11,390 INFO:     Epoch: 58
2022-12-05 22:08:12,184 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39151815833015874, 'Total loss': 0.39151815833015874} | train loss {'Reaction outcome loss': 0.14728539419781056, 'Total loss': 0.14728539419781056}
2022-12-05 22:08:12,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:12,185 INFO:     Epoch: 59
2022-12-05 22:08:12,982 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4168310703879053, 'Total loss': 0.4168310703879053} | train loss {'Reaction outcome loss': 0.14458349393680692, 'Total loss': 0.14458349393680692}
2022-12-05 22:08:12,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:12,983 INFO:     Epoch: 60
2022-12-05 22:08:13,777 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39261517622931436, 'Total loss': 0.39261517622931436} | train loss {'Reaction outcome loss': 0.1453453235050303, 'Total loss': 0.1453453235050303}
2022-12-05 22:08:13,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:13,778 INFO:     Epoch: 61
2022-12-05 22:08:14,573 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39158218320120464, 'Total loss': 0.39158218320120464} | train loss {'Reaction outcome loss': 0.14507733782633178, 'Total loss': 0.14507733782633178}
2022-12-05 22:08:14,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:14,573 INFO:     Epoch: 62
2022-12-05 22:08:15,371 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38941267429089005, 'Total loss': 0.38941267429089005} | train loss {'Reaction outcome loss': 0.14181493612517032, 'Total loss': 0.14181493612517032}
2022-12-05 22:08:15,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:15,371 INFO:     Epoch: 63
2022-12-05 22:08:16,169 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38992521234534006, 'Total loss': 0.38992521234534006} | train loss {'Reaction outcome loss': 0.14302659299104445, 'Total loss': 0.14302659299104445}
2022-12-05 22:08:16,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:16,170 INFO:     Epoch: 64
2022-12-05 22:08:16,967 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3834586633707989, 'Total loss': 0.3834586633707989} | train loss {'Reaction outcome loss': 0.14226028537227503, 'Total loss': 0.14226028537227503}
2022-12-05 22:08:16,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:16,967 INFO:     Epoch: 65
2022-12-05 22:08:17,769 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4057513363659382, 'Total loss': 0.4057513363659382} | train loss {'Reaction outcome loss': 0.13960342078034074, 'Total loss': 0.13960342078034074}
2022-12-05 22:08:17,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:17,770 INFO:     Epoch: 66
2022-12-05 22:08:18,571 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39333854378624394, 'Total loss': 0.39333854378624394} | train loss {'Reaction outcome loss': 0.14084467208463577, 'Total loss': 0.14084467208463577}
2022-12-05 22:08:18,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:18,571 INFO:     Epoch: 67
2022-12-05 22:08:19,372 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3934878215871074, 'Total loss': 0.3934878215871074} | train loss {'Reaction outcome loss': 0.140719790109283, 'Total loss': 0.140719790109283}
2022-12-05 22:08:19,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:19,373 INFO:     Epoch: 68
2022-12-05 22:08:20,174 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40434116971763695, 'Total loss': 0.40434116971763695} | train loss {'Reaction outcome loss': 0.14041411777162144, 'Total loss': 0.14041411777162144}
2022-12-05 22:08:20,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:20,174 INFO:     Epoch: 69
2022-12-05 22:08:20,979 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40285793793472374, 'Total loss': 0.40285793793472374} | train loss {'Reaction outcome loss': 0.1400849393028165, 'Total loss': 0.1400849393028165}
2022-12-05 22:08:20,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:20,979 INFO:     Epoch: 70
2022-12-05 22:08:21,780 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.382388753647154, 'Total loss': 0.382388753647154} | train loss {'Reaction outcome loss': 0.13945266672770582, 'Total loss': 0.13945266672770582}
2022-12-05 22:08:21,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:21,780 INFO:     Epoch: 71
2022-12-05 22:08:22,584 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39640349319035356, 'Total loss': 0.39640349319035356} | train loss {'Reaction outcome loss': 0.13722951343703654, 'Total loss': 0.13722951343703654}
2022-12-05 22:08:22,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:22,584 INFO:     Epoch: 72
2022-12-05 22:08:23,381 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4112101935527541, 'Total loss': 0.4112101935527541} | train loss {'Reaction outcome loss': 0.13822738424454245, 'Total loss': 0.13822738424454245}
2022-12-05 22:08:23,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:23,381 INFO:     Epoch: 73
2022-12-05 22:08:24,184 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40175269391726365, 'Total loss': 0.40175269391726365} | train loss {'Reaction outcome loss': 0.1367760156131079, 'Total loss': 0.1367760156131079}
2022-12-05 22:08:24,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:24,184 INFO:     Epoch: 74
2022-12-05 22:08:24,987 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3823915659873323, 'Total loss': 0.3823915659873323} | train loss {'Reaction outcome loss': 0.13405021752846696, 'Total loss': 0.13405021752846696}
2022-12-05 22:08:24,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:24,988 INFO:     Epoch: 75
2022-12-05 22:08:25,788 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4050621102479371, 'Total loss': 0.4050621102479371} | train loss {'Reaction outcome loss': 0.13620741913215287, 'Total loss': 0.13620741913215287}
2022-12-05 22:08:25,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:25,788 INFO:     Epoch: 76
2022-12-05 22:08:26,584 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39392468553375115, 'Total loss': 0.39392468553375115} | train loss {'Reaction outcome loss': 0.13612764302055322, 'Total loss': 0.13612764302055322}
2022-12-05 22:08:26,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:26,584 INFO:     Epoch: 77
2022-12-05 22:08:27,380 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37907232208685443, 'Total loss': 0.37907232208685443} | train loss {'Reaction outcome loss': 0.13364908015806107, 'Total loss': 0.13364908015806107}
2022-12-05 22:08:27,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:27,380 INFO:     Epoch: 78
2022-12-05 22:08:28,177 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4099990850822492, 'Total loss': 0.4099990850822492} | train loss {'Reaction outcome loss': 0.13259933095034812, 'Total loss': 0.13259933095034812}
2022-12-05 22:08:28,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:28,177 INFO:     Epoch: 79
2022-12-05 22:08:28,981 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3928008916025812, 'Total loss': 0.3928008916025812} | train loss {'Reaction outcome loss': 0.13398732890885684, 'Total loss': 0.13398732890885684}
2022-12-05 22:08:28,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:28,981 INFO:     Epoch: 80
2022-12-05 22:08:29,785 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3892184287648309, 'Total loss': 0.3892184287648309} | train loss {'Reaction outcome loss': 0.13225866865456826, 'Total loss': 0.13225866865456826}
2022-12-05 22:08:29,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:29,785 INFO:     Epoch: 81
2022-12-05 22:08:30,589 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39466065473177214, 'Total loss': 0.39466065473177214} | train loss {'Reaction outcome loss': 0.13240216064056562, 'Total loss': 0.13240216064056562}
2022-12-05 22:08:30,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:30,589 INFO:     Epoch: 82
2022-12-05 22:08:31,395 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3990705263885585, 'Total loss': 0.3990705263885585} | train loss {'Reaction outcome loss': 0.13092440359985397, 'Total loss': 0.13092440359985397}
2022-12-05 22:08:31,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:31,395 INFO:     Epoch: 83
2022-12-05 22:08:32,193 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40180114013227547, 'Total loss': 0.40180114013227547} | train loss {'Reaction outcome loss': 0.12777811962915886, 'Total loss': 0.12777811962915886}
2022-12-05 22:08:32,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:32,193 INFO:     Epoch: 84
2022-12-05 22:08:32,993 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3909652531147003, 'Total loss': 0.3909652531147003} | train loss {'Reaction outcome loss': 0.12983667923347844, 'Total loss': 0.12983667923347844}
2022-12-05 22:08:32,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:32,993 INFO:     Epoch: 85
2022-12-05 22:08:33,793 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3925220194188031, 'Total loss': 0.3925220194188031} | train loss {'Reaction outcome loss': 0.12893046563371055, 'Total loss': 0.12893046563371055}
2022-12-05 22:08:33,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:33,794 INFO:     Epoch: 86
2022-12-05 22:08:34,598 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38426386734301393, 'Total loss': 0.38426386734301393} | train loss {'Reaction outcome loss': 0.13137822572682653, 'Total loss': 0.13137822572682653}
2022-12-05 22:08:34,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:34,598 INFO:     Epoch: 87
2022-12-05 22:08:35,399 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.380438056351109, 'Total loss': 0.380438056351109} | train loss {'Reaction outcome loss': 0.12997564411301527, 'Total loss': 0.12997564411301527}
2022-12-05 22:08:35,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:35,399 INFO:     Epoch: 88
2022-12-05 22:08:36,202 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39875432374802505, 'Total loss': 0.39875432374802505} | train loss {'Reaction outcome loss': 0.1296252271821422, 'Total loss': 0.1296252271821422}
2022-12-05 22:08:36,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:36,203 INFO:     Epoch: 89
2022-12-05 22:08:37,004 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39216031337326224, 'Total loss': 0.39216031337326224} | train loss {'Reaction outcome loss': 0.12885783262355555, 'Total loss': 0.12885783262355555}
2022-12-05 22:08:37,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:37,005 INFO:     Epoch: 90
2022-12-05 22:08:37,804 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40647473253987054, 'Total loss': 0.40647473253987054} | train loss {'Reaction outcome loss': 0.12794356763122544, 'Total loss': 0.12794356763122544}
2022-12-05 22:08:37,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:37,804 INFO:     Epoch: 91
2022-12-05 22:08:38,604 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41164816882122646, 'Total loss': 0.41164816882122646} | train loss {'Reaction outcome loss': 0.12959420436339814, 'Total loss': 0.12959420436339814}
2022-12-05 22:08:38,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:38,604 INFO:     Epoch: 92
2022-12-05 22:08:39,405 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3924463243985718, 'Total loss': 0.3924463243985718} | train loss {'Reaction outcome loss': 0.1279491470758653, 'Total loss': 0.1279491470758653}
2022-12-05 22:08:39,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:39,405 INFO:     Epoch: 93
2022-12-05 22:08:40,203 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3862133171748031, 'Total loss': 0.3862133171748031} | train loss {'Reaction outcome loss': 0.1259718957552386, 'Total loss': 0.1259718957552386}
2022-12-05 22:08:40,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:40,203 INFO:     Epoch: 94
2022-12-05 22:08:41,002 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4033377387306907, 'Total loss': 0.4033377387306907} | train loss {'Reaction outcome loss': 0.12756112600196032, 'Total loss': 0.12756112600196032}
2022-12-05 22:08:41,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:41,002 INFO:     Epoch: 95
2022-12-05 22:08:41,800 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4003680707378821, 'Total loss': 0.4003680707378821} | train loss {'Reaction outcome loss': 0.1272673084655957, 'Total loss': 0.1272673084655957}
2022-12-05 22:08:41,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:41,800 INFO:     Epoch: 96
2022-12-05 22:08:42,599 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3871466519141739, 'Total loss': 0.3871466519141739} | train loss {'Reaction outcome loss': 0.12759718370263376, 'Total loss': 0.12759718370263376}
2022-12-05 22:08:42,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:42,599 INFO:     Epoch: 97
2022-12-05 22:08:43,395 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3966139690442519, 'Total loss': 0.3966139690442519} | train loss {'Reaction outcome loss': 0.12479065517113815, 'Total loss': 0.12479065517113815}
2022-12-05 22:08:43,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:43,396 INFO:     Epoch: 98
2022-12-05 22:08:44,193 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4040581284260208, 'Total loss': 0.4040581284260208} | train loss {'Reaction outcome loss': 0.128434871631344, 'Total loss': 0.128434871631344}
2022-12-05 22:08:44,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:44,195 INFO:     Epoch: 99
2022-12-05 22:08:44,992 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3880450204014778, 'Total loss': 0.3880450204014778} | train loss {'Reaction outcome loss': 0.1276895452962978, 'Total loss': 0.1276895452962978}
2022-12-05 22:08:44,993 INFO:     Best model found after epoch 16 of 100.
2022-12-05 22:08:44,993 INFO:   Done with stage: TRAINING
2022-12-05 22:08:44,993 INFO:   Starting stage: EVALUATION
2022-12-05 22:08:45,112 INFO:   Done with stage: EVALUATION
2022-12-05 22:08:45,112 INFO:   Leaving out SEQ value Fold_6
2022-12-05 22:08:45,125 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:08:45,125 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:08:45,777 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:08:45,777 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:08:45,847 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:08:45,847 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:08:45,847 INFO:     No hyperparam tuning for this model
2022-12-05 22:08:45,847 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:08:45,847 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:08:45,848 INFO:     None feature selector for col prot
2022-12-05 22:08:45,848 INFO:     None feature selector for col prot
2022-12-05 22:08:45,848 INFO:     None feature selector for col prot
2022-12-05 22:08:45,848 INFO:     None feature selector for col chem
2022-12-05 22:08:45,848 INFO:     None feature selector for col chem
2022-12-05 22:08:45,849 INFO:     None feature selector for col chem
2022-12-05 22:08:45,849 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:08:45,849 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:08:45,851 INFO:     Number of params in model 215821
2022-12-05 22:08:45,854 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:08:45,854 INFO:   Starting stage: TRAINING
2022-12-05 22:08:45,915 INFO:     Val loss before train {'Reaction outcome loss': 0.9079258557070385, 'Total loss': 0.9079258557070385}
2022-12-05 22:08:45,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:45,915 INFO:     Epoch: 0
2022-12-05 22:08:46,713 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5424868322231553, 'Total loss': 0.5424868322231553} | train loss {'Reaction outcome loss': 0.7948206735234107, 'Total loss': 0.7948206735234107}
2022-12-05 22:08:46,713 INFO:     Found new best model at epoch 0
2022-12-05 22:08:46,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:46,714 INFO:     Epoch: 1
2022-12-05 22:08:47,512 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.47325021163983777, 'Total loss': 0.47325021163983777} | train loss {'Reaction outcome loss': 0.540219166225964, 'Total loss': 0.540219166225964}
2022-12-05 22:08:47,512 INFO:     Found new best model at epoch 1
2022-12-05 22:08:47,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:47,513 INFO:     Epoch: 2
2022-12-05 22:08:48,313 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.441831497983499, 'Total loss': 0.441831497983499} | train loss {'Reaction outcome loss': 0.4695547250730376, 'Total loss': 0.4695547250730376}
2022-12-05 22:08:48,313 INFO:     Found new best model at epoch 2
2022-12-05 22:08:48,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:48,314 INFO:     Epoch: 3
2022-12-05 22:08:49,113 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.42182468927719374, 'Total loss': 0.42182468927719374} | train loss {'Reaction outcome loss': 0.4251023109761938, 'Total loss': 0.4251023109761938}
2022-12-05 22:08:49,113 INFO:     Found new best model at epoch 3
2022-12-05 22:08:49,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:49,114 INFO:     Epoch: 4
2022-12-05 22:08:49,916 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4162728806788271, 'Total loss': 0.4162728806788271} | train loss {'Reaction outcome loss': 0.3923235453905598, 'Total loss': 0.3923235453905598}
2022-12-05 22:08:49,916 INFO:     Found new best model at epoch 4
2022-12-05 22:08:49,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:49,917 INFO:     Epoch: 5
2022-12-05 22:08:50,715 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4058780853043903, 'Total loss': 0.4058780853043903} | train loss {'Reaction outcome loss': 0.37112386152148247, 'Total loss': 0.37112386152148247}
2022-12-05 22:08:50,716 INFO:     Found new best model at epoch 5
2022-12-05 22:08:50,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:50,717 INFO:     Epoch: 6
2022-12-05 22:08:51,510 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.3868536786599593, 'Total loss': 0.3868536786599593} | train loss {'Reaction outcome loss': 0.3508585340253288, 'Total loss': 0.3508585340253288}
2022-12-05 22:08:51,511 INFO:     Found new best model at epoch 6
2022-12-05 22:08:51,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:51,511 INFO:     Epoch: 7
2022-12-05 22:08:52,305 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.38964486054398795, 'Total loss': 0.38964486054398795} | train loss {'Reaction outcome loss': 0.3372327202870961, 'Total loss': 0.3372327202870961}
2022-12-05 22:08:52,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:52,305 INFO:     Epoch: 8
2022-12-05 22:08:53,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.38401595570824365, 'Total loss': 0.38401595570824365} | train loss {'Reaction outcome loss': 0.3194111401455537, 'Total loss': 0.3194111401455537}
2022-12-05 22:08:53,104 INFO:     Found new best model at epoch 8
2022-12-05 22:08:53,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:53,105 INFO:     Epoch: 9
2022-12-05 22:08:53,899 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3959982493384318, 'Total loss': 0.3959982493384318} | train loss {'Reaction outcome loss': 0.30900074784914333, 'Total loss': 0.30900074784914333}
2022-12-05 22:08:53,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:53,900 INFO:     Epoch: 10
2022-12-05 22:08:54,694 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3795652897520499, 'Total loss': 0.3795652897520499} | train loss {'Reaction outcome loss': 0.2948052673149974, 'Total loss': 0.2948052673149974}
2022-12-05 22:08:54,694 INFO:     Found new best model at epoch 10
2022-12-05 22:08:54,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:54,695 INFO:     Epoch: 11
2022-12-05 22:08:55,489 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38072644953023305, 'Total loss': 0.38072644953023305} | train loss {'Reaction outcome loss': 0.2838912969154696, 'Total loss': 0.2838912969154696}
2022-12-05 22:08:55,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:55,489 INFO:     Epoch: 12
2022-12-05 22:08:56,285 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.38787202604792337, 'Total loss': 0.38787202604792337} | train loss {'Reaction outcome loss': 0.2739579847322837, 'Total loss': 0.2739579847322837}
2022-12-05 22:08:56,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:56,285 INFO:     Epoch: 13
2022-12-05 22:08:57,081 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.37789776328612457, 'Total loss': 0.37789776328612457} | train loss {'Reaction outcome loss': 0.2638208955346096, 'Total loss': 0.2638208955346096}
2022-12-05 22:08:57,081 INFO:     Found new best model at epoch 13
2022-12-05 22:08:57,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:57,082 INFO:     Epoch: 14
2022-12-05 22:08:57,883 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3823441968045451, 'Total loss': 0.3823441968045451} | train loss {'Reaction outcome loss': 0.25601710470753813, 'Total loss': 0.25601710470753813}
2022-12-05 22:08:57,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:57,883 INFO:     Epoch: 15
2022-12-05 22:08:58,681 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41158541630614887, 'Total loss': 0.41158541630614887} | train loss {'Reaction outcome loss': 0.2475077389709411, 'Total loss': 0.2475077389709411}
2022-12-05 22:08:58,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:58,681 INFO:     Epoch: 16
2022-12-05 22:08:59,475 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3974370507692749, 'Total loss': 0.3974370507692749} | train loss {'Reaction outcome loss': 0.24391510184373585, 'Total loss': 0.24391510184373585}
2022-12-05 22:08:59,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:08:59,476 INFO:     Epoch: 17
2022-12-05 22:09:00,269 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38132230090824043, 'Total loss': 0.38132230090824043} | train loss {'Reaction outcome loss': 0.23381644101332752, 'Total loss': 0.23381644101332752}
2022-12-05 22:09:00,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:00,269 INFO:     Epoch: 18
2022-12-05 22:09:01,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38993848352269694, 'Total loss': 0.38993848352269694} | train loss {'Reaction outcome loss': 0.23179566260847834, 'Total loss': 0.23179566260847834}
2022-12-05 22:09:01,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:01,066 INFO:     Epoch: 19
2022-12-05 22:09:01,863 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3982925001870502, 'Total loss': 0.3982925001870502} | train loss {'Reaction outcome loss': 0.22342810983348999, 'Total loss': 0.22342810983348999}
2022-12-05 22:09:01,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:01,863 INFO:     Epoch: 20
2022-12-05 22:09:02,657 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39063604023646226, 'Total loss': 0.39063604023646226} | train loss {'Reaction outcome loss': 0.2177889422032862, 'Total loss': 0.2177889422032862}
2022-12-05 22:09:02,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:02,657 INFO:     Epoch: 21
2022-12-05 22:09:03,450 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39926252412525093, 'Total loss': 0.39926252412525093} | train loss {'Reaction outcome loss': 0.21234882672527625, 'Total loss': 0.21234882672527625}
2022-12-05 22:09:03,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:03,451 INFO:     Epoch: 22
2022-12-05 22:09:04,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38573337414047937, 'Total loss': 0.38573337414047937} | train loss {'Reaction outcome loss': 0.20780671335336182, 'Total loss': 0.20780671335336182}
2022-12-05 22:09:04,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:04,250 INFO:     Epoch: 23
2022-12-05 22:09:05,044 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38710188933394174, 'Total loss': 0.38710188933394174} | train loss {'Reaction outcome loss': 0.2033215668503075, 'Total loss': 0.2033215668503075}
2022-12-05 22:09:05,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:05,045 INFO:     Epoch: 24
2022-12-05 22:09:05,839 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3862483267757026, 'Total loss': 0.3862483267757026} | train loss {'Reaction outcome loss': 0.19712920997652314, 'Total loss': 0.19712920997652314}
2022-12-05 22:09:05,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:05,839 INFO:     Epoch: 25
2022-12-05 22:09:06,635 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3931179891594432, 'Total loss': 0.3931179891594432} | train loss {'Reaction outcome loss': 0.19721542050941818, 'Total loss': 0.19721542050941818}
2022-12-05 22:09:06,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:06,635 INFO:     Epoch: 26
2022-12-05 22:09:07,438 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3910619738427075, 'Total loss': 0.3910619738427075} | train loss {'Reaction outcome loss': 0.19134273339483526, 'Total loss': 0.19134273339483526}
2022-12-05 22:09:07,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:07,438 INFO:     Epoch: 27
2022-12-05 22:09:08,237 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39795428582213144, 'Total loss': 0.39795428582213144} | train loss {'Reaction outcome loss': 0.18873460577320186, 'Total loss': 0.18873460577320186}
2022-12-05 22:09:08,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:08,237 INFO:     Epoch: 28
2022-12-05 22:09:09,035 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4037987823513421, 'Total loss': 0.4037987823513421} | train loss {'Reaction outcome loss': 0.18719030994801752, 'Total loss': 0.18719030994801752}
2022-12-05 22:09:09,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:09,035 INFO:     Epoch: 29
2022-12-05 22:09:09,834 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4064220203594728, 'Total loss': 0.4064220203594728} | train loss {'Reaction outcome loss': 0.18188256956636906, 'Total loss': 0.18188256956636906}
2022-12-05 22:09:09,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:09,834 INFO:     Epoch: 30
2022-12-05 22:09:10,628 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4210017482665452, 'Total loss': 0.4210017482665452} | train loss {'Reaction outcome loss': 0.1803418714252691, 'Total loss': 0.1803418714252691}
2022-12-05 22:09:10,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:10,629 INFO:     Epoch: 31
2022-12-05 22:09:11,423 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3919630648398941, 'Total loss': 0.3919630648398941} | train loss {'Reaction outcome loss': 0.17546130378069658, 'Total loss': 0.17546130378069658}
2022-12-05 22:09:11,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:11,423 INFO:     Epoch: 32
2022-12-05 22:09:12,226 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4171373109248551, 'Total loss': 0.4171373109248551} | train loss {'Reaction outcome loss': 0.17520229764012318, 'Total loss': 0.17520229764012318}
2022-12-05 22:09:12,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:12,226 INFO:     Epoch: 33
2022-12-05 22:09:13,023 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4014888338067315, 'Total loss': 0.4014888338067315} | train loss {'Reaction outcome loss': 0.17447804932993266, 'Total loss': 0.17447804932993266}
2022-12-05 22:09:13,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:13,024 INFO:     Epoch: 34
2022-12-05 22:09:13,817 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41299401968717575, 'Total loss': 0.41299401968717575} | train loss {'Reaction outcome loss': 0.17067053757848277, 'Total loss': 0.17067053757848277}
2022-12-05 22:09:13,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:13,818 INFO:     Epoch: 35
2022-12-05 22:09:14,619 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4185244610363787, 'Total loss': 0.4185244610363787} | train loss {'Reaction outcome loss': 0.165792076901022, 'Total loss': 0.165792076901022}
2022-12-05 22:09:14,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:14,620 INFO:     Epoch: 36
2022-12-05 22:09:15,418 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41295298358256166, 'Total loss': 0.41295298358256166} | train loss {'Reaction outcome loss': 0.1673740962287411, 'Total loss': 0.1673740962287411}
2022-12-05 22:09:15,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:15,420 INFO:     Epoch: 37
2022-12-05 22:09:16,218 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4198148228566755, 'Total loss': 0.4198148228566755} | train loss {'Reaction outcome loss': 0.1648225656282457, 'Total loss': 0.1648225656282457}
2022-12-05 22:09:16,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:16,218 INFO:     Epoch: 38
2022-12-05 22:09:17,021 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41736987013031135, 'Total loss': 0.41736987013031135} | train loss {'Reaction outcome loss': 0.16327524211467995, 'Total loss': 0.16327524211467995}
2022-12-05 22:09:17,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:17,021 INFO:     Epoch: 39
2022-12-05 22:09:17,817 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4109644361517646, 'Total loss': 0.4109644361517646} | train loss {'Reaction outcome loss': 0.16303517096375506, 'Total loss': 0.16303517096375506}
2022-12-05 22:09:17,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:17,818 INFO:     Epoch: 40
2022-12-05 22:09:18,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40734759565781464, 'Total loss': 0.40734759565781464} | train loss {'Reaction outcome loss': 0.15849723920766864, 'Total loss': 0.15849723920766864}
2022-12-05 22:09:18,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:18,612 INFO:     Epoch: 41
2022-12-05 22:09:19,410 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4179161218079654, 'Total loss': 0.4179161218079654} | train loss {'Reaction outcome loss': 0.15873726841903502, 'Total loss': 0.15873726841903502}
2022-12-05 22:09:19,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:19,410 INFO:     Epoch: 42
2022-12-05 22:09:20,204 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4341005686331879, 'Total loss': 0.4341005686331879} | train loss {'Reaction outcome loss': 0.1538461794956557, 'Total loss': 0.1538461794956557}
2022-12-05 22:09:20,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:20,205 INFO:     Epoch: 43
2022-12-05 22:09:21,001 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4365886189043522, 'Total loss': 0.4365886189043522} | train loss {'Reaction outcome loss': 0.15713543419335638, 'Total loss': 0.15713543419335638}
2022-12-05 22:09:21,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:21,001 INFO:     Epoch: 44
2022-12-05 22:09:21,799 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4123698298565366, 'Total loss': 0.4123698298565366} | train loss {'Reaction outcome loss': 0.1521971906204858, 'Total loss': 0.1521971906204858}
2022-12-05 22:09:21,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:21,800 INFO:     Epoch: 45
2022-12-05 22:09:22,604 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42023322358727455, 'Total loss': 0.42023322358727455} | train loss {'Reaction outcome loss': 0.14966366717952392, 'Total loss': 0.14966366717952392}
2022-12-05 22:09:22,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:22,604 INFO:     Epoch: 46
2022-12-05 22:09:23,406 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4212291619994424, 'Total loss': 0.4212291619994424} | train loss {'Reaction outcome loss': 0.1506641056734107, 'Total loss': 0.1506641056734107}
2022-12-05 22:09:23,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:23,406 INFO:     Epoch: 47
2022-12-05 22:09:24,203 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42630593732676725, 'Total loss': 0.42630593732676725} | train loss {'Reaction outcome loss': 0.1516764295407601, 'Total loss': 0.1516764295407601}
2022-12-05 22:09:24,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:24,204 INFO:     Epoch: 48
2022-12-05 22:09:25,001 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.435460742901672, 'Total loss': 0.435460742901672} | train loss {'Reaction outcome loss': 0.1476452205134856, 'Total loss': 0.1476452205134856}
2022-12-05 22:09:25,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:25,001 INFO:     Epoch: 49
2022-12-05 22:09:25,797 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41134293834594166, 'Total loss': 0.41134293834594166} | train loss {'Reaction outcome loss': 0.14621892824934254, 'Total loss': 0.14621892824934254}
2022-12-05 22:09:25,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:25,798 INFO:     Epoch: 50
2022-12-05 22:09:26,593 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.412004849111492, 'Total loss': 0.412004849111492} | train loss {'Reaction outcome loss': 0.1465784011018132, 'Total loss': 0.1465784011018132}
2022-12-05 22:09:26,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:26,593 INFO:     Epoch: 51
2022-12-05 22:09:27,391 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41656589948318223, 'Total loss': 0.41656589948318223} | train loss {'Reaction outcome loss': 0.14668671046233467, 'Total loss': 0.14668671046233467}
2022-12-05 22:09:27,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:27,391 INFO:     Epoch: 52
2022-12-05 22:09:28,194 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.417616289278323, 'Total loss': 0.417616289278323} | train loss {'Reaction outcome loss': 0.1457730913121674, 'Total loss': 0.1457730913121674}
2022-12-05 22:09:28,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:28,195 INFO:     Epoch: 53
2022-12-05 22:09:28,996 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4339011355557225, 'Total loss': 0.4339011355557225} | train loss {'Reaction outcome loss': 0.1441496769717384, 'Total loss': 0.1441496769717384}
2022-12-05 22:09:28,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:28,997 INFO:     Epoch: 54
2022-12-05 22:09:29,790 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4369838126003742, 'Total loss': 0.4369838126003742} | train loss {'Reaction outcome loss': 0.14447828680427083, 'Total loss': 0.14447828680427083}
2022-12-05 22:09:29,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:29,791 INFO:     Epoch: 55
2022-12-05 22:09:30,591 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42369815842671826, 'Total loss': 0.42369815842671826} | train loss {'Reaction outcome loss': 0.14210213336252397, 'Total loss': 0.14210213336252397}
2022-12-05 22:09:30,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:30,591 INFO:     Epoch: 56
2022-12-05 22:09:31,385 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44223440844904294, 'Total loss': 0.44223440844904294} | train loss {'Reaction outcome loss': 0.1422717715106574, 'Total loss': 0.1422717715106574}
2022-12-05 22:09:31,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:31,385 INFO:     Epoch: 57
2022-12-05 22:09:32,182 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4246248780665072, 'Total loss': 0.4246248780665072} | train loss {'Reaction outcome loss': 0.14011392243687185, 'Total loss': 0.14011392243687185}
2022-12-05 22:09:32,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:32,182 INFO:     Epoch: 58
2022-12-05 22:09:32,981 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43932328711856494, 'Total loss': 0.43932328711856494} | train loss {'Reaction outcome loss': 0.13968736833832676, 'Total loss': 0.13968736833832676}
2022-12-05 22:09:32,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:32,981 INFO:     Epoch: 59
2022-12-05 22:09:33,774 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41599342972040176, 'Total loss': 0.41599342972040176} | train loss {'Reaction outcome loss': 0.14019402846573822, 'Total loss': 0.14019402846573822}
2022-12-05 22:09:33,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:33,774 INFO:     Epoch: 60
2022-12-05 22:09:34,568 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4376611838286573, 'Total loss': 0.4376611838286573} | train loss {'Reaction outcome loss': 0.13753163300815127, 'Total loss': 0.13753163300815127}
2022-12-05 22:09:34,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:34,569 INFO:     Epoch: 61
2022-12-05 22:09:35,363 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4364041408354586, 'Total loss': 0.4364041408354586} | train loss {'Reaction outcome loss': 0.13552462041843683, 'Total loss': 0.13552462041843683}
2022-12-05 22:09:35,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:35,363 INFO:     Epoch: 62
2022-12-05 22:09:36,157 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43375093811614945, 'Total loss': 0.43375093811614945} | train loss {'Reaction outcome loss': 0.13968234544154257, 'Total loss': 0.13968234544154257}
2022-12-05 22:09:36,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:36,157 INFO:     Epoch: 63
2022-12-05 22:09:36,951 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4311756315556439, 'Total loss': 0.4311756315556439} | train loss {'Reaction outcome loss': 0.1367646851952398, 'Total loss': 0.1367646851952398}
2022-12-05 22:09:36,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:36,951 INFO:     Epoch: 64
2022-12-05 22:09:37,749 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4328809675167907, 'Total loss': 0.4328809675167907} | train loss {'Reaction outcome loss': 0.13520587986380223, 'Total loss': 0.13520587986380223}
2022-12-05 22:09:37,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:37,750 INFO:     Epoch: 65
2022-12-05 22:09:38,549 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45021734285083687, 'Total loss': 0.45021734285083687} | train loss {'Reaction outcome loss': 0.1365080052205632, 'Total loss': 0.1365080052205632}
2022-12-05 22:09:38,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:38,549 INFO:     Epoch: 66
2022-12-05 22:09:39,348 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44088090414350684, 'Total loss': 0.44088090414350684} | train loss {'Reaction outcome loss': 0.13432721681367124, 'Total loss': 0.13432721681367124}
2022-12-05 22:09:39,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:39,348 INFO:     Epoch: 67
2022-12-05 22:09:40,145 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41715922714634374, 'Total loss': 0.41715922714634374} | train loss {'Reaction outcome loss': 0.1360986478806984, 'Total loss': 0.1360986478806984}
2022-12-05 22:09:40,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:40,146 INFO:     Epoch: 68
2022-12-05 22:09:40,943 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.426185204224153, 'Total loss': 0.426185204224153} | train loss {'Reaction outcome loss': 0.13790792637249275, 'Total loss': 0.13790792637249275}
2022-12-05 22:09:40,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:40,944 INFO:     Epoch: 69
2022-12-05 22:09:41,739 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43584587272595277, 'Total loss': 0.43584587272595277} | train loss {'Reaction outcome loss': 0.1347536408612805, 'Total loss': 0.1347536408612805}
2022-12-05 22:09:41,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:41,739 INFO:     Epoch: 70
2022-12-05 22:09:42,535 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4398739385333928, 'Total loss': 0.4398739385333928} | train loss {'Reaction outcome loss': 0.13294948877826815, 'Total loss': 0.13294948877826815}
2022-12-05 22:09:42,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:42,536 INFO:     Epoch: 71
2022-12-05 22:09:43,330 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43660285797986115, 'Total loss': 0.43660285797986115} | train loss {'Reaction outcome loss': 0.1309519289962707, 'Total loss': 0.1309519289962707}
2022-12-05 22:09:43,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:43,330 INFO:     Epoch: 72
2022-12-05 22:09:44,124 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44057767668908293, 'Total loss': 0.44057767668908293} | train loss {'Reaction outcome loss': 0.13191966474762246, 'Total loss': 0.13191966474762246}
2022-12-05 22:09:44,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:44,124 INFO:     Epoch: 73
2022-12-05 22:09:44,919 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43843389742753724, 'Total loss': 0.43843389742753724} | train loss {'Reaction outcome loss': 0.13240300024288795, 'Total loss': 0.13240300024288795}
2022-12-05 22:09:44,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:44,919 INFO:     Epoch: 74
2022-12-05 22:09:45,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4494158960878849, 'Total loss': 0.4494158960878849} | train loss {'Reaction outcome loss': 0.13206836540297034, 'Total loss': 0.13206836540297034}
2022-12-05 22:09:45,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:45,717 INFO:     Epoch: 75
2022-12-05 22:09:46,511 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45391621897843754, 'Total loss': 0.45391621897843754} | train loss {'Reaction outcome loss': 0.1307907898745109, 'Total loss': 0.1307907898745109}
2022-12-05 22:09:46,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:46,512 INFO:     Epoch: 76
2022-12-05 22:09:47,307 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44422753663225606, 'Total loss': 0.44422753663225606} | train loss {'Reaction outcome loss': 0.12969795700478098, 'Total loss': 0.12969795700478098}
2022-12-05 22:09:47,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:47,307 INFO:     Epoch: 77
2022-12-05 22:09:48,112 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4417628175155683, 'Total loss': 0.4417628175155683} | train loss {'Reaction outcome loss': 0.13051552240616612, 'Total loss': 0.13051552240616612}
2022-12-05 22:09:48,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:48,112 INFO:     Epoch: 78
2022-12-05 22:09:48,914 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4487040662630038, 'Total loss': 0.4487040662630038} | train loss {'Reaction outcome loss': 0.1295998954493928, 'Total loss': 0.1295998954493928}
2022-12-05 22:09:48,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:48,915 INFO:     Epoch: 79
2022-12-05 22:09:49,710 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44083575684238563, 'Total loss': 0.44083575684238563} | train loss {'Reaction outcome loss': 0.13225015691827022, 'Total loss': 0.13225015691827022}
2022-12-05 22:09:49,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:49,710 INFO:     Epoch: 80
2022-12-05 22:09:50,511 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43611049618233333, 'Total loss': 0.43611049618233333} | train loss {'Reaction outcome loss': 0.12874460134715324, 'Total loss': 0.12874460134715324}
2022-12-05 22:09:50,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:50,512 INFO:     Epoch: 81
2022-12-05 22:09:51,316 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4438894157382575, 'Total loss': 0.4438894157382575} | train loss {'Reaction outcome loss': 0.127490739067716, 'Total loss': 0.127490739067716}
2022-12-05 22:09:51,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:51,316 INFO:     Epoch: 82
2022-12-05 22:09:52,111 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45488298176364467, 'Total loss': 0.45488298176364467} | train loss {'Reaction outcome loss': 0.12792527528044076, 'Total loss': 0.12792527528044076}
2022-12-05 22:09:52,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:52,111 INFO:     Epoch: 83
2022-12-05 22:09:52,907 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4468170820989392, 'Total loss': 0.4468170820989392} | train loss {'Reaction outcome loss': 0.12769832617918692, 'Total loss': 0.12769832617918692}
2022-12-05 22:09:52,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:52,908 INFO:     Epoch: 84
2022-12-05 22:09:53,703 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45355037616735155, 'Total loss': 0.45355037616735155} | train loss {'Reaction outcome loss': 0.12817316093752462, 'Total loss': 0.12817316093752462}
2022-12-05 22:09:53,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:53,703 INFO:     Epoch: 85
2022-12-05 22:09:54,503 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43942801214077254, 'Total loss': 0.43942801214077254} | train loss {'Reaction outcome loss': 0.12585869824303494, 'Total loss': 0.12585869824303494}
2022-12-05 22:09:54,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:54,503 INFO:     Epoch: 86
2022-12-05 22:09:55,303 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44976237924261525, 'Total loss': 0.44976237924261525} | train loss {'Reaction outcome loss': 0.12902933682104753, 'Total loss': 0.12902933682104753}
2022-12-05 22:09:55,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:55,304 INFO:     Epoch: 87
2022-12-05 22:09:56,099 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46241660763255577, 'Total loss': 0.46241660763255577} | train loss {'Reaction outcome loss': 0.1278995592147112, 'Total loss': 0.1278995592147112}
2022-12-05 22:09:56,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:56,099 INFO:     Epoch: 88
2022-12-05 22:09:56,897 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4703972304070538, 'Total loss': 0.4703972304070538} | train loss {'Reaction outcome loss': 0.12659639651481544, 'Total loss': 0.12659639651481544}
2022-12-05 22:09:56,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:56,897 INFO:     Epoch: 89
2022-12-05 22:09:57,691 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4568651487881487, 'Total loss': 0.4568651487881487} | train loss {'Reaction outcome loss': 0.12814040547387012, 'Total loss': 0.12814040547387012}
2022-12-05 22:09:57,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:57,691 INFO:     Epoch: 90
2022-12-05 22:09:58,488 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4559944575144486, 'Total loss': 0.4559944575144486} | train loss {'Reaction outcome loss': 0.12470298746578215, 'Total loss': 0.12470298746578215}
2022-12-05 22:09:58,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:58,489 INFO:     Epoch: 91
2022-12-05 22:09:59,283 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4597890901971947, 'Total loss': 0.4597890901971947} | train loss {'Reaction outcome loss': 0.12495270686603392, 'Total loss': 0.12495270686603392}
2022-12-05 22:09:59,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:09:59,284 INFO:     Epoch: 92
2022-12-05 22:10:00,077 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4606169154020873, 'Total loss': 0.4606169154020873} | train loss {'Reaction outcome loss': 0.12494620812621209, 'Total loss': 0.12494620812621209}
2022-12-05 22:10:00,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:00,078 INFO:     Epoch: 93
2022-12-05 22:10:00,874 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4617238495160233, 'Total loss': 0.4617238495160233} | train loss {'Reaction outcome loss': 0.12568885356473225, 'Total loss': 0.12568885356473225}
2022-12-05 22:10:00,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:00,874 INFO:     Epoch: 94
2022-12-05 22:10:01,674 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44891744547269563, 'Total loss': 0.44891744547269563} | train loss {'Reaction outcome loss': 0.12454820513695238, 'Total loss': 0.12454820513695238}
2022-12-05 22:10:01,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:01,674 INFO:     Epoch: 95
2022-12-05 22:10:02,470 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45471434464508836, 'Total loss': 0.45471434464508836} | train loss {'Reaction outcome loss': 0.12228290355133434, 'Total loss': 0.12228290355133434}
2022-12-05 22:10:02,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:02,470 INFO:     Epoch: 96
2022-12-05 22:10:03,264 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4486176219176162, 'Total loss': 0.4486176219176162} | train loss {'Reaction outcome loss': 0.12334813631605357, 'Total loss': 0.12334813631605357}
2022-12-05 22:10:03,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:03,264 INFO:     Epoch: 97
2022-12-05 22:10:04,056 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45193850181319495, 'Total loss': 0.45193850181319495} | train loss {'Reaction outcome loss': 0.1230040725222939, 'Total loss': 0.1230040725222939}
2022-12-05 22:10:04,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:04,056 INFO:     Epoch: 98
2022-12-05 22:10:04,850 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44608594036915084, 'Total loss': 0.44608594036915084} | train loss {'Reaction outcome loss': 0.12298371120836706, 'Total loss': 0.12298371120836706}
2022-12-05 22:10:04,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:04,850 INFO:     Epoch: 99
2022-12-05 22:10:05,650 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4561770683662458, 'Total loss': 0.4561770683662458} | train loss {'Reaction outcome loss': 0.12300432898149255, 'Total loss': 0.12300432898149255}
2022-12-05 22:10:05,650 INFO:     Best model found after epoch 14 of 100.
2022-12-05 22:10:05,651 INFO:   Done with stage: TRAINING
2022-12-05 22:10:05,651 INFO:   Starting stage: EVALUATION
2022-12-05 22:10:05,770 INFO:   Done with stage: EVALUATION
2022-12-05 22:10:05,770 INFO:   Leaving out SEQ value Fold_7
2022-12-05 22:10:05,783 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:10:05,783 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:10:06,434 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:10:06,434 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:10:06,503 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:10:06,503 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:10:06,503 INFO:     No hyperparam tuning for this model
2022-12-05 22:10:06,503 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:10:06,503 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:10:06,504 INFO:     None feature selector for col prot
2022-12-05 22:10:06,504 INFO:     None feature selector for col prot
2022-12-05 22:10:06,504 INFO:     None feature selector for col prot
2022-12-05 22:10:06,505 INFO:     None feature selector for col chem
2022-12-05 22:10:06,505 INFO:     None feature selector for col chem
2022-12-05 22:10:06,505 INFO:     None feature selector for col chem
2022-12-05 22:10:06,505 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:10:06,505 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:10:06,507 INFO:     Number of params in model 215821
2022-12-05 22:10:06,510 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:10:06,510 INFO:   Starting stage: TRAINING
2022-12-05 22:10:06,571 INFO:     Val loss before train {'Reaction outcome loss': 0.9923278201710094, 'Total loss': 0.9923278201710094}
2022-12-05 22:10:06,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:06,571 INFO:     Epoch: 0
2022-12-05 22:10:07,371 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.592700604010712, 'Total loss': 0.592700604010712} | train loss {'Reaction outcome loss': 0.787848120615367, 'Total loss': 0.787848120615367}
2022-12-05 22:10:07,371 INFO:     Found new best model at epoch 0
2022-12-05 22:10:07,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:07,372 INFO:     Epoch: 1
2022-12-05 22:10:08,168 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5079832815311172, 'Total loss': 0.5079832815311172} | train loss {'Reaction outcome loss': 0.5261458990674827, 'Total loss': 0.5261458990674827}
2022-12-05 22:10:08,168 INFO:     Found new best model at epoch 1
2022-12-05 22:10:08,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:08,169 INFO:     Epoch: 2
2022-12-05 22:10:08,966 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48132873292673717, 'Total loss': 0.48132873292673717} | train loss {'Reaction outcome loss': 0.4583510403791743, 'Total loss': 0.4583510403791743}
2022-12-05 22:10:08,966 INFO:     Found new best model at epoch 2
2022-12-05 22:10:08,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:08,967 INFO:     Epoch: 3
2022-12-05 22:10:09,762 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45376534336669877, 'Total loss': 0.45376534336669877} | train loss {'Reaction outcome loss': 0.4202022303136126, 'Total loss': 0.4202022303136126}
2022-12-05 22:10:09,762 INFO:     Found new best model at epoch 3
2022-12-05 22:10:09,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:09,763 INFO:     Epoch: 4
2022-12-05 22:10:10,561 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45528360693292186, 'Total loss': 0.45528360693292186} | train loss {'Reaction outcome loss': 0.3932953947373936, 'Total loss': 0.3932953947373936}
2022-12-05 22:10:10,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:10,562 INFO:     Epoch: 5
2022-12-05 22:10:11,357 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4484252384440465, 'Total loss': 0.4484252384440465} | train loss {'Reaction outcome loss': 0.36640945257198426, 'Total loss': 0.36640945257198426}
2022-12-05 22:10:11,357 INFO:     Found new best model at epoch 5
2022-12-05 22:10:11,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:11,358 INFO:     Epoch: 6
2022-12-05 22:10:12,153 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4419677254151214, 'Total loss': 0.4419677254151214} | train loss {'Reaction outcome loss': 0.3502787974993548, 'Total loss': 0.3502787974993548}
2022-12-05 22:10:12,153 INFO:     Found new best model at epoch 6
2022-12-05 22:10:12,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:12,154 INFO:     Epoch: 7
2022-12-05 22:10:12,948 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44121661003340373, 'Total loss': 0.44121661003340373} | train loss {'Reaction outcome loss': 0.33525464933125243, 'Total loss': 0.33525464933125243}
2022-12-05 22:10:12,948 INFO:     Found new best model at epoch 7
2022-12-05 22:10:12,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:12,949 INFO:     Epoch: 8
2022-12-05 22:10:13,750 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4285092076117342, 'Total loss': 0.4285092076117342} | train loss {'Reaction outcome loss': 0.31989333868747755, 'Total loss': 0.31989333868747755}
2022-12-05 22:10:13,750 INFO:     Found new best model at epoch 8
2022-12-05 22:10:13,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:13,751 INFO:     Epoch: 9
2022-12-05 22:10:14,550 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4310532906516032, 'Total loss': 0.4310532906516032} | train loss {'Reaction outcome loss': 0.3059310364807325, 'Total loss': 0.3059310364807325}
2022-12-05 22:10:14,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:14,551 INFO:     Epoch: 10
2022-12-05 22:10:15,351 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42377756095745345, 'Total loss': 0.42377756095745345} | train loss {'Reaction outcome loss': 0.2958409244104499, 'Total loss': 0.2958409244104499}
2022-12-05 22:10:15,352 INFO:     Found new best model at epoch 10
2022-12-05 22:10:15,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:15,352 INFO:     Epoch: 11
2022-12-05 22:10:16,154 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42307336967099796, 'Total loss': 0.42307336967099796} | train loss {'Reaction outcome loss': 0.2839430670043634, 'Total loss': 0.2839430670043634}
2022-12-05 22:10:16,154 INFO:     Found new best model at epoch 11
2022-12-05 22:10:16,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:16,155 INFO:     Epoch: 12
2022-12-05 22:10:16,950 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4249932684681632, 'Total loss': 0.4249932684681632} | train loss {'Reaction outcome loss': 0.2721045736463801, 'Total loss': 0.2721045736463801}
2022-12-05 22:10:16,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:16,950 INFO:     Epoch: 13
2022-12-05 22:10:17,745 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.424705984917554, 'Total loss': 0.424705984917554} | train loss {'Reaction outcome loss': 0.2627847388446812, 'Total loss': 0.2627847388446812}
2022-12-05 22:10:17,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:17,747 INFO:     Epoch: 14
2022-12-05 22:10:18,541 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43342951956120407, 'Total loss': 0.43342951956120407} | train loss {'Reaction outcome loss': 0.2537239481274399, 'Total loss': 0.2537239481274399}
2022-12-05 22:10:18,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:18,541 INFO:     Epoch: 15
2022-12-05 22:10:19,336 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4153732203624465, 'Total loss': 0.4153732203624465} | train loss {'Reaction outcome loss': 0.24517238680874148, 'Total loss': 0.24517238680874148}
2022-12-05 22:10:19,336 INFO:     Found new best model at epoch 15
2022-12-05 22:10:19,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:19,337 INFO:     Epoch: 16
2022-12-05 22:10:20,137 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41082617979158054, 'Total loss': 0.41082617979158054} | train loss {'Reaction outcome loss': 0.23808800649919337, 'Total loss': 0.23808800649919337}
2022-12-05 22:10:20,137 INFO:     Found new best model at epoch 16
2022-12-05 22:10:20,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:20,138 INFO:     Epoch: 17
2022-12-05 22:10:20,936 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4162269849330187, 'Total loss': 0.4162269849330187} | train loss {'Reaction outcome loss': 0.22920966481850033, 'Total loss': 0.22920966481850033}
2022-12-05 22:10:20,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:20,936 INFO:     Epoch: 18
2022-12-05 22:10:21,738 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4070732952518897, 'Total loss': 0.4070732952518897} | train loss {'Reaction outcome loss': 0.22334801435710921, 'Total loss': 0.22334801435710921}
2022-12-05 22:10:21,738 INFO:     Found new best model at epoch 18
2022-12-05 22:10:21,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:21,739 INFO:     Epoch: 19
2022-12-05 22:10:22,534 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41171208633617923, 'Total loss': 0.41171208633617923} | train loss {'Reaction outcome loss': 0.22015794241170009, 'Total loss': 0.22015794241170009}
2022-12-05 22:10:22,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:22,534 INFO:     Epoch: 20
2022-12-05 22:10:23,332 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4044433825395324, 'Total loss': 0.4044433825395324} | train loss {'Reaction outcome loss': 0.2156276153700967, 'Total loss': 0.2156276153700967}
2022-12-05 22:10:23,332 INFO:     Found new best model at epoch 20
2022-12-05 22:10:23,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:23,333 INFO:     Epoch: 21
2022-12-05 22:10:24,129 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4172090857543729, 'Total loss': 0.4172090857543729} | train loss {'Reaction outcome loss': 0.21026071063393065, 'Total loss': 0.21026071063393065}
2022-12-05 22:10:24,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:24,130 INFO:     Epoch: 22
2022-12-05 22:10:24,925 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4194778085432269, 'Total loss': 0.4194778085432269} | train loss {'Reaction outcome loss': 0.20189118253127222, 'Total loss': 0.20189118253127222}
2022-12-05 22:10:24,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:24,925 INFO:     Epoch: 23
2022-12-05 22:10:25,722 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41856395741077984, 'Total loss': 0.41856395741077984} | train loss {'Reaction outcome loss': 0.1970825147131578, 'Total loss': 0.1970825147131578}
2022-12-05 22:10:25,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:25,722 INFO:     Epoch: 24
2022-12-05 22:10:26,526 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4195393923331391, 'Total loss': 0.4195393923331391} | train loss {'Reaction outcome loss': 0.19580408458357618, 'Total loss': 0.19580408458357618}
2022-12-05 22:10:26,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:26,527 INFO:     Epoch: 25
2022-12-05 22:10:27,323 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4191751886497844, 'Total loss': 0.4191751886497844} | train loss {'Reaction outcome loss': 0.19054600712092173, 'Total loss': 0.19054600712092173}
2022-12-05 22:10:27,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:27,323 INFO:     Epoch: 26
2022-12-05 22:10:28,117 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4121563507413322, 'Total loss': 0.4121563507413322} | train loss {'Reaction outcome loss': 0.18668949921735592, 'Total loss': 0.18668949921735592}
2022-12-05 22:10:28,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:28,117 INFO:     Epoch: 27
2022-12-05 22:10:28,916 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41009780256585643, 'Total loss': 0.41009780256585643} | train loss {'Reaction outcome loss': 0.1858880838469392, 'Total loss': 0.1858880838469392}
2022-12-05 22:10:28,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:28,916 INFO:     Epoch: 28
2022-12-05 22:10:29,718 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4282193068753589, 'Total loss': 0.4282193068753589} | train loss {'Reaction outcome loss': 0.1809989000490356, 'Total loss': 0.1809989000490356}
2022-12-05 22:10:29,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:29,718 INFO:     Epoch: 29
2022-12-05 22:10:30,514 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42300357432527974, 'Total loss': 0.42300357432527974} | train loss {'Reaction outcome loss': 0.17750936304970133, 'Total loss': 0.17750936304970133}
2022-12-05 22:10:30,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:30,514 INFO:     Epoch: 30
2022-12-05 22:10:31,310 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43532840128649364, 'Total loss': 0.43532840128649364} | train loss {'Reaction outcome loss': 0.17686597810637567, 'Total loss': 0.17686597810637567}
2022-12-05 22:10:31,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:31,311 INFO:     Epoch: 31
2022-12-05 22:10:32,107 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4116107782518322, 'Total loss': 0.4116107782518322} | train loss {'Reaction outcome loss': 0.1708969692248971, 'Total loss': 0.1708969692248971}
2022-12-05 22:10:32,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:32,107 INFO:     Epoch: 32
2022-12-05 22:10:32,904 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43168480254032393, 'Total loss': 0.43168480254032393} | train loss {'Reaction outcome loss': 0.16990388992182429, 'Total loss': 0.16990388992182429}
2022-12-05 22:10:32,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:32,904 INFO:     Epoch: 33
2022-12-05 22:10:33,701 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4238972199911421, 'Total loss': 0.4238972199911421} | train loss {'Reaction outcome loss': 0.1675584996269355, 'Total loss': 0.1675584996269355}
2022-12-05 22:10:33,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:33,701 INFO:     Epoch: 34
2022-12-05 22:10:34,500 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42324807901274075, 'Total loss': 0.42324807901274075} | train loss {'Reaction outcome loss': 0.1639121361677685, 'Total loss': 0.1639121361677685}
2022-12-05 22:10:34,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:34,501 INFO:     Epoch: 35
2022-12-05 22:10:35,298 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44127524915066635, 'Total loss': 0.44127524915066635} | train loss {'Reaction outcome loss': 0.16273488814101345, 'Total loss': 0.16273488814101345}
2022-12-05 22:10:35,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:35,298 INFO:     Epoch: 36
2022-12-05 22:10:36,095 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.432043215429241, 'Total loss': 0.432043215429241} | train loss {'Reaction outcome loss': 0.16163662546164087, 'Total loss': 0.16163662546164087}
2022-12-05 22:10:36,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:36,095 INFO:     Epoch: 37
2022-12-05 22:10:36,894 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42104488238692284, 'Total loss': 0.42104488238692284} | train loss {'Reaction outcome loss': 0.15849397284910083, 'Total loss': 0.15849397284910083}
2022-12-05 22:10:36,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:36,895 INFO:     Epoch: 38
2022-12-05 22:10:37,693 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43020172721960326, 'Total loss': 0.43020172721960326} | train loss {'Reaction outcome loss': 0.15750396186335675, 'Total loss': 0.15750396186335675}
2022-12-05 22:10:37,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:37,694 INFO:     Epoch: 39
2022-12-05 22:10:38,488 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4260061081837524, 'Total loss': 0.4260061081837524} | train loss {'Reaction outcome loss': 0.15634281693717406, 'Total loss': 0.15634281693717406}
2022-12-05 22:10:38,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:38,488 INFO:     Epoch: 40
2022-12-05 22:10:39,282 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4342018196528608, 'Total loss': 0.4342018196528608} | train loss {'Reaction outcome loss': 0.15445329900079918, 'Total loss': 0.15445329900079918}
2022-12-05 22:10:39,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:39,283 INFO:     Epoch: 41
2022-12-05 22:10:40,080 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45428075099533255, 'Total loss': 0.45428075099533255} | train loss {'Reaction outcome loss': 0.15089233264312027, 'Total loss': 0.15089233264312027}
2022-12-05 22:10:40,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:40,080 INFO:     Epoch: 42
2022-12-05 22:10:40,875 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43804616311734373, 'Total loss': 0.43804616311734373} | train loss {'Reaction outcome loss': 0.15053347830900982, 'Total loss': 0.15053347830900982}
2022-12-05 22:10:40,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:40,876 INFO:     Epoch: 43
2022-12-05 22:10:41,672 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43243028596043587, 'Total loss': 0.43243028596043587} | train loss {'Reaction outcome loss': 0.15111054682112748, 'Total loss': 0.15111054682112748}
2022-12-05 22:10:41,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:41,673 INFO:     Epoch: 44
2022-12-05 22:10:42,474 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43274412947622215, 'Total loss': 0.43274412947622215} | train loss {'Reaction outcome loss': 0.14749107887637952, 'Total loss': 0.14749107887637952}
2022-12-05 22:10:42,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:42,474 INFO:     Epoch: 45
2022-12-05 22:10:43,275 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4436405829407952, 'Total loss': 0.4436405829407952} | train loss {'Reaction outcome loss': 0.14667999121781078, 'Total loss': 0.14667999121781078}
2022-12-05 22:10:43,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:43,275 INFO:     Epoch: 46
2022-12-05 22:10:44,070 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44286458736116235, 'Total loss': 0.44286458736116235} | train loss {'Reaction outcome loss': 0.14563284673532773, 'Total loss': 0.14563284673532773}
2022-12-05 22:10:44,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:44,071 INFO:     Epoch: 47
2022-12-05 22:10:44,872 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4503306685523553, 'Total loss': 0.4503306685523553} | train loss {'Reaction outcome loss': 0.14489311088747794, 'Total loss': 0.14489311088747794}
2022-12-05 22:10:44,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:44,872 INFO:     Epoch: 48
2022-12-05 22:10:45,674 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44887683946977963, 'Total loss': 0.44887683946977963} | train loss {'Reaction outcome loss': 0.14495693937304518, 'Total loss': 0.14495693937304518}
2022-12-05 22:10:45,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:45,674 INFO:     Epoch: 49
2022-12-05 22:10:46,472 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44098921797492285, 'Total loss': 0.44098921797492285} | train loss {'Reaction outcome loss': 0.1445768269477412, 'Total loss': 0.1445768269477412}
2022-12-05 22:10:46,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:46,472 INFO:     Epoch: 50
2022-12-05 22:10:47,267 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4465521015226841, 'Total loss': 0.4465521015226841} | train loss {'Reaction outcome loss': 0.14074708273514144, 'Total loss': 0.14074708273514144}
2022-12-05 22:10:47,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:47,267 INFO:     Epoch: 51
2022-12-05 22:10:48,063 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4428088136694648, 'Total loss': 0.4428088136694648} | train loss {'Reaction outcome loss': 0.14122410720935272, 'Total loss': 0.14122410720935272}
2022-12-05 22:10:48,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:48,063 INFO:     Epoch: 52
2022-12-05 22:10:48,858 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4352569072083993, 'Total loss': 0.4352569072083993} | train loss {'Reaction outcome loss': 0.14143560395290655, 'Total loss': 0.14143560395290655}
2022-12-05 22:10:48,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:48,859 INFO:     Epoch: 53
2022-12-05 22:10:49,660 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44499978490851144, 'Total loss': 0.44499978490851144} | train loss {'Reaction outcome loss': 0.13669136284490027, 'Total loss': 0.13669136284490027}
2022-12-05 22:10:49,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:49,661 INFO:     Epoch: 54
2022-12-05 22:10:50,461 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4413813352584839, 'Total loss': 0.4413813352584839} | train loss {'Reaction outcome loss': 0.13909835098761944, 'Total loss': 0.13909835098761944}
2022-12-05 22:10:50,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:50,461 INFO:     Epoch: 55
2022-12-05 22:10:51,258 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46076616509394214, 'Total loss': 0.46076616509394214} | train loss {'Reaction outcome loss': 0.13581139592814348, 'Total loss': 0.13581139592814348}
2022-12-05 22:10:51,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:51,258 INFO:     Epoch: 56
2022-12-05 22:10:52,059 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4399854432452809, 'Total loss': 0.4399854432452809} | train loss {'Reaction outcome loss': 0.13535553754322352, 'Total loss': 0.13535553754322352}
2022-12-05 22:10:52,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:52,060 INFO:     Epoch: 57
2022-12-05 22:10:52,858 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45470422912727704, 'Total loss': 0.45470422912727704} | train loss {'Reaction outcome loss': 0.13603505583652745, 'Total loss': 0.13603505583652745}
2022-12-05 22:10:52,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:52,858 INFO:     Epoch: 58
2022-12-05 22:10:53,652 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44200359691273083, 'Total loss': 0.44200359691273083} | train loss {'Reaction outcome loss': 0.13450447504123253, 'Total loss': 0.13450447504123253}
2022-12-05 22:10:53,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:53,652 INFO:     Epoch: 59
2022-12-05 22:10:54,454 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4436193379488858, 'Total loss': 0.4436193379488858} | train loss {'Reaction outcome loss': 0.13289276309942286, 'Total loss': 0.13289276309942286}
2022-12-05 22:10:54,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:54,454 INFO:     Epoch: 60
2022-12-05 22:10:55,252 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43976932764053345, 'Total loss': 0.43976932764053345} | train loss {'Reaction outcome loss': 0.13336622659041877, 'Total loss': 0.13336622659041877}
2022-12-05 22:10:55,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:55,252 INFO:     Epoch: 61
2022-12-05 22:10:56,050 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45154631408778106, 'Total loss': 0.45154631408778106} | train loss {'Reaction outcome loss': 0.13255991307537882, 'Total loss': 0.13255991307537882}
2022-12-05 22:10:56,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:56,051 INFO:     Epoch: 62
2022-12-05 22:10:56,846 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43963405083526264, 'Total loss': 0.43963405083526264} | train loss {'Reaction outcome loss': 0.13313075271435082, 'Total loss': 0.13313075271435082}
2022-12-05 22:10:56,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:56,846 INFO:     Epoch: 63
2022-12-05 22:10:57,646 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4548747549680146, 'Total loss': 0.4548747549680146} | train loss {'Reaction outcome loss': 0.13277765533195868, 'Total loss': 0.13277765533195868}
2022-12-05 22:10:57,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:57,646 INFO:     Epoch: 64
2022-12-05 22:10:58,446 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4592215618626638, 'Total loss': 0.4592215618626638} | train loss {'Reaction outcome loss': 0.12927771339027752, 'Total loss': 0.12927771339027752}
2022-12-05 22:10:58,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:58,446 INFO:     Epoch: 65
2022-12-05 22:10:59,244 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4567223424938592, 'Total loss': 0.4567223424938592} | train loss {'Reaction outcome loss': 0.13177658457519306, 'Total loss': 0.13177658457519306}
2022-12-05 22:10:59,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:10:59,245 INFO:     Epoch: 66
2022-12-05 22:11:00,043 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4477125341919335, 'Total loss': 0.4477125341919335} | train loss {'Reaction outcome loss': 0.12872156255968636, 'Total loss': 0.12872156255968636}
2022-12-05 22:11:00,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:00,043 INFO:     Epoch: 67
2022-12-05 22:11:00,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4531495567749847, 'Total loss': 0.4531495567749847} | train loss {'Reaction outcome loss': 0.12801564600498927, 'Total loss': 0.12801564600498927}
2022-12-05 22:11:00,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:00,839 INFO:     Epoch: 68
2022-12-05 22:11:01,634 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4548657082698562, 'Total loss': 0.4548657082698562} | train loss {'Reaction outcome loss': 0.12821083547051756, 'Total loss': 0.12821083547051756}
2022-12-05 22:11:01,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:01,634 INFO:     Epoch: 69
2022-12-05 22:11:02,430 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.446044057268988, 'Total loss': 0.446044057268988} | train loss {'Reaction outcome loss': 0.12937384690233175, 'Total loss': 0.12937384690233175}
2022-12-05 22:11:02,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:02,430 INFO:     Epoch: 70
2022-12-05 22:11:03,231 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44349891116673296, 'Total loss': 0.44349891116673296} | train loss {'Reaction outcome loss': 0.12588476000218501, 'Total loss': 0.12588476000218501}
2022-12-05 22:11:03,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:03,231 INFO:     Epoch: 71
2022-12-05 22:11:04,031 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4678995588963682, 'Total loss': 0.4678995588963682} | train loss {'Reaction outcome loss': 0.12782733580247768, 'Total loss': 0.12782733580247768}
2022-12-05 22:11:04,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:04,031 INFO:     Epoch: 72
2022-12-05 22:11:04,832 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44628140567378566, 'Total loss': 0.44628140567378566} | train loss {'Reaction outcome loss': 0.12943749335564433, 'Total loss': 0.12943749335564433}
2022-12-05 22:11:04,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:04,832 INFO:     Epoch: 73
2022-12-05 22:11:05,633 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43517816202207044, 'Total loss': 0.43517816202207044} | train loss {'Reaction outcome loss': 0.1265666157442836, 'Total loss': 0.1265666157442836}
2022-12-05 22:11:05,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:05,633 INFO:     Epoch: 74
2022-12-05 22:11:06,434 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4503182518211278, 'Total loss': 0.4503182518211278} | train loss {'Reaction outcome loss': 0.1248292045277213, 'Total loss': 0.1248292045277213}
2022-12-05 22:11:06,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:06,434 INFO:     Epoch: 75
2022-12-05 22:11:07,231 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4372845364057205, 'Total loss': 0.4372845364057205} | train loss {'Reaction outcome loss': 0.12669101200487104, 'Total loss': 0.12669101200487104}
2022-12-05 22:11:07,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:07,232 INFO:     Epoch: 76
2022-12-05 22:11:08,028 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4479603757235137, 'Total loss': 0.4479603757235137} | train loss {'Reaction outcome loss': 0.12472859287874834, 'Total loss': 0.12472859287874834}
2022-12-05 22:11:08,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:08,029 INFO:     Epoch: 77
2022-12-05 22:11:08,827 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44497428952970286, 'Total loss': 0.44497428952970286} | train loss {'Reaction outcome loss': 0.1234676645084795, 'Total loss': 0.1234676645084795}
2022-12-05 22:11:08,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:08,828 INFO:     Epoch: 78
2022-12-05 22:11:09,628 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43933303671127016, 'Total loss': 0.43933303671127016} | train loss {'Reaction outcome loss': 0.1263740560614444, 'Total loss': 0.1263740560614444}
2022-12-05 22:11:09,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:09,628 INFO:     Epoch: 79
2022-12-05 22:11:10,424 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4499263827773658, 'Total loss': 0.4499263827773658} | train loss {'Reaction outcome loss': 0.12362631688254976, 'Total loss': 0.12362631688254976}
2022-12-05 22:11:10,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:10,424 INFO:     Epoch: 80
2022-12-05 22:11:11,223 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44366485523906624, 'Total loss': 0.44366485523906624} | train loss {'Reaction outcome loss': 0.12104433676182863, 'Total loss': 0.12104433676182863}
2022-12-05 22:11:11,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:11,223 INFO:     Epoch: 81
2022-12-05 22:11:12,020 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4571571233259006, 'Total loss': 0.4571571233259006} | train loss {'Reaction outcome loss': 0.1214269993398639, 'Total loss': 0.1214269993398639}
2022-12-05 22:11:12,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:12,020 INFO:     Epoch: 82
2022-12-05 22:11:12,825 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46025011214342987, 'Total loss': 0.46025011214342987} | train loss {'Reaction outcome loss': 0.12309217873975754, 'Total loss': 0.12309217873975754}
2022-12-05 22:11:12,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:12,826 INFO:     Epoch: 83
2022-12-05 22:11:13,630 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45520333268425683, 'Total loss': 0.45520333268425683} | train loss {'Reaction outcome loss': 0.12140932792587386, 'Total loss': 0.12140932792587386}
2022-12-05 22:11:13,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:13,630 INFO:     Epoch: 84
2022-12-05 22:11:14,433 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44915832951664925, 'Total loss': 0.44915832951664925} | train loss {'Reaction outcome loss': 0.1193302463657493, 'Total loss': 0.1193302463657493}
2022-12-05 22:11:14,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:14,433 INFO:     Epoch: 85
2022-12-05 22:11:15,236 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4648801284757527, 'Total loss': 0.4648801284757527} | train loss {'Reaction outcome loss': 0.12241514057724646, 'Total loss': 0.12241514057724646}
2022-12-05 22:11:15,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:15,236 INFO:     Epoch: 86
2022-12-05 22:11:16,038 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4553777214817025, 'Total loss': 0.4553777214817025} | train loss {'Reaction outcome loss': 0.12365797917816727, 'Total loss': 0.12365797917816727}
2022-12-05 22:11:16,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:16,038 INFO:     Epoch: 87
2022-12-05 22:11:16,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4495558318766681, 'Total loss': 0.4495558318766681} | train loss {'Reaction outcome loss': 0.11874966937372641, 'Total loss': 0.11874966937372641}
2022-12-05 22:11:16,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:16,842 INFO:     Epoch: 88
2022-12-05 22:11:17,643 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43478359282016754, 'Total loss': 0.43478359282016754} | train loss {'Reaction outcome loss': 0.120818140794478, 'Total loss': 0.120818140794478}
2022-12-05 22:11:17,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:17,644 INFO:     Epoch: 89
2022-12-05 22:11:18,448 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4680049522695216, 'Total loss': 0.4680049522695216} | train loss {'Reaction outcome loss': 0.12438576378589196, 'Total loss': 0.12438576378589196}
2022-12-05 22:11:18,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:18,448 INFO:     Epoch: 90
2022-12-05 22:11:19,249 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4384994422170249, 'Total loss': 0.4384994422170249} | train loss {'Reaction outcome loss': 0.1227061650790875, 'Total loss': 0.1227061650790875}
2022-12-05 22:11:19,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:19,249 INFO:     Epoch: 91
2022-12-05 22:11:20,043 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4541022496467287, 'Total loss': 0.4541022496467287} | train loss {'Reaction outcome loss': 0.12035040178846929, 'Total loss': 0.12035040178846929}
2022-12-05 22:11:20,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:20,044 INFO:     Epoch: 92
2022-12-05 22:11:20,844 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4515092179856517, 'Total loss': 0.4515092179856517} | train loss {'Reaction outcome loss': 0.11993444999003963, 'Total loss': 0.11993444999003963}
2022-12-05 22:11:20,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:20,845 INFO:     Epoch: 93
2022-12-05 22:11:21,642 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45442353358322923, 'Total loss': 0.45442353358322923} | train loss {'Reaction outcome loss': 0.118270858791807, 'Total loss': 0.118270858791807}
2022-12-05 22:11:21,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:21,643 INFO:     Epoch: 94
2022-12-05 22:11:22,443 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4761922254481099, 'Total loss': 0.4761922254481099} | train loss {'Reaction outcome loss': 0.12042451556020926, 'Total loss': 0.12042451556020926}
2022-12-05 22:11:22,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:22,444 INFO:     Epoch: 95
2022-12-05 22:11:23,247 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47061941704966803, 'Total loss': 0.47061941704966803} | train loss {'Reaction outcome loss': 0.11820138030264887, 'Total loss': 0.11820138030264887}
2022-12-05 22:11:23,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:23,248 INFO:     Epoch: 96
2022-12-05 22:11:24,051 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46454980241304095, 'Total loss': 0.46454980241304095} | train loss {'Reaction outcome loss': 0.11996345355686161, 'Total loss': 0.11996345355686161}
2022-12-05 22:11:24,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:24,052 INFO:     Epoch: 97
2022-12-05 22:11:24,851 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4552684653211724, 'Total loss': 0.4552684653211724} | train loss {'Reaction outcome loss': 0.11742004781450716, 'Total loss': 0.11742004781450716}
2022-12-05 22:11:24,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:24,852 INFO:     Epoch: 98
2022-12-05 22:11:25,656 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45858619260517036, 'Total loss': 0.45858619260517036} | train loss {'Reaction outcome loss': 0.1211230321712191, 'Total loss': 0.1211230321712191}
2022-12-05 22:11:25,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:25,656 INFO:     Epoch: 99
2022-12-05 22:11:26,459 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4549393518404527, 'Total loss': 0.4549393518404527} | train loss {'Reaction outcome loss': 0.11941109619463884, 'Total loss': 0.11941109619463884}
2022-12-05 22:11:26,460 INFO:     Best model found after epoch 21 of 100.
2022-12-05 22:11:26,460 INFO:   Done with stage: TRAINING
2022-12-05 22:11:26,460 INFO:   Starting stage: EVALUATION
2022-12-05 22:11:26,580 INFO:   Done with stage: EVALUATION
2022-12-05 22:11:26,580 INFO:   Leaving out SEQ value Fold_8
2022-12-05 22:11:26,592 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:11:26,592 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:11:27,226 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:11:27,226 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:11:27,294 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:11:27,294 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:11:27,294 INFO:     No hyperparam tuning for this model
2022-12-05 22:11:27,294 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:11:27,294 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:11:27,295 INFO:     None feature selector for col prot
2022-12-05 22:11:27,295 INFO:     None feature selector for col prot
2022-12-05 22:11:27,295 INFO:     None feature selector for col prot
2022-12-05 22:11:27,296 INFO:     None feature selector for col chem
2022-12-05 22:11:27,296 INFO:     None feature selector for col chem
2022-12-05 22:11:27,296 INFO:     None feature selector for col chem
2022-12-05 22:11:27,296 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:11:27,296 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:11:27,298 INFO:     Number of params in model 215821
2022-12-05 22:11:27,301 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:11:27,301 INFO:   Starting stage: TRAINING
2022-12-05 22:11:27,362 INFO:     Val loss before train {'Reaction outcome loss': 1.0237357927994295, 'Total loss': 1.0237357927994295}
2022-12-05 22:11:27,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:27,362 INFO:     Epoch: 0
2022-12-05 22:11:28,149 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6280419359152968, 'Total loss': 0.6280419359152968} | train loss {'Reaction outcome loss': 0.8113276210366464, 'Total loss': 0.8113276210366464}
2022-12-05 22:11:28,149 INFO:     Found new best model at epoch 0
2022-12-05 22:11:28,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:28,150 INFO:     Epoch: 1
2022-12-05 22:11:28,938 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5231748592447151, 'Total loss': 0.5231748592447151} | train loss {'Reaction outcome loss': 0.542167849686681, 'Total loss': 0.542167849686681}
2022-12-05 22:11:28,938 INFO:     Found new best model at epoch 1
2022-12-05 22:11:28,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:28,939 INFO:     Epoch: 2
2022-12-05 22:11:29,730 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4847019931132143, 'Total loss': 0.4847019931132143} | train loss {'Reaction outcome loss': 0.47051661008474777, 'Total loss': 0.47051661008474777}
2022-12-05 22:11:29,730 INFO:     Found new best model at epoch 2
2022-12-05 22:11:29,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:29,731 INFO:     Epoch: 3
2022-12-05 22:11:30,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4682774269445376, 'Total loss': 0.4682774269445376} | train loss {'Reaction outcome loss': 0.42922339424186823, 'Total loss': 0.42922339424186823}
2022-12-05 22:11:30,524 INFO:     Found new best model at epoch 3
2022-12-05 22:11:30,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:30,525 INFO:     Epoch: 4
2022-12-05 22:11:31,313 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44423319128426636, 'Total loss': 0.44423319128426636} | train loss {'Reaction outcome loss': 0.40061178627062816, 'Total loss': 0.40061178627062816}
2022-12-05 22:11:31,313 INFO:     Found new best model at epoch 4
2022-12-05 22:11:31,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:31,314 INFO:     Epoch: 5
2022-12-05 22:11:32,103 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4358412598852407, 'Total loss': 0.4358412598852407} | train loss {'Reaction outcome loss': 0.3780083312367906, 'Total loss': 0.3780083312367906}
2022-12-05 22:11:32,103 INFO:     Found new best model at epoch 5
2022-12-05 22:11:32,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:32,104 INFO:     Epoch: 6
2022-12-05 22:11:32,894 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43229440633546223, 'Total loss': 0.43229440633546223} | train loss {'Reaction outcome loss': 0.35980600444029787, 'Total loss': 0.35980600444029787}
2022-12-05 22:11:32,894 INFO:     Found new best model at epoch 6
2022-12-05 22:11:32,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:32,895 INFO:     Epoch: 7
2022-12-05 22:11:33,688 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4298002411696044, 'Total loss': 0.4298002411696044} | train loss {'Reaction outcome loss': 0.3418059489556721, 'Total loss': 0.3418059489556721}
2022-12-05 22:11:33,688 INFO:     Found new best model at epoch 7
2022-12-05 22:11:33,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:33,689 INFO:     Epoch: 8
2022-12-05 22:11:34,482 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4222706989808516, 'Total loss': 0.4222706989808516} | train loss {'Reaction outcome loss': 0.32849202451049064, 'Total loss': 0.32849202451049064}
2022-12-05 22:11:34,482 INFO:     Found new best model at epoch 8
2022-12-05 22:11:34,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:34,483 INFO:     Epoch: 9
2022-12-05 22:11:35,272 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41378931735049596, 'Total loss': 0.41378931735049596} | train loss {'Reaction outcome loss': 0.31373677448350556, 'Total loss': 0.31373677448350556}
2022-12-05 22:11:35,272 INFO:     Found new best model at epoch 9
2022-12-05 22:11:35,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:35,273 INFO:     Epoch: 10
2022-12-05 22:11:36,062 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42387266660278494, 'Total loss': 0.42387266660278494} | train loss {'Reaction outcome loss': 0.30251238817463116, 'Total loss': 0.30251238817463116}
2022-12-05 22:11:36,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:36,062 INFO:     Epoch: 11
2022-12-05 22:11:36,855 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4128603965721347, 'Total loss': 0.4128603965721347} | train loss {'Reaction outcome loss': 0.291231316632154, 'Total loss': 0.291231316632154}
2022-12-05 22:11:36,855 INFO:     Found new best model at epoch 11
2022-12-05 22:11:36,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:36,856 INFO:     Epoch: 12
2022-12-05 22:11:37,644 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4123783917589621, 'Total loss': 0.4123783917589621} | train loss {'Reaction outcome loss': 0.2779238812777461, 'Total loss': 0.2779238812777461}
2022-12-05 22:11:37,644 INFO:     Found new best model at epoch 12
2022-12-05 22:11:37,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:37,645 INFO:     Epoch: 13
2022-12-05 22:11:38,440 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4152669534087181, 'Total loss': 0.4152669534087181} | train loss {'Reaction outcome loss': 0.2706936357580886, 'Total loss': 0.2706936357580886}
2022-12-05 22:11:38,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:38,440 INFO:     Epoch: 14
2022-12-05 22:11:39,234 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4344156167723916, 'Total loss': 0.4344156167723916} | train loss {'Reaction outcome loss': 0.26053788262058275, 'Total loss': 0.26053788262058275}
2022-12-05 22:11:39,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:39,235 INFO:     Epoch: 15
2022-12-05 22:11:40,027 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41329373961145227, 'Total loss': 0.41329373961145227} | train loss {'Reaction outcome loss': 0.2546112159077002, 'Total loss': 0.2546112159077002}
2022-12-05 22:11:40,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:40,027 INFO:     Epoch: 16
2022-12-05 22:11:40,818 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43059372021393344, 'Total loss': 0.43059372021393344} | train loss {'Reaction outcome loss': 0.2467593429344041, 'Total loss': 0.2467593429344041}
2022-12-05 22:11:40,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:40,818 INFO:     Epoch: 17
2022-12-05 22:11:41,608 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4022022946314378, 'Total loss': 0.4022022946314378} | train loss {'Reaction outcome loss': 0.23919225053823723, 'Total loss': 0.23919225053823723}
2022-12-05 22:11:41,608 INFO:     Found new best model at epoch 17
2022-12-05 22:11:41,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:41,609 INFO:     Epoch: 18
2022-12-05 22:11:42,397 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4198668473823504, 'Total loss': 0.4198668473823504} | train loss {'Reaction outcome loss': 0.23407956614178055, 'Total loss': 0.23407956614178055}
2022-12-05 22:11:42,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:42,397 INFO:     Epoch: 19
2022-12-05 22:11:43,185 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41153691201047465, 'Total loss': 0.41153691201047465} | train loss {'Reaction outcome loss': 0.22941507122346333, 'Total loss': 0.22941507122346333}
2022-12-05 22:11:43,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:43,185 INFO:     Epoch: 20
2022-12-05 22:11:43,974 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4162944042420184, 'Total loss': 0.4162944042420184} | train loss {'Reaction outcome loss': 0.2234257860755434, 'Total loss': 0.2234257860755434}
2022-12-05 22:11:43,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:43,974 INFO:     Epoch: 21
2022-12-05 22:11:44,765 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4112672849812291, 'Total loss': 0.4112672849812291} | train loss {'Reaction outcome loss': 0.22023141435822663, 'Total loss': 0.22023141435822663}
2022-12-05 22:11:44,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:44,765 INFO:     Epoch: 22
2022-12-05 22:11:45,558 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42095170948993077, 'Total loss': 0.42095170948993077} | train loss {'Reaction outcome loss': 0.21530544953990954, 'Total loss': 0.21530544953990954}
2022-12-05 22:11:45,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:45,558 INFO:     Epoch: 23
2022-12-05 22:11:46,347 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.436995922841809, 'Total loss': 0.436995922841809} | train loss {'Reaction outcome loss': 0.2109090539265652, 'Total loss': 0.2109090539265652}
2022-12-05 22:11:46,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:46,347 INFO:     Epoch: 24
2022-12-05 22:11:47,136 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42604213089428167, 'Total loss': 0.42604213089428167} | train loss {'Reaction outcome loss': 0.2028116664107965, 'Total loss': 0.2028116664107965}
2022-12-05 22:11:47,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:47,136 INFO:     Epoch: 25
2022-12-05 22:11:47,924 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43339243734424765, 'Total loss': 0.43339243734424765} | train loss {'Reaction outcome loss': 0.20026763549112545, 'Total loss': 0.20026763549112545}
2022-12-05 22:11:47,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:47,924 INFO:     Epoch: 26
2022-12-05 22:11:48,713 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4425567561252551, 'Total loss': 0.4425567561252551} | train loss {'Reaction outcome loss': 0.1981027471243727, 'Total loss': 0.1981027471243727}
2022-12-05 22:11:48,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:48,713 INFO:     Epoch: 27
2022-12-05 22:11:49,500 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4101038918729914, 'Total loss': 0.4101038918729914} | train loss {'Reaction outcome loss': 0.19634591564536094, 'Total loss': 0.19634591564536094}
2022-12-05 22:11:49,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:49,500 INFO:     Epoch: 28
2022-12-05 22:11:50,291 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43607242100618104, 'Total loss': 0.43607242100618104} | train loss {'Reaction outcome loss': 0.19126643796964568, 'Total loss': 0.19126643796964568}
2022-12-05 22:11:50,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:50,291 INFO:     Epoch: 29
2022-12-05 22:11:51,084 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4235410371964628, 'Total loss': 0.4235410371964628} | train loss {'Reaction outcome loss': 0.1887519183359584, 'Total loss': 0.1887519183359584}
2022-12-05 22:11:51,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:51,085 INFO:     Epoch: 30
2022-12-05 22:11:51,874 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4242717295207761, 'Total loss': 0.4242717295207761} | train loss {'Reaction outcome loss': 0.18906105939222842, 'Total loss': 0.18906105939222842}
2022-12-05 22:11:51,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:51,874 INFO:     Epoch: 31
2022-12-05 22:11:52,663 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4365763433954932, 'Total loss': 0.4365763433954932} | train loss {'Reaction outcome loss': 0.18255550513918303, 'Total loss': 0.18255550513918303}
2022-12-05 22:11:52,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:52,664 INFO:     Epoch: 32
2022-12-05 22:11:53,455 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4241447875445539, 'Total loss': 0.4241447875445539} | train loss {'Reaction outcome loss': 0.1810867934810872, 'Total loss': 0.1810867934810872}
2022-12-05 22:11:53,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:53,456 INFO:     Epoch: 33
2022-12-05 22:11:54,252 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41958204013380135, 'Total loss': 0.41958204013380135} | train loss {'Reaction outcome loss': 0.18164076914212535, 'Total loss': 0.18164076914212535}
2022-12-05 22:11:54,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:54,252 INFO:     Epoch: 34
2022-12-05 22:11:55,044 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43106261031194165, 'Total loss': 0.43106261031194165} | train loss {'Reaction outcome loss': 0.17598629781634223, 'Total loss': 0.17598629781634223}
2022-12-05 22:11:55,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:55,044 INFO:     Epoch: 35
2022-12-05 22:11:55,837 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4431451345709237, 'Total loss': 0.4431451345709237} | train loss {'Reaction outcome loss': 0.17310155969189137, 'Total loss': 0.17310155969189137}
2022-12-05 22:11:55,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:55,838 INFO:     Epoch: 36
2022-12-05 22:11:56,633 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4328351000493223, 'Total loss': 0.4328351000493223} | train loss {'Reaction outcome loss': 0.17314339702834888, 'Total loss': 0.17314339702834888}
2022-12-05 22:11:56,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:56,633 INFO:     Epoch: 37
2022-12-05 22:11:57,425 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44857509298758075, 'Total loss': 0.44857509298758075} | train loss {'Reaction outcome loss': 0.1694009193200238, 'Total loss': 0.1694009193200238}
2022-12-05 22:11:57,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:57,426 INFO:     Epoch: 38
2022-12-05 22:11:58,217 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4299117292870175, 'Total loss': 0.4299117292870175} | train loss {'Reaction outcome loss': 0.16990936734542555, 'Total loss': 0.16990936734542555}
2022-12-05 22:11:58,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:58,218 INFO:     Epoch: 39
2022-12-05 22:11:59,014 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4451176713813435, 'Total loss': 0.4451176713813435} | train loss {'Reaction outcome loss': 0.16680950783953374, 'Total loss': 0.16680950783953374}
2022-12-05 22:11:59,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:59,014 INFO:     Epoch: 40
2022-12-05 22:11:59,812 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45105655906213954, 'Total loss': 0.45105655906213954} | train loss {'Reaction outcome loss': 0.16429770325063442, 'Total loss': 0.16429770325063442}
2022-12-05 22:11:59,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:11:59,813 INFO:     Epoch: 41
2022-12-05 22:12:00,605 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4296088293194771, 'Total loss': 0.4296088293194771} | train loss {'Reaction outcome loss': 0.16455450255651863, 'Total loss': 0.16455450255651863}
2022-12-05 22:12:00,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:00,605 INFO:     Epoch: 42
2022-12-05 22:12:01,394 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4318863343108784, 'Total loss': 0.4318863343108784} | train loss {'Reaction outcome loss': 0.16270993933537786, 'Total loss': 0.16270993933537786}
2022-12-05 22:12:01,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:01,395 INFO:     Epoch: 43
2022-12-05 22:12:02,188 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4311373220248656, 'Total loss': 0.4311373220248656} | train loss {'Reaction outcome loss': 0.16054579011943876, 'Total loss': 0.16054579011943876}
2022-12-05 22:12:02,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:02,188 INFO:     Epoch: 44
2022-12-05 22:12:02,982 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4228103458881378, 'Total loss': 0.4228103458881378} | train loss {'Reaction outcome loss': 0.16048489738331764, 'Total loss': 0.16048489738331764}
2022-12-05 22:12:02,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:02,982 INFO:     Epoch: 45
2022-12-05 22:12:03,771 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44651546667922626, 'Total loss': 0.44651546667922626} | train loss {'Reaction outcome loss': 0.1593042606449857, 'Total loss': 0.1593042606449857}
2022-12-05 22:12:03,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:03,771 INFO:     Epoch: 46
2022-12-05 22:12:04,563 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43215561082417314, 'Total loss': 0.43215561082417314} | train loss {'Reaction outcome loss': 0.15423664822414213, 'Total loss': 0.15423664822414213}
2022-12-05 22:12:04,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:04,564 INFO:     Epoch: 47
2022-12-05 22:12:05,355 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4346078742634166, 'Total loss': 0.4346078742634166} | train loss {'Reaction outcome loss': 0.1564694952979988, 'Total loss': 0.1564694952979988}
2022-12-05 22:12:05,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:05,355 INFO:     Epoch: 48
2022-12-05 22:12:06,143 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.438362390818921, 'Total loss': 0.438362390818921} | train loss {'Reaction outcome loss': 0.1573821521383159, 'Total loss': 0.1573821521383159}
2022-12-05 22:12:06,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:06,143 INFO:     Epoch: 49
2022-12-05 22:12:06,938 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43441677798347716, 'Total loss': 0.43441677798347716} | train loss {'Reaction outcome loss': 0.15596570434923074, 'Total loss': 0.15596570434923074}
2022-12-05 22:12:06,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:06,939 INFO:     Epoch: 50
2022-12-05 22:12:07,732 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.422353068027984, 'Total loss': 0.422353068027984} | train loss {'Reaction outcome loss': 0.15170568053667643, 'Total loss': 0.15170568053667643}
2022-12-05 22:12:07,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:07,732 INFO:     Epoch: 51
2022-12-05 22:12:08,532 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43840358744968067, 'Total loss': 0.43840358744968067} | train loss {'Reaction outcome loss': 0.15071918413195076, 'Total loss': 0.15071918413195076}
2022-12-05 22:12:08,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:08,532 INFO:     Epoch: 52
2022-12-05 22:12:09,324 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42875130813230167, 'Total loss': 0.42875130813230167} | train loss {'Reaction outcome loss': 0.1508281078113585, 'Total loss': 0.1508281078113585}
2022-12-05 22:12:09,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:09,324 INFO:     Epoch: 53
2022-12-05 22:12:10,125 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45549804310907016, 'Total loss': 0.45549804310907016} | train loss {'Reaction outcome loss': 0.1481299788938189, 'Total loss': 0.1481299788938189}
2022-12-05 22:12:10,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:10,126 INFO:     Epoch: 54
2022-12-05 22:12:10,926 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44313129206950014, 'Total loss': 0.44313129206950014} | train loss {'Reaction outcome loss': 0.15083095007861147, 'Total loss': 0.15083095007861147}
2022-12-05 22:12:10,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:10,927 INFO:     Epoch: 55
2022-12-05 22:12:11,726 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4719927676699378, 'Total loss': 0.4719927676699378} | train loss {'Reaction outcome loss': 0.1471271266210444, 'Total loss': 0.1471271266210444}
2022-12-05 22:12:11,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:11,727 INFO:     Epoch: 56
2022-12-05 22:12:12,527 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4714718566022136, 'Total loss': 0.4714718566022136} | train loss {'Reaction outcome loss': 0.14547468631395272, 'Total loss': 0.14547468631395272}
2022-12-05 22:12:12,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:12,527 INFO:     Epoch: 57
2022-12-05 22:12:13,327 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4454686225137927, 'Total loss': 0.4454686225137927} | train loss {'Reaction outcome loss': 0.14666402608308257, 'Total loss': 0.14666402608308257}
2022-12-05 22:12:13,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:13,327 INFO:     Epoch: 58
2022-12-05 22:12:14,117 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4437724776904691, 'Total loss': 0.4437724776904691} | train loss {'Reaction outcome loss': 0.14164289775475555, 'Total loss': 0.14164289775475555}
2022-12-05 22:12:14,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:14,117 INFO:     Epoch: 59
2022-12-05 22:12:14,911 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4384220120581714, 'Total loss': 0.4384220120581714} | train loss {'Reaction outcome loss': 0.14423093079608315, 'Total loss': 0.14423093079608315}
2022-12-05 22:12:14,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:14,911 INFO:     Epoch: 60
2022-12-05 22:12:15,700 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4482109990309585, 'Total loss': 0.4482109990309585} | train loss {'Reaction outcome loss': 0.14386685119599713, 'Total loss': 0.14386685119599713}
2022-12-05 22:12:15,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:15,700 INFO:     Epoch: 61
2022-12-05 22:12:16,486 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43928536281666974, 'Total loss': 0.43928536281666974} | train loss {'Reaction outcome loss': 0.1430541556328535, 'Total loss': 0.1430541556328535}
2022-12-05 22:12:16,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:16,486 INFO:     Epoch: 62
2022-12-05 22:12:17,269 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43323473005809565, 'Total loss': 0.43323473005809565} | train loss {'Reaction outcome loss': 0.1431793379084188, 'Total loss': 0.1431793379084188}
2022-12-05 22:12:17,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:17,269 INFO:     Epoch: 63
2022-12-05 22:12:18,055 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46685566168955783, 'Total loss': 0.46685566168955783} | train loss {'Reaction outcome loss': 0.14027608615555326, 'Total loss': 0.14027608615555326}
2022-12-05 22:12:18,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:18,055 INFO:     Epoch: 64
2022-12-05 22:12:18,837 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44935448687862267, 'Total loss': 0.44935448687862267} | train loss {'Reaction outcome loss': 0.1403983634003267, 'Total loss': 0.1403983634003267}
2022-12-05 22:12:18,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:18,837 INFO:     Epoch: 65
2022-12-05 22:12:19,617 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43570842932571063, 'Total loss': 0.43570842932571063} | train loss {'Reaction outcome loss': 0.13830798066468264, 'Total loss': 0.13830798066468264}
2022-12-05 22:12:19,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:19,617 INFO:     Epoch: 66
2022-12-05 22:12:20,396 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46088838746601885, 'Total loss': 0.46088838746601885} | train loss {'Reaction outcome loss': 0.13885907809040984, 'Total loss': 0.13885907809040984}
2022-12-05 22:12:20,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:20,396 INFO:     Epoch: 67
2022-12-05 22:12:21,182 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4478872299871661, 'Total loss': 0.4478872299871661} | train loss {'Reaction outcome loss': 0.14003627913794955, 'Total loss': 0.14003627913794955}
2022-12-05 22:12:21,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:21,182 INFO:     Epoch: 68
2022-12-05 22:12:21,962 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43906317702071235, 'Total loss': 0.43906317702071235} | train loss {'Reaction outcome loss': 0.13770085946485705, 'Total loss': 0.13770085946485705}
2022-12-05 22:12:21,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:21,963 INFO:     Epoch: 69
2022-12-05 22:12:22,746 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44205094840038905, 'Total loss': 0.44205094840038905} | train loss {'Reaction outcome loss': 0.13511375150054086, 'Total loss': 0.13511375150054086}
2022-12-05 22:12:22,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:22,746 INFO:     Epoch: 70
2022-12-05 22:12:23,529 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44817821647633205, 'Total loss': 0.44817821647633205} | train loss {'Reaction outcome loss': 0.13822752325890625, 'Total loss': 0.13822752325890625}
2022-12-05 22:12:23,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:23,529 INFO:     Epoch: 71
2022-12-05 22:12:24,316 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.44458346983248537, 'Total loss': 0.44458346983248537} | train loss {'Reaction outcome loss': 0.13388344721526516, 'Total loss': 0.13388344721526516}
2022-12-05 22:12:24,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:24,316 INFO:     Epoch: 72
2022-12-05 22:12:25,104 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4543932653243907, 'Total loss': 0.4543932653243907} | train loss {'Reaction outcome loss': 0.13611812089778938, 'Total loss': 0.13611812089778938}
2022-12-05 22:12:25,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:25,105 INFO:     Epoch: 73
2022-12-05 22:12:25,897 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45801487971435895, 'Total loss': 0.45801487971435895} | train loss {'Reaction outcome loss': 0.1326324437307764, 'Total loss': 0.1326324437307764}
2022-12-05 22:12:25,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:25,897 INFO:     Epoch: 74
2022-12-05 22:12:26,687 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44672192565419455, 'Total loss': 0.44672192565419455} | train loss {'Reaction outcome loss': 0.13395170776591617, 'Total loss': 0.13395170776591617}
2022-12-05 22:12:26,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:26,687 INFO:     Epoch: 75
2022-12-05 22:12:27,473 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43609021773392503, 'Total loss': 0.43609021773392503} | train loss {'Reaction outcome loss': 0.13209922084470793, 'Total loss': 0.13209922084470793}
2022-12-05 22:12:27,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:27,473 INFO:     Epoch: 76
2022-12-05 22:12:28,256 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43446780842813576, 'Total loss': 0.43446780842813576} | train loss {'Reaction outcome loss': 0.13363016429072133, 'Total loss': 0.13363016429072133}
2022-12-05 22:12:28,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:28,257 INFO:     Epoch: 77
2022-12-05 22:12:29,037 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4495475149967454, 'Total loss': 0.4495475149967454} | train loss {'Reaction outcome loss': 0.1316452247451763, 'Total loss': 0.1316452247451763}
2022-12-05 22:12:29,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:29,037 INFO:     Epoch: 78
2022-12-05 22:12:29,824 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44729758494279603, 'Total loss': 0.44729758494279603} | train loss {'Reaction outcome loss': 0.1321884421669707, 'Total loss': 0.1321884421669707}
2022-12-05 22:12:29,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:29,824 INFO:     Epoch: 79
2022-12-05 22:12:30,604 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45058206451887434, 'Total loss': 0.45058206451887434} | train loss {'Reaction outcome loss': 0.13269029436062793, 'Total loss': 0.13269029436062793}
2022-12-05 22:12:30,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:30,604 INFO:     Epoch: 80
2022-12-05 22:12:31,391 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4463349094783718, 'Total loss': 0.4463349094783718} | train loss {'Reaction outcome loss': 0.1274617980367371, 'Total loss': 0.1274617980367371}
2022-12-05 22:12:31,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:31,392 INFO:     Epoch: 81
2022-12-05 22:12:32,174 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4500566443259066, 'Total loss': 0.4500566443259066} | train loss {'Reaction outcome loss': 0.1313207634933749, 'Total loss': 0.1313207634933749}
2022-12-05 22:12:32,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:32,174 INFO:     Epoch: 82
2022-12-05 22:12:32,954 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46096114204688504, 'Total loss': 0.46096114204688504} | train loss {'Reaction outcome loss': 0.1306790923585697, 'Total loss': 0.1306790923585697}
2022-12-05 22:12:32,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:32,954 INFO:     Epoch: 83
2022-12-05 22:12:33,738 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4530808918855407, 'Total loss': 0.4530808918855407} | train loss {'Reaction outcome loss': 0.13102022938962493, 'Total loss': 0.13102022938962493}
2022-12-05 22:12:33,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:33,739 INFO:     Epoch: 84
2022-12-05 22:12:34,528 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45068859376690606, 'Total loss': 0.45068859376690606} | train loss {'Reaction outcome loss': 0.1308415098153815, 'Total loss': 0.1308415098153815}
2022-12-05 22:12:34,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:34,529 INFO:     Epoch: 85
2022-12-05 22:12:35,310 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4448917894200845, 'Total loss': 0.4448917894200845} | train loss {'Reaction outcome loss': 0.12591157804566377, 'Total loss': 0.12591157804566377}
2022-12-05 22:12:35,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:35,311 INFO:     Epoch: 86
2022-12-05 22:12:36,102 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4632045672359792, 'Total loss': 0.4632045672359792} | train loss {'Reaction outcome loss': 0.13051653904270152, 'Total loss': 0.13051653904270152}
2022-12-05 22:12:36,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:36,103 INFO:     Epoch: 87
2022-12-05 22:12:36,899 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4314170644025911, 'Total loss': 0.4314170644025911} | train loss {'Reaction outcome loss': 0.12799466206331034, 'Total loss': 0.12799466206331034}
2022-12-05 22:12:36,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:36,900 INFO:     Epoch: 88
2022-12-05 22:12:37,692 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45091192153367127, 'Total loss': 0.45091192153367127} | train loss {'Reaction outcome loss': 0.1278744724370083, 'Total loss': 0.1278744724370083}
2022-12-05 22:12:37,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:37,692 INFO:     Epoch: 89
2022-12-05 22:12:38,482 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44790943881327455, 'Total loss': 0.44790943881327455} | train loss {'Reaction outcome loss': 0.12546874676279876, 'Total loss': 0.12546874676279876}
2022-12-05 22:12:38,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:38,482 INFO:     Epoch: 90
2022-12-05 22:12:39,274 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4411987902765924, 'Total loss': 0.4411987902765924} | train loss {'Reaction outcome loss': 0.1279460837266275, 'Total loss': 0.1279460837266275}
2022-12-05 22:12:39,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:39,274 INFO:     Epoch: 91
2022-12-05 22:12:40,070 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.45549560473723844, 'Total loss': 0.45549560473723844} | train loss {'Reaction outcome loss': 0.1274873405809001, 'Total loss': 0.1274873405809001}
2022-12-05 22:12:40,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:40,070 INFO:     Epoch: 92
2022-12-05 22:12:40,862 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4516080343587832, 'Total loss': 0.4516080343587832} | train loss {'Reaction outcome loss': 0.1261897082041417, 'Total loss': 0.1261897082041417}
2022-12-05 22:12:40,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:40,862 INFO:     Epoch: 93
2022-12-05 22:12:41,659 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4557233546352522, 'Total loss': 0.4557233546352522} | train loss {'Reaction outcome loss': 0.1276954184115237, 'Total loss': 0.1276954184115237}
2022-12-05 22:12:41,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:41,660 INFO:     Epoch: 94
2022-12-05 22:12:42,458 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44692252136089583, 'Total loss': 0.44692252136089583} | train loss {'Reaction outcome loss': 0.12461539390972075, 'Total loss': 0.12461539390972075}
2022-12-05 22:12:42,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:42,459 INFO:     Epoch: 95
2022-12-05 22:12:43,248 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45429168336770753, 'Total loss': 0.45429168336770753} | train loss {'Reaction outcome loss': 0.12877356411166946, 'Total loss': 0.12877356411166946}
2022-12-05 22:12:43,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:43,248 INFO:     Epoch: 96
2022-12-05 22:12:44,038 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45179896463047375, 'Total loss': 0.45179896463047375} | train loss {'Reaction outcome loss': 0.12415878431377363, 'Total loss': 0.12415878431377363}
2022-12-05 22:12:44,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:44,038 INFO:     Epoch: 97
2022-12-05 22:12:44,832 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4462510439651934, 'Total loss': 0.4462510439651934} | train loss {'Reaction outcome loss': 0.1268192473114753, 'Total loss': 0.1268192473114753}
2022-12-05 22:12:44,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:44,832 INFO:     Epoch: 98
2022-12-05 22:12:45,624 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4454519328745929, 'Total loss': 0.4454519328745929} | train loss {'Reaction outcome loss': 0.12443006995077036, 'Total loss': 0.12443006995077036}
2022-12-05 22:12:45,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:45,625 INFO:     Epoch: 99
2022-12-05 22:12:46,418 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4529302804307504, 'Total loss': 0.4529302804307504} | train loss {'Reaction outcome loss': 0.12391124579067132, 'Total loss': 0.12391124579067132}
2022-12-05 22:12:46,418 INFO:     Best model found after epoch 18 of 100.
2022-12-05 22:12:46,418 INFO:   Done with stage: TRAINING
2022-12-05 22:12:46,418 INFO:   Starting stage: EVALUATION
2022-12-05 22:12:46,550 INFO:   Done with stage: EVALUATION
2022-12-05 22:12:46,550 INFO:   Leaving out SEQ value Fold_9
2022-12-05 22:12:46,563 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:12:46,563 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:12:47,213 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:12:47,213 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:12:47,284 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:12:47,284 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:12:47,284 INFO:     No hyperparam tuning for this model
2022-12-05 22:12:47,284 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:12:47,284 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:12:47,285 INFO:     None feature selector for col prot
2022-12-05 22:12:47,285 INFO:     None feature selector for col prot
2022-12-05 22:12:47,285 INFO:     None feature selector for col prot
2022-12-05 22:12:47,285 INFO:     None feature selector for col chem
2022-12-05 22:12:47,286 INFO:     None feature selector for col chem
2022-12-05 22:12:47,286 INFO:     None feature selector for col chem
2022-12-05 22:12:47,286 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:12:47,286 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:12:47,287 INFO:     Number of params in model 215821
2022-12-05 22:12:47,291 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:12:47,291 INFO:   Starting stage: TRAINING
2022-12-05 22:12:47,353 INFO:     Val loss before train {'Reaction outcome loss': 1.0144570822065526, 'Total loss': 1.0144570822065526}
2022-12-05 22:12:47,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:47,353 INFO:     Epoch: 0
2022-12-05 22:12:48,158 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6401896767995574, 'Total loss': 0.6401896767995574} | train loss {'Reaction outcome loss': 0.7704533089992971, 'Total loss': 0.7704533089992971}
2022-12-05 22:12:48,158 INFO:     Found new best model at epoch 0
2022-12-05 22:12:48,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:48,159 INFO:     Epoch: 1
2022-12-05 22:12:48,960 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5507571053775874, 'Total loss': 0.5507571053775874} | train loss {'Reaction outcome loss': 0.5210857344301123, 'Total loss': 0.5210857344301123}
2022-12-05 22:12:48,960 INFO:     Found new best model at epoch 1
2022-12-05 22:12:48,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:48,961 INFO:     Epoch: 2
2022-12-05 22:12:49,767 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5065436112609777, 'Total loss': 0.5065436112609777} | train loss {'Reaction outcome loss': 0.4604666908139642, 'Total loss': 0.4604666908139642}
2022-12-05 22:12:49,767 INFO:     Found new best model at epoch 2
2022-12-05 22:12:49,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:49,768 INFO:     Epoch: 3
2022-12-05 22:12:50,573 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4825758810409091, 'Total loss': 0.4825758810409091} | train loss {'Reaction outcome loss': 0.4254593683881798, 'Total loss': 0.4254593683881798}
2022-12-05 22:12:50,573 INFO:     Found new best model at epoch 3
2022-12-05 22:12:50,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:50,574 INFO:     Epoch: 4
2022-12-05 22:12:51,379 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48159269378943875, 'Total loss': 0.48159269378943875} | train loss {'Reaction outcome loss': 0.39214678124057106, 'Total loss': 0.39214678124057106}
2022-12-05 22:12:51,380 INFO:     Found new best model at epoch 4
2022-12-05 22:12:51,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:51,380 INFO:     Epoch: 5
2022-12-05 22:12:52,181 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46664944799108937, 'Total loss': 0.46664944799108937} | train loss {'Reaction outcome loss': 0.37194501888006926, 'Total loss': 0.37194501888006926}
2022-12-05 22:12:52,181 INFO:     Found new best model at epoch 5
2022-12-05 22:12:52,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:52,182 INFO:     Epoch: 6
2022-12-05 22:12:52,981 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4726947457952933, 'Total loss': 0.4726947457952933} | train loss {'Reaction outcome loss': 0.3531280647405246, 'Total loss': 0.3531280647405246}
2022-12-05 22:12:52,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:52,983 INFO:     Epoch: 7
2022-12-05 22:12:53,782 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4687029082666744, 'Total loss': 0.4687029082666744} | train loss {'Reaction outcome loss': 0.3381496298349338, 'Total loss': 0.3381496298349338}
2022-12-05 22:12:53,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:53,782 INFO:     Epoch: 8
2022-12-05 22:12:54,584 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45729193463921547, 'Total loss': 0.45729193463921547} | train loss {'Reaction outcome loss': 0.32266445747512557, 'Total loss': 0.32266445747512557}
2022-12-05 22:12:54,585 INFO:     Found new best model at epoch 8
2022-12-05 22:12:54,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:54,585 INFO:     Epoch: 9
2022-12-05 22:12:55,387 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4627828218720176, 'Total loss': 0.4627828218720176} | train loss {'Reaction outcome loss': 0.30957749463346323, 'Total loss': 0.30957749463346323}
2022-12-05 22:12:55,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:55,387 INFO:     Epoch: 10
2022-12-05 22:12:56,188 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46073613823814824, 'Total loss': 0.46073613823814824} | train loss {'Reaction outcome loss': 0.29746061000927737, 'Total loss': 0.29746061000927737}
2022-12-05 22:12:56,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:56,188 INFO:     Epoch: 11
2022-12-05 22:12:56,986 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4619045745242726, 'Total loss': 0.4619045745242726} | train loss {'Reaction outcome loss': 0.2886676943402828, 'Total loss': 0.2886676943402828}
2022-12-05 22:12:56,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:56,986 INFO:     Epoch: 12
2022-12-05 22:12:57,782 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.460054355927489, 'Total loss': 0.460054355927489} | train loss {'Reaction outcome loss': 0.27677397743651744, 'Total loss': 0.27677397743651744}
2022-12-05 22:12:57,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:57,782 INFO:     Epoch: 13
2022-12-05 22:12:58,581 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4656844941729849, 'Total loss': 0.4656844941729849} | train loss {'Reaction outcome loss': 0.26520010559001433, 'Total loss': 0.26520010559001433}
2022-12-05 22:12:58,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:58,581 INFO:     Epoch: 14
2022-12-05 22:12:59,378 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4642687378959222, 'Total loss': 0.4642687378959222} | train loss {'Reaction outcome loss': 0.25869863220916584, 'Total loss': 0.25869863220916584}
2022-12-05 22:12:59,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:12:59,379 INFO:     Epoch: 15
2022-12-05 22:13:00,178 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4662392579696395, 'Total loss': 0.4662392579696395} | train loss {'Reaction outcome loss': 0.25090765358827377, 'Total loss': 0.25090765358827377}
2022-12-05 22:13:00,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:00,178 INFO:     Epoch: 16
2022-12-05 22:13:00,980 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45429867082698777, 'Total loss': 0.45429867082698777} | train loss {'Reaction outcome loss': 0.24478913329330534, 'Total loss': 0.24478913329330534}
2022-12-05 22:13:00,981 INFO:     Found new best model at epoch 16
2022-12-05 22:13:00,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:00,981 INFO:     Epoch: 17
2022-12-05 22:13:01,780 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46547711301933636, 'Total loss': 0.46547711301933636} | train loss {'Reaction outcome loss': 0.2347687312825074, 'Total loss': 0.2347687312825074}
2022-12-05 22:13:01,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:01,780 INFO:     Epoch: 18
2022-12-05 22:13:02,580 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45848371562632645, 'Total loss': 0.45848371562632645} | train loss {'Reaction outcome loss': 0.22622336915916638, 'Total loss': 0.22622336915916638}
2022-12-05 22:13:02,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:02,580 INFO:     Epoch: 19
2022-12-05 22:13:03,383 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4695957028730349, 'Total loss': 0.4695957028730349} | train loss {'Reaction outcome loss': 0.22261954892260827, 'Total loss': 0.22261954892260827}
2022-12-05 22:13:03,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:03,383 INFO:     Epoch: 20
2022-12-05 22:13:04,180 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47903147813948715, 'Total loss': 0.47903147813948715} | train loss {'Reaction outcome loss': 0.21886498351328768, 'Total loss': 0.21886498351328768}
2022-12-05 22:13:04,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:04,181 INFO:     Epoch: 21
2022-12-05 22:13:04,978 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4757633649490096, 'Total loss': 0.4757633649490096} | train loss {'Reaction outcome loss': 0.21531382075846497, 'Total loss': 0.21531382075846497}
2022-12-05 22:13:04,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:04,978 INFO:     Epoch: 22
2022-12-05 22:13:05,776 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4708061164075678, 'Total loss': 0.4708061164075678} | train loss {'Reaction outcome loss': 0.209189543432673, 'Total loss': 0.209189543432673}
2022-12-05 22:13:05,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:05,776 INFO:     Epoch: 23
2022-12-05 22:13:06,576 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47627632142129267, 'Total loss': 0.47627632142129267} | train loss {'Reaction outcome loss': 0.20405312028792705, 'Total loss': 0.20405312028792705}
2022-12-05 22:13:06,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:06,577 INFO:     Epoch: 24
2022-12-05 22:13:07,373 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4618542861532081, 'Total loss': 0.4618542861532081} | train loss {'Reaction outcome loss': 0.20135163399673667, 'Total loss': 0.20135163399673667}
2022-12-05 22:13:07,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:07,373 INFO:     Epoch: 25
2022-12-05 22:13:08,169 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4730523760345849, 'Total loss': 0.4730523760345849} | train loss {'Reaction outcome loss': 0.19747811014413352, 'Total loss': 0.19747811014413352}
2022-12-05 22:13:08,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:08,169 INFO:     Epoch: 26
2022-12-05 22:13:08,969 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47293603352525015, 'Total loss': 0.47293603352525015} | train loss {'Reaction outcome loss': 0.19042286943448217, 'Total loss': 0.19042286943448217}
2022-12-05 22:13:08,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:08,969 INFO:     Epoch: 27
2022-12-05 22:13:09,772 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47590804049237206, 'Total loss': 0.47590804049237206} | train loss {'Reaction outcome loss': 0.19051000901152895, 'Total loss': 0.19051000901152895}
2022-12-05 22:13:09,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:09,773 INFO:     Epoch: 28
2022-12-05 22:13:10,571 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4745712534270503, 'Total loss': 0.4745712534270503} | train loss {'Reaction outcome loss': 0.18234438519182083, 'Total loss': 0.18234438519182083}
2022-12-05 22:13:10,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:10,571 INFO:     Epoch: 29
2022-12-05 22:13:11,371 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48313312300226907, 'Total loss': 0.48313312300226907} | train loss {'Reaction outcome loss': 0.182854159972687, 'Total loss': 0.182854159972687}
2022-12-05 22:13:11,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:11,371 INFO:     Epoch: 30
2022-12-05 22:13:12,170 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4871715737337416, 'Total loss': 0.4871715737337416} | train loss {'Reaction outcome loss': 0.18235704798990415, 'Total loss': 0.18235704798990415}
2022-12-05 22:13:12,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:12,171 INFO:     Epoch: 31
2022-12-05 22:13:12,971 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4743692454966632, 'Total loss': 0.4743692454966632} | train loss {'Reaction outcome loss': 0.17761168334640653, 'Total loss': 0.17761168334640653}
2022-12-05 22:13:12,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:12,971 INFO:     Epoch: 32
2022-12-05 22:13:13,769 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48698142577301373, 'Total loss': 0.48698142577301373} | train loss {'Reaction outcome loss': 0.1723632860008763, 'Total loss': 0.1723632860008763}
2022-12-05 22:13:13,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:13,769 INFO:     Epoch: 33
2022-12-05 22:13:14,567 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4822047169912945, 'Total loss': 0.4822047169912945} | train loss {'Reaction outcome loss': 0.1722496042276925, 'Total loss': 0.1722496042276925}
2022-12-05 22:13:14,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:14,567 INFO:     Epoch: 34
2022-12-05 22:13:15,365 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5055421170863238, 'Total loss': 0.5055421170863238} | train loss {'Reaction outcome loss': 0.16903936645668377, 'Total loss': 0.16903936645668377}
2022-12-05 22:13:15,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:15,365 INFO:     Epoch: 35
2022-12-05 22:13:16,163 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4912188171663068, 'Total loss': 0.4912188171663068} | train loss {'Reaction outcome loss': 0.16623876892362047, 'Total loss': 0.16623876892362047}
2022-12-05 22:13:16,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:16,163 INFO:     Epoch: 36
2022-12-05 22:13:16,968 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.488442901013927, 'Total loss': 0.488442901013927} | train loss {'Reaction outcome loss': 0.16707958650552793, 'Total loss': 0.16707958650552793}
2022-12-05 22:13:16,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:16,968 INFO:     Epoch: 37
2022-12-05 22:13:17,765 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4962232082404874, 'Total loss': 0.4962232082404874} | train loss {'Reaction outcome loss': 0.16335532011139972, 'Total loss': 0.16335532011139972}
2022-12-05 22:13:17,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:17,765 INFO:     Epoch: 38
2022-12-05 22:13:18,565 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4825524069707502, 'Total loss': 0.4825524069707502} | train loss {'Reaction outcome loss': 0.16154831839416192, 'Total loss': 0.16154831839416192}
2022-12-05 22:13:18,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:18,565 INFO:     Epoch: 39
2022-12-05 22:13:19,366 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48417570983821695, 'Total loss': 0.48417570983821695} | train loss {'Reaction outcome loss': 0.15755570578098538, 'Total loss': 0.15755570578098538}
2022-12-05 22:13:19,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:19,366 INFO:     Epoch: 40
2022-12-05 22:13:20,171 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48409039205448195, 'Total loss': 0.48409039205448195} | train loss {'Reaction outcome loss': 0.16000426704486312, 'Total loss': 0.16000426704486312}
2022-12-05 22:13:20,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:20,172 INFO:     Epoch: 41
2022-12-05 22:13:20,970 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4950159774585204, 'Total loss': 0.4950159774585204} | train loss {'Reaction outcome loss': 0.15376682576548067, 'Total loss': 0.15376682576548067}
2022-12-05 22:13:20,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:20,970 INFO:     Epoch: 42
2022-12-05 22:13:21,772 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5058056536045942, 'Total loss': 0.5058056536045942} | train loss {'Reaction outcome loss': 0.15415466683709367, 'Total loss': 0.15415466683709367}
2022-12-05 22:13:21,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:21,772 INFO:     Epoch: 43
2022-12-05 22:13:22,574 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48408416218378325, 'Total loss': 0.48408416218378325} | train loss {'Reaction outcome loss': 0.15519172977279072, 'Total loss': 0.15519172977279072}
2022-12-05 22:13:22,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:22,574 INFO:     Epoch: 44
2022-12-05 22:13:23,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4990741896697066, 'Total loss': 0.4990741896697066} | train loss {'Reaction outcome loss': 0.1521245586866822, 'Total loss': 0.1521245586866822}
2022-12-05 22:13:23,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:23,372 INFO:     Epoch: 45
2022-12-05 22:13:24,171 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48831944980404596, 'Total loss': 0.48831944980404596} | train loss {'Reaction outcome loss': 0.149467472752428, 'Total loss': 0.149467472752428}
2022-12-05 22:13:24,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:24,172 INFO:     Epoch: 46
2022-12-05 22:13:24,972 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4993718486617912, 'Total loss': 0.4993718486617912} | train loss {'Reaction outcome loss': 0.14978525483545277, 'Total loss': 0.14978525483545277}
2022-12-05 22:13:24,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:24,973 INFO:     Epoch: 47
2022-12-05 22:13:25,771 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48437969996170566, 'Total loss': 0.48437969996170566} | train loss {'Reaction outcome loss': 0.14747164812813765, 'Total loss': 0.14747164812813765}
2022-12-05 22:13:25,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:25,771 INFO:     Epoch: 48
2022-12-05 22:13:26,569 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5098146173087034, 'Total loss': 0.5098146173087034} | train loss {'Reaction outcome loss': 0.1471458847921055, 'Total loss': 0.1471458847921055}
2022-12-05 22:13:26,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:26,570 INFO:     Epoch: 49
2022-12-05 22:13:27,368 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5090658204122023, 'Total loss': 0.5090658204122023} | train loss {'Reaction outcome loss': 0.1485332318238522, 'Total loss': 0.1485332318238522}
2022-12-05 22:13:27,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:27,369 INFO:     Epoch: 50
2022-12-05 22:13:28,170 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4978075672618367, 'Total loss': 0.4978075672618367} | train loss {'Reaction outcome loss': 0.14720761101044383, 'Total loss': 0.14720761101044383}
2022-12-05 22:13:28,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:28,170 INFO:     Epoch: 51
2022-12-05 22:13:28,973 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5022825876420195, 'Total loss': 0.5022825876420195} | train loss {'Reaction outcome loss': 0.14295794539575876, 'Total loss': 0.14295794539575876}
2022-12-05 22:13:28,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:28,973 INFO:     Epoch: 52
2022-12-05 22:13:29,770 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5097273147918961, 'Total loss': 0.5097273147918961} | train loss {'Reaction outcome loss': 0.14231945262837264, 'Total loss': 0.14231945262837264}
2022-12-05 22:13:29,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:29,770 INFO:     Epoch: 53
2022-12-05 22:13:30,567 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5046041943132877, 'Total loss': 0.5046041943132877} | train loss {'Reaction outcome loss': 0.1426743171913059, 'Total loss': 0.1426743171913059}
2022-12-05 22:13:30,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:30,568 INFO:     Epoch: 54
2022-12-05 22:13:31,367 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5126797810874202, 'Total loss': 0.5126797810874202} | train loss {'Reaction outcome loss': 0.1401283177000429, 'Total loss': 0.1401283177000429}
2022-12-05 22:13:31,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:31,367 INFO:     Epoch: 55
2022-12-05 22:13:32,170 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.514506590298631, 'Total loss': 0.514506590298631} | train loss {'Reaction outcome loss': 0.14548049522337583, 'Total loss': 0.14548049522337583}
2022-12-05 22:13:32,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:32,170 INFO:     Epoch: 56
2022-12-05 22:13:32,971 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4957578678361394, 'Total loss': 0.4957578678361394} | train loss {'Reaction outcome loss': 0.13590020058263727, 'Total loss': 0.13590020058263727}
2022-12-05 22:13:32,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:32,971 INFO:     Epoch: 57
2022-12-05 22:13:33,774 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5096261166036129, 'Total loss': 0.5096261166036129} | train loss {'Reaction outcome loss': 0.1334042382098523, 'Total loss': 0.1334042382098523}
2022-12-05 22:13:33,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:33,775 INFO:     Epoch: 58
2022-12-05 22:13:34,576 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4953419711779464, 'Total loss': 0.4953419711779464} | train loss {'Reaction outcome loss': 0.13890854202669023, 'Total loss': 0.13890854202669023}
2022-12-05 22:13:34,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:34,576 INFO:     Epoch: 59
2022-12-05 22:13:35,382 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5050952332940969, 'Total loss': 0.5050952332940969} | train loss {'Reaction outcome loss': 0.13363394937534565, 'Total loss': 0.13363394937534565}
2022-12-05 22:13:35,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:35,382 INFO:     Epoch: 60
2022-12-05 22:13:36,181 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5135062794116411, 'Total loss': 0.5135062794116411} | train loss {'Reaction outcome loss': 0.13454198894969485, 'Total loss': 0.13454198894969485}
2022-12-05 22:13:36,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:36,181 INFO:     Epoch: 61
2022-12-05 22:13:36,982 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5086468800225041, 'Total loss': 0.5086468800225041} | train loss {'Reaction outcome loss': 0.13237586457976083, 'Total loss': 0.13237586457976083}
2022-12-05 22:13:36,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:36,982 INFO:     Epoch: 62
2022-12-05 22:13:37,778 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5079202651977539, 'Total loss': 0.5079202651977539} | train loss {'Reaction outcome loss': 0.13560993692683063, 'Total loss': 0.13560993692683063}
2022-12-05 22:13:37,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:37,778 INFO:     Epoch: 63
2022-12-05 22:13:38,580 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5086937726221301, 'Total loss': 0.5086937726221301} | train loss {'Reaction outcome loss': 0.13543721729218355, 'Total loss': 0.13543721729218355}
2022-12-05 22:13:38,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:38,580 INFO:     Epoch: 64
2022-12-05 22:13:39,376 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5050372427160089, 'Total loss': 0.5050372427160089} | train loss {'Reaction outcome loss': 0.13102426614446439, 'Total loss': 0.13102426614446439}
2022-12-05 22:13:39,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:39,376 INFO:     Epoch: 65
2022-12-05 22:13:40,171 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5105381211773916, 'Total loss': 0.5105381211773916} | train loss {'Reaction outcome loss': 0.1289728243839041, 'Total loss': 0.1289728243839041}
2022-12-05 22:13:40,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:40,171 INFO:     Epoch: 66
2022-12-05 22:13:40,967 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5007670857012272, 'Total loss': 0.5007670857012272} | train loss {'Reaction outcome loss': 0.13169870453958327, 'Total loss': 0.13169870453958327}
2022-12-05 22:13:40,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:40,967 INFO:     Epoch: 67
2022-12-05 22:13:41,760 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5099376399408687, 'Total loss': 0.5099376399408687} | train loss {'Reaction outcome loss': 0.13320821093825194, 'Total loss': 0.13320821093825194}
2022-12-05 22:13:41,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:41,761 INFO:     Epoch: 68
2022-12-05 22:13:42,551 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5136618052016605, 'Total loss': 0.5136618052016605} | train loss {'Reaction outcome loss': 0.12509327888656557, 'Total loss': 0.12509327888656557}
2022-12-05 22:13:42,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:42,552 INFO:     Epoch: 69
2022-12-05 22:13:43,342 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5019353347068484, 'Total loss': 0.5019353347068484} | train loss {'Reaction outcome loss': 0.12808240924090872, 'Total loss': 0.12808240924090872}
2022-12-05 22:13:43,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:43,343 INFO:     Epoch: 70
2022-12-05 22:13:44,140 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5146636478602886, 'Total loss': 0.5146636478602886} | train loss {'Reaction outcome loss': 0.12668100823902786, 'Total loss': 0.12668100823902786}
2022-12-05 22:13:44,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:44,140 INFO:     Epoch: 71
2022-12-05 22:13:44,933 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5135022699832916, 'Total loss': 0.5135022699832916} | train loss {'Reaction outcome loss': 0.12604303592401236, 'Total loss': 0.12604303592401236}
2022-12-05 22:13:44,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:44,934 INFO:     Epoch: 72
2022-12-05 22:13:45,730 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5283657674762335, 'Total loss': 0.5283657674762335} | train loss {'Reaction outcome loss': 0.12528676015884815, 'Total loss': 0.12528676015884815}
2022-12-05 22:13:45,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:45,730 INFO:     Epoch: 73
2022-12-05 22:13:46,523 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5091304873878305, 'Total loss': 0.5091304873878305} | train loss {'Reaction outcome loss': 0.12596026375919941, 'Total loss': 0.12596026375919941}
2022-12-05 22:13:46,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:46,523 INFO:     Epoch: 74
2022-12-05 22:13:47,321 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5193778764117848, 'Total loss': 0.5193778764117848} | train loss {'Reaction outcome loss': 0.1285338344807484, 'Total loss': 0.1285338344807484}
2022-12-05 22:13:47,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:47,321 INFO:     Epoch: 75
2022-12-05 22:13:48,122 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5079104632816531, 'Total loss': 0.5079104632816531} | train loss {'Reaction outcome loss': 0.12230944298660225, 'Total loss': 0.12230944298660225}
2022-12-05 22:13:48,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:48,122 INFO:     Epoch: 76
2022-12-05 22:13:48,919 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5085895454341715, 'Total loss': 0.5085895454341715} | train loss {'Reaction outcome loss': 0.12601825243865067, 'Total loss': 0.12601825243865067}
2022-12-05 22:13:48,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:48,920 INFO:     Epoch: 77
2022-12-05 22:13:49,711 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5212590006942098, 'Total loss': 0.5212590006942098} | train loss {'Reaction outcome loss': 0.12381235692981887, 'Total loss': 0.12381235692981887}
2022-12-05 22:13:49,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:49,711 INFO:     Epoch: 78
2022-12-05 22:13:50,505 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5125688270411708, 'Total loss': 0.5125688270411708} | train loss {'Reaction outcome loss': 0.12521029159668004, 'Total loss': 0.12521029159668004}
2022-12-05 22:13:50,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:50,505 INFO:     Epoch: 79
2022-12-05 22:13:51,302 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5110686517913233, 'Total loss': 0.5110686517913233} | train loss {'Reaction outcome loss': 0.12126706480255976, 'Total loss': 0.12126706480255976}
2022-12-05 22:13:51,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:51,302 INFO:     Epoch: 80
2022-12-05 22:13:52,095 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5068890156055038, 'Total loss': 0.5068890156055038} | train loss {'Reaction outcome loss': 0.1246167351510602, 'Total loss': 0.1246167351510602}
2022-12-05 22:13:52,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:52,095 INFO:     Epoch: 81
2022-12-05 22:13:52,890 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4995967285199599, 'Total loss': 0.4995967285199599} | train loss {'Reaction outcome loss': 0.11873904842061371, 'Total loss': 0.11873904842061371}
2022-12-05 22:13:52,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:52,890 INFO:     Epoch: 82
2022-12-05 22:13:53,687 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5126459798563949, 'Total loss': 0.5126459798563949} | train loss {'Reaction outcome loss': 0.1225080883530108, 'Total loss': 0.1225080883530108}
2022-12-05 22:13:53,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:53,687 INFO:     Epoch: 83
2022-12-05 22:13:54,478 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5247565728019584, 'Total loss': 0.5247565728019584} | train loss {'Reaction outcome loss': 0.12241848325168314, 'Total loss': 0.12241848325168314}
2022-12-05 22:13:54,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:54,479 INFO:     Epoch: 84
2022-12-05 22:13:55,271 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5050980546935038, 'Total loss': 0.5050980546935038} | train loss {'Reaction outcome loss': 0.12279216038734324, 'Total loss': 0.12279216038734324}
2022-12-05 22:13:55,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:55,272 INFO:     Epoch: 85
2022-12-05 22:13:56,063 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5142227221618999, 'Total loss': 0.5142227221618999} | train loss {'Reaction outcome loss': 0.12046751762299161, 'Total loss': 0.12046751762299161}
2022-12-05 22:13:56,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:56,063 INFO:     Epoch: 86
2022-12-05 22:13:56,859 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5096489153802395, 'Total loss': 0.5096489153802395} | train loss {'Reaction outcome loss': 0.1275952446881516, 'Total loss': 0.1275952446881516}
2022-12-05 22:13:56,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:56,859 INFO:     Epoch: 87
2022-12-05 22:13:57,651 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49429896202954376, 'Total loss': 0.49429896202954376} | train loss {'Reaction outcome loss': 0.12069770312577727, 'Total loss': 0.12069770312577727}
2022-12-05 22:13:57,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:57,652 INFO:     Epoch: 88
2022-12-05 22:13:58,443 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5026424119079654, 'Total loss': 0.5026424119079654} | train loss {'Reaction outcome loss': 0.11800874440142742, 'Total loss': 0.11800874440142742}
2022-12-05 22:13:58,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:58,443 INFO:     Epoch: 89
2022-12-05 22:13:59,235 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5127700357274576, 'Total loss': 0.5127700357274576} | train loss {'Reaction outcome loss': 0.12172528426445689, 'Total loss': 0.12172528426445689}
2022-12-05 22:13:59,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:13:59,235 INFO:     Epoch: 90
2022-12-05 22:14:00,030 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5060537142509763, 'Total loss': 0.5060537142509763} | train loss {'Reaction outcome loss': 0.11660385107704502, 'Total loss': 0.11660385107704502}
2022-12-05 22:14:00,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:00,030 INFO:     Epoch: 91
2022-12-05 22:14:00,825 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5205100625753403, 'Total loss': 0.5205100625753403} | train loss {'Reaction outcome loss': 0.11721281305159091, 'Total loss': 0.11721281305159091}
2022-12-05 22:14:00,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:00,825 INFO:     Epoch: 92
2022-12-05 22:14:01,618 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5063238479197025, 'Total loss': 0.5063238479197025} | train loss {'Reaction outcome loss': 0.11765866087153856, 'Total loss': 0.11765866087153856}
2022-12-05 22:14:01,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:01,619 INFO:     Epoch: 93
2022-12-05 22:14:02,409 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5107600414617495, 'Total loss': 0.5107600414617495} | train loss {'Reaction outcome loss': 0.11639283654404435, 'Total loss': 0.11639283654404435}
2022-12-05 22:14:02,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:02,410 INFO:     Epoch: 94
2022-12-05 22:14:03,204 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5163394426080313, 'Total loss': 0.5163394426080313} | train loss {'Reaction outcome loss': 0.1152543656788163, 'Total loss': 0.1152543656788163}
2022-12-05 22:14:03,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:03,204 INFO:     Epoch: 95
2022-12-05 22:14:04,002 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.512582755562934, 'Total loss': 0.512582755562934} | train loss {'Reaction outcome loss': 0.12103009248446477, 'Total loss': 0.12103009248446477}
2022-12-05 22:14:04,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:04,002 INFO:     Epoch: 96
2022-12-05 22:14:04,797 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5220043724614449, 'Total loss': 0.5220043724614449} | train loss {'Reaction outcome loss': 0.13501373590403784, 'Total loss': 0.13501373590403784}
2022-12-05 22:14:04,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:04,797 INFO:     Epoch: 97
2022-12-05 22:14:05,590 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5174454020505602, 'Total loss': 0.5174454020505602} | train loss {'Reaction outcome loss': 0.12478155914226524, 'Total loss': 0.12478155914226524}
2022-12-05 22:14:05,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:05,590 INFO:     Epoch: 98
2022-12-05 22:14:06,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5170531665736978, 'Total loss': 0.5170531665736978} | train loss {'Reaction outcome loss': 0.11376167353815757, 'Total loss': 0.11376167353815757}
2022-12-05 22:14:06,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:06,388 INFO:     Epoch: 99
2022-12-05 22:14:07,181 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4966653815724633, 'Total loss': 0.4966653815724633} | train loss {'Reaction outcome loss': 0.11574961180960842, 'Total loss': 0.11574961180960842}
2022-12-05 22:14:07,181 INFO:     Best model found after epoch 17 of 100.
2022-12-05 22:14:07,181 INFO:   Done with stage: TRAINING
2022-12-05 22:14:07,181 INFO:   Starting stage: EVALUATION
2022-12-05 22:14:07,308 INFO:   Done with stage: EVALUATION
2022-12-05 22:14:07,316 INFO:   Leaving out SEQ value Fold_0
2022-12-05 22:14:07,329 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 22:14:07,329 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:14:07,961 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:14:07,961 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:14:08,030 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:14:08,030 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:14:08,030 INFO:     No hyperparam tuning for this model
2022-12-05 22:14:08,030 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:14:08,030 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:14:08,031 INFO:     None feature selector for col prot
2022-12-05 22:14:08,031 INFO:     None feature selector for col prot
2022-12-05 22:14:08,031 INFO:     None feature selector for col prot
2022-12-05 22:14:08,032 INFO:     None feature selector for col chem
2022-12-05 22:14:08,032 INFO:     None feature selector for col chem
2022-12-05 22:14:08,032 INFO:     None feature selector for col chem
2022-12-05 22:14:08,032 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:14:08,032 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:14:08,034 INFO:     Number of params in model 215821
2022-12-05 22:14:08,037 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:14:08,037 INFO:   Starting stage: TRAINING
2022-12-05 22:14:08,096 INFO:     Val loss before train {'Reaction outcome loss': 0.998718568058901, 'Total loss': 0.998718568058901}
2022-12-05 22:14:08,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:08,097 INFO:     Epoch: 0
2022-12-05 22:14:08,879 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6257251300090967, 'Total loss': 0.6257251300090967} | train loss {'Reaction outcome loss': 0.7941430428145845, 'Total loss': 0.7941430428145845}
2022-12-05 22:14:08,879 INFO:     Found new best model at epoch 0
2022-12-05 22:14:08,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:08,880 INFO:     Epoch: 1
2022-12-05 22:14:09,657 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5248076354348382, 'Total loss': 0.5248076354348382} | train loss {'Reaction outcome loss': 0.5341325167397903, 'Total loss': 0.5341325167397903}
2022-12-05 22:14:09,657 INFO:     Found new best model at epoch 1
2022-12-05 22:14:09,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:09,658 INFO:     Epoch: 2
2022-12-05 22:14:10,444 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48758277054442917, 'Total loss': 0.48758277054442917} | train loss {'Reaction outcome loss': 0.45948524503305616, 'Total loss': 0.45948524503305616}
2022-12-05 22:14:10,445 INFO:     Found new best model at epoch 2
2022-12-05 22:14:10,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:10,445 INFO:     Epoch: 3
2022-12-05 22:14:11,225 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4697980908460395, 'Total loss': 0.4697980908460395} | train loss {'Reaction outcome loss': 0.4217957498298751, 'Total loss': 0.4217957498298751}
2022-12-05 22:14:11,225 INFO:     Found new best model at epoch 3
2022-12-05 22:14:11,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:11,226 INFO:     Epoch: 4
2022-12-05 22:14:12,004 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4574198847593263, 'Total loss': 0.4574198847593263} | train loss {'Reaction outcome loss': 0.388577949669626, 'Total loss': 0.388577949669626}
2022-12-05 22:14:12,004 INFO:     Found new best model at epoch 4
2022-12-05 22:14:12,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:12,005 INFO:     Epoch: 5
2022-12-05 22:14:12,780 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44469109038973964, 'Total loss': 0.44469109038973964} | train loss {'Reaction outcome loss': 0.3669349496624597, 'Total loss': 0.3669349496624597}
2022-12-05 22:14:12,780 INFO:     Found new best model at epoch 5
2022-12-05 22:14:12,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:12,781 INFO:     Epoch: 6
2022-12-05 22:14:13,557 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44630852757498274, 'Total loss': 0.44630852757498274} | train loss {'Reaction outcome loss': 0.3484171101585828, 'Total loss': 0.3484171101585828}
2022-12-05 22:14:13,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:13,558 INFO:     Epoch: 7
2022-12-05 22:14:14,337 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4272622247768003, 'Total loss': 0.4272622247768003} | train loss {'Reaction outcome loss': 0.3273885318771802, 'Total loss': 0.3273885318771802}
2022-12-05 22:14:14,338 INFO:     Found new best model at epoch 7
2022-12-05 22:14:14,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:14,339 INFO:     Epoch: 8
2022-12-05 22:14:15,119 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43300450021444364, 'Total loss': 0.43300450021444364} | train loss {'Reaction outcome loss': 0.3135580995691166, 'Total loss': 0.3135580995691166}
2022-12-05 22:14:15,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:15,119 INFO:     Epoch: 9
2022-12-05 22:14:15,899 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4298335388302803, 'Total loss': 0.4298335388302803} | train loss {'Reaction outcome loss': 0.30204729787974693, 'Total loss': 0.30204729787974693}
2022-12-05 22:14:15,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:15,899 INFO:     Epoch: 10
2022-12-05 22:14:16,679 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4207809321409048, 'Total loss': 0.4207809321409048} | train loss {'Reaction outcome loss': 0.28596827797131774, 'Total loss': 0.28596827797131774}
2022-12-05 22:14:16,679 INFO:     Found new best model at epoch 10
2022-12-05 22:14:16,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:16,680 INFO:     Epoch: 11
2022-12-05 22:14:17,459 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42317873724671295, 'Total loss': 0.42317873724671295} | train loss {'Reaction outcome loss': 0.27547186278879887, 'Total loss': 0.27547186278879887}
2022-12-05 22:14:17,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:17,459 INFO:     Epoch: 12
2022-12-05 22:14:18,240 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42633222528668335, 'Total loss': 0.42633222528668335} | train loss {'Reaction outcome loss': 0.26768116254374813, 'Total loss': 0.26768116254374813}
2022-12-05 22:14:18,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:18,240 INFO:     Epoch: 13
2022-12-05 22:14:19,017 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4297704745170682, 'Total loss': 0.4297704745170682} | train loss {'Reaction outcome loss': 0.25459777451898336, 'Total loss': 0.25459777451898336}
2022-12-05 22:14:19,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:19,017 INFO:     Epoch: 14
2022-12-05 22:14:19,794 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.427266416508098, 'Total loss': 0.427266416508098} | train loss {'Reaction outcome loss': 0.2437917937221841, 'Total loss': 0.2437917937221841}
2022-12-05 22:14:19,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:19,794 INFO:     Epoch: 15
2022-12-05 22:14:20,572 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41789586668790774, 'Total loss': 0.41789586668790774} | train loss {'Reaction outcome loss': 0.23749607428908348, 'Total loss': 0.23749607428908348}
2022-12-05 22:14:20,572 INFO:     Found new best model at epoch 15
2022-12-05 22:14:20,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:20,573 INFO:     Epoch: 16
2022-12-05 22:14:21,350 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4189876997193625, 'Total loss': 0.4189876997193625} | train loss {'Reaction outcome loss': 0.22893226310733414, 'Total loss': 0.22893226310733414}
2022-12-05 22:14:21,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:21,350 INFO:     Epoch: 17
2022-12-05 22:14:22,126 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4387895492620246, 'Total loss': 0.4387895492620246} | train loss {'Reaction outcome loss': 0.2208565224130703, 'Total loss': 0.2208565224130703}
2022-12-05 22:14:22,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:22,127 INFO:     Epoch: 18
2022-12-05 22:14:22,904 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4160481310167978, 'Total loss': 0.4160481310167978} | train loss {'Reaction outcome loss': 0.21467044503416544, 'Total loss': 0.21467044503416544}
2022-12-05 22:14:22,904 INFO:     Found new best model at epoch 18
2022-12-05 22:14:22,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:22,905 INFO:     Epoch: 19
2022-12-05 22:14:23,689 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42098270287347395, 'Total loss': 0.42098270287347395} | train loss {'Reaction outcome loss': 0.20948155417486472, 'Total loss': 0.20948155417486472}
2022-12-05 22:14:23,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:23,689 INFO:     Epoch: 20
2022-12-05 22:14:24,468 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.450580905343211, 'Total loss': 0.450580905343211} | train loss {'Reaction outcome loss': 0.2032224193767265, 'Total loss': 0.2032224193767265}
2022-12-05 22:14:24,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:24,469 INFO:     Epoch: 21
2022-12-05 22:14:25,252 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43889503215634545, 'Total loss': 0.43889503215634545} | train loss {'Reaction outcome loss': 0.1987190004514814, 'Total loss': 0.1987190004514814}
2022-12-05 22:14:25,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:25,252 INFO:     Epoch: 22
2022-12-05 22:14:26,033 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41909296100222787, 'Total loss': 0.41909296100222787} | train loss {'Reaction outcome loss': 0.1949798301812798, 'Total loss': 0.1949798301812798}
2022-12-05 22:14:26,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:26,034 INFO:     Epoch: 23
2022-12-05 22:14:26,814 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42129366377065347, 'Total loss': 0.42129366377065347} | train loss {'Reaction outcome loss': 0.1870367823229957, 'Total loss': 0.1870367823229957}
2022-12-05 22:14:26,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:26,815 INFO:     Epoch: 24
2022-12-05 22:14:27,593 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42395139502924545, 'Total loss': 0.42395139502924545} | train loss {'Reaction outcome loss': 0.18457964686638534, 'Total loss': 0.18457964686638534}
2022-12-05 22:14:27,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:27,593 INFO:     Epoch: 25
2022-12-05 22:14:28,371 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4188092167294303, 'Total loss': 0.4188092167294303} | train loss {'Reaction outcome loss': 0.1789959381514616, 'Total loss': 0.1789959381514616}
2022-12-05 22:14:28,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:28,371 INFO:     Epoch: 26
2022-12-05 22:14:29,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43846903568090395, 'Total loss': 0.43846903568090395} | train loss {'Reaction outcome loss': 0.17782412685545873, 'Total loss': 0.17782412685545873}
2022-12-05 22:14:29,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:29,151 INFO:     Epoch: 27
2022-12-05 22:14:29,932 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4240134583656178, 'Total loss': 0.4240134583656178} | train loss {'Reaction outcome loss': 0.17794015175766414, 'Total loss': 0.17794015175766414}
2022-12-05 22:14:29,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:29,932 INFO:     Epoch: 28
2022-12-05 22:14:30,712 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4350462441527566, 'Total loss': 0.4350462441527566} | train loss {'Reaction outcome loss': 0.17118917173349563, 'Total loss': 0.17118917173349563}
2022-12-05 22:14:30,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:30,713 INFO:     Epoch: 29
2022-12-05 22:14:31,492 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.420925822368888, 'Total loss': 0.420925822368888} | train loss {'Reaction outcome loss': 0.1660122643435688, 'Total loss': 0.1660122643435688}
2022-12-05 22:14:31,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:31,493 INFO:     Epoch: 30
2022-12-05 22:14:32,272 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4296251760665761, 'Total loss': 0.4296251760665761} | train loss {'Reaction outcome loss': 0.16085844174977929, 'Total loss': 0.16085844174977929}
2022-12-05 22:14:32,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:32,272 INFO:     Epoch: 31
2022-12-05 22:14:33,055 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42000370853862096, 'Total loss': 0.42000370853862096} | train loss {'Reaction outcome loss': 0.16198598807332693, 'Total loss': 0.16198598807332693}
2022-12-05 22:14:33,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:33,055 INFO:     Epoch: 32
2022-12-05 22:14:33,834 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4172109933786614, 'Total loss': 0.4172109933786614} | train loss {'Reaction outcome loss': 0.1571159591446075, 'Total loss': 0.1571159591446075}
2022-12-05 22:14:33,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:33,834 INFO:     Epoch: 33
2022-12-05 22:14:34,616 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42408626370651775, 'Total loss': 0.42408626370651775} | train loss {'Reaction outcome loss': 0.1560827952200248, 'Total loss': 0.1560827952200248}
2022-12-05 22:14:34,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:34,616 INFO:     Epoch: 34
2022-12-05 22:14:35,400 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42532068248405014, 'Total loss': 0.42532068248405014} | train loss {'Reaction outcome loss': 0.15634877431693145, 'Total loss': 0.15634877431693145}
2022-12-05 22:14:35,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:35,400 INFO:     Epoch: 35
2022-12-05 22:14:36,179 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4314493316897126, 'Total loss': 0.4314493316897126} | train loss {'Reaction outcome loss': 0.15235571559794522, 'Total loss': 0.15235571559794522}
2022-12-05 22:14:36,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:36,180 INFO:     Epoch: 36
2022-12-05 22:14:36,960 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41841833206803297, 'Total loss': 0.41841833206803297} | train loss {'Reaction outcome loss': 0.15071469983047664, 'Total loss': 0.15071469983047664}
2022-12-05 22:14:36,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:36,960 INFO:     Epoch: 37
2022-12-05 22:14:37,741 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4230599301152451, 'Total loss': 0.4230599301152451} | train loss {'Reaction outcome loss': 0.14717649449996742, 'Total loss': 0.14717649449996742}
2022-12-05 22:14:37,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:37,742 INFO:     Epoch: 38
2022-12-05 22:14:38,524 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4319808663323868, 'Total loss': 0.4319808663323868} | train loss {'Reaction outcome loss': 0.14655429544502202, 'Total loss': 0.14655429544502202}
2022-12-05 22:14:38,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:38,524 INFO:     Epoch: 39
2022-12-05 22:14:39,303 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43650524560795273, 'Total loss': 0.43650524560795273} | train loss {'Reaction outcome loss': 0.14525570275085697, 'Total loss': 0.14525570275085697}
2022-12-05 22:14:39,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:39,303 INFO:     Epoch: 40
2022-12-05 22:14:40,083 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43614652025145156, 'Total loss': 0.43614652025145156} | train loss {'Reaction outcome loss': 0.14595628618703457, 'Total loss': 0.14595628618703457}
2022-12-05 22:14:40,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:40,084 INFO:     Epoch: 41
2022-12-05 22:14:40,864 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.423449692338012, 'Total loss': 0.423449692338012} | train loss {'Reaction outcome loss': 0.14399320211399486, 'Total loss': 0.14399320211399486}
2022-12-05 22:14:40,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:40,864 INFO:     Epoch: 42
2022-12-05 22:14:41,644 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4315211987772653, 'Total loss': 0.4315211987772653} | train loss {'Reaction outcome loss': 0.1447034712589572, 'Total loss': 0.1447034712589572}
2022-12-05 22:14:41,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:41,644 INFO:     Epoch: 43
2022-12-05 22:14:42,425 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4237483755447144, 'Total loss': 0.4237483755447144} | train loss {'Reaction outcome loss': 0.13799142622898636, 'Total loss': 0.13799142622898636}
2022-12-05 22:14:42,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:42,426 INFO:     Epoch: 44
2022-12-05 22:14:43,204 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42606400992981225, 'Total loss': 0.42606400992981225} | train loss {'Reaction outcome loss': 0.13725781576409016, 'Total loss': 0.13725781576409016}
2022-12-05 22:14:43,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:43,205 INFO:     Epoch: 45
2022-12-05 22:14:43,983 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40562448425348413, 'Total loss': 0.40562448425348413} | train loss {'Reaction outcome loss': 0.13627032430482255, 'Total loss': 0.13627032430482255}
2022-12-05 22:14:43,984 INFO:     Found new best model at epoch 45
2022-12-05 22:14:43,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:43,984 INFO:     Epoch: 46
2022-12-05 22:14:44,766 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4260730317165685, 'Total loss': 0.4260730317165685} | train loss {'Reaction outcome loss': 0.1379577521610346, 'Total loss': 0.1379577521610346}
2022-12-05 22:14:44,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:44,767 INFO:     Epoch: 47
2022-12-05 22:14:45,547 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4266477263597555, 'Total loss': 0.4266477263597555} | train loss {'Reaction outcome loss': 0.13573957070777262, 'Total loss': 0.13573957070777262}
2022-12-05 22:14:45,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:45,547 INFO:     Epoch: 48
2022-12-05 22:14:46,333 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4302668207606604, 'Total loss': 0.4302668207606604} | train loss {'Reaction outcome loss': 0.13711948211806915, 'Total loss': 0.13711948211806915}
2022-12-05 22:14:46,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:46,334 INFO:     Epoch: 49
2022-12-05 22:14:47,113 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43295403760533, 'Total loss': 0.43295403760533} | train loss {'Reaction outcome loss': 0.1324005575482676, 'Total loss': 0.1324005575482676}
2022-12-05 22:14:47,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:47,113 INFO:     Epoch: 50
2022-12-05 22:14:47,898 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42331595718860626, 'Total loss': 0.42331595718860626} | train loss {'Reaction outcome loss': 0.1314805519878251, 'Total loss': 0.1314805519878251}
2022-12-05 22:14:47,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:47,898 INFO:     Epoch: 51
2022-12-05 22:14:48,681 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42636817849652714, 'Total loss': 0.42636817849652714} | train loss {'Reaction outcome loss': 0.13127245395271867, 'Total loss': 0.13127245395271867}
2022-12-05 22:14:48,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:48,681 INFO:     Epoch: 52
2022-12-05 22:14:49,462 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41841508274854616, 'Total loss': 0.41841508274854616} | train loss {'Reaction outcome loss': 0.13323691206765764, 'Total loss': 0.13323691206765764}
2022-12-05 22:14:49,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:49,462 INFO:     Epoch: 53
2022-12-05 22:14:50,247 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42707874366017273, 'Total loss': 0.42707874366017273} | train loss {'Reaction outcome loss': 0.13140734547266253, 'Total loss': 0.13140734547266253}
2022-12-05 22:14:50,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:50,247 INFO:     Epoch: 54
2022-12-05 22:14:51,027 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4118941259938617, 'Total loss': 0.4118941259938617} | train loss {'Reaction outcome loss': 0.1304994664258427, 'Total loss': 0.1304994664258427}
2022-12-05 22:14:51,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:51,027 INFO:     Epoch: 55
2022-12-05 22:14:51,810 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4146594039575998, 'Total loss': 0.4146594039575998} | train loss {'Reaction outcome loss': 0.1298539340112803, 'Total loss': 0.1298539340112803}
2022-12-05 22:14:51,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:51,811 INFO:     Epoch: 56
2022-12-05 22:14:52,591 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41210463556439375, 'Total loss': 0.41210463556439375} | train loss {'Reaction outcome loss': 0.1281352819483957, 'Total loss': 0.1281352819483957}
2022-12-05 22:14:52,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:52,591 INFO:     Epoch: 57
2022-12-05 22:14:53,373 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.424573264496271, 'Total loss': 0.424573264496271} | train loss {'Reaction outcome loss': 0.12570634110229006, 'Total loss': 0.12570634110229006}
2022-12-05 22:14:53,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:53,373 INFO:     Epoch: 58
2022-12-05 22:14:54,152 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40673520831867704, 'Total loss': 0.40673520831867704} | train loss {'Reaction outcome loss': 0.12734526542969693, 'Total loss': 0.12734526542969693}
2022-12-05 22:14:54,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:54,152 INFO:     Epoch: 59
2022-12-05 22:14:54,934 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40963975634685784, 'Total loss': 0.40963975634685784} | train loss {'Reaction outcome loss': 0.12796257298301766, 'Total loss': 0.12796257298301766}
2022-12-05 22:14:54,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:54,935 INFO:     Epoch: 60
2022-12-05 22:14:55,718 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42350132243577826, 'Total loss': 0.42350132243577826} | train loss {'Reaction outcome loss': 0.12338942220365559, 'Total loss': 0.12338942220365559}
2022-12-05 22:14:55,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:55,718 INFO:     Epoch: 61
2022-12-05 22:14:56,504 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4326505349125973, 'Total loss': 0.4326505349125973} | train loss {'Reaction outcome loss': 0.12177729062398765, 'Total loss': 0.12177729062398765}
2022-12-05 22:14:56,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:56,505 INFO:     Epoch: 62
2022-12-05 22:14:57,286 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4301056577715763, 'Total loss': 0.4301056577715763} | train loss {'Reaction outcome loss': 0.125147730342032, 'Total loss': 0.125147730342032}
2022-12-05 22:14:57,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:57,288 INFO:     Epoch: 63
2022-12-05 22:14:58,067 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42900007997834405, 'Total loss': 0.42900007997834405} | train loss {'Reaction outcome loss': 0.12134011186000128, 'Total loss': 0.12134011186000128}
2022-12-05 22:14:58,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:58,067 INFO:     Epoch: 64
2022-12-05 22:14:58,847 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42117287287878435, 'Total loss': 0.42117287287878435} | train loss {'Reaction outcome loss': 0.12185872943090742, 'Total loss': 0.12185872943090742}
2022-12-05 22:14:58,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:58,847 INFO:     Epoch: 65
2022-12-05 22:14:59,627 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42779464846433596, 'Total loss': 0.42779464846433596} | train loss {'Reaction outcome loss': 0.12231625840757732, 'Total loss': 0.12231625840757732}
2022-12-05 22:14:59,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:14:59,627 INFO:     Epoch: 66
2022-12-05 22:15:00,410 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41721673933572545, 'Total loss': 0.41721673933572545} | train loss {'Reaction outcome loss': 0.12225251028567184, 'Total loss': 0.12225251028567184}
2022-12-05 22:15:00,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:00,410 INFO:     Epoch: 67
2022-12-05 22:15:01,191 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41863796149575433, 'Total loss': 0.41863796149575433} | train loss {'Reaction outcome loss': 0.1228613739281341, 'Total loss': 0.1228613739281341}
2022-12-05 22:15:01,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:01,191 INFO:     Epoch: 68
2022-12-05 22:15:01,973 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4194962818955266, 'Total loss': 0.4194962818955266} | train loss {'Reaction outcome loss': 0.11903746994241014, 'Total loss': 0.11903746994241014}
2022-12-05 22:15:01,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:01,973 INFO:     Epoch: 69
2022-12-05 22:15:02,753 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.415088334575642, 'Total loss': 0.415088334575642} | train loss {'Reaction outcome loss': 0.12004873266926518, 'Total loss': 0.12004873266926518}
2022-12-05 22:15:02,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:02,753 INFO:     Epoch: 70
2022-12-05 22:15:03,532 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4148918049799841, 'Total loss': 0.4148918049799841} | train loss {'Reaction outcome loss': 0.11879374247442916, 'Total loss': 0.11879374247442916}
2022-12-05 22:15:03,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:03,532 INFO:     Epoch: 71
2022-12-05 22:15:04,314 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4222832786482434, 'Total loss': 0.4222832786482434} | train loss {'Reaction outcome loss': 0.11887755757197738, 'Total loss': 0.11887755757197738}
2022-12-05 22:15:04,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:04,314 INFO:     Epoch: 72
2022-12-05 22:15:05,096 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41232907841371935, 'Total loss': 0.41232907841371935} | train loss {'Reaction outcome loss': 0.12003587372984292, 'Total loss': 0.12003587372984292}
2022-12-05 22:15:05,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:05,096 INFO:     Epoch: 73
2022-12-05 22:15:05,878 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41550664811633353, 'Total loss': 0.41550664811633353} | train loss {'Reaction outcome loss': 0.11686301141318102, 'Total loss': 0.11686301141318102}
2022-12-05 22:15:05,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:05,879 INFO:     Epoch: 74
2022-12-05 22:15:06,659 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4182141693525536, 'Total loss': 0.4182141693525536} | train loss {'Reaction outcome loss': 0.11603253272289234, 'Total loss': 0.11603253272289234}
2022-12-05 22:15:06,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:06,659 INFO:     Epoch: 75
2022-12-05 22:15:07,444 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42331302027369655, 'Total loss': 0.42331302027369655} | train loss {'Reaction outcome loss': 0.11742237490437035, 'Total loss': 0.11742237490437035}
2022-12-05 22:15:07,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:07,444 INFO:     Epoch: 76
2022-12-05 22:15:08,229 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42042937320332197, 'Total loss': 0.42042937320332197} | train loss {'Reaction outcome loss': 0.11552581401856103, 'Total loss': 0.11552581401856103}
2022-12-05 22:15:08,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:08,229 INFO:     Epoch: 77
2022-12-05 22:15:09,010 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4310132807423902, 'Total loss': 0.4310132807423902} | train loss {'Reaction outcome loss': 0.11368725405921662, 'Total loss': 0.11368725405921662}
2022-12-05 22:15:09,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:09,010 INFO:     Epoch: 78
2022-12-05 22:15:09,793 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43070623243963996, 'Total loss': 0.43070623243963996} | train loss {'Reaction outcome loss': 0.11641501303026337, 'Total loss': 0.11641501303026337}
2022-12-05 22:15:09,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:09,793 INFO:     Epoch: 79
2022-12-05 22:15:10,573 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4364010743623556, 'Total loss': 0.4364010743623556} | train loss {'Reaction outcome loss': 0.11453090704318304, 'Total loss': 0.11453090704318304}
2022-12-05 22:15:10,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:10,574 INFO:     Epoch: 80
2022-12-05 22:15:11,358 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4141888764015464, 'Total loss': 0.4141888764015464} | train loss {'Reaction outcome loss': 0.11306737742382926, 'Total loss': 0.11306737742382926}
2022-12-05 22:15:11,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:11,358 INFO:     Epoch: 81
2022-12-05 22:15:12,140 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4146081126013467, 'Total loss': 0.4146081126013467} | train loss {'Reaction outcome loss': 0.11327128061342509, 'Total loss': 0.11327128061342509}
2022-12-05 22:15:12,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:12,140 INFO:     Epoch: 82
2022-12-05 22:15:12,920 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4306154741450798, 'Total loss': 0.4306154741450798} | train loss {'Reaction outcome loss': 0.11227437392751008, 'Total loss': 0.11227437392751008}
2022-12-05 22:15:12,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:12,920 INFO:     Epoch: 83
2022-12-05 22:15:13,705 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4249874786582104, 'Total loss': 0.4249874786582104} | train loss {'Reaction outcome loss': 0.1115858134173562, 'Total loss': 0.1115858134173562}
2022-12-05 22:15:13,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:13,705 INFO:     Epoch: 84
2022-12-05 22:15:14,489 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42033677322919977, 'Total loss': 0.42033677322919977} | train loss {'Reaction outcome loss': 0.11264836347044864, 'Total loss': 0.11264836347044864}
2022-12-05 22:15:14,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:14,489 INFO:     Epoch: 85
2022-12-05 22:15:15,273 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41852817285892574, 'Total loss': 0.41852817285892574} | train loss {'Reaction outcome loss': 0.11376178354684095, 'Total loss': 0.11376178354684095}
2022-12-05 22:15:15,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:15,273 INFO:     Epoch: 86
2022-12-05 22:15:16,059 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40915216505527496, 'Total loss': 0.40915216505527496} | train loss {'Reaction outcome loss': 0.10977310346010229, 'Total loss': 0.10977310346010229}
2022-12-05 22:15:16,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:16,060 INFO:     Epoch: 87
2022-12-05 22:15:16,849 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42222975090492604, 'Total loss': 0.42222975090492604} | train loss {'Reaction outcome loss': 0.11327341078960723, 'Total loss': 0.11327341078960723}
2022-12-05 22:15:16,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:16,849 INFO:     Epoch: 88
2022-12-05 22:15:17,635 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4145797841077627, 'Total loss': 0.4145797841077627} | train loss {'Reaction outcome loss': 0.11073980270597486, 'Total loss': 0.11073980270597486}
2022-12-05 22:15:17,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:17,635 INFO:     Epoch: 89
2022-12-05 22:15:18,419 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41877073257468467, 'Total loss': 0.41877073257468467} | train loss {'Reaction outcome loss': 0.11150789242851022, 'Total loss': 0.11150789242851022}
2022-12-05 22:15:18,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:18,419 INFO:     Epoch: 90
2022-12-05 22:15:19,198 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42055213919212653, 'Total loss': 0.42055213919212653} | train loss {'Reaction outcome loss': 0.10899278859190122, 'Total loss': 0.10899278859190122}
2022-12-05 22:15:19,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:19,198 INFO:     Epoch: 91
2022-12-05 22:15:19,984 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4419184566237206, 'Total loss': 0.4419184566237206} | train loss {'Reaction outcome loss': 0.10952357987685458, 'Total loss': 0.10952357987685458}
2022-12-05 22:15:19,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:19,985 INFO:     Epoch: 92
2022-12-05 22:15:20,764 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42059087476064994, 'Total loss': 0.42059087476064994} | train loss {'Reaction outcome loss': 0.10776394368398459, 'Total loss': 0.10776394368398459}
2022-12-05 22:15:20,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:20,764 INFO:     Epoch: 93
2022-12-05 22:15:21,546 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4204777111840803, 'Total loss': 0.4204777111840803} | train loss {'Reaction outcome loss': 0.10574780572435738, 'Total loss': 0.10574780572435738}
2022-12-05 22:15:21,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:21,547 INFO:     Epoch: 94
2022-12-05 22:15:22,325 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41412000011566075, 'Total loss': 0.41412000011566075} | train loss {'Reaction outcome loss': 0.11046798496579928, 'Total loss': 0.11046798496579928}
2022-12-05 22:15:22,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:22,325 INFO:     Epoch: 95
2022-12-05 22:15:23,107 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4207782402288082, 'Total loss': 0.4207782402288082} | train loss {'Reaction outcome loss': 0.11094611208816921, 'Total loss': 0.11094611208816921}
2022-12-05 22:15:23,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:23,107 INFO:     Epoch: 96
2022-12-05 22:15:23,885 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4197408212132232, 'Total loss': 0.4197408212132232} | train loss {'Reaction outcome loss': 0.1064016296923038, 'Total loss': 0.1064016296923038}
2022-12-05 22:15:23,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:23,885 INFO:     Epoch: 97
2022-12-05 22:15:24,667 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42011329098496325, 'Total loss': 0.42011329098496325} | train loss {'Reaction outcome loss': 0.10677964146892874, 'Total loss': 0.10677964146892874}
2022-12-05 22:15:24,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:24,667 INFO:     Epoch: 98
2022-12-05 22:15:25,455 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4143475477778634, 'Total loss': 0.4143475477778634} | train loss {'Reaction outcome loss': 0.10895085346084012, 'Total loss': 0.10895085346084012}
2022-12-05 22:15:25,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:25,455 INFO:     Epoch: 99
2022-12-05 22:15:26,236 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42326407654340875, 'Total loss': 0.42326407654340875} | train loss {'Reaction outcome loss': 0.10566375622288189, 'Total loss': 0.10566375622288189}
2022-12-05 22:15:26,237 INFO:     Best model found after epoch 46 of 100.
2022-12-05 22:15:26,237 INFO:   Done with stage: TRAINING
2022-12-05 22:15:26,237 INFO:   Starting stage: EVALUATION
2022-12-05 22:15:26,380 INFO:   Done with stage: EVALUATION
2022-12-05 22:15:26,380 INFO:   Leaving out SEQ value Fold_1
2022-12-05 22:15:26,393 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:15:26,393 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:15:27,033 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:15:27,033 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:15:27,103 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:15:27,103 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:15:27,103 INFO:     No hyperparam tuning for this model
2022-12-05 22:15:27,103 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:15:27,103 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:15:27,104 INFO:     None feature selector for col prot
2022-12-05 22:15:27,104 INFO:     None feature selector for col prot
2022-12-05 22:15:27,104 INFO:     None feature selector for col prot
2022-12-05 22:15:27,104 INFO:     None feature selector for col chem
2022-12-05 22:15:27,105 INFO:     None feature selector for col chem
2022-12-05 22:15:27,105 INFO:     None feature selector for col chem
2022-12-05 22:15:27,105 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:15:27,105 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:15:27,107 INFO:     Number of params in model 215821
2022-12-05 22:15:27,110 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:15:27,110 INFO:   Starting stage: TRAINING
2022-12-05 22:15:27,171 INFO:     Val loss before train {'Reaction outcome loss': 0.9839235341007059, 'Total loss': 0.9839235341007059}
2022-12-05 22:15:27,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:27,171 INFO:     Epoch: 0
2022-12-05 22:15:27,961 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6017732489854097, 'Total loss': 0.6017732489854097} | train loss {'Reaction outcome loss': 0.8040243160967924, 'Total loss': 0.8040243160967924}
2022-12-05 22:15:27,962 INFO:     Found new best model at epoch 0
2022-12-05 22:15:27,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:27,963 INFO:     Epoch: 1
2022-12-05 22:15:28,754 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5028700516982512, 'Total loss': 0.5028700516982512} | train loss {'Reaction outcome loss': 0.5541099759388943, 'Total loss': 0.5541099759388943}
2022-12-05 22:15:28,755 INFO:     Found new best model at epoch 1
2022-12-05 22:15:28,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:28,755 INFO:     Epoch: 2
2022-12-05 22:15:29,542 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4866940531541001, 'Total loss': 0.4866940531541001} | train loss {'Reaction outcome loss': 0.48510288030517346, 'Total loss': 0.48510288030517346}
2022-12-05 22:15:29,543 INFO:     Found new best model at epoch 2
2022-12-05 22:15:29,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:29,543 INFO:     Epoch: 3
2022-12-05 22:15:30,331 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4598548835651441, 'Total loss': 0.4598548835651441} | train loss {'Reaction outcome loss': 0.4416628565107073, 'Total loss': 0.4416628565107073}
2022-12-05 22:15:30,331 INFO:     Found new best model at epoch 3
2022-12-05 22:15:30,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:30,332 INFO:     Epoch: 4
2022-12-05 22:15:31,121 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43034070831808174, 'Total loss': 0.43034070831808174} | train loss {'Reaction outcome loss': 0.41147514922278267, 'Total loss': 0.41147514922278267}
2022-12-05 22:15:31,122 INFO:     Found new best model at epoch 4
2022-12-05 22:15:31,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:31,122 INFO:     Epoch: 5
2022-12-05 22:15:31,911 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41863954676823184, 'Total loss': 0.41863954676823184} | train loss {'Reaction outcome loss': 0.3846797452289231, 'Total loss': 0.3846797452289231}
2022-12-05 22:15:31,912 INFO:     Found new best model at epoch 5
2022-12-05 22:15:31,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:31,912 INFO:     Epoch: 6
2022-12-05 22:15:32,702 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4254630736329339, 'Total loss': 0.4254630736329339} | train loss {'Reaction outcome loss': 0.3676718842010109, 'Total loss': 0.3676718842010109}
2022-12-05 22:15:32,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:32,702 INFO:     Epoch: 7
2022-12-05 22:15:33,491 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4190610752186992, 'Total loss': 0.4190610752186992} | train loss {'Reaction outcome loss': 0.3490267917209742, 'Total loss': 0.3490267917209742}
2022-12-05 22:15:33,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:33,491 INFO:     Epoch: 8
2022-12-05 22:15:34,285 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4087575992399996, 'Total loss': 0.4087575992399996} | train loss {'Reaction outcome loss': 0.33582407020184457, 'Total loss': 0.33582407020184457}
2022-12-05 22:15:34,286 INFO:     Found new best model at epoch 8
2022-12-05 22:15:34,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:34,287 INFO:     Epoch: 9
2022-12-05 22:15:35,076 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.40161992236971855, 'Total loss': 0.40161992236971855} | train loss {'Reaction outcome loss': 0.32271789619509056, 'Total loss': 0.32271789619509056}
2022-12-05 22:15:35,076 INFO:     Found new best model at epoch 9
2022-12-05 22:15:35,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:35,077 INFO:     Epoch: 10
2022-12-05 22:15:35,870 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.39532856016673823, 'Total loss': 0.39532856016673823} | train loss {'Reaction outcome loss': 0.3115216959495934, 'Total loss': 0.3115216959495934}
2022-12-05 22:15:35,870 INFO:     Found new best model at epoch 10
2022-12-05 22:15:35,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:35,871 INFO:     Epoch: 11
2022-12-05 22:15:36,662 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4126797751946883, 'Total loss': 0.4126797751946883} | train loss {'Reaction outcome loss': 0.30125394998764504, 'Total loss': 0.30125394998764504}
2022-12-05 22:15:36,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:36,663 INFO:     Epoch: 12
2022-12-05 22:15:37,450 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40944158285856247, 'Total loss': 0.40944158285856247} | train loss {'Reaction outcome loss': 0.2902292723558387, 'Total loss': 0.2902292723558387}
2022-12-05 22:15:37,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:37,451 INFO:     Epoch: 13
2022-12-05 22:15:38,241 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39828625236722554, 'Total loss': 0.39828625236722554} | train loss {'Reaction outcome loss': 0.2799576234148473, 'Total loss': 0.2799576234148473}
2022-12-05 22:15:38,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:38,241 INFO:     Epoch: 14
2022-12-05 22:15:39,030 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.388991693881425, 'Total loss': 0.388991693881425} | train loss {'Reaction outcome loss': 0.2718732595291673, 'Total loss': 0.2718732595291673}
2022-12-05 22:15:39,030 INFO:     Found new best model at epoch 14
2022-12-05 22:15:39,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:39,031 INFO:     Epoch: 15
2022-12-05 22:15:39,817 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3868338375944983, 'Total loss': 0.3868338375944983} | train loss {'Reaction outcome loss': 0.2648556637824798, 'Total loss': 0.2648556637824798}
2022-12-05 22:15:39,817 INFO:     Found new best model at epoch 15
2022-12-05 22:15:39,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:39,818 INFO:     Epoch: 16
2022-12-05 22:15:40,606 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3888009217652408, 'Total loss': 0.3888009217652408} | train loss {'Reaction outcome loss': 0.25842435919508644, 'Total loss': 0.25842435919508644}
2022-12-05 22:15:40,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:40,607 INFO:     Epoch: 17
2022-12-05 22:15:41,395 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41417470235716214, 'Total loss': 0.41417470235716214} | train loss {'Reaction outcome loss': 0.2507418341478523, 'Total loss': 0.2507418341478523}
2022-12-05 22:15:41,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:41,395 INFO:     Epoch: 18
2022-12-05 22:15:42,187 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3835258963094516, 'Total loss': 0.3835258963094516} | train loss {'Reaction outcome loss': 0.2454894127894421, 'Total loss': 0.2454894127894421}
2022-12-05 22:15:42,187 INFO:     Found new best model at epoch 18
2022-12-05 22:15:42,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:42,188 INFO:     Epoch: 19
2022-12-05 22:15:42,977 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40267305584116414, 'Total loss': 0.40267305584116414} | train loss {'Reaction outcome loss': 0.23663099982908795, 'Total loss': 0.23663099982908795}
2022-12-05 22:15:42,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:42,977 INFO:     Epoch: 20
2022-12-05 22:15:43,767 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3923005068844015, 'Total loss': 0.3923005068844015} | train loss {'Reaction outcome loss': 0.23196128351347786, 'Total loss': 0.23196128351347786}
2022-12-05 22:15:43,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:43,767 INFO:     Epoch: 21
2022-12-05 22:15:44,554 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39671748876571655, 'Total loss': 0.39671748876571655} | train loss {'Reaction outcome loss': 0.22781016861601752, 'Total loss': 0.22781016861601752}
2022-12-05 22:15:44,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:44,554 INFO:     Epoch: 22
2022-12-05 22:15:45,341 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39539697055112233, 'Total loss': 0.39539697055112233} | train loss {'Reaction outcome loss': 0.2239930954362665, 'Total loss': 0.2239930954362665}
2022-12-05 22:15:45,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:45,341 INFO:     Epoch: 23
2022-12-05 22:15:46,134 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39908271274444734, 'Total loss': 0.39908271274444734} | train loss {'Reaction outcome loss': 0.21949528789489853, 'Total loss': 0.21949528789489853}
2022-12-05 22:15:46,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:46,134 INFO:     Epoch: 24
2022-12-05 22:15:46,922 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3897815424610268, 'Total loss': 0.3897815424610268} | train loss {'Reaction outcome loss': 0.21226906251846528, 'Total loss': 0.21226906251846528}
2022-12-05 22:15:46,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:46,922 INFO:     Epoch: 25
2022-12-05 22:15:47,711 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3901285474950617, 'Total loss': 0.3901285474950617} | train loss {'Reaction outcome loss': 0.21225280469777633, 'Total loss': 0.21225280469777633}
2022-12-05 22:15:47,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:47,711 INFO:     Epoch: 26
2022-12-05 22:15:48,500 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38402153145183215, 'Total loss': 0.38402153145183215} | train loss {'Reaction outcome loss': 0.2070518061518669, 'Total loss': 0.2070518061518669}
2022-12-05 22:15:48,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:48,500 INFO:     Epoch: 27
2022-12-05 22:15:49,288 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4094740077853203, 'Total loss': 0.4094740077853203} | train loss {'Reaction outcome loss': 0.20247537300598864, 'Total loss': 0.20247537300598864}
2022-12-05 22:15:49,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:49,289 INFO:     Epoch: 28
2022-12-05 22:15:50,080 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39176963337443094, 'Total loss': 0.39176963337443094} | train loss {'Reaction outcome loss': 0.20009540498864894, 'Total loss': 0.20009540498864894}
2022-12-05 22:15:50,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:50,081 INFO:     Epoch: 29
2022-12-05 22:15:50,871 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39007777483625844, 'Total loss': 0.39007777483625844} | train loss {'Reaction outcome loss': 0.19809504879676565, 'Total loss': 0.19809504879676565}
2022-12-05 22:15:50,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:50,872 INFO:     Epoch: 30
2022-12-05 22:15:51,660 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39493928223171015, 'Total loss': 0.39493928223171015} | train loss {'Reaction outcome loss': 0.19253066454310808, 'Total loss': 0.19253066454310808}
2022-12-05 22:15:51,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:51,660 INFO:     Epoch: 31
2022-12-05 22:15:52,448 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3874617928469723, 'Total loss': 0.3874617928469723} | train loss {'Reaction outcome loss': 0.18942248928455674, 'Total loss': 0.18942248928455674}
2022-12-05 22:15:52,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:52,449 INFO:     Epoch: 32
2022-12-05 22:15:53,246 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3929753699763255, 'Total loss': 0.3929753699763255} | train loss {'Reaction outcome loss': 0.1877242700177796, 'Total loss': 0.1877242700177796}
2022-12-05 22:15:53,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:53,247 INFO:     Epoch: 33
2022-12-05 22:15:54,037 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3981986403973265, 'Total loss': 0.3981986403973265} | train loss {'Reaction outcome loss': 0.18481704908974317, 'Total loss': 0.18481704908974317}
2022-12-05 22:15:54,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:54,037 INFO:     Epoch: 34
2022-12-05 22:15:54,824 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3725684250450947, 'Total loss': 0.3725684250450947} | train loss {'Reaction outcome loss': 0.1823480256966182, 'Total loss': 0.1823480256966182}
2022-12-05 22:15:54,824 INFO:     Found new best model at epoch 34
2022-12-05 22:15:54,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:54,825 INFO:     Epoch: 35
2022-12-05 22:15:55,619 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3906734252179211, 'Total loss': 0.3906734252179211} | train loss {'Reaction outcome loss': 0.17991688055347424, 'Total loss': 0.17991688055347424}
2022-12-05 22:15:55,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:55,619 INFO:     Epoch: 36
2022-12-05 22:15:56,405 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3951870873570442, 'Total loss': 0.3951870873570442} | train loss {'Reaction outcome loss': 0.1756671277844176, 'Total loss': 0.1756671277844176}
2022-12-05 22:15:56,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:56,406 INFO:     Epoch: 37
2022-12-05 22:15:57,195 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39788277819752693, 'Total loss': 0.39788277819752693} | train loss {'Reaction outcome loss': 0.17496462306197808, 'Total loss': 0.17496462306197808}
2022-12-05 22:15:57,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:57,195 INFO:     Epoch: 38
2022-12-05 22:15:57,988 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39358451014215295, 'Total loss': 0.39358451014215295} | train loss {'Reaction outcome loss': 0.17274225820996322, 'Total loss': 0.17274225820996322}
2022-12-05 22:15:57,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:57,988 INFO:     Epoch: 39
2022-12-05 22:15:58,779 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.38320984030989086, 'Total loss': 0.38320984030989086} | train loss {'Reaction outcome loss': 0.1705713120194114, 'Total loss': 0.1705713120194114}
2022-12-05 22:15:58,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:58,780 INFO:     Epoch: 40
2022-12-05 22:15:59,569 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4000651587478139, 'Total loss': 0.4000651587478139} | train loss {'Reaction outcome loss': 0.16756646507704745, 'Total loss': 0.16756646507704745}
2022-12-05 22:15:59,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:15:59,570 INFO:     Epoch: 41
2022-12-05 22:16:00,360 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.397576794620942, 'Total loss': 0.397576794620942} | train loss {'Reaction outcome loss': 0.16816325803496399, 'Total loss': 0.16816325803496399}
2022-12-05 22:16:00,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:00,360 INFO:     Epoch: 42
2022-12-05 22:16:01,151 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38586235588247125, 'Total loss': 0.38586235588247125} | train loss {'Reaction outcome loss': 0.1633212539082279, 'Total loss': 0.1633212539082279}
2022-12-05 22:16:01,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:01,151 INFO:     Epoch: 43
2022-12-05 22:16:01,949 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40273724420165474, 'Total loss': 0.40273724420165474} | train loss {'Reaction outcome loss': 0.1655746053220058, 'Total loss': 0.1655746053220058}
2022-12-05 22:16:01,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:01,949 INFO:     Epoch: 44
2022-12-05 22:16:02,743 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4056988216259263, 'Total loss': 0.4056988216259263} | train loss {'Reaction outcome loss': 0.16240238616509098, 'Total loss': 0.16240238616509098}
2022-12-05 22:16:02,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:02,744 INFO:     Epoch: 45
2022-12-05 22:16:03,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39402510496703064, 'Total loss': 0.39402510496703064} | train loss {'Reaction outcome loss': 0.16294335411215316, 'Total loss': 0.16294335411215316}
2022-12-05 22:16:03,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:03,542 INFO:     Epoch: 46
2022-12-05 22:16:04,329 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3860305971042676, 'Total loss': 0.3860305971042676} | train loss {'Reaction outcome loss': 0.15874580584694536, 'Total loss': 0.15874580584694536}
2022-12-05 22:16:04,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:04,330 INFO:     Epoch: 47
2022-12-05 22:16:05,118 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41184693710370496, 'Total loss': 0.41184693710370496} | train loss {'Reaction outcome loss': 0.1550242621147511, 'Total loss': 0.1550242621147511}
2022-12-05 22:16:05,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:05,119 INFO:     Epoch: 48
2022-12-05 22:16:05,911 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39673385802995076, 'Total loss': 0.39673385802995076} | train loss {'Reaction outcome loss': 0.1587422331224899, 'Total loss': 0.1587422331224899}
2022-12-05 22:16:05,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:05,912 INFO:     Epoch: 49
2022-12-05 22:16:06,702 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39739519645544613, 'Total loss': 0.39739519645544613} | train loss {'Reaction outcome loss': 0.15460055891652497, 'Total loss': 0.15460055891652497}
2022-12-05 22:16:06,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:06,702 INFO:     Epoch: 50
2022-12-05 22:16:07,490 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39515533501451666, 'Total loss': 0.39515533501451666} | train loss {'Reaction outcome loss': 0.15645271110519463, 'Total loss': 0.15645271110519463}
2022-12-05 22:16:07,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:07,491 INFO:     Epoch: 51
2022-12-05 22:16:08,282 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3988307352093133, 'Total loss': 0.3988307352093133} | train loss {'Reaction outcome loss': 0.15261550132869459, 'Total loss': 0.15261550132869459}
2022-12-05 22:16:08,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:08,282 INFO:     Epoch: 52
2022-12-05 22:16:09,071 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3951353948902, 'Total loss': 0.3951353948902} | train loss {'Reaction outcome loss': 0.1531107212131729, 'Total loss': 0.1531107212131729}
2022-12-05 22:16:09,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:09,072 INFO:     Epoch: 53
2022-12-05 22:16:09,860 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.390862575054846, 'Total loss': 0.390862575054846} | train loss {'Reaction outcome loss': 0.1547580378700276, 'Total loss': 0.1547580378700276}
2022-12-05 22:16:09,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:09,860 INFO:     Epoch: 54
2022-12-05 22:16:10,651 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4285526382313533, 'Total loss': 0.4285526382313533} | train loss {'Reaction outcome loss': 0.15113421394204607, 'Total loss': 0.15113421394204607}
2022-12-05 22:16:10,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:10,652 INFO:     Epoch: 55
2022-12-05 22:16:11,444 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39606128923002293, 'Total loss': 0.39606128923002293} | train loss {'Reaction outcome loss': 0.15077554043002275, 'Total loss': 0.15077554043002275}
2022-12-05 22:16:11,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:11,444 INFO:     Epoch: 56
2022-12-05 22:16:12,231 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39135182005437935, 'Total loss': 0.39135182005437935} | train loss {'Reaction outcome loss': 0.14909709527404333, 'Total loss': 0.14909709527404333}
2022-12-05 22:16:12,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:12,232 INFO:     Epoch: 57
2022-12-05 22:16:13,020 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.407244417139075, 'Total loss': 0.407244417139075} | train loss {'Reaction outcome loss': 0.1447970001521159, 'Total loss': 0.1447970001521159}
2022-12-05 22:16:13,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:13,020 INFO:     Epoch: 58
2022-12-05 22:16:13,811 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.392077834430066, 'Total loss': 0.392077834430066} | train loss {'Reaction outcome loss': 0.14774317478342933, 'Total loss': 0.14774317478342933}
2022-12-05 22:16:13,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:13,811 INFO:     Epoch: 59
2022-12-05 22:16:14,604 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.390041055073115, 'Total loss': 0.390041055073115} | train loss {'Reaction outcome loss': 0.14562605554808158, 'Total loss': 0.14562605554808158}
2022-12-05 22:16:14,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:14,605 INFO:     Epoch: 60
2022-12-05 22:16:15,399 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40840582244775514, 'Total loss': 0.40840582244775514} | train loss {'Reaction outcome loss': 0.1434070214325068, 'Total loss': 0.1434070214325068}
2022-12-05 22:16:15,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:15,400 INFO:     Epoch: 61
2022-12-05 22:16:16,198 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.392559369856661, 'Total loss': 0.392559369856661} | train loss {'Reaction outcome loss': 0.143346219965998, 'Total loss': 0.143346219965998}
2022-12-05 22:16:16,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:16,198 INFO:     Epoch: 62
2022-12-05 22:16:16,996 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39316060309383, 'Total loss': 0.39316060309383} | train loss {'Reaction outcome loss': 0.1422771805631263, 'Total loss': 0.1422771805631263}
2022-12-05 22:16:16,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:16,996 INFO:     Epoch: 63
2022-12-05 22:16:17,793 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3842240473763509, 'Total loss': 0.3842240473763509} | train loss {'Reaction outcome loss': 0.1444309440194344, 'Total loss': 0.1444309440194344}
2022-12-05 22:16:17,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:17,793 INFO:     Epoch: 64
2022-12-05 22:16:18,586 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3994082748381929, 'Total loss': 0.3994082748381929} | train loss {'Reaction outcome loss': 0.14162325881877724, 'Total loss': 0.14162325881877724}
2022-12-05 22:16:18,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:18,587 INFO:     Epoch: 65
2022-12-05 22:16:19,380 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4006824598393657, 'Total loss': 0.4006824598393657} | train loss {'Reaction outcome loss': 0.1412119017571819, 'Total loss': 0.1412119017571819}
2022-12-05 22:16:19,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:19,380 INFO:     Epoch: 66
2022-12-05 22:16:20,180 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40139924531633203, 'Total loss': 0.40139924531633203} | train loss {'Reaction outcome loss': 0.13877773113852862, 'Total loss': 0.13877773113852862}
2022-12-05 22:16:20,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:20,180 INFO:     Epoch: 67
2022-12-05 22:16:20,974 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3783100497993556, 'Total loss': 0.3783100497993556} | train loss {'Reaction outcome loss': 0.14052192804460623, 'Total loss': 0.14052192804460623}
2022-12-05 22:16:20,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:20,974 INFO:     Epoch: 68
2022-12-05 22:16:21,768 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3909464759847403, 'Total loss': 0.3909464759847403} | train loss {'Reaction outcome loss': 0.1373666264344843, 'Total loss': 0.1373666264344843}
2022-12-05 22:16:21,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:21,769 INFO:     Epoch: 69
2022-12-05 22:16:22,562 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40007597555152397, 'Total loss': 0.40007597555152397} | train loss {'Reaction outcome loss': 0.13661346195303664, 'Total loss': 0.13661346195303664}
2022-12-05 22:16:22,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:22,563 INFO:     Epoch: 70
2022-12-05 22:16:23,356 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3931640400127931, 'Total loss': 0.3931640400127931} | train loss {'Reaction outcome loss': 0.13706966652249802, 'Total loss': 0.13706966652249802}
2022-12-05 22:16:23,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:23,356 INFO:     Epoch: 71
2022-12-05 22:16:24,149 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3980251992629333, 'Total loss': 0.3980251992629333} | train loss {'Reaction outcome loss': 0.13603622431353646, 'Total loss': 0.13603622431353646}
2022-12-05 22:16:24,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:24,149 INFO:     Epoch: 72
2022-12-05 22:16:24,944 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.39033494192302565, 'Total loss': 0.39033494192302565} | train loss {'Reaction outcome loss': 0.13787743414239007, 'Total loss': 0.13787743414239007}
2022-12-05 22:16:24,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:24,944 INFO:     Epoch: 73
2022-12-05 22:16:25,740 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39733276837928727, 'Total loss': 0.39733276837928727} | train loss {'Reaction outcome loss': 0.13572564177899335, 'Total loss': 0.13572564177899335}
2022-12-05 22:16:25,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:25,740 INFO:     Epoch: 74
2022-12-05 22:16:26,534 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.391945383426818, 'Total loss': 0.391945383426818} | train loss {'Reaction outcome loss': 0.1363077986757366, 'Total loss': 0.1363077986757366}
2022-12-05 22:16:26,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:26,534 INFO:     Epoch: 75
2022-12-05 22:16:27,327 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3925878364931453, 'Total loss': 0.3925878364931453} | train loss {'Reaction outcome loss': 0.13624431325160727, 'Total loss': 0.13624431325160727}
2022-12-05 22:16:27,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:27,327 INFO:     Epoch: 76
2022-12-05 22:16:28,121 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3901321120898832, 'Total loss': 0.3901321120898832} | train loss {'Reaction outcome loss': 0.13697007407187198, 'Total loss': 0.13697007407187198}
2022-12-05 22:16:28,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:28,121 INFO:     Epoch: 77
2022-12-05 22:16:28,915 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3845325464552099, 'Total loss': 0.3845325464552099} | train loss {'Reaction outcome loss': 0.13322113567050928, 'Total loss': 0.13322113567050928}
2022-12-05 22:16:28,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:28,916 INFO:     Epoch: 78
2022-12-05 22:16:29,712 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40110958503051236, 'Total loss': 0.40110958503051236} | train loss {'Reaction outcome loss': 0.13481052317941675, 'Total loss': 0.13481052317941675}
2022-12-05 22:16:29,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:29,712 INFO:     Epoch: 79
2022-12-05 22:16:30,510 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3930085055868734, 'Total loss': 0.3930085055868734} | train loss {'Reaction outcome loss': 0.13297488712230507, 'Total loss': 0.13297488712230507}
2022-12-05 22:16:30,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:30,511 INFO:     Epoch: 80
2022-12-05 22:16:31,306 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39260881529612973, 'Total loss': 0.39260881529612973} | train loss {'Reaction outcome loss': 0.13100869426009606, 'Total loss': 0.13100869426009606}
2022-12-05 22:16:31,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:31,306 INFO:     Epoch: 81
2022-12-05 22:16:32,104 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4074147262356498, 'Total loss': 0.4074147262356498} | train loss {'Reaction outcome loss': 0.13195768760099094, 'Total loss': 0.13195768760099094}
2022-12-05 22:16:32,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:32,104 INFO:     Epoch: 82
2022-12-05 22:16:32,898 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40048569068312645, 'Total loss': 0.40048569068312645} | train loss {'Reaction outcome loss': 0.1313283699735695, 'Total loss': 0.1313283699735695}
2022-12-05 22:16:32,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:32,898 INFO:     Epoch: 83
2022-12-05 22:16:33,693 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4036040929230777, 'Total loss': 0.4036040929230777} | train loss {'Reaction outcome loss': 0.1286552437029931, 'Total loss': 0.1286552437029931}
2022-12-05 22:16:33,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:33,693 INFO:     Epoch: 84
2022-12-05 22:16:34,489 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3911864391782067, 'Total loss': 0.3911864391782067} | train loss {'Reaction outcome loss': 0.12884557571794306, 'Total loss': 0.12884557571794306}
2022-12-05 22:16:34,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:34,489 INFO:     Epoch: 85
2022-12-05 22:16:35,283 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38492404771122063, 'Total loss': 0.38492404771122063} | train loss {'Reaction outcome loss': 0.13048785967486246, 'Total loss': 0.13048785967486246}
2022-12-05 22:16:35,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:35,283 INFO:     Epoch: 86
2022-12-05 22:16:36,083 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3864423129707575, 'Total loss': 0.3864423129707575} | train loss {'Reaction outcome loss': 0.12968980497775637, 'Total loss': 0.12968980497775637}
2022-12-05 22:16:36,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:36,083 INFO:     Epoch: 87
2022-12-05 22:16:36,877 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4194137479432605, 'Total loss': 0.4194137479432605} | train loss {'Reaction outcome loss': 0.1298165874061536, 'Total loss': 0.1298165874061536}
2022-12-05 22:16:36,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:36,878 INFO:     Epoch: 88
2022-12-05 22:16:37,675 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39879273115233943, 'Total loss': 0.39879273115233943} | train loss {'Reaction outcome loss': 0.1292312989505578, 'Total loss': 0.1292312989505578}
2022-12-05 22:16:37,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:37,675 INFO:     Epoch: 89
2022-12-05 22:16:38,471 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4030977991324934, 'Total loss': 0.4030977991324934} | train loss {'Reaction outcome loss': 0.1284810958392158, 'Total loss': 0.1284810958392158}
2022-12-05 22:16:38,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:38,472 INFO:     Epoch: 90
2022-12-05 22:16:39,268 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3988694694231857, 'Total loss': 0.3988694694231857} | train loss {'Reaction outcome loss': 0.12689369674391893, 'Total loss': 0.12689369674391893}
2022-12-05 22:16:39,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:39,268 INFO:     Epoch: 91
2022-12-05 22:16:40,061 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38628697949884966, 'Total loss': 0.38628697949884966} | train loss {'Reaction outcome loss': 0.1277182547641652, 'Total loss': 0.1277182547641652}
2022-12-05 22:16:40,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:40,061 INFO:     Epoch: 92
2022-12-05 22:16:40,855 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4150893167507919, 'Total loss': 0.4150893167507919} | train loss {'Reaction outcome loss': 0.12772348133124867, 'Total loss': 0.12772348133124867}
2022-12-05 22:16:40,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:40,855 INFO:     Epoch: 93
2022-12-05 22:16:41,649 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39834740317680617, 'Total loss': 0.39834740317680617} | train loss {'Reaction outcome loss': 0.12815635594710403, 'Total loss': 0.12815635594710403}
2022-12-05 22:16:41,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:41,649 INFO:     Epoch: 94
2022-12-05 22:16:42,447 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38570612093264406, 'Total loss': 0.38570612093264406} | train loss {'Reaction outcome loss': 0.12468865359468119, 'Total loss': 0.12468865359468119}
2022-12-05 22:16:42,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:42,447 INFO:     Epoch: 95
2022-12-05 22:16:43,247 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39248863023451785, 'Total loss': 0.39248863023451785} | train loss {'Reaction outcome loss': 0.12580788355244665, 'Total loss': 0.12580788355244665}
2022-12-05 22:16:43,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:43,247 INFO:     Epoch: 96
2022-12-05 22:16:44,045 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40888308225707576, 'Total loss': 0.40888308225707576} | train loss {'Reaction outcome loss': 0.12576776793872824, 'Total loss': 0.12576776793872824}
2022-12-05 22:16:44,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:44,045 INFO:     Epoch: 97
2022-12-05 22:16:44,840 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.39002364154227753, 'Total loss': 0.39002364154227753} | train loss {'Reaction outcome loss': 0.1268656060403707, 'Total loss': 0.1268656060403707}
2022-12-05 22:16:44,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:44,840 INFO:     Epoch: 98
2022-12-05 22:16:45,633 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38366788354786957, 'Total loss': 0.38366788354786957} | train loss {'Reaction outcome loss': 0.12718067693010884, 'Total loss': 0.12718067693010884}
2022-12-05 22:16:45,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:45,633 INFO:     Epoch: 99
2022-12-05 22:16:46,428 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3881966872987422, 'Total loss': 0.3881966872987422} | train loss {'Reaction outcome loss': 0.12766823278245878, 'Total loss': 0.12766823278245878}
2022-12-05 22:16:46,429 INFO:     Best model found after epoch 35 of 100.
2022-12-05 22:16:46,429 INFO:   Done with stage: TRAINING
2022-12-05 22:16:46,429 INFO:   Starting stage: EVALUATION
2022-12-05 22:16:46,560 INFO:   Done with stage: EVALUATION
2022-12-05 22:16:46,560 INFO:   Leaving out SEQ value Fold_2
2022-12-05 22:16:46,573 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:16:46,573 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:16:47,218 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:16:47,219 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:16:47,289 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:16:47,289 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:16:47,289 INFO:     No hyperparam tuning for this model
2022-12-05 22:16:47,289 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:16:47,289 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:16:47,290 INFO:     None feature selector for col prot
2022-12-05 22:16:47,290 INFO:     None feature selector for col prot
2022-12-05 22:16:47,290 INFO:     None feature selector for col prot
2022-12-05 22:16:47,291 INFO:     None feature selector for col chem
2022-12-05 22:16:47,291 INFO:     None feature selector for col chem
2022-12-05 22:16:47,291 INFO:     None feature selector for col chem
2022-12-05 22:16:47,291 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:16:47,291 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:16:47,293 INFO:     Number of params in model 215821
2022-12-05 22:16:47,296 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:16:47,296 INFO:   Starting stage: TRAINING
2022-12-05 22:16:47,357 INFO:     Val loss before train {'Reaction outcome loss': 1.0131715143268758, 'Total loss': 1.0131715143268758}
2022-12-05 22:16:47,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:47,357 INFO:     Epoch: 0
2022-12-05 22:16:48,155 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6060017848556692, 'Total loss': 0.6060017848556692} | train loss {'Reaction outcome loss': 0.8085289650600449, 'Total loss': 0.8085289650600449}
2022-12-05 22:16:48,155 INFO:     Found new best model at epoch 0
2022-12-05 22:16:48,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:48,156 INFO:     Epoch: 1
2022-12-05 22:16:48,955 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5220871716737747, 'Total loss': 0.5220871716737747} | train loss {'Reaction outcome loss': 0.5501924980024577, 'Total loss': 0.5501924980024577}
2022-12-05 22:16:48,956 INFO:     Found new best model at epoch 1
2022-12-05 22:16:48,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:48,957 INFO:     Epoch: 2
2022-12-05 22:16:49,757 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48203174634413287, 'Total loss': 0.48203174634413287} | train loss {'Reaction outcome loss': 0.47731112510810497, 'Total loss': 0.47731112510810497}
2022-12-05 22:16:49,757 INFO:     Found new best model at epoch 2
2022-12-05 22:16:49,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:49,758 INFO:     Epoch: 3
2022-12-05 22:16:50,560 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4563209732825106, 'Total loss': 0.4563209732825106} | train loss {'Reaction outcome loss': 0.43530432558203724, 'Total loss': 0.43530432558203724}
2022-12-05 22:16:50,560 INFO:     Found new best model at epoch 3
2022-12-05 22:16:50,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:50,561 INFO:     Epoch: 4
2022-12-05 22:16:51,361 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44873425737023354, 'Total loss': 0.44873425737023354} | train loss {'Reaction outcome loss': 0.40835731364937444, 'Total loss': 0.40835731364937444}
2022-12-05 22:16:51,361 INFO:     Found new best model at epoch 4
2022-12-05 22:16:51,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:51,362 INFO:     Epoch: 5
2022-12-05 22:16:52,162 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4382350578565489, 'Total loss': 0.4382350578565489} | train loss {'Reaction outcome loss': 0.38601665910680283, 'Total loss': 0.38601665910680283}
2022-12-05 22:16:52,162 INFO:     Found new best model at epoch 5
2022-12-05 22:16:52,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:52,163 INFO:     Epoch: 6
2022-12-05 22:16:52,961 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42839802479879424, 'Total loss': 0.42839802479879424} | train loss {'Reaction outcome loss': 0.36491733059468057, 'Total loss': 0.36491733059468057}
2022-12-05 22:16:52,961 INFO:     Found new best model at epoch 6
2022-12-05 22:16:52,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:52,962 INFO:     Epoch: 7
2022-12-05 22:16:53,758 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.426221967082132, 'Total loss': 0.426221967082132} | train loss {'Reaction outcome loss': 0.353041065306316, 'Total loss': 0.353041065306316}
2022-12-05 22:16:53,759 INFO:     Found new best model at epoch 7
2022-12-05 22:16:53,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:53,759 INFO:     Epoch: 8
2022-12-05 22:16:54,558 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42223487608134747, 'Total loss': 0.42223487608134747} | train loss {'Reaction outcome loss': 0.33601640332782423, 'Total loss': 0.33601640332782423}
2022-12-05 22:16:54,558 INFO:     Found new best model at epoch 8
2022-12-05 22:16:54,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:54,559 INFO:     Epoch: 9
2022-12-05 22:16:55,357 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4096954410726374, 'Total loss': 0.4096954410726374} | train loss {'Reaction outcome loss': 0.3237800181273989, 'Total loss': 0.3237800181273989}
2022-12-05 22:16:55,357 INFO:     Found new best model at epoch 9
2022-12-05 22:16:55,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:55,358 INFO:     Epoch: 10
2022-12-05 22:16:56,157 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42914884876121173, 'Total loss': 0.42914884876121173} | train loss {'Reaction outcome loss': 0.31047507529128116, 'Total loss': 0.31047507529128116}
2022-12-05 22:16:56,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:56,157 INFO:     Epoch: 11
2022-12-05 22:16:56,959 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.419038440016183, 'Total loss': 0.419038440016183} | train loss {'Reaction outcome loss': 0.3000702856915441, 'Total loss': 0.3000702856915441}
2022-12-05 22:16:56,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:56,959 INFO:     Epoch: 12
2022-12-05 22:16:57,761 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40800271047787234, 'Total loss': 0.40800271047787234} | train loss {'Reaction outcome loss': 0.2917804893997954, 'Total loss': 0.2917804893997954}
2022-12-05 22:16:57,761 INFO:     Found new best model at epoch 12
2022-12-05 22:16:57,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:57,762 INFO:     Epoch: 13
2022-12-05 22:16:58,564 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4076536660167304, 'Total loss': 0.4076536660167304} | train loss {'Reaction outcome loss': 0.2810379166593436, 'Total loss': 0.2810379166593436}
2022-12-05 22:16:58,564 INFO:     Found new best model at epoch 13
2022-12-05 22:16:58,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:58,565 INFO:     Epoch: 14
2022-12-05 22:16:59,366 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4083237424492836, 'Total loss': 0.4083237424492836} | train loss {'Reaction outcome loss': 0.2717941495239252, 'Total loss': 0.2717941495239252}
2022-12-05 22:16:59,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:16:59,366 INFO:     Epoch: 15
2022-12-05 22:17:00,165 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41722156818617473, 'Total loss': 0.41722156818617473} | train loss {'Reaction outcome loss': 0.26006351188126847, 'Total loss': 0.26006351188126847}
2022-12-05 22:17:00,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:00,165 INFO:     Epoch: 16
2022-12-05 22:17:00,965 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41301934962922876, 'Total loss': 0.41301934962922876} | train loss {'Reaction outcome loss': 0.2562992510193514, 'Total loss': 0.2562992510193514}
2022-12-05 22:17:00,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:00,965 INFO:     Epoch: 17
2022-12-05 22:17:01,764 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4048523052849553, 'Total loss': 0.4048523052849553} | train loss {'Reaction outcome loss': 0.24763694260201533, 'Total loss': 0.24763694260201533}
2022-12-05 22:17:01,766 INFO:     Found new best model at epoch 17
2022-12-05 22:17:01,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:01,767 INFO:     Epoch: 18
2022-12-05 22:17:02,568 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41684340448542073, 'Total loss': 0.41684340448542073} | train loss {'Reaction outcome loss': 0.24030977375461315, 'Total loss': 0.24030977375461315}
2022-12-05 22:17:02,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:02,568 INFO:     Epoch: 19
2022-12-05 22:17:03,366 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4022537815299901, 'Total loss': 0.4022537815299901} | train loss {'Reaction outcome loss': 0.23708974584363973, 'Total loss': 0.23708974584363973}
2022-12-05 22:17:03,366 INFO:     Found new best model at epoch 19
2022-12-05 22:17:03,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:03,367 INFO:     Epoch: 20
2022-12-05 22:17:04,165 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42268978465687146, 'Total loss': 0.42268978465687146} | train loss {'Reaction outcome loss': 0.23430990741441124, 'Total loss': 0.23430990741441124}
2022-12-05 22:17:04,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:04,165 INFO:     Epoch: 21
2022-12-05 22:17:04,963 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4112783832983537, 'Total loss': 0.4112783832983537} | train loss {'Reaction outcome loss': 0.2274922610596124, 'Total loss': 0.2274922610596124}
2022-12-05 22:17:04,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:04,964 INFO:     Epoch: 22
2022-12-05 22:17:05,763 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41268328577280045, 'Total loss': 0.41268328577280045} | train loss {'Reaction outcome loss': 0.22042780511292367, 'Total loss': 0.22042780511292367}
2022-12-05 22:17:05,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:05,763 INFO:     Epoch: 23
2022-12-05 22:17:06,569 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4349193186922507, 'Total loss': 0.4349193186922507} | train loss {'Reaction outcome loss': 0.22063672961855707, 'Total loss': 0.22063672961855707}
2022-12-05 22:17:06,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:06,569 INFO:     Epoch: 24
2022-12-05 22:17:07,371 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40843764336949046, 'Total loss': 0.40843764336949046} | train loss {'Reaction outcome loss': 0.21289798845103394, 'Total loss': 0.21289798845103394}
2022-12-05 22:17:07,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:07,371 INFO:     Epoch: 25
2022-12-05 22:17:08,169 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41389857029372995, 'Total loss': 0.41389857029372995} | train loss {'Reaction outcome loss': 0.2146308306106913, 'Total loss': 0.2146308306106913}
2022-12-05 22:17:08,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:08,170 INFO:     Epoch: 26
2022-12-05 22:17:08,971 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4242384962060235, 'Total loss': 0.4242384962060235} | train loss {'Reaction outcome loss': 0.20867349364255605, 'Total loss': 0.20867349364255605}
2022-12-05 22:17:08,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:08,971 INFO:     Epoch: 27
2022-12-05 22:17:09,774 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4119197946380485, 'Total loss': 0.4119197946380485} | train loss {'Reaction outcome loss': 0.2040593851845983, 'Total loss': 0.2040593851845983}
2022-12-05 22:17:09,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:09,774 INFO:     Epoch: 28
2022-12-05 22:17:10,575 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4197984476658431, 'Total loss': 0.4197984476658431} | train loss {'Reaction outcome loss': 0.19487930685922744, 'Total loss': 0.19487930685922744}
2022-12-05 22:17:10,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:10,575 INFO:     Epoch: 29
2022-12-05 22:17:11,373 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4272175478664311, 'Total loss': 0.4272175478664311} | train loss {'Reaction outcome loss': 0.1935231362201786, 'Total loss': 0.1935231362201786}
2022-12-05 22:17:11,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:11,373 INFO:     Epoch: 30
2022-12-05 22:17:12,172 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41569795222444966, 'Total loss': 0.41569795222444966} | train loss {'Reaction outcome loss': 0.19362700166866967, 'Total loss': 0.19362700166866967}
2022-12-05 22:17:12,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:12,172 INFO:     Epoch: 31
2022-12-05 22:17:12,974 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4097285568714142, 'Total loss': 0.4097285568714142} | train loss {'Reaction outcome loss': 0.18757264779858018, 'Total loss': 0.18757264779858018}
2022-12-05 22:17:12,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:12,974 INFO:     Epoch: 32
2022-12-05 22:17:13,772 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42067544467069884, 'Total loss': 0.42067544467069884} | train loss {'Reaction outcome loss': 0.18255779347740686, 'Total loss': 0.18255779347740686}
2022-12-05 22:17:13,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:13,772 INFO:     Epoch: 33
2022-12-05 22:17:14,575 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4262776737186042, 'Total loss': 0.4262776737186042} | train loss {'Reaction outcome loss': 0.1881476167046469, 'Total loss': 0.1881476167046469}
2022-12-05 22:17:14,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:14,575 INFO:     Epoch: 34
2022-12-05 22:17:15,374 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4141199361871589, 'Total loss': 0.4141199361871589} | train loss {'Reaction outcome loss': 0.1859068301796672, 'Total loss': 0.1859068301796672}
2022-12-05 22:17:15,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:15,374 INFO:     Epoch: 35
2022-12-05 22:17:16,172 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4269414493306117, 'Total loss': 0.4269414493306117} | train loss {'Reaction outcome loss': 0.18052305225358317, 'Total loss': 0.18052305225358317}
2022-12-05 22:17:16,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:16,172 INFO:     Epoch: 36
2022-12-05 22:17:16,970 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43173040923747147, 'Total loss': 0.43173040923747147} | train loss {'Reaction outcome loss': 0.17732614836832772, 'Total loss': 0.17732614836832772}
2022-12-05 22:17:16,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:16,971 INFO:     Epoch: 37
2022-12-05 22:17:17,776 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4284665278074416, 'Total loss': 0.4284665278074416} | train loss {'Reaction outcome loss': 0.1755061288956206, 'Total loss': 0.1755061288956206}
2022-12-05 22:17:17,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:17,776 INFO:     Epoch: 38
2022-12-05 22:17:18,579 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41892561384222726, 'Total loss': 0.41892561384222726} | train loss {'Reaction outcome loss': 0.1787624519604903, 'Total loss': 0.1787624519604903}
2022-12-05 22:17:18,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:18,580 INFO:     Epoch: 39
2022-12-05 22:17:19,381 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4240495538000356, 'Total loss': 0.4240495538000356} | train loss {'Reaction outcome loss': 0.17199985256139566, 'Total loss': 0.17199985256139566}
2022-12-05 22:17:19,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:19,381 INFO:     Epoch: 40
2022-12-05 22:17:20,178 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4324294443834912, 'Total loss': 0.4324294443834912} | train loss {'Reaction outcome loss': 0.16897388947335815, 'Total loss': 0.16897388947335815}
2022-12-05 22:17:20,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:20,179 INFO:     Epoch: 41
2022-12-05 22:17:20,981 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4355467419055375, 'Total loss': 0.4355467419055375} | train loss {'Reaction outcome loss': 0.16839284537103677, 'Total loss': 0.16839284537103677}
2022-12-05 22:17:20,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:20,981 INFO:     Epoch: 42
2022-12-05 22:17:21,779 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4324531358751384, 'Total loss': 0.4324531358751384} | train loss {'Reaction outcome loss': 0.16297109910713034, 'Total loss': 0.16297109910713034}
2022-12-05 22:17:21,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:21,780 INFO:     Epoch: 43
2022-12-05 22:17:22,578 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44123588366941974, 'Total loss': 0.44123588366941974} | train loss {'Reaction outcome loss': 0.15874691502104404, 'Total loss': 0.15874691502104404}
2022-12-05 22:17:22,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:22,578 INFO:     Epoch: 44
2022-12-05 22:17:23,376 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4368968599221923, 'Total loss': 0.4368968599221923} | train loss {'Reaction outcome loss': 0.15853438221732616, 'Total loss': 0.15853438221732616}
2022-12-05 22:17:23,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:23,376 INFO:     Epoch: 45
2022-12-05 22:17:24,177 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42728228359059856, 'Total loss': 0.42728228359059856} | train loss {'Reaction outcome loss': 0.16144798411742636, 'Total loss': 0.16144798411742636}
2022-12-05 22:17:24,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:24,177 INFO:     Epoch: 46
2022-12-05 22:17:24,976 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4364869787611745, 'Total loss': 0.4364869787611745} | train loss {'Reaction outcome loss': 0.15950688494648407, 'Total loss': 0.15950688494648407}
2022-12-05 22:17:24,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:24,977 INFO:     Epoch: 47
2022-12-05 22:17:25,776 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46445146744901483, 'Total loss': 0.46445146744901483} | train loss {'Reaction outcome loss': 0.15370581344690037, 'Total loss': 0.15370581344690037}
2022-12-05 22:17:25,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:25,776 INFO:     Epoch: 48
2022-12-05 22:17:26,579 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44733673156323756, 'Total loss': 0.44733673156323756} | train loss {'Reaction outcome loss': 0.1578835048580821, 'Total loss': 0.1578835048580821}
2022-12-05 22:17:26,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:26,579 INFO:     Epoch: 49
2022-12-05 22:17:27,378 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4449394683946263, 'Total loss': 0.4449394683946263} | train loss {'Reaction outcome loss': 0.1540154372813248, 'Total loss': 0.1540154372813248}
2022-12-05 22:17:27,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:27,378 INFO:     Epoch: 50
2022-12-05 22:17:28,177 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4415836232629689, 'Total loss': 0.4415836232629689} | train loss {'Reaction outcome loss': 0.15170635662309312, 'Total loss': 0.15170635662309312}
2022-12-05 22:17:28,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:28,177 INFO:     Epoch: 51
2022-12-05 22:17:28,978 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45325448364019394, 'Total loss': 0.45325448364019394} | train loss {'Reaction outcome loss': 0.15130116874050453, 'Total loss': 0.15130116874050453}
2022-12-05 22:17:28,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:28,979 INFO:     Epoch: 52
2022-12-05 22:17:29,778 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4469718472524123, 'Total loss': 0.4469718472524123} | train loss {'Reaction outcome loss': 0.14983880405996733, 'Total loss': 0.14983880405996733}
2022-12-05 22:17:29,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:29,779 INFO:     Epoch: 53
2022-12-05 22:17:30,584 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45373935862021014, 'Total loss': 0.45373935862021014} | train loss {'Reaction outcome loss': 0.15074821339113267, 'Total loss': 0.15074821339113267}
2022-12-05 22:17:30,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:30,584 INFO:     Epoch: 54
2022-12-05 22:17:31,388 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44152843444184825, 'Total loss': 0.44152843444184825} | train loss {'Reaction outcome loss': 0.15496540968476036, 'Total loss': 0.15496540968476036}
2022-12-05 22:17:31,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:31,388 INFO:     Epoch: 55
2022-12-05 22:17:32,187 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.45414395935156127, 'Total loss': 0.45414395935156127} | train loss {'Reaction outcome loss': 0.14925527433121977, 'Total loss': 0.14925527433121977}
2022-12-05 22:17:32,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:32,187 INFO:     Epoch: 56
2022-12-05 22:17:32,989 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.462735888632861, 'Total loss': 0.462735888632861} | train loss {'Reaction outcome loss': 0.14389077336470849, 'Total loss': 0.14389077336470849}
2022-12-05 22:17:32,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:32,990 INFO:     Epoch: 57
2022-12-05 22:17:33,790 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4509641236879609, 'Total loss': 0.4509641236879609} | train loss {'Reaction outcome loss': 0.1435826571077591, 'Total loss': 0.1435826571077591}
2022-12-05 22:17:33,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:33,791 INFO:     Epoch: 58
2022-12-05 22:17:34,591 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4477440982379697, 'Total loss': 0.4477440982379697} | train loss {'Reaction outcome loss': 0.14386778980161738, 'Total loss': 0.14386778980161738}
2022-12-05 22:17:34,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:34,591 INFO:     Epoch: 59
2022-12-05 22:17:35,391 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4496613900092515, 'Total loss': 0.4496613900092515} | train loss {'Reaction outcome loss': 0.14585377045375433, 'Total loss': 0.14585377045375433}
2022-12-05 22:17:35,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:35,392 INFO:     Epoch: 60
2022-12-05 22:17:36,190 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4437171918424693, 'Total loss': 0.4437171918424693} | train loss {'Reaction outcome loss': 0.1438486496545563, 'Total loss': 0.1438486496545563}
2022-12-05 22:17:36,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:36,191 INFO:     Epoch: 61
2022-12-05 22:17:36,993 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4618041862479665, 'Total loss': 0.4618041862479665} | train loss {'Reaction outcome loss': 0.1409910648442835, 'Total loss': 0.1409910648442835}
2022-12-05 22:17:36,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:36,993 INFO:     Epoch: 62
2022-12-05 22:17:37,797 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45397685129534116, 'Total loss': 0.45397685129534116} | train loss {'Reaction outcome loss': 0.14067981173548288, 'Total loss': 0.14067981173548288}
2022-12-05 22:17:37,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:37,797 INFO:     Epoch: 63
2022-12-05 22:17:38,604 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4570246044207703, 'Total loss': 0.4570246044207703} | train loss {'Reaction outcome loss': 0.1379646798181027, 'Total loss': 0.1379646798181027}
2022-12-05 22:17:38,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:38,605 INFO:     Epoch: 64
2022-12-05 22:17:39,403 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46575307846069336, 'Total loss': 0.46575307846069336} | train loss {'Reaction outcome loss': 0.13920669908812533, 'Total loss': 0.13920669908812533}
2022-12-05 22:17:39,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:39,404 INFO:     Epoch: 65
2022-12-05 22:17:40,209 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4586848755451766, 'Total loss': 0.4586848755451766} | train loss {'Reaction outcome loss': 0.13825399898791965, 'Total loss': 0.13825399898791965}
2022-12-05 22:17:40,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:40,209 INFO:     Epoch: 66
2022-12-05 22:17:41,013 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47752373496239836, 'Total loss': 0.47752373496239836} | train loss {'Reaction outcome loss': 0.13811030866378382, 'Total loss': 0.13811030866378382}
2022-12-05 22:17:41,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:41,014 INFO:     Epoch: 67
2022-12-05 22:17:41,815 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44845579530705104, 'Total loss': 0.44845579530705104} | train loss {'Reaction outcome loss': 0.13803583026867405, 'Total loss': 0.13803583026867405}
2022-12-05 22:17:41,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:41,816 INFO:     Epoch: 68
2022-12-05 22:17:42,615 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4698474901643666, 'Total loss': 0.4698474901643666} | train loss {'Reaction outcome loss': 0.13850734896414918, 'Total loss': 0.13850734896414918}
2022-12-05 22:17:42,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:42,615 INFO:     Epoch: 69
2022-12-05 22:17:43,414 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4680295456200838, 'Total loss': 0.4680295456200838} | train loss {'Reaction outcome loss': 0.143352640438297, 'Total loss': 0.143352640438297}
2022-12-05 22:17:43,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:43,414 INFO:     Epoch: 70
2022-12-05 22:17:44,211 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4576687711206349, 'Total loss': 0.4576687711206349} | train loss {'Reaction outcome loss': 0.13548684703951575, 'Total loss': 0.13548684703951575}
2022-12-05 22:17:44,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:44,212 INFO:     Epoch: 71
2022-12-05 22:17:45,013 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45422613857821986, 'Total loss': 0.45422613857821986} | train loss {'Reaction outcome loss': 0.13351506791464035, 'Total loss': 0.13351506791464035}
2022-12-05 22:17:45,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:45,013 INFO:     Epoch: 72
2022-12-05 22:17:45,811 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47252389636229386, 'Total loss': 0.47252389636229386} | train loss {'Reaction outcome loss': 0.13344398599404556, 'Total loss': 0.13344398599404556}
2022-12-05 22:17:45,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:45,811 INFO:     Epoch: 73
2022-12-05 22:17:46,621 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.469299967316064, 'Total loss': 0.469299967316064} | train loss {'Reaction outcome loss': 0.14033248065075335, 'Total loss': 0.14033248065075335}
2022-12-05 22:17:46,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:46,621 INFO:     Epoch: 74
2022-12-05 22:17:47,424 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4547100624238903, 'Total loss': 0.4547100624238903} | train loss {'Reaction outcome loss': 0.13236519634471036, 'Total loss': 0.13236519634471036}
2022-12-05 22:17:47,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:47,424 INFO:     Epoch: 75
2022-12-05 22:17:48,223 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46973125060850923, 'Total loss': 0.46973125060850923} | train loss {'Reaction outcome loss': 0.13280332150684315, 'Total loss': 0.13280332150684315}
2022-12-05 22:17:48,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:48,223 INFO:     Epoch: 76
2022-12-05 22:17:49,028 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46680380776524544, 'Total loss': 0.46680380776524544} | train loss {'Reaction outcome loss': 0.1335617594443533, 'Total loss': 0.1335617594443533}
2022-12-05 22:17:49,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:49,028 INFO:     Epoch: 77
2022-12-05 22:17:49,829 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4656794944947416, 'Total loss': 0.4656794944947416} | train loss {'Reaction outcome loss': 0.1293681724994304, 'Total loss': 0.1293681724994304}
2022-12-05 22:17:49,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:49,829 INFO:     Epoch: 78
2022-12-05 22:17:50,628 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.474477707831697, 'Total loss': 0.474477707831697} | train loss {'Reaction outcome loss': 0.13265546958757798, 'Total loss': 0.13265546958757798}
2022-12-05 22:17:50,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:50,628 INFO:     Epoch: 79
2022-12-05 22:17:51,427 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46497131274505094, 'Total loss': 0.46497131274505094} | train loss {'Reaction outcome loss': 0.1318845790528093, 'Total loss': 0.1318845790528093}
2022-12-05 22:17:51,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:51,427 INFO:     Epoch: 80
2022-12-05 22:17:52,227 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4810872061008757, 'Total loss': 0.4810872061008757} | train loss {'Reaction outcome loss': 0.1288133730750384, 'Total loss': 0.1288133730750384}
2022-12-05 22:17:52,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:52,227 INFO:     Epoch: 81
2022-12-05 22:17:53,029 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46025238050655887, 'Total loss': 0.46025238050655887} | train loss {'Reaction outcome loss': 0.12881124534018276, 'Total loss': 0.12881124534018276}
2022-12-05 22:17:53,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:53,029 INFO:     Epoch: 82
2022-12-05 22:17:53,827 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4691175679591569, 'Total loss': 0.4691175679591569} | train loss {'Reaction outcome loss': 0.1280974527266676, 'Total loss': 0.1280974527266676}
2022-12-05 22:17:53,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:53,828 INFO:     Epoch: 83
2022-12-05 22:17:54,632 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46503674594516103, 'Total loss': 0.46503674594516103} | train loss {'Reaction outcome loss': 0.128670440421172, 'Total loss': 0.128670440421172}
2022-12-05 22:17:54,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:54,632 INFO:     Epoch: 84
2022-12-05 22:17:55,441 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49377953565933486, 'Total loss': 0.49377953565933486} | train loss {'Reaction outcome loss': 0.12674472220821745, 'Total loss': 0.12674472220821745}
2022-12-05 22:17:55,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:55,441 INFO:     Epoch: 85
2022-12-05 22:17:56,245 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4787846153432673, 'Total loss': 0.4787846153432673} | train loss {'Reaction outcome loss': 0.13030241167753454, 'Total loss': 0.13030241167753454}
2022-12-05 22:17:56,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:56,245 INFO:     Epoch: 86
2022-12-05 22:17:57,044 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47783932530067186, 'Total loss': 0.47783932530067186} | train loss {'Reaction outcome loss': 0.13172798627904553, 'Total loss': 0.13172798627904553}
2022-12-05 22:17:57,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:57,044 INFO:     Epoch: 87
2022-12-05 22:17:57,845 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4938728961754929, 'Total loss': 0.4938728961754929} | train loss {'Reaction outcome loss': 0.125715175922583, 'Total loss': 0.125715175922583}
2022-12-05 22:17:57,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:57,846 INFO:     Epoch: 88
2022-12-05 22:17:58,645 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.465229946103963, 'Total loss': 0.465229946103963} | train loss {'Reaction outcome loss': 0.12612352694614756, 'Total loss': 0.12612352694614756}
2022-12-05 22:17:58,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:58,645 INFO:     Epoch: 89
2022-12-05 22:17:59,445 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47292213260450144, 'Total loss': 0.47292213260450144} | train loss {'Reaction outcome loss': 0.1302100318193677, 'Total loss': 0.1302100318193677}
2022-12-05 22:17:59,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:17:59,445 INFO:     Epoch: 90
2022-12-05 22:18:00,249 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4759349406442859, 'Total loss': 0.4759349406442859} | train loss {'Reaction outcome loss': 0.12788638905791738, 'Total loss': 0.12788638905791738}
2022-12-05 22:18:00,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:00,249 INFO:     Epoch: 91
2022-12-05 22:18:01,056 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46697971190918575, 'Total loss': 0.46697971190918575} | train loss {'Reaction outcome loss': 0.12506455071421288, 'Total loss': 0.12506455071421288}
2022-12-05 22:18:01,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:01,056 INFO:     Epoch: 92
2022-12-05 22:18:01,859 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4736000108109279, 'Total loss': 0.4736000108109279} | train loss {'Reaction outcome loss': 0.1297337579515457, 'Total loss': 0.1297337579515457}
2022-12-05 22:18:01,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:01,859 INFO:     Epoch: 93
2022-12-05 22:18:02,658 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4628307551822879, 'Total loss': 0.4628307551822879} | train loss {'Reaction outcome loss': 0.12301769072137139, 'Total loss': 0.12301769072137139}
2022-12-05 22:18:02,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:02,658 INFO:     Epoch: 94
2022-12-05 22:18:03,460 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47271024469624867, 'Total loss': 0.47271024469624867} | train loss {'Reaction outcome loss': 0.12698499893068302, 'Total loss': 0.12698499893068302}
2022-12-05 22:18:03,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:03,460 INFO:     Epoch: 95
2022-12-05 22:18:04,262 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48145989125425165, 'Total loss': 0.48145989125425165} | train loss {'Reaction outcome loss': 0.12307634472693571, 'Total loss': 0.12307634472693571}
2022-12-05 22:18:04,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:04,263 INFO:     Epoch: 96
2022-12-05 22:18:05,067 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46099926980043, 'Total loss': 0.46099926980043} | train loss {'Reaction outcome loss': 0.12328165264136577, 'Total loss': 0.12328165264136577}
2022-12-05 22:18:05,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:05,067 INFO:     Epoch: 97
2022-12-05 22:18:05,869 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46799564226107165, 'Total loss': 0.46799564226107165} | train loss {'Reaction outcome loss': 0.12398183610109303, 'Total loss': 0.12398183610109303}
2022-12-05 22:18:05,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:05,869 INFO:     Epoch: 98
2022-12-05 22:18:06,669 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4675495560196313, 'Total loss': 0.4675495560196313} | train loss {'Reaction outcome loss': 0.12489101446803041, 'Total loss': 0.12489101446803041}
2022-12-05 22:18:06,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:06,669 INFO:     Epoch: 99
2022-12-05 22:18:07,471 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.47226922755891626, 'Total loss': 0.47226922755891626} | train loss {'Reaction outcome loss': 0.1242488705381555, 'Total loss': 0.1242488705381555}
2022-12-05 22:18:07,471 INFO:     Best model found after epoch 20 of 100.
2022-12-05 22:18:07,472 INFO:   Done with stage: TRAINING
2022-12-05 22:18:07,472 INFO:   Starting stage: EVALUATION
2022-12-05 22:18:07,597 INFO:   Done with stage: EVALUATION
2022-12-05 22:18:07,598 INFO:   Leaving out SEQ value Fold_3
2022-12-05 22:18:07,610 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:18:07,610 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:18:08,257 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:18:08,257 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:18:08,326 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:18:08,327 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:18:08,327 INFO:     No hyperparam tuning for this model
2022-12-05 22:18:08,327 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:18:08,327 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:18:08,327 INFO:     None feature selector for col prot
2022-12-05 22:18:08,327 INFO:     None feature selector for col prot
2022-12-05 22:18:08,328 INFO:     None feature selector for col prot
2022-12-05 22:18:08,328 INFO:     None feature selector for col chem
2022-12-05 22:18:08,328 INFO:     None feature selector for col chem
2022-12-05 22:18:08,328 INFO:     None feature selector for col chem
2022-12-05 22:18:08,328 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:18:08,328 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:18:08,330 INFO:     Number of params in model 215821
2022-12-05 22:18:08,334 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:18:08,334 INFO:   Starting stage: TRAINING
2022-12-05 22:18:08,395 INFO:     Val loss before train {'Reaction outcome loss': 1.0182752080939033, 'Total loss': 1.0182752080939033}
2022-12-05 22:18:08,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:08,395 INFO:     Epoch: 0
2022-12-05 22:18:09,194 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6030401858416471, 'Total loss': 0.6030401858416471} | train loss {'Reaction outcome loss': 0.7897116655280233, 'Total loss': 0.7897116655280233}
2022-12-05 22:18:09,194 INFO:     Found new best model at epoch 0
2022-12-05 22:18:09,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:09,195 INFO:     Epoch: 1
2022-12-05 22:18:09,996 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5294501520693302, 'Total loss': 0.5294501520693302} | train loss {'Reaction outcome loss': 0.5390619627739254, 'Total loss': 0.5390619627739254}
2022-12-05 22:18:09,997 INFO:     Found new best model at epoch 1
2022-12-05 22:18:09,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:09,997 INFO:     Epoch: 2
2022-12-05 22:18:10,801 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4931699948554689, 'Total loss': 0.4931699948554689} | train loss {'Reaction outcome loss': 0.47136101518806656, 'Total loss': 0.47136101518806656}
2022-12-05 22:18:10,802 INFO:     Found new best model at epoch 2
2022-12-05 22:18:10,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:10,803 INFO:     Epoch: 3
2022-12-05 22:18:11,602 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46821774406866595, 'Total loss': 0.46821774406866595} | train loss {'Reaction outcome loss': 0.43077009927617155, 'Total loss': 0.43077009927617155}
2022-12-05 22:18:11,602 INFO:     Found new best model at epoch 3
2022-12-05 22:18:11,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:11,603 INFO:     Epoch: 4
2022-12-05 22:18:12,400 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45568006350235507, 'Total loss': 0.45568006350235507} | train loss {'Reaction outcome loss': 0.39583575544569655, 'Total loss': 0.39583575544569655}
2022-12-05 22:18:12,400 INFO:     Found new best model at epoch 4
2022-12-05 22:18:12,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:12,401 INFO:     Epoch: 5
2022-12-05 22:18:13,198 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45033168589526956, 'Total loss': 0.45033168589526956} | train loss {'Reaction outcome loss': 0.3765156706455748, 'Total loss': 0.3765156706455748}
2022-12-05 22:18:13,198 INFO:     Found new best model at epoch 5
2022-12-05 22:18:13,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:13,199 INFO:     Epoch: 6
2022-12-05 22:18:13,999 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43369549986991013, 'Total loss': 0.43369549986991013} | train loss {'Reaction outcome loss': 0.3554579092657216, 'Total loss': 0.3554579092657216}
2022-12-05 22:18:13,999 INFO:     Found new best model at epoch 6
2022-12-05 22:18:14,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:14,000 INFO:     Epoch: 7
2022-12-05 22:18:14,797 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4518146382814104, 'Total loss': 0.4518146382814104} | train loss {'Reaction outcome loss': 0.34208192715519353, 'Total loss': 0.34208192715519353}
2022-12-05 22:18:14,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:14,797 INFO:     Epoch: 8
2022-12-05 22:18:15,595 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43928398784588685, 'Total loss': 0.43928398784588685} | train loss {'Reaction outcome loss': 0.32312306113963424, 'Total loss': 0.32312306113963424}
2022-12-05 22:18:15,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:15,596 INFO:     Epoch: 9
2022-12-05 22:18:16,398 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4244894676587798, 'Total loss': 0.4244894676587798} | train loss {'Reaction outcome loss': 0.3086520555742115, 'Total loss': 0.3086520555742115}
2022-12-05 22:18:16,398 INFO:     Found new best model at epoch 9
2022-12-05 22:18:16,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:16,399 INFO:     Epoch: 10
2022-12-05 22:18:17,202 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4195558841932904, 'Total loss': 0.4195558841932904} | train loss {'Reaction outcome loss': 0.29874319884820505, 'Total loss': 0.29874319884820505}
2022-12-05 22:18:17,202 INFO:     Found new best model at epoch 10
2022-12-05 22:18:17,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:17,203 INFO:     Epoch: 11
2022-12-05 22:18:18,002 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42413281344554643, 'Total loss': 0.42413281344554643} | train loss {'Reaction outcome loss': 0.28771164156647344, 'Total loss': 0.28771164156647344}
2022-12-05 22:18:18,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:18,002 INFO:     Epoch: 12
2022-12-05 22:18:18,801 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4228241535072977, 'Total loss': 0.4228241535072977} | train loss {'Reaction outcome loss': 0.2837672857680784, 'Total loss': 0.2837672857680784}
2022-12-05 22:18:18,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:18,802 INFO:     Epoch: 13
2022-12-05 22:18:19,605 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43566028299656784, 'Total loss': 0.43566028299656784} | train loss {'Reaction outcome loss': 0.2650545586733834, 'Total loss': 0.2650545586733834}
2022-12-05 22:18:19,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:19,605 INFO:     Epoch: 14
2022-12-05 22:18:20,406 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4264713363213973, 'Total loss': 0.4264713363213973} | train loss {'Reaction outcome loss': 0.2561648518171327, 'Total loss': 0.2561648518171327}
2022-12-05 22:18:20,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:20,406 INFO:     Epoch: 15
2022-12-05 22:18:21,208 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42666347087784245, 'Total loss': 0.42666347087784245} | train loss {'Reaction outcome loss': 0.2494040734251501, 'Total loss': 0.2494040734251501}
2022-12-05 22:18:21,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:21,208 INFO:     Epoch: 16
2022-12-05 22:18:22,014 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4045346458865838, 'Total loss': 0.4045346458865838} | train loss {'Reaction outcome loss': 0.24127840449814855, 'Total loss': 0.24127840449814855}
2022-12-05 22:18:22,014 INFO:     Found new best model at epoch 16
2022-12-05 22:18:22,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:22,015 INFO:     Epoch: 17
2022-12-05 22:18:22,816 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42418856207620015, 'Total loss': 0.42418856207620015} | train loss {'Reaction outcome loss': 0.23699485860493502, 'Total loss': 0.23699485860493502}
2022-12-05 22:18:22,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:22,817 INFO:     Epoch: 18
2022-12-05 22:18:23,616 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4290755682370879, 'Total loss': 0.4290755682370879} | train loss {'Reaction outcome loss': 0.23367256929094976, 'Total loss': 0.23367256929094976}
2022-12-05 22:18:23,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:23,617 INFO:     Epoch: 19
2022-12-05 22:18:24,413 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42820108580318367, 'Total loss': 0.42820108580318367} | train loss {'Reaction outcome loss': 0.22887605244693485, 'Total loss': 0.22887605244693485}
2022-12-05 22:18:24,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:24,413 INFO:     Epoch: 20
2022-12-05 22:18:25,210 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42671813849698415, 'Total loss': 0.42671813849698415} | train loss {'Reaction outcome loss': 0.22063099610268588, 'Total loss': 0.22063099610268588}
2022-12-05 22:18:25,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:25,210 INFO:     Epoch: 21
2022-12-05 22:18:26,006 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4350290684537454, 'Total loss': 0.4350290684537454} | train loss {'Reaction outcome loss': 0.21722103610091847, 'Total loss': 0.21722103610091847}
2022-12-05 22:18:26,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:26,006 INFO:     Epoch: 22
2022-12-05 22:18:26,808 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42331327497959137, 'Total loss': 0.42331327497959137} | train loss {'Reaction outcome loss': 0.21667929875064898, 'Total loss': 0.21667929875064898}
2022-12-05 22:18:26,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:26,808 INFO:     Epoch: 23
2022-12-05 22:18:27,604 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42904233221303334, 'Total loss': 0.42904233221303334} | train loss {'Reaction outcome loss': 0.20278832179151082, 'Total loss': 0.20278832179151082}
2022-12-05 22:18:27,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:27,604 INFO:     Epoch: 24
2022-12-05 22:18:28,403 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4397982050749389, 'Total loss': 0.4397982050749389} | train loss {'Reaction outcome loss': 0.19966192290409343, 'Total loss': 0.19966192290409343}
2022-12-05 22:18:28,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:28,403 INFO:     Epoch: 25
2022-12-05 22:18:29,199 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4301609495146708, 'Total loss': 0.4301609495146708} | train loss {'Reaction outcome loss': 0.19445461935178954, 'Total loss': 0.19445461935178954}
2022-12-05 22:18:29,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:29,200 INFO:     Epoch: 26
2022-12-05 22:18:29,996 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42329042879017914, 'Total loss': 0.42329042879017914} | train loss {'Reaction outcome loss': 0.19296946169182597, 'Total loss': 0.19296946169182597}
2022-12-05 22:18:29,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:29,996 INFO:     Epoch: 27
2022-12-05 22:18:30,793 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4298819615082307, 'Total loss': 0.4298819615082307} | train loss {'Reaction outcome loss': 0.18962869777340396, 'Total loss': 0.18962869777340396}
2022-12-05 22:18:30,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:30,793 INFO:     Epoch: 28
2022-12-05 22:18:31,589 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4438481036234986, 'Total loss': 0.4438481036234986} | train loss {'Reaction outcome loss': 0.18705889829981182, 'Total loss': 0.18705889829981182}
2022-12-05 22:18:31,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:31,589 INFO:     Epoch: 29
2022-12-05 22:18:32,389 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43562544306570833, 'Total loss': 0.43562544306570833} | train loss {'Reaction outcome loss': 0.18129714400420788, 'Total loss': 0.18129714400420788}
2022-12-05 22:18:32,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:32,390 INFO:     Epoch: 30
2022-12-05 22:18:33,187 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.445319737392393, 'Total loss': 0.445319737392393} | train loss {'Reaction outcome loss': 0.18127559315458483, 'Total loss': 0.18127559315458483}
2022-12-05 22:18:33,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:33,187 INFO:     Epoch: 31
2022-12-05 22:18:33,989 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4417359144850211, 'Total loss': 0.4417359144850211} | train loss {'Reaction outcome loss': 0.17816722777630636, 'Total loss': 0.17816722777630636}
2022-12-05 22:18:33,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:33,989 INFO:     Epoch: 32
2022-12-05 22:18:34,792 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44548359445550223, 'Total loss': 0.44548359445550223} | train loss {'Reaction outcome loss': 0.17530206873304086, 'Total loss': 0.17530206873304086}
2022-12-05 22:18:34,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:34,792 INFO:     Epoch: 33
2022-12-05 22:18:35,593 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43373665924776683, 'Total loss': 0.43373665924776683} | train loss {'Reaction outcome loss': 0.17039731788912765, 'Total loss': 0.17039731788912765}
2022-12-05 22:18:35,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:35,594 INFO:     Epoch: 34
2022-12-05 22:18:36,391 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44146858291192487, 'Total loss': 0.44146858291192487} | train loss {'Reaction outcome loss': 0.17123693454377203, 'Total loss': 0.17123693454377203}
2022-12-05 22:18:36,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:36,391 INFO:     Epoch: 35
2022-12-05 22:18:37,191 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4454315443607894, 'Total loss': 0.4454315443607894} | train loss {'Reaction outcome loss': 0.1656542694203646, 'Total loss': 0.1656542694203646}
2022-12-05 22:18:37,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:37,191 INFO:     Epoch: 36
2022-12-05 22:18:37,990 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4448367107490247, 'Total loss': 0.4448367107490247} | train loss {'Reaction outcome loss': 0.166202073004323, 'Total loss': 0.166202073004323}
2022-12-05 22:18:37,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:37,991 INFO:     Epoch: 37
2022-12-05 22:18:38,794 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46617142923853616, 'Total loss': 0.46617142923853616} | train loss {'Reaction outcome loss': 0.16260881457187476, 'Total loss': 0.16260881457187476}
2022-12-05 22:18:38,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:38,795 INFO:     Epoch: 38
2022-12-05 22:18:39,599 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4478353827514432, 'Total loss': 0.4478353827514432} | train loss {'Reaction outcome loss': 0.16269882983760908, 'Total loss': 0.16269882983760908}
2022-12-05 22:18:39,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:39,599 INFO:     Epoch: 39
2022-12-05 22:18:40,398 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44803025234829297, 'Total loss': 0.44803025234829297} | train loss {'Reaction outcome loss': 0.16102844636570587, 'Total loss': 0.16102844636570587}
2022-12-05 22:18:40,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:40,398 INFO:     Epoch: 40
2022-12-05 22:18:41,198 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4429696093906056, 'Total loss': 0.4429696093906056} | train loss {'Reaction outcome loss': 0.1599591387330219, 'Total loss': 0.1599591387330219}
2022-12-05 22:18:41,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:41,198 INFO:     Epoch: 41
2022-12-05 22:18:41,998 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45368077741427854, 'Total loss': 0.45368077741427854} | train loss {'Reaction outcome loss': 0.1610339171128717, 'Total loss': 0.1610339171128717}
2022-12-05 22:18:41,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:41,999 INFO:     Epoch: 42
2022-12-05 22:18:42,799 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45139449614692817, 'Total loss': 0.45139449614692817} | train loss {'Reaction outcome loss': 0.1585416028592811, 'Total loss': 0.1585416028592811}
2022-12-05 22:18:42,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:42,799 INFO:     Epoch: 43
2022-12-05 22:18:43,601 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4578209920701655, 'Total loss': 0.4578209920701655} | train loss {'Reaction outcome loss': 0.1536524737864612, 'Total loss': 0.1536524737864612}
2022-12-05 22:18:43,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:43,601 INFO:     Epoch: 44
2022-12-05 22:18:44,400 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4428741550919684, 'Total loss': 0.4428741550919684} | train loss {'Reaction outcome loss': 0.1493939064124501, 'Total loss': 0.1493939064124501}
2022-12-05 22:18:44,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:44,400 INFO:     Epoch: 45
2022-12-05 22:18:45,197 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4776368420571089, 'Total loss': 0.4776368420571089} | train loss {'Reaction outcome loss': 0.153379975090384, 'Total loss': 0.153379975090384}
2022-12-05 22:18:45,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:45,197 INFO:     Epoch: 46
2022-12-05 22:18:45,994 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46082487634637137, 'Total loss': 0.46082487634637137} | train loss {'Reaction outcome loss': 0.15487808596931005, 'Total loss': 0.15487808596931005}
2022-12-05 22:18:45,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:45,995 INFO:     Epoch: 47
2022-12-05 22:18:46,806 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.460189588367939, 'Total loss': 0.460189588367939} | train loss {'Reaction outcome loss': 0.14590734372722355, 'Total loss': 0.14590734372722355}
2022-12-05 22:18:46,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:46,806 INFO:     Epoch: 48
2022-12-05 22:18:47,603 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4653672857040709, 'Total loss': 0.4653672857040709} | train loss {'Reaction outcome loss': 0.14729567679014766, 'Total loss': 0.14729567679014766}
2022-12-05 22:18:47,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:47,604 INFO:     Epoch: 49
2022-12-05 22:18:48,403 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4578562365336852, 'Total loss': 0.4578562365336852} | train loss {'Reaction outcome loss': 0.1442913459467222, 'Total loss': 0.1442913459467222}
2022-12-05 22:18:48,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:48,403 INFO:     Epoch: 50
2022-12-05 22:18:49,203 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45649788257750595, 'Total loss': 0.45649788257750595} | train loss {'Reaction outcome loss': 0.1436409668069378, 'Total loss': 0.1436409668069378}
2022-12-05 22:18:49,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:49,203 INFO:     Epoch: 51
2022-12-05 22:18:50,010 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45867724919861014, 'Total loss': 0.45867724919861014} | train loss {'Reaction outcome loss': 0.14019288391116178, 'Total loss': 0.14019288391116178}
2022-12-05 22:18:50,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:50,010 INFO:     Epoch: 52
2022-12-05 22:18:50,815 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46350608325817366, 'Total loss': 0.46350608325817366} | train loss {'Reaction outcome loss': 0.14461349174832766, 'Total loss': 0.14461349174832766}
2022-12-05 22:18:50,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:50,815 INFO:     Epoch: 53
2022-12-05 22:18:51,613 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47264690256931563, 'Total loss': 0.47264690256931563} | train loss {'Reaction outcome loss': 0.14764045535583004, 'Total loss': 0.14764045535583004}
2022-12-05 22:18:51,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:51,614 INFO:     Epoch: 54
2022-12-05 22:18:52,413 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4593108198182149, 'Total loss': 0.4593108198182149} | train loss {'Reaction outcome loss': 0.14161967760261132, 'Total loss': 0.14161967760261132}
2022-12-05 22:18:52,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:52,414 INFO:     Epoch: 55
2022-12-05 22:18:53,214 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4727777384898879, 'Total loss': 0.4727777384898879} | train loss {'Reaction outcome loss': 0.1423664790189821, 'Total loss': 0.1423664790189821}
2022-12-05 22:18:53,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:53,214 INFO:     Epoch: 56
2022-12-05 22:18:54,014 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.464927423406731, 'Total loss': 0.464927423406731} | train loss {'Reaction outcome loss': 0.1375039913295674, 'Total loss': 0.1375039913295674}
2022-12-05 22:18:54,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:54,015 INFO:     Epoch: 57
2022-12-05 22:18:54,812 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46748408302664757, 'Total loss': 0.46748408302664757} | train loss {'Reaction outcome loss': 0.14064952093911798, 'Total loss': 0.14064952093911798}
2022-12-05 22:18:54,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:54,812 INFO:     Epoch: 58
2022-12-05 22:18:55,611 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4693638746711341, 'Total loss': 0.4693638746711341} | train loss {'Reaction outcome loss': 0.14199107031334146, 'Total loss': 0.14199107031334146}
2022-12-05 22:18:55,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:55,611 INFO:     Epoch: 59
2022-12-05 22:18:56,413 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4689367623491721, 'Total loss': 0.4689367623491721} | train loss {'Reaction outcome loss': 0.13623949316771408, 'Total loss': 0.13623949316771408}
2022-12-05 22:18:56,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:56,413 INFO:     Epoch: 60
2022-12-05 22:18:57,215 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4613865122876384, 'Total loss': 0.4613865122876384} | train loss {'Reaction outcome loss': 0.13479878584126592, 'Total loss': 0.13479878584126592}
2022-12-05 22:18:57,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:57,215 INFO:     Epoch: 61
2022-12-05 22:18:58,013 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47356949213214894, 'Total loss': 0.47356949213214894} | train loss {'Reaction outcome loss': 0.1355079471356111, 'Total loss': 0.1355079471356111}
2022-12-05 22:18:58,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:58,013 INFO:     Epoch: 62
2022-12-05 22:18:58,811 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47672047364440834, 'Total loss': 0.47672047364440834} | train loss {'Reaction outcome loss': 0.1334161137948039, 'Total loss': 0.1334161137948039}
2022-12-05 22:18:58,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:58,812 INFO:     Epoch: 63
2022-12-05 22:18:59,611 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47518983618779614, 'Total loss': 0.47518983618779614} | train loss {'Reaction outcome loss': 0.1339869629940478, 'Total loss': 0.1339869629940478}
2022-12-05 22:18:59,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:18:59,611 INFO:     Epoch: 64
2022-12-05 22:19:00,408 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46778460524298926, 'Total loss': 0.46778460524298926} | train loss {'Reaction outcome loss': 0.13323553285782078, 'Total loss': 0.13323553285782078}
2022-12-05 22:19:00,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:00,408 INFO:     Epoch: 65
2022-12-05 22:19:01,207 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.458090082149614, 'Total loss': 0.458090082149614} | train loss {'Reaction outcome loss': 0.13347930084868723, 'Total loss': 0.13347930084868723}
2022-12-05 22:19:01,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:01,208 INFO:     Epoch: 66
2022-12-05 22:19:02,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4687340520322323, 'Total loss': 0.4687340520322323} | train loss {'Reaction outcome loss': 0.13048855207204396, 'Total loss': 0.13048855207204396}
2022-12-05 22:19:02,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:02,010 INFO:     Epoch: 67
2022-12-05 22:19:02,810 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4817842258648439, 'Total loss': 0.4817842258648439} | train loss {'Reaction outcome loss': 0.12989212104556744, 'Total loss': 0.12989212104556744}
2022-12-05 22:19:02,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:02,810 INFO:     Epoch: 68
2022-12-05 22:19:03,611 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45731991360133345, 'Total loss': 0.45731991360133345} | train loss {'Reaction outcome loss': 0.12958292168780014, 'Total loss': 0.12958292168780014}
2022-12-05 22:19:03,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:03,612 INFO:     Epoch: 69
2022-12-05 22:19:04,408 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47011107341809705, 'Total loss': 0.47011107341809705} | train loss {'Reaction outcome loss': 0.13468823734640714, 'Total loss': 0.13468823734640714}
2022-12-05 22:19:04,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:04,408 INFO:     Epoch: 70
2022-12-05 22:19:05,208 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.478753826496276, 'Total loss': 0.478753826496276} | train loss {'Reaction outcome loss': 0.12722938778802662, 'Total loss': 0.12722938778802662}
2022-12-05 22:19:05,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:05,209 INFO:     Epoch: 71
2022-12-05 22:19:06,007 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4701730395582589, 'Total loss': 0.4701730395582589} | train loss {'Reaction outcome loss': 0.1290411384708365, 'Total loss': 0.1290411384708365}
2022-12-05 22:19:06,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:06,007 INFO:     Epoch: 72
2022-12-05 22:19:06,806 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46333613754673436, 'Total loss': 0.46333613754673436} | train loss {'Reaction outcome loss': 0.12658193280264313, 'Total loss': 0.12658193280264313}
2022-12-05 22:19:06,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:06,807 INFO:     Epoch: 73
2022-12-05 22:19:07,607 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46756533262404526, 'Total loss': 0.46756533262404526} | train loss {'Reaction outcome loss': 0.12938569807390934, 'Total loss': 0.12938569807390934}
2022-12-05 22:19:07,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:07,607 INFO:     Epoch: 74
2022-12-05 22:19:08,405 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4653360882604664, 'Total loss': 0.4653360882604664} | train loss {'Reaction outcome loss': 0.13038811449014284, 'Total loss': 0.13038811449014284}
2022-12-05 22:19:08,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:08,406 INFO:     Epoch: 75
2022-12-05 22:19:09,207 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4723808121952144, 'Total loss': 0.4723808121952144} | train loss {'Reaction outcome loss': 0.12619430606483448, 'Total loss': 0.12619430606483448}
2022-12-05 22:19:09,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:09,207 INFO:     Epoch: 76
2022-12-05 22:19:10,009 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4638376487419009, 'Total loss': 0.4638376487419009} | train loss {'Reaction outcome loss': 0.127954488620162, 'Total loss': 0.127954488620162}
2022-12-05 22:19:10,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:10,009 INFO:     Epoch: 77
2022-12-05 22:19:10,811 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4626920605924996, 'Total loss': 0.4626920605924996} | train loss {'Reaction outcome loss': 0.12669505451161128, 'Total loss': 0.12669505451161128}
2022-12-05 22:19:10,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:10,811 INFO:     Epoch: 78
2022-12-05 22:19:11,620 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46910982782190497, 'Total loss': 0.46910982782190497} | train loss {'Reaction outcome loss': 0.12429275736778311, 'Total loss': 0.12429275736778311}
2022-12-05 22:19:11,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:11,620 INFO:     Epoch: 79
2022-12-05 22:19:12,427 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4630827072330497, 'Total loss': 0.4630827072330497} | train loss {'Reaction outcome loss': 0.12327997829116549, 'Total loss': 0.12327997829116549}
2022-12-05 22:19:12,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:12,428 INFO:     Epoch: 80
2022-12-05 22:19:13,229 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47063826566392725, 'Total loss': 0.47063826566392725} | train loss {'Reaction outcome loss': 0.12561365949962786, 'Total loss': 0.12561365949962786}
2022-12-05 22:19:13,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:13,230 INFO:     Epoch: 81
2022-12-05 22:19:14,033 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.47029261968352576, 'Total loss': 0.47029261968352576} | train loss {'Reaction outcome loss': 0.12799557057908748, 'Total loss': 0.12799557057908748}
2022-12-05 22:19:14,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:14,034 INFO:     Epoch: 82
2022-12-05 22:19:14,832 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4929263005879792, 'Total loss': 0.4929263005879792} | train loss {'Reaction outcome loss': 0.13041750410277592, 'Total loss': 0.13041750410277592}
2022-12-05 22:19:14,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:14,832 INFO:     Epoch: 83
2022-12-05 22:19:15,630 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47358106991106813, 'Total loss': 0.47358106991106813} | train loss {'Reaction outcome loss': 0.13784566488840921, 'Total loss': 0.13784566488840921}
2022-12-05 22:19:15,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:15,631 INFO:     Epoch: 84
2022-12-05 22:19:16,437 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48096099055626174, 'Total loss': 0.48096099055626174} | train loss {'Reaction outcome loss': 0.1252144803613545, 'Total loss': 0.1252144803613545}
2022-12-05 22:19:16,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:16,437 INFO:     Epoch: 85
2022-12-05 22:19:17,238 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4707221758805893, 'Total loss': 0.4707221758805893} | train loss {'Reaction outcome loss': 0.12332074753261409, 'Total loss': 0.12332074753261409}
2022-12-05 22:19:17,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:17,238 INFO:     Epoch: 86
2022-12-05 22:19:18,040 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.481272236190059, 'Total loss': 0.481272236190059} | train loss {'Reaction outcome loss': 0.12031514954617481, 'Total loss': 0.12031514954617481}
2022-12-05 22:19:18,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:18,040 INFO:     Epoch: 87
2022-12-05 22:19:18,839 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4850084307518872, 'Total loss': 0.4850084307518872} | train loss {'Reaction outcome loss': 0.12009680979632535, 'Total loss': 0.12009680979632535}
2022-12-05 22:19:18,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:18,839 INFO:     Epoch: 88
2022-12-05 22:19:19,643 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4777550229972059, 'Total loss': 0.4777550229972059} | train loss {'Reaction outcome loss': 0.12880743332282613, 'Total loss': 0.12880743332282613}
2022-12-05 22:19:19,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:19,644 INFO:     Epoch: 89
2022-12-05 22:19:20,445 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4777881960299882, 'Total loss': 0.4777881960299882} | train loss {'Reaction outcome loss': 0.12521599517448953, 'Total loss': 0.12521599517448953}
2022-12-05 22:19:20,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:20,445 INFO:     Epoch: 90
2022-12-05 22:19:21,245 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.48986807533285837, 'Total loss': 0.48986807533285837} | train loss {'Reaction outcome loss': 0.12754525080264775, 'Total loss': 0.12754525080264775}
2022-12-05 22:19:21,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:21,245 INFO:     Epoch: 91
2022-12-05 22:19:22,046 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4813487030227076, 'Total loss': 0.4813487030227076} | train loss {'Reaction outcome loss': 0.12247610609103673, 'Total loss': 0.12247610609103673}
2022-12-05 22:19:22,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:22,046 INFO:     Epoch: 92
2022-12-05 22:19:22,845 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48246975683353166, 'Total loss': 0.48246975683353166} | train loss {'Reaction outcome loss': 0.12396613962624056, 'Total loss': 0.12396613962624056}
2022-12-05 22:19:22,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:22,845 INFO:     Epoch: 93
2022-12-05 22:19:23,645 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48558109693906526, 'Total loss': 0.48558109693906526} | train loss {'Reaction outcome loss': 0.1319463548520561, 'Total loss': 0.1319463548520561}
2022-12-05 22:19:23,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:23,645 INFO:     Epoch: 94
2022-12-05 22:19:24,448 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4806723760610277, 'Total loss': 0.4806723760610277} | train loss {'Reaction outcome loss': 0.12028228659333609, 'Total loss': 0.12028228659333609}
2022-12-05 22:19:24,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:24,448 INFO:     Epoch: 95
2022-12-05 22:19:25,249 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47687275673855434, 'Total loss': 0.47687275673855434} | train loss {'Reaction outcome loss': 0.12010751301441568, 'Total loss': 0.12010751301441568}
2022-12-05 22:19:25,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:25,250 INFO:     Epoch: 96
2022-12-05 22:19:26,048 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48122571578080003, 'Total loss': 0.48122571578080003} | train loss {'Reaction outcome loss': 0.11880843500467206, 'Total loss': 0.11880843500467206}
2022-12-05 22:19:26,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:26,048 INFO:     Epoch: 97
2022-12-05 22:19:26,846 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48062227767976845, 'Total loss': 0.48062227767976845} | train loss {'Reaction outcome loss': 0.12373144356420769, 'Total loss': 0.12373144356420769}
2022-12-05 22:19:26,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:26,846 INFO:     Epoch: 98
2022-12-05 22:19:27,645 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4863347912376577, 'Total loss': 0.4863347912376577} | train loss {'Reaction outcome loss': 0.12226503324621406, 'Total loss': 0.12226503324621406}
2022-12-05 22:19:27,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:27,645 INFO:     Epoch: 99
2022-12-05 22:19:28,442 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48815588957884093, 'Total loss': 0.48815588957884093} | train loss {'Reaction outcome loss': 0.11892833453621941, 'Total loss': 0.11892833453621941}
2022-12-05 22:19:28,443 INFO:     Best model found after epoch 17 of 100.
2022-12-05 22:19:28,443 INFO:   Done with stage: TRAINING
2022-12-05 22:19:28,443 INFO:   Starting stage: EVALUATION
2022-12-05 22:19:28,570 INFO:   Done with stage: EVALUATION
2022-12-05 22:19:28,570 INFO:   Leaving out SEQ value Fold_4
2022-12-05 22:19:28,582 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:19:28,582 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:19:29,231 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:19:29,231 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:19:29,301 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:19:29,301 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:19:29,301 INFO:     No hyperparam tuning for this model
2022-12-05 22:19:29,301 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:19:29,301 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:19:29,302 INFO:     None feature selector for col prot
2022-12-05 22:19:29,302 INFO:     None feature selector for col prot
2022-12-05 22:19:29,302 INFO:     None feature selector for col prot
2022-12-05 22:19:29,302 INFO:     None feature selector for col chem
2022-12-05 22:19:29,302 INFO:     None feature selector for col chem
2022-12-05 22:19:29,303 INFO:     None feature selector for col chem
2022-12-05 22:19:29,303 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:19:29,303 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:19:29,304 INFO:     Number of params in model 215821
2022-12-05 22:19:29,307 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:19:29,307 INFO:   Starting stage: TRAINING
2022-12-05 22:19:29,368 INFO:     Val loss before train {'Reaction outcome loss': 0.9845938262614337, 'Total loss': 0.9845938262614337}
2022-12-05 22:19:29,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:29,369 INFO:     Epoch: 0
2022-12-05 22:19:30,169 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5929666832089424, 'Total loss': 0.5929666832089424} | train loss {'Reaction outcome loss': 0.7949734931631435, 'Total loss': 0.7949734931631435}
2022-12-05 22:19:30,169 INFO:     Found new best model at epoch 0
2022-12-05 22:19:30,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:30,170 INFO:     Epoch: 1
2022-12-05 22:19:30,973 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5167837159877474, 'Total loss': 0.5167837159877474} | train loss {'Reaction outcome loss': 0.5363635843199107, 'Total loss': 0.5363635843199107}
2022-12-05 22:19:30,973 INFO:     Found new best model at epoch 1
2022-12-05 22:19:30,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:30,974 INFO:     Epoch: 2
2022-12-05 22:19:31,778 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4890373945236206, 'Total loss': 0.4890373945236206} | train loss {'Reaction outcome loss': 0.4660837975360693, 'Total loss': 0.4660837975360693}
2022-12-05 22:19:31,778 INFO:     Found new best model at epoch 2
2022-12-05 22:19:31,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:31,779 INFO:     Epoch: 3
2022-12-05 22:19:32,579 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4653831347823143, 'Total loss': 0.4653831347823143} | train loss {'Reaction outcome loss': 0.4278311042055007, 'Total loss': 0.4278311042055007}
2022-12-05 22:19:32,580 INFO:     Found new best model at epoch 3
2022-12-05 22:19:32,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:32,580 INFO:     Epoch: 4
2022-12-05 22:19:33,381 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4650649262422865, 'Total loss': 0.4650649262422865} | train loss {'Reaction outcome loss': 0.4014576197631897, 'Total loss': 0.4014576197631897}
2022-12-05 22:19:33,381 INFO:     Found new best model at epoch 4
2022-12-05 22:19:33,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:33,382 INFO:     Epoch: 5
2022-12-05 22:19:34,180 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45521841232072224, 'Total loss': 0.45521841232072224} | train loss {'Reaction outcome loss': 0.3779189027245006, 'Total loss': 0.3779189027245006}
2022-12-05 22:19:34,180 INFO:     Found new best model at epoch 5
2022-12-05 22:19:34,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:34,181 INFO:     Epoch: 6
2022-12-05 22:19:34,982 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44719249314882537, 'Total loss': 0.44719249314882537} | train loss {'Reaction outcome loss': 0.3616802062719099, 'Total loss': 0.3616802062719099}
2022-12-05 22:19:34,982 INFO:     Found new best model at epoch 6
2022-12-05 22:19:34,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:34,983 INFO:     Epoch: 7
2022-12-05 22:19:35,788 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4369580371474678, 'Total loss': 0.4369580371474678} | train loss {'Reaction outcome loss': 0.3418365535476515, 'Total loss': 0.3418365535476515}
2022-12-05 22:19:35,789 INFO:     Found new best model at epoch 7
2022-12-05 22:19:35,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:35,789 INFO:     Epoch: 8
2022-12-05 22:19:36,590 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44730333306572656, 'Total loss': 0.44730333306572656} | train loss {'Reaction outcome loss': 0.329504773050787, 'Total loss': 0.329504773050787}
2022-12-05 22:19:36,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:36,590 INFO:     Epoch: 9
2022-12-05 22:19:37,392 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43493771205910225, 'Total loss': 0.43493771205910225} | train loss {'Reaction outcome loss': 0.3155027071254388, 'Total loss': 0.3155027071254388}
2022-12-05 22:19:37,393 INFO:     Found new best model at epoch 9
2022-12-05 22:19:37,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:37,394 INFO:     Epoch: 10
2022-12-05 22:19:38,195 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4330666336146268, 'Total loss': 0.4330666336146268} | train loss {'Reaction outcome loss': 0.3018245228055504, 'Total loss': 0.3018245228055504}
2022-12-05 22:19:38,196 INFO:     Found new best model at epoch 10
2022-12-05 22:19:38,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:38,196 INFO:     Epoch: 11
2022-12-05 22:19:38,998 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4317285591228442, 'Total loss': 0.4317285591228442} | train loss {'Reaction outcome loss': 0.2923299271553274, 'Total loss': 0.2923299271553274}
2022-12-05 22:19:38,998 INFO:     Found new best model at epoch 11
2022-12-05 22:19:38,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:38,999 INFO:     Epoch: 12
2022-12-05 22:19:39,807 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42867281050844624, 'Total loss': 0.42867281050844624} | train loss {'Reaction outcome loss': 0.28298229000140585, 'Total loss': 0.28298229000140585}
2022-12-05 22:19:39,807 INFO:     Found new best model at epoch 12
2022-12-05 22:19:39,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:39,808 INFO:     Epoch: 13
2022-12-05 22:19:40,612 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4239826114340262, 'Total loss': 0.4239826114340262} | train loss {'Reaction outcome loss': 0.27427719845887155, 'Total loss': 0.27427719845887155}
2022-12-05 22:19:40,612 INFO:     Found new best model at epoch 13
2022-12-05 22:19:40,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:40,613 INFO:     Epoch: 14
2022-12-05 22:19:41,416 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43135070766914974, 'Total loss': 0.43135070766914974} | train loss {'Reaction outcome loss': 0.2636164601952318, 'Total loss': 0.2636164601952318}
2022-12-05 22:19:41,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:41,416 INFO:     Epoch: 15
2022-12-05 22:19:42,219 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43437397480010986, 'Total loss': 0.43437397480010986} | train loss {'Reaction outcome loss': 0.2559357004901094, 'Total loss': 0.2559357004901094}
2022-12-05 22:19:42,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:42,219 INFO:     Epoch: 16
2022-12-05 22:19:43,019 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4435460066253489, 'Total loss': 0.4435460066253489} | train loss {'Reaction outcome loss': 0.24694681541633703, 'Total loss': 0.24694681541633703}
2022-12-05 22:19:43,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:43,019 INFO:     Epoch: 17
2022-12-05 22:19:43,821 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4325504374097694, 'Total loss': 0.4325504374097694} | train loss {'Reaction outcome loss': 0.24053121340130607, 'Total loss': 0.24053121340130607}
2022-12-05 22:19:43,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:43,822 INFO:     Epoch: 18
2022-12-05 22:19:44,627 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44494191743433475, 'Total loss': 0.44494191743433475} | train loss {'Reaction outcome loss': 0.23677328554913402, 'Total loss': 0.23677328554913402}
2022-12-05 22:19:44,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:44,628 INFO:     Epoch: 19
2022-12-05 22:19:45,435 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4289223665202206, 'Total loss': 0.4289223665202206} | train loss {'Reaction outcome loss': 0.23216802880708728, 'Total loss': 0.23216802880708728}
2022-12-05 22:19:45,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:45,435 INFO:     Epoch: 20
2022-12-05 22:19:46,250 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4339311964471232, 'Total loss': 0.4339311964471232} | train loss {'Reaction outcome loss': 0.2241681391343234, 'Total loss': 0.2241681391343234}
2022-12-05 22:19:46,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:46,250 INFO:     Epoch: 21
2022-12-05 22:19:47,053 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4508608852259137, 'Total loss': 0.4508608852259137} | train loss {'Reaction outcome loss': 0.2203695372107529, 'Total loss': 0.2203695372107529}
2022-12-05 22:19:47,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:47,053 INFO:     Epoch: 22
2022-12-05 22:19:47,859 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4437632853673263, 'Total loss': 0.4437632853673263} | train loss {'Reaction outcome loss': 0.21642155482644035, 'Total loss': 0.21642155482644035}
2022-12-05 22:19:47,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:47,860 INFO:     Epoch: 23
2022-12-05 22:19:48,663 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44338627125729213, 'Total loss': 0.44338627125729213} | train loss {'Reaction outcome loss': 0.20911471892689024, 'Total loss': 0.20911471892689024}
2022-12-05 22:19:48,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:48,664 INFO:     Epoch: 24
2022-12-05 22:19:49,468 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44011968340386043, 'Total loss': 0.44011968340386043} | train loss {'Reaction outcome loss': 0.20980168185046605, 'Total loss': 0.20980168185046605}
2022-12-05 22:19:49,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:49,468 INFO:     Epoch: 25
2022-12-05 22:19:50,276 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4343893544917757, 'Total loss': 0.4343893544917757} | train loss {'Reaction outcome loss': 0.20359768554748547, 'Total loss': 0.20359768554748547}
2022-12-05 22:19:50,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:50,276 INFO:     Epoch: 26
2022-12-05 22:19:51,089 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43377799540758133, 'Total loss': 0.43377799540758133} | train loss {'Reaction outcome loss': 0.19990810360609285, 'Total loss': 0.19990810360609285}
2022-12-05 22:19:51,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:51,089 INFO:     Epoch: 27
2022-12-05 22:19:51,895 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43308529596437106, 'Total loss': 0.43308529596437106} | train loss {'Reaction outcome loss': 0.19665469163127483, 'Total loss': 0.19665469163127483}
2022-12-05 22:19:51,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:51,895 INFO:     Epoch: 28
2022-12-05 22:19:52,700 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4511217435991222, 'Total loss': 0.4511217435991222} | train loss {'Reaction outcome loss': 0.19273801853940373, 'Total loss': 0.19273801853940373}
2022-12-05 22:19:52,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:52,700 INFO:     Epoch: 29
2022-12-05 22:19:53,504 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43997254459695384, 'Total loss': 0.43997254459695384} | train loss {'Reaction outcome loss': 0.18943811365733704, 'Total loss': 0.18943811365733704}
2022-12-05 22:19:53,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:53,504 INFO:     Epoch: 30
2022-12-05 22:19:54,312 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4379930474202741, 'Total loss': 0.4379930474202741} | train loss {'Reaction outcome loss': 0.18772579855736224, 'Total loss': 0.18772579855736224}
2022-12-05 22:19:54,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:54,312 INFO:     Epoch: 31
2022-12-05 22:19:55,117 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4467682062902234, 'Total loss': 0.4467682062902234} | train loss {'Reaction outcome loss': 0.18808170968306162, 'Total loss': 0.18808170968306162}
2022-12-05 22:19:55,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:55,118 INFO:     Epoch: 32
2022-12-05 22:19:55,922 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4619580463252284, 'Total loss': 0.4619580463252284} | train loss {'Reaction outcome loss': 0.1829070146345804, 'Total loss': 0.1829070146345804}
2022-12-05 22:19:55,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:55,923 INFO:     Epoch: 33
2022-12-05 22:19:56,727 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.457386181097139, 'Total loss': 0.457386181097139} | train loss {'Reaction outcome loss': 0.18065353395086864, 'Total loss': 0.18065353395086864}
2022-12-05 22:19:56,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:56,727 INFO:     Epoch: 34
2022-12-05 22:19:57,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45920496654104104, 'Total loss': 0.45920496654104104} | train loss {'Reaction outcome loss': 0.1783441953030565, 'Total loss': 0.1783441953030565}
2022-12-05 22:19:57,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:57,527 INFO:     Epoch: 35
2022-12-05 22:19:58,327 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4513095549561761, 'Total loss': 0.4513095549561761} | train loss {'Reaction outcome loss': 0.178466011086599, 'Total loss': 0.178466011086599}
2022-12-05 22:19:58,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:58,327 INFO:     Epoch: 36
2022-12-05 22:19:59,128 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45072510838508606, 'Total loss': 0.45072510838508606} | train loss {'Reaction outcome loss': 0.17110183556383896, 'Total loss': 0.17110183556383896}
2022-12-05 22:19:59,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:59,128 INFO:     Epoch: 37
2022-12-05 22:19:59,930 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4382471108639782, 'Total loss': 0.4382471108639782} | train loss {'Reaction outcome loss': 0.16882346493883, 'Total loss': 0.16882346493883}
2022-12-05 22:19:59,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:19:59,930 INFO:     Epoch: 38
2022-12-05 22:20:00,729 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4635979211465879, 'Total loss': 0.4635979211465879} | train loss {'Reaction outcome loss': 0.17001396358283538, 'Total loss': 0.17001396358283538}
2022-12-05 22:20:00,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:00,730 INFO:     Epoch: 39
2022-12-05 22:20:01,530 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46153334426608955, 'Total loss': 0.46153334426608955} | train loss {'Reaction outcome loss': 0.16768553862798838, 'Total loss': 0.16768553862798838}
2022-12-05 22:20:01,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:01,531 INFO:     Epoch: 40
2022-12-05 22:20:02,332 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44791538403792813, 'Total loss': 0.44791538403792813} | train loss {'Reaction outcome loss': 0.16836054056822772, 'Total loss': 0.16836054056822772}
2022-12-05 22:20:02,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:02,332 INFO:     Epoch: 41
2022-12-05 22:20:03,134 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46370290727777913, 'Total loss': 0.46370290727777913} | train loss {'Reaction outcome loss': 0.16380430181180278, 'Total loss': 0.16380430181180278}
2022-12-05 22:20:03,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:03,134 INFO:     Epoch: 42
2022-12-05 22:20:03,935 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45362821356816724, 'Total loss': 0.45362821356816724} | train loss {'Reaction outcome loss': 0.1661772568514871, 'Total loss': 0.1661772568514871}
2022-12-05 22:20:03,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:03,935 INFO:     Epoch: 43
2022-12-05 22:20:04,735 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45486632277342404, 'Total loss': 0.45486632277342404} | train loss {'Reaction outcome loss': 0.15990247788478532, 'Total loss': 0.15990247788478532}
2022-12-05 22:20:04,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:04,735 INFO:     Epoch: 44
2022-12-05 22:20:05,535 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4696187488734722, 'Total loss': 0.4696187488734722} | train loss {'Reaction outcome loss': 0.1598705364721677, 'Total loss': 0.1598705364721677}
2022-12-05 22:20:05,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:05,535 INFO:     Epoch: 45
2022-12-05 22:20:06,336 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4670852856202559, 'Total loss': 0.4670852856202559} | train loss {'Reaction outcome loss': 0.157532099228833, 'Total loss': 0.157532099228833}
2022-12-05 22:20:06,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:06,336 INFO:     Epoch: 46
2022-12-05 22:20:07,139 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4775158224458044, 'Total loss': 0.4775158224458044} | train loss {'Reaction outcome loss': 0.1580294183560557, 'Total loss': 0.1580294183560557}
2022-12-05 22:20:07,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:07,139 INFO:     Epoch: 47
2022-12-05 22:20:07,939 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4415630992840637, 'Total loss': 0.4415630992840637} | train loss {'Reaction outcome loss': 0.15590014299678226, 'Total loss': 0.15590014299678226}
2022-12-05 22:20:07,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:07,939 INFO:     Epoch: 48
2022-12-05 22:20:08,738 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45185803791338747, 'Total loss': 0.45185803791338747} | train loss {'Reaction outcome loss': 0.15593227469212106, 'Total loss': 0.15593227469212106}
2022-12-05 22:20:08,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:08,739 INFO:     Epoch: 49
2022-12-05 22:20:09,541 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.455384643917734, 'Total loss': 0.455384643917734} | train loss {'Reaction outcome loss': 0.15525821934364015, 'Total loss': 0.15525821934364015}
2022-12-05 22:20:09,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:09,542 INFO:     Epoch: 50
2022-12-05 22:20:10,343 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45346302031116054, 'Total loss': 0.45346302031116054} | train loss {'Reaction outcome loss': 0.1519756765900961, 'Total loss': 0.1519756765900961}
2022-12-05 22:20:10,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:10,343 INFO:     Epoch: 51
2022-12-05 22:20:11,149 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46505513855002145, 'Total loss': 0.46505513855002145} | train loss {'Reaction outcome loss': 0.1498299088411694, 'Total loss': 0.1498299088411694}
2022-12-05 22:20:11,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:11,149 INFO:     Epoch: 52
2022-12-05 22:20:11,949 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4573585101487962, 'Total loss': 0.4573585101487962} | train loss {'Reaction outcome loss': 0.14946523332037032, 'Total loss': 0.14946523332037032}
2022-12-05 22:20:11,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:11,950 INFO:     Epoch: 53
2022-12-05 22:20:12,752 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47801399061625655, 'Total loss': 0.47801399061625655} | train loss {'Reaction outcome loss': 0.14851880459595593, 'Total loss': 0.14851880459595593}
2022-12-05 22:20:12,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:12,752 INFO:     Epoch: 54
2022-12-05 22:20:13,552 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45915124294432724, 'Total loss': 0.45915124294432724} | train loss {'Reaction outcome loss': 0.14708351976268233, 'Total loss': 0.14708351976268233}
2022-12-05 22:20:13,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:13,552 INFO:     Epoch: 55
2022-12-05 22:20:14,352 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46285694668238814, 'Total loss': 0.46285694668238814} | train loss {'Reaction outcome loss': 0.14817172506703966, 'Total loss': 0.14817172506703966}
2022-12-05 22:20:14,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:14,352 INFO:     Epoch: 56
2022-12-05 22:20:15,164 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47825700349428435, 'Total loss': 0.47825700349428435} | train loss {'Reaction outcome loss': 0.14483307805212756, 'Total loss': 0.14483307805212756}
2022-12-05 22:20:15,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:15,164 INFO:     Epoch: 57
2022-12-05 22:20:15,975 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46621742378920317, 'Total loss': 0.46621742378920317} | train loss {'Reaction outcome loss': 0.1474944050649121, 'Total loss': 0.1474944050649121}
2022-12-05 22:20:15,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:15,976 INFO:     Epoch: 58
2022-12-05 22:20:16,780 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4597610374065963, 'Total loss': 0.4597610374065963} | train loss {'Reaction outcome loss': 0.14175271100154327, 'Total loss': 0.14175271100154327}
2022-12-05 22:20:16,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:16,780 INFO:     Epoch: 59
2022-12-05 22:20:17,583 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4716418734328313, 'Total loss': 0.4716418734328313} | train loss {'Reaction outcome loss': 0.14498266088025225, 'Total loss': 0.14498266088025225}
2022-12-05 22:20:17,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:17,584 INFO:     Epoch: 60
2022-12-05 22:20:18,390 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47049248726530507, 'Total loss': 0.47049248726530507} | train loss {'Reaction outcome loss': 0.14279128250575834, 'Total loss': 0.14279128250575834}
2022-12-05 22:20:18,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:18,390 INFO:     Epoch: 61
2022-12-05 22:20:19,194 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46957416188987816, 'Total loss': 0.46957416188987816} | train loss {'Reaction outcome loss': 0.14246169874264347, 'Total loss': 0.14246169874264347}
2022-12-05 22:20:19,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:19,194 INFO:     Epoch: 62
2022-12-05 22:20:19,995 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47180957584218547, 'Total loss': 0.47180957584218547} | train loss {'Reaction outcome loss': 0.14167265775012633, 'Total loss': 0.14167265775012633}
2022-12-05 22:20:19,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:19,996 INFO:     Epoch: 63
2022-12-05 22:20:20,798 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46765094927766104, 'Total loss': 0.46765094927766104} | train loss {'Reaction outcome loss': 0.14161423484854882, 'Total loss': 0.14161423484854882}
2022-12-05 22:20:20,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:20,798 INFO:     Epoch: 64
2022-12-05 22:20:21,601 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4981943213126876, 'Total loss': 0.4981943213126876} | train loss {'Reaction outcome loss': 0.14046500799726816, 'Total loss': 0.14046500799726816}
2022-12-05 22:20:21,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:21,601 INFO:     Epoch: 65
2022-12-05 22:20:22,407 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46468165482987056, 'Total loss': 0.46468165482987056} | train loss {'Reaction outcome loss': 0.14256418108819954, 'Total loss': 0.14256418108819954}
2022-12-05 22:20:22,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:22,408 INFO:     Epoch: 66
2022-12-05 22:20:23,213 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4638290252875198, 'Total loss': 0.4638290252875198} | train loss {'Reaction outcome loss': 0.13849241169725335, 'Total loss': 0.13849241169725335}
2022-12-05 22:20:23,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:23,214 INFO:     Epoch: 67
2022-12-05 22:20:24,020 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46956210278651933, 'Total loss': 0.46956210278651933} | train loss {'Reaction outcome loss': 0.1393705277080317, 'Total loss': 0.1393705277080317}
2022-12-05 22:20:24,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:24,020 INFO:     Epoch: 68
2022-12-05 22:20:24,820 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4579419246451421, 'Total loss': 0.4579419246451421} | train loss {'Reaction outcome loss': 0.13897075033145806, 'Total loss': 0.13897075033145806}
2022-12-05 22:20:24,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:24,821 INFO:     Epoch: 69
2022-12-05 22:20:25,623 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4854548441415483, 'Total loss': 0.4854548441415483} | train loss {'Reaction outcome loss': 0.13740418191563578, 'Total loss': 0.13740418191563578}
2022-12-05 22:20:25,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:25,623 INFO:     Epoch: 70
2022-12-05 22:20:26,423 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4791033135896379, 'Total loss': 0.4791033135896379} | train loss {'Reaction outcome loss': 0.13640287303696236, 'Total loss': 0.13640287303696236}
2022-12-05 22:20:26,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:26,424 INFO:     Epoch: 71
2022-12-05 22:20:27,225 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4743333702737635, 'Total loss': 0.4743333702737635} | train loss {'Reaction outcome loss': 0.13500472280992976, 'Total loss': 0.13500472280992976}
2022-12-05 22:20:27,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:27,225 INFO:     Epoch: 72
2022-12-05 22:20:28,025 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48411339995535935, 'Total loss': 0.48411339995535935} | train loss {'Reaction outcome loss': 0.1354327467345302, 'Total loss': 0.1354327467345302}
2022-12-05 22:20:28,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:28,026 INFO:     Epoch: 73
2022-12-05 22:20:28,825 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48158466477285733, 'Total loss': 0.48158466477285733} | train loss {'Reaction outcome loss': 0.13674298527785728, 'Total loss': 0.13674298527785728}
2022-12-05 22:20:28,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:28,826 INFO:     Epoch: 74
2022-12-05 22:20:29,632 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4700588905675845, 'Total loss': 0.4700588905675845} | train loss {'Reaction outcome loss': 0.134159215756001, 'Total loss': 0.134159215756001}
2022-12-05 22:20:29,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:29,633 INFO:     Epoch: 75
2022-12-05 22:20:30,432 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47412413104691287, 'Total loss': 0.47412413104691287} | train loss {'Reaction outcome loss': 0.13361898351520782, 'Total loss': 0.13361898351520782}
2022-12-05 22:20:30,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:30,433 INFO:     Epoch: 76
2022-12-05 22:20:31,232 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4757858897474679, 'Total loss': 0.4757858897474679} | train loss {'Reaction outcome loss': 0.13058116284739826, 'Total loss': 0.13058116284739826}
2022-12-05 22:20:31,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:31,232 INFO:     Epoch: 77
2022-12-05 22:20:32,035 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47172427109696646, 'Total loss': 0.47172427109696646} | train loss {'Reaction outcome loss': 0.13432233926517168, 'Total loss': 0.13432233926517168}
2022-12-05 22:20:32,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:32,036 INFO:     Epoch: 78
2022-12-05 22:20:32,838 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46832063590938394, 'Total loss': 0.46832063590938394} | train loss {'Reaction outcome loss': 0.13522745518674772, 'Total loss': 0.13522745518674772}
2022-12-05 22:20:32,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:32,838 INFO:     Epoch: 79
2022-12-05 22:20:33,643 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4551635669036345, 'Total loss': 0.4551635669036345} | train loss {'Reaction outcome loss': 0.13318285824836143, 'Total loss': 0.13318285824836143}
2022-12-05 22:20:33,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:33,644 INFO:     Epoch: 80
2022-12-05 22:20:34,449 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45912528664551, 'Total loss': 0.45912528664551} | train loss {'Reaction outcome loss': 0.13441536499698076, 'Total loss': 0.13441536499698076}
2022-12-05 22:20:34,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:34,449 INFO:     Epoch: 81
2022-12-05 22:20:35,250 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4753861525519328, 'Total loss': 0.4753861525519328} | train loss {'Reaction outcome loss': 0.13007739829950996, 'Total loss': 0.13007739829950996}
2022-12-05 22:20:35,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:35,251 INFO:     Epoch: 82
2022-12-05 22:20:36,050 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4577699293467132, 'Total loss': 0.4577699293467132} | train loss {'Reaction outcome loss': 0.1322114272550079, 'Total loss': 0.1322114272550079}
2022-12-05 22:20:36,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:36,050 INFO:     Epoch: 83
2022-12-05 22:20:36,850 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47777609137648885, 'Total loss': 0.47777609137648885} | train loss {'Reaction outcome loss': 0.12955467692846734, 'Total loss': 0.12955467692846734}
2022-12-05 22:20:36,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:36,850 INFO:     Epoch: 84
2022-12-05 22:20:37,653 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.481946565549482, 'Total loss': 0.481946565549482} | train loss {'Reaction outcome loss': 0.1315660623818516, 'Total loss': 0.1315660623818516}
2022-12-05 22:20:37,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:37,654 INFO:     Epoch: 85
2022-12-05 22:20:38,460 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48822805556384, 'Total loss': 0.48822805556384} | train loss {'Reaction outcome loss': 0.13068834254743472, 'Total loss': 0.13068834254743472}
2022-12-05 22:20:38,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:38,460 INFO:     Epoch: 86
2022-12-05 22:20:39,261 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46436087550087407, 'Total loss': 0.46436087550087407} | train loss {'Reaction outcome loss': 0.13066655726382329, 'Total loss': 0.13066655726382329}
2022-12-05 22:20:39,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:39,261 INFO:     Epoch: 87
2022-12-05 22:20:40,064 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4629880325360732, 'Total loss': 0.4629880325360732} | train loss {'Reaction outcome loss': 0.12997153329272423, 'Total loss': 0.12997153329272423}
2022-12-05 22:20:40,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:40,065 INFO:     Epoch: 88
2022-12-05 22:20:40,867 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48251536285335367, 'Total loss': 0.48251536285335367} | train loss {'Reaction outcome loss': 0.12841685020154522, 'Total loss': 0.12841685020154522}
2022-12-05 22:20:40,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:40,867 INFO:     Epoch: 89
2022-12-05 22:20:41,666 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4658071527426893, 'Total loss': 0.4658071527426893} | train loss {'Reaction outcome loss': 0.12736856450341763, 'Total loss': 0.12736856450341763}
2022-12-05 22:20:41,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:41,666 INFO:     Epoch: 90
2022-12-05 22:20:42,468 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4709659648889845, 'Total loss': 0.4709659648889845} | train loss {'Reaction outcome loss': 0.12667170223299293, 'Total loss': 0.12667170223299293}
2022-12-05 22:20:42,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:42,468 INFO:     Epoch: 91
2022-12-05 22:20:43,268 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48553500087423757, 'Total loss': 0.48553500087423757} | train loss {'Reaction outcome loss': 0.12749146048971002, 'Total loss': 0.12749146048971002}
2022-12-05 22:20:43,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:43,268 INFO:     Epoch: 92
2022-12-05 22:20:44,069 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4722625481134111, 'Total loss': 0.4722625481134111} | train loss {'Reaction outcome loss': 0.1310393446981306, 'Total loss': 0.1310393446981306}
2022-12-05 22:20:44,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:44,069 INFO:     Epoch: 93
2022-12-05 22:20:44,876 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47182720459320326, 'Total loss': 0.47182720459320326} | train loss {'Reaction outcome loss': 0.12801135401992547, 'Total loss': 0.12801135401992547}
2022-12-05 22:20:44,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:44,876 INFO:     Epoch: 94
2022-12-05 22:20:45,675 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4828041758049618, 'Total loss': 0.4828041758049618} | train loss {'Reaction outcome loss': 0.12475158648580432, 'Total loss': 0.12475158648580432}
2022-12-05 22:20:45,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:45,675 INFO:     Epoch: 95
2022-12-05 22:20:46,483 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.470699146728624, 'Total loss': 0.470699146728624} | train loss {'Reaction outcome loss': 0.12484421355709914, 'Total loss': 0.12484421355709914}
2022-12-05 22:20:46,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:46,484 INFO:     Epoch: 96
2022-12-05 22:20:47,282 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46865290809761395, 'Total loss': 0.46865290809761395} | train loss {'Reaction outcome loss': 0.1259696645429358, 'Total loss': 0.1259696645429358}
2022-12-05 22:20:47,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:47,283 INFO:     Epoch: 97
2022-12-05 22:20:48,085 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4825780682943084, 'Total loss': 0.4825780682943084} | train loss {'Reaction outcome loss': 0.12543234709019382, 'Total loss': 0.12543234709019382}
2022-12-05 22:20:48,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:48,085 INFO:     Epoch: 98
2022-12-05 22:20:48,884 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4911322197453542, 'Total loss': 0.4911322197453542} | train loss {'Reaction outcome loss': 0.12383873543829747, 'Total loss': 0.12383873543829747}
2022-12-05 22:20:48,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:48,884 INFO:     Epoch: 99
2022-12-05 22:20:49,686 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4861773072995923, 'Total loss': 0.4861773072995923} | train loss {'Reaction outcome loss': 0.12610500013726134, 'Total loss': 0.12610500013726134}
2022-12-05 22:20:49,686 INFO:     Best model found after epoch 14 of 100.
2022-12-05 22:20:49,686 INFO:   Done with stage: TRAINING
2022-12-05 22:20:49,686 INFO:   Starting stage: EVALUATION
2022-12-05 22:20:49,806 INFO:   Done with stage: EVALUATION
2022-12-05 22:20:49,806 INFO:   Leaving out SEQ value Fold_5
2022-12-05 22:20:49,819 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:20:49,819 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:20:50,462 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:20:50,463 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:20:50,532 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:20:50,532 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:20:50,532 INFO:     No hyperparam tuning for this model
2022-12-05 22:20:50,532 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:20:50,532 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:20:50,533 INFO:     None feature selector for col prot
2022-12-05 22:20:50,533 INFO:     None feature selector for col prot
2022-12-05 22:20:50,533 INFO:     None feature selector for col prot
2022-12-05 22:20:50,533 INFO:     None feature selector for col chem
2022-12-05 22:20:50,533 INFO:     None feature selector for col chem
2022-12-05 22:20:50,533 INFO:     None feature selector for col chem
2022-12-05 22:20:50,534 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:20:50,534 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:20:50,535 INFO:     Number of params in model 215821
2022-12-05 22:20:50,538 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:20:50,539 INFO:   Starting stage: TRAINING
2022-12-05 22:20:50,599 INFO:     Val loss before train {'Reaction outcome loss': 0.9591676985675638, 'Total loss': 0.9591676985675638}
2022-12-05 22:20:50,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:50,600 INFO:     Epoch: 0
2022-12-05 22:20:51,390 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5649858144196597, 'Total loss': 0.5649858144196597} | train loss {'Reaction outcome loss': 0.7766688688677185, 'Total loss': 0.7766688688677185}
2022-12-05 22:20:51,390 INFO:     Found new best model at epoch 0
2022-12-05 22:20:51,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:51,391 INFO:     Epoch: 1
2022-12-05 22:20:52,188 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48903528126803314, 'Total loss': 0.48903528126803314} | train loss {'Reaction outcome loss': 0.5225366164835132, 'Total loss': 0.5225366164835132}
2022-12-05 22:20:52,188 INFO:     Found new best model at epoch 1
2022-12-05 22:20:52,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:52,189 INFO:     Epoch: 2
2022-12-05 22:20:52,985 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45697218721563165, 'Total loss': 0.45697218721563165} | train loss {'Reaction outcome loss': 0.45241044869228286, 'Total loss': 0.45241044869228286}
2022-12-05 22:20:52,985 INFO:     Found new best model at epoch 2
2022-12-05 22:20:52,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:52,986 INFO:     Epoch: 3
2022-12-05 22:20:53,776 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4394905316558751, 'Total loss': 0.4394905316558751} | train loss {'Reaction outcome loss': 0.41605069013882656, 'Total loss': 0.41605069013882656}
2022-12-05 22:20:53,776 INFO:     Found new best model at epoch 3
2022-12-05 22:20:53,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:53,777 INFO:     Epoch: 4
2022-12-05 22:20:54,567 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4302565783939578, 'Total loss': 0.4302565783939578} | train loss {'Reaction outcome loss': 0.38646441272326876, 'Total loss': 0.38646441272326876}
2022-12-05 22:20:54,567 INFO:     Found new best model at epoch 4
2022-12-05 22:20:54,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:54,568 INFO:     Epoch: 5
2022-12-05 22:20:55,361 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4230304631319913, 'Total loss': 0.4230304631319913} | train loss {'Reaction outcome loss': 0.3647229574772776, 'Total loss': 0.3647229574772776}
2022-12-05 22:20:55,361 INFO:     Found new best model at epoch 5
2022-12-05 22:20:55,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:55,362 INFO:     Epoch: 6
2022-12-05 22:20:56,151 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.41684709015217697, 'Total loss': 0.41684709015217697} | train loss {'Reaction outcome loss': 0.34302806699154326, 'Total loss': 0.34302806699154326}
2022-12-05 22:20:56,151 INFO:     Found new best model at epoch 6
2022-12-05 22:20:56,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:56,152 INFO:     Epoch: 7
2022-12-05 22:20:56,943 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40294368632815103, 'Total loss': 0.40294368632815103} | train loss {'Reaction outcome loss': 0.3271794683471018, 'Total loss': 0.3271794683471018}
2022-12-05 22:20:56,944 INFO:     Found new best model at epoch 7
2022-12-05 22:20:56,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:56,944 INFO:     Epoch: 8
2022-12-05 22:20:57,738 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4153361561792818, 'Total loss': 0.4153361561792818} | train loss {'Reaction outcome loss': 0.3096862298797588, 'Total loss': 0.3096862298797588}
2022-12-05 22:20:57,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:57,738 INFO:     Epoch: 9
2022-12-05 22:20:58,534 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4027830318293788, 'Total loss': 0.4027830318293788} | train loss {'Reaction outcome loss': 0.2949211678334645, 'Total loss': 0.2949211678334645}
2022-12-05 22:20:58,534 INFO:     Found new best model at epoch 9
2022-12-05 22:20:58,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:58,535 INFO:     Epoch: 10
2022-12-05 22:20:59,325 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3996809422969818, 'Total loss': 0.3996809422969818} | train loss {'Reaction outcome loss': 0.28297336591141564, 'Total loss': 0.28297336591141564}
2022-12-05 22:20:59,325 INFO:     Found new best model at epoch 10
2022-12-05 22:20:59,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:20:59,326 INFO:     Epoch: 11
2022-12-05 22:21:00,116 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4005460136316039, 'Total loss': 0.4005460136316039} | train loss {'Reaction outcome loss': 0.2724821049339917, 'Total loss': 0.2724821049339917}
2022-12-05 22:21:00,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:00,117 INFO:     Epoch: 12
2022-12-05 22:21:00,906 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4032163636928255, 'Total loss': 0.4032163636928255} | train loss {'Reaction outcome loss': 0.26248314669545814, 'Total loss': 0.26248314669545814}
2022-12-05 22:21:00,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:00,907 INFO:     Epoch: 13
2022-12-05 22:21:01,697 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40823047642003407, 'Total loss': 0.40823047642003407} | train loss {'Reaction outcome loss': 0.25642056238590455, 'Total loss': 0.25642056238590455}
2022-12-05 22:21:01,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:01,697 INFO:     Epoch: 14
2022-12-05 22:21:02,491 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.39805571565573866, 'Total loss': 0.39805571565573866} | train loss {'Reaction outcome loss': 0.2441722132721726, 'Total loss': 0.2441722132721726}
2022-12-05 22:21:02,491 INFO:     Found new best model at epoch 14
2022-12-05 22:21:02,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:02,492 INFO:     Epoch: 15
2022-12-05 22:21:03,293 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.406108779494058, 'Total loss': 0.406108779494058} | train loss {'Reaction outcome loss': 0.23786052863816826, 'Total loss': 0.23786052863816826}
2022-12-05 22:21:03,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:03,293 INFO:     Epoch: 16
2022-12-05 22:21:04,085 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4091597920791669, 'Total loss': 0.4091597920791669} | train loss {'Reaction outcome loss': 0.23185975705178416, 'Total loss': 0.23185975705178416}
2022-12-05 22:21:04,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:04,085 INFO:     Epoch: 17
2022-12-05 22:21:04,876 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4037904231385751, 'Total loss': 0.4037904231385751} | train loss {'Reaction outcome loss': 0.2237926765668149, 'Total loss': 0.2237926765668149}
2022-12-05 22:21:04,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:04,877 INFO:     Epoch: 18
2022-12-05 22:21:05,667 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3954145083711906, 'Total loss': 0.3954145083711906} | train loss {'Reaction outcome loss': 0.21782049783030336, 'Total loss': 0.21782049783030336}
2022-12-05 22:21:05,668 INFO:     Found new best model at epoch 18
2022-12-05 22:21:05,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:05,668 INFO:     Epoch: 19
2022-12-05 22:21:06,460 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40216727724129503, 'Total loss': 0.40216727724129503} | train loss {'Reaction outcome loss': 0.21515761930115368, 'Total loss': 0.21515761930115368}
2022-12-05 22:21:06,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:06,460 INFO:     Epoch: 20
2022-12-05 22:21:07,256 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42460557107221, 'Total loss': 0.42460557107221} | train loss {'Reaction outcome loss': 0.20841018137503034, 'Total loss': 0.20841018137503034}
2022-12-05 22:21:07,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:07,257 INFO:     Epoch: 21
2022-12-05 22:21:08,050 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4100221673196012, 'Total loss': 0.4100221673196012} | train loss {'Reaction outcome loss': 0.20465543375027423, 'Total loss': 0.20465543375027423}
2022-12-05 22:21:08,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:08,050 INFO:     Epoch: 22
2022-12-05 22:21:08,842 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4158882071602751, 'Total loss': 0.4158882071602751} | train loss {'Reaction outcome loss': 0.20131862552798524, 'Total loss': 0.20131862552798524}
2022-12-05 22:21:08,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:08,842 INFO:     Epoch: 23
2022-12-05 22:21:09,633 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41634804831648414, 'Total loss': 0.41634804831648414} | train loss {'Reaction outcome loss': 0.19758164274449252, 'Total loss': 0.19758164274449252}
2022-12-05 22:21:09,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:09,634 INFO:     Epoch: 24
2022-12-05 22:21:10,423 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41073574612594466, 'Total loss': 0.41073574612594466} | train loss {'Reaction outcome loss': 0.19264829313876677, 'Total loss': 0.19264829313876677}
2022-12-05 22:21:10,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:10,423 INFO:     Epoch: 25
2022-12-05 22:21:11,215 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4081065021455288, 'Total loss': 0.4081065021455288} | train loss {'Reaction outcome loss': 0.18908943473836598, 'Total loss': 0.18908943473836598}
2022-12-05 22:21:11,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:11,216 INFO:     Epoch: 26
2022-12-05 22:21:12,005 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40569221397692506, 'Total loss': 0.40569221397692506} | train loss {'Reaction outcome loss': 0.18287684081160294, 'Total loss': 0.18287684081160294}
2022-12-05 22:21:12,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:12,006 INFO:     Epoch: 27
2022-12-05 22:21:12,797 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41574743373150175, 'Total loss': 0.41574743373150175} | train loss {'Reaction outcome loss': 0.18200035168200124, 'Total loss': 0.18200035168200124}
2022-12-05 22:21:12,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:12,798 INFO:     Epoch: 28
2022-12-05 22:21:13,593 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42179919203574007, 'Total loss': 0.42179919203574007} | train loss {'Reaction outcome loss': 0.17766827385948628, 'Total loss': 0.17766827385948628}
2022-12-05 22:21:13,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:13,594 INFO:     Epoch: 29
2022-12-05 22:21:14,390 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40906581621278415, 'Total loss': 0.40906581621278415} | train loss {'Reaction outcome loss': 0.17645998076364702, 'Total loss': 0.17645998076364702}
2022-12-05 22:21:14,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:14,390 INFO:     Epoch: 30
2022-12-05 22:21:15,186 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41997936300256034, 'Total loss': 0.41997936300256034} | train loss {'Reaction outcome loss': 0.1712490671447345, 'Total loss': 0.1712490671447345}
2022-12-05 22:21:15,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:15,186 INFO:     Epoch: 31
2022-12-05 22:21:15,977 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4299061362716285, 'Total loss': 0.4299061362716285} | train loss {'Reaction outcome loss': 0.16982562897764908, 'Total loss': 0.16982562897764908}
2022-12-05 22:21:15,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:15,977 INFO:     Epoch: 32
2022-12-05 22:21:16,766 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.422885829413479, 'Total loss': 0.422885829413479} | train loss {'Reaction outcome loss': 0.16880012032176767, 'Total loss': 0.16880012032176767}
2022-12-05 22:21:16,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:16,767 INFO:     Epoch: 33
2022-12-05 22:21:17,559 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4366950717839328, 'Total loss': 0.4366950717839328} | train loss {'Reaction outcome loss': 0.16454795293357907, 'Total loss': 0.16454795293357907}
2022-12-05 22:21:17,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:17,560 INFO:     Epoch: 34
2022-12-05 22:21:18,351 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4145852933553132, 'Total loss': 0.4145852933553132} | train loss {'Reaction outcome loss': 0.16438148698332358, 'Total loss': 0.16438148698332358}
2022-12-05 22:21:18,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:18,352 INFO:     Epoch: 35
2022-12-05 22:21:19,142 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43166473135352135, 'Total loss': 0.43166473135352135} | train loss {'Reaction outcome loss': 0.1642448377396379, 'Total loss': 0.1642448377396379}
2022-12-05 22:21:19,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:19,142 INFO:     Epoch: 36
2022-12-05 22:21:19,937 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44112161530012434, 'Total loss': 0.44112161530012434} | train loss {'Reaction outcome loss': 0.15819063478586626, 'Total loss': 0.15819063478586626}
2022-12-05 22:21:19,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:19,937 INFO:     Epoch: 37
2022-12-05 22:21:20,726 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43400898508050223, 'Total loss': 0.43400898508050223} | train loss {'Reaction outcome loss': 0.15758722416904508, 'Total loss': 0.15758722416904508}
2022-12-05 22:21:20,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:20,727 INFO:     Epoch: 38
2022-12-05 22:21:21,520 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44238766248930583, 'Total loss': 0.44238766248930583} | train loss {'Reaction outcome loss': 0.15696524059285924, 'Total loss': 0.15696524059285924}
2022-12-05 22:21:21,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:21,520 INFO:     Epoch: 39
2022-12-05 22:21:22,317 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4351342608305541, 'Total loss': 0.4351342608305541} | train loss {'Reaction outcome loss': 0.15663488451011326, 'Total loss': 0.15663488451011326}
2022-12-05 22:21:22,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:22,317 INFO:     Epoch: 40
2022-12-05 22:21:23,107 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4146572423421524, 'Total loss': 0.4146572423421524} | train loss {'Reaction outcome loss': 0.1545465633805309, 'Total loss': 0.1545465633805309}
2022-12-05 22:21:23,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:23,107 INFO:     Epoch: 41
2022-12-05 22:21:23,896 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41544062179640273, 'Total loss': 0.41544062179640273} | train loss {'Reaction outcome loss': 0.1523452565073967, 'Total loss': 0.1523452565073967}
2022-12-05 22:21:23,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:23,896 INFO:     Epoch: 42
2022-12-05 22:21:24,687 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45319307019764726, 'Total loss': 0.45319307019764726} | train loss {'Reaction outcome loss': 0.1490438010619611, 'Total loss': 0.1490438010619611}
2022-12-05 22:21:24,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:24,687 INFO:     Epoch: 43
2022-12-05 22:21:25,478 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43814752640371973, 'Total loss': 0.43814752640371973} | train loss {'Reaction outcome loss': 0.15133276295144948, 'Total loss': 0.15133276295144948}
2022-12-05 22:21:25,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:25,478 INFO:     Epoch: 44
2022-12-05 22:21:26,271 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4347425783899697, 'Total loss': 0.4347425783899697} | train loss {'Reaction outcome loss': 0.1492833034648579, 'Total loss': 0.1492833034648579}
2022-12-05 22:21:26,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:26,272 INFO:     Epoch: 45
2022-12-05 22:21:27,066 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43504818257960404, 'Total loss': 0.43504818257960404} | train loss {'Reaction outcome loss': 0.14647253665845006, 'Total loss': 0.14647253665845006}
2022-12-05 22:21:27,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:27,067 INFO:     Epoch: 46
2022-12-05 22:21:27,859 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42166044520722196, 'Total loss': 0.42166044520722196} | train loss {'Reaction outcome loss': 0.14636670699229046, 'Total loss': 0.14636670699229046}
2022-12-05 22:21:27,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:27,859 INFO:     Epoch: 47
2022-12-05 22:21:28,649 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4633864658800038, 'Total loss': 0.4633864658800038} | train loss {'Reaction outcome loss': 0.14465947379643213, 'Total loss': 0.14465947379643213}
2022-12-05 22:21:28,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:28,649 INFO:     Epoch: 48
2022-12-05 22:21:29,439 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45210953293876216, 'Total loss': 0.45210953293876216} | train loss {'Reaction outcome loss': 0.14104426943563989, 'Total loss': 0.14104426943563989}
2022-12-05 22:21:29,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:29,440 INFO:     Epoch: 49
2022-12-05 22:21:30,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4284654530611905, 'Total loss': 0.4284654530611905} | train loss {'Reaction outcome loss': 0.14134024283183472, 'Total loss': 0.14134024283183472}
2022-12-05 22:21:30,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:30,233 INFO:     Epoch: 50
2022-12-05 22:21:31,023 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4201228235932914, 'Total loss': 0.4201228235932914} | train loss {'Reaction outcome loss': 0.14022406205839041, 'Total loss': 0.14022406205839041}
2022-12-05 22:21:31,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:31,024 INFO:     Epoch: 51
2022-12-05 22:21:31,814 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4324337192070247, 'Total loss': 0.4324337192070247} | train loss {'Reaction outcome loss': 0.1425919733485397, 'Total loss': 0.1425919733485397}
2022-12-05 22:21:31,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:31,814 INFO:     Epoch: 52
2022-12-05 22:21:32,605 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4453541175885634, 'Total loss': 0.4453541175885634} | train loss {'Reaction outcome loss': 0.1393231222672122, 'Total loss': 0.1393231222672122}
2022-12-05 22:21:32,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:32,605 INFO:     Epoch: 53
2022-12-05 22:21:33,396 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42831311459568416, 'Total loss': 0.42831311459568416} | train loss {'Reaction outcome loss': 0.13904697332455188, 'Total loss': 0.13904697332455188}
2022-12-05 22:21:33,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:33,397 INFO:     Epoch: 54
2022-12-05 22:21:34,195 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4394643780860034, 'Total loss': 0.4394643780860034} | train loss {'Reaction outcome loss': 0.13709810601965505, 'Total loss': 0.13709810601965505}
2022-12-05 22:21:34,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:34,196 INFO:     Epoch: 55
2022-12-05 22:21:34,996 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4456833240322091, 'Total loss': 0.4456833240322091} | train loss {'Reaction outcome loss': 0.1381002753706915, 'Total loss': 0.1381002753706915}
2022-12-05 22:21:34,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:34,996 INFO:     Epoch: 56
2022-12-05 22:21:35,790 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44532910480417986, 'Total loss': 0.44532910480417986} | train loss {'Reaction outcome loss': 0.13671204887178479, 'Total loss': 0.13671204887178479}
2022-12-05 22:21:35,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:35,790 INFO:     Epoch: 57
2022-12-05 22:21:36,587 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4339346726509658, 'Total loss': 0.4339346726509658} | train loss {'Reaction outcome loss': 0.13732013893978937, 'Total loss': 0.13732013893978937}
2022-12-05 22:21:36,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:36,588 INFO:     Epoch: 58
2022-12-05 22:21:37,381 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.446518598632379, 'Total loss': 0.446518598632379} | train loss {'Reaction outcome loss': 0.1371833330818585, 'Total loss': 0.1371833330818585}
2022-12-05 22:21:37,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:37,381 INFO:     Epoch: 59
2022-12-05 22:21:38,173 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4397706328467889, 'Total loss': 0.4397706328467889} | train loss {'Reaction outcome loss': 0.13356919842487086, 'Total loss': 0.13356919842487086}
2022-12-05 22:21:38,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:38,173 INFO:     Epoch: 60
2022-12-05 22:21:38,965 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43087412061339075, 'Total loss': 0.43087412061339075} | train loss {'Reaction outcome loss': 0.13493201898372903, 'Total loss': 0.13493201898372903}
2022-12-05 22:21:38,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:38,965 INFO:     Epoch: 61
2022-12-05 22:21:39,758 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43740518154068425, 'Total loss': 0.43740518154068425} | train loss {'Reaction outcome loss': 0.13130830863148582, 'Total loss': 0.13130830863148582}
2022-12-05 22:21:39,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:39,758 INFO:     Epoch: 62
2022-12-05 22:21:40,551 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4336433826353062, 'Total loss': 0.4336433826353062} | train loss {'Reaction outcome loss': 0.13187651282214388, 'Total loss': 0.13187651282214388}
2022-12-05 22:21:40,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:40,551 INFO:     Epoch: 63
2022-12-05 22:21:41,350 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.43158265203237534, 'Total loss': 0.43158265203237534} | train loss {'Reaction outcome loss': 0.130491502560219, 'Total loss': 0.130491502560219}
2022-12-05 22:21:41,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:41,351 INFO:     Epoch: 64
2022-12-05 22:21:42,148 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43741814453493466, 'Total loss': 0.43741814453493466} | train loss {'Reaction outcome loss': 0.13319097698038937, 'Total loss': 0.13319097698038937}
2022-12-05 22:21:42,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:42,148 INFO:     Epoch: 65
2022-12-05 22:21:42,947 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45653042502023955, 'Total loss': 0.45653042502023955} | train loss {'Reaction outcome loss': 0.13093314146508975, 'Total loss': 0.13093314146508975}
2022-12-05 22:21:42,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:42,948 INFO:     Epoch: 66
2022-12-05 22:21:43,746 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4487053148279136, 'Total loss': 0.4487053148279136} | train loss {'Reaction outcome loss': 0.12913271957362185, 'Total loss': 0.12913271957362185}
2022-12-05 22:21:43,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:43,747 INFO:     Epoch: 67
2022-12-05 22:21:44,541 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4374937851997939, 'Total loss': 0.4374937851997939} | train loss {'Reaction outcome loss': 0.13086974936708504, 'Total loss': 0.13086974936708504}
2022-12-05 22:21:44,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:44,541 INFO:     Epoch: 68
2022-12-05 22:21:45,334 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4472786821424961, 'Total loss': 0.4472786821424961} | train loss {'Reaction outcome loss': 0.1274786599968769, 'Total loss': 0.1274786599968769}
2022-12-05 22:21:45,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:45,335 INFO:     Epoch: 69
2022-12-05 22:21:46,138 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44658473235639656, 'Total loss': 0.44658473235639656} | train loss {'Reaction outcome loss': 0.12883721744755702, 'Total loss': 0.12883721744755702}
2022-12-05 22:21:46,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:46,138 INFO:     Epoch: 70
2022-12-05 22:21:46,929 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4300976883281361, 'Total loss': 0.4300976883281361} | train loss {'Reaction outcome loss': 0.1294656091616774, 'Total loss': 0.1294656091616774}
2022-12-05 22:21:46,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:46,929 INFO:     Epoch: 71
2022-12-05 22:21:47,722 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4235048851167614, 'Total loss': 0.4235048851167614} | train loss {'Reaction outcome loss': 0.12691250859322598, 'Total loss': 0.12691250859322598}
2022-12-05 22:21:47,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:47,723 INFO:     Epoch: 72
2022-12-05 22:21:48,514 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43813168680803344, 'Total loss': 0.43813168680803344} | train loss {'Reaction outcome loss': 0.12731245191843837, 'Total loss': 0.12731245191843837}
2022-12-05 22:21:48,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:48,514 INFO:     Epoch: 73
2022-12-05 22:21:49,304 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4440859347920526, 'Total loss': 0.4440859347920526} | train loss {'Reaction outcome loss': 0.12453129846906784, 'Total loss': 0.12453129846906784}
2022-12-05 22:21:49,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:49,305 INFO:     Epoch: 74
2022-12-05 22:21:50,098 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43051185458898544, 'Total loss': 0.43051185458898544} | train loss {'Reaction outcome loss': 0.12356526803377331, 'Total loss': 0.12356526803377331}
2022-12-05 22:21:50,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:50,099 INFO:     Epoch: 75
2022-12-05 22:21:50,889 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4207658324051987, 'Total loss': 0.4207658324051987} | train loss {'Reaction outcome loss': 0.12500553075604293, 'Total loss': 0.12500553075604293}
2022-12-05 22:21:50,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:50,890 INFO:     Epoch: 76
2022-12-05 22:21:51,681 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4220041252503341, 'Total loss': 0.4220041252503341} | train loss {'Reaction outcome loss': 0.12428322018181183, 'Total loss': 0.12428322018181183}
2022-12-05 22:21:51,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:51,681 INFO:     Epoch: 77
2022-12-05 22:21:52,476 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4437397499145432, 'Total loss': 0.4437397499145432} | train loss {'Reaction outcome loss': 0.12454070299863815, 'Total loss': 0.12454070299863815}
2022-12-05 22:21:52,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:52,477 INFO:     Epoch: 78
2022-12-05 22:21:53,272 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4502563239498572, 'Total loss': 0.4502563239498572} | train loss {'Reaction outcome loss': 0.12672535839053442, 'Total loss': 0.12672535839053442}
2022-12-05 22:21:53,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:53,272 INFO:     Epoch: 79
2022-12-05 22:21:54,062 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43849356878887524, 'Total loss': 0.43849356878887524} | train loss {'Reaction outcome loss': 0.12257415751109318, 'Total loss': 0.12257415751109318}
2022-12-05 22:21:54,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:54,062 INFO:     Epoch: 80
2022-12-05 22:21:54,852 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.452823572199453, 'Total loss': 0.452823572199453} | train loss {'Reaction outcome loss': 0.12124244141183338, 'Total loss': 0.12124244141183338}
2022-12-05 22:21:54,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:54,852 INFO:     Epoch: 81
2022-12-05 22:21:55,642 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43904615015807474, 'Total loss': 0.43904615015807474} | train loss {'Reaction outcome loss': 0.12246321682267043, 'Total loss': 0.12246321682267043}
2022-12-05 22:21:55,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:55,643 INFO:     Epoch: 82
2022-12-05 22:21:56,433 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42741589270934294, 'Total loss': 0.42741589270934294} | train loss {'Reaction outcome loss': 0.12040876994783781, 'Total loss': 0.12040876994783781}
2022-12-05 22:21:56,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:56,433 INFO:     Epoch: 83
2022-12-05 22:21:57,222 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4272837294265628, 'Total loss': 0.4272837294265628} | train loss {'Reaction outcome loss': 0.12146320432728651, 'Total loss': 0.12146320432728651}
2022-12-05 22:21:57,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:57,223 INFO:     Epoch: 84
2022-12-05 22:21:58,013 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4325255468826402, 'Total loss': 0.4325255468826402} | train loss {'Reaction outcome loss': 0.1200487671381965, 'Total loss': 0.1200487671381965}
2022-12-05 22:21:58,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:58,013 INFO:     Epoch: 85
2022-12-05 22:21:58,802 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4304797093976628, 'Total loss': 0.4304797093976628} | train loss {'Reaction outcome loss': 0.12113415492052326, 'Total loss': 0.12113415492052326}
2022-12-05 22:21:58,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:58,802 INFO:     Epoch: 86
2022-12-05 22:21:59,595 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43601755594665353, 'Total loss': 0.43601755594665353} | train loss {'Reaction outcome loss': 0.11947468807730748, 'Total loss': 0.11947468807730748}
2022-12-05 22:21:59,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:21:59,596 INFO:     Epoch: 87
2022-12-05 22:22:00,395 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4388548352501609, 'Total loss': 0.4388548352501609} | train loss {'Reaction outcome loss': 0.11920281523382481, 'Total loss': 0.11920281523382481}
2022-12-05 22:22:00,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:00,395 INFO:     Epoch: 88
2022-12-05 22:22:01,192 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4418817548589273, 'Total loss': 0.4418817548589273} | train loss {'Reaction outcome loss': 0.11789744396370892, 'Total loss': 0.11789744396370892}
2022-12-05 22:22:01,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:01,193 INFO:     Epoch: 89
2022-12-05 22:22:01,986 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4723258109932596, 'Total loss': 0.4723258109932596} | train loss {'Reaction outcome loss': 0.11815645040145942, 'Total loss': 0.11815645040145942}
2022-12-05 22:22:01,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:01,987 INFO:     Epoch: 90
2022-12-05 22:22:02,781 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43479291315783153, 'Total loss': 0.43479291315783153} | train loss {'Reaction outcome loss': 0.11924811649535383, 'Total loss': 0.11924811649535383}
2022-12-05 22:22:02,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:02,781 INFO:     Epoch: 91
2022-12-05 22:22:03,572 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43264694105495105, 'Total loss': 0.43264694105495105} | train loss {'Reaction outcome loss': 0.12042558358944193, 'Total loss': 0.12042558358944193}
2022-12-05 22:22:03,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:03,573 INFO:     Epoch: 92
2022-12-05 22:22:04,362 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4336908987977288, 'Total loss': 0.4336908987977288} | train loss {'Reaction outcome loss': 0.1184357141353646, 'Total loss': 0.1184357141353646}
2022-12-05 22:22:04,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:04,363 INFO:     Epoch: 93
2022-12-05 22:22:05,156 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4240738361470655, 'Total loss': 0.4240738361470655} | train loss {'Reaction outcome loss': 0.1168885637987025, 'Total loss': 0.1168885637987025}
2022-12-05 22:22:05,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:05,156 INFO:     Epoch: 94
2022-12-05 22:22:05,945 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4558272808790207, 'Total loss': 0.4558272808790207} | train loss {'Reaction outcome loss': 0.11460547796545588, 'Total loss': 0.11460547796545588}
2022-12-05 22:22:05,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:05,945 INFO:     Epoch: 95
2022-12-05 22:22:06,734 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4407960616729476, 'Total loss': 0.4407960616729476} | train loss {'Reaction outcome loss': 0.11806095912672428, 'Total loss': 0.11806095912672428}
2022-12-05 22:22:06,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:06,735 INFO:     Epoch: 96
2022-12-05 22:22:07,525 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4396148571236567, 'Total loss': 0.4396148571236567} | train loss {'Reaction outcome loss': 0.11732841440077339, 'Total loss': 0.11732841440077339}
2022-12-05 22:22:07,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:07,525 INFO:     Epoch: 97
2022-12-05 22:22:08,315 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4360659974203868, 'Total loss': 0.4360659974203868} | train loss {'Reaction outcome loss': 0.11499252531069273, 'Total loss': 0.11499252531069273}
2022-12-05 22:22:08,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:08,315 INFO:     Epoch: 98
2022-12-05 22:22:09,108 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.442440861048288, 'Total loss': 0.442440861048288} | train loss {'Reaction outcome loss': 0.11602289138019693, 'Total loss': 0.11602289138019693}
2022-12-05 22:22:09,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:09,108 INFO:     Epoch: 99
2022-12-05 22:22:09,903 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43704560669985687, 'Total loss': 0.43704560669985687} | train loss {'Reaction outcome loss': 0.11432997609431646, 'Total loss': 0.11432997609431646}
2022-12-05 22:22:09,903 INFO:     Best model found after epoch 19 of 100.
2022-12-05 22:22:09,903 INFO:   Done with stage: TRAINING
2022-12-05 22:22:09,903 INFO:   Starting stage: EVALUATION
2022-12-05 22:22:10,035 INFO:   Done with stage: EVALUATION
2022-12-05 22:22:10,035 INFO:   Leaving out SEQ value Fold_6
2022-12-05 22:22:10,047 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 22:22:10,047 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:22:10,682 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:22:10,683 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:22:10,750 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:22:10,750 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:22:10,750 INFO:     No hyperparam tuning for this model
2022-12-05 22:22:10,750 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:22:10,750 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:22:10,751 INFO:     None feature selector for col prot
2022-12-05 22:22:10,751 INFO:     None feature selector for col prot
2022-12-05 22:22:10,751 INFO:     None feature selector for col prot
2022-12-05 22:22:10,752 INFO:     None feature selector for col chem
2022-12-05 22:22:10,752 INFO:     None feature selector for col chem
2022-12-05 22:22:10,752 INFO:     None feature selector for col chem
2022-12-05 22:22:10,752 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:22:10,752 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:22:10,754 INFO:     Number of params in model 215821
2022-12-05 22:22:10,757 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:22:10,757 INFO:   Starting stage: TRAINING
2022-12-05 22:22:10,817 INFO:     Val loss before train {'Reaction outcome loss': 1.0283432131589845, 'Total loss': 1.0283432131589845}
2022-12-05 22:22:10,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:10,817 INFO:     Epoch: 0
2022-12-05 22:22:11,606 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6425940588463185, 'Total loss': 0.6425940588463185} | train loss {'Reaction outcome loss': 0.7833616288959003, 'Total loss': 0.7833616288959003}
2022-12-05 22:22:11,606 INFO:     Found new best model at epoch 0
2022-12-05 22:22:11,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:11,607 INFO:     Epoch: 1
2022-12-05 22:22:12,394 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.544292748667473, 'Total loss': 0.544292748667473} | train loss {'Reaction outcome loss': 0.5375223589725182, 'Total loss': 0.5375223589725182}
2022-12-05 22:22:12,395 INFO:     Found new best model at epoch 1
2022-12-05 22:22:12,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:12,395 INFO:     Epoch: 2
2022-12-05 22:22:13,186 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5075545449589574, 'Total loss': 0.5075545449589574} | train loss {'Reaction outcome loss': 0.4596309379109594, 'Total loss': 0.4596309379109594}
2022-12-05 22:22:13,186 INFO:     Found new best model at epoch 2
2022-12-05 22:22:13,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:13,187 INFO:     Epoch: 3
2022-12-05 22:22:13,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49252303603083586, 'Total loss': 0.49252303603083586} | train loss {'Reaction outcome loss': 0.41971065989527545, 'Total loss': 0.41971065989527545}
2022-12-05 22:22:13,976 INFO:     Found new best model at epoch 3
2022-12-05 22:22:13,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:13,977 INFO:     Epoch: 4
2022-12-05 22:22:14,764 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47725806056067, 'Total loss': 0.47725806056067} | train loss {'Reaction outcome loss': 0.3914250914679199, 'Total loss': 0.3914250914679199}
2022-12-05 22:22:14,764 INFO:     Found new best model at epoch 4
2022-12-05 22:22:14,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:14,765 INFO:     Epoch: 5
2022-12-05 22:22:15,551 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47419864736324135, 'Total loss': 0.47419864736324135} | train loss {'Reaction outcome loss': 0.36954157164350887, 'Total loss': 0.36954157164350887}
2022-12-05 22:22:15,551 INFO:     Found new best model at epoch 5
2022-12-05 22:22:15,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:15,552 INFO:     Epoch: 6
2022-12-05 22:22:16,343 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47365007844082146, 'Total loss': 0.47365007844082146} | train loss {'Reaction outcome loss': 0.3524396071118898, 'Total loss': 0.3524396071118898}
2022-12-05 22:22:16,343 INFO:     Found new best model at epoch 6
2022-12-05 22:22:16,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:16,344 INFO:     Epoch: 7
2022-12-05 22:22:17,130 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46426286045895065, 'Total loss': 0.46426286045895065} | train loss {'Reaction outcome loss': 0.33442913969887084, 'Total loss': 0.33442913969887084}
2022-12-05 22:22:17,130 INFO:     Found new best model at epoch 7
2022-12-05 22:22:17,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:17,131 INFO:     Epoch: 8
2022-12-05 22:22:17,921 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46754372327826743, 'Total loss': 0.46754372327826743} | train loss {'Reaction outcome loss': 0.31889923524539, 'Total loss': 0.31889923524539}
2022-12-05 22:22:17,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:17,922 INFO:     Epoch: 9
2022-12-05 22:22:18,708 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4632931095223094, 'Total loss': 0.4632931095223094} | train loss {'Reaction outcome loss': 0.30616344206157275, 'Total loss': 0.30616344206157275}
2022-12-05 22:22:18,708 INFO:     Found new best model at epoch 9
2022-12-05 22:22:18,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:18,709 INFO:     Epoch: 10
2022-12-05 22:22:19,494 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46670050676478897, 'Total loss': 0.46670050676478897} | train loss {'Reaction outcome loss': 0.29129644068049604, 'Total loss': 0.29129644068049604}
2022-12-05 22:22:19,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:19,494 INFO:     Epoch: 11
2022-12-05 22:22:20,280 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4608735196119131, 'Total loss': 0.4608735196119131} | train loss {'Reaction outcome loss': 0.28280512683215686, 'Total loss': 0.28280512683215686}
2022-12-05 22:22:20,281 INFO:     Found new best model at epoch 11
2022-12-05 22:22:20,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:20,282 INFO:     Epoch: 12
2022-12-05 22:22:21,073 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.467719009102777, 'Total loss': 0.467719009102777} | train loss {'Reaction outcome loss': 0.27049069784459523, 'Total loss': 0.27049069784459523}
2022-12-05 22:22:21,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:21,074 INFO:     Epoch: 13
2022-12-05 22:22:21,864 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45838512203028037, 'Total loss': 0.45838512203028037} | train loss {'Reaction outcome loss': 0.26296649479353035, 'Total loss': 0.26296649479353035}
2022-12-05 22:22:21,864 INFO:     Found new best model at epoch 13
2022-12-05 22:22:21,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:21,865 INFO:     Epoch: 14
2022-12-05 22:22:22,650 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4678503132836763, 'Total loss': 0.4678503132836763} | train loss {'Reaction outcome loss': 0.25048716784622826, 'Total loss': 0.25048716784622826}
2022-12-05 22:22:22,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:22,651 INFO:     Epoch: 15
2022-12-05 22:22:23,439 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4598486357650092, 'Total loss': 0.4598486357650092} | train loss {'Reaction outcome loss': 0.24610181207783888, 'Total loss': 0.24610181207783888}
2022-12-05 22:22:23,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:23,439 INFO:     Epoch: 16
2022-12-05 22:22:24,225 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46028643967800364, 'Total loss': 0.46028643967800364} | train loss {'Reaction outcome loss': 0.23895670062877605, 'Total loss': 0.23895670062877605}
2022-12-05 22:22:24,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:24,225 INFO:     Epoch: 17
2022-12-05 22:22:25,014 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4604612030955248, 'Total loss': 0.4604612030955248} | train loss {'Reaction outcome loss': 0.22940069682835068, 'Total loss': 0.22940069682835068}
2022-12-05 22:22:25,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:25,014 INFO:     Epoch: 18
2022-12-05 22:22:25,807 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4640250341143719, 'Total loss': 0.4640250341143719} | train loss {'Reaction outcome loss': 0.22451529961048824, 'Total loss': 0.22451529961048824}
2022-12-05 22:22:25,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:25,807 INFO:     Epoch: 19
2022-12-05 22:22:26,592 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46299166570222655, 'Total loss': 0.46299166570222655} | train loss {'Reaction outcome loss': 0.2190681166763677, 'Total loss': 0.2190681166763677}
2022-12-05 22:22:26,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:26,592 INFO:     Epoch: 20
2022-12-05 22:22:27,372 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46163077201954156, 'Total loss': 0.46163077201954156} | train loss {'Reaction outcome loss': 0.21327498814732324, 'Total loss': 0.21327498814732324}
2022-12-05 22:22:27,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:27,372 INFO:     Epoch: 21
2022-12-05 22:22:28,152 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46734479139017504, 'Total loss': 0.46734479139017504} | train loss {'Reaction outcome loss': 0.20962799858057596, 'Total loss': 0.20962799858057596}
2022-12-05 22:22:28,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:28,153 INFO:     Epoch: 22
2022-12-05 22:22:28,934 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47520045728184457, 'Total loss': 0.47520045728184457} | train loss {'Reaction outcome loss': 0.20286808036206688, 'Total loss': 0.20286808036206688}
2022-12-05 22:22:28,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:28,934 INFO:     Epoch: 23
2022-12-05 22:22:29,717 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4720511883497238, 'Total loss': 0.4720511883497238} | train loss {'Reaction outcome loss': 0.20112117931063547, 'Total loss': 0.20112117931063547}
2022-12-05 22:22:29,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:29,718 INFO:     Epoch: 24
2022-12-05 22:22:30,498 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49674274477847785, 'Total loss': 0.49674274477847785} | train loss {'Reaction outcome loss': 0.19653064873619158, 'Total loss': 0.19653064873619158}
2022-12-05 22:22:30,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:30,498 INFO:     Epoch: 25
2022-12-05 22:22:31,278 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46806211457696073, 'Total loss': 0.46806211457696073} | train loss {'Reaction outcome loss': 0.1931077322663098, 'Total loss': 0.1931077322663098}
2022-12-05 22:22:31,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:31,278 INFO:     Epoch: 26
2022-12-05 22:22:32,056 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4846273418082747, 'Total loss': 0.4846273418082747} | train loss {'Reaction outcome loss': 0.18858021885523055, 'Total loss': 0.18858021885523055}
2022-12-05 22:22:32,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:32,057 INFO:     Epoch: 27
2022-12-05 22:22:32,835 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4852107482594113, 'Total loss': 0.4852107482594113} | train loss {'Reaction outcome loss': 0.18513349610090743, 'Total loss': 0.18513349610090743}
2022-12-05 22:22:32,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:32,836 INFO:     Epoch: 28
2022-12-05 22:22:33,618 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4788008405025615, 'Total loss': 0.4788008405025615} | train loss {'Reaction outcome loss': 0.18241858922830614, 'Total loss': 0.18241858922830614}
2022-12-05 22:22:33,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:33,618 INFO:     Epoch: 29
2022-12-05 22:22:34,396 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4846948277811671, 'Total loss': 0.4846948277811671} | train loss {'Reaction outcome loss': 0.17912024400029025, 'Total loss': 0.17912024400029025}
2022-12-05 22:22:34,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:34,397 INFO:     Epoch: 30
2022-12-05 22:22:35,175 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4767349819804347, 'Total loss': 0.4767349819804347} | train loss {'Reaction outcome loss': 0.17546743472091486, 'Total loss': 0.17546743472091486}
2022-12-05 22:22:35,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:35,175 INFO:     Epoch: 31
2022-12-05 22:22:35,957 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.483456838616105, 'Total loss': 0.483456838616105} | train loss {'Reaction outcome loss': 0.17170229687767682, 'Total loss': 0.17170229687767682}
2022-12-05 22:22:35,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:35,957 INFO:     Epoch: 32
2022-12-05 22:22:36,737 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4971290109462516, 'Total loss': 0.4971290109462516} | train loss {'Reaction outcome loss': 0.17041099690603184, 'Total loss': 0.17041099690603184}
2022-12-05 22:22:36,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:36,737 INFO:     Epoch: 33
2022-12-05 22:22:37,516 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4958597962246385, 'Total loss': 0.4958597962246385} | train loss {'Reaction outcome loss': 0.16940305143075643, 'Total loss': 0.16940305143075643}
2022-12-05 22:22:37,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:37,517 INFO:     Epoch: 34
2022-12-05 22:22:38,300 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48328061055305394, 'Total loss': 0.48328061055305394} | train loss {'Reaction outcome loss': 0.16588436314439187, 'Total loss': 0.16588436314439187}
2022-12-05 22:22:38,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:38,300 INFO:     Epoch: 35
2022-12-05 22:22:39,079 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4862710400376209, 'Total loss': 0.4862710400376209} | train loss {'Reaction outcome loss': 0.16395331228335128, 'Total loss': 0.16395331228335128}
2022-12-05 22:22:39,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:39,079 INFO:     Epoch: 36
2022-12-05 22:22:39,859 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4819994035155274, 'Total loss': 0.4819994035155274} | train loss {'Reaction outcome loss': 0.16067722145864954, 'Total loss': 0.16067722145864954}
2022-12-05 22:22:39,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:39,859 INFO:     Epoch: 37
2022-12-05 22:22:40,640 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4808077193623365, 'Total loss': 0.4808077193623365} | train loss {'Reaction outcome loss': 0.15872839337489644, 'Total loss': 0.15872839337489644}
2022-12-05 22:22:40,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:40,641 INFO:     Epoch: 38
2022-12-05 22:22:41,423 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.49150998578515165, 'Total loss': 0.49150998578515165} | train loss {'Reaction outcome loss': 0.15551671257517377, 'Total loss': 0.15551671257517377}
2022-12-05 22:22:41,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:41,423 INFO:     Epoch: 39
2022-12-05 22:22:42,202 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4831062967694083, 'Total loss': 0.4831062967694083} | train loss {'Reaction outcome loss': 0.1535506066713543, 'Total loss': 0.1535506066713543}
2022-12-05 22:22:42,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:42,202 INFO:     Epoch: 40
2022-12-05 22:22:42,984 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5045020601084066, 'Total loss': 0.5045020601084066} | train loss {'Reaction outcome loss': 0.1518081315243464, 'Total loss': 0.1518081315243464}
2022-12-05 22:22:42,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:42,985 INFO:     Epoch: 41
2022-12-05 22:22:43,768 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5053583579354508, 'Total loss': 0.5053583579354508} | train loss {'Reaction outcome loss': 0.1517683165682266, 'Total loss': 0.1517683165682266}
2022-12-05 22:22:43,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:43,768 INFO:     Epoch: 42
2022-12-05 22:22:44,548 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4998708897551825, 'Total loss': 0.4998708897551825} | train loss {'Reaction outcome loss': 0.15152032346632638, 'Total loss': 0.15152032346632638}
2022-12-05 22:22:44,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:44,549 INFO:     Epoch: 43
2022-12-05 22:22:45,328 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5047499464694843, 'Total loss': 0.5047499464694843} | train loss {'Reaction outcome loss': 0.14825997553521492, 'Total loss': 0.14825997553521492}
2022-12-05 22:22:45,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:45,329 INFO:     Epoch: 44
2022-12-05 22:22:46,112 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5012075228746548, 'Total loss': 0.5012075228746548} | train loss {'Reaction outcome loss': 0.14619021478383878, 'Total loss': 0.14619021478383878}
2022-12-05 22:22:46,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:46,113 INFO:     Epoch: 45
2022-12-05 22:22:46,901 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5080613577088644, 'Total loss': 0.5080613577088644} | train loss {'Reaction outcome loss': 0.14479713757201784, 'Total loss': 0.14479713757201784}
2022-12-05 22:22:46,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:46,901 INFO:     Epoch: 46
2022-12-05 22:22:47,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5003436984017838, 'Total loss': 0.5003436984017838} | train loss {'Reaction outcome loss': 0.14596158820280775, 'Total loss': 0.14596158820280775}
2022-12-05 22:22:47,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:47,683 INFO:     Epoch: 47
2022-12-05 22:22:48,467 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5106214714604754, 'Total loss': 0.5106214714604754} | train loss {'Reaction outcome loss': 0.14614065942644586, 'Total loss': 0.14614065942644586}
2022-12-05 22:22:48,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:48,467 INFO:     Epoch: 48
2022-12-05 22:22:49,247 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5046571898599004, 'Total loss': 0.5046571898599004} | train loss {'Reaction outcome loss': 0.1422078513051765, 'Total loss': 0.1422078513051765}
2022-12-05 22:22:49,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:49,248 INFO:     Epoch: 49
2022-12-05 22:22:50,030 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5142183030067489, 'Total loss': 0.5142183030067489} | train loss {'Reaction outcome loss': 0.14117594832004826, 'Total loss': 0.14117594832004826}
2022-12-05 22:22:50,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:50,030 INFO:     Epoch: 50
2022-12-05 22:22:50,822 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5201783970344899, 'Total loss': 0.5201783970344899} | train loss {'Reaction outcome loss': 0.13943267983124882, 'Total loss': 0.13943267983124882}
2022-12-05 22:22:50,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:50,823 INFO:     Epoch: 51
2022-12-05 22:22:51,618 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4901562499445538, 'Total loss': 0.4901562499445538} | train loss {'Reaction outcome loss': 0.13936938361463244, 'Total loss': 0.13936938361463244}
2022-12-05 22:22:51,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:51,618 INFO:     Epoch: 52
2022-12-05 22:22:52,408 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5099404530469761, 'Total loss': 0.5099404530469761} | train loss {'Reaction outcome loss': 0.1381067678210188, 'Total loss': 0.1381067678210188}
2022-12-05 22:22:52,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:52,408 INFO:     Epoch: 53
2022-12-05 22:22:53,200 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5017881968686747, 'Total loss': 0.5017881968686747} | train loss {'Reaction outcome loss': 0.13982631287110023, 'Total loss': 0.13982631287110023}
2022-12-05 22:22:53,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:53,200 INFO:     Epoch: 54
2022-12-05 22:22:53,994 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5128633348747741, 'Total loss': 0.5128633348747741} | train loss {'Reaction outcome loss': 0.13573330280477883, 'Total loss': 0.13573330280477883}
2022-12-05 22:22:53,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:53,994 INFO:     Epoch: 55
2022-12-05 22:22:54,785 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5076526458873305, 'Total loss': 0.5076526458873305} | train loss {'Reaction outcome loss': 0.1388862128598524, 'Total loss': 0.1388862128598524}
2022-12-05 22:22:54,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:54,785 INFO:     Epoch: 56
2022-12-05 22:22:55,576 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5163486274175866, 'Total loss': 0.5163486274175866} | train loss {'Reaction outcome loss': 0.13502668601567627, 'Total loss': 0.13502668601567627}
2022-12-05 22:22:55,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:55,576 INFO:     Epoch: 57
2022-12-05 22:22:56,371 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5214723015940467, 'Total loss': 0.5214723015940467} | train loss {'Reaction outcome loss': 0.1330408307143533, 'Total loss': 0.1330408307143533}
2022-12-05 22:22:56,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:56,371 INFO:     Epoch: 58
2022-12-05 22:22:57,160 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5147153156441312, 'Total loss': 0.5147153156441312} | train loss {'Reaction outcome loss': 0.13200943065104914, 'Total loss': 0.13200943065104914}
2022-12-05 22:22:57,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:57,160 INFO:     Epoch: 59
2022-12-05 22:22:57,950 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.530113889380943, 'Total loss': 0.530113889380943} | train loss {'Reaction outcome loss': 0.1323265990349235, 'Total loss': 0.1323265990349235}
2022-12-05 22:22:57,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:57,950 INFO:     Epoch: 60
2022-12-05 22:22:58,739 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5108172623224037, 'Total loss': 0.5108172623224037} | train loss {'Reaction outcome loss': 0.1300400225674642, 'Total loss': 0.1300400225674642}
2022-12-05 22:22:58,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:58,739 INFO:     Epoch: 61
2022-12-05 22:22:59,529 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5177500667267068, 'Total loss': 0.5177500667267068} | train loss {'Reaction outcome loss': 0.1276884050887139, 'Total loss': 0.1276884050887139}
2022-12-05 22:22:59,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:22:59,529 INFO:     Epoch: 62
2022-12-05 22:23:00,330 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5208812927783921, 'Total loss': 0.5208812927783921} | train loss {'Reaction outcome loss': 0.12989795015605746, 'Total loss': 0.12989795015605746}
2022-12-05 22:23:00,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:00,330 INFO:     Epoch: 63
2022-12-05 22:23:01,124 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5275127932775853, 'Total loss': 0.5275127932775853} | train loss {'Reaction outcome loss': 0.1290220162281614, 'Total loss': 0.1290220162281614}
2022-12-05 22:23:01,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:01,124 INFO:     Epoch: 64
2022-12-05 22:23:01,917 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5146383927312008, 'Total loss': 0.5146383927312008} | train loss {'Reaction outcome loss': 0.13044956095944174, 'Total loss': 0.13044956095944174}
2022-12-05 22:23:01,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:01,917 INFO:     Epoch: 65
2022-12-05 22:23:02,710 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5206452611573907, 'Total loss': 0.5206452611573907} | train loss {'Reaction outcome loss': 0.12665350612665174, 'Total loss': 0.12665350612665174}
2022-12-05 22:23:02,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:02,710 INFO:     Epoch: 66
2022-12-05 22:23:03,502 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5382763230523397, 'Total loss': 0.5382763230523397} | train loss {'Reaction outcome loss': 0.12712004873901606, 'Total loss': 0.12712004873901606}
2022-12-05 22:23:03,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:03,503 INFO:     Epoch: 67
2022-12-05 22:23:04,296 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5273212527119836, 'Total loss': 0.5273212527119836} | train loss {'Reaction outcome loss': 0.12615420928866158, 'Total loss': 0.12615420928866158}
2022-12-05 22:23:04,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:04,296 INFO:     Epoch: 68
2022-12-05 22:23:05,087 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5303552355184111, 'Total loss': 0.5303552355184111} | train loss {'Reaction outcome loss': 0.1247329408089157, 'Total loss': 0.1247329408089157}
2022-12-05 22:23:05,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:05,087 INFO:     Epoch: 69
2022-12-05 22:23:05,880 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5195301001848176, 'Total loss': 0.5195301001848176} | train loss {'Reaction outcome loss': 0.12558670441207828, 'Total loss': 0.12558670441207828}
2022-12-05 22:23:05,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:05,880 INFO:     Epoch: 70
2022-12-05 22:23:06,669 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5243314355611801, 'Total loss': 0.5243314355611801} | train loss {'Reaction outcome loss': 0.12838352940304845, 'Total loss': 0.12838352940304845}
2022-12-05 22:23:06,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:06,670 INFO:     Epoch: 71
2022-12-05 22:23:07,460 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5256196482236996, 'Total loss': 0.5256196482236996} | train loss {'Reaction outcome loss': 0.12289583108571099, 'Total loss': 0.12289583108571099}
2022-12-05 22:23:07,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:07,461 INFO:     Epoch: 72
2022-12-05 22:23:08,250 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5216482350992602, 'Total loss': 0.5216482350992602} | train loss {'Reaction outcome loss': 0.12566160021319253, 'Total loss': 0.12566160021319253}
2022-12-05 22:23:08,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:08,250 INFO:     Epoch: 73
2022-12-05 22:23:09,039 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5303224034087602, 'Total loss': 0.5303224034087602} | train loss {'Reaction outcome loss': 0.12161635048305769, 'Total loss': 0.12161635048305769}
2022-12-05 22:23:09,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:09,039 INFO:     Epoch: 74
2022-12-05 22:23:09,843 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5187009687340537, 'Total loss': 0.5187009687340537} | train loss {'Reaction outcome loss': 0.1253327725562038, 'Total loss': 0.1253327725562038}
2022-12-05 22:23:09,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:09,844 INFO:     Epoch: 75
2022-12-05 22:23:10,650 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5350717181383178, 'Total loss': 0.5350717181383178} | train loss {'Reaction outcome loss': 0.1214143198506418, 'Total loss': 0.1214143198506418}
2022-12-05 22:23:10,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:10,651 INFO:     Epoch: 76
2022-12-05 22:23:11,461 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5199025723823282, 'Total loss': 0.5199025723823282} | train loss {'Reaction outcome loss': 0.1228966603101399, 'Total loss': 0.1228966603101399}
2022-12-05 22:23:11,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:11,461 INFO:     Epoch: 77
2022-12-05 22:23:12,257 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5307683237763339, 'Total loss': 0.5307683237763339} | train loss {'Reaction outcome loss': 0.12114412302807828, 'Total loss': 0.12114412302807828}
2022-12-05 22:23:12,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:12,258 INFO:     Epoch: 78
2022-12-05 22:23:13,049 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5160384304648222, 'Total loss': 0.5160384304648222} | train loss {'Reaction outcome loss': 0.1190675145289937, 'Total loss': 0.1190675145289937}
2022-12-05 22:23:13,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:13,049 INFO:     Epoch: 79
2022-12-05 22:23:13,842 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5170978392625964, 'Total loss': 0.5170978392625964} | train loss {'Reaction outcome loss': 0.12049404255755734, 'Total loss': 0.12049404255755734}
2022-12-05 22:23:13,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:13,843 INFO:     Epoch: 80
2022-12-05 22:23:14,637 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5222191439811573, 'Total loss': 0.5222191439811573} | train loss {'Reaction outcome loss': 0.11944051925092936, 'Total loss': 0.11944051925092936}
2022-12-05 22:23:14,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:14,637 INFO:     Epoch: 81
2022-12-05 22:23:15,432 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5412711501121521, 'Total loss': 0.5412711501121521} | train loss {'Reaction outcome loss': 0.12018789477707421, 'Total loss': 0.12018789477707421}
2022-12-05 22:23:15,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:15,433 INFO:     Epoch: 82
2022-12-05 22:23:16,226 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5140722009331681, 'Total loss': 0.5140722009331681} | train loss {'Reaction outcome loss': 0.11901917450175789, 'Total loss': 0.11901917450175789}
2022-12-05 22:23:16,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:16,228 INFO:     Epoch: 83
2022-12-05 22:23:17,021 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5254100448516912, 'Total loss': 0.5254100448516912} | train loss {'Reaction outcome loss': 0.11700570782585466, 'Total loss': 0.11700570782585466}
2022-12-05 22:23:17,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:17,021 INFO:     Epoch: 84
2022-12-05 22:23:17,816 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5182406822609347, 'Total loss': 0.5182406822609347} | train loss {'Reaction outcome loss': 0.11575446621759138, 'Total loss': 0.11575446621759138}
2022-12-05 22:23:17,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:17,816 INFO:     Epoch: 85
2022-12-05 22:23:18,610 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5192094213047693, 'Total loss': 0.5192094213047693} | train loss {'Reaction outcome loss': 0.1165327538094926, 'Total loss': 0.1165327538094926}
2022-12-05 22:23:18,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:18,610 INFO:     Epoch: 86
2022-12-05 22:23:19,401 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5171219003061915, 'Total loss': 0.5171219003061915} | train loss {'Reaction outcome loss': 0.11614611064709846, 'Total loss': 0.11614611064709846}
2022-12-05 22:23:19,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:19,401 INFO:     Epoch: 87
2022-12-05 22:23:20,193 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5257843268472094, 'Total loss': 0.5257843268472094} | train loss {'Reaction outcome loss': 0.11833549634416084, 'Total loss': 0.11833549634416084}
2022-12-05 22:23:20,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:20,193 INFO:     Epoch: 88
2022-12-05 22:23:20,989 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.51810007732968, 'Total loss': 0.51810007732968} | train loss {'Reaction outcome loss': 0.11540320522503042, 'Total loss': 0.11540320522503042}
2022-12-05 22:23:20,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:20,989 INFO:     Epoch: 89
2022-12-05 22:23:21,782 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5361615440180135, 'Total loss': 0.5361615440180135} | train loss {'Reaction outcome loss': 0.11885949885129135, 'Total loss': 0.11885949885129135}
2022-12-05 22:23:21,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:21,782 INFO:     Epoch: 90
2022-12-05 22:23:22,573 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5252789965895719, 'Total loss': 0.5252789965895719} | train loss {'Reaction outcome loss': 0.11679669371882423, 'Total loss': 0.11679669371882423}
2022-12-05 22:23:22,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:22,574 INFO:     Epoch: 91
2022-12-05 22:23:23,365 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5261801529762357, 'Total loss': 0.5261801529762357} | train loss {'Reaction outcome loss': 0.11654300648398454, 'Total loss': 0.11654300648398454}
2022-12-05 22:23:23,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:23,365 INFO:     Epoch: 92
2022-12-05 22:23:24,155 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5450338665829149, 'Total loss': 0.5450338665829149} | train loss {'Reaction outcome loss': 0.11459918734693869, 'Total loss': 0.11459918734693869}
2022-12-05 22:23:24,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:24,155 INFO:     Epoch: 93
2022-12-05 22:23:24,950 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5274859091570211, 'Total loss': 0.5274859091570211} | train loss {'Reaction outcome loss': 0.11382949745022981, 'Total loss': 0.11382949745022981}
2022-12-05 22:23:24,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:24,950 INFO:     Epoch: 94
2022-12-05 22:23:25,744 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5286196220752805, 'Total loss': 0.5286196220752805} | train loss {'Reaction outcome loss': 0.11748848507394556, 'Total loss': 0.11748848507394556}
2022-12-05 22:23:25,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:25,744 INFO:     Epoch: 95
2022-12-05 22:23:26,536 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5238139449163924, 'Total loss': 0.5238139449163924} | train loss {'Reaction outcome loss': 0.1114813388615358, 'Total loss': 0.1114813388615358}
2022-12-05 22:23:26,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:26,536 INFO:     Epoch: 96
2022-12-05 22:23:27,332 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5208833155243896, 'Total loss': 0.5208833155243896} | train loss {'Reaction outcome loss': 0.11507768557620708, 'Total loss': 0.11507768557620708}
2022-12-05 22:23:27,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:27,332 INFO:     Epoch: 97
2022-12-05 22:23:28,123 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5220318223501361, 'Total loss': 0.5220318223501361} | train loss {'Reaction outcome loss': 0.11330409196861943, 'Total loss': 0.11330409196861943}
2022-12-05 22:23:28,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:28,123 INFO:     Epoch: 98
2022-12-05 22:23:28,917 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.527940280908762, 'Total loss': 0.527940280908762} | train loss {'Reaction outcome loss': 0.11030516208180027, 'Total loss': 0.11030516208180027}
2022-12-05 22:23:28,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:28,917 INFO:     Epoch: 99
2022-12-05 22:23:29,712 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5232968541771866, 'Total loss': 0.5232968541771866} | train loss {'Reaction outcome loss': 0.11255976811936888, 'Total loss': 0.11255976811936888}
2022-12-05 22:23:29,712 INFO:     Best model found after epoch 14 of 100.
2022-12-05 22:23:29,712 INFO:   Done with stage: TRAINING
2022-12-05 22:23:29,712 INFO:   Starting stage: EVALUATION
2022-12-05 22:23:29,851 INFO:   Done with stage: EVALUATION
2022-12-05 22:23:29,851 INFO:   Leaving out SEQ value Fold_7
2022-12-05 22:23:29,864 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:23:29,864 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:23:30,510 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:23:30,510 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:23:30,580 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:23:30,580 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:23:30,580 INFO:     No hyperparam tuning for this model
2022-12-05 22:23:30,580 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:23:30,580 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:23:30,581 INFO:     None feature selector for col prot
2022-12-05 22:23:30,581 INFO:     None feature selector for col prot
2022-12-05 22:23:30,581 INFO:     None feature selector for col prot
2022-12-05 22:23:30,581 INFO:     None feature selector for col chem
2022-12-05 22:23:30,581 INFO:     None feature selector for col chem
2022-12-05 22:23:30,582 INFO:     None feature selector for col chem
2022-12-05 22:23:30,582 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:23:30,582 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:23:30,583 INFO:     Number of params in model 215821
2022-12-05 22:23:30,586 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:23:30,587 INFO:   Starting stage: TRAINING
2022-12-05 22:23:30,648 INFO:     Val loss before train {'Reaction outcome loss': 1.0453008271076463, 'Total loss': 1.0453008271076463}
2022-12-05 22:23:30,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:30,648 INFO:     Epoch: 0
2022-12-05 22:23:31,451 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.657018440013582, 'Total loss': 0.657018440013582} | train loss {'Reaction outcome loss': 0.7905731678249375, 'Total loss': 0.7905731678249375}
2022-12-05 22:23:31,451 INFO:     Found new best model at epoch 0
2022-12-05 22:23:31,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:31,452 INFO:     Epoch: 1
2022-12-05 22:23:32,256 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5597510744224895, 'Total loss': 0.5597510744224895} | train loss {'Reaction outcome loss': 0.5420072943332696, 'Total loss': 0.5420072943332696}
2022-12-05 22:23:32,256 INFO:     Found new best model at epoch 1
2022-12-05 22:23:32,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:32,257 INFO:     Epoch: 2
2022-12-05 22:23:33,060 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5214810242707079, 'Total loss': 0.5214810242707079} | train loss {'Reaction outcome loss': 0.4730490482742748, 'Total loss': 0.4730490482742748}
2022-12-05 22:23:33,060 INFO:     Found new best model at epoch 2
2022-12-05 22:23:33,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:33,061 INFO:     Epoch: 3
2022-12-05 22:23:33,863 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4828870733353225, 'Total loss': 0.4828870733353225} | train loss {'Reaction outcome loss': 0.4296346740616906, 'Total loss': 0.4296346740616906}
2022-12-05 22:23:33,863 INFO:     Found new best model at epoch 3
2022-12-05 22:23:33,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:33,864 INFO:     Epoch: 4
2022-12-05 22:23:34,673 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4636499627747319, 'Total loss': 0.4636499627747319} | train loss {'Reaction outcome loss': 0.40123470403975053, 'Total loss': 0.40123470403975053}
2022-12-05 22:23:34,674 INFO:     Found new best model at epoch 4
2022-12-05 22:23:34,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:34,674 INFO:     Epoch: 5
2022-12-05 22:23:35,481 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4512100693854419, 'Total loss': 0.4512100693854419} | train loss {'Reaction outcome loss': 0.3764301866533295, 'Total loss': 0.3764301866533295}
2022-12-05 22:23:35,481 INFO:     Found new best model at epoch 5
2022-12-05 22:23:35,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:35,482 INFO:     Epoch: 6
2022-12-05 22:23:36,284 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44875662977045233, 'Total loss': 0.44875662977045233} | train loss {'Reaction outcome loss': 0.35657717621014, 'Total loss': 0.35657717621014}
2022-12-05 22:23:36,284 INFO:     Found new best model at epoch 6
2022-12-05 22:23:36,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:36,285 INFO:     Epoch: 7
2022-12-05 22:23:37,094 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45245336707342754, 'Total loss': 0.45245336707342754} | train loss {'Reaction outcome loss': 0.3393055670744469, 'Total loss': 0.3393055670744469}
2022-12-05 22:23:37,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:37,094 INFO:     Epoch: 8
2022-12-05 22:23:37,896 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43753062696619466, 'Total loss': 0.43753062696619466} | train loss {'Reaction outcome loss': 0.3243052062668627, 'Total loss': 0.3243052062668627}
2022-12-05 22:23:37,896 INFO:     Found new best model at epoch 8
2022-12-05 22:23:37,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:37,897 INFO:     Epoch: 9
2022-12-05 22:23:38,706 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4272525395182046, 'Total loss': 0.4272525395182046} | train loss {'Reaction outcome loss': 0.3073373165642542, 'Total loss': 0.3073373165642542}
2022-12-05 22:23:38,706 INFO:     Found new best model at epoch 9
2022-12-05 22:23:38,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:38,707 INFO:     Epoch: 10
2022-12-05 22:23:39,514 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42657047882676125, 'Total loss': 0.42657047882676125} | train loss {'Reaction outcome loss': 0.29424824842041536, 'Total loss': 0.29424824842041536}
2022-12-05 22:23:39,514 INFO:     Found new best model at epoch 10
2022-12-05 22:23:39,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:39,515 INFO:     Epoch: 11
2022-12-05 22:23:40,322 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42454798790541565, 'Total loss': 0.42454798790541565} | train loss {'Reaction outcome loss': 0.28093544336696785, 'Total loss': 0.28093544336696785}
2022-12-05 22:23:40,322 INFO:     Found new best model at epoch 11
2022-12-05 22:23:40,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:40,323 INFO:     Epoch: 12
2022-12-05 22:23:41,132 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4322873404757543, 'Total loss': 0.4322873404757543} | train loss {'Reaction outcome loss': 0.2721206123730348, 'Total loss': 0.2721206123730348}
2022-12-05 22:23:41,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:41,132 INFO:     Epoch: 13
2022-12-05 22:23:41,935 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43398091197013855, 'Total loss': 0.43398091197013855} | train loss {'Reaction outcome loss': 0.26084746552571175, 'Total loss': 0.26084746552571175}
2022-12-05 22:23:41,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:41,935 INFO:     Epoch: 14
2022-12-05 22:23:42,741 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42826210165565665, 'Total loss': 0.42826210165565665} | train loss {'Reaction outcome loss': 0.252563395762756, 'Total loss': 0.252563395762756}
2022-12-05 22:23:42,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:42,742 INFO:     Epoch: 15
2022-12-05 22:23:43,544 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42524445260112936, 'Total loss': 0.42524445260112936} | train loss {'Reaction outcome loss': 0.24462659807214815, 'Total loss': 0.24462659807214815}
2022-12-05 22:23:43,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:43,544 INFO:     Epoch: 16
2022-12-05 22:23:44,352 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43705425546927884, 'Total loss': 0.43705425546927884} | train loss {'Reaction outcome loss': 0.23563821073020658, 'Total loss': 0.23563821073020658}
2022-12-05 22:23:44,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:44,352 INFO:     Epoch: 17
2022-12-05 22:23:45,159 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44440309500152414, 'Total loss': 0.44440309500152414} | train loss {'Reaction outcome loss': 0.23236733158269235, 'Total loss': 0.23236733158269235}
2022-12-05 22:23:45,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:45,159 INFO:     Epoch: 18
2022-12-05 22:23:45,965 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4352952130138874, 'Total loss': 0.4352952130138874} | train loss {'Reaction outcome loss': 0.22404951079478186, 'Total loss': 0.22404951079478186}
2022-12-05 22:23:45,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:45,965 INFO:     Epoch: 19
2022-12-05 22:23:46,769 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43225881965322926, 'Total loss': 0.43225881965322926} | train loss {'Reaction outcome loss': 0.21563535036459083, 'Total loss': 0.21563535036459083}
2022-12-05 22:23:46,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:46,769 INFO:     Epoch: 20
2022-12-05 22:23:47,578 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4461138758131049, 'Total loss': 0.4461138758131049} | train loss {'Reaction outcome loss': 0.21423892818030812, 'Total loss': 0.21423892818030812}
2022-12-05 22:23:47,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:47,579 INFO:     Epoch: 21
2022-12-05 22:23:48,387 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.443084373392842, 'Total loss': 0.443084373392842} | train loss {'Reaction outcome loss': 0.20816742837609303, 'Total loss': 0.20816742837609303}
2022-12-05 22:23:48,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:48,387 INFO:     Epoch: 22
2022-12-05 22:23:49,194 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.450439167632298, 'Total loss': 0.450439167632298} | train loss {'Reaction outcome loss': 0.20288203120411885, 'Total loss': 0.20288203120411885}
2022-12-05 22:23:49,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:49,195 INFO:     Epoch: 23
2022-12-05 22:23:50,002 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44757856327024376, 'Total loss': 0.44757856327024376} | train loss {'Reaction outcome loss': 0.19993673916906118, 'Total loss': 0.19993673916906118}
2022-12-05 22:23:50,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:50,002 INFO:     Epoch: 24
2022-12-05 22:23:50,809 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44025940278714354, 'Total loss': 0.44025940278714354} | train loss {'Reaction outcome loss': 0.1971003035263669, 'Total loss': 0.1971003035263669}
2022-12-05 22:23:50,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:50,810 INFO:     Epoch: 25
2022-12-05 22:23:51,613 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4344210841438987, 'Total loss': 0.4344210841438987} | train loss {'Reaction outcome loss': 0.1918387324248831, 'Total loss': 0.1918387324248831}
2022-12-05 22:23:51,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:51,613 INFO:     Epoch: 26
2022-12-05 22:23:52,420 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4517026421698657, 'Total loss': 0.4517026421698657} | train loss {'Reaction outcome loss': 0.18790282933942734, 'Total loss': 0.18790282933942734}
2022-12-05 22:23:52,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:52,421 INFO:     Epoch: 27
2022-12-05 22:23:53,227 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4479589279402386, 'Total loss': 0.4479589279402386} | train loss {'Reaction outcome loss': 0.1846823776140809, 'Total loss': 0.1846823776140809}
2022-12-05 22:23:53,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:53,227 INFO:     Epoch: 28
2022-12-05 22:23:54,029 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4516880051656203, 'Total loss': 0.4516880051656203} | train loss {'Reaction outcome loss': 0.18148363327547426, 'Total loss': 0.18148363327547426}
2022-12-05 22:23:54,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:54,030 INFO:     Epoch: 29
2022-12-05 22:23:54,833 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44215314936908806, 'Total loss': 0.44215314936908806} | train loss {'Reaction outcome loss': 0.17848939653636225, 'Total loss': 0.17848939653636225}
2022-12-05 22:23:54,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:54,834 INFO:     Epoch: 30
2022-12-05 22:23:55,640 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43897926985201513, 'Total loss': 0.43897926985201513} | train loss {'Reaction outcome loss': 0.1781329650153977, 'Total loss': 0.1781329650153977}
2022-12-05 22:23:55,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:55,640 INFO:     Epoch: 31
2022-12-05 22:23:56,447 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4601671477271752, 'Total loss': 0.4601671477271752} | train loss {'Reaction outcome loss': 0.17355161773100977, 'Total loss': 0.17355161773100977}
2022-12-05 22:23:56,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:56,447 INFO:     Epoch: 32
2022-12-05 22:23:57,251 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.458382719789039, 'Total loss': 0.458382719789039} | train loss {'Reaction outcome loss': 0.1740428720781159, 'Total loss': 0.1740428720781159}
2022-12-05 22:23:57,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:57,251 INFO:     Epoch: 33
2022-12-05 22:23:58,059 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45794467560269614, 'Total loss': 0.45794467560269614} | train loss {'Reaction outcome loss': 0.16993084112783113, 'Total loss': 0.16993084112783113}
2022-12-05 22:23:58,060 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:58,060 INFO:     Epoch: 34
2022-12-05 22:23:58,864 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4448480030352419, 'Total loss': 0.4448480030352419} | train loss {'Reaction outcome loss': 0.17024806717170343, 'Total loss': 0.17024806717170343}
2022-12-05 22:23:58,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:58,864 INFO:     Epoch: 35
2022-12-05 22:23:59,671 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4510731282220645, 'Total loss': 0.4510731282220645} | train loss {'Reaction outcome loss': 0.16704103851225227, 'Total loss': 0.16704103851225227}
2022-12-05 22:23:59,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:23:59,672 INFO:     Epoch: 36
2022-12-05 22:24:00,478 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45691258053887973, 'Total loss': 0.45691258053887973} | train loss {'Reaction outcome loss': 0.16405215587527042, 'Total loss': 0.16405215587527042}
2022-12-05 22:24:00,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:00,479 INFO:     Epoch: 37
2022-12-05 22:24:01,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.457662682980299, 'Total loss': 0.457662682980299} | train loss {'Reaction outcome loss': 0.16147161210556665, 'Total loss': 0.16147161210556665}
2022-12-05 22:24:01,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:01,286 INFO:     Epoch: 38
2022-12-05 22:24:02,092 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4437439145350998, 'Total loss': 0.4437439145350998} | train loss {'Reaction outcome loss': 0.15930037090795174, 'Total loss': 0.15930037090795174}
2022-12-05 22:24:02,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:02,092 INFO:     Epoch: 39
2022-12-05 22:24:02,900 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4605356671593406, 'Total loss': 0.4605356671593406} | train loss {'Reaction outcome loss': 0.15823438451174768, 'Total loss': 0.15823438451174768}
2022-12-05 22:24:02,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:02,901 INFO:     Epoch: 40
2022-12-05 22:24:03,711 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46156485785137524, 'Total loss': 0.46156485785137524} | train loss {'Reaction outcome loss': 0.15627122949808836, 'Total loss': 0.15627122949808836}
2022-12-05 22:24:03,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:03,711 INFO:     Epoch: 41
2022-12-05 22:24:04,518 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4645663338967345, 'Total loss': 0.4645663338967345} | train loss {'Reaction outcome loss': 0.15606587015903525, 'Total loss': 0.15606587015903525}
2022-12-05 22:24:04,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:04,518 INFO:     Epoch: 42
2022-12-05 22:24:05,328 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4522794583304362, 'Total loss': 0.4522794583304362} | train loss {'Reaction outcome loss': 0.15318054347599466, 'Total loss': 0.15318054347599466}
2022-12-05 22:24:05,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:05,328 INFO:     Epoch: 43
2022-12-05 22:24:06,135 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4490620419383049, 'Total loss': 0.4490620419383049} | train loss {'Reaction outcome loss': 0.15338600381472778, 'Total loss': 0.15338600381472778}
2022-12-05 22:24:06,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:06,136 INFO:     Epoch: 44
2022-12-05 22:24:06,942 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4551255296577107, 'Total loss': 0.4551255296577107} | train loss {'Reaction outcome loss': 0.1498075309059312, 'Total loss': 0.1498075309059312}
2022-12-05 22:24:06,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:06,942 INFO:     Epoch: 45
2022-12-05 22:24:07,748 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4560252533040263, 'Total loss': 0.4560252533040263} | train loss {'Reaction outcome loss': 0.1494865089940328, 'Total loss': 0.1494865089940328}
2022-12-05 22:24:07,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:07,748 INFO:     Epoch: 46
2022-12-05 22:24:08,552 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4596707524562424, 'Total loss': 0.4596707524562424} | train loss {'Reaction outcome loss': 0.14760782865567074, 'Total loss': 0.14760782865567074}
2022-12-05 22:24:08,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:08,552 INFO:     Epoch: 47
2022-12-05 22:24:09,358 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47345426644791255, 'Total loss': 0.47345426644791255} | train loss {'Reaction outcome loss': 0.14849613105217296, 'Total loss': 0.14849613105217296}
2022-12-05 22:24:09,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:09,358 INFO:     Epoch: 48
2022-12-05 22:24:10,162 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44907483052123676, 'Total loss': 0.44907483052123676} | train loss {'Reaction outcome loss': 0.14622029864920244, 'Total loss': 0.14622029864920244}
2022-12-05 22:24:10,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:10,162 INFO:     Epoch: 49
2022-12-05 22:24:10,967 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4582100420851599, 'Total loss': 0.4582100420851599} | train loss {'Reaction outcome loss': 0.14659780738574843, 'Total loss': 0.14659780738574843}
2022-12-05 22:24:10,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:10,967 INFO:     Epoch: 50
2022-12-05 22:24:11,778 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4526631977747787, 'Total loss': 0.4526631977747787} | train loss {'Reaction outcome loss': 0.14246881875254575, 'Total loss': 0.14246881875254575}
2022-12-05 22:24:11,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:11,778 INFO:     Epoch: 51
2022-12-05 22:24:12,591 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4557462233034047, 'Total loss': 0.4557462233034047} | train loss {'Reaction outcome loss': 0.14162900808808063, 'Total loss': 0.14162900808808063}
2022-12-05 22:24:12,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:12,591 INFO:     Epoch: 52
2022-12-05 22:24:13,396 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4601997289467942, 'Total loss': 0.4601997289467942} | train loss {'Reaction outcome loss': 0.14015351696270367, 'Total loss': 0.14015351696270367}
2022-12-05 22:24:13,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:13,396 INFO:     Epoch: 53
2022-12-05 22:24:14,199 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46109969981692056, 'Total loss': 0.46109969981692056} | train loss {'Reaction outcome loss': 0.13970674925874318, 'Total loss': 0.13970674925874318}
2022-12-05 22:24:14,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:14,199 INFO:     Epoch: 54
2022-12-05 22:24:15,004 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46470321918075735, 'Total loss': 0.46470321918075735} | train loss {'Reaction outcome loss': 0.14264307806133142, 'Total loss': 0.14264307806133142}
2022-12-05 22:24:15,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:15,004 INFO:     Epoch: 55
2022-12-05 22:24:15,810 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4433187060058117, 'Total loss': 0.4433187060058117} | train loss {'Reaction outcome loss': 0.1390955773212256, 'Total loss': 0.1390955773212256}
2022-12-05 22:24:15,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:15,810 INFO:     Epoch: 56
2022-12-05 22:24:16,619 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44495304775508965, 'Total loss': 0.44495304775508965} | train loss {'Reaction outcome loss': 0.13606522240555816, 'Total loss': 0.13606522240555816}
2022-12-05 22:24:16,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:16,619 INFO:     Epoch: 57
2022-12-05 22:24:17,424 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4724958207119595, 'Total loss': 0.4724958207119595} | train loss {'Reaction outcome loss': 0.13710972812447336, 'Total loss': 0.13710972812447336}
2022-12-05 22:24:17,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:17,424 INFO:     Epoch: 58
2022-12-05 22:24:18,229 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4559948363087394, 'Total loss': 0.4559948363087394} | train loss {'Reaction outcome loss': 0.1367270062572413, 'Total loss': 0.1367270062572413}
2022-12-05 22:24:18,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:18,231 INFO:     Epoch: 59
2022-12-05 22:24:19,033 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.460569270293821, 'Total loss': 0.460569270293821} | train loss {'Reaction outcome loss': 0.1351811445032757, 'Total loss': 0.1351811445032757}
2022-12-05 22:24:19,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:19,034 INFO:     Epoch: 60
2022-12-05 22:24:19,837 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47180337966843083, 'Total loss': 0.47180337966843083} | train loss {'Reaction outcome loss': 0.13521749329482835, 'Total loss': 0.13521749329482835}
2022-12-05 22:24:19,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:19,837 INFO:     Epoch: 61
2022-12-05 22:24:20,645 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4712841651317748, 'Total loss': 0.4712841651317748} | train loss {'Reaction outcome loss': 0.133034213810348, 'Total loss': 0.133034213810348}
2022-12-05 22:24:20,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:20,645 INFO:     Epoch: 62
2022-12-05 22:24:21,454 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45352461256764154, 'Total loss': 0.45352461256764154} | train loss {'Reaction outcome loss': 0.1312877809433567, 'Total loss': 0.1312877809433567}
2022-12-05 22:24:21,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:21,454 INFO:     Epoch: 63
2022-12-05 22:24:22,258 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4607868492603302, 'Total loss': 0.4607868492603302} | train loss {'Reaction outcome loss': 0.13387671852063748, 'Total loss': 0.13387671852063748}
2022-12-05 22:24:22,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:22,258 INFO:     Epoch: 64
2022-12-05 22:24:23,068 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45733101361177186, 'Total loss': 0.45733101361177186} | train loss {'Reaction outcome loss': 0.13081002799839142, 'Total loss': 0.13081002799839142}
2022-12-05 22:24:23,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:23,068 INFO:     Epoch: 65
2022-12-05 22:24:23,875 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46069452268156136, 'Total loss': 0.46069452268156136} | train loss {'Reaction outcome loss': 0.13226459109442187, 'Total loss': 0.13226459109442187}
2022-12-05 22:24:23,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:23,875 INFO:     Epoch: 66
2022-12-05 22:24:24,678 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4542332725091414, 'Total loss': 0.4542332725091414} | train loss {'Reaction outcome loss': 0.1308322472445246, 'Total loss': 0.1308322472445246}
2022-12-05 22:24:24,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:24,679 INFO:     Epoch: 67
2022-12-05 22:24:25,485 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45196476646445016, 'Total loss': 0.45196476646445016} | train loss {'Reaction outcome loss': 0.12833823985420167, 'Total loss': 0.12833823985420167}
2022-12-05 22:24:25,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:25,485 INFO:     Epoch: 68
2022-12-05 22:24:26,288 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46008444679054344, 'Total loss': 0.46008444679054344} | train loss {'Reaction outcome loss': 0.12988946143342484, 'Total loss': 0.12988946143342484}
2022-12-05 22:24:26,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:26,288 INFO:     Epoch: 69
2022-12-05 22:24:27,091 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45953992212360556, 'Total loss': 0.45953992212360556} | train loss {'Reaction outcome loss': 0.12605993177050784, 'Total loss': 0.12605993177050784}
2022-12-05 22:24:27,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:27,091 INFO:     Epoch: 70
2022-12-05 22:24:27,897 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4647273255342787, 'Total loss': 0.4647273255342787} | train loss {'Reaction outcome loss': 0.12702403186572594, 'Total loss': 0.12702403186572594}
2022-12-05 22:24:27,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:27,898 INFO:     Epoch: 71
2022-12-05 22:24:28,702 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4617887715047056, 'Total loss': 0.4617887715047056} | train loss {'Reaction outcome loss': 0.12637887610828563, 'Total loss': 0.12637887610828563}
2022-12-05 22:24:28,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:28,703 INFO:     Epoch: 72
2022-12-05 22:24:29,507 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45406925170259044, 'Total loss': 0.45406925170259044} | train loss {'Reaction outcome loss': 0.1300003310560339, 'Total loss': 0.1300003310560339}
2022-12-05 22:24:29,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:29,507 INFO:     Epoch: 73
2022-12-05 22:24:30,311 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45943155783143913, 'Total loss': 0.45943155783143913} | train loss {'Reaction outcome loss': 0.12740476648773877, 'Total loss': 0.12740476648773877}
2022-12-05 22:24:30,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:30,311 INFO:     Epoch: 74
2022-12-05 22:24:31,113 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46266173469749367, 'Total loss': 0.46266173469749367} | train loss {'Reaction outcome loss': 0.12681653528969974, 'Total loss': 0.12681653528969974}
2022-12-05 22:24:31,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:31,114 INFO:     Epoch: 75
2022-12-05 22:24:31,919 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46762695705348795, 'Total loss': 0.46762695705348795} | train loss {'Reaction outcome loss': 0.12387825168233606, 'Total loss': 0.12387825168233606}
2022-12-05 22:24:31,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:31,919 INFO:     Epoch: 76
2022-12-05 22:24:32,725 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4692442451011051, 'Total loss': 0.4692442451011051} | train loss {'Reaction outcome loss': 0.12394992954232881, 'Total loss': 0.12394992954232881}
2022-12-05 22:24:32,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:32,726 INFO:     Epoch: 77
2022-12-05 22:24:33,536 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46664976464076474, 'Total loss': 0.46664976464076474} | train loss {'Reaction outcome loss': 0.12239727833413429, 'Total loss': 0.12239727833413429}
2022-12-05 22:24:33,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:33,536 INFO:     Epoch: 78
2022-12-05 22:24:34,341 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4618004523217678, 'Total loss': 0.4618004523217678} | train loss {'Reaction outcome loss': 0.12284052135768317, 'Total loss': 0.12284052135768317}
2022-12-05 22:24:34,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:34,342 INFO:     Epoch: 79
2022-12-05 22:24:35,152 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4668557471172376, 'Total loss': 0.4668557471172376} | train loss {'Reaction outcome loss': 0.12016477029500229, 'Total loss': 0.12016477029500229}
2022-12-05 22:24:35,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:35,153 INFO:     Epoch: 80
2022-12-05 22:24:35,957 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46949626674706285, 'Total loss': 0.46949626674706285} | train loss {'Reaction outcome loss': 0.12395898555780971, 'Total loss': 0.12395898555780971}
2022-12-05 22:24:35,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:35,957 INFO:     Epoch: 81
2022-12-05 22:24:36,764 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46687165139751, 'Total loss': 0.46687165139751} | train loss {'Reaction outcome loss': 0.12273177070047465, 'Total loss': 0.12273177070047465}
2022-12-05 22:24:36,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:36,765 INFO:     Epoch: 82
2022-12-05 22:24:37,568 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45432175348766823, 'Total loss': 0.45432175348766823} | train loss {'Reaction outcome loss': 0.12129216166889115, 'Total loss': 0.12129216166889115}
2022-12-05 22:24:37,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:37,568 INFO:     Epoch: 83
2022-12-05 22:24:38,374 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46172724748876964, 'Total loss': 0.46172724748876964} | train loss {'Reaction outcome loss': 0.120351500790416, 'Total loss': 0.120351500790416}
2022-12-05 22:24:38,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:38,374 INFO:     Epoch: 84
2022-12-05 22:24:39,179 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4704167182472619, 'Total loss': 0.4704167182472619} | train loss {'Reaction outcome loss': 0.12006165258090702, 'Total loss': 0.12006165258090702}
2022-12-05 22:24:39,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:39,179 INFO:     Epoch: 85
2022-12-05 22:24:39,988 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46251464262604713, 'Total loss': 0.46251464262604713} | train loss {'Reaction outcome loss': 0.1201099059018757, 'Total loss': 0.1201099059018757}
2022-12-05 22:24:39,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:39,988 INFO:     Epoch: 86
2022-12-05 22:24:40,793 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46325462785634125, 'Total loss': 0.46325462785634125} | train loss {'Reaction outcome loss': 0.1191409939802402, 'Total loss': 0.1191409939802402}
2022-12-05 22:24:40,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:40,793 INFO:     Epoch: 87
2022-12-05 22:24:41,596 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45829985409297724, 'Total loss': 0.45829985409297724} | train loss {'Reaction outcome loss': 0.11877309009920986, 'Total loss': 0.11877309009920986}
2022-12-05 22:24:41,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:41,596 INFO:     Epoch: 88
2022-12-05 22:24:42,403 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4563855440779166, 'Total loss': 0.4563855440779166} | train loss {'Reaction outcome loss': 0.12069479002422022, 'Total loss': 0.12069479002422022}
2022-12-05 22:24:42,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:42,403 INFO:     Epoch: 89
2022-12-05 22:24:43,208 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43668781830505893, 'Total loss': 0.43668781830505893} | train loss {'Reaction outcome loss': 0.11689930877107527, 'Total loss': 0.11689930877107527}
2022-12-05 22:24:43,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:43,209 INFO:     Epoch: 90
2022-12-05 22:24:44,016 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4563731493597681, 'Total loss': 0.4563731493597681} | train loss {'Reaction outcome loss': 0.11855660484833343, 'Total loss': 0.11855660484833343}
2022-12-05 22:24:44,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:44,017 INFO:     Epoch: 91
2022-12-05 22:24:44,823 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4690193913199685, 'Total loss': 0.4690193913199685} | train loss {'Reaction outcome loss': 0.11916029176134016, 'Total loss': 0.11916029176134016}
2022-12-05 22:24:44,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:44,823 INFO:     Epoch: 92
2022-12-05 22:24:45,628 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45767806470394135, 'Total loss': 0.45767806470394135} | train loss {'Reaction outcome loss': 0.11747920930370569, 'Total loss': 0.11747920930370569}
2022-12-05 22:24:45,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:45,628 INFO:     Epoch: 93
2022-12-05 22:24:46,435 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45746902511878446, 'Total loss': 0.45746902511878446} | train loss {'Reaction outcome loss': 0.11448508980233342, 'Total loss': 0.11448508980233342}
2022-12-05 22:24:46,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:46,436 INFO:     Epoch: 94
2022-12-05 22:24:47,239 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4664572849869728, 'Total loss': 0.4664572849869728} | train loss {'Reaction outcome loss': 0.11613912844932789, 'Total loss': 0.11613912844932789}
2022-12-05 22:24:47,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:47,239 INFO:     Epoch: 95
2022-12-05 22:24:48,049 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4549489989876747, 'Total loss': 0.4549489989876747} | train loss {'Reaction outcome loss': 0.11391797824762762, 'Total loss': 0.11391797824762762}
2022-12-05 22:24:48,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:48,049 INFO:     Epoch: 96
2022-12-05 22:24:48,859 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46247216686606407, 'Total loss': 0.46247216686606407} | train loss {'Reaction outcome loss': 0.11396221979708981, 'Total loss': 0.11396221979708981}
2022-12-05 22:24:48,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:48,859 INFO:     Epoch: 97
2022-12-05 22:24:49,665 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45862675906920974, 'Total loss': 0.45862675906920974} | train loss {'Reaction outcome loss': 0.11614529596596596, 'Total loss': 0.11614529596596596}
2022-12-05 22:24:49,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:49,666 INFO:     Epoch: 98
2022-12-05 22:24:50,470 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4626724427904595, 'Total loss': 0.4626724427904595} | train loss {'Reaction outcome loss': 0.11650167941866864, 'Total loss': 0.11650167941866864}
2022-12-05 22:24:50,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:50,470 INFO:     Epoch: 99
2022-12-05 22:24:51,273 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4556020327251066, 'Total loss': 0.4556020327251066} | train loss {'Reaction outcome loss': 0.11542117956184572, 'Total loss': 0.11542117956184572}
2022-12-05 22:24:51,273 INFO:     Best model found after epoch 12 of 100.
2022-12-05 22:24:51,273 INFO:   Done with stage: TRAINING
2022-12-05 22:24:51,273 INFO:   Starting stage: EVALUATION
2022-12-05 22:24:51,393 INFO:   Done with stage: EVALUATION
2022-12-05 22:24:51,394 INFO:   Leaving out SEQ value Fold_8
2022-12-05 22:24:51,406 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:24:51,406 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:24:52,114 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:24:52,114 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:24:52,183 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:24:52,183 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:24:52,183 INFO:     No hyperparam tuning for this model
2022-12-05 22:24:52,183 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:24:52,183 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:24:52,184 INFO:     None feature selector for col prot
2022-12-05 22:24:52,184 INFO:     None feature selector for col prot
2022-12-05 22:24:52,184 INFO:     None feature selector for col prot
2022-12-05 22:24:52,185 INFO:     None feature selector for col chem
2022-12-05 22:24:52,185 INFO:     None feature selector for col chem
2022-12-05 22:24:52,185 INFO:     None feature selector for col chem
2022-12-05 22:24:52,185 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:24:52,185 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:24:52,187 INFO:     Number of params in model 215821
2022-12-05 22:24:52,190 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:24:52,190 INFO:   Starting stage: TRAINING
2022-12-05 22:24:52,251 INFO:     Val loss before train {'Reaction outcome loss': 1.066461901773106, 'Total loss': 1.066461901773106}
2022-12-05 22:24:52,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:52,251 INFO:     Epoch: 0
2022-12-05 22:24:53,049 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6179496896537867, 'Total loss': 0.6179496896537867} | train loss {'Reaction outcome loss': 0.7847208512818765, 'Total loss': 0.7847208512818765}
2022-12-05 22:24:53,049 INFO:     Found new best model at epoch 0
2022-12-05 22:24:53,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:53,050 INFO:     Epoch: 1
2022-12-05 22:24:53,851 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.531267756765539, 'Total loss': 0.531267756765539} | train loss {'Reaction outcome loss': 0.5312091150143852, 'Total loss': 0.5312091150143852}
2022-12-05 22:24:53,852 INFO:     Found new best model at epoch 1
2022-12-05 22:24:53,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:53,852 INFO:     Epoch: 2
2022-12-05 22:24:54,655 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49462106823921204, 'Total loss': 0.49462106823921204} | train loss {'Reaction outcome loss': 0.46714642523271355, 'Total loss': 0.46714642523271355}
2022-12-05 22:24:54,655 INFO:     Found new best model at epoch 2
2022-12-05 22:24:54,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:54,656 INFO:     Epoch: 3
2022-12-05 22:24:55,457 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4653095453977585, 'Total loss': 0.4653095453977585} | train loss {'Reaction outcome loss': 0.42802126374970445, 'Total loss': 0.42802126374970445}
2022-12-05 22:24:55,457 INFO:     Found new best model at epoch 3
2022-12-05 22:24:55,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:55,458 INFO:     Epoch: 4
2022-12-05 22:24:56,257 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47420432757247577, 'Total loss': 0.47420432757247577} | train loss {'Reaction outcome loss': 0.3997123796749211, 'Total loss': 0.3997123796749211}
2022-12-05 22:24:56,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:56,258 INFO:     Epoch: 5
2022-12-05 22:24:57,066 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44666702435775235, 'Total loss': 0.44666702435775235} | train loss {'Reaction outcome loss': 0.38285889983297844, 'Total loss': 0.38285889983297844}
2022-12-05 22:24:57,066 INFO:     Found new best model at epoch 5
2022-12-05 22:24:57,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:57,067 INFO:     Epoch: 6
2022-12-05 22:24:57,873 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4279812692918561, 'Total loss': 0.4279812692918561} | train loss {'Reaction outcome loss': 0.3636756226489215, 'Total loss': 0.3636756226489215}
2022-12-05 22:24:57,873 INFO:     Found new best model at epoch 6
2022-12-05 22:24:57,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:57,874 INFO:     Epoch: 7
2022-12-05 22:24:58,672 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.415378521789204, 'Total loss': 0.415378521789204} | train loss {'Reaction outcome loss': 0.3438762129011785, 'Total loss': 0.3438762129011785}
2022-12-05 22:24:58,672 INFO:     Found new best model at epoch 7
2022-12-05 22:24:58,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:58,673 INFO:     Epoch: 8
2022-12-05 22:24:59,474 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4230082065544345, 'Total loss': 0.4230082065544345} | train loss {'Reaction outcome loss': 0.3281035641668297, 'Total loss': 0.3281035641668297}
2022-12-05 22:24:59,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:24:59,474 INFO:     Epoch: 9
2022-12-05 22:25:00,273 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41979326883500273, 'Total loss': 0.41979326883500273} | train loss {'Reaction outcome loss': 0.31861749716736526, 'Total loss': 0.31861749716736526}
2022-12-05 22:25:00,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:00,273 INFO:     Epoch: 10
2022-12-05 22:25:01,073 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41216177662665193, 'Total loss': 0.41216177662665193} | train loss {'Reaction outcome loss': 0.3012641575338266, 'Total loss': 0.3012641575338266}
2022-12-05 22:25:01,073 INFO:     Found new best model at epoch 10
2022-12-05 22:25:01,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:01,074 INFO:     Epoch: 11
2022-12-05 22:25:01,874 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42196725410493935, 'Total loss': 0.42196725410493935} | train loss {'Reaction outcome loss': 0.2967336111162838, 'Total loss': 0.2967336111162838}
2022-12-05 22:25:01,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:01,874 INFO:     Epoch: 12
2022-12-05 22:25:02,673 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39796863801100035, 'Total loss': 0.39796863801100035} | train loss {'Reaction outcome loss': 0.28984409489250373, 'Total loss': 0.28984409489250373}
2022-12-05 22:25:02,673 INFO:     Found new best model at epoch 12
2022-12-05 22:25:02,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:02,674 INFO:     Epoch: 13
2022-12-05 22:25:03,475 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4171959593553435, 'Total loss': 0.4171959593553435} | train loss {'Reaction outcome loss': 0.2771786788388001, 'Total loss': 0.2771786788388001}
2022-12-05 22:25:03,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:03,475 INFO:     Epoch: 14
2022-12-05 22:25:04,278 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41372674297202716, 'Total loss': 0.41372674297202716} | train loss {'Reaction outcome loss': 0.2646833154625497, 'Total loss': 0.2646833154625497}
2022-12-05 22:25:04,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:04,278 INFO:     Epoch: 15
2022-12-05 22:25:05,081 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42394550720399077, 'Total loss': 0.42394550720399077} | train loss {'Reaction outcome loss': 0.25775534754641627, 'Total loss': 0.25775534754641627}
2022-12-05 22:25:05,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:05,081 INFO:     Epoch: 16
2022-12-05 22:25:05,881 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.397652085701173, 'Total loss': 0.397652085701173} | train loss {'Reaction outcome loss': 0.25087432432090223, 'Total loss': 0.25087432432090223}
2022-12-05 22:25:05,881 INFO:     Found new best model at epoch 16
2022-12-05 22:25:05,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:05,882 INFO:     Epoch: 17
2022-12-05 22:25:06,688 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4079557660628449, 'Total loss': 0.4079557660628449} | train loss {'Reaction outcome loss': 0.24307089452801445, 'Total loss': 0.24307089452801445}
2022-12-05 22:25:06,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:06,688 INFO:     Epoch: 18
2022-12-05 22:25:07,489 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4335765378041701, 'Total loss': 0.4335765378041701} | train loss {'Reaction outcome loss': 0.2367603546046173, 'Total loss': 0.2367603546046173}
2022-12-05 22:25:07,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:07,489 INFO:     Epoch: 19
2022-12-05 22:25:08,288 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41540099917487666, 'Total loss': 0.41540099917487666} | train loss {'Reaction outcome loss': 0.23239484578672692, 'Total loss': 0.23239484578672692}
2022-12-05 22:25:08,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:08,289 INFO:     Epoch: 20
2022-12-05 22:25:09,086 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40623207187110727, 'Total loss': 0.40623207187110727} | train loss {'Reaction outcome loss': 0.22868787056883336, 'Total loss': 0.22868787056883336}
2022-12-05 22:25:09,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:09,086 INFO:     Epoch: 21
2022-12-05 22:25:09,887 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4098470178856091, 'Total loss': 0.4098470178856091} | train loss {'Reaction outcome loss': 0.22306944702389964, 'Total loss': 0.22306944702389964}
2022-12-05 22:25:09,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:09,887 INFO:     Epoch: 22
2022-12-05 22:25:10,687 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4198834386400201, 'Total loss': 0.4198834386400201} | train loss {'Reaction outcome loss': 0.21668921350708858, 'Total loss': 0.21668921350708858}
2022-12-05 22:25:10,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:10,688 INFO:     Epoch: 23
2022-12-05 22:25:11,487 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41877431828867306, 'Total loss': 0.41877431828867306} | train loss {'Reaction outcome loss': 0.2147713348209134, 'Total loss': 0.2147713348209134}
2022-12-05 22:25:11,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:11,488 INFO:     Epoch: 24
2022-12-05 22:25:12,285 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4188309596343474, 'Total loss': 0.4188309596343474} | train loss {'Reaction outcome loss': 0.21126164695783425, 'Total loss': 0.21126164695783425}
2022-12-05 22:25:12,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:12,285 INFO:     Epoch: 25
2022-12-05 22:25:13,085 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41564498062838207, 'Total loss': 0.41564498062838207} | train loss {'Reaction outcome loss': 0.20526850571938854, 'Total loss': 0.20526850571938854}
2022-12-05 22:25:13,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:13,085 INFO:     Epoch: 26
2022-12-05 22:25:13,883 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4285141820596023, 'Total loss': 0.4285141820596023} | train loss {'Reaction outcome loss': 0.20152329615796144, 'Total loss': 0.20152329615796144}
2022-12-05 22:25:13,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:13,883 INFO:     Epoch: 27
2022-12-05 22:25:14,686 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42363613505255093, 'Total loss': 0.42363613505255093} | train loss {'Reaction outcome loss': 0.2023830738687805, 'Total loss': 0.2023830738687805}
2022-12-05 22:25:14,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:14,686 INFO:     Epoch: 28
2022-12-05 22:25:15,487 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41989555819468066, 'Total loss': 0.41989555819468066} | train loss {'Reaction outcome loss': 0.1980626866672007, 'Total loss': 0.1980626866672007}
2022-12-05 22:25:15,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:15,487 INFO:     Epoch: 29
2022-12-05 22:25:16,288 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42268111861564894, 'Total loss': 0.42268111861564894} | train loss {'Reaction outcome loss': 0.1956681259851224, 'Total loss': 0.1956681259851224}
2022-12-05 22:25:16,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:16,288 INFO:     Epoch: 30
2022-12-05 22:25:17,088 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42483108592304314, 'Total loss': 0.42483108592304314} | train loss {'Reaction outcome loss': 0.19072189470112083, 'Total loss': 0.19072189470112083}
2022-12-05 22:25:17,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:17,088 INFO:     Epoch: 31
2022-12-05 22:25:17,886 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4191847514699806, 'Total loss': 0.4191847514699806} | train loss {'Reaction outcome loss': 0.19277938874626932, 'Total loss': 0.19277938874626932}
2022-12-05 22:25:17,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:17,887 INFO:     Epoch: 32
2022-12-05 22:25:18,688 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42263557304712857, 'Total loss': 0.42263557304712857} | train loss {'Reaction outcome loss': 0.1827423217072932, 'Total loss': 0.1827423217072932}
2022-12-05 22:25:18,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:18,689 INFO:     Epoch: 33
2022-12-05 22:25:19,486 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44327702948992903, 'Total loss': 0.44327702948992903} | train loss {'Reaction outcome loss': 0.1799496212589596, 'Total loss': 0.1799496212589596}
2022-12-05 22:25:19,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:19,487 INFO:     Epoch: 34
2022-12-05 22:25:20,289 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4125824997370893, 'Total loss': 0.4125824997370893} | train loss {'Reaction outcome loss': 0.17735192679653042, 'Total loss': 0.17735192679653042}
2022-12-05 22:25:20,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:20,290 INFO:     Epoch: 35
2022-12-05 22:25:21,088 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4304210340434855, 'Total loss': 0.4304210340434855} | train loss {'Reaction outcome loss': 0.17625790423438376, 'Total loss': 0.17625790423438376}
2022-12-05 22:25:21,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:21,089 INFO:     Epoch: 36
2022-12-05 22:25:21,887 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42906716432083736, 'Total loss': 0.42906716432083736} | train loss {'Reaction outcome loss': 0.17193335726072914, 'Total loss': 0.17193335726072914}
2022-12-05 22:25:21,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:21,888 INFO:     Epoch: 37
2022-12-05 22:25:22,687 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42040593989870767, 'Total loss': 0.42040593989870767} | train loss {'Reaction outcome loss': 0.17052292086586765, 'Total loss': 0.17052292086586765}
2022-12-05 22:25:22,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:22,687 INFO:     Epoch: 38
2022-12-05 22:25:23,485 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4191625439985232, 'Total loss': 0.4191625439985232} | train loss {'Reaction outcome loss': 0.17007784706800572, 'Total loss': 0.17007784706800572}
2022-12-05 22:25:23,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:23,485 INFO:     Epoch: 39
2022-12-05 22:25:24,285 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41590157185088505, 'Total loss': 0.41590157185088505} | train loss {'Reaction outcome loss': 0.17092044434325415, 'Total loss': 0.17092044434325415}
2022-12-05 22:25:24,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:24,286 INFO:     Epoch: 40
2022-12-05 22:25:25,087 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4286946779624982, 'Total loss': 0.4286946779624982} | train loss {'Reaction outcome loss': 0.1629179860144733, 'Total loss': 0.1629179860144733}
2022-12-05 22:25:25,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:25,087 INFO:     Epoch: 41
2022-12-05 22:25:25,885 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4264217290011319, 'Total loss': 0.4264217290011319} | train loss {'Reaction outcome loss': 0.16219207912170694, 'Total loss': 0.16219207912170694}
2022-12-05 22:25:25,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:25,886 INFO:     Epoch: 42
2022-12-05 22:25:26,687 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42769487269900064, 'Total loss': 0.42769487269900064} | train loss {'Reaction outcome loss': 0.15982630678833376, 'Total loss': 0.15982630678833376}
2022-12-05 22:25:26,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:26,688 INFO:     Epoch: 43
2022-12-05 22:25:27,486 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42471112175421283, 'Total loss': 0.42471112175421283} | train loss {'Reaction outcome loss': 0.15865562243485137, 'Total loss': 0.15865562243485137}
2022-12-05 22:25:27,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:27,486 INFO:     Epoch: 44
2022-12-05 22:25:28,292 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4383934707465497, 'Total loss': 0.4383934707465497} | train loss {'Reaction outcome loss': 0.15800923566797725, 'Total loss': 0.15800923566797725}
2022-12-05 22:25:28,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:28,292 INFO:     Epoch: 45
2022-12-05 22:25:29,092 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43242137743668124, 'Total loss': 0.43242137743668124} | train loss {'Reaction outcome loss': 0.15717754333547734, 'Total loss': 0.15717754333547734}
2022-12-05 22:25:29,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:29,093 INFO:     Epoch: 46
2022-12-05 22:25:29,895 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4161234586076303, 'Total loss': 0.4161234586076303} | train loss {'Reaction outcome loss': 0.15920770516324984, 'Total loss': 0.15920770516324984}
2022-12-05 22:25:29,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:29,895 INFO:     Epoch: 47
2022-12-05 22:25:30,696 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42540331692858174, 'Total loss': 0.42540331692858174} | train loss {'Reaction outcome loss': 0.15315842291770074, 'Total loss': 0.15315842291770074}
2022-12-05 22:25:30,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:30,697 INFO:     Epoch: 48
2022-12-05 22:25:31,494 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4376172160899097, 'Total loss': 0.4376172160899097} | train loss {'Reaction outcome loss': 0.1534890891674921, 'Total loss': 0.1534890891674921}
2022-12-05 22:25:31,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:31,494 INFO:     Epoch: 49
2022-12-05 22:25:32,291 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4326111586256461, 'Total loss': 0.4326111586256461} | train loss {'Reaction outcome loss': 0.151200918081077, 'Total loss': 0.151200918081077}
2022-12-05 22:25:32,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:32,291 INFO:     Epoch: 50
2022-12-05 22:25:33,090 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42073196003382857, 'Total loss': 0.42073196003382857} | train loss {'Reaction outcome loss': 0.15171315520247708, 'Total loss': 0.15171315520247708}
2022-12-05 22:25:33,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:33,090 INFO:     Epoch: 51
2022-12-05 22:25:33,894 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.431037227538499, 'Total loss': 0.431037227538499} | train loss {'Reaction outcome loss': 0.1499032549756138, 'Total loss': 0.1499032549756138}
2022-12-05 22:25:33,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:33,895 INFO:     Epoch: 52
2022-12-05 22:25:34,694 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41659789566289296, 'Total loss': 0.41659789566289296} | train loss {'Reaction outcome loss': 0.14876752739644003, 'Total loss': 0.14876752739644003}
2022-12-05 22:25:34,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:34,695 INFO:     Epoch: 53
2022-12-05 22:25:35,497 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43215992200103676, 'Total loss': 0.43215992200103676} | train loss {'Reaction outcome loss': 0.1616933111719757, 'Total loss': 0.1616933111719757}
2022-12-05 22:25:35,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:35,497 INFO:     Epoch: 54
2022-12-05 22:25:36,298 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4351400187747045, 'Total loss': 0.4351400187747045} | train loss {'Reaction outcome loss': 0.1506938562287312, 'Total loss': 0.1506938562287312}
2022-12-05 22:25:36,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:36,298 INFO:     Epoch: 55
2022-12-05 22:25:37,097 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43194627355445514, 'Total loss': 0.43194627355445514} | train loss {'Reaction outcome loss': 0.1406040299638563, 'Total loss': 0.1406040299638563}
2022-12-05 22:25:37,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:37,098 INFO:     Epoch: 56
2022-12-05 22:25:37,900 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4358225351368839, 'Total loss': 0.4358225351368839} | train loss {'Reaction outcome loss': 0.14239721058496474, 'Total loss': 0.14239721058496474}
2022-12-05 22:25:37,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:37,900 INFO:     Epoch: 57
2022-12-05 22:25:38,704 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4271657612513412, 'Total loss': 0.4271657612513412} | train loss {'Reaction outcome loss': 0.13969526134774482, 'Total loss': 0.13969526134774482}
2022-12-05 22:25:38,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:38,704 INFO:     Epoch: 58
2022-12-05 22:25:39,501 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41915378482504323, 'Total loss': 0.41915378482504323} | train loss {'Reaction outcome loss': 0.14426214039054236, 'Total loss': 0.14426214039054236}
2022-12-05 22:25:39,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:39,502 INFO:     Epoch: 59
2022-12-05 22:25:40,301 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4250794928520918, 'Total loss': 0.4250794928520918} | train loss {'Reaction outcome loss': 0.14147903251391342, 'Total loss': 0.14147903251391342}
2022-12-05 22:25:40,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:40,301 INFO:     Epoch: 60
2022-12-05 22:25:41,103 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41992569545453245, 'Total loss': 0.41992569545453245} | train loss {'Reaction outcome loss': 0.1399485490205679, 'Total loss': 0.1399485490205679}
2022-12-05 22:25:41,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:41,103 INFO:     Epoch: 61
2022-12-05 22:25:41,903 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4103416163812984, 'Total loss': 0.4103416163812984} | train loss {'Reaction outcome loss': 0.14195117896501924, 'Total loss': 0.14195117896501924}
2022-12-05 22:25:41,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:41,903 INFO:     Epoch: 62
2022-12-05 22:25:42,704 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42817552692510863, 'Total loss': 0.42817552692510863} | train loss {'Reaction outcome loss': 0.13580966487466564, 'Total loss': 0.13580966487466564}
2022-12-05 22:25:42,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:42,705 INFO:     Epoch: 63
2022-12-05 22:25:43,510 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4240083782510324, 'Total loss': 0.4240083782510324} | train loss {'Reaction outcome loss': 0.137031757252042, 'Total loss': 0.137031757252042}
2022-12-05 22:25:43,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:43,511 INFO:     Epoch: 64
2022-12-05 22:25:44,316 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42262853986837645, 'Total loss': 0.42262853986837645} | train loss {'Reaction outcome loss': 0.13348211790906334, 'Total loss': 0.13348211790906334}
2022-12-05 22:25:44,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:44,316 INFO:     Epoch: 65
2022-12-05 22:25:45,116 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4329060532829978, 'Total loss': 0.4329060532829978} | train loss {'Reaction outcome loss': 0.134088464759984, 'Total loss': 0.134088464759984}
2022-12-05 22:25:45,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:45,116 INFO:     Epoch: 66
2022-12-05 22:25:45,917 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4437025724486871, 'Total loss': 0.4437025724486871} | train loss {'Reaction outcome loss': 0.13307310164216077, 'Total loss': 0.13307310164216077}
2022-12-05 22:25:45,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:45,918 INFO:     Epoch: 67
2022-12-05 22:25:46,719 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.426245103166862, 'Total loss': 0.426245103166862} | train loss {'Reaction outcome loss': 0.1327574085444212, 'Total loss': 0.1327574085444212}
2022-12-05 22:25:46,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:46,719 INFO:     Epoch: 68
2022-12-05 22:25:47,525 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43237689255990763, 'Total loss': 0.43237689255990763} | train loss {'Reaction outcome loss': 0.13434936032302466, 'Total loss': 0.13434936032302466}
2022-12-05 22:25:47,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:47,525 INFO:     Epoch: 69
2022-12-05 22:25:48,324 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42612372067841614, 'Total loss': 0.42612372067841614} | train loss {'Reaction outcome loss': 0.13141203943172447, 'Total loss': 0.13141203943172447}
2022-12-05 22:25:48,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:48,324 INFO:     Epoch: 70
2022-12-05 22:25:49,123 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42252969843420113, 'Total loss': 0.42252969843420113} | train loss {'Reaction outcome loss': 0.13134808220753544, 'Total loss': 0.13134808220753544}
2022-12-05 22:25:49,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:49,124 INFO:     Epoch: 71
2022-12-05 22:25:49,922 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4262473860924894, 'Total loss': 0.4262473860924894} | train loss {'Reaction outcome loss': 0.12919455192802165, 'Total loss': 0.12919455192802165}
2022-12-05 22:25:49,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:49,923 INFO:     Epoch: 72
2022-12-05 22:25:50,726 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.437615633349527, 'Total loss': 0.437615633349527} | train loss {'Reaction outcome loss': 0.1305470520758677, 'Total loss': 0.1305470520758677}
2022-12-05 22:25:50,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:50,727 INFO:     Epoch: 73
2022-12-05 22:25:51,526 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43639862774447963, 'Total loss': 0.43639862774447963} | train loss {'Reaction outcome loss': 0.13064948629648218, 'Total loss': 0.13064948629648218}
2022-12-05 22:25:51,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:51,526 INFO:     Epoch: 74
2022-12-05 22:25:52,331 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42048640193587, 'Total loss': 0.42048640193587} | train loss {'Reaction outcome loss': 0.1317537074309099, 'Total loss': 0.1317537074309099}
2022-12-05 22:25:52,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:52,332 INFO:     Epoch: 75
2022-12-05 22:25:53,134 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4310129608281634, 'Total loss': 0.4310129608281634} | train loss {'Reaction outcome loss': 0.1257447055182778, 'Total loss': 0.1257447055182778}
2022-12-05 22:25:53,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:53,135 INFO:     Epoch: 76
2022-12-05 22:25:53,935 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.429890249940482, 'Total loss': 0.429890249940482} | train loss {'Reaction outcome loss': 0.1259529034801295, 'Total loss': 0.1259529034801295}
2022-12-05 22:25:53,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:53,935 INFO:     Epoch: 77
2022-12-05 22:25:54,734 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42927423695271666, 'Total loss': 0.42927423695271666} | train loss {'Reaction outcome loss': 0.12485493881899395, 'Total loss': 0.12485493881899395}
2022-12-05 22:25:54,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:54,735 INFO:     Epoch: 78
2022-12-05 22:25:55,532 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43886647068641405, 'Total loss': 0.43886647068641405} | train loss {'Reaction outcome loss': 0.12633047062481342, 'Total loss': 0.12633047062481342}
2022-12-05 22:25:55,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:55,532 INFO:     Epoch: 79
2022-12-05 22:25:56,328 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4280908826992593, 'Total loss': 0.4280908826992593} | train loss {'Reaction outcome loss': 0.1301329296255703, 'Total loss': 0.1301329296255703}
2022-12-05 22:25:56,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:56,328 INFO:     Epoch: 80
2022-12-05 22:25:57,125 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4314741177315062, 'Total loss': 0.4314741177315062} | train loss {'Reaction outcome loss': 0.12243196138214728, 'Total loss': 0.12243196138214728}
2022-12-05 22:25:57,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:57,125 INFO:     Epoch: 81
2022-12-05 22:25:57,926 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42047014934095467, 'Total loss': 0.42047014934095467} | train loss {'Reaction outcome loss': 0.12662146074946232, 'Total loss': 0.12662146074946232}
2022-12-05 22:25:57,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:57,926 INFO:     Epoch: 82
2022-12-05 22:25:58,723 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.432745272801681, 'Total loss': 0.432745272801681} | train loss {'Reaction outcome loss': 0.12356481471509947, 'Total loss': 0.12356481471509947}
2022-12-05 22:25:58,724 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:58,724 INFO:     Epoch: 83
2022-12-05 22:25:59,521 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43288792280310934, 'Total loss': 0.43288792280310934} | train loss {'Reaction outcome loss': 0.12338276417843003, 'Total loss': 0.12338276417843003}
2022-12-05 22:25:59,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:25:59,521 INFO:     Epoch: 84
2022-12-05 22:26:00,318 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43734723287211225, 'Total loss': 0.43734723287211225} | train loss {'Reaction outcome loss': 0.12338350052042273, 'Total loss': 0.12338350052042273}
2022-12-05 22:26:00,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:00,318 INFO:     Epoch: 85
2022-12-05 22:26:01,121 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42709014598618855, 'Total loss': 0.42709014598618855} | train loss {'Reaction outcome loss': 0.12066646782221341, 'Total loss': 0.12066646782221341}
2022-12-05 22:26:01,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:01,121 INFO:     Epoch: 86
2022-12-05 22:26:01,921 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42762222953818063, 'Total loss': 0.42762222953818063} | train loss {'Reaction outcome loss': 0.12079860492296486, 'Total loss': 0.12079860492296486}
2022-12-05 22:26:01,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:01,921 INFO:     Epoch: 87
2022-12-05 22:26:02,721 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4231363921002908, 'Total loss': 0.4231363921002908} | train loss {'Reaction outcome loss': 0.12061601111039459, 'Total loss': 0.12061601111039459}
2022-12-05 22:26:02,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:02,721 INFO:     Epoch: 88
2022-12-05 22:26:03,518 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43923282267695124, 'Total loss': 0.43923282267695124} | train loss {'Reaction outcome loss': 0.12029326842204188, 'Total loss': 0.12029326842204188}
2022-12-05 22:26:03,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:03,519 INFO:     Epoch: 89
2022-12-05 22:26:04,322 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42675636810335243, 'Total loss': 0.42675636810335243} | train loss {'Reaction outcome loss': 0.11852967244693595, 'Total loss': 0.11852967244693595}
2022-12-05 22:26:04,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:04,322 INFO:     Epoch: 90
2022-12-05 22:26:05,122 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44059552353891457, 'Total loss': 0.44059552353891457} | train loss {'Reaction outcome loss': 0.11987448979531101, 'Total loss': 0.11987448979531101}
2022-12-05 22:26:05,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:05,122 INFO:     Epoch: 91
2022-12-05 22:26:05,922 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43654944917017763, 'Total loss': 0.43654944917017763} | train loss {'Reaction outcome loss': 0.12178251790146717, 'Total loss': 0.12178251790146717}
2022-12-05 22:26:05,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:05,922 INFO:     Epoch: 92
2022-12-05 22:26:06,719 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4147532746534456, 'Total loss': 0.4147532746534456} | train loss {'Reaction outcome loss': 0.12110821761922376, 'Total loss': 0.12110821761922376}
2022-12-05 22:26:06,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:06,720 INFO:     Epoch: 93
2022-12-05 22:26:07,519 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4319093952124769, 'Total loss': 0.4319093952124769} | train loss {'Reaction outcome loss': 0.11808101386529382, 'Total loss': 0.11808101386529382}
2022-12-05 22:26:07,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:07,520 INFO:     Epoch: 94
2022-12-05 22:26:08,319 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43024099042469804, 'Total loss': 0.43024099042469804} | train loss {'Reaction outcome loss': 0.11892999378353478, 'Total loss': 0.11892999378353478}
2022-12-05 22:26:08,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:08,319 INFO:     Epoch: 95
2022-12-05 22:26:09,119 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4321047223427079, 'Total loss': 0.4321047223427079} | train loss {'Reaction outcome loss': 0.11808365496697455, 'Total loss': 0.11808365496697455}
2022-12-05 22:26:09,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:09,119 INFO:     Epoch: 96
2022-12-05 22:26:09,916 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4304773523048921, 'Total loss': 0.4304773523048921} | train loss {'Reaction outcome loss': 0.11717190832910147, 'Total loss': 0.11717190832910147}
2022-12-05 22:26:09,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:09,916 INFO:     Epoch: 97
2022-12-05 22:26:10,716 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4230856959792701, 'Total loss': 0.4230856959792701} | train loss {'Reaction outcome loss': 0.11790074400513278, 'Total loss': 0.11790074400513278}
2022-12-05 22:26:10,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:10,716 INFO:     Epoch: 98
2022-12-05 22:26:11,516 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.415772841904651, 'Total loss': 0.415772841904651} | train loss {'Reaction outcome loss': 0.12060952384631915, 'Total loss': 0.12060952384631915}
2022-12-05 22:26:11,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:11,517 INFO:     Epoch: 99
2022-12-05 22:26:12,315 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42287549071691255, 'Total loss': 0.42287549071691255} | train loss {'Reaction outcome loss': 0.1156852872446481, 'Total loss': 0.1156852872446481}
2022-12-05 22:26:12,315 INFO:     Best model found after epoch 17 of 100.
2022-12-05 22:26:12,315 INFO:   Done with stage: TRAINING
2022-12-05 22:26:12,316 INFO:   Starting stage: EVALUATION
2022-12-05 22:26:12,442 INFO:   Done with stage: EVALUATION
2022-12-05 22:26:12,442 INFO:   Leaving out SEQ value Fold_9
2022-12-05 22:26:12,455 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:26:12,455 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:26:13,098 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:26:13,098 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:26:13,168 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:26:13,168 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:26:13,168 INFO:     No hyperparam tuning for this model
2022-12-05 22:26:13,168 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:26:13,168 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:26:13,169 INFO:     None feature selector for col prot
2022-12-05 22:26:13,169 INFO:     None feature selector for col prot
2022-12-05 22:26:13,169 INFO:     None feature selector for col prot
2022-12-05 22:26:13,170 INFO:     None feature selector for col chem
2022-12-05 22:26:13,170 INFO:     None feature selector for col chem
2022-12-05 22:26:13,170 INFO:     None feature selector for col chem
2022-12-05 22:26:13,170 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:26:13,170 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:26:13,171 INFO:     Number of params in model 215821
2022-12-05 22:26:13,175 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:26:13,175 INFO:   Starting stage: TRAINING
2022-12-05 22:26:13,236 INFO:     Val loss before train {'Reaction outcome loss': 0.9876570931889794, 'Total loss': 0.9876570931889794}
2022-12-05 22:26:13,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:13,237 INFO:     Epoch: 0
2022-12-05 22:26:14,037 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6220835447311401, 'Total loss': 0.6220835447311401} | train loss {'Reaction outcome loss': 0.8036986643508557, 'Total loss': 0.8036986643508557}
2022-12-05 22:26:14,038 INFO:     Found new best model at epoch 0
2022-12-05 22:26:14,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:14,038 INFO:     Epoch: 1
2022-12-05 22:26:14,839 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5334992158142003, 'Total loss': 0.5334992158142003} | train loss {'Reaction outcome loss': 0.5499776171580437, 'Total loss': 0.5499776171580437}
2022-12-05 22:26:14,839 INFO:     Found new best model at epoch 1
2022-12-05 22:26:14,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:14,840 INFO:     Epoch: 2
2022-12-05 22:26:15,643 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4979254041205753, 'Total loss': 0.4979254041205753} | train loss {'Reaction outcome loss': 0.47494126724139335, 'Total loss': 0.47494126724139335}
2022-12-05 22:26:15,643 INFO:     Found new best model at epoch 2
2022-12-05 22:26:15,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:15,644 INFO:     Epoch: 3
2022-12-05 22:26:16,448 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.467685228721662, 'Total loss': 0.467685228721662} | train loss {'Reaction outcome loss': 0.4373726319040983, 'Total loss': 0.4373726319040983}
2022-12-05 22:26:16,448 INFO:     Found new best model at epoch 3
2022-12-05 22:26:16,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:16,449 INFO:     Epoch: 4
2022-12-05 22:26:17,250 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4840624515305866, 'Total loss': 0.4840624515305866} | train loss {'Reaction outcome loss': 0.4074328222402161, 'Total loss': 0.4074328222402161}
2022-12-05 22:26:17,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:17,250 INFO:     Epoch: 5
2022-12-05 22:26:18,053 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.454084885391322, 'Total loss': 0.454084885391322} | train loss {'Reaction outcome loss': 0.3856083428667438, 'Total loss': 0.3856083428667438}
2022-12-05 22:26:18,053 INFO:     Found new best model at epoch 5
2022-12-05 22:26:18,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:18,054 INFO:     Epoch: 6
2022-12-05 22:26:18,857 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4482166719707576, 'Total loss': 0.4482166719707576} | train loss {'Reaction outcome loss': 0.36434693442236993, 'Total loss': 0.36434693442236993}
2022-12-05 22:26:18,857 INFO:     Found new best model at epoch 6
2022-12-05 22:26:18,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:18,858 INFO:     Epoch: 7
2022-12-05 22:26:19,661 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43829597160220146, 'Total loss': 0.43829597160220146} | train loss {'Reaction outcome loss': 0.34528940035811356, 'Total loss': 0.34528940035811356}
2022-12-05 22:26:19,662 INFO:     Found new best model at epoch 7
2022-12-05 22:26:19,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:19,662 INFO:     Epoch: 8
2022-12-05 22:26:20,465 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43303723497824237, 'Total loss': 0.43303723497824237} | train loss {'Reaction outcome loss': 0.3330194764440098, 'Total loss': 0.3330194764440098}
2022-12-05 22:26:20,465 INFO:     Found new best model at epoch 8
2022-12-05 22:26:20,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:20,466 INFO:     Epoch: 9
2022-12-05 22:26:21,273 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4377311552790078, 'Total loss': 0.4377311552790078} | train loss {'Reaction outcome loss': 0.3186464386601602, 'Total loss': 0.3186464386601602}
2022-12-05 22:26:21,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:21,273 INFO:     Epoch: 10
2022-12-05 22:26:22,075 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4385893964631991, 'Total loss': 0.4385893964631991} | train loss {'Reaction outcome loss': 0.30384972331023985, 'Total loss': 0.30384972331023985}
2022-12-05 22:26:22,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:22,075 INFO:     Epoch: 11
2022-12-05 22:26:22,877 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4291850443590771, 'Total loss': 0.4291850443590771} | train loss {'Reaction outcome loss': 0.29772735678500706, 'Total loss': 0.29772735678500706}
2022-12-05 22:26:22,878 INFO:     Found new best model at epoch 11
2022-12-05 22:26:22,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:22,879 INFO:     Epoch: 12
2022-12-05 22:26:23,681 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4161089939827269, 'Total loss': 0.4161089939827269} | train loss {'Reaction outcome loss': 0.2848846357195608, 'Total loss': 0.2848846357195608}
2022-12-05 22:26:23,681 INFO:     Found new best model at epoch 12
2022-12-05 22:26:23,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:23,682 INFO:     Epoch: 13
2022-12-05 22:26:24,483 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42242599380287255, 'Total loss': 0.42242599380287255} | train loss {'Reaction outcome loss': 0.2774985576829603, 'Total loss': 0.2774985576829603}
2022-12-05 22:26:24,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:24,483 INFO:     Epoch: 14
2022-12-05 22:26:25,289 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4320697073232044, 'Total loss': 0.4320697073232044} | train loss {'Reaction outcome loss': 0.26553405415747433, 'Total loss': 0.26553405415747433}
2022-12-05 22:26:25,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:25,289 INFO:     Epoch: 15
2022-12-05 22:26:26,094 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41893040761351585, 'Total loss': 0.41893040761351585} | train loss {'Reaction outcome loss': 0.26037620593823735, 'Total loss': 0.26037620593823735}
2022-12-05 22:26:26,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:26,095 INFO:     Epoch: 16
2022-12-05 22:26:26,901 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4246244386515834, 'Total loss': 0.4246244386515834} | train loss {'Reaction outcome loss': 0.25134392163806385, 'Total loss': 0.25134392163806385}
2022-12-05 22:26:26,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:26,901 INFO:     Epoch: 17
2022-12-05 22:26:27,703 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43217534165490756, 'Total loss': 0.43217534165490756} | train loss {'Reaction outcome loss': 0.2471225982561948, 'Total loss': 0.2471225982561948}
2022-12-05 22:26:27,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:27,703 INFO:     Epoch: 18
2022-12-05 22:26:28,498 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43029633062807, 'Total loss': 0.43029633062807} | train loss {'Reaction outcome loss': 0.2411769796763697, 'Total loss': 0.2411769796763697}
2022-12-05 22:26:28,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:28,499 INFO:     Epoch: 19
2022-12-05 22:26:29,297 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41662435877052223, 'Total loss': 0.41662435877052223} | train loss {'Reaction outcome loss': 0.23305094485441524, 'Total loss': 0.23305094485441524}
2022-12-05 22:26:29,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:29,298 INFO:     Epoch: 20
2022-12-05 22:26:30,100 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42057602954181755, 'Total loss': 0.42057602954181755} | train loss {'Reaction outcome loss': 0.22693952617626037, 'Total loss': 0.22693952617626037}
2022-12-05 22:26:30,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:30,100 INFO:     Epoch: 21
2022-12-05 22:26:30,895 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4171968932178887, 'Total loss': 0.4171968932178887} | train loss {'Reaction outcome loss': 0.2251929381051131, 'Total loss': 0.2251929381051131}
2022-12-05 22:26:30,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:30,895 INFO:     Epoch: 22
2022-12-05 22:26:31,696 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4156957214528864, 'Total loss': 0.4156957214528864} | train loss {'Reaction outcome loss': 0.2208669565152377, 'Total loss': 0.2208669565152377}
2022-12-05 22:26:31,696 INFO:     Found new best model at epoch 22
2022-12-05 22:26:31,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:31,697 INFO:     Epoch: 23
2022-12-05 22:26:32,491 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.431754345074296, 'Total loss': 0.431754345074296} | train loss {'Reaction outcome loss': 0.2161168791053276, 'Total loss': 0.2161168791053276}
2022-12-05 22:26:32,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:32,491 INFO:     Epoch: 24
2022-12-05 22:26:33,294 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4346296724609353, 'Total loss': 0.4346296724609353} | train loss {'Reaction outcome loss': 0.20841065598952194, 'Total loss': 0.20841065598952194}
2022-12-05 22:26:33,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:33,294 INFO:     Epoch: 25
2022-12-05 22:26:34,096 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4330888603898612, 'Total loss': 0.4330888603898612} | train loss {'Reaction outcome loss': 0.20294424992114787, 'Total loss': 0.20294424992114787}
2022-12-05 22:26:34,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:34,096 INFO:     Epoch: 26
2022-12-05 22:26:34,892 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43460149385712366, 'Total loss': 0.43460149385712366} | train loss {'Reaction outcome loss': 0.2012529079201481, 'Total loss': 0.2012529079201481}
2022-12-05 22:26:34,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:34,892 INFO:     Epoch: 27
2022-12-05 22:26:35,693 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4272289921275594, 'Total loss': 0.4272289921275594} | train loss {'Reaction outcome loss': 0.20022835567473404, 'Total loss': 0.20022835567473404}
2022-12-05 22:26:35,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:35,693 INFO:     Epoch: 28
2022-12-05 22:26:36,489 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44051744924350217, 'Total loss': 0.44051744924350217} | train loss {'Reaction outcome loss': 0.1952709014857969, 'Total loss': 0.1952709014857969}
2022-12-05 22:26:36,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:36,489 INFO:     Epoch: 29
2022-12-05 22:26:37,285 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4308060258626938, 'Total loss': 0.4308060258626938} | train loss {'Reaction outcome loss': 0.19093727736523555, 'Total loss': 0.19093727736523555}
2022-12-05 22:26:37,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:37,286 INFO:     Epoch: 30
2022-12-05 22:26:38,085 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4417637163265185, 'Total loss': 0.4417637163265185} | train loss {'Reaction outcome loss': 0.18900914409107739, 'Total loss': 0.18900914409107739}
2022-12-05 22:26:38,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:38,085 INFO:     Epoch: 31
2022-12-05 22:26:38,881 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43651427878913557, 'Total loss': 0.43651427878913557} | train loss {'Reaction outcome loss': 0.18192418487442116, 'Total loss': 0.18192418487442116}
2022-12-05 22:26:38,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:38,881 INFO:     Epoch: 32
2022-12-05 22:26:39,680 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4449219002642415, 'Total loss': 0.4449219002642415} | train loss {'Reaction outcome loss': 0.18378835165452573, 'Total loss': 0.18378835165452573}
2022-12-05 22:26:39,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:39,680 INFO:     Epoch: 33
2022-12-05 22:26:40,481 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4429526677863164, 'Total loss': 0.4429526677863164} | train loss {'Reaction outcome loss': 0.1803835206364672, 'Total loss': 0.1803835206364672}
2022-12-05 22:26:40,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:40,481 INFO:     Epoch: 34
2022-12-05 22:26:41,281 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4405018440024419, 'Total loss': 0.4405018440024419} | train loss {'Reaction outcome loss': 0.1783756916861861, 'Total loss': 0.1783756916861861}
2022-12-05 22:26:41,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:41,281 INFO:     Epoch: 35
2022-12-05 22:26:42,079 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4437821377068758, 'Total loss': 0.4437821377068758} | train loss {'Reaction outcome loss': 0.17546662649950914, 'Total loss': 0.17546662649950914}
2022-12-05 22:26:42,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:42,080 INFO:     Epoch: 36
2022-12-05 22:26:42,876 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45171354558657517, 'Total loss': 0.45171354558657517} | train loss {'Reaction outcome loss': 0.17437079373086173, 'Total loss': 0.17437079373086173}
2022-12-05 22:26:42,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:42,877 INFO:     Epoch: 37
2022-12-05 22:26:43,674 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45953884720802307, 'Total loss': 0.45953884720802307} | train loss {'Reaction outcome loss': 0.17014824629070296, 'Total loss': 0.17014824629070296}
2022-12-05 22:26:43,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:43,674 INFO:     Epoch: 38
2022-12-05 22:26:44,470 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.445849721997299, 'Total loss': 0.445849721997299} | train loss {'Reaction outcome loss': 0.16856685633050097, 'Total loss': 0.16856685633050097}
2022-12-05 22:26:44,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:44,470 INFO:     Epoch: 39
2022-12-05 22:26:45,265 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46242759038101544, 'Total loss': 0.46242759038101544} | train loss {'Reaction outcome loss': 0.16403996583915526, 'Total loss': 0.16403996583915526}
2022-12-05 22:26:45,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:45,265 INFO:     Epoch: 40
2022-12-05 22:26:46,061 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44651592624458397, 'Total loss': 0.44651592624458397} | train loss {'Reaction outcome loss': 0.16608317138537043, 'Total loss': 0.16608317138537043}
2022-12-05 22:26:46,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:46,062 INFO:     Epoch: 41
2022-12-05 22:26:46,860 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4581710337237878, 'Total loss': 0.4581710337237878} | train loss {'Reaction outcome loss': 0.16179188073898154, 'Total loss': 0.16179188073898154}
2022-12-05 22:26:46,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:46,860 INFO:     Epoch: 42
2022-12-05 22:26:47,660 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47277140007777646, 'Total loss': 0.47277140007777646} | train loss {'Reaction outcome loss': 0.1597634291111101, 'Total loss': 0.1597634291111101}
2022-12-05 22:26:47,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:47,660 INFO:     Epoch: 43
2022-12-05 22:26:48,456 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4514718619598584, 'Total loss': 0.4514718619598584} | train loss {'Reaction outcome loss': 0.16029610498357685, 'Total loss': 0.16029610498357685}
2022-12-05 22:26:48,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:48,457 INFO:     Epoch: 44
2022-12-05 22:26:49,255 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45521745627576654, 'Total loss': 0.45521745627576654} | train loss {'Reaction outcome loss': 0.15757326203428448, 'Total loss': 0.15757326203428448}
2022-12-05 22:26:49,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:49,255 INFO:     Epoch: 45
2022-12-05 22:26:50,058 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46139173446731135, 'Total loss': 0.46139173446731135} | train loss {'Reaction outcome loss': 0.1562824883017569, 'Total loss': 0.1562824883017569}
2022-12-05 22:26:50,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:50,059 INFO:     Epoch: 46
2022-12-05 22:26:50,855 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4695837470618161, 'Total loss': 0.4695837470618161} | train loss {'Reaction outcome loss': 0.15516777980261512, 'Total loss': 0.15516777980261512}
2022-12-05 22:26:50,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:50,855 INFO:     Epoch: 47
2022-12-05 22:26:51,651 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45713732865723694, 'Total loss': 0.45713732865723694} | train loss {'Reaction outcome loss': 0.15739267490684025, 'Total loss': 0.15739267490684025}
2022-12-05 22:26:51,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:51,651 INFO:     Epoch: 48
2022-12-05 22:26:52,449 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.46365517597984185, 'Total loss': 0.46365517597984185} | train loss {'Reaction outcome loss': 0.15522024892420777, 'Total loss': 0.15522024892420777}
2022-12-05 22:26:52,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:52,449 INFO:     Epoch: 49
2022-12-05 22:26:53,248 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4540290317752145, 'Total loss': 0.4540290317752145} | train loss {'Reaction outcome loss': 0.15305821102623257, 'Total loss': 0.15305821102623257}
2022-12-05 22:26:53,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:53,249 INFO:     Epoch: 50
2022-12-05 22:26:54,049 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4752358675680377, 'Total loss': 0.4752358675680377} | train loss {'Reaction outcome loss': 0.15314861037768424, 'Total loss': 0.15314861037768424}
2022-12-05 22:26:54,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:54,050 INFO:     Epoch: 51
2022-12-05 22:26:54,847 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.466846395961263, 'Total loss': 0.466846395961263} | train loss {'Reaction outcome loss': 0.15569255572007668, 'Total loss': 0.15569255572007668}
2022-12-05 22:26:54,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:54,848 INFO:     Epoch: 52
2022-12-05 22:26:55,648 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47378364544023166, 'Total loss': 0.47378364544023166} | train loss {'Reaction outcome loss': 0.1509108937255317, 'Total loss': 0.1509108937255317}
2022-12-05 22:26:55,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:55,648 INFO:     Epoch: 53
2022-12-05 22:26:56,444 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4527841904623942, 'Total loss': 0.4527841904623942} | train loss {'Reaction outcome loss': 0.14866445175251894, 'Total loss': 0.14866445175251894}
2022-12-05 22:26:56,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:56,444 INFO:     Epoch: 54
2022-12-05 22:26:57,239 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4560783596878702, 'Total loss': 0.4560783596878702} | train loss {'Reaction outcome loss': 0.146371457778338, 'Total loss': 0.146371457778338}
2022-12-05 22:26:57,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:57,239 INFO:     Epoch: 55
2022-12-05 22:26:58,040 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.46464821289886127, 'Total loss': 0.46464821289886127} | train loss {'Reaction outcome loss': 0.1473304372461092, 'Total loss': 0.1473304372461092}
2022-12-05 22:26:58,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:58,040 INFO:     Epoch: 56
2022-12-05 22:26:58,837 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4635798777030273, 'Total loss': 0.4635798777030273} | train loss {'Reaction outcome loss': 0.14590136390630035, 'Total loss': 0.14590136390630035}
2022-12-05 22:26:58,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:58,837 INFO:     Epoch: 57
2022-12-05 22:26:59,633 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4684947593645616, 'Total loss': 0.4684947593645616} | train loss {'Reaction outcome loss': 0.14709363296447742, 'Total loss': 0.14709363296447742}
2022-12-05 22:26:59,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:26:59,633 INFO:     Epoch: 58
2022-12-05 22:27:00,437 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45906139232895593, 'Total loss': 0.45906139232895593} | train loss {'Reaction outcome loss': 0.1470030859308017, 'Total loss': 0.1470030859308017}
2022-12-05 22:27:00,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:00,437 INFO:     Epoch: 59
2022-12-05 22:27:01,235 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4621336490593173, 'Total loss': 0.4621336490593173} | train loss {'Reaction outcome loss': 0.14525068980630398, 'Total loss': 0.14525068980630398}
2022-12-05 22:27:01,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:01,236 INFO:     Epoch: 60
2022-12-05 22:27:02,040 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4690177345817739, 'Total loss': 0.4690177345817739} | train loss {'Reaction outcome loss': 0.1419213325265915, 'Total loss': 0.1419213325265915}
2022-12-05 22:27:02,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:02,040 INFO:     Epoch: 61
2022-12-05 22:27:02,842 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4734971660443328, 'Total loss': 0.4734971660443328} | train loss {'Reaction outcome loss': 0.1394007719692684, 'Total loss': 0.1394007719692684}
2022-12-05 22:27:02,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:02,842 INFO:     Epoch: 62
2022-12-05 22:27:03,640 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47841760143637657, 'Total loss': 0.47841760143637657} | train loss {'Reaction outcome loss': 0.140040097341332, 'Total loss': 0.140040097341332}
2022-12-05 22:27:03,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:03,640 INFO:     Epoch: 63
2022-12-05 22:27:04,436 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46856964921409433, 'Total loss': 0.46856964921409433} | train loss {'Reaction outcome loss': 0.141536109487436, 'Total loss': 0.141536109487436}
2022-12-05 22:27:04,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:04,436 INFO:     Epoch: 64
2022-12-05 22:27:05,232 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4761755435981534, 'Total loss': 0.4761755435981534} | train loss {'Reaction outcome loss': 0.1411340351802327, 'Total loss': 0.1411340351802327}
2022-12-05 22:27:05,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:05,232 INFO:     Epoch: 65
2022-12-05 22:27:06,028 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4657633040438999, 'Total loss': 0.4657633040438999} | train loss {'Reaction outcome loss': 0.13836352770487148, 'Total loss': 0.13836352770487148}
2022-12-05 22:27:06,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:06,028 INFO:     Epoch: 66
2022-12-05 22:27:06,824 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46759517321532423, 'Total loss': 0.46759517321532423} | train loss {'Reaction outcome loss': 0.13758140897393348, 'Total loss': 0.13758140897393348}
2022-12-05 22:27:06,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:06,824 INFO:     Epoch: 67
2022-12-05 22:27:07,620 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4722256057641723, 'Total loss': 0.4722256057641723} | train loss {'Reaction outcome loss': 0.13947945840716844, 'Total loss': 0.13947945840716844}
2022-12-05 22:27:07,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:07,620 INFO:     Epoch: 68
2022-12-05 22:27:08,413 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4826294925402511, 'Total loss': 0.4826294925402511} | train loss {'Reaction outcome loss': 0.1354539244653537, 'Total loss': 0.1354539244653537}
2022-12-05 22:27:08,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:08,414 INFO:     Epoch: 69
2022-12-05 22:27:09,206 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47525180054997856, 'Total loss': 0.47525180054997856} | train loss {'Reaction outcome loss': 0.13574450242242986, 'Total loss': 0.13574450242242986}
2022-12-05 22:27:09,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:09,206 INFO:     Epoch: 70
2022-12-05 22:27:10,004 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46980541944503784, 'Total loss': 0.46980541944503784} | train loss {'Reaction outcome loss': 0.13976713471234806, 'Total loss': 0.13976713471234806}
2022-12-05 22:27:10,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:10,004 INFO:     Epoch: 71
2022-12-05 22:27:10,800 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4901769337328998, 'Total loss': 0.4901769337328998} | train loss {'Reaction outcome loss': 0.136078633015014, 'Total loss': 0.136078633015014}
2022-12-05 22:27:10,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:10,800 INFO:     Epoch: 72
2022-12-05 22:27:11,592 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46548412029038777, 'Total loss': 0.46548412029038777} | train loss {'Reaction outcome loss': 0.13581670098938048, 'Total loss': 0.13581670098938048}
2022-12-05 22:27:11,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:11,592 INFO:     Epoch: 73
2022-12-05 22:27:12,386 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4822327443821864, 'Total loss': 0.4822327443821864} | train loss {'Reaction outcome loss': 0.1359087859220322, 'Total loss': 0.1359087859220322}
2022-12-05 22:27:12,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:12,386 INFO:     Epoch: 74
2022-12-05 22:27:13,179 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4647045419974761, 'Total loss': 0.4647045419974761} | train loss {'Reaction outcome loss': 0.13164364035812118, 'Total loss': 0.13164364035812118}
2022-12-05 22:27:13,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:13,179 INFO:     Epoch: 75
2022-12-05 22:27:13,971 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4803044284609231, 'Total loss': 0.4803044284609231} | train loss {'Reaction outcome loss': 0.1351986745702884, 'Total loss': 0.1351986745702884}
2022-12-05 22:27:13,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:13,971 INFO:     Epoch: 76
2022-12-05 22:27:14,772 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47679912265051494, 'Total loss': 0.47679912265051494} | train loss {'Reaction outcome loss': 0.13370696824765013, 'Total loss': 0.13370696824765013}
2022-12-05 22:27:14,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:14,772 INFO:     Epoch: 77
2022-12-05 22:27:15,566 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46620474535633216, 'Total loss': 0.46620474535633216} | train loss {'Reaction outcome loss': 0.13401270801982573, 'Total loss': 0.13401270801982573}
2022-12-05 22:27:15,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:15,566 INFO:     Epoch: 78
2022-12-05 22:27:16,360 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4545580040324818, 'Total loss': 0.4545580040324818} | train loss {'Reaction outcome loss': 0.1328258929105716, 'Total loss': 0.1328258929105716}
2022-12-05 22:27:16,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:16,360 INFO:     Epoch: 79
2022-12-05 22:27:17,160 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4747330769896507, 'Total loss': 0.4747330769896507} | train loss {'Reaction outcome loss': 0.13017359522787192, 'Total loss': 0.13017359522787192}
2022-12-05 22:27:17,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:17,160 INFO:     Epoch: 80
2022-12-05 22:27:17,952 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46668652682141826, 'Total loss': 0.46668652682141826} | train loss {'Reaction outcome loss': 0.1307276267588379, 'Total loss': 0.1307276267588379}
2022-12-05 22:27:17,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:17,952 INFO:     Epoch: 81
2022-12-05 22:27:18,747 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4613724388182163, 'Total loss': 0.4613724388182163} | train loss {'Reaction outcome loss': 0.13125714438126213, 'Total loss': 0.13125714438126213}
2022-12-05 22:27:18,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:18,748 INFO:     Epoch: 82
2022-12-05 22:27:19,539 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4650635233318264, 'Total loss': 0.4650635233318264} | train loss {'Reaction outcome loss': 0.12963085550995124, 'Total loss': 0.12963085550995124}
2022-12-05 22:27:19,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:19,539 INFO:     Epoch: 83
2022-12-05 22:27:20,334 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4638993530110879, 'Total loss': 0.4638993530110879} | train loss {'Reaction outcome loss': 0.13102318171877414, 'Total loss': 0.13102318171877414}
2022-12-05 22:27:20,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:20,335 INFO:     Epoch: 84
2022-12-05 22:27:21,126 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4721603329208764, 'Total loss': 0.4721603329208764} | train loss {'Reaction outcome loss': 0.13001543063400012, 'Total loss': 0.13001543063400012}
2022-12-05 22:27:21,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:21,126 INFO:     Epoch: 85
2022-12-05 22:27:21,920 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46571734987876634, 'Total loss': 0.46571734987876634} | train loss {'Reaction outcome loss': 0.12814595058350073, 'Total loss': 0.12814595058350073}
2022-12-05 22:27:21,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:21,921 INFO:     Epoch: 86
2022-12-05 22:27:22,716 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46729519844732503, 'Total loss': 0.46729519844732503} | train loss {'Reaction outcome loss': 0.1283262923112019, 'Total loss': 0.1283262923112019}
2022-12-05 22:27:22,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:22,716 INFO:     Epoch: 87
2022-12-05 22:27:23,508 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4557205770503391, 'Total loss': 0.4557205770503391} | train loss {'Reaction outcome loss': 0.12897275298488356, 'Total loss': 0.12897275298488356}
2022-12-05 22:27:23,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:23,509 INFO:     Epoch: 88
2022-12-05 22:27:24,307 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4794870482927019, 'Total loss': 0.4794870482927019} | train loss {'Reaction outcome loss': 0.12479491840537277, 'Total loss': 0.12479491840537277}
2022-12-05 22:27:24,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:24,308 INFO:     Epoch: 89
2022-12-05 22:27:25,102 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4656094034964388, 'Total loss': 0.4656094034964388} | train loss {'Reaction outcome loss': 0.12766317735546298, 'Total loss': 0.12766317735546298}
2022-12-05 22:27:25,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:25,103 INFO:     Epoch: 90
2022-12-05 22:27:25,894 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4713290865448388, 'Total loss': 0.4713290865448388} | train loss {'Reaction outcome loss': 0.12725419071202557, 'Total loss': 0.12725419071202557}
2022-12-05 22:27:25,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:25,895 INFO:     Epoch: 91
2022-12-05 22:27:26,689 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4779317274012349, 'Total loss': 0.4779317274012349} | train loss {'Reaction outcome loss': 0.12365936952447819, 'Total loss': 0.12365936952447819}
2022-12-05 22:27:26,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:26,689 INFO:     Epoch: 92
2022-12-05 22:27:27,491 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47100021893327887, 'Total loss': 0.47100021893327887} | train loss {'Reaction outcome loss': 0.12732259292792034, 'Total loss': 0.12732259292792034}
2022-12-05 22:27:27,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:27,492 INFO:     Epoch: 93
2022-12-05 22:27:28,293 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46214181455698883, 'Total loss': 0.46214181455698883} | train loss {'Reaction outcome loss': 0.12576361735832067, 'Total loss': 0.12576361735832067}
2022-12-05 22:27:28,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:28,294 INFO:     Epoch: 94
2022-12-05 22:27:29,088 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45951685173944995, 'Total loss': 0.45951685173944995} | train loss {'Reaction outcome loss': 0.12328191371183962, 'Total loss': 0.12328191371183962}
2022-12-05 22:27:29,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:29,088 INFO:     Epoch: 95
2022-12-05 22:27:29,881 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46078294329345226, 'Total loss': 0.46078294329345226} | train loss {'Reaction outcome loss': 0.12639916100494203, 'Total loss': 0.12639916100494203}
2022-12-05 22:27:29,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:29,881 INFO:     Epoch: 96
2022-12-05 22:27:30,676 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46490866521542723, 'Total loss': 0.46490866521542723} | train loss {'Reaction outcome loss': 0.12490167008757952, 'Total loss': 0.12490167008757952}
2022-12-05 22:27:30,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:30,677 INFO:     Epoch: 97
2022-12-05 22:27:31,472 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46149606664072385, 'Total loss': 0.46149606664072385} | train loss {'Reaction outcome loss': 0.12590168142360786, 'Total loss': 0.12590168142360786}
2022-12-05 22:27:31,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:31,472 INFO:     Epoch: 98
2022-12-05 22:27:32,265 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4689475897360932, 'Total loss': 0.4689475897360932} | train loss {'Reaction outcome loss': 0.1225077718150832, 'Total loss': 0.1225077718150832}
2022-12-05 22:27:32,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:32,266 INFO:     Epoch: 99
2022-12-05 22:27:33,065 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4563362422314557, 'Total loss': 0.4563362422314557} | train loss {'Reaction outcome loss': 0.1258250718575812, 'Total loss': 0.1258250718575812}
2022-12-05 22:27:33,065 INFO:     Best model found after epoch 23 of 100.
2022-12-05 22:27:33,065 INFO:   Done with stage: TRAINING
2022-12-05 22:27:33,065 INFO:   Starting stage: EVALUATION
2022-12-05 22:27:33,185 INFO:   Done with stage: EVALUATION
2022-12-05 22:27:33,193 INFO:   Leaving out SEQ value Fold_0
2022-12-05 22:27:33,206 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:27:33,207 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:27:33,847 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:27:33,847 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:27:33,916 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:27:33,916 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:27:33,916 INFO:     No hyperparam tuning for this model
2022-12-05 22:27:33,916 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:27:33,916 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:27:33,917 INFO:     None feature selector for col prot
2022-12-05 22:27:33,917 INFO:     None feature selector for col prot
2022-12-05 22:27:33,917 INFO:     None feature selector for col prot
2022-12-05 22:27:33,917 INFO:     None feature selector for col chem
2022-12-05 22:27:33,918 INFO:     None feature selector for col chem
2022-12-05 22:27:33,918 INFO:     None feature selector for col chem
2022-12-05 22:27:33,918 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:27:33,918 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:27:33,919 INFO:     Number of params in model 215821
2022-12-05 22:27:33,923 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:27:33,923 INFO:   Starting stage: TRAINING
2022-12-05 22:27:33,983 INFO:     Val loss before train {'Reaction outcome loss': 1.0187596028501338, 'Total loss': 1.0187596028501338}
2022-12-05 22:27:33,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:33,984 INFO:     Epoch: 0
2022-12-05 22:27:34,779 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6311039599505338, 'Total loss': 0.6311039599505338} | train loss {'Reaction outcome loss': 0.8132788527470368, 'Total loss': 0.8132788527470368}
2022-12-05 22:27:34,779 INFO:     Found new best model at epoch 0
2022-12-05 22:27:34,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:34,780 INFO:     Epoch: 1
2022-12-05 22:27:35,578 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5417706421153112, 'Total loss': 0.5417706421153112} | train loss {'Reaction outcome loss': 0.5479865416220808, 'Total loss': 0.5479865416220808}
2022-12-05 22:27:35,578 INFO:     Found new best model at epoch 1
2022-12-05 22:27:35,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:35,579 INFO:     Epoch: 2
2022-12-05 22:27:36,370 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5047892098399726, 'Total loss': 0.5047892098399726} | train loss {'Reaction outcome loss': 0.4734301408111808, 'Total loss': 0.4734301408111808}
2022-12-05 22:27:36,370 INFO:     Found new best model at epoch 2
2022-12-05 22:27:36,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:36,371 INFO:     Epoch: 3
2022-12-05 22:27:37,168 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48706095530228183, 'Total loss': 0.48706095530228183} | train loss {'Reaction outcome loss': 0.4289401027596431, 'Total loss': 0.4289401027596431}
2022-12-05 22:27:37,169 INFO:     Found new best model at epoch 3
2022-12-05 22:27:37,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:37,169 INFO:     Epoch: 4
2022-12-05 22:27:37,961 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4706218445842916, 'Total loss': 0.4706218445842916} | train loss {'Reaction outcome loss': 0.4013411995129064, 'Total loss': 0.4013411995129064}
2022-12-05 22:27:37,962 INFO:     Found new best model at epoch 4
2022-12-05 22:27:37,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:37,963 INFO:     Epoch: 5
2022-12-05 22:27:38,753 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4568408741192384, 'Total loss': 0.4568408741192384} | train loss {'Reaction outcome loss': 0.3776284954567187, 'Total loss': 0.3776284954567187}
2022-12-05 22:27:38,753 INFO:     Found new best model at epoch 5
2022-12-05 22:27:38,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:38,754 INFO:     Epoch: 6
2022-12-05 22:27:39,543 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44602642547000537, 'Total loss': 0.44602642547000537} | train loss {'Reaction outcome loss': 0.35814958750100634, 'Total loss': 0.35814958750100634}
2022-12-05 22:27:39,543 INFO:     Found new best model at epoch 6
2022-12-05 22:27:39,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:39,544 INFO:     Epoch: 7
2022-12-05 22:27:40,332 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.44598834893920203, 'Total loss': 0.44598834893920203} | train loss {'Reaction outcome loss': 0.34655086370373545, 'Total loss': 0.34655086370373545}
2022-12-05 22:27:40,332 INFO:     Found new best model at epoch 7
2022-12-05 22:27:40,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:40,333 INFO:     Epoch: 8
2022-12-05 22:27:41,129 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4409003301777623, 'Total loss': 0.4409003301777623} | train loss {'Reaction outcome loss': 0.3296104257225025, 'Total loss': 0.3296104257225025}
2022-12-05 22:27:41,129 INFO:     Found new best model at epoch 8
2022-12-05 22:27:41,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:41,130 INFO:     Epoch: 9
2022-12-05 22:27:41,921 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4341643144461242, 'Total loss': 0.4341643144461242} | train loss {'Reaction outcome loss': 0.31519686174296174, 'Total loss': 0.31519686174296174}
2022-12-05 22:27:41,921 INFO:     Found new best model at epoch 9
2022-12-05 22:27:41,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:41,922 INFO:     Epoch: 10
2022-12-05 22:27:42,716 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42787814140319824, 'Total loss': 0.42787814140319824} | train loss {'Reaction outcome loss': 0.30192987785980047, 'Total loss': 0.30192987785980047}
2022-12-05 22:27:42,716 INFO:     Found new best model at epoch 10
2022-12-05 22:27:42,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:42,717 INFO:     Epoch: 11
2022-12-05 22:27:43,507 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42913825301961467, 'Total loss': 0.42913825301961467} | train loss {'Reaction outcome loss': 0.290380271264778, 'Total loss': 0.290380271264778}
2022-12-05 22:27:43,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:43,507 INFO:     Epoch: 12
2022-12-05 22:27:44,296 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4267699813300913, 'Total loss': 0.4267699813300913} | train loss {'Reaction outcome loss': 0.2779681457108573, 'Total loss': 0.2779681457108573}
2022-12-05 22:27:44,297 INFO:     Found new best model at epoch 12
2022-12-05 22:27:44,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:44,298 INFO:     Epoch: 13
2022-12-05 22:27:45,087 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42411327395926823, 'Total loss': 0.42411327395926823} | train loss {'Reaction outcome loss': 0.26765088939111725, 'Total loss': 0.26765088939111725}
2022-12-05 22:27:45,087 INFO:     Found new best model at epoch 13
2022-12-05 22:27:45,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:45,088 INFO:     Epoch: 14
2022-12-05 22:27:45,877 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4255027889528058, 'Total loss': 0.4255027889528058} | train loss {'Reaction outcome loss': 0.26254363127263936, 'Total loss': 0.26254363127263936}
2022-12-05 22:27:45,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:45,877 INFO:     Epoch: 15
2022-12-05 22:27:46,670 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.41177267276427965, 'Total loss': 0.41177267276427965} | train loss {'Reaction outcome loss': 0.2531861598916382, 'Total loss': 0.2531861598916382}
2022-12-05 22:27:46,670 INFO:     Found new best model at epoch 15
2022-12-05 22:27:46,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:46,671 INFO:     Epoch: 16
2022-12-05 22:27:47,466 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44024042480371217, 'Total loss': 0.44024042480371217} | train loss {'Reaction outcome loss': 0.24855718460039572, 'Total loss': 0.24855718460039572}
2022-12-05 22:27:47,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:47,467 INFO:     Epoch: 17
2022-12-05 22:27:48,261 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42212045277384197, 'Total loss': 0.42212045277384197} | train loss {'Reaction outcome loss': 0.24186810501191297, 'Total loss': 0.24186810501191297}
2022-12-05 22:27:48,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:48,261 INFO:     Epoch: 18
2022-12-05 22:27:49,051 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4296170278367671, 'Total loss': 0.4296170278367671} | train loss {'Reaction outcome loss': 0.2352239629970147, 'Total loss': 0.2352239629970147}
2022-12-05 22:27:49,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:49,051 INFO:     Epoch: 19
2022-12-05 22:27:49,846 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4253440042111007, 'Total loss': 0.4253440042111007} | train loss {'Reaction outcome loss': 0.23086589113300146, 'Total loss': 0.23086589113300146}
2022-12-05 22:27:49,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:49,846 INFO:     Epoch: 20
2022-12-05 22:27:50,638 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4215824753046036, 'Total loss': 0.4215824753046036} | train loss {'Reaction outcome loss': 0.222941877644675, 'Total loss': 0.222941877644675}
2022-12-05 22:27:50,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:50,638 INFO:     Epoch: 21
2022-12-05 22:27:51,429 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40906842425465584, 'Total loss': 0.40906842425465584} | train loss {'Reaction outcome loss': 0.21577467045441331, 'Total loss': 0.21577467045441331}
2022-12-05 22:27:51,429 INFO:     Found new best model at epoch 21
2022-12-05 22:27:51,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:51,430 INFO:     Epoch: 22
2022-12-05 22:27:52,219 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4306726164438508, 'Total loss': 0.4306726164438508} | train loss {'Reaction outcome loss': 0.21274411465655937, 'Total loss': 0.21274411465655937}
2022-12-05 22:27:52,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:52,219 INFO:     Epoch: 23
2022-12-05 22:27:53,010 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.414627653631297, 'Total loss': 0.414627653631297} | train loss {'Reaction outcome loss': 0.20719529359567504, 'Total loss': 0.20719529359567504}
2022-12-05 22:27:53,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:53,010 INFO:     Epoch: 24
2022-12-05 22:27:53,804 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4181578809564764, 'Total loss': 0.4181578809564764} | train loss {'Reaction outcome loss': 0.20221870061130778, 'Total loss': 0.20221870061130778}
2022-12-05 22:27:53,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:53,804 INFO:     Epoch: 25
2022-12-05 22:27:54,602 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43707649663768033, 'Total loss': 0.43707649663768033} | train loss {'Reaction outcome loss': 0.19929160008787628, 'Total loss': 0.19929160008787628}
2022-12-05 22:27:54,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:54,602 INFO:     Epoch: 26
2022-12-05 22:27:55,395 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4154800119047815, 'Total loss': 0.4154800119047815} | train loss {'Reaction outcome loss': 0.1960149530457099, 'Total loss': 0.1960149530457099}
2022-12-05 22:27:55,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:55,395 INFO:     Epoch: 27
2022-12-05 22:27:56,189 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4284120730378411, 'Total loss': 0.4284120730378411} | train loss {'Reaction outcome loss': 0.19398833391999426, 'Total loss': 0.19398833391999426}
2022-12-05 22:27:56,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:56,189 INFO:     Epoch: 28
2022-12-05 22:27:56,982 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4217626875774427, 'Total loss': 0.4217626875774427} | train loss {'Reaction outcome loss': 0.19023755805845927, 'Total loss': 0.19023755805845927}
2022-12-05 22:27:56,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:56,983 INFO:     Epoch: 29
2022-12-05 22:27:57,779 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4212606004015966, 'Total loss': 0.4212606004015966} | train loss {'Reaction outcome loss': 0.1902530998413862, 'Total loss': 0.1902530998413862}
2022-12-05 22:27:57,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:57,779 INFO:     Epoch: 30
2022-12-05 22:27:58,571 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42528358000245964, 'Total loss': 0.42528358000245964} | train loss {'Reaction outcome loss': 0.18480764815455628, 'Total loss': 0.18480764815455628}
2022-12-05 22:27:58,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:58,572 INFO:     Epoch: 31
2022-12-05 22:27:59,365 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.432069330052896, 'Total loss': 0.432069330052896} | train loss {'Reaction outcome loss': 0.1772985072459588, 'Total loss': 0.1772985072459588}
2022-12-05 22:27:59,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:27:59,365 INFO:     Epoch: 32
2022-12-05 22:28:00,158 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43551529063419864, 'Total loss': 0.43551529063419864} | train loss {'Reaction outcome loss': 0.17572662480145332, 'Total loss': 0.17572662480145332}
2022-12-05 22:28:00,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:00,158 INFO:     Epoch: 33
2022-12-05 22:28:00,955 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4309858806769956, 'Total loss': 0.4309858806769956} | train loss {'Reaction outcome loss': 0.1745989264746909, 'Total loss': 0.1745989264746909}
2022-12-05 22:28:00,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:00,955 INFO:     Epoch: 34
2022-12-05 22:28:01,757 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4387582316994667, 'Total loss': 0.4387582316994667} | train loss {'Reaction outcome loss': 0.1709843010449337, 'Total loss': 0.1709843010449337}
2022-12-05 22:28:01,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:01,758 INFO:     Epoch: 35
2022-12-05 22:28:02,552 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43087715723297815, 'Total loss': 0.43087715723297815} | train loss {'Reaction outcome loss': 0.16975414090853955, 'Total loss': 0.16975414090853955}
2022-12-05 22:28:02,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:02,553 INFO:     Epoch: 36
2022-12-05 22:28:03,346 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.432916693050753, 'Total loss': 0.432916693050753} | train loss {'Reaction outcome loss': 0.17309103989106442, 'Total loss': 0.17309103989106442}
2022-12-05 22:28:03,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:03,347 INFO:     Epoch: 37
2022-12-05 22:28:04,141 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44417314349927683, 'Total loss': 0.44417314349927683} | train loss {'Reaction outcome loss': 0.1644900020113901, 'Total loss': 0.1644900020113901}
2022-12-05 22:28:04,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:04,141 INFO:     Epoch: 38
2022-12-05 22:28:04,935 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42678915641524573, 'Total loss': 0.42678915641524573} | train loss {'Reaction outcome loss': 0.16228429781464362, 'Total loss': 0.16228429781464362}
2022-12-05 22:28:04,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:04,935 INFO:     Epoch: 39
2022-12-05 22:28:05,728 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43365884402936156, 'Total loss': 0.43365884402936156} | train loss {'Reaction outcome loss': 0.15930188553189098, 'Total loss': 0.15930188553189098}
2022-12-05 22:28:05,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:05,728 INFO:     Epoch: 40
2022-12-05 22:28:06,526 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4283521886576306, 'Total loss': 0.4283521886576306} | train loss {'Reaction outcome loss': 0.16509019118933543, 'Total loss': 0.16509019118933543}
2022-12-05 22:28:06,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:06,526 INFO:     Epoch: 41
2022-12-05 22:28:07,321 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4299650117754936, 'Total loss': 0.4299650117754936} | train loss {'Reaction outcome loss': 0.16697643894837935, 'Total loss': 0.16697643894837935}
2022-12-05 22:28:07,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:07,321 INFO:     Epoch: 42
2022-12-05 22:28:08,116 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4252351707863537, 'Total loss': 0.4252351707863537} | train loss {'Reaction outcome loss': 0.1599139859862173, 'Total loss': 0.1599139859862173}
2022-12-05 22:28:08,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:08,116 INFO:     Epoch: 43
2022-12-05 22:28:08,912 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4358111271126704, 'Total loss': 0.4358111271126704} | train loss {'Reaction outcome loss': 0.15620515192010503, 'Total loss': 0.15620515192010503}
2022-12-05 22:28:08,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:08,912 INFO:     Epoch: 44
2022-12-05 22:28:09,708 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4276202344758944, 'Total loss': 0.4276202344758944} | train loss {'Reaction outcome loss': 0.15523897823104674, 'Total loss': 0.15523897823104674}
2022-12-05 22:28:09,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:09,708 INFO:     Epoch: 45
2022-12-05 22:28:10,500 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4368022514337843, 'Total loss': 0.4368022514337843} | train loss {'Reaction outcome loss': 0.1545731169605243, 'Total loss': 0.1545731169605243}
2022-12-05 22:28:10,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:10,500 INFO:     Epoch: 46
2022-12-05 22:28:11,292 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42837252908132295, 'Total loss': 0.42837252908132295} | train loss {'Reaction outcome loss': 0.14726135859205594, 'Total loss': 0.14726135859205594}
2022-12-05 22:28:11,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:11,292 INFO:     Epoch: 47
2022-12-05 22:28:12,086 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4409055550667373, 'Total loss': 0.4409055550667373} | train loss {'Reaction outcome loss': 0.1497451415373133, 'Total loss': 0.1497451415373133}
2022-12-05 22:28:12,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:12,086 INFO:     Epoch: 48
2022-12-05 22:28:12,881 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44963176819411194, 'Total loss': 0.44963176819411194} | train loss {'Reaction outcome loss': 0.14997094393771912, 'Total loss': 0.14997094393771912}
2022-12-05 22:28:12,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:12,881 INFO:     Epoch: 49
2022-12-05 22:28:13,674 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4366051561453126, 'Total loss': 0.4366051561453126} | train loss {'Reaction outcome loss': 0.1533238729608136, 'Total loss': 0.1533238729608136}
2022-12-05 22:28:13,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:13,674 INFO:     Epoch: 50
2022-12-05 22:28:14,465 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4319334119896997, 'Total loss': 0.4319334119896997} | train loss {'Reaction outcome loss': 0.14547945880463067, 'Total loss': 0.14547945880463067}
2022-12-05 22:28:14,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:14,465 INFO:     Epoch: 51
2022-12-05 22:28:15,257 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4408146869391203, 'Total loss': 0.4408146869391203} | train loss {'Reaction outcome loss': 0.14415594184514785, 'Total loss': 0.14415594184514785}
2022-12-05 22:28:15,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:15,258 INFO:     Epoch: 52
2022-12-05 22:28:16,049 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44645371101796627, 'Total loss': 0.44645371101796627} | train loss {'Reaction outcome loss': 0.14394976203197893, 'Total loss': 0.14394976203197893}
2022-12-05 22:28:16,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:16,050 INFO:     Epoch: 53
2022-12-05 22:28:16,843 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43988740748979827, 'Total loss': 0.43988740748979827} | train loss {'Reaction outcome loss': 0.14904952645000175, 'Total loss': 0.14904952645000175}
2022-12-05 22:28:16,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:16,843 INFO:     Epoch: 54
2022-12-05 22:28:17,634 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4409054812382568, 'Total loss': 0.4409054812382568} | train loss {'Reaction outcome loss': 0.14459225779181528, 'Total loss': 0.14459225779181528}
2022-12-05 22:28:17,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:17,634 INFO:     Epoch: 55
2022-12-05 22:28:18,426 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4472049410370263, 'Total loss': 0.4472049410370263} | train loss {'Reaction outcome loss': 0.1407531053958996, 'Total loss': 0.1407531053958996}
2022-12-05 22:28:18,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:18,426 INFO:     Epoch: 56
2022-12-05 22:28:19,217 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41862727600065147, 'Total loss': 0.41862727600065147} | train loss {'Reaction outcome loss': 0.13867544641469412, 'Total loss': 0.13867544641469412}
2022-12-05 22:28:19,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:19,217 INFO:     Epoch: 57
2022-12-05 22:28:20,013 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44541500542651524, 'Total loss': 0.44541500542651524} | train loss {'Reaction outcome loss': 0.1356954177754822, 'Total loss': 0.1356954177754822}
2022-12-05 22:28:20,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:20,013 INFO:     Epoch: 58
2022-12-05 22:28:20,806 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4665404231372205, 'Total loss': 0.4665404231372205} | train loss {'Reaction outcome loss': 0.13652641125973541, 'Total loss': 0.13652641125973541}
2022-12-05 22:28:20,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:20,806 INFO:     Epoch: 59
2022-12-05 22:28:21,601 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4380821639841253, 'Total loss': 0.4380821639841253} | train loss {'Reaction outcome loss': 0.13889658538556773, 'Total loss': 0.13889658538556773}
2022-12-05 22:28:21,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:21,602 INFO:     Epoch: 60
2022-12-05 22:28:22,393 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42832350730895996, 'Total loss': 0.42832350730895996} | train loss {'Reaction outcome loss': 0.1357853135701103, 'Total loss': 0.1357853135701103}
2022-12-05 22:28:22,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:22,394 INFO:     Epoch: 61
2022-12-05 22:28:23,189 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44088850339705293, 'Total loss': 0.44088850339705293} | train loss {'Reaction outcome loss': 0.13504618553535236, 'Total loss': 0.13504618553535236}
2022-12-05 22:28:23,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:23,189 INFO:     Epoch: 62
2022-12-05 22:28:23,983 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4478530494326895, 'Total loss': 0.4478530494326895} | train loss {'Reaction outcome loss': 0.13594225252627845, 'Total loss': 0.13594225252627845}
2022-12-05 22:28:23,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:23,983 INFO:     Epoch: 63
2022-12-05 22:28:24,776 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4594893811101263, 'Total loss': 0.4594893811101263} | train loss {'Reaction outcome loss': 0.13580710320216924, 'Total loss': 0.13580710320216924}
2022-12-05 22:28:24,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:24,777 INFO:     Epoch: 64
2022-12-05 22:28:25,570 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.446564343334599, 'Total loss': 0.446564343334599} | train loss {'Reaction outcome loss': 0.13495170495469078, 'Total loss': 0.13495170495469078}
2022-12-05 22:28:25,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:25,570 INFO:     Epoch: 65
2022-12-05 22:28:26,362 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44218413633379067, 'Total loss': 0.44218413633379067} | train loss {'Reaction outcome loss': 0.13331359029023604, 'Total loss': 0.13331359029023604}
2022-12-05 22:28:26,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:26,362 INFO:     Epoch: 66
2022-12-05 22:28:27,155 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42473016205159103, 'Total loss': 0.42473016205159103} | train loss {'Reaction outcome loss': 0.13181093997634977, 'Total loss': 0.13181093997634977}
2022-12-05 22:28:27,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:27,155 INFO:     Epoch: 67
2022-12-05 22:28:27,948 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45398886129260063, 'Total loss': 0.45398886129260063} | train loss {'Reaction outcome loss': 0.12987403152321997, 'Total loss': 0.12987403152321997}
2022-12-05 22:28:27,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:27,950 INFO:     Epoch: 68
2022-12-05 22:28:28,742 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4373366730287671, 'Total loss': 0.4373366730287671} | train loss {'Reaction outcome loss': 0.13164407822495772, 'Total loss': 0.13164407822495772}
2022-12-05 22:28:28,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:28,742 INFO:     Epoch: 69
2022-12-05 22:28:29,537 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4536900141022422, 'Total loss': 0.4536900141022422} | train loss {'Reaction outcome loss': 0.13071714756399513, 'Total loss': 0.13071714756399513}
2022-12-05 22:28:29,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:29,538 INFO:     Epoch: 70
2022-12-05 22:28:30,334 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43915047124028206, 'Total loss': 0.43915047124028206} | train loss {'Reaction outcome loss': 0.13241749456546342, 'Total loss': 0.13241749456546342}
2022-12-05 22:28:30,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:30,334 INFO:     Epoch: 71
2022-12-05 22:28:31,127 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4194512108171528, 'Total loss': 0.4194512108171528} | train loss {'Reaction outcome loss': 0.12993852422395458, 'Total loss': 0.12993852422395458}
2022-12-05 22:28:31,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:31,127 INFO:     Epoch: 72
2022-12-05 22:28:31,922 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43060218153352087, 'Total loss': 0.43060218153352087} | train loss {'Reaction outcome loss': 0.1292472881140557, 'Total loss': 0.1292472881140557}
2022-12-05 22:28:31,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:31,922 INFO:     Epoch: 73
2022-12-05 22:28:32,714 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45136595077135344, 'Total loss': 0.45136595077135344} | train loss {'Reaction outcome loss': 0.12976123099234183, 'Total loss': 0.12976123099234183}
2022-12-05 22:28:32,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:32,715 INFO:     Epoch: 74
2022-12-05 22:28:33,508 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44175015118989075, 'Total loss': 0.44175015118989075} | train loss {'Reaction outcome loss': 0.13153298151668025, 'Total loss': 0.13153298151668025}
2022-12-05 22:28:33,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:33,509 INFO:     Epoch: 75
2022-12-05 22:28:34,302 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44256497208367696, 'Total loss': 0.44256497208367696} | train loss {'Reaction outcome loss': 0.12941698292232598, 'Total loss': 0.12941698292232598}
2022-12-05 22:28:34,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:34,303 INFO:     Epoch: 76
2022-12-05 22:28:35,098 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45133156227794563, 'Total loss': 0.45133156227794563} | train loss {'Reaction outcome loss': 0.12660361839993764, 'Total loss': 0.12660361839993764}
2022-12-05 22:28:35,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:35,098 INFO:     Epoch: 77
2022-12-05 22:28:35,893 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4465708827430552, 'Total loss': 0.4465708827430552} | train loss {'Reaction outcome loss': 0.12511623880792003, 'Total loss': 0.12511623880792003}
2022-12-05 22:28:35,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:35,893 INFO:     Epoch: 78
2022-12-05 22:28:36,686 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43970735574310477, 'Total loss': 0.43970735574310477} | train loss {'Reaction outcome loss': 0.12581362610735633, 'Total loss': 0.12581362610735633}
2022-12-05 22:28:36,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:36,686 INFO:     Epoch: 79
2022-12-05 22:28:37,480 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4426878956569867, 'Total loss': 0.4426878956569867} | train loss {'Reaction outcome loss': 0.12623602805304746, 'Total loss': 0.12623602805304746}
2022-12-05 22:28:37,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:37,480 INFO:     Epoch: 80
2022-12-05 22:28:38,274 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4318548227575692, 'Total loss': 0.4318548227575692} | train loss {'Reaction outcome loss': 0.12373286614624354, 'Total loss': 0.12373286614624354}
2022-12-05 22:28:38,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:38,275 INFO:     Epoch: 81
2022-12-05 22:28:39,073 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4332335628569126, 'Total loss': 0.4332335628569126} | train loss {'Reaction outcome loss': 0.12262722825337398, 'Total loss': 0.12262722825337398}
2022-12-05 22:28:39,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:39,073 INFO:     Epoch: 82
2022-12-05 22:28:39,867 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4382836398753253, 'Total loss': 0.4382836398753253} | train loss {'Reaction outcome loss': 0.12530078413153467, 'Total loss': 0.12530078413153467}
2022-12-05 22:28:39,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:39,867 INFO:     Epoch: 83
2022-12-05 22:28:40,658 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4670946533707055, 'Total loss': 0.4670946533707055} | train loss {'Reaction outcome loss': 0.12724040045123924, 'Total loss': 0.12724040045123924}
2022-12-05 22:28:40,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:40,658 INFO:     Epoch: 84
2022-12-05 22:28:41,448 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4416241967542605, 'Total loss': 0.4416241967542605} | train loss {'Reaction outcome loss': 0.12436892398772573, 'Total loss': 0.12436892398772573}
2022-12-05 22:28:41,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:41,448 INFO:     Epoch: 85
2022-12-05 22:28:42,236 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4462995698506182, 'Total loss': 0.4462995698506182} | train loss {'Reaction outcome loss': 0.12555942727773176, 'Total loss': 0.12555942727773176}
2022-12-05 22:28:42,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:42,236 INFO:     Epoch: 86
2022-12-05 22:28:43,024 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44304732301018457, 'Total loss': 0.44304732301018457} | train loss {'Reaction outcome loss': 0.12470853327243751, 'Total loss': 0.12470853327243751}
2022-12-05 22:28:43,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:43,024 INFO:     Epoch: 87
2022-12-05 22:28:43,815 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4351133924316276, 'Total loss': 0.4351133924316276} | train loss {'Reaction outcome loss': 0.12186376001263557, 'Total loss': 0.12186376001263557}
2022-12-05 22:28:43,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:43,815 INFO:     Epoch: 88
2022-12-05 22:28:44,605 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4455390365116976, 'Total loss': 0.4455390365116976} | train loss {'Reaction outcome loss': 0.1258349469052213, 'Total loss': 0.1258349469052213}
2022-12-05 22:28:44,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:44,605 INFO:     Epoch: 89
2022-12-05 22:28:45,396 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.442810213023966, 'Total loss': 0.442810213023966} | train loss {'Reaction outcome loss': 0.1262644544745294, 'Total loss': 0.1262644544745294}
2022-12-05 22:28:45,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:45,396 INFO:     Epoch: 90
2022-12-05 22:28:46,183 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4576662409711968, 'Total loss': 0.4576662409711968} | train loss {'Reaction outcome loss': 0.12101772372509062, 'Total loss': 0.12101772372509062}
2022-12-05 22:28:46,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:46,183 INFO:     Epoch: 91
2022-12-05 22:28:46,970 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44931689548221504, 'Total loss': 0.44931689548221504} | train loss {'Reaction outcome loss': 0.1205000957428866, 'Total loss': 0.1205000957428866}
2022-12-05 22:28:46,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:46,971 INFO:     Epoch: 92
2022-12-05 22:28:47,759 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4436284154653549, 'Total loss': 0.4436284154653549} | train loss {'Reaction outcome loss': 0.11984360444657353, 'Total loss': 0.11984360444657353}
2022-12-05 22:28:47,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:47,759 INFO:     Epoch: 93
2022-12-05 22:28:48,546 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4454713779586283, 'Total loss': 0.4454713779586283} | train loss {'Reaction outcome loss': 0.12626944710066926, 'Total loss': 0.12626944710066926}
2022-12-05 22:28:48,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:48,547 INFO:     Epoch: 94
2022-12-05 22:28:49,334 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44426134499636566, 'Total loss': 0.44426134499636566} | train loss {'Reaction outcome loss': 0.12511716084743318, 'Total loss': 0.12511716084743318}
2022-12-05 22:28:49,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:49,334 INFO:     Epoch: 95
2022-12-05 22:28:50,126 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44149363007057796, 'Total loss': 0.44149363007057796} | train loss {'Reaction outcome loss': 0.12100992421148277, 'Total loss': 0.12100992421148277}
2022-12-05 22:28:50,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:50,126 INFO:     Epoch: 96
2022-12-05 22:28:50,917 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.426961771805178, 'Total loss': 0.426961771805178} | train loss {'Reaction outcome loss': 0.12521268625607948, 'Total loss': 0.12521268625607948}
2022-12-05 22:28:50,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:50,917 INFO:     Epoch: 97
2022-12-05 22:28:51,707 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44119238684123213, 'Total loss': 0.44119238684123213} | train loss {'Reaction outcome loss': 0.115711252132491, 'Total loss': 0.115711252132491}
2022-12-05 22:28:51,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:51,708 INFO:     Epoch: 98
2022-12-05 22:28:52,498 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4411286400123076, 'Total loss': 0.4411286400123076} | train loss {'Reaction outcome loss': 0.11749237149021577, 'Total loss': 0.11749237149021577}
2022-12-05 22:28:52,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:52,499 INFO:     Epoch: 99
2022-12-05 22:28:53,290 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43951657820831647, 'Total loss': 0.43951657820831647} | train loss {'Reaction outcome loss': 0.11796578549994872, 'Total loss': 0.11796578549994872}
2022-12-05 22:28:53,290 INFO:     Best model found after epoch 22 of 100.
2022-12-05 22:28:53,290 INFO:   Done with stage: TRAINING
2022-12-05 22:28:53,290 INFO:   Starting stage: EVALUATION
2022-12-05 22:28:53,416 INFO:   Done with stage: EVALUATION
2022-12-05 22:28:53,416 INFO:   Leaving out SEQ value Fold_1
2022-12-05 22:28:53,429 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:28:53,429 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:28:54,073 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:28:54,073 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:28:54,143 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:28:54,143 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:28:54,143 INFO:     No hyperparam tuning for this model
2022-12-05 22:28:54,143 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:28:54,143 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:28:54,144 INFO:     None feature selector for col prot
2022-12-05 22:28:54,144 INFO:     None feature selector for col prot
2022-12-05 22:28:54,144 INFO:     None feature selector for col prot
2022-12-05 22:28:54,144 INFO:     None feature selector for col chem
2022-12-05 22:28:54,144 INFO:     None feature selector for col chem
2022-12-05 22:28:54,145 INFO:     None feature selector for col chem
2022-12-05 22:28:54,145 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:28:54,145 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:28:54,146 INFO:     Number of params in model 215821
2022-12-05 22:28:54,149 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:28:54,150 INFO:   Starting stage: TRAINING
2022-12-05 22:28:54,210 INFO:     Val loss before train {'Reaction outcome loss': 1.0022981640967457, 'Total loss': 1.0022981640967457}
2022-12-05 22:28:54,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:54,211 INFO:     Epoch: 0
2022-12-05 22:28:55,002 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5868410962549123, 'Total loss': 0.5868410962549123} | train loss {'Reaction outcome loss': 0.7790754743915821, 'Total loss': 0.7790754743915821}
2022-12-05 22:28:55,002 INFO:     Found new best model at epoch 0
2022-12-05 22:28:55,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:55,003 INFO:     Epoch: 1
2022-12-05 22:28:55,793 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5051828385754065, 'Total loss': 0.5051828385754065} | train loss {'Reaction outcome loss': 0.5340936845130766, 'Total loss': 0.5340936845130766}
2022-12-05 22:28:55,793 INFO:     Found new best model at epoch 1
2022-12-05 22:28:55,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:55,794 INFO:     Epoch: 2
2022-12-05 22:28:56,587 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.47926725447177887, 'Total loss': 0.47926725447177887} | train loss {'Reaction outcome loss': 0.46773496543355136, 'Total loss': 0.46773496543355136}
2022-12-05 22:28:56,587 INFO:     Found new best model at epoch 2
2022-12-05 22:28:56,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:56,588 INFO:     Epoch: 3
2022-12-05 22:28:57,377 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43983822857791727, 'Total loss': 0.43983822857791727} | train loss {'Reaction outcome loss': 0.43021555953783547, 'Total loss': 0.43021555953783547}
2022-12-05 22:28:57,378 INFO:     Found new best model at epoch 3
2022-12-05 22:28:57,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:57,378 INFO:     Epoch: 4
2022-12-05 22:28:58,169 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43065477230332116, 'Total loss': 0.43065477230332116} | train loss {'Reaction outcome loss': 0.4044796229615385, 'Total loss': 0.4044796229615385}
2022-12-05 22:28:58,169 INFO:     Found new best model at epoch 4
2022-12-05 22:28:58,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:58,170 INFO:     Epoch: 5
2022-12-05 22:28:58,958 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4191457669843327, 'Total loss': 0.4191457669843327} | train loss {'Reaction outcome loss': 0.37992296020994304, 'Total loss': 0.37992296020994304}
2022-12-05 22:28:58,959 INFO:     Found new best model at epoch 5
2022-12-05 22:28:58,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:58,960 INFO:     Epoch: 6
2022-12-05 22:28:59,751 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4063376262784004, 'Total loss': 0.4063376262784004} | train loss {'Reaction outcome loss': 0.36156899359846406, 'Total loss': 0.36156899359846406}
2022-12-05 22:28:59,751 INFO:     Found new best model at epoch 6
2022-12-05 22:28:59,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:28:59,752 INFO:     Epoch: 7
2022-12-05 22:29:00,541 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3988683708012104, 'Total loss': 0.3988683708012104} | train loss {'Reaction outcome loss': 0.3430690098749964, 'Total loss': 0.3430690098749964}
2022-12-05 22:29:00,542 INFO:     Found new best model at epoch 7
2022-12-05 22:29:00,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:00,543 INFO:     Epoch: 8
2022-12-05 22:29:01,331 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40406997400251304, 'Total loss': 0.40406997400251304} | train loss {'Reaction outcome loss': 0.3312954924065574, 'Total loss': 0.3312954924065574}
2022-12-05 22:29:01,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:01,331 INFO:     Epoch: 9
2022-12-05 22:29:02,123 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3924528475512158, 'Total loss': 0.3924528475512158} | train loss {'Reaction outcome loss': 0.31758297602778024, 'Total loss': 0.31758297602778024}
2022-12-05 22:29:02,123 INFO:     Found new best model at epoch 9
2022-12-05 22:29:02,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:02,124 INFO:     Epoch: 10
2022-12-05 22:29:02,912 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3919492753391916, 'Total loss': 0.3919492753391916} | train loss {'Reaction outcome loss': 0.30417177317473615, 'Total loss': 0.30417177317473615}
2022-12-05 22:29:02,912 INFO:     Found new best model at epoch 10
2022-12-05 22:29:02,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:02,913 INFO:     Epoch: 11
2022-12-05 22:29:03,702 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3960216204551133, 'Total loss': 0.3960216204551133} | train loss {'Reaction outcome loss': 0.2945344029710843, 'Total loss': 0.2945344029710843}
2022-12-05 22:29:03,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:03,702 INFO:     Epoch: 12
2022-12-05 22:29:04,493 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40179293941367755, 'Total loss': 0.40179293941367755} | train loss {'Reaction outcome loss': 0.284445619022074, 'Total loss': 0.284445619022074}
2022-12-05 22:29:04,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:04,494 INFO:     Epoch: 13
2022-12-05 22:29:05,289 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3929884396493435, 'Total loss': 0.3929884396493435} | train loss {'Reaction outcome loss': 0.27276337455943045, 'Total loss': 0.27276337455943045}
2022-12-05 22:29:05,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:05,289 INFO:     Epoch: 14
2022-12-05 22:29:06,084 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3995187983594157, 'Total loss': 0.3995187983594157} | train loss {'Reaction outcome loss': 0.2661310209617441, 'Total loss': 0.2661310209617441}
2022-12-05 22:29:06,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:06,084 INFO:     Epoch: 15
2022-12-05 22:29:06,878 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39611846013841306, 'Total loss': 0.39611846013841306} | train loss {'Reaction outcome loss': 0.2578723886717669, 'Total loss': 0.2578723886717669}
2022-12-05 22:29:06,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:06,878 INFO:     Epoch: 16
2022-12-05 22:29:07,668 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3962859646840529, 'Total loss': 0.3962859646840529} | train loss {'Reaction outcome loss': 0.252273028618411, 'Total loss': 0.252273028618411}
2022-12-05 22:29:07,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:07,668 INFO:     Epoch: 17
2022-12-05 22:29:08,458 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41072412580251694, 'Total loss': 0.41072412580251694} | train loss {'Reaction outcome loss': 0.2446916840729202, 'Total loss': 0.2446916840729202}
2022-12-05 22:29:08,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:08,459 INFO:     Epoch: 18
2022-12-05 22:29:09,250 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4041619475253604, 'Total loss': 0.4041619475253604} | train loss {'Reaction outcome loss': 0.23753402753156205, 'Total loss': 0.23753402753156205}
2022-12-05 22:29:09,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:09,251 INFO:     Epoch: 19
2022-12-05 22:29:10,043 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40007826838303695, 'Total loss': 0.40007826838303695} | train loss {'Reaction outcome loss': 0.2332764113480263, 'Total loss': 0.2332764113480263}
2022-12-05 22:29:10,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:10,044 INFO:     Epoch: 20
2022-12-05 22:29:10,839 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4072605825283311, 'Total loss': 0.4072605825283311} | train loss {'Reaction outcome loss': 0.23195015560639531, 'Total loss': 0.23195015560639531}
2022-12-05 22:29:10,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:10,839 INFO:     Epoch: 21
2022-12-05 22:29:11,629 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3950924991884015, 'Total loss': 0.3950924991884015} | train loss {'Reaction outcome loss': 0.22244621269585874, 'Total loss': 0.22244621269585874}
2022-12-05 22:29:11,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:11,629 INFO:     Epoch: 22
2022-12-05 22:29:12,419 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.410378135740757, 'Total loss': 0.410378135740757} | train loss {'Reaction outcome loss': 0.22031162612833957, 'Total loss': 0.22031162612833957}
2022-12-05 22:29:12,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:12,419 INFO:     Epoch: 23
2022-12-05 22:29:13,208 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4126834473149343, 'Total loss': 0.4126834473149343} | train loss {'Reaction outcome loss': 0.2167434457704606, 'Total loss': 0.2167434457704606}
2022-12-05 22:29:13,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:13,208 INFO:     Epoch: 24
2022-12-05 22:29:13,998 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4190352975644849, 'Total loss': 0.4190352975644849} | train loss {'Reaction outcome loss': 0.20972854374089706, 'Total loss': 0.20972854374089706}
2022-12-05 22:29:13,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:13,998 INFO:     Epoch: 25
2022-12-05 22:29:14,787 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41501798582347954, 'Total loss': 0.41501798582347954} | train loss {'Reaction outcome loss': 0.20399414321128656, 'Total loss': 0.20399414321128656}
2022-12-05 22:29:14,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:14,788 INFO:     Epoch: 26
2022-12-05 22:29:15,577 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42752165550535376, 'Total loss': 0.42752165550535376} | train loss {'Reaction outcome loss': 0.19819460841657421, 'Total loss': 0.19819460841657421}
2022-12-05 22:29:15,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:15,577 INFO:     Epoch: 27
2022-12-05 22:29:16,368 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4227041571655057, 'Total loss': 0.4227041571655057} | train loss {'Reaction outcome loss': 0.19697890300228288, 'Total loss': 0.19697890300228288}
2022-12-05 22:29:16,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:16,368 INFO:     Epoch: 28
2022-12-05 22:29:17,158 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4217067740180276, 'Total loss': 0.4217067740180276} | train loss {'Reaction outcome loss': 0.19335164823889853, 'Total loss': 0.19335164823889853}
2022-12-05 22:29:17,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:17,158 INFO:     Epoch: 29
2022-12-05 22:29:17,949 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42733378437432373, 'Total loss': 0.42733378437432373} | train loss {'Reaction outcome loss': 0.186917517356846, 'Total loss': 0.186917517356846}
2022-12-05 22:29:17,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:17,950 INFO:     Epoch: 30
2022-12-05 22:29:18,746 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4194186952981082, 'Total loss': 0.4194186952981082} | train loss {'Reaction outcome loss': 0.19338494964577407, 'Total loss': 0.19338494964577407}
2022-12-05 22:29:18,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:18,746 INFO:     Epoch: 31
2022-12-05 22:29:19,542 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4185742204162208, 'Total loss': 0.4185742204162208} | train loss {'Reaction outcome loss': 0.19314628523898872, 'Total loss': 0.19314628523898872}
2022-12-05 22:29:19,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:19,543 INFO:     Epoch: 32
2022-12-05 22:29:20,338 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43465288305147126, 'Total loss': 0.43465288305147126} | train loss {'Reaction outcome loss': 0.18175356363055678, 'Total loss': 0.18175356363055678}
2022-12-05 22:29:20,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:20,338 INFO:     Epoch: 33
2022-12-05 22:29:21,127 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43785371191122313, 'Total loss': 0.43785371191122313} | train loss {'Reaction outcome loss': 0.17741219982173037, 'Total loss': 0.17741219982173037}
2022-12-05 22:29:21,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:21,127 INFO:     Epoch: 34
2022-12-05 22:29:21,920 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.448601480234753, 'Total loss': 0.448601480234753} | train loss {'Reaction outcome loss': 0.17969314756271568, 'Total loss': 0.17969314756271568}
2022-12-05 22:29:21,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:21,920 INFO:     Epoch: 35
2022-12-05 22:29:22,710 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4370929879898375, 'Total loss': 0.4370929879898375} | train loss {'Reaction outcome loss': 0.1738962759999068, 'Total loss': 0.1738962759999068}
2022-12-05 22:29:22,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:22,711 INFO:     Epoch: 36
2022-12-05 22:29:23,506 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43762964653697883, 'Total loss': 0.43762964653697883} | train loss {'Reaction outcome loss': 0.1724374372453659, 'Total loss': 0.1724374372453659}
2022-12-05 22:29:23,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:23,506 INFO:     Epoch: 37
2022-12-05 22:29:24,299 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44890472157434985, 'Total loss': 0.44890472157434985} | train loss {'Reaction outcome loss': 0.17113314133687962, 'Total loss': 0.17113314133687962}
2022-12-05 22:29:24,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:24,300 INFO:     Epoch: 38
2022-12-05 22:29:25,090 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4389074739407409, 'Total loss': 0.4389074739407409} | train loss {'Reaction outcome loss': 0.16722428768511244, 'Total loss': 0.16722428768511244}
2022-12-05 22:29:25,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:25,090 INFO:     Epoch: 39
2022-12-05 22:29:25,883 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43910336189649324, 'Total loss': 0.43910336189649324} | train loss {'Reaction outcome loss': 0.16729585137142827, 'Total loss': 0.16729585137142827}
2022-12-05 22:29:25,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:25,883 INFO:     Epoch: 40
2022-12-05 22:29:26,674 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4332418086176569, 'Total loss': 0.4332418086176569} | train loss {'Reaction outcome loss': 0.1736759716825869, 'Total loss': 0.1736759716825869}
2022-12-05 22:29:26,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:26,674 INFO:     Epoch: 41
2022-12-05 22:29:27,467 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44895118034698744, 'Total loss': 0.44895118034698744} | train loss {'Reaction outcome loss': 0.16626039149639335, 'Total loss': 0.16626039149639335}
2022-12-05 22:29:27,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:27,468 INFO:     Epoch: 42
2022-12-05 22:29:28,264 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44780168174342677, 'Total loss': 0.44780168174342677} | train loss {'Reaction outcome loss': 0.16631069323538164, 'Total loss': 0.16631069323538164}
2022-12-05 22:29:28,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:28,264 INFO:     Epoch: 43
2022-12-05 22:29:29,054 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.440435750071298, 'Total loss': 0.440435750071298} | train loss {'Reaction outcome loss': 0.16082779422915175, 'Total loss': 0.16082779422915175}
2022-12-05 22:29:29,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:29,055 INFO:     Epoch: 44
2022-12-05 22:29:29,849 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45448320477523585, 'Total loss': 0.45448320477523585} | train loss {'Reaction outcome loss': 0.15545511550386906, 'Total loss': 0.15545511550386906}
2022-12-05 22:29:29,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:29,850 INFO:     Epoch: 45
2022-12-05 22:29:30,643 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4545989344743165, 'Total loss': 0.4545989344743165} | train loss {'Reaction outcome loss': 0.1544261769606517, 'Total loss': 0.1544261769606517}
2022-12-05 22:29:30,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:30,644 INFO:     Epoch: 46
2022-12-05 22:29:31,436 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.439900143918666, 'Total loss': 0.439900143918666} | train loss {'Reaction outcome loss': 0.15673653428491793, 'Total loss': 0.15673653428491793}
2022-12-05 22:29:31,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:31,436 INFO:     Epoch: 47
2022-12-05 22:29:32,226 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45542983372103085, 'Total loss': 0.45542983372103085} | train loss {'Reaction outcome loss': 0.16111553408326165, 'Total loss': 0.16111553408326165}
2022-12-05 22:29:32,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:32,227 INFO:     Epoch: 48
2022-12-05 22:29:33,019 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4522901475429535, 'Total loss': 0.4522901475429535} | train loss {'Reaction outcome loss': 0.15320848344037166, 'Total loss': 0.15320848344037166}
2022-12-05 22:29:33,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:33,019 INFO:     Epoch: 49
2022-12-05 22:29:33,810 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44751920855858107, 'Total loss': 0.44751920855858107} | train loss {'Reaction outcome loss': 0.14875639056332546, 'Total loss': 0.14875639056332546}
2022-12-05 22:29:33,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:33,810 INFO:     Epoch: 50
2022-12-05 22:29:34,601 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.441899200393395, 'Total loss': 0.441899200393395} | train loss {'Reaction outcome loss': 0.15364681111897535, 'Total loss': 0.15364681111897535}
2022-12-05 22:29:34,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:34,601 INFO:     Epoch: 51
2022-12-05 22:29:35,396 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46091607500883663, 'Total loss': 0.46091607500883663} | train loss {'Reaction outcome loss': 0.15482987771715653, 'Total loss': 0.15482987771715653}
2022-12-05 22:29:35,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:35,396 INFO:     Epoch: 52
2022-12-05 22:29:36,193 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4562533497810364, 'Total loss': 0.4562533497810364} | train loss {'Reaction outcome loss': 0.1462823458257233, 'Total loss': 0.1462823458257233}
2022-12-05 22:29:36,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:36,194 INFO:     Epoch: 53
2022-12-05 22:29:36,985 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46053685510361736, 'Total loss': 0.46053685510361736} | train loss {'Reaction outcome loss': 0.14691298232443992, 'Total loss': 0.14691298232443992}
2022-12-05 22:29:36,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:36,985 INFO:     Epoch: 54
2022-12-05 22:29:37,778 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45622074231505394, 'Total loss': 0.45622074231505394} | train loss {'Reaction outcome loss': 0.1444239431647169, 'Total loss': 0.1444239431647169}
2022-12-05 22:29:37,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:37,778 INFO:     Epoch: 55
2022-12-05 22:29:38,569 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4736876870420846, 'Total loss': 0.4736876870420846} | train loss {'Reaction outcome loss': 0.14454396268888284, 'Total loss': 0.14454396268888284}
2022-12-05 22:29:38,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:38,569 INFO:     Epoch: 56
2022-12-05 22:29:39,362 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4596286598931659, 'Total loss': 0.4596286598931659} | train loss {'Reaction outcome loss': 0.14435776381146329, 'Total loss': 0.14435776381146329}
2022-12-05 22:29:39,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:39,362 INFO:     Epoch: 57
2022-12-05 22:29:40,158 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.477209651673382, 'Total loss': 0.477209651673382} | train loss {'Reaction outcome loss': 0.1428783589857159, 'Total loss': 0.1428783589857159}
2022-12-05 22:29:40,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:40,158 INFO:     Epoch: 58
2022-12-05 22:29:40,949 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4496628337285735, 'Total loss': 0.4496628337285735} | train loss {'Reaction outcome loss': 0.1411769823491694, 'Total loss': 0.1411769823491694}
2022-12-05 22:29:40,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:40,949 INFO:     Epoch: 59
2022-12-05 22:29:41,740 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4717164964161136, 'Total loss': 0.4717164964161136} | train loss {'Reaction outcome loss': 0.1404349055421173, 'Total loss': 0.1404349055421173}
2022-12-05 22:29:41,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:41,740 INFO:     Epoch: 60
2022-12-05 22:29:42,531 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46350800144401466, 'Total loss': 0.46350800144401466} | train loss {'Reaction outcome loss': 0.13737015748304138, 'Total loss': 0.13737015748304138}
2022-12-05 22:29:42,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:42,531 INFO:     Epoch: 61
2022-12-05 22:29:43,324 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46612346612594346, 'Total loss': 0.46612346612594346} | train loss {'Reaction outcome loss': 0.13853790713587272, 'Total loss': 0.13853790713587272}
2022-12-05 22:29:43,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:43,324 INFO:     Epoch: 62
2022-12-05 22:29:44,115 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.45263793353330006, 'Total loss': 0.45263793353330006} | train loss {'Reaction outcome loss': 0.14098371489554162, 'Total loss': 0.14098371489554162}
2022-12-05 22:29:44,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:44,115 INFO:     Epoch: 63
2022-12-05 22:29:44,905 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4753732053055005, 'Total loss': 0.4753732053055005} | train loss {'Reaction outcome loss': 0.14025750671426657, 'Total loss': 0.14025750671426657}
2022-12-05 22:29:44,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:44,906 INFO:     Epoch: 64
2022-12-05 22:29:45,696 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4683873421427878, 'Total loss': 0.4683873421427878} | train loss {'Reaction outcome loss': 0.1402227968610974, 'Total loss': 0.1402227968610974}
2022-12-05 22:29:45,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:45,697 INFO:     Epoch: 65
2022-12-05 22:29:46,490 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47232100096615875, 'Total loss': 0.47232100096615875} | train loss {'Reaction outcome loss': 0.13400740260239463, 'Total loss': 0.13400740260239463}
2022-12-05 22:29:46,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:46,490 INFO:     Epoch: 66
2022-12-05 22:29:47,280 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4781693999062885, 'Total loss': 0.4781693999062885} | train loss {'Reaction outcome loss': 0.13349851341880406, 'Total loss': 0.13349851341880406}
2022-12-05 22:29:47,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:47,280 INFO:     Epoch: 67
2022-12-05 22:29:48,069 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.46266818994825537, 'Total loss': 0.46266818994825537} | train loss {'Reaction outcome loss': 0.1389914675151952, 'Total loss': 0.1389914675151952}
2022-12-05 22:29:48,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:48,070 INFO:     Epoch: 68
2022-12-05 22:29:48,860 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4681816500696269, 'Total loss': 0.4681816500696269} | train loss {'Reaction outcome loss': 0.13962579270808764, 'Total loss': 0.13962579270808764}
2022-12-05 22:29:48,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:48,860 INFO:     Epoch: 69
2022-12-05 22:29:49,654 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4656599821014838, 'Total loss': 0.4656599821014838} | train loss {'Reaction outcome loss': 0.13383882845137343, 'Total loss': 0.13383882845137343}
2022-12-05 22:29:49,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:49,654 INFO:     Epoch: 70
2022-12-05 22:29:50,448 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4718559675595977, 'Total loss': 0.4718559675595977} | train loss {'Reaction outcome loss': 0.13248359583891356, 'Total loss': 0.13248359583891356}
2022-12-05 22:29:50,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:50,448 INFO:     Epoch: 71
2022-12-05 22:29:51,239 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4693324521861293, 'Total loss': 0.4693324521861293} | train loss {'Reaction outcome loss': 0.13197050871787525, 'Total loss': 0.13197050871787525}
2022-12-05 22:29:51,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:51,239 INFO:     Epoch: 72
2022-12-05 22:29:52,029 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4707444626837969, 'Total loss': 0.4707444626837969} | train loss {'Reaction outcome loss': 0.1378316475221744, 'Total loss': 0.1378316475221744}
2022-12-05 22:29:52,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:52,029 INFO:     Epoch: 73
2022-12-05 22:29:52,821 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45872947438196704, 'Total loss': 0.45872947438196704} | train loss {'Reaction outcome loss': 0.1343013783341824, 'Total loss': 0.1343013783341824}
2022-12-05 22:29:52,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:52,821 INFO:     Epoch: 74
2022-12-05 22:29:53,615 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48237519270994444, 'Total loss': 0.48237519270994444} | train loss {'Reaction outcome loss': 0.12789488390468906, 'Total loss': 0.12789488390468906}
2022-12-05 22:29:53,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:53,615 INFO:     Epoch: 75
2022-12-05 22:29:54,409 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4850426026704637, 'Total loss': 0.4850426026704637} | train loss {'Reaction outcome loss': 0.1265764064457162, 'Total loss': 0.1265764064457162}
2022-12-05 22:29:54,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:54,410 INFO:     Epoch: 76
2022-12-05 22:29:55,207 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4834864039651372, 'Total loss': 0.4834864039651372} | train loss {'Reaction outcome loss': 0.1295069989235506, 'Total loss': 0.1295069989235506}
2022-12-05 22:29:55,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:55,207 INFO:     Epoch: 77
2022-12-05 22:29:56,001 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4675827365029942, 'Total loss': 0.4675827365029942} | train loss {'Reaction outcome loss': 0.1269241455406976, 'Total loss': 0.1269241455406976}
2022-12-05 22:29:56,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:56,002 INFO:     Epoch: 78
2022-12-05 22:29:56,798 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4875748719681393, 'Total loss': 0.4875748719681393} | train loss {'Reaction outcome loss': 0.1286125187413307, 'Total loss': 0.1286125187413307}
2022-12-05 22:29:56,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:56,799 INFO:     Epoch: 79
2022-12-05 22:29:57,592 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49150968207554385, 'Total loss': 0.49150968207554385} | train loss {'Reaction outcome loss': 0.12457575575874644, 'Total loss': 0.12457575575874644}
2022-12-05 22:29:57,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:57,592 INFO:     Epoch: 80
2022-12-05 22:29:58,382 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4686753292652694, 'Total loss': 0.4686753292652694} | train loss {'Reaction outcome loss': 0.12636394399455805, 'Total loss': 0.12636394399455805}
2022-12-05 22:29:58,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:58,382 INFO:     Epoch: 81
2022-12-05 22:29:59,176 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4718105715106834, 'Total loss': 0.4718105715106834} | train loss {'Reaction outcome loss': 0.12681725154431, 'Total loss': 0.12681725154431}
2022-12-05 22:29:59,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:59,176 INFO:     Epoch: 82
2022-12-05 22:29:59,965 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4829886037517678, 'Total loss': 0.4829886037517678} | train loss {'Reaction outcome loss': 0.1266055265441537, 'Total loss': 0.1266055265441537}
2022-12-05 22:29:59,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:29:59,965 INFO:     Epoch: 83
2022-12-05 22:30:00,758 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48421641608530824, 'Total loss': 0.48421641608530824} | train loss {'Reaction outcome loss': 0.12672858703353626, 'Total loss': 0.12672858703353626}
2022-12-05 22:30:00,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:00,759 INFO:     Epoch: 84
2022-12-05 22:30:01,552 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47485931539400056, 'Total loss': 0.47485931539400056} | train loss {'Reaction outcome loss': 0.12612494800394394, 'Total loss': 0.12612494800394394}
2022-12-05 22:30:01,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:01,553 INFO:     Epoch: 85
2022-12-05 22:30:02,342 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46859742226925766, 'Total loss': 0.46859742226925766} | train loss {'Reaction outcome loss': 0.12563553018502982, 'Total loss': 0.12563553018502982}
2022-12-05 22:30:02,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:02,342 INFO:     Epoch: 86
2022-12-05 22:30:03,131 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4742844484069131, 'Total loss': 0.4742844484069131} | train loss {'Reaction outcome loss': 0.12520073040535576, 'Total loss': 0.12520073040535576}
2022-12-05 22:30:03,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:03,132 INFO:     Epoch: 87
2022-12-05 22:30:03,921 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4773145859891718, 'Total loss': 0.4773145859891718} | train loss {'Reaction outcome loss': 0.12462063297994155, 'Total loss': 0.12462063297994155}
2022-12-05 22:30:03,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:03,921 INFO:     Epoch: 88
2022-12-05 22:30:04,710 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4785059913992882, 'Total loss': 0.4785059913992882} | train loss {'Reaction outcome loss': 0.12394646083114118, 'Total loss': 0.12394646083114118}
2022-12-05 22:30:04,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:04,710 INFO:     Epoch: 89
2022-12-05 22:30:05,499 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46200488710945303, 'Total loss': 0.46200488710945303} | train loss {'Reaction outcome loss': 0.12866360507905483, 'Total loss': 0.12866360507905483}
2022-12-05 22:30:05,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:05,499 INFO:     Epoch: 90
2022-12-05 22:30:06,291 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4577846825122833, 'Total loss': 0.4577846825122833} | train loss {'Reaction outcome loss': 0.12271638712487541, 'Total loss': 0.12271638712487541}
2022-12-05 22:30:06,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:06,291 INFO:     Epoch: 91
2022-12-05 22:30:07,081 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4743716476315802, 'Total loss': 0.4743716476315802} | train loss {'Reaction outcome loss': 0.12356052275837554, 'Total loss': 0.12356052275837554}
2022-12-05 22:30:07,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:07,081 INFO:     Epoch: 92
2022-12-05 22:30:07,869 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4753256988796321, 'Total loss': 0.4753256988796321} | train loss {'Reaction outcome loss': 0.1216436020656666, 'Total loss': 0.1216436020656666}
2022-12-05 22:30:07,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:07,869 INFO:     Epoch: 93
2022-12-05 22:30:08,661 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49202088808471506, 'Total loss': 0.49202088808471506} | train loss {'Reaction outcome loss': 0.12364978776294512, 'Total loss': 0.12364978776294512}
2022-12-05 22:30:08,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:08,661 INFO:     Epoch: 94
2022-12-05 22:30:09,455 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4828395244072784, 'Total loss': 0.4828395244072784} | train loss {'Reaction outcome loss': 0.1234049014615174, 'Total loss': 0.1234049014615174}
2022-12-05 22:30:09,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:09,455 INFO:     Epoch: 95
2022-12-05 22:30:10,244 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.47426729717037897, 'Total loss': 0.47426729717037897} | train loss {'Reaction outcome loss': 0.12111392993996531, 'Total loss': 0.12111392993996531}
2022-12-05 22:30:10,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:10,244 INFO:     Epoch: 96
2022-12-05 22:30:11,032 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4830179138278419, 'Total loss': 0.4830179138278419} | train loss {'Reaction outcome loss': 0.12408861598972729, 'Total loss': 0.12408861598972729}
2022-12-05 22:30:11,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:11,032 INFO:     Epoch: 97
2022-12-05 22:30:11,823 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4865062700753862, 'Total loss': 0.4865062700753862} | train loss {'Reaction outcome loss': 0.13185709493936074, 'Total loss': 0.13185709493936074}
2022-12-05 22:30:11,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:11,823 INFO:     Epoch: 98
2022-12-05 22:30:12,610 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4753642373464324, 'Total loss': 0.4753642373464324} | train loss {'Reaction outcome loss': 0.11895619871281936, 'Total loss': 0.11895619871281936}
2022-12-05 22:30:12,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:12,611 INFO:     Epoch: 99
2022-12-05 22:30:13,398 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48665160753510217, 'Total loss': 0.48665160753510217} | train loss {'Reaction outcome loss': 0.12007844425089326, 'Total loss': 0.12007844425089326}
2022-12-05 22:30:13,398 INFO:     Best model found after epoch 11 of 100.
2022-12-05 22:30:13,398 INFO:   Done with stage: TRAINING
2022-12-05 22:30:13,399 INFO:   Starting stage: EVALUATION
2022-12-05 22:30:13,524 INFO:   Done with stage: EVALUATION
2022-12-05 22:30:13,524 INFO:   Leaving out SEQ value Fold_2
2022-12-05 22:30:13,537 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 22:30:13,537 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:30:14,166 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:30:14,166 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:30:14,234 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:30:14,234 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:30:14,234 INFO:     No hyperparam tuning for this model
2022-12-05 22:30:14,234 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:30:14,234 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:30:14,235 INFO:     None feature selector for col prot
2022-12-05 22:30:14,235 INFO:     None feature selector for col prot
2022-12-05 22:30:14,235 INFO:     None feature selector for col prot
2022-12-05 22:30:14,236 INFO:     None feature selector for col chem
2022-12-05 22:30:14,236 INFO:     None feature selector for col chem
2022-12-05 22:30:14,236 INFO:     None feature selector for col chem
2022-12-05 22:30:14,236 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:30:14,236 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:30:14,238 INFO:     Number of params in model 215821
2022-12-05 22:30:14,241 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:30:14,241 INFO:   Starting stage: TRAINING
2022-12-05 22:30:14,300 INFO:     Val loss before train {'Reaction outcome loss': 0.9989243122034295, 'Total loss': 0.9989243122034295}
2022-12-05 22:30:14,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:14,300 INFO:     Epoch: 0
2022-12-05 22:30:15,074 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5983455312806506, 'Total loss': 0.5983455312806506} | train loss {'Reaction outcome loss': 0.7983201256504765, 'Total loss': 0.7983201256504765}
2022-12-05 22:30:15,075 INFO:     Found new best model at epoch 0
2022-12-05 22:30:15,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:15,075 INFO:     Epoch: 1
2022-12-05 22:30:15,847 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4953288020089615, 'Total loss': 0.4953288020089615} | train loss {'Reaction outcome loss': 0.5466238525178697, 'Total loss': 0.5466238525178697}
2022-12-05 22:30:15,847 INFO:     Found new best model at epoch 1
2022-12-05 22:30:15,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:15,848 INFO:     Epoch: 2
2022-12-05 22:30:16,624 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45598778994970546, 'Total loss': 0.45598778994970546} | train loss {'Reaction outcome loss': 0.46754345708668477, 'Total loss': 0.46754345708668477}
2022-12-05 22:30:16,625 INFO:     Found new best model at epoch 2
2022-12-05 22:30:16,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:16,625 INFO:     Epoch: 3
2022-12-05 22:30:17,398 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4447651623293411, 'Total loss': 0.4447651623293411} | train loss {'Reaction outcome loss': 0.42778732495788685, 'Total loss': 0.42778732495788685}
2022-12-05 22:30:17,398 INFO:     Found new best model at epoch 3
2022-12-05 22:30:17,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:17,399 INFO:     Epoch: 4
2022-12-05 22:30:18,172 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4329931891934816, 'Total loss': 0.4329931891934816} | train loss {'Reaction outcome loss': 0.39896920216058995, 'Total loss': 0.39896920216058995}
2022-12-05 22:30:18,172 INFO:     Found new best model at epoch 4
2022-12-05 22:30:18,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:18,173 INFO:     Epoch: 5
2022-12-05 22:30:18,947 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4243898093700409, 'Total loss': 0.4243898093700409} | train loss {'Reaction outcome loss': 0.3768631271680687, 'Total loss': 0.3768631271680687}
2022-12-05 22:30:18,947 INFO:     Found new best model at epoch 5
2022-12-05 22:30:18,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:18,948 INFO:     Epoch: 6
2022-12-05 22:30:19,723 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4169776879770811, 'Total loss': 0.4169776879770811} | train loss {'Reaction outcome loss': 0.35938273554230915, 'Total loss': 0.35938273554230915}
2022-12-05 22:30:19,724 INFO:     Found new best model at epoch 6
2022-12-05 22:30:19,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:19,725 INFO:     Epoch: 7
2022-12-05 22:30:20,498 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4159350932337517, 'Total loss': 0.4159350932337517} | train loss {'Reaction outcome loss': 0.34108521571620504, 'Total loss': 0.34108521571620504}
2022-12-05 22:30:20,498 INFO:     Found new best model at epoch 7
2022-12-05 22:30:20,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:20,499 INFO:     Epoch: 8
2022-12-05 22:30:21,273 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41795531850914625, 'Total loss': 0.41795531850914625} | train loss {'Reaction outcome loss': 0.3251731439566416, 'Total loss': 0.3251731439566416}
2022-12-05 22:30:21,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:21,273 INFO:     Epoch: 9
2022-12-05 22:30:22,048 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4240335558736047, 'Total loss': 0.4240335558736047} | train loss {'Reaction outcome loss': 0.3151223559867698, 'Total loss': 0.3151223559867698}
2022-12-05 22:30:22,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:22,048 INFO:     Epoch: 10
2022-12-05 22:30:22,826 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4308139735529589, 'Total loss': 0.4308139735529589} | train loss {'Reaction outcome loss': 0.3017293671031057, 'Total loss': 0.3017293671031057}
2022-12-05 22:30:22,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:22,826 INFO:     Epoch: 11
2022-12-05 22:30:23,605 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4201664543429086, 'Total loss': 0.4201664543429086} | train loss {'Reaction outcome loss': 0.2916861025639522, 'Total loss': 0.2916861025639522}
2022-12-05 22:30:23,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:23,606 INFO:     Epoch: 12
2022-12-05 22:30:24,379 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.420874492720116, 'Total loss': 0.420874492720116} | train loss {'Reaction outcome loss': 0.28074599771833225, 'Total loss': 0.28074599771833225}
2022-12-05 22:30:24,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:24,379 INFO:     Epoch: 13
2022-12-05 22:30:25,153 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42896163082400035, 'Total loss': 0.42896163082400035} | train loss {'Reaction outcome loss': 0.2732403077062511, 'Total loss': 0.2732403077062511}
2022-12-05 22:30:25,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:25,153 INFO:     Epoch: 14
2022-12-05 22:30:25,927 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4208387087943942, 'Total loss': 0.4208387087943942} | train loss {'Reaction outcome loss': 0.26576426274185316, 'Total loss': 0.26576426274185316}
2022-12-05 22:30:25,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:25,927 INFO:     Epoch: 15
2022-12-05 22:30:26,703 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4527067521283793, 'Total loss': 0.4527067521283793} | train loss {'Reaction outcome loss': 0.25879887936046586, 'Total loss': 0.25879887936046586}
2022-12-05 22:30:26,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:26,703 INFO:     Epoch: 16
2022-12-05 22:30:27,480 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43264627837857533, 'Total loss': 0.43264627837857533} | train loss {'Reaction outcome loss': 0.2494152869431325, 'Total loss': 0.2494152869431325}
2022-12-05 22:30:27,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:27,480 INFO:     Epoch: 17
2022-12-05 22:30:28,264 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42952014540517053, 'Total loss': 0.42952014540517053} | train loss {'Reaction outcome loss': 0.2440535382141547, 'Total loss': 0.2440535382141547}
2022-12-05 22:30:28,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:28,264 INFO:     Epoch: 18
2022-12-05 22:30:29,046 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42056975149831105, 'Total loss': 0.42056975149831105} | train loss {'Reaction outcome loss': 0.23920405278971166, 'Total loss': 0.23920405278971166}
2022-12-05 22:30:29,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:29,046 INFO:     Epoch: 19
2022-12-05 22:30:29,823 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43301645960918694, 'Total loss': 0.43301645960918694} | train loss {'Reaction outcome loss': 0.23139240135871825, 'Total loss': 0.23139240135871825}
2022-12-05 22:30:29,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:29,824 INFO:     Epoch: 20
2022-12-05 22:30:30,602 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44088666522225667, 'Total loss': 0.44088666522225667} | train loss {'Reaction outcome loss': 0.227316463557781, 'Total loss': 0.227316463557781}
2022-12-05 22:30:30,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:30,603 INFO:     Epoch: 21
2022-12-05 22:30:31,382 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43989369758339814, 'Total loss': 0.43989369758339814} | train loss {'Reaction outcome loss': 0.22075131898860872, 'Total loss': 0.22075131898860872}
2022-12-05 22:30:31,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:31,382 INFO:     Epoch: 22
2022-12-05 22:30:32,164 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4336367460877396, 'Total loss': 0.4336367460877396} | train loss {'Reaction outcome loss': 0.21545833300170583, 'Total loss': 0.21545833300170583}
2022-12-05 22:30:32,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:32,166 INFO:     Epoch: 23
2022-12-05 22:30:32,943 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43497819193573883, 'Total loss': 0.43497819193573883} | train loss {'Reaction outcome loss': 0.21241525894820446, 'Total loss': 0.21241525894820446}
2022-12-05 22:30:32,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:32,943 INFO:     Epoch: 24
2022-12-05 22:30:33,725 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4499381014774012, 'Total loss': 0.4499381014774012} | train loss {'Reaction outcome loss': 0.2062676130744165, 'Total loss': 0.2062676130744165}
2022-12-05 22:30:33,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:33,725 INFO:     Epoch: 25
2022-12-05 22:30:34,511 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4393631491896718, 'Total loss': 0.4393631491896718} | train loss {'Reaction outcome loss': 0.20595205260954277, 'Total loss': 0.20595205260954277}
2022-12-05 22:30:34,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:34,512 INFO:     Epoch: 26
2022-12-05 22:30:35,296 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42949449322944466, 'Total loss': 0.42949449322944466} | train loss {'Reaction outcome loss': 0.19970730509716297, 'Total loss': 0.19970730509716297}
2022-12-05 22:30:35,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:35,296 INFO:     Epoch: 27
2022-12-05 22:30:36,074 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43339217246271844, 'Total loss': 0.43339217246271844} | train loss {'Reaction outcome loss': 0.19423982424377906, 'Total loss': 0.19423982424377906}
2022-12-05 22:30:36,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:36,074 INFO:     Epoch: 28
2022-12-05 22:30:36,851 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4516108217974042, 'Total loss': 0.4516108217974042} | train loss {'Reaction outcome loss': 0.19075666228500904, 'Total loss': 0.19075666228500904}
2022-12-05 22:30:36,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:36,852 INFO:     Epoch: 29
2022-12-05 22:30:37,630 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45650301059318144, 'Total loss': 0.45650301059318144} | train loss {'Reaction outcome loss': 0.18807326333880914, 'Total loss': 0.18807326333880914}
2022-12-05 22:30:37,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:37,630 INFO:     Epoch: 30
2022-12-05 22:30:38,411 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44819627373024473, 'Total loss': 0.44819627373024473} | train loss {'Reaction outcome loss': 0.18730457157755095, 'Total loss': 0.18730457157755095}
2022-12-05 22:30:38,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:38,412 INFO:     Epoch: 31
2022-12-05 22:30:39,190 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42950101162112037, 'Total loss': 0.42950101162112037} | train loss {'Reaction outcome loss': 0.18336831154340089, 'Total loss': 0.18336831154340089}
2022-12-05 22:30:39,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:39,191 INFO:     Epoch: 32
2022-12-05 22:30:39,968 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4457292487454969, 'Total loss': 0.4457292487454969} | train loss {'Reaction outcome loss': 0.17851971871690986, 'Total loss': 0.17851971871690986}
2022-12-05 22:30:39,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:39,968 INFO:     Epoch: 33
2022-12-05 22:30:40,745 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4315196293037991, 'Total loss': 0.4315196293037991} | train loss {'Reaction outcome loss': 0.1800221921837747, 'Total loss': 0.1800221921837747}
2022-12-05 22:30:40,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:40,745 INFO:     Epoch: 34
2022-12-05 22:30:41,522 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44773769898470056, 'Total loss': 0.44773769898470056} | train loss {'Reaction outcome loss': 0.17527479669194163, 'Total loss': 0.17527479669194163}
2022-12-05 22:30:41,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:41,522 INFO:     Epoch: 35
2022-12-05 22:30:42,299 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4426178464362788, 'Total loss': 0.4426178464362788} | train loss {'Reaction outcome loss': 0.171874564508965, 'Total loss': 0.171874564508965}
2022-12-05 22:30:42,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:42,299 INFO:     Epoch: 36
2022-12-05 22:30:43,082 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44768461862275766, 'Total loss': 0.44768461862275766} | train loss {'Reaction outcome loss': 0.16906971703647586, 'Total loss': 0.16906971703647586}
2022-12-05 22:30:43,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:43,083 INFO:     Epoch: 37
2022-12-05 22:30:43,860 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4460354833755382, 'Total loss': 0.4460354833755382} | train loss {'Reaction outcome loss': 0.1694092474908495, 'Total loss': 0.1694092474908495}
2022-12-05 22:30:43,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:43,860 INFO:     Epoch: 38
2022-12-05 22:30:44,640 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44729218320098035, 'Total loss': 0.44729218320098035} | train loss {'Reaction outcome loss': 0.1644206664643783, 'Total loss': 0.1644206664643783}
2022-12-05 22:30:44,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:44,640 INFO:     Epoch: 39
2022-12-05 22:30:45,420 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44160548926785936, 'Total loss': 0.44160548926785936} | train loss {'Reaction outcome loss': 0.16723519932371353, 'Total loss': 0.16723519932371353}
2022-12-05 22:30:45,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:45,420 INFO:     Epoch: 40
2022-12-05 22:30:46,202 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4466098335593246, 'Total loss': 0.4466098335593246} | train loss {'Reaction outcome loss': 0.16148400062948098, 'Total loss': 0.16148400062948098}
2022-12-05 22:30:46,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:46,202 INFO:     Epoch: 41
2022-12-05 22:30:46,984 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43624490672765776, 'Total loss': 0.43624490672765776} | train loss {'Reaction outcome loss': 0.16269187433760107, 'Total loss': 0.16269187433760107}
2022-12-05 22:30:46,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:46,984 INFO:     Epoch: 42
2022-12-05 22:30:47,763 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4380937287973803, 'Total loss': 0.4380937287973803} | train loss {'Reaction outcome loss': 0.15904554648424496, 'Total loss': 0.15904554648424496}
2022-12-05 22:30:47,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:47,763 INFO:     Epoch: 43
2022-12-05 22:30:48,541 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4424253480378972, 'Total loss': 0.4424253480378972} | train loss {'Reaction outcome loss': 0.15600902049844403, 'Total loss': 0.15600902049844403}
2022-12-05 22:30:48,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:48,541 INFO:     Epoch: 44
2022-12-05 22:30:49,320 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44170903674391815, 'Total loss': 0.44170903674391815} | train loss {'Reaction outcome loss': 0.15775794919902159, 'Total loss': 0.15775794919902159}
2022-12-05 22:30:49,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:49,320 INFO:     Epoch: 45
2022-12-05 22:30:50,097 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4469085193650667, 'Total loss': 0.4469085193650667} | train loss {'Reaction outcome loss': 0.15531816006036392, 'Total loss': 0.15531816006036392}
2022-12-05 22:30:50,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:50,097 INFO:     Epoch: 46
2022-12-05 22:30:50,880 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44407051108604256, 'Total loss': 0.44407051108604256} | train loss {'Reaction outcome loss': 0.15346285219423075, 'Total loss': 0.15346285219423075}
2022-12-05 22:30:50,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:50,881 INFO:     Epoch: 47
2022-12-05 22:30:51,664 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4560070904188378, 'Total loss': 0.4560070904188378} | train loss {'Reaction outcome loss': 0.15297104414445137, 'Total loss': 0.15297104414445137}
2022-12-05 22:30:51,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:51,665 INFO:     Epoch: 48
2022-12-05 22:30:52,441 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4427134448359179, 'Total loss': 0.4427134448359179} | train loss {'Reaction outcome loss': 0.15163868505492378, 'Total loss': 0.15163868505492378}
2022-12-05 22:30:52,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:52,442 INFO:     Epoch: 49
2022-12-05 22:30:53,221 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.443735761004825, 'Total loss': 0.443735761004825} | train loss {'Reaction outcome loss': 0.15073981141449247, 'Total loss': 0.15073981141449247}
2022-12-05 22:30:53,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:53,221 INFO:     Epoch: 50
2022-12-05 22:30:53,998 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4475614684958791, 'Total loss': 0.4475614684958791} | train loss {'Reaction outcome loss': 0.15129546926418175, 'Total loss': 0.15129546926418175}
2022-12-05 22:30:53,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:53,999 INFO:     Epoch: 51
2022-12-05 22:30:54,778 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.450947736584863, 'Total loss': 0.450947736584863} | train loss {'Reaction outcome loss': 0.14514825068444873, 'Total loss': 0.14514825068444873}
2022-12-05 22:30:54,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:54,778 INFO:     Epoch: 52
2022-12-05 22:30:55,559 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4662010628123616, 'Total loss': 0.4662010628123616} | train loss {'Reaction outcome loss': 0.14396817406539808, 'Total loss': 0.14396817406539808}
2022-12-05 22:30:55,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:55,559 INFO:     Epoch: 53
2022-12-05 22:30:56,338 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4548566230507784, 'Total loss': 0.4548566230507784} | train loss {'Reaction outcome loss': 0.14346570320381427, 'Total loss': 0.14346570320381427}
2022-12-05 22:30:56,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:56,338 INFO:     Epoch: 54
2022-12-05 22:30:57,115 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46479934453964233, 'Total loss': 0.46479934453964233} | train loss {'Reaction outcome loss': 0.1440909436670105, 'Total loss': 0.1440909436670105}
2022-12-05 22:30:57,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:57,115 INFO:     Epoch: 55
2022-12-05 22:30:57,895 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.470009031337361, 'Total loss': 0.470009031337361} | train loss {'Reaction outcome loss': 0.14588631044138115, 'Total loss': 0.14588631044138115}
2022-12-05 22:30:57,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:57,896 INFO:     Epoch: 56
2022-12-05 22:30:58,678 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4482567150925481, 'Total loss': 0.4482567150925481} | train loss {'Reaction outcome loss': 0.14324916802622653, 'Total loss': 0.14324916802622653}
2022-12-05 22:30:58,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:58,678 INFO:     Epoch: 57
2022-12-05 22:30:59,457 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44620458833700005, 'Total loss': 0.44620458833700005} | train loss {'Reaction outcome loss': 0.14131710988779864, 'Total loss': 0.14131710988779864}
2022-12-05 22:30:59,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:30:59,457 INFO:     Epoch: 58
2022-12-05 22:31:00,239 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46841429208600244, 'Total loss': 0.46841429208600244} | train loss {'Reaction outcome loss': 0.14282897537106595, 'Total loss': 0.14282897537106595}
2022-12-05 22:31:00,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:00,239 INFO:     Epoch: 59
2022-12-05 22:31:01,017 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45469913302465925, 'Total loss': 0.45469913302465925} | train loss {'Reaction outcome loss': 0.13914472208868084, 'Total loss': 0.13914472208868084}
2022-12-05 22:31:01,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:01,017 INFO:     Epoch: 60
2022-12-05 22:31:01,797 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4499401834815048, 'Total loss': 0.4499401834815048} | train loss {'Reaction outcome loss': 0.1387755233687138, 'Total loss': 0.1387755233687138}
2022-12-05 22:31:01,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:01,798 INFO:     Epoch: 61
2022-12-05 22:31:02,574 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44048773722593176, 'Total loss': 0.44048773722593176} | train loss {'Reaction outcome loss': 0.1391657263945037, 'Total loss': 0.1391657263945037}
2022-12-05 22:31:02,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:02,575 INFO:     Epoch: 62
2022-12-05 22:31:03,360 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4405984036451162, 'Total loss': 0.4405984036451162} | train loss {'Reaction outcome loss': 0.1390834323364337, 'Total loss': 0.1390834323364337}
2022-12-05 22:31:03,361 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:03,361 INFO:     Epoch: 63
2022-12-05 22:31:04,150 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44781564453313516, 'Total loss': 0.44781564453313516} | train loss {'Reaction outcome loss': 0.14091751304428274, 'Total loss': 0.14091751304428274}
2022-12-05 22:31:04,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:04,151 INFO:     Epoch: 64
2022-12-05 22:31:04,943 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4462747688210288, 'Total loss': 0.4462747688210288} | train loss {'Reaction outcome loss': 0.13705947931564638, 'Total loss': 0.13705947931564638}
2022-12-05 22:31:04,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:04,943 INFO:     Epoch: 65
2022-12-05 22:31:05,736 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44972751202971434, 'Total loss': 0.44972751202971434} | train loss {'Reaction outcome loss': 0.1370116464119144, 'Total loss': 0.1370116464119144}
2022-12-05 22:31:05,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:05,736 INFO:     Epoch: 66
2022-12-05 22:31:06,525 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46397464081298473, 'Total loss': 0.46397464081298473} | train loss {'Reaction outcome loss': 0.1350183489697951, 'Total loss': 0.1350183489697951}
2022-12-05 22:31:06,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:06,525 INFO:     Epoch: 67
2022-12-05 22:31:07,317 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4478003677240638, 'Total loss': 0.4478003677240638} | train loss {'Reaction outcome loss': 0.13480955228562094, 'Total loss': 0.13480955228562094}
2022-12-05 22:31:07,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:07,317 INFO:     Epoch: 68
2022-12-05 22:31:08,111 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4379611417304638, 'Total loss': 0.4379611417304638} | train loss {'Reaction outcome loss': 0.13397866363326708, 'Total loss': 0.13397866363326708}
2022-12-05 22:31:08,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:08,111 INFO:     Epoch: 69
2022-12-05 22:31:08,906 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4505578511676123, 'Total loss': 0.4505578511676123} | train loss {'Reaction outcome loss': 0.1375395068937123, 'Total loss': 0.1375395068937123}
2022-12-05 22:31:08,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:08,906 INFO:     Epoch: 70
2022-12-05 22:31:09,701 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4639835253704426, 'Total loss': 0.4639835253704426} | train loss {'Reaction outcome loss': 0.13287580826553544, 'Total loss': 0.13287580826553544}
2022-12-05 22:31:09,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:09,701 INFO:     Epoch: 71
2022-12-05 22:31:10,495 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46236899061951525, 'Total loss': 0.46236899061951525} | train loss {'Reaction outcome loss': 0.13220385803913873, 'Total loss': 0.13220385803913873}
2022-12-05 22:31:10,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:10,495 INFO:     Epoch: 72
2022-12-05 22:31:11,290 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46149727858083195, 'Total loss': 0.46149727858083195} | train loss {'Reaction outcome loss': 0.1315993217084511, 'Total loss': 0.1315993217084511}
2022-12-05 22:31:11,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:11,290 INFO:     Epoch: 73
2022-12-05 22:31:12,087 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43523810977159544, 'Total loss': 0.43523810977159544} | train loss {'Reaction outcome loss': 0.13178168893350986, 'Total loss': 0.13178168893350986}
2022-12-05 22:31:12,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:12,087 INFO:     Epoch: 74
2022-12-05 22:31:12,884 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45797891845536787, 'Total loss': 0.45797891845536787} | train loss {'Reaction outcome loss': 0.12839878122839662, 'Total loss': 0.12839878122839662}
2022-12-05 22:31:12,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:12,884 INFO:     Epoch: 75
2022-12-05 22:31:13,677 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4575062983257826, 'Total loss': 0.4575062983257826} | train loss {'Reaction outcome loss': 0.13232120450340795, 'Total loss': 0.13232120450340795}
2022-12-05 22:31:13,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:13,677 INFO:     Epoch: 76
2022-12-05 22:31:14,473 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4538246098645898, 'Total loss': 0.4538246098645898} | train loss {'Reaction outcome loss': 0.13370236486901718, 'Total loss': 0.13370236486901718}
2022-12-05 22:31:14,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:14,474 INFO:     Epoch: 77
2022-12-05 22:31:15,267 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45624317506025003, 'Total loss': 0.45624317506025003} | train loss {'Reaction outcome loss': 0.13026425732613958, 'Total loss': 0.13026425732613958}
2022-12-05 22:31:15,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:15,267 INFO:     Epoch: 78
2022-12-05 22:31:16,063 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4610329949578574, 'Total loss': 0.4610329949578574} | train loss {'Reaction outcome loss': 0.12828021035088924, 'Total loss': 0.12828021035088924}
2022-12-05 22:31:16,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:16,063 INFO:     Epoch: 79
2022-12-05 22:31:16,857 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4692944083795991, 'Total loss': 0.4692944083795991} | train loss {'Reaction outcome loss': 0.1260907327518664, 'Total loss': 0.1260907327518664}
2022-12-05 22:31:16,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:16,857 INFO:     Epoch: 80
2022-12-05 22:31:17,652 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.447123846169128, 'Total loss': 0.447123846169128} | train loss {'Reaction outcome loss': 0.12995860383773047, 'Total loss': 0.12995860383773047}
2022-12-05 22:31:17,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:17,653 INFO:     Epoch: 81
2022-12-05 22:31:18,445 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45219096783981766, 'Total loss': 0.45219096783981766} | train loss {'Reaction outcome loss': 0.12511845909197022, 'Total loss': 0.12511845909197022}
2022-12-05 22:31:18,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:18,445 INFO:     Epoch: 82
2022-12-05 22:31:19,237 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4577269912805668, 'Total loss': 0.4577269912805668} | train loss {'Reaction outcome loss': 0.12814508064615507, 'Total loss': 0.12814508064615507}
2022-12-05 22:31:19,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:19,237 INFO:     Epoch: 83
2022-12-05 22:31:20,035 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4669460867379987, 'Total loss': 0.4669460867379987} | train loss {'Reaction outcome loss': 0.1297623859910072, 'Total loss': 0.1297623859910072}
2022-12-05 22:31:20,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:20,036 INFO:     Epoch: 84
2022-12-05 22:31:20,833 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4505756532036981, 'Total loss': 0.4505756532036981} | train loss {'Reaction outcome loss': 0.12746055073146959, 'Total loss': 0.12746055073146959}
2022-12-05 22:31:20,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:20,833 INFO:     Epoch: 85
2022-12-05 22:31:21,625 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4605425762575726, 'Total loss': 0.4605425762575726} | train loss {'Reaction outcome loss': 0.12654699068593145, 'Total loss': 0.12654699068593145}
2022-12-05 22:31:21,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:21,625 INFO:     Epoch: 86
2022-12-05 22:31:22,419 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4531806345249331, 'Total loss': 0.4531806345249331} | train loss {'Reaction outcome loss': 0.1259529431362027, 'Total loss': 0.1259529431362027}
2022-12-05 22:31:22,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:22,420 INFO:     Epoch: 87
2022-12-05 22:31:23,215 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4480444300313329, 'Total loss': 0.4480444300313329} | train loss {'Reaction outcome loss': 0.1263729695023762, 'Total loss': 0.1263729695023762}
2022-12-05 22:31:23,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:23,215 INFO:     Epoch: 88
2022-12-05 22:31:24,019 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45188605923985325, 'Total loss': 0.45188605923985325} | train loss {'Reaction outcome loss': 0.12693769759939286, 'Total loss': 0.12693769759939286}
2022-12-05 22:31:24,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:24,019 INFO:     Epoch: 89
2022-12-05 22:31:24,818 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4616559151300164, 'Total loss': 0.4616559151300164} | train loss {'Reaction outcome loss': 0.12359686110574951, 'Total loss': 0.12359686110574951}
2022-12-05 22:31:24,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:24,818 INFO:     Epoch: 90
2022-12-05 22:31:25,614 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.452188782740471, 'Total loss': 0.452188782740471} | train loss {'Reaction outcome loss': 0.124950433621344, 'Total loss': 0.124950433621344}
2022-12-05 22:31:25,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:25,614 INFO:     Epoch: 91
2022-12-05 22:31:26,413 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4429294168082781, 'Total loss': 0.4429294168082781} | train loss {'Reaction outcome loss': 0.12664213537434002, 'Total loss': 0.12664213537434002}
2022-12-05 22:31:26,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:26,413 INFO:     Epoch: 92
2022-12-05 22:31:27,207 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.450211476794509, 'Total loss': 0.450211476794509} | train loss {'Reaction outcome loss': 0.12406316404939924, 'Total loss': 0.12406316404939924}
2022-12-05 22:31:27,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:27,208 INFO:     Epoch: 93
2022-12-05 22:31:28,003 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4547519365022349, 'Total loss': 0.4547519365022349} | train loss {'Reaction outcome loss': 0.12278162476840455, 'Total loss': 0.12278162476840455}
2022-12-05 22:31:28,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:28,004 INFO:     Epoch: 94
2022-12-05 22:31:28,798 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46689108499260834, 'Total loss': 0.46689108499260834} | train loss {'Reaction outcome loss': 0.12310164371972958, 'Total loss': 0.12310164371972958}
2022-12-05 22:31:28,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:28,798 INFO:     Epoch: 95
2022-12-05 22:31:29,591 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4533745223699614, 'Total loss': 0.4533745223699614} | train loss {'Reaction outcome loss': 0.1222352701749024, 'Total loss': 0.1222352701749024}
2022-12-05 22:31:29,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:29,591 INFO:     Epoch: 96
2022-12-05 22:31:30,385 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46135568324216575, 'Total loss': 0.46135568324216575} | train loss {'Reaction outcome loss': 0.1243768223856457, 'Total loss': 0.1243768223856457}
2022-12-05 22:31:30,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:30,385 INFO:     Epoch: 97
2022-12-05 22:31:31,177 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4493117505727812, 'Total loss': 0.4493117505727812} | train loss {'Reaction outcome loss': 0.12292875082005934, 'Total loss': 0.12292875082005934}
2022-12-05 22:31:31,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:31,178 INFO:     Epoch: 98
2022-12-05 22:31:31,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46340771885805354, 'Total loss': 0.46340771885805354} | train loss {'Reaction outcome loss': 0.12390502668733214, 'Total loss': 0.12390502668733214}
2022-12-05 22:31:31,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:31,971 INFO:     Epoch: 99
2022-12-05 22:31:32,764 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4667920778657115, 'Total loss': 0.4667920778657115} | train loss {'Reaction outcome loss': 0.12224896550715092, 'Total loss': 0.12224896550715092}
2022-12-05 22:31:32,765 INFO:     Best model found after epoch 8 of 100.
2022-12-05 22:31:32,765 INFO:   Done with stage: TRAINING
2022-12-05 22:31:32,765 INFO:   Starting stage: EVALUATION
2022-12-05 22:31:32,909 INFO:   Done with stage: EVALUATION
2022-12-05 22:31:32,909 INFO:   Leaving out SEQ value Fold_3
2022-12-05 22:31:32,922 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 22:31:32,922 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:31:33,562 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:31:33,562 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:31:33,630 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:31:33,630 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:31:33,630 INFO:     No hyperparam tuning for this model
2022-12-05 22:31:33,630 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:31:33,630 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:31:33,631 INFO:     None feature selector for col prot
2022-12-05 22:31:33,631 INFO:     None feature selector for col prot
2022-12-05 22:31:33,631 INFO:     None feature selector for col prot
2022-12-05 22:31:33,632 INFO:     None feature selector for col chem
2022-12-05 22:31:33,632 INFO:     None feature selector for col chem
2022-12-05 22:31:33,632 INFO:     None feature selector for col chem
2022-12-05 22:31:33,632 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:31:33,632 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:31:33,634 INFO:     Number of params in model 215821
2022-12-05 22:31:33,637 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:31:33,637 INFO:   Starting stage: TRAINING
2022-12-05 22:31:33,697 INFO:     Val loss before train {'Reaction outcome loss': 1.0719545802404715, 'Total loss': 1.0719545802404715}
2022-12-05 22:31:33,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:33,697 INFO:     Epoch: 0
2022-12-05 22:31:34,490 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5989637056062388, 'Total loss': 0.5989637056062388} | train loss {'Reaction outcome loss': 0.7719940040337205, 'Total loss': 0.7719940040337205}
2022-12-05 22:31:34,491 INFO:     Found new best model at epoch 0
2022-12-05 22:31:34,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:34,492 INFO:     Epoch: 1
2022-12-05 22:31:35,287 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.52353324515875, 'Total loss': 0.52353324515875} | train loss {'Reaction outcome loss': 0.5206693456251434, 'Total loss': 0.5206693456251434}
2022-12-05 22:31:35,287 INFO:     Found new best model at epoch 1
2022-12-05 22:31:35,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:35,288 INFO:     Epoch: 2
2022-12-05 22:31:36,081 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48874359699182734, 'Total loss': 0.48874359699182734} | train loss {'Reaction outcome loss': 0.4546905706939383, 'Total loss': 0.4546905706939383}
2022-12-05 22:31:36,081 INFO:     Found new best model at epoch 2
2022-12-05 22:31:36,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:36,082 INFO:     Epoch: 3
2022-12-05 22:31:36,872 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.47789190986821817, 'Total loss': 0.47789190986821817} | train loss {'Reaction outcome loss': 0.416434265949108, 'Total loss': 0.416434265949108}
2022-12-05 22:31:36,872 INFO:     Found new best model at epoch 3
2022-12-05 22:31:36,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:36,873 INFO:     Epoch: 4
2022-12-05 22:31:37,666 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46888282236664797, 'Total loss': 0.46888282236664797} | train loss {'Reaction outcome loss': 0.38833606322851694, 'Total loss': 0.38833606322851694}
2022-12-05 22:31:37,666 INFO:     Found new best model at epoch 4
2022-12-05 22:31:37,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:37,667 INFO:     Epoch: 5
2022-12-05 22:31:38,461 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4472976292288581, 'Total loss': 0.4472976292288581} | train loss {'Reaction outcome loss': 0.36427007244570264, 'Total loss': 0.36427007244570264}
2022-12-05 22:31:38,461 INFO:     Found new best model at epoch 5
2022-12-05 22:31:38,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:38,462 INFO:     Epoch: 6
2022-12-05 22:31:39,260 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4597398493179055, 'Total loss': 0.4597398493179055} | train loss {'Reaction outcome loss': 0.3451600771075414, 'Total loss': 0.3451600771075414}
2022-12-05 22:31:39,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:39,260 INFO:     Epoch: 7
2022-12-05 22:31:40,060 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43447007308172625, 'Total loss': 0.43447007308172625} | train loss {'Reaction outcome loss': 0.32593548316278576, 'Total loss': 0.32593548316278576}
2022-12-05 22:31:40,060 INFO:     Found new best model at epoch 7
2022-12-05 22:31:40,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:40,061 INFO:     Epoch: 8
2022-12-05 22:31:40,856 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4512319599473199, 'Total loss': 0.4512319599473199} | train loss {'Reaction outcome loss': 0.309542530358083, 'Total loss': 0.309542530358083}
2022-12-05 22:31:40,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:40,856 INFO:     Epoch: 9
2022-12-05 22:31:41,648 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.445088870650114, 'Total loss': 0.445088870650114} | train loss {'Reaction outcome loss': 0.2980156911866655, 'Total loss': 0.2980156911866655}
2022-12-05 22:31:41,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:41,649 INFO:     Epoch: 10
2022-12-05 22:31:42,442 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43088350323743596, 'Total loss': 0.43088350323743596} | train loss {'Reaction outcome loss': 0.28311680867470834, 'Total loss': 0.28311680867470834}
2022-12-05 22:31:42,442 INFO:     Found new best model at epoch 10
2022-12-05 22:31:42,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:42,443 INFO:     Epoch: 11
2022-12-05 22:31:43,234 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4316686835399894, 'Total loss': 0.4316686835399894} | train loss {'Reaction outcome loss': 0.2733107462157438, 'Total loss': 0.2733107462157438}
2022-12-05 22:31:43,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:43,234 INFO:     Epoch: 12
2022-12-05 22:31:44,030 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.446505997416585, 'Total loss': 0.446505997416585} | train loss {'Reaction outcome loss': 0.26682958011457947, 'Total loss': 0.26682958011457947}
2022-12-05 22:31:44,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:44,030 INFO:     Epoch: 13
2022-12-05 22:31:44,826 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.433137658723565, 'Total loss': 0.433137658723565} | train loss {'Reaction outcome loss': 0.25724981041479505, 'Total loss': 0.25724981041479505}
2022-12-05 22:31:44,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:44,827 INFO:     Epoch: 14
2022-12-05 22:31:45,622 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4470289554013762, 'Total loss': 0.4470289554013762} | train loss {'Reaction outcome loss': 0.24673827303719129, 'Total loss': 0.24673827303719129}
2022-12-05 22:31:45,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:45,622 INFO:     Epoch: 15
2022-12-05 22:31:46,417 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.437536962157072, 'Total loss': 0.437536962157072} | train loss {'Reaction outcome loss': 0.239649742151852, 'Total loss': 0.239649742151852}
2022-12-05 22:31:46,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:46,417 INFO:     Epoch: 16
2022-12-05 22:31:47,209 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44333131472731746, 'Total loss': 0.44333131472731746} | train loss {'Reaction outcome loss': 0.23263236306944993, 'Total loss': 0.23263236306944993}
2022-12-05 22:31:47,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:47,209 INFO:     Epoch: 17
2022-12-05 22:31:48,002 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44565862278605617, 'Total loss': 0.44565862278605617} | train loss {'Reaction outcome loss': 0.22486745515539322, 'Total loss': 0.22486745515539322}
2022-12-05 22:31:48,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:48,002 INFO:     Epoch: 18
2022-12-05 22:31:48,796 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4465304181672806, 'Total loss': 0.4465304181672806} | train loss {'Reaction outcome loss': 0.2189073553730431, 'Total loss': 0.2189073553730431}
2022-12-05 22:31:48,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:48,796 INFO:     Epoch: 19
2022-12-05 22:31:49,588 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4533569511286048, 'Total loss': 0.4533569511286048} | train loss {'Reaction outcome loss': 0.20920438581594714, 'Total loss': 0.20920438581594714}
2022-12-05 22:31:49,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:49,588 INFO:     Epoch: 20
2022-12-05 22:31:50,382 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4472035751786343, 'Total loss': 0.4472035751786343} | train loss {'Reaction outcome loss': 0.20710210295187104, 'Total loss': 0.20710210295187104}
2022-12-05 22:31:50,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:50,382 INFO:     Epoch: 21
2022-12-05 22:31:51,174 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4530222998108975, 'Total loss': 0.4530222998108975} | train loss {'Reaction outcome loss': 0.19987648955465834, 'Total loss': 0.19987648955465834}
2022-12-05 22:31:51,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:51,174 INFO:     Epoch: 22
2022-12-05 22:31:51,966 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4595052443964537, 'Total loss': 0.4595052443964537} | train loss {'Reaction outcome loss': 0.19535300076590398, 'Total loss': 0.19535300076590398}
2022-12-05 22:31:51,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:51,966 INFO:     Epoch: 23
2022-12-05 22:31:52,756 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46082788601864216, 'Total loss': 0.46082788601864216} | train loss {'Reaction outcome loss': 0.19238466603888404, 'Total loss': 0.19238466603888404}
2022-12-05 22:31:52,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:52,756 INFO:     Epoch: 24
2022-12-05 22:31:53,549 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.470912289827369, 'Total loss': 0.470912289827369} | train loss {'Reaction outcome loss': 0.1857090815595148, 'Total loss': 0.1857090815595148}
2022-12-05 22:31:53,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:53,550 INFO:     Epoch: 25
2022-12-05 22:31:54,339 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49174692325813824, 'Total loss': 0.49174692325813824} | train loss {'Reaction outcome loss': 0.1809433858780336, 'Total loss': 0.1809433858780336}
2022-12-05 22:31:54,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:54,340 INFO:     Epoch: 26
2022-12-05 22:31:55,131 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4624697455140047, 'Total loss': 0.4624697455140047} | train loss {'Reaction outcome loss': 0.1800175957887629, 'Total loss': 0.1800175957887629}
2022-12-05 22:31:55,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:55,131 INFO:     Epoch: 27
2022-12-05 22:31:55,921 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45484921925289684, 'Total loss': 0.45484921925289684} | train loss {'Reaction outcome loss': 0.17834388768231427, 'Total loss': 0.17834388768231427}
2022-12-05 22:31:55,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:55,922 INFO:     Epoch: 28
2022-12-05 22:31:56,712 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4599679268376772, 'Total loss': 0.4599679268376772} | train loss {'Reaction outcome loss': 0.17360449858285762, 'Total loss': 0.17360449858285762}
2022-12-05 22:31:56,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:56,712 INFO:     Epoch: 29
2022-12-05 22:31:57,502 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46345229516195696, 'Total loss': 0.46345229516195696} | train loss {'Reaction outcome loss': 0.16761622492055345, 'Total loss': 0.16761622492055345}
2022-12-05 22:31:57,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:57,502 INFO:     Epoch: 30
2022-12-05 22:31:58,284 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4705099262470423, 'Total loss': 0.4705099262470423} | train loss {'Reaction outcome loss': 0.16272775275410448, 'Total loss': 0.16272775275410448}
2022-12-05 22:31:58,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:58,284 INFO:     Epoch: 31
2022-12-05 22:31:59,064 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4655082787192145, 'Total loss': 0.4655082787192145} | train loss {'Reaction outcome loss': 0.16029178561190519, 'Total loss': 0.16029178561190519}
2022-12-05 22:31:59,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:59,065 INFO:     Epoch: 32
2022-12-05 22:31:59,849 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46757994210997295, 'Total loss': 0.46757994210997295} | train loss {'Reaction outcome loss': 0.15811892741440256, 'Total loss': 0.15811892741440256}
2022-12-05 22:31:59,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:31:59,849 INFO:     Epoch: 33
2022-12-05 22:32:00,632 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5097610077192617, 'Total loss': 0.5097610077192617} | train loss {'Reaction outcome loss': 0.15691858421965146, 'Total loss': 0.15691858421965146}
2022-12-05 22:32:00,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:00,632 INFO:     Epoch: 34
2022-12-05 22:32:01,413 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4683963736129362, 'Total loss': 0.4683963736129362} | train loss {'Reaction outcome loss': 0.15886884048550462, 'Total loss': 0.15886884048550462}
2022-12-05 22:32:01,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:01,413 INFO:     Epoch: 35
2022-12-05 22:32:02,199 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4948208706323491, 'Total loss': 0.4948208706323491} | train loss {'Reaction outcome loss': 0.15416185201026897, 'Total loss': 0.15416185201026897}
2022-12-05 22:32:02,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:02,199 INFO:     Epoch: 36
2022-12-05 22:32:02,982 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48796192989792936, 'Total loss': 0.48796192989792936} | train loss {'Reaction outcome loss': 0.15180134548663848, 'Total loss': 0.15180134548663848}
2022-12-05 22:32:02,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:02,983 INFO:     Epoch: 37
2022-12-05 22:32:03,763 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47198721558548684, 'Total loss': 0.47198721558548684} | train loss {'Reaction outcome loss': 0.1500976361456967, 'Total loss': 0.1500976361456967}
2022-12-05 22:32:03,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:03,763 INFO:     Epoch: 38
2022-12-05 22:32:04,547 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.485679836467255, 'Total loss': 0.485679836467255} | train loss {'Reaction outcome loss': 0.14781376448126488, 'Total loss': 0.14781376448126488}
2022-12-05 22:32:04,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:04,547 INFO:     Epoch: 39
2022-12-05 22:32:05,333 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4769069051673246, 'Total loss': 0.4769069051673246} | train loss {'Reaction outcome loss': 0.14559274293298338, 'Total loss': 0.14559274293298338}
2022-12-05 22:32:05,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:05,335 INFO:     Epoch: 40
2022-12-05 22:32:06,115 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48876203076784003, 'Total loss': 0.48876203076784003} | train loss {'Reaction outcome loss': 0.1425175152243778, 'Total loss': 0.1425175152243778}
2022-12-05 22:32:06,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:06,116 INFO:     Epoch: 41
2022-12-05 22:32:06,901 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.497716476057851, 'Total loss': 0.497716476057851} | train loss {'Reaction outcome loss': 0.14158127619405833, 'Total loss': 0.14158127619405833}
2022-12-05 22:32:06,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:06,901 INFO:     Epoch: 42
2022-12-05 22:32:07,684 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4893829018570656, 'Total loss': 0.4893829018570656} | train loss {'Reaction outcome loss': 0.14009176587509642, 'Total loss': 0.14009176587509642}
2022-12-05 22:32:07,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:07,684 INFO:     Epoch: 43
2022-12-05 22:32:08,465 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.487652987241745, 'Total loss': 0.487652987241745} | train loss {'Reaction outcome loss': 0.14008231481169292, 'Total loss': 0.14008231481169292}
2022-12-05 22:32:08,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:08,465 INFO:     Epoch: 44
2022-12-05 22:32:09,247 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49332409057506293, 'Total loss': 0.49332409057506293} | train loss {'Reaction outcome loss': 0.13706830009020896, 'Total loss': 0.13706830009020896}
2022-12-05 22:32:09,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:09,247 INFO:     Epoch: 45
2022-12-05 22:32:10,030 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48144308425659355, 'Total loss': 0.48144308425659355} | train loss {'Reaction outcome loss': 0.13776500446055037, 'Total loss': 0.13776500446055037}
2022-12-05 22:32:10,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:10,030 INFO:     Epoch: 46
2022-12-05 22:32:10,816 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48988436405048813, 'Total loss': 0.48988436405048813} | train loss {'Reaction outcome loss': 0.13599683606514223, 'Total loss': 0.13599683606514223}
2022-12-05 22:32:10,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:10,816 INFO:     Epoch: 47
2022-12-05 22:32:11,603 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4793070805973785, 'Total loss': 0.4793070805973785} | train loss {'Reaction outcome loss': 0.13470688693746619, 'Total loss': 0.13470688693746619}
2022-12-05 22:32:11,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:11,604 INFO:     Epoch: 48
2022-12-05 22:32:12,385 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49925336103106654, 'Total loss': 0.49925336103106654} | train loss {'Reaction outcome loss': 0.13382885454092253, 'Total loss': 0.13382885454092253}
2022-12-05 22:32:12,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:12,385 INFO:     Epoch: 49
2022-12-05 22:32:13,167 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4939618831457094, 'Total loss': 0.4939618831457094} | train loss {'Reaction outcome loss': 0.1311693755035967, 'Total loss': 0.1311693755035967}
2022-12-05 22:32:13,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:13,167 INFO:     Epoch: 50
2022-12-05 22:32:13,947 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4923825586257979, 'Total loss': 0.4923825586257979} | train loss {'Reaction outcome loss': 0.130454045685905, 'Total loss': 0.130454045685905}
2022-12-05 22:32:13,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:13,947 INFO:     Epoch: 51
2022-12-05 22:32:14,732 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48728535688200664, 'Total loss': 0.48728535688200664} | train loss {'Reaction outcome loss': 0.12968578694365274, 'Total loss': 0.12968578694365274}
2022-12-05 22:32:14,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:14,732 INFO:     Epoch: 52
2022-12-05 22:32:15,513 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4874983904666679, 'Total loss': 0.4874983904666679} | train loss {'Reaction outcome loss': 0.12687906125798024, 'Total loss': 0.12687906125798024}
2022-12-05 22:32:15,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:15,513 INFO:     Epoch: 53
2022-12-05 22:32:16,293 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4905796012906141, 'Total loss': 0.4905796012906141} | train loss {'Reaction outcome loss': 0.12668933944753658, 'Total loss': 0.12668933944753658}
2022-12-05 22:32:16,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:16,293 INFO:     Epoch: 54
2022-12-05 22:32:17,072 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4935384527888409, 'Total loss': 0.4935384527888409} | train loss {'Reaction outcome loss': 0.12729368062973512, 'Total loss': 0.12729368062973512}
2022-12-05 22:32:17,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:17,072 INFO:     Epoch: 55
2022-12-05 22:32:17,849 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5069698424533357, 'Total loss': 0.5069698424533357} | train loss {'Reaction outcome loss': 0.12727303422772834, 'Total loss': 0.12727303422772834}
2022-12-05 22:32:17,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:17,849 INFO:     Epoch: 56
2022-12-05 22:32:18,626 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4886013255562893, 'Total loss': 0.4886013255562893} | train loss {'Reaction outcome loss': 0.12455422655821091, 'Total loss': 0.12455422655821091}
2022-12-05 22:32:18,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:18,627 INFO:     Epoch: 57
2022-12-05 22:32:19,406 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48523986720761586, 'Total loss': 0.48523986720761586} | train loss {'Reaction outcome loss': 0.12863168600992655, 'Total loss': 0.12863168600992655}
2022-12-05 22:32:19,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:19,407 INFO:     Epoch: 58
2022-12-05 22:32:20,184 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48001882745776064, 'Total loss': 0.48001882745776064} | train loss {'Reaction outcome loss': 0.12347223132143541, 'Total loss': 0.12347223132143541}
2022-12-05 22:32:20,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:20,184 INFO:     Epoch: 59
2022-12-05 22:32:20,964 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49198408251584963, 'Total loss': 0.49198408251584963} | train loss {'Reaction outcome loss': 0.12315695982717682, 'Total loss': 0.12315695982717682}
2022-12-05 22:32:20,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:20,965 INFO:     Epoch: 60
2022-12-05 22:32:21,741 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5041138030761896, 'Total loss': 0.5041138030761896} | train loss {'Reaction outcome loss': 0.121746763123253, 'Total loss': 0.121746763123253}
2022-12-05 22:32:21,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:21,742 INFO:     Epoch: 61
2022-12-05 22:32:22,519 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49399845371412676, 'Total loss': 0.49399845371412676} | train loss {'Reaction outcome loss': 0.12182508035344475, 'Total loss': 0.12182508035344475}
2022-12-05 22:32:22,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:22,519 INFO:     Epoch: 62
2022-12-05 22:32:23,296 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49579717565414516, 'Total loss': 0.49579717565414516} | train loss {'Reaction outcome loss': 0.11929527329809872, 'Total loss': 0.11929527329809872}
2022-12-05 22:32:23,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:23,296 INFO:     Epoch: 63
2022-12-05 22:32:24,076 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4897715023090673, 'Total loss': 0.4897715023090673} | train loss {'Reaction outcome loss': 0.12123647848059857, 'Total loss': 0.12123647848059857}
2022-12-05 22:32:24,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:24,077 INFO:     Epoch: 64
2022-12-05 22:32:24,857 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4893307363571123, 'Total loss': 0.4893307363571123} | train loss {'Reaction outcome loss': 0.12082349334617333, 'Total loss': 0.12082349334617333}
2022-12-05 22:32:24,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:24,857 INFO:     Epoch: 65
2022-12-05 22:32:25,635 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5006071911301724, 'Total loss': 0.5006071911301724} | train loss {'Reaction outcome loss': 0.11807066923076356, 'Total loss': 0.11807066923076356}
2022-12-05 22:32:25,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:25,635 INFO:     Epoch: 66
2022-12-05 22:32:26,413 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4940752816754718, 'Total loss': 0.4940752816754718} | train loss {'Reaction outcome loss': 0.12098474290083956, 'Total loss': 0.12098474290083956}
2022-12-05 22:32:26,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:26,414 INFO:     Epoch: 67
2022-12-05 22:32:27,192 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49662650601808417, 'Total loss': 0.49662650601808417} | train loss {'Reaction outcome loss': 0.11960796522812098, 'Total loss': 0.11960796522812098}
2022-12-05 22:32:27,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:27,193 INFO:     Epoch: 68
2022-12-05 22:32:27,971 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49560390551422917, 'Total loss': 0.49560390551422917} | train loss {'Reaction outcome loss': 0.11699818459879836, 'Total loss': 0.11699818459879836}
2022-12-05 22:32:27,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:27,972 INFO:     Epoch: 69
2022-12-05 22:32:28,757 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49349399326845655, 'Total loss': 0.49349399326845655} | train loss {'Reaction outcome loss': 0.11586386968722805, 'Total loss': 0.11586386968722805}
2022-12-05 22:32:28,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:28,757 INFO:     Epoch: 70
2022-12-05 22:32:29,551 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49258123476837956, 'Total loss': 0.49258123476837956} | train loss {'Reaction outcome loss': 0.11597744247458354, 'Total loss': 0.11597744247458354}
2022-12-05 22:32:29,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:29,551 INFO:     Epoch: 71
2022-12-05 22:32:30,342 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5031699378823125, 'Total loss': 0.5031699378823125} | train loss {'Reaction outcome loss': 0.11530733386000978, 'Total loss': 0.11530733386000978}
2022-12-05 22:32:30,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:30,342 INFO:     Epoch: 72
2022-12-05 22:32:31,135 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49974386290062306, 'Total loss': 0.49974386290062306} | train loss {'Reaction outcome loss': 0.11832847273352828, 'Total loss': 0.11832847273352828}
2022-12-05 22:32:31,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:31,135 INFO:     Epoch: 73
2022-12-05 22:32:31,923 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49087231970110606, 'Total loss': 0.49087231970110606} | train loss {'Reaction outcome loss': 0.1167507139877742, 'Total loss': 0.1167507139877742}
2022-12-05 22:32:31,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:31,924 INFO:     Epoch: 74
2022-12-05 22:32:32,712 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49681953254134154, 'Total loss': 0.49681953254134154} | train loss {'Reaction outcome loss': 0.11676030771599875, 'Total loss': 0.11676030771599875}
2022-12-05 22:32:32,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:32,712 INFO:     Epoch: 75
2022-12-05 22:32:33,502 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49716973616633303, 'Total loss': 0.49716973616633303} | train loss {'Reaction outcome loss': 0.11424613967844488, 'Total loss': 0.11424613967844488}
2022-12-05 22:32:33,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:33,502 INFO:     Epoch: 76
2022-12-05 22:32:34,293 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5079872220061546, 'Total loss': 0.5079872220061546} | train loss {'Reaction outcome loss': 0.11644273070779479, 'Total loss': 0.11644273070779479}
2022-12-05 22:32:34,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:34,294 INFO:     Epoch: 77
2022-12-05 22:32:35,088 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5060896142277607, 'Total loss': 0.5060896142277607} | train loss {'Reaction outcome loss': 0.1144006784484097, 'Total loss': 0.1144006784484097}
2022-12-05 22:32:35,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:35,088 INFO:     Epoch: 78
2022-12-05 22:32:35,877 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47417088095531906, 'Total loss': 0.47417088095531906} | train loss {'Reaction outcome loss': 0.11318109585777109, 'Total loss': 0.11318109585777109}
2022-12-05 22:32:35,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:35,878 INFO:     Epoch: 79
2022-12-05 22:32:36,658 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5000072464693425, 'Total loss': 0.5000072464693425} | train loss {'Reaction outcome loss': 0.11256607619991886, 'Total loss': 0.11256607619991886}
2022-12-05 22:32:36,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:36,660 INFO:     Epoch: 80
2022-12-05 22:32:37,437 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48218623912611674, 'Total loss': 0.48218623912611674} | train loss {'Reaction outcome loss': 0.11095577394858064, 'Total loss': 0.11095577394858064}
2022-12-05 22:32:37,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:37,437 INFO:     Epoch: 81
2022-12-05 22:32:38,220 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4835312316237494, 'Total loss': 0.4835312316237494} | train loss {'Reaction outcome loss': 0.1116189122230673, 'Total loss': 0.1116189122230673}
2022-12-05 22:32:38,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:38,221 INFO:     Epoch: 82
2022-12-05 22:32:39,002 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4978847905646923, 'Total loss': 0.4978847905646923} | train loss {'Reaction outcome loss': 0.1103852670256493, 'Total loss': 0.1103852670256493}
2022-12-05 22:32:39,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:39,003 INFO:     Epoch: 83
2022-12-05 22:32:39,783 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4831532312687053, 'Total loss': 0.4831532312687053} | train loss {'Reaction outcome loss': 0.11192493592561395, 'Total loss': 0.11192493592561395}
2022-12-05 22:32:39,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:39,783 INFO:     Epoch: 84
2022-12-05 22:32:40,560 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4979505649832792, 'Total loss': 0.4979505649832792} | train loss {'Reaction outcome loss': 0.1132308009958255, 'Total loss': 0.1132308009958255}
2022-12-05 22:32:40,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:40,560 INFO:     Epoch: 85
2022-12-05 22:32:41,339 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49574740750845087, 'Total loss': 0.49574740750845087} | train loss {'Reaction outcome loss': 0.11191023843661871, 'Total loss': 0.11191023843661871}
2022-12-05 22:32:41,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:41,339 INFO:     Epoch: 86
2022-12-05 22:32:42,120 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5006669886236967, 'Total loss': 0.5006669886236967} | train loss {'Reaction outcome loss': 0.11147918892878686, 'Total loss': 0.11147918892878686}
2022-12-05 22:32:42,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:42,120 INFO:     Epoch: 87
2022-12-05 22:32:42,898 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4966086731400601, 'Total loss': 0.4966086731400601} | train loss {'Reaction outcome loss': 0.11168070677897812, 'Total loss': 0.11168070677897812}
2022-12-05 22:32:42,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:42,899 INFO:     Epoch: 88
2022-12-05 22:32:43,680 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49559932046158367, 'Total loss': 0.49559932046158367} | train loss {'Reaction outcome loss': 0.10995509647170212, 'Total loss': 0.10995509647170212}
2022-12-05 22:32:43,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:43,680 INFO:     Epoch: 89
2022-12-05 22:32:44,456 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49430359484151354, 'Total loss': 0.49430359484151354} | train loss {'Reaction outcome loss': 0.11005124473108799, 'Total loss': 0.11005124473108799}
2022-12-05 22:32:44,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:44,456 INFO:     Epoch: 90
2022-12-05 22:32:45,234 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4872119062861731, 'Total loss': 0.4872119062861731} | train loss {'Reaction outcome loss': 0.11017894529480747, 'Total loss': 0.11017894529480747}
2022-12-05 22:32:45,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:45,234 INFO:     Epoch: 91
2022-12-05 22:32:46,009 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.500637372565824, 'Total loss': 0.500637372565824} | train loss {'Reaction outcome loss': 0.10673236143257883, 'Total loss': 0.10673236143257883}
2022-12-05 22:32:46,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:46,009 INFO:     Epoch: 92
2022-12-05 22:32:46,785 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5013274448209031, 'Total loss': 0.5013274448209031} | train loss {'Reaction outcome loss': 0.10789241549585765, 'Total loss': 0.10789241549585765}
2022-12-05 22:32:46,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:46,785 INFO:     Epoch: 93
2022-12-05 22:32:47,561 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48033756121646526, 'Total loss': 0.48033756121646526} | train loss {'Reaction outcome loss': 0.108939016778252, 'Total loss': 0.108939016778252}
2022-12-05 22:32:47,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:47,561 INFO:     Epoch: 94
2022-12-05 22:32:48,335 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.480722050334132, 'Total loss': 0.480722050334132} | train loss {'Reaction outcome loss': 0.10960101380698965, 'Total loss': 0.10960101380698965}
2022-12-05 22:32:48,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:48,336 INFO:     Epoch: 95
2022-12-05 22:32:49,111 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48155162362165227, 'Total loss': 0.48155162362165227} | train loss {'Reaction outcome loss': 0.11007204451004174, 'Total loss': 0.11007204451004174}
2022-12-05 22:32:49,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:49,111 INFO:     Epoch: 96
2022-12-05 22:32:49,886 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4795587520266688, 'Total loss': 0.4795587520266688} | train loss {'Reaction outcome loss': 0.1070073911146004, 'Total loss': 0.1070073911146004}
2022-12-05 22:32:49,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:49,886 INFO:     Epoch: 97
2022-12-05 22:32:50,660 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4817492469798687, 'Total loss': 0.4817492469798687} | train loss {'Reaction outcome loss': 0.10832265000637054, 'Total loss': 0.10832265000637054}
2022-12-05 22:32:50,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:50,661 INFO:     Epoch: 98
2022-12-05 22:32:51,436 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4917328503242759, 'Total loss': 0.4917328503242759} | train loss {'Reaction outcome loss': 0.10675780974527813, 'Total loss': 0.10675780974527813}
2022-12-05 22:32:51,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:51,436 INFO:     Epoch: 99
2022-12-05 22:32:52,213 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4717193450345549, 'Total loss': 0.4717193450345549} | train loss {'Reaction outcome loss': 0.10794492062457182, 'Total loss': 0.10794492062457182}
2022-12-05 22:32:52,213 INFO:     Best model found after epoch 11 of 100.
2022-12-05 22:32:52,213 INFO:   Done with stage: TRAINING
2022-12-05 22:32:52,213 INFO:   Starting stage: EVALUATION
2022-12-05 22:32:52,355 INFO:   Done with stage: EVALUATION
2022-12-05 22:32:52,355 INFO:   Leaving out SEQ value Fold_4
2022-12-05 22:32:52,368 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:32:52,368 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:32:53,008 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:32:53,009 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:32:53,078 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:32:53,078 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:32:53,078 INFO:     No hyperparam tuning for this model
2022-12-05 22:32:53,078 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:32:53,078 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:32:53,079 INFO:     None feature selector for col prot
2022-12-05 22:32:53,079 INFO:     None feature selector for col prot
2022-12-05 22:32:53,079 INFO:     None feature selector for col prot
2022-12-05 22:32:53,080 INFO:     None feature selector for col chem
2022-12-05 22:32:53,080 INFO:     None feature selector for col chem
2022-12-05 22:32:53,080 INFO:     None feature selector for col chem
2022-12-05 22:32:53,080 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:32:53,080 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:32:53,082 INFO:     Number of params in model 215821
2022-12-05 22:32:53,085 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:32:53,085 INFO:   Starting stage: TRAINING
2022-12-05 22:32:53,146 INFO:     Val loss before train {'Reaction outcome loss': 0.9774864207614552, 'Total loss': 0.9774864207614552}
2022-12-05 22:32:53,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:53,146 INFO:     Epoch: 0
2022-12-05 22:32:53,939 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5841231508688494, 'Total loss': 0.5841231508688494} | train loss {'Reaction outcome loss': 0.7925031573301361, 'Total loss': 0.7925031573301361}
2022-12-05 22:32:53,939 INFO:     Found new best model at epoch 0
2022-12-05 22:32:53,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:53,940 INFO:     Epoch: 1
2022-12-05 22:32:54,733 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4877381307834929, 'Total loss': 0.4877381307834929} | train loss {'Reaction outcome loss': 0.533755344969611, 'Total loss': 0.533755344969611}
2022-12-05 22:32:54,733 INFO:     Found new best model at epoch 1
2022-12-05 22:32:54,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:54,734 INFO:     Epoch: 2
2022-12-05 22:32:55,533 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46250267259099265, 'Total loss': 0.46250267259099265} | train loss {'Reaction outcome loss': 0.4649933887225005, 'Total loss': 0.4649933887225005}
2022-12-05 22:32:55,534 INFO:     Found new best model at epoch 2
2022-12-05 22:32:55,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:55,535 INFO:     Epoch: 3
2022-12-05 22:32:56,338 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4524483145637946, 'Total loss': 0.4524483145637946} | train loss {'Reaction outcome loss': 0.4288184943819238, 'Total loss': 0.4288184943819238}
2022-12-05 22:32:56,338 INFO:     Found new best model at epoch 3
2022-12-05 22:32:56,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:56,339 INFO:     Epoch: 4
2022-12-05 22:32:57,142 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4387573457577012, 'Total loss': 0.4387573457577012} | train loss {'Reaction outcome loss': 0.40317762156407677, 'Total loss': 0.40317762156407677}
2022-12-05 22:32:57,142 INFO:     Found new best model at epoch 4
2022-12-05 22:32:57,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:57,143 INFO:     Epoch: 5
2022-12-05 22:32:57,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.433903345330195, 'Total loss': 0.433903345330195} | train loss {'Reaction outcome loss': 0.3813218267093743, 'Total loss': 0.3813218267093743}
2022-12-05 22:32:57,952 INFO:     Found new best model at epoch 5
2022-12-05 22:32:57,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:57,953 INFO:     Epoch: 6
2022-12-05 22:32:58,758 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42718646776947106, 'Total loss': 0.42718646776947106} | train loss {'Reaction outcome loss': 0.36057263982271953, 'Total loss': 0.36057263982271953}
2022-12-05 22:32:58,759 INFO:     Found new best model at epoch 6
2022-12-05 22:32:58,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:58,760 INFO:     Epoch: 7
2022-12-05 22:32:59,572 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4222609627653252, 'Total loss': 0.4222609627653252} | train loss {'Reaction outcome loss': 0.344552316732945, 'Total loss': 0.344552316732945}
2022-12-05 22:32:59,572 INFO:     Found new best model at epoch 7
2022-12-05 22:32:59,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:32:59,573 INFO:     Epoch: 8
2022-12-05 22:33:00,386 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4267724981023507, 'Total loss': 0.4267724981023507} | train loss {'Reaction outcome loss': 0.32990404188392625, 'Total loss': 0.32990404188392625}
2022-12-05 22:33:00,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:00,387 INFO:     Epoch: 9
2022-12-05 22:33:01,193 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4248078265650706, 'Total loss': 0.4248078265650706} | train loss {'Reaction outcome loss': 0.3157206650282587, 'Total loss': 0.3157206650282587}
2022-12-05 22:33:01,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:01,193 INFO:     Epoch: 10
2022-12-05 22:33:02,001 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4206518259915439, 'Total loss': 0.4206518259915439} | train loss {'Reaction outcome loss': 0.3040011244555635, 'Total loss': 0.3040011244555635}
2022-12-05 22:33:02,001 INFO:     Found new best model at epoch 10
2022-12-05 22:33:02,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:02,002 INFO:     Epoch: 11
2022-12-05 22:33:02,806 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4304614986547015, 'Total loss': 0.4304614986547015} | train loss {'Reaction outcome loss': 0.29015561691935987, 'Total loss': 0.29015561691935987}
2022-12-05 22:33:02,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:02,807 INFO:     Epoch: 12
2022-12-05 22:33:03,605 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42661848393353546, 'Total loss': 0.42661848393353546} | train loss {'Reaction outcome loss': 0.2775991887995793, 'Total loss': 0.2775991887995793}
2022-12-05 22:33:03,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:03,605 INFO:     Epoch: 13
2022-12-05 22:33:04,406 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42520150677724317, 'Total loss': 0.42520150677724317} | train loss {'Reaction outcome loss': 0.26973666719371275, 'Total loss': 0.26973666719371275}
2022-12-05 22:33:04,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:04,406 INFO:     Epoch: 14
2022-12-05 22:33:05,206 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42706157673488965, 'Total loss': 0.42706157673488965} | train loss {'Reaction outcome loss': 0.26338750526549354, 'Total loss': 0.26338750526549354}
2022-12-05 22:33:05,206 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:05,206 INFO:     Epoch: 15
2022-12-05 22:33:06,008 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4225896295498718, 'Total loss': 0.4225896295498718} | train loss {'Reaction outcome loss': 0.2526806529701477, 'Total loss': 0.2526806529701477}
2022-12-05 22:33:06,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:06,008 INFO:     Epoch: 16
2022-12-05 22:33:06,809 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41023016009818425, 'Total loss': 0.41023016009818425} | train loss {'Reaction outcome loss': 0.2481755319261743, 'Total loss': 0.2481755319261743}
2022-12-05 22:33:06,809 INFO:     Found new best model at epoch 16
2022-12-05 22:33:06,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:06,810 INFO:     Epoch: 17
2022-12-05 22:33:07,612 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4333444813435728, 'Total loss': 0.4333444813435728} | train loss {'Reaction outcome loss': 0.23935587997097643, 'Total loss': 0.23935587997097643}
2022-12-05 22:33:07,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:07,613 INFO:     Epoch: 18
2022-12-05 22:33:08,418 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.432406116954305, 'Total loss': 0.432406116954305} | train loss {'Reaction outcome loss': 0.23217362832398183, 'Total loss': 0.23217362832398183}
2022-12-05 22:33:08,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:08,418 INFO:     Epoch: 19
2022-12-05 22:33:09,218 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42394710264422675, 'Total loss': 0.42394710264422675} | train loss {'Reaction outcome loss': 0.2258185530381818, 'Total loss': 0.2258185530381818}
2022-12-05 22:33:09,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:09,218 INFO:     Epoch: 20
2022-12-05 22:33:10,019 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4273268255320462, 'Total loss': 0.4273268255320462} | train loss {'Reaction outcome loss': 0.21893151890065882, 'Total loss': 0.21893151890065882}
2022-12-05 22:33:10,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:10,020 INFO:     Epoch: 21
2022-12-05 22:33:10,817 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4224401102824645, 'Total loss': 0.4224401102824645} | train loss {'Reaction outcome loss': 0.21507532014361314, 'Total loss': 0.21507532014361314}
2022-12-05 22:33:10,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:10,817 INFO:     Epoch: 22
2022-12-05 22:33:11,622 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4167703302069144, 'Total loss': 0.4167703302069144} | train loss {'Reaction outcome loss': 0.21246200460459916, 'Total loss': 0.21246200460459916}
2022-12-05 22:33:11,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:11,622 INFO:     Epoch: 23
2022-12-05 22:33:12,420 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42040774903514166, 'Total loss': 0.42040774903514166} | train loss {'Reaction outcome loss': 0.20501245646136662, 'Total loss': 0.20501245646136662}
2022-12-05 22:33:12,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:12,421 INFO:     Epoch: 24
2022-12-05 22:33:13,221 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4356298219751228, 'Total loss': 0.4356298219751228} | train loss {'Reaction outcome loss': 0.20109009044244885, 'Total loss': 0.20109009044244885}
2022-12-05 22:33:13,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:13,221 INFO:     Epoch: 25
2022-12-05 22:33:14,023 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41753507286987523, 'Total loss': 0.41753507286987523} | train loss {'Reaction outcome loss': 0.19676653130520735, 'Total loss': 0.19676653130520735}
2022-12-05 22:33:14,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:14,023 INFO:     Epoch: 26
2022-12-05 22:33:14,825 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4288167025555264, 'Total loss': 0.4288167025555264} | train loss {'Reaction outcome loss': 0.1940813577553678, 'Total loss': 0.1940813577553678}
2022-12-05 22:33:14,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:14,825 INFO:     Epoch: 27
2022-12-05 22:33:15,630 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40641924332488666, 'Total loss': 0.40641924332488666} | train loss {'Reaction outcome loss': 0.19183547377225854, 'Total loss': 0.19183547377225854}
2022-12-05 22:33:15,630 INFO:     Found new best model at epoch 27
2022-12-05 22:33:15,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:15,631 INFO:     Epoch: 28
2022-12-05 22:33:16,429 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41605508530681784, 'Total loss': 0.41605508530681784} | train loss {'Reaction outcome loss': 0.18669337454822757, 'Total loss': 0.18669337454822757}
2022-12-05 22:33:16,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:16,430 INFO:     Epoch: 29
2022-12-05 22:33:17,227 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4258105991916223, 'Total loss': 0.4258105991916223} | train loss {'Reaction outcome loss': 0.18465737061154458, 'Total loss': 0.18465737061154458}
2022-12-05 22:33:17,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:17,227 INFO:     Epoch: 30
2022-12-05 22:33:18,023 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42960688776590605, 'Total loss': 0.42960688776590605} | train loss {'Reaction outcome loss': 0.18275533846369194, 'Total loss': 0.18275533846369194}
2022-12-05 22:33:18,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:18,023 INFO:     Epoch: 31
2022-12-05 22:33:18,818 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43946022709662264, 'Total loss': 0.43946022709662264} | train loss {'Reaction outcome loss': 0.18029523182720428, 'Total loss': 0.18029523182720428}
2022-12-05 22:33:18,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:18,819 INFO:     Epoch: 32
2022-12-05 22:33:19,613 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4133794558319179, 'Total loss': 0.4133794558319179} | train loss {'Reaction outcome loss': 0.1808825798873459, 'Total loss': 0.1808825798873459}
2022-12-05 22:33:19,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:19,613 INFO:     Epoch: 33
2022-12-05 22:33:20,409 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4158912853083827, 'Total loss': 0.4158912853083827} | train loss {'Reaction outcome loss': 0.17490250511365313, 'Total loss': 0.17490250511365313}
2022-12-05 22:33:20,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:20,410 INFO:     Epoch: 34
2022-12-05 22:33:21,204 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42031973464922473, 'Total loss': 0.42031973464922473} | train loss {'Reaction outcome loss': 0.17427261646897083, 'Total loss': 0.17427261646897083}
2022-12-05 22:33:21,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:21,205 INFO:     Epoch: 35
2022-12-05 22:33:21,998 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.426438626579263, 'Total loss': 0.426438626579263} | train loss {'Reaction outcome loss': 0.17034657446727638, 'Total loss': 0.17034657446727638}
2022-12-05 22:33:21,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:21,999 INFO:     Epoch: 36
2022-12-05 22:33:22,792 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42542061887004157, 'Total loss': 0.42542061887004157} | train loss {'Reaction outcome loss': 0.16751689955802454, 'Total loss': 0.16751689955802454}
2022-12-05 22:33:22,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:22,793 INFO:     Epoch: 37
2022-12-05 22:33:23,585 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4234829902310263, 'Total loss': 0.4234829902310263} | train loss {'Reaction outcome loss': 0.16407355743520444, 'Total loss': 0.16407355743520444}
2022-12-05 22:33:23,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:23,585 INFO:     Epoch: 38
2022-12-05 22:33:24,379 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42813331075012684, 'Total loss': 0.42813331075012684} | train loss {'Reaction outcome loss': 0.16638326141682844, 'Total loss': 0.16638326141682844}
2022-12-05 22:33:24,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:24,380 INFO:     Epoch: 39
2022-12-05 22:33:25,176 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4207442609423941, 'Total loss': 0.4207442609423941} | train loss {'Reaction outcome loss': 0.16324601622839127, 'Total loss': 0.16324601622839127}
2022-12-05 22:33:25,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:25,176 INFO:     Epoch: 40
2022-12-05 22:33:25,973 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44189175963401794, 'Total loss': 0.44189175963401794} | train loss {'Reaction outcome loss': 0.15816215707379724, 'Total loss': 0.15816215707379724}
2022-12-05 22:33:25,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:25,973 INFO:     Epoch: 41
2022-12-05 22:33:26,767 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4369143278084018, 'Total loss': 0.4369143278084018} | train loss {'Reaction outcome loss': 0.16035034415882923, 'Total loss': 0.16035034415882923}
2022-12-05 22:33:26,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:26,767 INFO:     Epoch: 42
2022-12-05 22:33:27,561 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4235941083593802, 'Total loss': 0.4235941083593802} | train loss {'Reaction outcome loss': 0.15928379646802862, 'Total loss': 0.15928379646802862}
2022-12-05 22:33:27,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:27,561 INFO:     Epoch: 43
2022-12-05 22:33:28,356 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4355234114283865, 'Total loss': 0.4355234114283865} | train loss {'Reaction outcome loss': 0.15832417499604484, 'Total loss': 0.15832417499604484}
2022-12-05 22:33:28,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:28,356 INFO:     Epoch: 44
2022-12-05 22:33:29,150 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.431972839276899, 'Total loss': 0.431972839276899} | train loss {'Reaction outcome loss': 0.15739928469842962, 'Total loss': 0.15739928469842962}
2022-12-05 22:33:29,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:29,150 INFO:     Epoch: 45
2022-12-05 22:33:29,944 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4389756511558186, 'Total loss': 0.4389756511558186} | train loss {'Reaction outcome loss': 0.1557263891332813, 'Total loss': 0.1557263891332813}
2022-12-05 22:33:29,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:29,944 INFO:     Epoch: 46
2022-12-05 22:33:30,741 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44856174832040613, 'Total loss': 0.44856174832040613} | train loss {'Reaction outcome loss': 0.15368263907880791, 'Total loss': 0.15368263907880791}
2022-12-05 22:33:30,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:30,741 INFO:     Epoch: 47
2022-12-05 22:33:31,538 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42165285044095735, 'Total loss': 0.42165285044095735} | train loss {'Reaction outcome loss': 0.15065887074677214, 'Total loss': 0.15065887074677214}
2022-12-05 22:33:31,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:31,538 INFO:     Epoch: 48
2022-12-05 22:33:32,332 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44046863744204695, 'Total loss': 0.44046863744204695} | train loss {'Reaction outcome loss': 0.14976034233827265, 'Total loss': 0.14976034233827265}
2022-12-05 22:33:32,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:32,333 INFO:     Epoch: 49
2022-12-05 22:33:33,130 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43467303094538773, 'Total loss': 0.43467303094538773} | train loss {'Reaction outcome loss': 0.15456460025762359, 'Total loss': 0.15456460025762359}
2022-12-05 22:33:33,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:33,130 INFO:     Epoch: 50
2022-12-05 22:33:33,927 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45405552722513676, 'Total loss': 0.45405552722513676} | train loss {'Reaction outcome loss': 0.14661538510042574, 'Total loss': 0.14661538510042574}
2022-12-05 22:33:33,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:33,927 INFO:     Epoch: 51
2022-12-05 22:33:34,721 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4294371107085185, 'Total loss': 0.4294371107085185} | train loss {'Reaction outcome loss': 0.14784301923317533, 'Total loss': 0.14784301923317533}
2022-12-05 22:33:34,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:34,721 INFO:     Epoch: 52
2022-12-05 22:33:35,514 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43876074864105746, 'Total loss': 0.43876074864105746} | train loss {'Reaction outcome loss': 0.14771913520751462, 'Total loss': 0.14771913520751462}
2022-12-05 22:33:35,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:35,515 INFO:     Epoch: 53
2022-12-05 22:33:36,312 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.438327511603182, 'Total loss': 0.438327511603182} | train loss {'Reaction outcome loss': 0.14699765008633897, 'Total loss': 0.14699765008633897}
2022-12-05 22:33:36,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:36,313 INFO:     Epoch: 54
2022-12-05 22:33:37,106 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.445595625618642, 'Total loss': 0.445595625618642} | train loss {'Reaction outcome loss': 0.14458507251354955, 'Total loss': 0.14458507251354955}
2022-12-05 22:33:37,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:37,107 INFO:     Epoch: 55
2022-12-05 22:33:37,904 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44475084594027564, 'Total loss': 0.44475084594027564} | train loss {'Reaction outcome loss': 0.14498264579883507, 'Total loss': 0.14498264579883507}
2022-12-05 22:33:37,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:37,905 INFO:     Epoch: 56
2022-12-05 22:33:38,702 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43378390761261637, 'Total loss': 0.43378390761261637} | train loss {'Reaction outcome loss': 0.1431924818804668, 'Total loss': 0.1431924818804668}
2022-12-05 22:33:38,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:38,703 INFO:     Epoch: 57
2022-12-05 22:33:39,503 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4440337566828186, 'Total loss': 0.4440337566828186} | train loss {'Reaction outcome loss': 0.14158644993609237, 'Total loss': 0.14158644993609237}
2022-12-05 22:33:39,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:39,504 INFO:     Epoch: 58
2022-12-05 22:33:40,298 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4330060180615295, 'Total loss': 0.4330060180615295} | train loss {'Reaction outcome loss': 0.14189976525883521, 'Total loss': 0.14189976525883521}
2022-12-05 22:33:40,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:40,299 INFO:     Epoch: 59
2022-12-05 22:33:41,093 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4291489796543663, 'Total loss': 0.4291489796543663} | train loss {'Reaction outcome loss': 0.13969429359290628, 'Total loss': 0.13969429359290628}
2022-12-05 22:33:41,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:41,093 INFO:     Epoch: 60
2022-12-05 22:33:41,888 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44437667998400604, 'Total loss': 0.44437667998400604} | train loss {'Reaction outcome loss': 0.14439014479472873, 'Total loss': 0.14439014479472873}
2022-12-05 22:33:41,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:41,889 INFO:     Epoch: 61
2022-12-05 22:33:42,683 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4318095306781205, 'Total loss': 0.4318095306781205} | train loss {'Reaction outcome loss': 0.13817413296220044, 'Total loss': 0.13817413296220044}
2022-12-05 22:33:42,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:42,683 INFO:     Epoch: 62
2022-12-05 22:33:43,477 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42486708001656964, 'Total loss': 0.42486708001656964} | train loss {'Reaction outcome loss': 0.14067486112546776, 'Total loss': 0.14067486112546776}
2022-12-05 22:33:43,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:43,477 INFO:     Epoch: 63
2022-12-05 22:33:44,270 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44514117957177485, 'Total loss': 0.44514117957177485} | train loss {'Reaction outcome loss': 0.13842181895949668, 'Total loss': 0.13842181895949668}
2022-12-05 22:33:44,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:44,271 INFO:     Epoch: 64
2022-12-05 22:33:45,065 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4400307055224072, 'Total loss': 0.4400307055224072} | train loss {'Reaction outcome loss': 0.1391480493982653, 'Total loss': 0.1391480493982653}
2022-12-05 22:33:45,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:45,066 INFO:     Epoch: 65
2022-12-05 22:33:45,860 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4371495802294124, 'Total loss': 0.4371495802294124} | train loss {'Reaction outcome loss': 0.14022632468972476, 'Total loss': 0.14022632468972476}
2022-12-05 22:33:45,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:45,860 INFO:     Epoch: 66
2022-12-05 22:33:46,655 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43086363578384573, 'Total loss': 0.43086363578384573} | train loss {'Reaction outcome loss': 0.13829761297411977, 'Total loss': 0.13829761297411977}
2022-12-05 22:33:46,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:46,655 INFO:     Epoch: 67
2022-12-05 22:33:47,448 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42044894803654065, 'Total loss': 0.42044894803654065} | train loss {'Reaction outcome loss': 0.13787110843845912, 'Total loss': 0.13787110843845912}
2022-12-05 22:33:47,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:47,449 INFO:     Epoch: 68
2022-12-05 22:33:48,248 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4377978569404645, 'Total loss': 0.4377978569404645} | train loss {'Reaction outcome loss': 0.13263705794158723, 'Total loss': 0.13263705794158723}
2022-12-05 22:33:48,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:48,248 INFO:     Epoch: 69
2022-12-05 22:33:49,044 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42663815515962517, 'Total loss': 0.42663815515962517} | train loss {'Reaction outcome loss': 0.13639831363839366, 'Total loss': 0.13639831363839366}
2022-12-05 22:33:49,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:49,044 INFO:     Epoch: 70
2022-12-05 22:33:49,839 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4427340291440487, 'Total loss': 0.4427340291440487} | train loss {'Reaction outcome loss': 0.13501314824116567, 'Total loss': 0.13501314824116567}
2022-12-05 22:33:49,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:49,839 INFO:     Epoch: 71
2022-12-05 22:33:50,636 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4255730665542863, 'Total loss': 0.4255730665542863} | train loss {'Reaction outcome loss': 0.13549935674264788, 'Total loss': 0.13549935674264788}
2022-12-05 22:33:50,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:50,636 INFO:     Epoch: 72
2022-12-05 22:33:51,429 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43436315249313007, 'Total loss': 0.43436315249313007} | train loss {'Reaction outcome loss': 0.1324921395524495, 'Total loss': 0.1324921395524495}
2022-12-05 22:33:51,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:51,429 INFO:     Epoch: 73
2022-12-05 22:33:52,223 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4390410167927092, 'Total loss': 0.4390410167927092} | train loss {'Reaction outcome loss': 0.13413708401288116, 'Total loss': 0.13413708401288116}
2022-12-05 22:33:52,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:52,223 INFO:     Epoch: 74
2022-12-05 22:33:53,017 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43670738403770054, 'Total loss': 0.43670738403770054} | train loss {'Reaction outcome loss': 0.13248292048041138, 'Total loss': 0.13248292048041138}
2022-12-05 22:33:53,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:53,017 INFO:     Epoch: 75
2022-12-05 22:33:53,812 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4320767701349475, 'Total loss': 0.4320767701349475} | train loss {'Reaction outcome loss': 0.13697693374143133, 'Total loss': 0.13697693374143133}
2022-12-05 22:33:53,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:53,813 INFO:     Epoch: 76
2022-12-05 22:33:54,609 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4388783736662431, 'Total loss': 0.4388783736662431} | train loss {'Reaction outcome loss': 0.1312847273957525, 'Total loss': 0.1312847273957525}
2022-12-05 22:33:54,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:54,609 INFO:     Epoch: 77
2022-12-05 22:33:55,405 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4341899413954128, 'Total loss': 0.4341899413954128} | train loss {'Reaction outcome loss': 0.13327302359750554, 'Total loss': 0.13327302359750554}
2022-12-05 22:33:55,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:55,405 INFO:     Epoch: 78
2022-12-05 22:33:56,204 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44626690684394404, 'Total loss': 0.44626690684394404} | train loss {'Reaction outcome loss': 0.13068872250075783, 'Total loss': 0.13068872250075783}
2022-12-05 22:33:56,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:56,204 INFO:     Epoch: 79
2022-12-05 22:33:57,002 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4334812489422885, 'Total loss': 0.4334812489422885} | train loss {'Reaction outcome loss': 0.12892947699348892, 'Total loss': 0.12892947699348892}
2022-12-05 22:33:57,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:57,002 INFO:     Epoch: 80
2022-12-05 22:33:57,804 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43573278645900165, 'Total loss': 0.43573278645900165} | train loss {'Reaction outcome loss': 0.13116944171187858, 'Total loss': 0.13116944171187858}
2022-12-05 22:33:57,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:57,805 INFO:     Epoch: 81
2022-12-05 22:33:58,606 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4422195858576081, 'Total loss': 0.4422195858576081} | train loss {'Reaction outcome loss': 0.1285464005289419, 'Total loss': 0.1285464005289419}
2022-12-05 22:33:58,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:58,606 INFO:     Epoch: 82
2022-12-05 22:33:59,404 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4236401099372994, 'Total loss': 0.4236401099372994} | train loss {'Reaction outcome loss': 0.13045139557066104, 'Total loss': 0.13045139557066104}
2022-12-05 22:33:59,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:33:59,405 INFO:     Epoch: 83
2022-12-05 22:34:00,205 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42337956550446426, 'Total loss': 0.42337956550446426} | train loss {'Reaction outcome loss': 0.12753155842168076, 'Total loss': 0.12753155842168076}
2022-12-05 22:34:00,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:00,205 INFO:     Epoch: 84
2022-12-05 22:34:01,001 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44036213562569837, 'Total loss': 0.44036213562569837} | train loss {'Reaction outcome loss': 0.1260448343443474, 'Total loss': 0.1260448343443474}
2022-12-05 22:34:01,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:01,002 INFO:     Epoch: 85
2022-12-05 22:34:01,797 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44482801854610443, 'Total loss': 0.44482801854610443} | train loss {'Reaction outcome loss': 0.12899422431514868, 'Total loss': 0.12899422431514868}
2022-12-05 22:34:01,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:01,797 INFO:     Epoch: 86
2022-12-05 22:34:02,594 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.430071218108589, 'Total loss': 0.430071218108589} | train loss {'Reaction outcome loss': 0.1281570429883657, 'Total loss': 0.1281570429883657}
2022-12-05 22:34:02,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:02,594 INFO:     Epoch: 87
2022-12-05 22:34:03,389 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43663307397880335, 'Total loss': 0.43663307397880335} | train loss {'Reaction outcome loss': 0.12572739999966637, 'Total loss': 0.12572739999966637}
2022-12-05 22:34:03,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:03,389 INFO:     Epoch: 88
2022-12-05 22:34:04,185 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4360934075984088, 'Total loss': 0.4360934075984088} | train loss {'Reaction outcome loss': 0.1270091922976257, 'Total loss': 0.1270091922976257}
2022-12-05 22:34:04,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:04,185 INFO:     Epoch: 89
2022-12-05 22:34:04,981 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4413873441517353, 'Total loss': 0.4413873441517353} | train loss {'Reaction outcome loss': 0.1259757303294816, 'Total loss': 0.1259757303294816}
2022-12-05 22:34:04,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:04,981 INFO:     Epoch: 90
2022-12-05 22:34:05,778 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4236631630496545, 'Total loss': 0.4236631630496545} | train loss {'Reaction outcome loss': 0.12727636666292505, 'Total loss': 0.12727636666292505}
2022-12-05 22:34:05,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:05,778 INFO:     Epoch: 91
2022-12-05 22:34:06,573 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4380875331434337, 'Total loss': 0.4380875331434337} | train loss {'Reaction outcome loss': 0.12303671830393854, 'Total loss': 0.12303671830393854}
2022-12-05 22:34:06,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:06,573 INFO:     Epoch: 92
2022-12-05 22:34:07,368 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42879944057627156, 'Total loss': 0.42879944057627156} | train loss {'Reaction outcome loss': 0.12406956944464435, 'Total loss': 0.12406956944464435}
2022-12-05 22:34:07,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:07,369 INFO:     Epoch: 93
2022-12-05 22:34:08,165 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43075665391304274, 'Total loss': 0.43075665391304274} | train loss {'Reaction outcome loss': 0.12223411662008372, 'Total loss': 0.12223411662008372}
2022-12-05 22:34:08,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:08,165 INFO:     Epoch: 94
2022-12-05 22:34:08,961 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43421921506524086, 'Total loss': 0.43421921506524086} | train loss {'Reaction outcome loss': 0.1225363620286507, 'Total loss': 0.1225363620286507}
2022-12-05 22:34:08,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:08,961 INFO:     Epoch: 95
2022-12-05 22:34:09,756 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4302587529475039, 'Total loss': 0.4302587529475039} | train loss {'Reaction outcome loss': 0.12083262581783798, 'Total loss': 0.12083262581783798}
2022-12-05 22:34:09,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:09,757 INFO:     Epoch: 96
2022-12-05 22:34:10,554 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4548850547183644, 'Total loss': 0.4548850547183644} | train loss {'Reaction outcome loss': 0.12477887847701148, 'Total loss': 0.12477887847701148}
2022-12-05 22:34:10,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:10,554 INFO:     Epoch: 97
2022-12-05 22:34:11,346 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4439795349131931, 'Total loss': 0.4439795349131931} | train loss {'Reaction outcome loss': 0.12417511534201162, 'Total loss': 0.12417511534201162}
2022-12-05 22:34:11,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:11,346 INFO:     Epoch: 98
2022-12-05 22:34:12,141 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44536608694629237, 'Total loss': 0.44536608694629237} | train loss {'Reaction outcome loss': 0.12418321055179883, 'Total loss': 0.12418321055179883}
2022-12-05 22:34:12,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:12,141 INFO:     Epoch: 99
2022-12-05 22:34:12,934 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4356865105642514, 'Total loss': 0.4356865105642514} | train loss {'Reaction outcome loss': 0.12014819142378626, 'Total loss': 0.12014819142378626}
2022-12-05 22:34:12,934 INFO:     Best model found after epoch 28 of 100.
2022-12-05 22:34:12,934 INFO:   Done with stage: TRAINING
2022-12-05 22:34:12,934 INFO:   Starting stage: EVALUATION
2022-12-05 22:34:13,054 INFO:   Done with stage: EVALUATION
2022-12-05 22:34:13,054 INFO:   Leaving out SEQ value Fold_5
2022-12-05 22:34:13,067 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:34:13,067 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:34:13,705 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:34:13,705 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:34:13,774 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:34:13,774 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:34:13,774 INFO:     No hyperparam tuning for this model
2022-12-05 22:34:13,774 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:34:13,774 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:34:13,775 INFO:     None feature selector for col prot
2022-12-05 22:34:13,775 INFO:     None feature selector for col prot
2022-12-05 22:34:13,775 INFO:     None feature selector for col prot
2022-12-05 22:34:13,776 INFO:     None feature selector for col chem
2022-12-05 22:34:13,776 INFO:     None feature selector for col chem
2022-12-05 22:34:13,776 INFO:     None feature selector for col chem
2022-12-05 22:34:13,776 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:34:13,776 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:34:13,778 INFO:     Number of params in model 215821
2022-12-05 22:34:13,781 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:34:13,781 INFO:   Starting stage: TRAINING
2022-12-05 22:34:13,841 INFO:     Val loss before train {'Reaction outcome loss': 1.0548276901245117, 'Total loss': 1.0548276901245117}
2022-12-05 22:34:13,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:13,841 INFO:     Epoch: 0
2022-12-05 22:34:14,628 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6320389387282458, 'Total loss': 0.6320389387282458} | train loss {'Reaction outcome loss': 0.7847444817727925, 'Total loss': 0.7847444817727925}
2022-12-05 22:34:14,628 INFO:     Found new best model at epoch 0
2022-12-05 22:34:14,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:14,629 INFO:     Epoch: 1
2022-12-05 22:34:15,411 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5431947765702551, 'Total loss': 0.5431947765702551} | train loss {'Reaction outcome loss': 0.5357128774025002, 'Total loss': 0.5357128774025002}
2022-12-05 22:34:15,411 INFO:     Found new best model at epoch 1
2022-12-05 22:34:15,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:15,412 INFO:     Epoch: 2
2022-12-05 22:34:16,203 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5086006623777476, 'Total loss': 0.5086006623777476} | train loss {'Reaction outcome loss': 0.46633472010797383, 'Total loss': 0.46633472010797383}
2022-12-05 22:34:16,204 INFO:     Found new best model at epoch 2
2022-12-05 22:34:16,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:16,205 INFO:     Epoch: 3
2022-12-05 22:34:16,989 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49464057284322654, 'Total loss': 0.49464057284322654} | train loss {'Reaction outcome loss': 0.4245528980785487, 'Total loss': 0.4245528980785487}
2022-12-05 22:34:16,990 INFO:     Found new best model at epoch 3
2022-12-05 22:34:16,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:16,990 INFO:     Epoch: 4
2022-12-05 22:34:17,776 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4678927036848935, 'Total loss': 0.4678927036848935} | train loss {'Reaction outcome loss': 0.3959776600708767, 'Total loss': 0.3959776600708767}
2022-12-05 22:34:17,777 INFO:     Found new best model at epoch 4
2022-12-05 22:34:17,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:17,778 INFO:     Epoch: 5
2022-12-05 22:34:18,566 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46233087845823984, 'Total loss': 0.46233087845823984} | train loss {'Reaction outcome loss': 0.3723899494324412, 'Total loss': 0.3723899494324412}
2022-12-05 22:34:18,566 INFO:     Found new best model at epoch 5
2022-12-05 22:34:18,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:18,567 INFO:     Epoch: 6
2022-12-05 22:34:19,354 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4613411961631341, 'Total loss': 0.4613411961631341} | train loss {'Reaction outcome loss': 0.3501503108411419, 'Total loss': 0.3501503108411419}
2022-12-05 22:34:19,354 INFO:     Found new best model at epoch 6
2022-12-05 22:34:19,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:19,355 INFO:     Epoch: 7
2022-12-05 22:34:20,138 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47274522415616294, 'Total loss': 0.47274522415616294} | train loss {'Reaction outcome loss': 0.33422163855664583, 'Total loss': 0.33422163855664583}
2022-12-05 22:34:20,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:20,138 INFO:     Epoch: 8
2022-12-05 22:34:20,925 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4622329883277416, 'Total loss': 0.4622329883277416} | train loss {'Reaction outcome loss': 0.31539075423260127, 'Total loss': 0.31539075423260127}
2022-12-05 22:34:20,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:20,925 INFO:     Epoch: 9
2022-12-05 22:34:21,712 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45114660381593485, 'Total loss': 0.45114660381593485} | train loss {'Reaction outcome loss': 0.3031658508643812, 'Total loss': 0.3031658508643812}
2022-12-05 22:34:21,712 INFO:     Found new best model at epoch 9
2022-12-05 22:34:21,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:21,713 INFO:     Epoch: 10
2022-12-05 22:34:22,506 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44182118807326665, 'Total loss': 0.44182118807326665} | train loss {'Reaction outcome loss': 0.28897573774566454, 'Total loss': 0.28897573774566454}
2022-12-05 22:34:22,506 INFO:     Found new best model at epoch 10
2022-12-05 22:34:22,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:22,507 INFO:     Epoch: 11
2022-12-05 22:34:23,290 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.439364186742089, 'Total loss': 0.439364186742089} | train loss {'Reaction outcome loss': 0.2773016896783089, 'Total loss': 0.2773016896783089}
2022-12-05 22:34:23,290 INFO:     Found new best model at epoch 11
2022-12-05 22:34:23,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:23,291 INFO:     Epoch: 12
2022-12-05 22:34:24,074 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4421250552616336, 'Total loss': 0.4421250552616336} | train loss {'Reaction outcome loss': 0.2664185688659853, 'Total loss': 0.2664185688659853}
2022-12-05 22:34:24,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:24,075 INFO:     Epoch: 13
2022-12-05 22:34:24,862 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4388454040639441, 'Total loss': 0.4388454040639441} | train loss {'Reaction outcome loss': 0.25454198286241414, 'Total loss': 0.25454198286241414}
2022-12-05 22:34:24,862 INFO:     Found new best model at epoch 13
2022-12-05 22:34:24,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:24,863 INFO:     Epoch: 14
2022-12-05 22:34:25,649 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4314156706360253, 'Total loss': 0.4314156706360253} | train loss {'Reaction outcome loss': 0.24614839719570414, 'Total loss': 0.24614839719570414}
2022-12-05 22:34:25,649 INFO:     Found new best model at epoch 14
2022-12-05 22:34:25,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:25,650 INFO:     Epoch: 15
2022-12-05 22:34:26,439 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4336077064614404, 'Total loss': 0.4336077064614404} | train loss {'Reaction outcome loss': 0.23990982672845831, 'Total loss': 0.23990982672845831}
2022-12-05 22:34:26,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:26,440 INFO:     Epoch: 16
2022-12-05 22:34:27,231 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46491659635847266, 'Total loss': 0.46491659635847266} | train loss {'Reaction outcome loss': 0.22928769144476677, 'Total loss': 0.22928769144476677}
2022-12-05 22:34:27,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:27,231 INFO:     Epoch: 17
2022-12-05 22:34:28,019 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44026021896438167, 'Total loss': 0.44026021896438167} | train loss {'Reaction outcome loss': 0.2229643166065216, 'Total loss': 0.2229643166065216}
2022-12-05 22:34:28,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:28,019 INFO:     Epoch: 18
2022-12-05 22:34:28,804 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4249651608141986, 'Total loss': 0.4249651608141986} | train loss {'Reaction outcome loss': 0.21714662266324977, 'Total loss': 0.21714662266324977}
2022-12-05 22:34:28,805 INFO:     Found new best model at epoch 18
2022-12-05 22:34:28,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:28,806 INFO:     Epoch: 19
2022-12-05 22:34:29,591 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43514426391233096, 'Total loss': 0.43514426391233096} | train loss {'Reaction outcome loss': 0.21119048619756894, 'Total loss': 0.21119048619756894}
2022-12-05 22:34:29,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:29,591 INFO:     Epoch: 20
2022-12-05 22:34:30,379 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43874648670581257, 'Total loss': 0.43874648670581257} | train loss {'Reaction outcome loss': 0.2002550173778923, 'Total loss': 0.2002550173778923}
2022-12-05 22:34:30,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:30,380 INFO:     Epoch: 21
2022-12-05 22:34:31,163 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4446603859012777, 'Total loss': 0.4446603859012777} | train loss {'Reaction outcome loss': 0.20017605630718932, 'Total loss': 0.20017605630718932}
2022-12-05 22:34:31,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:31,164 INFO:     Epoch: 22
2022-12-05 22:34:31,949 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4381789785217155, 'Total loss': 0.4381789785217155} | train loss {'Reaction outcome loss': 0.19704620999341108, 'Total loss': 0.19704620999341108}
2022-12-05 22:34:31,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:31,950 INFO:     Epoch: 23
2022-12-05 22:34:32,734 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4434539482674815, 'Total loss': 0.4434539482674815} | train loss {'Reaction outcome loss': 0.19005721514018215, 'Total loss': 0.19005721514018215}
2022-12-05 22:34:32,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:32,734 INFO:     Epoch: 24
2022-12-05 22:34:33,519 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4730548005212437, 'Total loss': 0.4730548005212437} | train loss {'Reaction outcome loss': 0.1870197452452718, 'Total loss': 0.1870197452452718}
2022-12-05 22:34:33,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:33,519 INFO:     Epoch: 25
2022-12-05 22:34:34,305 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4564917717467655, 'Total loss': 0.4564917717467655} | train loss {'Reaction outcome loss': 0.18176040432358884, 'Total loss': 0.18176040432358884}
2022-12-05 22:34:34,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:34,306 INFO:     Epoch: 26
2022-12-05 22:34:35,089 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4620401520620693, 'Total loss': 0.4620401520620693} | train loss {'Reaction outcome loss': 0.1780325010646971, 'Total loss': 0.1780325010646971}
2022-12-05 22:34:35,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:35,089 INFO:     Epoch: 27
2022-12-05 22:34:35,872 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4601448754018003, 'Total loss': 0.4601448754018003} | train loss {'Reaction outcome loss': 0.17474843274269786, 'Total loss': 0.17474843274269786}
2022-12-05 22:34:35,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:35,872 INFO:     Epoch: 28
2022-12-05 22:34:36,655 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4589366750283675, 'Total loss': 0.4589366750283675} | train loss {'Reaction outcome loss': 0.17313906437888438, 'Total loss': 0.17313906437888438}
2022-12-05 22:34:36,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:36,656 INFO:     Epoch: 29
2022-12-05 22:34:37,441 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44915098358284344, 'Total loss': 0.44915098358284344} | train loss {'Reaction outcome loss': 0.16659415403799135, 'Total loss': 0.16659415403799135}
2022-12-05 22:34:37,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:37,441 INFO:     Epoch: 30
2022-12-05 22:34:38,227 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.452224258502776, 'Total loss': 0.452224258502776} | train loss {'Reaction outcome loss': 0.16622886905560688, 'Total loss': 0.16622886905560688}
2022-12-05 22:34:38,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:38,228 INFO:     Epoch: 31
2022-12-05 22:34:39,014 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4599959928203713, 'Total loss': 0.4599959928203713} | train loss {'Reaction outcome loss': 0.16296631163176226, 'Total loss': 0.16296631163176226}
2022-12-05 22:34:39,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:39,014 INFO:     Epoch: 32
2022-12-05 22:34:39,799 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.445723580877794, 'Total loss': 0.445723580877794} | train loss {'Reaction outcome loss': 0.1601237959057397, 'Total loss': 0.1601237959057397}
2022-12-05 22:34:39,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:39,799 INFO:     Epoch: 33
2022-12-05 22:34:40,584 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4642199963669885, 'Total loss': 0.4642199963669885} | train loss {'Reaction outcome loss': 0.1611053608966117, 'Total loss': 0.1611053608966117}
2022-12-05 22:34:40,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:40,585 INFO:     Epoch: 34
2022-12-05 22:34:41,373 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48367828130722046, 'Total loss': 0.48367828130722046} | train loss {'Reaction outcome loss': 0.15525330623649822, 'Total loss': 0.15525330623649822}
2022-12-05 22:34:41,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:41,373 INFO:     Epoch: 35
2022-12-05 22:34:42,157 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4615423266183246, 'Total loss': 0.4615423266183246} | train loss {'Reaction outcome loss': 0.15585468467705105, 'Total loss': 0.15585468467705105}
2022-12-05 22:34:42,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:42,158 INFO:     Epoch: 36
2022-12-05 22:34:42,943 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46519943834705785, 'Total loss': 0.46519943834705785} | train loss {'Reaction outcome loss': 0.1545392546954812, 'Total loss': 0.1545392546954812}
2022-12-05 22:34:42,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:42,943 INFO:     Epoch: 37
2022-12-05 22:34:43,727 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4553454499691725, 'Total loss': 0.4553454499691725} | train loss {'Reaction outcome loss': 0.15284189584151822, 'Total loss': 0.15284189584151822}
2022-12-05 22:34:43,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:43,727 INFO:     Epoch: 38
2022-12-05 22:34:44,514 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4655054836449298, 'Total loss': 0.4655054836449298} | train loss {'Reaction outcome loss': 0.14955830955687835, 'Total loss': 0.14955830955687835}
2022-12-05 22:34:44,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:44,514 INFO:     Epoch: 39
2022-12-05 22:34:45,301 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44635814462195744, 'Total loss': 0.44635814462195744} | train loss {'Reaction outcome loss': 0.14811463778724476, 'Total loss': 0.14811463778724476}
2022-12-05 22:34:45,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:45,301 INFO:     Epoch: 40
2022-12-05 22:34:46,091 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4600392475046895, 'Total loss': 0.4600392475046895} | train loss {'Reaction outcome loss': 0.14483166980956283, 'Total loss': 0.14483166980956283}
2022-12-05 22:34:46,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:46,091 INFO:     Epoch: 41
2022-12-05 22:34:46,880 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4602948736230081, 'Total loss': 0.4602948736230081} | train loss {'Reaction outcome loss': 0.14475638551675543, 'Total loss': 0.14475638551675543}
2022-12-05 22:34:46,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:46,881 INFO:     Epoch: 42
2022-12-05 22:34:47,668 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48220300064845517, 'Total loss': 0.48220300064845517} | train loss {'Reaction outcome loss': 0.14033881471473345, 'Total loss': 0.14033881471473345}
2022-12-05 22:34:47,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:47,669 INFO:     Epoch: 43
2022-12-05 22:34:48,455 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49083757027983665, 'Total loss': 0.49083757027983665} | train loss {'Reaction outcome loss': 0.14049799013502745, 'Total loss': 0.14049799013502745}
2022-12-05 22:34:48,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:48,455 INFO:     Epoch: 44
2022-12-05 22:34:49,245 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4893358779901808, 'Total loss': 0.4893358779901808} | train loss {'Reaction outcome loss': 0.1399698450553174, 'Total loss': 0.1399698450553174}
2022-12-05 22:34:49,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:49,246 INFO:     Epoch: 45
2022-12-05 22:34:50,032 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4654294892468236, 'Total loss': 0.4654294892468236} | train loss {'Reaction outcome loss': 0.13757341517401592, 'Total loss': 0.13757341517401592}
2022-12-05 22:34:50,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:50,032 INFO:     Epoch: 46
2022-12-05 22:34:50,817 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4595677994868972, 'Total loss': 0.4595677994868972} | train loss {'Reaction outcome loss': 0.13901818995268977, 'Total loss': 0.13901818995268977}
2022-12-05 22:34:50,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:50,818 INFO:     Epoch: 47
2022-12-05 22:34:51,605 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4690295379947532, 'Total loss': 0.4690295379947532} | train loss {'Reaction outcome loss': 0.135966233931938, 'Total loss': 0.135966233931938}
2022-12-05 22:34:51,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:51,605 INFO:     Epoch: 48
2022-12-05 22:34:52,392 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4789857579903169, 'Total loss': 0.4789857579903169} | train loss {'Reaction outcome loss': 0.13761508714179604, 'Total loss': 0.13761508714179604}
2022-12-05 22:34:52,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:52,392 INFO:     Epoch: 49
2022-12-05 22:34:53,178 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4875600053505464, 'Total loss': 0.4875600053505464} | train loss {'Reaction outcome loss': 0.13528877917905244, 'Total loss': 0.13528877917905244}
2022-12-05 22:34:53,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:53,178 INFO:     Epoch: 50
2022-12-05 22:34:53,970 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47791954942724924, 'Total loss': 0.47791954942724924} | train loss {'Reaction outcome loss': 0.13283977139437078, 'Total loss': 0.13283977139437078}
2022-12-05 22:34:53,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:53,970 INFO:     Epoch: 51
2022-12-05 22:34:54,755 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5086630779233846, 'Total loss': 0.5086630779233846} | train loss {'Reaction outcome loss': 0.1354778909219467, 'Total loss': 0.1354778909219467}
2022-12-05 22:34:54,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:54,755 INFO:     Epoch: 52
2022-12-05 22:34:55,540 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4861456978727471, 'Total loss': 0.4861456978727471} | train loss {'Reaction outcome loss': 0.13266670199453223, 'Total loss': 0.13266670199453223}
2022-12-05 22:34:55,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:55,540 INFO:     Epoch: 53
2022-12-05 22:34:56,324 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4775346839292483, 'Total loss': 0.4775346839292483} | train loss {'Reaction outcome loss': 0.12985791667763677, 'Total loss': 0.12985791667763677}
2022-12-05 22:34:56,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:56,324 INFO:     Epoch: 54
2022-12-05 22:34:57,109 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47332218543372373, 'Total loss': 0.47332218543372373} | train loss {'Reaction outcome loss': 0.131005234476559, 'Total loss': 0.131005234476559}
2022-12-05 22:34:57,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:57,109 INFO:     Epoch: 55
2022-12-05 22:34:57,893 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4779622189023278, 'Total loss': 0.4779622189023278} | train loss {'Reaction outcome loss': 0.13019244315064682, 'Total loss': 0.13019244315064682}
2022-12-05 22:34:57,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:57,894 INFO:     Epoch: 56
2022-12-05 22:34:58,678 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.47166118025779724, 'Total loss': 0.47166118025779724} | train loss {'Reaction outcome loss': 0.1284695243881065, 'Total loss': 0.1284695243881065}
2022-12-05 22:34:58,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:58,679 INFO:     Epoch: 57
2022-12-05 22:34:59,467 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47250078872523527, 'Total loss': 0.47250078872523527} | train loss {'Reaction outcome loss': 0.13042230234690466, 'Total loss': 0.13042230234690466}
2022-12-05 22:34:59,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:34:59,468 INFO:     Epoch: 58
2022-12-05 22:35:00,253 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47734935039823706, 'Total loss': 0.47734935039823706} | train loss {'Reaction outcome loss': 0.12984223671409548, 'Total loss': 0.12984223671409548}
2022-12-05 22:35:00,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:00,253 INFO:     Epoch: 59
2022-12-05 22:35:01,038 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48556339960883965, 'Total loss': 0.48556339960883965} | train loss {'Reaction outcome loss': 0.12457041833169606, 'Total loss': 0.12457041833169606}
2022-12-05 22:35:01,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:01,039 INFO:     Epoch: 60
2022-12-05 22:35:01,830 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46605241226709704, 'Total loss': 0.46605241226709704} | train loss {'Reaction outcome loss': 0.12447926304018012, 'Total loss': 0.12447926304018012}
2022-12-05 22:35:01,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:01,830 INFO:     Epoch: 61
2022-12-05 22:35:02,618 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4794393740594387, 'Total loss': 0.4794393740594387} | train loss {'Reaction outcome loss': 0.1266556002275676, 'Total loss': 0.1266556002275676}
2022-12-05 22:35:02,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:02,618 INFO:     Epoch: 62
2022-12-05 22:35:03,405 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4572479176250371, 'Total loss': 0.4572479176250371} | train loss {'Reaction outcome loss': 0.12334808372341248, 'Total loss': 0.12334808372341248}
2022-12-05 22:35:03,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:03,406 INFO:     Epoch: 63
2022-12-05 22:35:04,189 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.498507990247824, 'Total loss': 0.498507990247824} | train loss {'Reaction outcome loss': 0.12549958686363333, 'Total loss': 0.12549958686363333}
2022-12-05 22:35:04,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:04,190 INFO:     Epoch: 64
2022-12-05 22:35:04,975 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5072779960253022, 'Total loss': 0.5072779960253022} | train loss {'Reaction outcome loss': 0.1231481612374892, 'Total loss': 0.1231481612374892}
2022-12-05 22:35:04,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:04,975 INFO:     Epoch: 65
2022-12-05 22:35:05,760 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4948071116073565, 'Total loss': 0.4948071116073565} | train loss {'Reaction outcome loss': 0.12250355533039084, 'Total loss': 0.12250355533039084}
2022-12-05 22:35:05,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:05,760 INFO:     Epoch: 66
2022-12-05 22:35:06,545 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48132637380199, 'Total loss': 0.48132637380199} | train loss {'Reaction outcome loss': 0.1243174162864381, 'Total loss': 0.1243174162864381}
2022-12-05 22:35:06,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:06,545 INFO:     Epoch: 67
2022-12-05 22:35:07,335 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4778917010196231, 'Total loss': 0.4778917010196231} | train loss {'Reaction outcome loss': 0.12348958061703919, 'Total loss': 0.12348958061703919}
2022-12-05 22:35:07,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:07,336 INFO:     Epoch: 68
2022-12-05 22:35:08,119 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4690504585477439, 'Total loss': 0.4690504585477439} | train loss {'Reaction outcome loss': 0.12015680235107334, 'Total loss': 0.12015680235107334}
2022-12-05 22:35:08,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:08,119 INFO:     Epoch: 69
2022-12-05 22:35:08,903 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47729825804179365, 'Total loss': 0.47729825804179365} | train loss {'Reaction outcome loss': 0.1217381222021519, 'Total loss': 0.1217381222021519}
2022-12-05 22:35:08,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:08,903 INFO:     Epoch: 70
2022-12-05 22:35:09,688 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46621810763397, 'Total loss': 0.46621810763397} | train loss {'Reaction outcome loss': 0.12126112129463225, 'Total loss': 0.12126112129463225}
2022-12-05 22:35:09,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:09,688 INFO:     Epoch: 71
2022-12-05 22:35:10,479 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48385496115819976, 'Total loss': 0.48385496115819976} | train loss {'Reaction outcome loss': 0.1208050009851553, 'Total loss': 0.1208050009851553}
2022-12-05 22:35:10,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:10,479 INFO:     Epoch: 72
2022-12-05 22:35:11,266 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4836414178664034, 'Total loss': 0.4836414178664034} | train loss {'Reaction outcome loss': 0.12134278264961072, 'Total loss': 0.12134278264961072}
2022-12-05 22:35:11,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:11,267 INFO:     Epoch: 73
2022-12-05 22:35:12,051 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49337748709050094, 'Total loss': 0.49337748709050094} | train loss {'Reaction outcome loss': 0.12072924611405754, 'Total loss': 0.12072924611405754}
2022-12-05 22:35:12,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:12,052 INFO:     Epoch: 74
2022-12-05 22:35:12,841 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49510922012003983, 'Total loss': 0.49510922012003983} | train loss {'Reaction outcome loss': 0.12016301937401294, 'Total loss': 0.12016301937401294}
2022-12-05 22:35:12,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:12,841 INFO:     Epoch: 75
2022-12-05 22:35:13,630 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48049739172512834, 'Total loss': 0.48049739172512834} | train loss {'Reaction outcome loss': 0.11893825676786351, 'Total loss': 0.11893825676786351}
2022-12-05 22:35:13,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:13,630 INFO:     Epoch: 76
2022-12-05 22:35:14,423 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48178373548117553, 'Total loss': 0.48178373548117553} | train loss {'Reaction outcome loss': 0.11760158359016083, 'Total loss': 0.11760158359016083}
2022-12-05 22:35:14,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:14,423 INFO:     Epoch: 77
2022-12-05 22:35:15,210 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.479227192313622, 'Total loss': 0.479227192313622} | train loss {'Reaction outcome loss': 0.11760256997480685, 'Total loss': 0.11760256997480685}
2022-12-05 22:35:15,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:15,211 INFO:     Epoch: 78
2022-12-05 22:35:15,999 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4637231731004166, 'Total loss': 0.4637231731004166} | train loss {'Reaction outcome loss': 0.11707866758260192, 'Total loss': 0.11707866758260192}
2022-12-05 22:35:15,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:15,999 INFO:     Epoch: 79
2022-12-05 22:35:16,791 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49600143324245105, 'Total loss': 0.49600143324245105} | train loss {'Reaction outcome loss': 0.11749282618414382, 'Total loss': 0.11749282618414382}
2022-12-05 22:35:16,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:16,792 INFO:     Epoch: 80
2022-12-05 22:35:17,577 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4836454543877732, 'Total loss': 0.4836454543877732} | train loss {'Reaction outcome loss': 0.1196584981086911, 'Total loss': 0.1196584981086911}
2022-12-05 22:35:17,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:17,578 INFO:     Epoch: 81
2022-12-05 22:35:18,363 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48529681969772687, 'Total loss': 0.48529681969772687} | train loss {'Reaction outcome loss': 0.11847667290391971, 'Total loss': 0.11847667290391971}
2022-12-05 22:35:18,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:18,363 INFO:     Epoch: 82
2022-12-05 22:35:19,151 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5067816264927387, 'Total loss': 0.5067816264927387} | train loss {'Reaction outcome loss': 0.11519856095047934, 'Total loss': 0.11519856095047934}
2022-12-05 22:35:19,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:19,151 INFO:     Epoch: 83
2022-12-05 22:35:19,939 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5002884129908952, 'Total loss': 0.5002884129908952} | train loss {'Reaction outcome loss': 0.11729938649401372, 'Total loss': 0.11729938649401372}
2022-12-05 22:35:19,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:19,940 INFO:     Epoch: 84
2022-12-05 22:35:20,725 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48256116529757326, 'Total loss': 0.48256116529757326} | train loss {'Reaction outcome loss': 0.11676031322959735, 'Total loss': 0.11676031322959735}
2022-12-05 22:35:20,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:20,725 INFO:     Epoch: 85
2022-12-05 22:35:21,510 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4714343436062336, 'Total loss': 0.4714343436062336} | train loss {'Reaction outcome loss': 0.11608348551909534, 'Total loss': 0.11608348551909534}
2022-12-05 22:35:21,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:21,510 INFO:     Epoch: 86
2022-12-05 22:35:22,300 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47583202577450057, 'Total loss': 0.47583202577450057} | train loss {'Reaction outcome loss': 0.11487078620310949, 'Total loss': 0.11487078620310949}
2022-12-05 22:35:22,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:22,301 INFO:     Epoch: 87
2022-12-05 22:35:23,088 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47902198372916743, 'Total loss': 0.47902198372916743} | train loss {'Reaction outcome loss': 0.11633105902761524, 'Total loss': 0.11633105902761524}
2022-12-05 22:35:23,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:23,089 INFO:     Epoch: 88
2022-12-05 22:35:23,876 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4826423798433759, 'Total loss': 0.4826423798433759} | train loss {'Reaction outcome loss': 0.1151957544935297, 'Total loss': 0.1151957544935297}
2022-12-05 22:35:23,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:23,876 INFO:     Epoch: 89
2022-12-05 22:35:24,661 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48581112040714786, 'Total loss': 0.48581112040714786} | train loss {'Reaction outcome loss': 0.11510931434946096, 'Total loss': 0.11510931434946096}
2022-12-05 22:35:24,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:24,661 INFO:     Epoch: 90
2022-12-05 22:35:25,446 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47099477442150767, 'Total loss': 0.47099477442150767} | train loss {'Reaction outcome loss': 0.11533926291657345, 'Total loss': 0.11533926291657345}
2022-12-05 22:35:25,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:25,447 INFO:     Epoch: 91
2022-12-05 22:35:26,231 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49165477840737865, 'Total loss': 0.49165477840737865} | train loss {'Reaction outcome loss': 0.11294215345489127, 'Total loss': 0.11294215345489127}
2022-12-05 22:35:26,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:26,231 INFO:     Epoch: 92
2022-12-05 22:35:27,015 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.495109637691216, 'Total loss': 0.495109637691216} | train loss {'Reaction outcome loss': 0.1148872132470109, 'Total loss': 0.1148872132470109}
2022-12-05 22:35:27,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:27,016 INFO:     Epoch: 93
2022-12-05 22:35:27,801 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48829562724991277, 'Total loss': 0.48829562724991277} | train loss {'Reaction outcome loss': 0.11519096248916218, 'Total loss': 0.11519096248916218}
2022-12-05 22:35:27,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:27,802 INFO:     Epoch: 94
2022-12-05 22:35:28,592 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48813578418710013, 'Total loss': 0.48813578418710013} | train loss {'Reaction outcome loss': 0.11329782688039906, 'Total loss': 0.11329782688039906}
2022-12-05 22:35:28,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:28,593 INFO:     Epoch: 95
2022-12-05 22:35:29,381 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46902573853731155, 'Total loss': 0.46902573853731155} | train loss {'Reaction outcome loss': 0.11221537615685742, 'Total loss': 0.11221537615685742}
2022-12-05 22:35:29,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:29,381 INFO:     Epoch: 96
2022-12-05 22:35:30,169 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48654779012907634, 'Total loss': 0.48654779012907634} | train loss {'Reaction outcome loss': 0.11291450814686108, 'Total loss': 0.11291450814686108}
2022-12-05 22:35:30,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:30,170 INFO:     Epoch: 97
2022-12-05 22:35:30,959 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4608307244806466, 'Total loss': 0.4608307244806466} | train loss {'Reaction outcome loss': 0.11288541138020097, 'Total loss': 0.11288541138020097}
2022-12-05 22:35:30,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:30,959 INFO:     Epoch: 98
2022-12-05 22:35:31,747 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4666097076101737, 'Total loss': 0.4666097076101737} | train loss {'Reaction outcome loss': 0.11123502795413441, 'Total loss': 0.11123502795413441}
2022-12-05 22:35:31,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:31,747 INFO:     Epoch: 99
2022-12-05 22:35:32,532 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4787851470861245, 'Total loss': 0.4787851470861245} | train loss {'Reaction outcome loss': 0.11141456655245655, 'Total loss': 0.11141456655245655}
2022-12-05 22:35:32,532 INFO:     Best model found after epoch 19 of 100.
2022-12-05 22:35:32,533 INFO:   Done with stage: TRAINING
2022-12-05 22:35:32,533 INFO:   Starting stage: EVALUATION
2022-12-05 22:35:32,663 INFO:   Done with stage: EVALUATION
2022-12-05 22:35:32,663 INFO:   Leaving out SEQ value Fold_6
2022-12-05 22:35:32,676 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:35:32,676 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:35:33,330 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:35:33,330 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:35:33,399 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:35:33,400 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:35:33,400 INFO:     No hyperparam tuning for this model
2022-12-05 22:35:33,400 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:35:33,400 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:35:33,400 INFO:     None feature selector for col prot
2022-12-05 22:35:33,401 INFO:     None feature selector for col prot
2022-12-05 22:35:33,401 INFO:     None feature selector for col prot
2022-12-05 22:35:33,401 INFO:     None feature selector for col chem
2022-12-05 22:35:33,401 INFO:     None feature selector for col chem
2022-12-05 22:35:33,401 INFO:     None feature selector for col chem
2022-12-05 22:35:33,401 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:35:33,401 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:35:33,403 INFO:     Number of params in model 215821
2022-12-05 22:35:33,406 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:35:33,406 INFO:   Starting stage: TRAINING
2022-12-05 22:35:33,466 INFO:     Val loss before train {'Reaction outcome loss': 0.9919000484726646, 'Total loss': 0.9919000484726646}
2022-12-05 22:35:33,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:33,467 INFO:     Epoch: 0
2022-12-05 22:35:34,259 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5736629881642081, 'Total loss': 0.5736629881642081} | train loss {'Reaction outcome loss': 0.781261512949582, 'Total loss': 0.781261512949582}
2022-12-05 22:35:34,259 INFO:     Found new best model at epoch 0
2022-12-05 22:35:34,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:34,260 INFO:     Epoch: 1
2022-12-05 22:35:35,051 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48249662294983864, 'Total loss': 0.48249662294983864} | train loss {'Reaction outcome loss': 0.5298198970455316, 'Total loss': 0.5298198970455316}
2022-12-05 22:35:35,051 INFO:     Found new best model at epoch 1
2022-12-05 22:35:35,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:35,052 INFO:     Epoch: 2
2022-12-05 22:35:35,848 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4524316909638318, 'Total loss': 0.4524316909638318} | train loss {'Reaction outcome loss': 0.46156174413138823, 'Total loss': 0.46156174413138823}
2022-12-05 22:35:35,848 INFO:     Found new best model at epoch 2
2022-12-05 22:35:35,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:35,849 INFO:     Epoch: 3
2022-12-05 22:35:36,645 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4427288106896661, 'Total loss': 0.4427288106896661} | train loss {'Reaction outcome loss': 0.42083372884700376, 'Total loss': 0.42083372884700376}
2022-12-05 22:35:36,646 INFO:     Found new best model at epoch 3
2022-12-05 22:35:36,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:36,647 INFO:     Epoch: 4
2022-12-05 22:35:37,438 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4313295219432224, 'Total loss': 0.4313295219432224} | train loss {'Reaction outcome loss': 0.39416180971649384, 'Total loss': 0.39416180971649384}
2022-12-05 22:35:37,438 INFO:     Found new best model at epoch 4
2022-12-05 22:35:37,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:37,439 INFO:     Epoch: 5
2022-12-05 22:35:38,234 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4283211803571744, 'Total loss': 0.4283211803571744} | train loss {'Reaction outcome loss': 0.3742359199471051, 'Total loss': 0.3742359199471051}
2022-12-05 22:35:38,234 INFO:     Found new best model at epoch 5
2022-12-05 22:35:38,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:38,235 INFO:     Epoch: 6
2022-12-05 22:35:39,027 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4213595011017539, 'Total loss': 0.4213595011017539} | train loss {'Reaction outcome loss': 0.3567089280414005, 'Total loss': 0.3567089280414005}
2022-12-05 22:35:39,027 INFO:     Found new best model at epoch 6
2022-12-05 22:35:39,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:39,028 INFO:     Epoch: 7
2022-12-05 22:35:39,824 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.40692215819250455, 'Total loss': 0.40692215819250455} | train loss {'Reaction outcome loss': 0.33593302616669285, 'Total loss': 0.33593302616669285}
2022-12-05 22:35:39,824 INFO:     Found new best model at epoch 7
2022-12-05 22:35:39,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:39,825 INFO:     Epoch: 8
2022-12-05 22:35:40,618 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41915845396843826, 'Total loss': 0.41915845396843826} | train loss {'Reaction outcome loss': 0.31974340497606224, 'Total loss': 0.31974340497606224}
2022-12-05 22:35:40,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:40,619 INFO:     Epoch: 9
2022-12-05 22:35:41,415 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4134482754902406, 'Total loss': 0.4134482754902406} | train loss {'Reaction outcome loss': 0.3047716511834052, 'Total loss': 0.3047716511834052}
2022-12-05 22:35:41,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:41,416 INFO:     Epoch: 10
2022-12-05 22:35:42,211 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41128532791679556, 'Total loss': 0.41128532791679556} | train loss {'Reaction outcome loss': 0.29508418978882894, 'Total loss': 0.29508418978882894}
2022-12-05 22:35:42,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:42,212 INFO:     Epoch: 11
2022-12-05 22:35:43,005 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.40878782827745785, 'Total loss': 0.40878782827745785} | train loss {'Reaction outcome loss': 0.28468248407326396, 'Total loss': 0.28468248407326396}
2022-12-05 22:35:43,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:43,006 INFO:     Epoch: 12
2022-12-05 22:35:43,801 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4179544685916467, 'Total loss': 0.4179544685916467} | train loss {'Reaction outcome loss': 0.27022571508742627, 'Total loss': 0.27022571508742627}
2022-12-05 22:35:43,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:43,801 INFO:     Epoch: 13
2022-12-05 22:35:44,593 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4074608097699555, 'Total loss': 0.4074608097699555} | train loss {'Reaction outcome loss': 0.26197675313620317, 'Total loss': 0.26197675313620317}
2022-12-05 22:35:44,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:44,593 INFO:     Epoch: 14
2022-12-05 22:35:45,388 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40954452685334464, 'Total loss': 0.40954452685334464} | train loss {'Reaction outcome loss': 0.2562626364130166, 'Total loss': 0.2562626364130166}
2022-12-05 22:35:45,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:45,389 INFO:     Epoch: 15
2022-12-05 22:35:46,182 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40969257175245066, 'Total loss': 0.40969257175245066} | train loss {'Reaction outcome loss': 0.2466734384614674, 'Total loss': 0.2466734384614674}
2022-12-05 22:35:46,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:46,183 INFO:     Epoch: 16
2022-12-05 22:35:46,977 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4094622683796016, 'Total loss': 0.4094622683796016} | train loss {'Reaction outcome loss': 0.240655918305199, 'Total loss': 0.240655918305199}
2022-12-05 22:35:46,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:46,978 INFO:     Epoch: 17
2022-12-05 22:35:47,773 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.420943617482077, 'Total loss': 0.420943617482077} | train loss {'Reaction outcome loss': 0.23351499732703931, 'Total loss': 0.23351499732703931}
2022-12-05 22:35:47,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:47,773 INFO:     Epoch: 18
2022-12-05 22:35:48,566 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42205851965329866, 'Total loss': 0.42205851965329866} | train loss {'Reaction outcome loss': 0.22792749120403202, 'Total loss': 0.22792749120403202}
2022-12-05 22:35:48,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:48,566 INFO:     Epoch: 19
2022-12-05 22:35:49,358 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41897358203476126, 'Total loss': 0.41897358203476126} | train loss {'Reaction outcome loss': 0.2199513945247858, 'Total loss': 0.2199513945247858}
2022-12-05 22:35:49,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:49,359 INFO:     Epoch: 20
2022-12-05 22:35:50,158 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4322784361852841, 'Total loss': 0.4322784361852841} | train loss {'Reaction outcome loss': 0.21617383150864514, 'Total loss': 0.21617383150864514}
2022-12-05 22:35:50,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:50,158 INFO:     Epoch: 21
2022-12-05 22:35:50,952 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4287279945882884, 'Total loss': 0.4287279945882884} | train loss {'Reaction outcome loss': 0.2086144607784527, 'Total loss': 0.2086144607784527}
2022-12-05 22:35:50,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:50,952 INFO:     Epoch: 22
2022-12-05 22:35:51,746 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4358428665860133, 'Total loss': 0.4358428665860133} | train loss {'Reaction outcome loss': 0.20526061842458382, 'Total loss': 0.20526061842458382}
2022-12-05 22:35:51,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:51,746 INFO:     Epoch: 23
2022-12-05 22:35:52,542 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43268849937753245, 'Total loss': 0.43268849937753245} | train loss {'Reaction outcome loss': 0.20349092819097062, 'Total loss': 0.20349092819097062}
2022-12-05 22:35:52,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:52,542 INFO:     Epoch: 24
2022-12-05 22:35:53,334 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4336416335268454, 'Total loss': 0.4336416335268454} | train loss {'Reaction outcome loss': 0.20051340948069288, 'Total loss': 0.20051340948069288}
2022-12-05 22:35:53,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:53,335 INFO:     Epoch: 25
2022-12-05 22:35:54,133 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42490874230861664, 'Total loss': 0.42490874230861664} | train loss {'Reaction outcome loss': 0.19477870758442628, 'Total loss': 0.19477870758442628}
2022-12-05 22:35:54,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:54,133 INFO:     Epoch: 26
2022-12-05 22:35:54,927 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43062021617184987, 'Total loss': 0.43062021617184987} | train loss {'Reaction outcome loss': 0.1889294054689667, 'Total loss': 0.1889294054689667}
2022-12-05 22:35:54,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:54,928 INFO:     Epoch: 27
2022-12-05 22:35:55,727 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4422484880143946, 'Total loss': 0.4422484880143946} | train loss {'Reaction outcome loss': 0.18824519903489179, 'Total loss': 0.18824519903489179}
2022-12-05 22:35:55,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:55,727 INFO:     Epoch: 28
2022-12-05 22:35:56,530 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44490094550631265, 'Total loss': 0.44490094550631265} | train loss {'Reaction outcome loss': 0.18731382292424958, 'Total loss': 0.18731382292424958}
2022-12-05 22:35:56,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:56,531 INFO:     Epoch: 29
2022-12-05 22:35:57,324 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42769768986512313, 'Total loss': 0.42769768986512313} | train loss {'Reaction outcome loss': 0.1813802771540659, 'Total loss': 0.1813802771540659}
2022-12-05 22:35:57,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:57,325 INFO:     Epoch: 30
2022-12-05 22:35:58,121 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4421778050335971, 'Total loss': 0.4421778050335971} | train loss {'Reaction outcome loss': 0.18258681050651976, 'Total loss': 0.18258681050651976}
2022-12-05 22:35:58,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:58,121 INFO:     Epoch: 31
2022-12-05 22:35:58,914 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43429873646660283, 'Total loss': 0.43429873646660283} | train loss {'Reaction outcome loss': 0.1761854932335536, 'Total loss': 0.1761854932335536}
2022-12-05 22:35:58,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:58,915 INFO:     Epoch: 32
2022-12-05 22:35:59,708 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4433450302617116, 'Total loss': 0.4433450302617116} | train loss {'Reaction outcome loss': 0.17020242437419872, 'Total loss': 0.17020242437419872}
2022-12-05 22:35:59,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:35:59,708 INFO:     Epoch: 33
2022-12-05 22:36:00,503 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44348551400683145, 'Total loss': 0.44348551400683145} | train loss {'Reaction outcome loss': 0.1704557124945906, 'Total loss': 0.1704557124945906}
2022-12-05 22:36:00,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:00,503 INFO:     Epoch: 34
2022-12-05 22:36:01,297 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4563414810056036, 'Total loss': 0.4563414810056036} | train loss {'Reaction outcome loss': 0.1714038673653117, 'Total loss': 0.1714038673653117}
2022-12-05 22:36:01,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:01,297 INFO:     Epoch: 35
2022-12-05 22:36:02,091 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4559038230641322, 'Total loss': 0.4559038230641322} | train loss {'Reaction outcome loss': 0.16749561433830568, 'Total loss': 0.16749561433830568}
2022-12-05 22:36:02,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:02,092 INFO:     Epoch: 36
2022-12-05 22:36:02,886 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4545044317333536, 'Total loss': 0.4545044317333536} | train loss {'Reaction outcome loss': 0.1652349615469575, 'Total loss': 0.1652349615469575}
2022-12-05 22:36:02,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:02,886 INFO:     Epoch: 37
2022-12-05 22:36:03,679 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45235379853031854, 'Total loss': 0.45235379853031854} | train loss {'Reaction outcome loss': 0.16333088246850117, 'Total loss': 0.16333088246850117}
2022-12-05 22:36:03,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:03,679 INFO:     Epoch: 38
2022-12-05 22:36:04,473 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4663424830545079, 'Total loss': 0.4663424830545079} | train loss {'Reaction outcome loss': 0.1629152018727074, 'Total loss': 0.1629152018727074}
2022-12-05 22:36:04,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:04,473 INFO:     Epoch: 39
2022-12-05 22:36:05,267 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4549753383140672, 'Total loss': 0.4549753383140672} | train loss {'Reaction outcome loss': 0.1570202182047069, 'Total loss': 0.1570202182047069}
2022-12-05 22:36:05,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:05,268 INFO:     Epoch: 40
2022-12-05 22:36:06,064 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4417494203556668, 'Total loss': 0.4417494203556668} | train loss {'Reaction outcome loss': 0.15886362962755224, 'Total loss': 0.15886362962755224}
2022-12-05 22:36:06,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:06,064 INFO:     Epoch: 41
2022-12-05 22:36:06,871 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4622043882581321, 'Total loss': 0.4622043882581321} | train loss {'Reaction outcome loss': 0.15657867123973707, 'Total loss': 0.15657867123973707}
2022-12-05 22:36:06,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:06,872 INFO:     Epoch: 42
2022-12-05 22:36:07,682 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4613218395547433, 'Total loss': 0.4613218395547433} | train loss {'Reaction outcome loss': 0.1535634195296875, 'Total loss': 0.1535634195296875}
2022-12-05 22:36:07,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:07,683 INFO:     Epoch: 43
2022-12-05 22:36:08,492 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.45786011015827005, 'Total loss': 0.45786011015827005} | train loss {'Reaction outcome loss': 0.15354941465381172, 'Total loss': 0.15354941465381172}
2022-12-05 22:36:08,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:08,493 INFO:     Epoch: 44
2022-12-05 22:36:09,301 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4475404794581912, 'Total loss': 0.4475404794581912} | train loss {'Reaction outcome loss': 0.1548874787836065, 'Total loss': 0.1548874787836065}
2022-12-05 22:36:09,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:09,302 INFO:     Epoch: 45
2022-12-05 22:36:10,115 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45658497884869576, 'Total loss': 0.45658497884869576} | train loss {'Reaction outcome loss': 0.15242836819285707, 'Total loss': 0.15242836819285707}
2022-12-05 22:36:10,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:10,115 INFO:     Epoch: 46
2022-12-05 22:36:10,926 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46792068908160384, 'Total loss': 0.46792068908160384} | train loss {'Reaction outcome loss': 0.15244530666349154, 'Total loss': 0.15244530666349154}
2022-12-05 22:36:10,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:10,926 INFO:     Epoch: 47
2022-12-05 22:36:11,738 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46273180876265874, 'Total loss': 0.46273180876265874} | train loss {'Reaction outcome loss': 0.14919039678399362, 'Total loss': 0.14919039678399362}
2022-12-05 22:36:11,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:11,739 INFO:     Epoch: 48
2022-12-05 22:36:12,549 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.465745424343781, 'Total loss': 0.465745424343781} | train loss {'Reaction outcome loss': 0.14789453884136053, 'Total loss': 0.14789453884136053}
2022-12-05 22:36:12,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:12,549 INFO:     Epoch: 49
2022-12-05 22:36:13,357 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45186143537813966, 'Total loss': 0.45186143537813966} | train loss {'Reaction outcome loss': 0.14948717576842155, 'Total loss': 0.14948717576842155}
2022-12-05 22:36:13,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:13,357 INFO:     Epoch: 50
2022-12-05 22:36:14,166 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47821960056369955, 'Total loss': 0.47821960056369955} | train loss {'Reaction outcome loss': 0.14848743893596675, 'Total loss': 0.14848743893596675}
2022-12-05 22:36:14,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:14,168 INFO:     Epoch: 51
2022-12-05 22:36:14,978 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46341363001953473, 'Total loss': 0.46341363001953473} | train loss {'Reaction outcome loss': 0.1465675577506303, 'Total loss': 0.1465675577506303}
2022-12-05 22:36:14,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:14,978 INFO:     Epoch: 52
2022-12-05 22:36:15,791 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4776735624129122, 'Total loss': 0.4776735624129122} | train loss {'Reaction outcome loss': 0.14853416922532262, 'Total loss': 0.14853416922532262}
2022-12-05 22:36:15,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:15,792 INFO:     Epoch: 53
2022-12-05 22:36:16,602 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45734850960699, 'Total loss': 0.45734850960699} | train loss {'Reaction outcome loss': 0.14427458185462222, 'Total loss': 0.14427458185462222}
2022-12-05 22:36:16,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:16,602 INFO:     Epoch: 54
2022-12-05 22:36:17,417 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4874261749738997, 'Total loss': 0.4874261749738997} | train loss {'Reaction outcome loss': 0.13996270129216776, 'Total loss': 0.13996270129216776}
2022-12-05 22:36:17,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:17,417 INFO:     Epoch: 55
2022-12-05 22:36:18,227 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44119732759215613, 'Total loss': 0.44119732759215613} | train loss {'Reaction outcome loss': 0.14248809597883072, 'Total loss': 0.14248809597883072}
2022-12-05 22:36:18,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:18,228 INFO:     Epoch: 56
2022-12-05 22:36:19,039 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45104080269282515, 'Total loss': 0.45104080269282515} | train loss {'Reaction outcome loss': 0.1421658241625635, 'Total loss': 0.1421658241625635}
2022-12-05 22:36:19,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:19,039 INFO:     Epoch: 57
2022-12-05 22:36:19,851 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48704240742054855, 'Total loss': 0.48704240742054855} | train loss {'Reaction outcome loss': 0.1425063901340529, 'Total loss': 0.1425063901340529}
2022-12-05 22:36:19,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:19,852 INFO:     Epoch: 58
2022-12-05 22:36:20,665 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46776131709868257, 'Total loss': 0.46776131709868257} | train loss {'Reaction outcome loss': 0.1420127019368773, 'Total loss': 0.1420127019368773}
2022-12-05 22:36:20,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:20,666 INFO:     Epoch: 59
2022-12-05 22:36:21,475 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4732737246562134, 'Total loss': 0.4732737246562134} | train loss {'Reaction outcome loss': 0.13904825495856424, 'Total loss': 0.13904825495856424}
2022-12-05 22:36:21,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:21,475 INFO:     Epoch: 60
2022-12-05 22:36:22,285 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4720746725797653, 'Total loss': 0.4720746725797653} | train loss {'Reaction outcome loss': 0.1405639653469646, 'Total loss': 0.1405639653469646}
2022-12-05 22:36:22,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:22,286 INFO:     Epoch: 61
2022-12-05 22:36:23,105 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.464927328242497, 'Total loss': 0.464927328242497} | train loss {'Reaction outcome loss': 0.13868460541350708, 'Total loss': 0.13868460541350708}
2022-12-05 22:36:23,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:23,105 INFO:     Epoch: 62
2022-12-05 22:36:23,914 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4851097728718411, 'Total loss': 0.4851097728718411} | train loss {'Reaction outcome loss': 0.1330160600163283, 'Total loss': 0.1330160600163283}
2022-12-05 22:36:23,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:23,915 INFO:     Epoch: 63
2022-12-05 22:36:24,727 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4808479611846534, 'Total loss': 0.4808479611846534} | train loss {'Reaction outcome loss': 0.1380501164709248, 'Total loss': 0.1380501164709248}
2022-12-05 22:36:24,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:24,727 INFO:     Epoch: 64
2022-12-05 22:36:25,537 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46803281185301865, 'Total loss': 0.46803281185301865} | train loss {'Reaction outcome loss': 0.13466535686635442, 'Total loss': 0.13466535686635442}
2022-12-05 22:36:25,537 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:25,537 INFO:     Epoch: 65
2022-12-05 22:36:26,350 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47492061961780896, 'Total loss': 0.47492061961780896} | train loss {'Reaction outcome loss': 0.13545979723905124, 'Total loss': 0.13545979723905124}
2022-12-05 22:36:26,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:26,351 INFO:     Epoch: 66
2022-12-05 22:36:27,164 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4792879858816212, 'Total loss': 0.4792879858816212} | train loss {'Reaction outcome loss': 0.13552786850730977, 'Total loss': 0.13552786850730977}
2022-12-05 22:36:27,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:27,164 INFO:     Epoch: 67
2022-12-05 22:36:27,974 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45606294951655646, 'Total loss': 0.45606294951655646} | train loss {'Reaction outcome loss': 0.13249663488128252, 'Total loss': 0.13249663488128252}
2022-12-05 22:36:27,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:27,974 INFO:     Epoch: 68
2022-12-05 22:36:28,786 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4521042511544444, 'Total loss': 0.4521042511544444} | train loss {'Reaction outcome loss': 0.13211598322020784, 'Total loss': 0.13211598322020784}
2022-12-05 22:36:28,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:28,786 INFO:     Epoch: 69
2022-12-05 22:36:29,595 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4645671814002774, 'Total loss': 0.4645671814002774} | train loss {'Reaction outcome loss': 0.1344251086665017, 'Total loss': 0.1344251086665017}
2022-12-05 22:36:29,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:29,595 INFO:     Epoch: 70
2022-12-05 22:36:30,405 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49118858033960516, 'Total loss': 0.49118858033960516} | train loss {'Reaction outcome loss': 0.13137800071103078, 'Total loss': 0.13137800071103078}
2022-12-05 22:36:30,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:30,405 INFO:     Epoch: 71
2022-12-05 22:36:31,215 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4604313607242974, 'Total loss': 0.4604313607242974} | train loss {'Reaction outcome loss': 0.13444167286938719, 'Total loss': 0.13444167286938719}
2022-12-05 22:36:31,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:31,215 INFO:     Epoch: 72
2022-12-05 22:36:32,024 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4777138509194959, 'Total loss': 0.4777138509194959} | train loss {'Reaction outcome loss': 0.13128599241815297, 'Total loss': 0.13128599241815297}
2022-12-05 22:36:32,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:32,024 INFO:     Epoch: 73
2022-12-05 22:36:32,834 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4570950378071178, 'Total loss': 0.4570950378071178} | train loss {'Reaction outcome loss': 0.13279178568853006, 'Total loss': 0.13279178568853006}
2022-12-05 22:36:32,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:32,835 INFO:     Epoch: 74
2022-12-05 22:36:33,651 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4698329405351119, 'Total loss': 0.4698329405351119} | train loss {'Reaction outcome loss': 0.12998130479301775, 'Total loss': 0.12998130479301775}
2022-12-05 22:36:33,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:33,652 INFO:     Epoch: 75
2022-12-05 22:36:34,466 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4525071965022521, 'Total loss': 0.4525071965022521} | train loss {'Reaction outcome loss': 0.13002028147644934, 'Total loss': 0.13002028147644934}
2022-12-05 22:36:34,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:34,466 INFO:     Epoch: 76
2022-12-05 22:36:35,276 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47035553746602754, 'Total loss': 0.47035553746602754} | train loss {'Reaction outcome loss': 0.1292123963958734, 'Total loss': 0.1292123963958734}
2022-12-05 22:36:35,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:35,276 INFO:     Epoch: 77
2022-12-05 22:36:36,088 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46129178712991153, 'Total loss': 0.46129178712991153} | train loss {'Reaction outcome loss': 0.13157927660617016, 'Total loss': 0.13157927660617016}
2022-12-05 22:36:36,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:36,088 INFO:     Epoch: 78
2022-12-05 22:36:36,898 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4752955734729767, 'Total loss': 0.4752955734729767} | train loss {'Reaction outcome loss': 0.12850814881253866, 'Total loss': 0.12850814881253866}
2022-12-05 22:36:36,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:36,898 INFO:     Epoch: 79
2022-12-05 22:36:37,712 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47382536564360966, 'Total loss': 0.47382536564360966} | train loss {'Reaction outcome loss': 0.12941154361807652, 'Total loss': 0.12941154361807652}
2022-12-05 22:36:37,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:37,712 INFO:     Epoch: 80
2022-12-05 22:36:38,526 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45114353502338583, 'Total loss': 0.45114353502338583} | train loss {'Reaction outcome loss': 0.12726293718667642, 'Total loss': 0.12726293718667642}
2022-12-05 22:36:38,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:38,526 INFO:     Epoch: 81
2022-12-05 22:36:39,344 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4703055505048145, 'Total loss': 0.4703055505048145} | train loss {'Reaction outcome loss': 0.12658738356924826, 'Total loss': 0.12658738356924826}
2022-12-05 22:36:39,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:39,344 INFO:     Epoch: 82
2022-12-05 22:36:40,158 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4571223492649468, 'Total loss': 0.4571223492649468} | train loss {'Reaction outcome loss': 0.1280293068585677, 'Total loss': 0.1280293068585677}
2022-12-05 22:36:40,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:40,158 INFO:     Epoch: 83
2022-12-05 22:36:40,968 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45636049353263597, 'Total loss': 0.45636049353263597} | train loss {'Reaction outcome loss': 0.1261973405433368, 'Total loss': 0.1261973405433368}
2022-12-05 22:36:40,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:40,968 INFO:     Epoch: 84
2022-12-05 22:36:41,777 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.463526767085899, 'Total loss': 0.463526767085899} | train loss {'Reaction outcome loss': 0.12766504740988416, 'Total loss': 0.12766504740988416}
2022-12-05 22:36:41,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:41,777 INFO:     Epoch: 85
2022-12-05 22:36:42,586 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45926207066936925, 'Total loss': 0.45926207066936925} | train loss {'Reaction outcome loss': 0.12785278836775932, 'Total loss': 0.12785278836775932}
2022-12-05 22:36:42,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:42,586 INFO:     Epoch: 86
2022-12-05 22:36:43,398 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46031393483281136, 'Total loss': 0.46031393483281136} | train loss {'Reaction outcome loss': 0.12655152314748133, 'Total loss': 0.12655152314748133}
2022-12-05 22:36:43,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:43,398 INFO:     Epoch: 87
2022-12-05 22:36:44,209 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4757222919301553, 'Total loss': 0.4757222919301553} | train loss {'Reaction outcome loss': 0.1266652549759695, 'Total loss': 0.1266652549759695}
2022-12-05 22:36:44,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:44,209 INFO:     Epoch: 88
2022-12-05 22:36:45,018 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4659948172894391, 'Total loss': 0.4659948172894391} | train loss {'Reaction outcome loss': 0.1251973737061264, 'Total loss': 0.1251973737061264}
2022-12-05 22:36:45,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:45,019 INFO:     Epoch: 89
2022-12-05 22:36:45,831 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46413796835324983, 'Total loss': 0.46413796835324983} | train loss {'Reaction outcome loss': 0.1268395048175608, 'Total loss': 0.1268395048175608}
2022-12-05 22:36:45,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:45,832 INFO:     Epoch: 90
2022-12-05 22:36:46,646 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.467853653837334, 'Total loss': 0.467853653837334} | train loss {'Reaction outcome loss': 0.12314957939088345, 'Total loss': 0.12314957939088345}
2022-12-05 22:36:46,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:46,646 INFO:     Epoch: 91
2022-12-05 22:36:47,460 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46373806961558084, 'Total loss': 0.46373806961558084} | train loss {'Reaction outcome loss': 0.1243644844151042, 'Total loss': 0.1243644844151042}
2022-12-05 22:36:47,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:47,461 INFO:     Epoch: 92
2022-12-05 22:36:48,274 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48136069456284697, 'Total loss': 0.48136069456284697} | train loss {'Reaction outcome loss': 0.12445919684344722, 'Total loss': 0.12445919684344722}
2022-12-05 22:36:48,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:48,274 INFO:     Epoch: 93
2022-12-05 22:36:49,085 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4719359227879481, 'Total loss': 0.4719359227879481} | train loss {'Reaction outcome loss': 0.1248198110129564, 'Total loss': 0.1248198110129564}
2022-12-05 22:36:49,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:49,085 INFO:     Epoch: 94
2022-12-05 22:36:49,899 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4604073625735261, 'Total loss': 0.4604073625735261} | train loss {'Reaction outcome loss': 0.12391351846482364, 'Total loss': 0.12391351846482364}
2022-12-05 22:36:49,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:49,899 INFO:     Epoch: 95
2022-12-05 22:36:50,711 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4446840011938052, 'Total loss': 0.4446840011938052} | train loss {'Reaction outcome loss': 0.11978160696584851, 'Total loss': 0.11978160696584851}
2022-12-05 22:36:50,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:50,712 INFO:     Epoch: 96
2022-12-05 22:36:51,522 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46236988597295503, 'Total loss': 0.46236988597295503} | train loss {'Reaction outcome loss': 0.12102958206237564, 'Total loss': 0.12102958206237564}
2022-12-05 22:36:51,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:51,523 INFO:     Epoch: 97
2022-12-05 22:36:52,333 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4510158071802421, 'Total loss': 0.4510158071802421} | train loss {'Reaction outcome loss': 0.12386896631364981, 'Total loss': 0.12386896631364981}
2022-12-05 22:36:52,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:52,334 INFO:     Epoch: 98
2022-12-05 22:36:53,144 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46295848522673955, 'Total loss': 0.46295848522673955} | train loss {'Reaction outcome loss': 0.12258420979243613, 'Total loss': 0.12258420979243613}
2022-12-05 22:36:53,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:53,144 INFO:     Epoch: 99
2022-12-05 22:36:53,954 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4570542411370711, 'Total loss': 0.4570542411370711} | train loss {'Reaction outcome loss': 0.12218103110564933, 'Total loss': 0.12218103110564933}
2022-12-05 22:36:53,954 INFO:     Best model found after epoch 8 of 100.
2022-12-05 22:36:53,954 INFO:   Done with stage: TRAINING
2022-12-05 22:36:53,954 INFO:   Starting stage: EVALUATION
2022-12-05 22:36:54,073 INFO:   Done with stage: EVALUATION
2022-12-05 22:36:54,073 INFO:   Leaving out SEQ value Fold_7
2022-12-05 22:36:54,086 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:36:54,086 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:36:54,736 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:36:54,736 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:36:54,807 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:36:54,807 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:36:54,807 INFO:     No hyperparam tuning for this model
2022-12-05 22:36:54,807 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:36:54,807 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:36:54,808 INFO:     None feature selector for col prot
2022-12-05 22:36:54,808 INFO:     None feature selector for col prot
2022-12-05 22:36:54,808 INFO:     None feature selector for col prot
2022-12-05 22:36:54,809 INFO:     None feature selector for col chem
2022-12-05 22:36:54,809 INFO:     None feature selector for col chem
2022-12-05 22:36:54,809 INFO:     None feature selector for col chem
2022-12-05 22:36:54,809 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:36:54,809 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:36:54,811 INFO:     Number of params in model 215821
2022-12-05 22:36:54,814 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:36:54,814 INFO:   Starting stage: TRAINING
2022-12-05 22:36:54,875 INFO:     Val loss before train {'Reaction outcome loss': 1.0041801821101795, 'Total loss': 1.0041801821101795}
2022-12-05 22:36:54,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:54,876 INFO:     Epoch: 0
2022-12-05 22:36:55,689 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.594951909374107, 'Total loss': 0.594951909374107} | train loss {'Reaction outcome loss': 0.7912712755703157, 'Total loss': 0.7912712755703157}
2022-12-05 22:36:55,689 INFO:     Found new best model at epoch 0
2022-12-05 22:36:55,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:55,690 INFO:     Epoch: 1
2022-12-05 22:36:56,501 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.513000816445459, 'Total loss': 0.513000816445459} | train loss {'Reaction outcome loss': 0.5451589219512478, 'Total loss': 0.5451589219512478}
2022-12-05 22:36:56,501 INFO:     Found new best model at epoch 1
2022-12-05 22:36:56,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:56,502 INFO:     Epoch: 2
2022-12-05 22:36:57,308 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.481969070028175, 'Total loss': 0.481969070028175} | train loss {'Reaction outcome loss': 0.4747208240892618, 'Total loss': 0.4747208240892618}
2022-12-05 22:36:57,308 INFO:     Found new best model at epoch 2
2022-12-05 22:36:57,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:57,309 INFO:     Epoch: 3
2022-12-05 22:36:58,111 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4647385051304644, 'Total loss': 0.4647385051304644} | train loss {'Reaction outcome loss': 0.4323036796864002, 'Total loss': 0.4323036796864002}
2022-12-05 22:36:58,111 INFO:     Found new best model at epoch 3
2022-12-05 22:36:58,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:58,112 INFO:     Epoch: 4
2022-12-05 22:36:58,913 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4555820396000689, 'Total loss': 0.4555820396000689} | train loss {'Reaction outcome loss': 0.40571780677043623, 'Total loss': 0.40571780677043623}
2022-12-05 22:36:58,914 INFO:     Found new best model at epoch 4
2022-12-05 22:36:58,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:58,914 INFO:     Epoch: 5
2022-12-05 22:36:59,718 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4320930770852349, 'Total loss': 0.4320930770852349} | train loss {'Reaction outcome loss': 0.3868171073376171, 'Total loss': 0.3868171073376171}
2022-12-05 22:36:59,719 INFO:     Found new best model at epoch 5
2022-12-05 22:36:59,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:36:59,719 INFO:     Epoch: 6
2022-12-05 22:37:00,518 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42972743240269745, 'Total loss': 0.42972743240269745} | train loss {'Reaction outcome loss': 0.3653762227885665, 'Total loss': 0.3653762227885665}
2022-12-05 22:37:00,518 INFO:     Found new best model at epoch 6
2022-12-05 22:37:00,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:00,519 INFO:     Epoch: 7
2022-12-05 22:37:01,318 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42939168925989757, 'Total loss': 0.42939168925989757} | train loss {'Reaction outcome loss': 0.35050131059101514, 'Total loss': 0.35050131059101514}
2022-12-05 22:37:01,318 INFO:     Found new best model at epoch 7
2022-12-05 22:37:01,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:01,319 INFO:     Epoch: 8
2022-12-05 22:37:02,117 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4237755699591203, 'Total loss': 0.4237755699591203} | train loss {'Reaction outcome loss': 0.3363697230215034, 'Total loss': 0.3363697230215034}
2022-12-05 22:37:02,117 INFO:     Found new best model at epoch 8
2022-12-05 22:37:02,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:02,118 INFO:     Epoch: 9
2022-12-05 22:37:02,914 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.41823588650334964, 'Total loss': 0.41823588650334964} | train loss {'Reaction outcome loss': 0.3236171263119867, 'Total loss': 0.3236171263119867}
2022-12-05 22:37:02,914 INFO:     Found new best model at epoch 9
2022-12-05 22:37:02,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:02,915 INFO:     Epoch: 10
2022-12-05 22:37:03,715 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4116695042360913, 'Total loss': 0.4116695042360913} | train loss {'Reaction outcome loss': 0.312259471659819, 'Total loss': 0.312259471659819}
2022-12-05 22:37:03,716 INFO:     Found new best model at epoch 10
2022-12-05 22:37:03,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:03,717 INFO:     Epoch: 11
2022-12-05 22:37:04,516 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41937957060607994, 'Total loss': 0.41937957060607994} | train loss {'Reaction outcome loss': 0.3007567134655772, 'Total loss': 0.3007567134655772}
2022-12-05 22:37:04,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:04,516 INFO:     Epoch: 12
2022-12-05 22:37:05,313 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4087825839153745, 'Total loss': 0.4087825839153745} | train loss {'Reaction outcome loss': 0.29180825027006285, 'Total loss': 0.29180825027006285}
2022-12-05 22:37:05,314 INFO:     Found new best model at epoch 12
2022-12-05 22:37:05,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:05,314 INFO:     Epoch: 13
2022-12-05 22:37:06,110 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4201765385541049, 'Total loss': 0.4201765385541049} | train loss {'Reaction outcome loss': 0.2792557354175275, 'Total loss': 0.2792557354175275}
2022-12-05 22:37:06,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:06,111 INFO:     Epoch: 14
2022-12-05 22:37:06,910 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41105914319103415, 'Total loss': 0.41105914319103415} | train loss {'Reaction outcome loss': 0.27330050995994, 'Total loss': 0.27330050995994}
2022-12-05 22:37:06,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:06,910 INFO:     Epoch: 15
2022-12-05 22:37:07,710 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4023826315321706, 'Total loss': 0.4023826315321706} | train loss {'Reaction outcome loss': 0.2613238953354378, 'Total loss': 0.2613238953354378}
2022-12-05 22:37:07,710 INFO:     Found new best model at epoch 15
2022-12-05 22:37:07,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:07,711 INFO:     Epoch: 16
2022-12-05 22:37:08,508 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41556158424778417, 'Total loss': 0.41556158424778417} | train loss {'Reaction outcome loss': 0.2551850480057539, 'Total loss': 0.2551850480057539}
2022-12-05 22:37:08,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:08,508 INFO:     Epoch: 17
2022-12-05 22:37:09,308 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40897354585203255, 'Total loss': 0.40897354585203255} | train loss {'Reaction outcome loss': 0.24960206391950768, 'Total loss': 0.24960206391950768}
2022-12-05 22:37:09,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:09,308 INFO:     Epoch: 18
2022-12-05 22:37:10,105 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.401609956710176, 'Total loss': 0.401609956710176} | train loss {'Reaction outcome loss': 0.24104220013044053, 'Total loss': 0.24104220013044053}
2022-12-05 22:37:10,105 INFO:     Found new best model at epoch 18
2022-12-05 22:37:10,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:10,106 INFO:     Epoch: 19
2022-12-05 22:37:10,905 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4079615920782089, 'Total loss': 0.4079615920782089} | train loss {'Reaction outcome loss': 0.2348216663325025, 'Total loss': 0.2348216663325025}
2022-12-05 22:37:10,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:10,905 INFO:     Epoch: 20
2022-12-05 22:37:11,703 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4125094119120728, 'Total loss': 0.4125094119120728} | train loss {'Reaction outcome loss': 0.23028537491336465, 'Total loss': 0.23028537491336465}
2022-12-05 22:37:11,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:11,703 INFO:     Epoch: 21
2022-12-05 22:37:12,504 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40239137749780307, 'Total loss': 0.40239137749780307} | train loss {'Reaction outcome loss': 0.22472904921479284, 'Total loss': 0.22472904921479284}
2022-12-05 22:37:12,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:12,504 INFO:     Epoch: 22
2022-12-05 22:37:13,304 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40694229982116004, 'Total loss': 0.40694229982116004} | train loss {'Reaction outcome loss': 0.21831822357771377, 'Total loss': 0.21831822357771377}
2022-12-05 22:37:13,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:13,304 INFO:     Epoch: 23
2022-12-05 22:37:14,101 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3977527137507092, 'Total loss': 0.3977527137507092} | train loss {'Reaction outcome loss': 0.21756118328701105, 'Total loss': 0.21756118328701105}
2022-12-05 22:37:14,101 INFO:     Found new best model at epoch 23
2022-12-05 22:37:14,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:14,102 INFO:     Epoch: 24
2022-12-05 22:37:14,898 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41103980487043207, 'Total loss': 0.41103980487043207} | train loss {'Reaction outcome loss': 0.20625920671849482, 'Total loss': 0.20625920671849482}
2022-12-05 22:37:14,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:14,898 INFO:     Epoch: 25
2022-12-05 22:37:15,696 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41303734278137033, 'Total loss': 0.41303734278137033} | train loss {'Reaction outcome loss': 0.20547908377052554, 'Total loss': 0.20547908377052554}
2022-12-05 22:37:15,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:15,697 INFO:     Epoch: 26
2022-12-05 22:37:16,494 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4153630106963895, 'Total loss': 0.4153630106963895} | train loss {'Reaction outcome loss': 0.2034158164019426, 'Total loss': 0.2034158164019426}
2022-12-05 22:37:16,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:16,494 INFO:     Epoch: 27
2022-12-05 22:37:17,295 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41290741854093294, 'Total loss': 0.41290741854093294} | train loss {'Reaction outcome loss': 0.19921964690870336, 'Total loss': 0.19921964690870336}
2022-12-05 22:37:17,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:17,295 INFO:     Epoch: 28
2022-12-05 22:37:18,095 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4038996422155337, 'Total loss': 0.4038996422155337} | train loss {'Reaction outcome loss': 0.19522680086834776, 'Total loss': 0.19522680086834776}
2022-12-05 22:37:18,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:18,095 INFO:     Epoch: 29
2022-12-05 22:37:18,896 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41156612438234413, 'Total loss': 0.41156612438234413} | train loss {'Reaction outcome loss': 0.19230243428460053, 'Total loss': 0.19230243428460053}
2022-12-05 22:37:18,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:18,896 INFO:     Epoch: 30
2022-12-05 22:37:19,694 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.430066509002989, 'Total loss': 0.430066509002989} | train loss {'Reaction outcome loss': 0.18863910626650096, 'Total loss': 0.18863910626650096}
2022-12-05 22:37:19,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:19,694 INFO:     Epoch: 31
2022-12-05 22:37:20,492 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4106510952115059, 'Total loss': 0.4106510952115059} | train loss {'Reaction outcome loss': 0.18662969635859614, 'Total loss': 0.18662969635859614}
2022-12-05 22:37:20,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:20,492 INFO:     Epoch: 32
2022-12-05 22:37:21,292 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4154518514194272, 'Total loss': 0.4154518514194272} | train loss {'Reaction outcome loss': 0.1846683108728499, 'Total loss': 0.1846683108728499}
2022-12-05 22:37:21,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:21,292 INFO:     Epoch: 33
2022-12-05 22:37:22,090 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4231050451370803, 'Total loss': 0.4231050451370803} | train loss {'Reaction outcome loss': 0.1802069149881361, 'Total loss': 0.1802069149881361}
2022-12-05 22:37:22,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:22,090 INFO:     Epoch: 34
2022-12-05 22:37:22,891 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4101193984123794, 'Total loss': 0.4101193984123794} | train loss {'Reaction outcome loss': 0.17814259493212786, 'Total loss': 0.17814259493212786}
2022-12-05 22:37:22,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:22,891 INFO:     Epoch: 35
2022-12-05 22:37:23,689 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4150158620693467, 'Total loss': 0.4150158620693467} | train loss {'Reaction outcome loss': 0.1742252827276506, 'Total loss': 0.1742252827276506}
2022-12-05 22:37:23,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:23,689 INFO:     Epoch: 36
2022-12-05 22:37:24,486 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41641404073346744, 'Total loss': 0.41641404073346744} | train loss {'Reaction outcome loss': 0.17652512440878537, 'Total loss': 0.17652512440878537}
2022-12-05 22:37:24,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:24,486 INFO:     Epoch: 37
2022-12-05 22:37:25,284 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43097792667421425, 'Total loss': 0.43097792667421425} | train loss {'Reaction outcome loss': 0.1744009861797695, 'Total loss': 0.1744009861797695}
2022-12-05 22:37:25,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:25,284 INFO:     Epoch: 38
2022-12-05 22:37:26,082 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4377783138982274, 'Total loss': 0.4377783138982274} | train loss {'Reaction outcome loss': 0.1690668468363583, 'Total loss': 0.1690668468363583}
2022-12-05 22:37:26,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:26,082 INFO:     Epoch: 39
2022-12-05 22:37:26,880 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42501071180132305, 'Total loss': 0.42501071180132305} | train loss {'Reaction outcome loss': 0.1707841617716176, 'Total loss': 0.1707841617716176}
2022-12-05 22:37:26,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:26,880 INFO:     Epoch: 40
2022-12-05 22:37:27,680 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4335761825469407, 'Total loss': 0.4335761825469407} | train loss {'Reaction outcome loss': 0.16868682937215893, 'Total loss': 0.16868682937215893}
2022-12-05 22:37:27,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:27,681 INFO:     Epoch: 41
2022-12-05 22:37:28,477 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4185948288914832, 'Total loss': 0.4185948288914832} | train loss {'Reaction outcome loss': 0.16399829059598908, 'Total loss': 0.16399829059598908}
2022-12-05 22:37:28,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:28,477 INFO:     Epoch: 42
2022-12-05 22:37:29,275 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42788718234408984, 'Total loss': 0.42788718234408984} | train loss {'Reaction outcome loss': 0.16519781184803334, 'Total loss': 0.16519781184803334}
2022-12-05 22:37:29,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:29,275 INFO:     Epoch: 43
2022-12-05 22:37:30,076 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41429183733734215, 'Total loss': 0.41429183733734215} | train loss {'Reaction outcome loss': 0.16581821015044565, 'Total loss': 0.16581821015044565}
2022-12-05 22:37:30,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:30,076 INFO:     Epoch: 44
2022-12-05 22:37:30,873 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4223319644277746, 'Total loss': 0.4223319644277746} | train loss {'Reaction outcome loss': 0.16083575895566854, 'Total loss': 0.16083575895566854}
2022-12-05 22:37:30,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:30,873 INFO:     Epoch: 45
2022-12-05 22:37:31,672 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4292535927485336, 'Total loss': 0.4292535927485336} | train loss {'Reaction outcome loss': 0.16062261753024593, 'Total loss': 0.16062261753024593}
2022-12-05 22:37:31,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:31,673 INFO:     Epoch: 46
2022-12-05 22:37:32,470 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42981026660312305, 'Total loss': 0.42981026660312305} | train loss {'Reaction outcome loss': 0.15813525827721722, 'Total loss': 0.15813525827721722}
2022-12-05 22:37:32,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:32,470 INFO:     Epoch: 47
2022-12-05 22:37:33,268 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4135535252703862, 'Total loss': 0.4135535252703862} | train loss {'Reaction outcome loss': 0.15933720123833947, 'Total loss': 0.15933720123833947}
2022-12-05 22:37:33,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:33,268 INFO:     Epoch: 48
2022-12-05 22:37:34,072 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4266120215708559, 'Total loss': 0.4266120215708559} | train loss {'Reaction outcome loss': 0.15695944051408478, 'Total loss': 0.15695944051408478}
2022-12-05 22:37:34,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:34,072 INFO:     Epoch: 49
2022-12-05 22:37:34,870 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4246002906425433, 'Total loss': 0.4246002906425433} | train loss {'Reaction outcome loss': 0.15784220668231888, 'Total loss': 0.15784220668231888}
2022-12-05 22:37:34,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:34,871 INFO:     Epoch: 50
2022-12-05 22:37:35,669 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42716602998023684, 'Total loss': 0.42716602998023684} | train loss {'Reaction outcome loss': 0.1567649831770048, 'Total loss': 0.1567649831770048}
2022-12-05 22:37:35,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:35,670 INFO:     Epoch: 51
2022-12-05 22:37:36,467 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4290058409625834, 'Total loss': 0.4290058409625834} | train loss {'Reaction outcome loss': 0.15306271085019915, 'Total loss': 0.15306271085019915}
2022-12-05 22:37:36,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:36,467 INFO:     Epoch: 52
2022-12-05 22:37:37,264 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42680120027878066, 'Total loss': 0.42680120027878066} | train loss {'Reaction outcome loss': 0.15079750942306652, 'Total loss': 0.15079750942306652}
2022-12-05 22:37:37,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:37,264 INFO:     Epoch: 53
2022-12-05 22:37:38,063 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4309252446348017, 'Total loss': 0.4309252446348017} | train loss {'Reaction outcome loss': 0.15002154120274128, 'Total loss': 0.15002154120274128}
2022-12-05 22:37:38,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:38,063 INFO:     Epoch: 54
2022-12-05 22:37:38,860 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4270027967339212, 'Total loss': 0.4270027967339212} | train loss {'Reaction outcome loss': 0.15124179160357604, 'Total loss': 0.15124179160357604}
2022-12-05 22:37:38,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:38,861 INFO:     Epoch: 55
2022-12-05 22:37:39,664 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43564151329073036, 'Total loss': 0.43564151329073036} | train loss {'Reaction outcome loss': 0.15028214351754757, 'Total loss': 0.15028214351754757}
2022-12-05 22:37:39,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:39,665 INFO:     Epoch: 56
2022-12-05 22:37:40,463 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43989554386247287, 'Total loss': 0.43989554386247287} | train loss {'Reaction outcome loss': 0.1501843817607169, 'Total loss': 0.1501843817607169}
2022-12-05 22:37:40,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:40,463 INFO:     Epoch: 57
2022-12-05 22:37:41,262 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41411077535965224, 'Total loss': 0.41411077535965224} | train loss {'Reaction outcome loss': 0.15114664940554048, 'Total loss': 0.15114664940554048}
2022-12-05 22:37:41,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:41,262 INFO:     Epoch: 58
2022-12-05 22:37:42,063 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4396485083482482, 'Total loss': 0.4396485083482482} | train loss {'Reaction outcome loss': 0.14669917168981966, 'Total loss': 0.14669917168981966}
2022-12-05 22:37:42,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:42,063 INFO:     Epoch: 59
2022-12-05 22:37:42,861 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42357715913517907, 'Total loss': 0.42357715913517907} | train loss {'Reaction outcome loss': 0.14359930502776538, 'Total loss': 0.14359930502776538}
2022-12-05 22:37:42,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:42,861 INFO:     Epoch: 60
2022-12-05 22:37:43,662 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41581041941588576, 'Total loss': 0.41581041941588576} | train loss {'Reaction outcome loss': 0.14538851070157702, 'Total loss': 0.14538851070157702}
2022-12-05 22:37:43,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:43,662 INFO:     Epoch: 61
2022-12-05 22:37:44,466 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42525763369419356, 'Total loss': 0.42525763369419356} | train loss {'Reaction outcome loss': 0.1470449021041033, 'Total loss': 0.1470449021041033}
2022-12-05 22:37:44,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:44,466 INFO:     Epoch: 62
2022-12-05 22:37:45,275 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4459301541474732, 'Total loss': 0.4459301541474732} | train loss {'Reaction outcome loss': 0.1466282286921576, 'Total loss': 0.1466282286921576}
2022-12-05 22:37:45,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:45,275 INFO:     Epoch: 63
2022-12-05 22:37:46,078 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44083843820474367, 'Total loss': 0.44083843820474367} | train loss {'Reaction outcome loss': 0.14244605805124005, 'Total loss': 0.14244605805124005}
2022-12-05 22:37:46,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:46,079 INFO:     Epoch: 64
2022-12-05 22:37:46,882 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4322970876978202, 'Total loss': 0.4322970876978202} | train loss {'Reaction outcome loss': 0.1452570622373793, 'Total loss': 0.1452570622373793}
2022-12-05 22:37:46,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:46,882 INFO:     Epoch: 65
2022-12-05 22:37:47,688 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43523710695180023, 'Total loss': 0.43523710695180023} | train loss {'Reaction outcome loss': 0.1424598408442351, 'Total loss': 0.1424598408442351}
2022-12-05 22:37:47,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:47,689 INFO:     Epoch: 66
2022-12-05 22:37:48,496 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43217324634844606, 'Total loss': 0.43217324634844606} | train loss {'Reaction outcome loss': 0.14346607151861873, 'Total loss': 0.14346607151861873}
2022-12-05 22:37:48,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:48,496 INFO:     Epoch: 67
2022-12-05 22:37:49,303 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4343443831259554, 'Total loss': 0.4343443831259554} | train loss {'Reaction outcome loss': 0.14281789702363312, 'Total loss': 0.14281789702363312}
2022-12-05 22:37:49,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:49,303 INFO:     Epoch: 68
2022-12-05 22:37:50,107 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4315353415229104, 'Total loss': 0.4315353415229104} | train loss {'Reaction outcome loss': 0.13713707089153748, 'Total loss': 0.13713707089153748}
2022-12-05 22:37:50,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:50,107 INFO:     Epoch: 69
2022-12-05 22:37:50,914 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42277801934291015, 'Total loss': 0.42277801934291015} | train loss {'Reaction outcome loss': 0.1392564596232748, 'Total loss': 0.1392564596232748}
2022-12-05 22:37:50,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:50,914 INFO:     Epoch: 70
2022-12-05 22:37:51,721 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.430694057521495, 'Total loss': 0.430694057521495} | train loss {'Reaction outcome loss': 0.13924241271020182, 'Total loss': 0.13924241271020182}
2022-12-05 22:37:51,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:51,721 INFO:     Epoch: 71
2022-12-05 22:37:52,526 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4318275864828717, 'Total loss': 0.4318275864828717} | train loss {'Reaction outcome loss': 0.13977933663784736, 'Total loss': 0.13977933663784736}
2022-12-05 22:37:52,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:52,526 INFO:     Epoch: 72
2022-12-05 22:37:53,329 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42456556687300856, 'Total loss': 0.42456556687300856} | train loss {'Reaction outcome loss': 0.1391855614304903, 'Total loss': 0.1391855614304903}
2022-12-05 22:37:53,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:53,330 INFO:     Epoch: 73
2022-12-05 22:37:54,131 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42194806987589056, 'Total loss': 0.42194806987589056} | train loss {'Reaction outcome loss': 0.14048007024722475, 'Total loss': 0.14048007024722475}
2022-12-05 22:37:54,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:54,131 INFO:     Epoch: 74
2022-12-05 22:37:54,939 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42531403933059087, 'Total loss': 0.42531403933059087} | train loss {'Reaction outcome loss': 0.1378317540286169, 'Total loss': 0.1378317540286169}
2022-12-05 22:37:54,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:54,939 INFO:     Epoch: 75
2022-12-05 22:37:55,739 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42318787341090763, 'Total loss': 0.42318787341090763} | train loss {'Reaction outcome loss': 0.13497033390036273, 'Total loss': 0.13497033390036273}
2022-12-05 22:37:55,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:55,739 INFO:     Epoch: 76
2022-12-05 22:37:56,539 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4300908859480511, 'Total loss': 0.4300908859480511} | train loss {'Reaction outcome loss': 0.13631803576173562, 'Total loss': 0.13631803576173562}
2022-12-05 22:37:56,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:56,539 INFO:     Epoch: 77
2022-12-05 22:37:57,343 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44058381529016927, 'Total loss': 0.44058381529016927} | train loss {'Reaction outcome loss': 0.13574139017521614, 'Total loss': 0.13574139017521614}
2022-12-05 22:37:57,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:57,344 INFO:     Epoch: 78
2022-12-05 22:37:58,149 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43193471330133354, 'Total loss': 0.43193471330133354} | train loss {'Reaction outcome loss': 0.13389241963534826, 'Total loss': 0.13389241963534826}
2022-12-05 22:37:58,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:58,149 INFO:     Epoch: 79
2022-12-05 22:37:58,949 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43223957666619256, 'Total loss': 0.43223957666619256} | train loss {'Reaction outcome loss': 0.13235581823204073, 'Total loss': 0.13235581823204073}
2022-12-05 22:37:58,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:58,950 INFO:     Epoch: 80
2022-12-05 22:37:59,750 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42182526872916654, 'Total loss': 0.42182526872916654} | train loss {'Reaction outcome loss': 0.13314957376719722, 'Total loss': 0.13314957376719722}
2022-12-05 22:37:59,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:37:59,750 INFO:     Epoch: 81
2022-12-05 22:38:00,551 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4233349839394743, 'Total loss': 0.4233349839394743} | train loss {'Reaction outcome loss': 0.13262739070060273, 'Total loss': 0.13262739070060273}
2022-12-05 22:38:00,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:00,551 INFO:     Epoch: 82
2022-12-05 22:38:01,350 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4446056778119369, 'Total loss': 0.4446056778119369} | train loss {'Reaction outcome loss': 0.13127834956356954, 'Total loss': 0.13127834956356954}
2022-12-05 22:38:01,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:01,350 INFO:     Epoch: 83
2022-12-05 22:38:02,150 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4287955036217516, 'Total loss': 0.4287955036217516} | train loss {'Reaction outcome loss': 0.1313969815044754, 'Total loss': 0.1313969815044754}
2022-12-05 22:38:02,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:02,150 INFO:     Epoch: 84
2022-12-05 22:38:02,949 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4301842080259865, 'Total loss': 0.4301842080259865} | train loss {'Reaction outcome loss': 0.13499689090155786, 'Total loss': 0.13499689090155786}
2022-12-05 22:38:02,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:02,949 INFO:     Epoch: 85
2022-12-05 22:38:03,748 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42757653106342663, 'Total loss': 0.42757653106342663} | train loss {'Reaction outcome loss': 0.13205234164131746, 'Total loss': 0.13205234164131746}
2022-12-05 22:38:03,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:03,749 INFO:     Epoch: 86
2022-12-05 22:38:04,551 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4378201551735401, 'Total loss': 0.4378201551735401} | train loss {'Reaction outcome loss': 0.1317054720054711, 'Total loss': 0.1317054720054711}
2022-12-05 22:38:04,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:04,551 INFO:     Epoch: 87
2022-12-05 22:38:05,353 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4428353810852224, 'Total loss': 0.4428353810852224} | train loss {'Reaction outcome loss': 0.13004672714704346, 'Total loss': 0.13004672714704346}
2022-12-05 22:38:05,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:05,353 INFO:     Epoch: 88
2022-12-05 22:38:06,154 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43142800812016835, 'Total loss': 0.43142800812016835} | train loss {'Reaction outcome loss': 0.1324977620782691, 'Total loss': 0.1324977620782691}
2022-12-05 22:38:06,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:06,155 INFO:     Epoch: 89
2022-12-05 22:38:06,956 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4265152297236703, 'Total loss': 0.4265152297236703} | train loss {'Reaction outcome loss': 0.1316184489349384, 'Total loss': 0.1316184489349384}
2022-12-05 22:38:06,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:06,957 INFO:     Epoch: 90
2022-12-05 22:38:07,757 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4259367451410402, 'Total loss': 0.4259367451410402} | train loss {'Reaction outcome loss': 0.12937291075039895, 'Total loss': 0.12937291075039895}
2022-12-05 22:38:07,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:07,758 INFO:     Epoch: 91
2022-12-05 22:38:08,559 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4361072214828296, 'Total loss': 0.4361072214828296} | train loss {'Reaction outcome loss': 0.13002648363415634, 'Total loss': 0.13002648363415634}
2022-12-05 22:38:08,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:08,559 INFO:     Epoch: 92
2022-12-05 22:38:09,362 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44891858981414273, 'Total loss': 0.44891858981414273} | train loss {'Reaction outcome loss': 0.12976763685864787, 'Total loss': 0.12976763685864787}
2022-12-05 22:38:09,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:09,363 INFO:     Epoch: 93
2022-12-05 22:38:10,173 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.41912508789788594, 'Total loss': 0.41912508789788594} | train loss {'Reaction outcome loss': 0.12944654834967467, 'Total loss': 0.12944654834967467}
2022-12-05 22:38:10,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:10,174 INFO:     Epoch: 94
2022-12-05 22:38:10,977 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4446917169473388, 'Total loss': 0.4446917169473388} | train loss {'Reaction outcome loss': 0.12775663479096105, 'Total loss': 0.12775663479096105}
2022-12-05 22:38:10,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:10,977 INFO:     Epoch: 95
2022-12-05 22:38:11,777 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4189160479740663, 'Total loss': 0.4189160479740663} | train loss {'Reaction outcome loss': 0.12942202417405263, 'Total loss': 0.12942202417405263}
2022-12-05 22:38:11,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:11,777 INFO:     Epoch: 96
2022-12-05 22:38:12,580 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4206243979490616, 'Total loss': 0.4206243979490616} | train loss {'Reaction outcome loss': 0.12616398518214061, 'Total loss': 0.12616398518214061}
2022-12-05 22:38:12,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:12,580 INFO:     Epoch: 97
2022-12-05 22:38:13,382 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44379328699274495, 'Total loss': 0.44379328699274495} | train loss {'Reaction outcome loss': 0.1228498857122876, 'Total loss': 0.1228498857122876}
2022-12-05 22:38:13,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:13,382 INFO:     Epoch: 98
2022-12-05 22:38:14,185 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4417200195179744, 'Total loss': 0.4417200195179744} | train loss {'Reaction outcome loss': 0.1276454507155464, 'Total loss': 0.1276454507155464}
2022-12-05 22:38:14,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:14,185 INFO:     Epoch: 99
2022-12-05 22:38:14,989 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43344575369899924, 'Total loss': 0.43344575369899924} | train loss {'Reaction outcome loss': 0.1253310047848631, 'Total loss': 0.1253310047848631}
2022-12-05 22:38:14,989 INFO:     Best model found after epoch 24 of 100.
2022-12-05 22:38:14,989 INFO:   Done with stage: TRAINING
2022-12-05 22:38:14,989 INFO:   Starting stage: EVALUATION
2022-12-05 22:38:15,110 INFO:   Done with stage: EVALUATION
2022-12-05 22:38:15,110 INFO:   Leaving out SEQ value Fold_8
2022-12-05 22:38:15,122 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:38:15,122 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:38:15,764 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:38:15,764 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:38:15,832 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:38:15,832 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:38:15,832 INFO:     No hyperparam tuning for this model
2022-12-05 22:38:15,832 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:38:15,832 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:38:15,833 INFO:     None feature selector for col prot
2022-12-05 22:38:15,833 INFO:     None feature selector for col prot
2022-12-05 22:38:15,833 INFO:     None feature selector for col prot
2022-12-05 22:38:15,834 INFO:     None feature selector for col chem
2022-12-05 22:38:15,834 INFO:     None feature selector for col chem
2022-12-05 22:38:15,834 INFO:     None feature selector for col chem
2022-12-05 22:38:15,834 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:38:15,834 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:38:15,836 INFO:     Number of params in model 215821
2022-12-05 22:38:15,839 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:38:15,839 INFO:   Starting stage: TRAINING
2022-12-05 22:38:15,900 INFO:     Val loss before train {'Reaction outcome loss': 0.9689455113627694, 'Total loss': 0.9689455113627694}
2022-12-05 22:38:15,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:15,900 INFO:     Epoch: 0
2022-12-05 22:38:16,691 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5859287482771006, 'Total loss': 0.5859287482771006} | train loss {'Reaction outcome loss': 0.7920562633446284, 'Total loss': 0.7920562633446284}
2022-12-05 22:38:16,691 INFO:     Found new best model at epoch 0
2022-12-05 22:38:16,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:16,692 INFO:     Epoch: 1
2022-12-05 22:38:17,481 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5126697051931511, 'Total loss': 0.5126697051931511} | train loss {'Reaction outcome loss': 0.5258976441256854, 'Total loss': 0.5258976441256854}
2022-12-05 22:38:17,481 INFO:     Found new best model at epoch 1
2022-12-05 22:38:17,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:17,482 INFO:     Epoch: 2
2022-12-05 22:38:18,273 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48535079847682605, 'Total loss': 0.48535079847682605} | train loss {'Reaction outcome loss': 0.45960029862364943, 'Total loss': 0.45960029862364943}
2022-12-05 22:38:18,274 INFO:     Found new best model at epoch 2
2022-12-05 22:38:18,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:18,275 INFO:     Epoch: 3
2022-12-05 22:38:19,069 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4658613140610131, 'Total loss': 0.4658613140610131} | train loss {'Reaction outcome loss': 0.4158766366389333, 'Total loss': 0.4158766366389333}
2022-12-05 22:38:19,069 INFO:     Found new best model at epoch 3
2022-12-05 22:38:19,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:19,070 INFO:     Epoch: 4
2022-12-05 22:38:19,861 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4772852049632506, 'Total loss': 0.4772852049632506} | train loss {'Reaction outcome loss': 0.38806308690382507, 'Total loss': 0.38806308690382507}
2022-12-05 22:38:19,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:19,862 INFO:     Epoch: 5
2022-12-05 22:38:20,656 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.44077304208820517, 'Total loss': 0.44077304208820517} | train loss {'Reaction outcome loss': 0.3681803252015795, 'Total loss': 0.3681803252015795}
2022-12-05 22:38:20,656 INFO:     Found new best model at epoch 5
2022-12-05 22:38:20,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:20,657 INFO:     Epoch: 6
2022-12-05 22:38:21,449 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4150970693339001, 'Total loss': 0.4150970693339001} | train loss {'Reaction outcome loss': 0.3434969590938821, 'Total loss': 0.3434969590938821}
2022-12-05 22:38:21,449 INFO:     Found new best model at epoch 6
2022-12-05 22:38:21,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:21,450 INFO:     Epoch: 7
2022-12-05 22:38:22,241 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4420044513588602, 'Total loss': 0.4420044513588602} | train loss {'Reaction outcome loss': 0.3274175767691768, 'Total loss': 0.3274175767691768}
2022-12-05 22:38:22,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:22,241 INFO:     Epoch: 8
2022-12-05 22:38:23,032 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4225967438383536, 'Total loss': 0.4225967438383536} | train loss {'Reaction outcome loss': 0.3142858433784271, 'Total loss': 0.3142858433784271}
2022-12-05 22:38:23,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:23,033 INFO:     Epoch: 9
2022-12-05 22:38:23,824 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42779185521331703, 'Total loss': 0.42779185521331703} | train loss {'Reaction outcome loss': 0.2983546893359447, 'Total loss': 0.2983546893359447}
2022-12-05 22:38:23,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:23,824 INFO:     Epoch: 10
2022-12-05 22:38:24,616 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42599219286983664, 'Total loss': 0.42599219286983664} | train loss {'Reaction outcome loss': 0.28977791581835066, 'Total loss': 0.28977791581835066}
2022-12-05 22:38:24,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:24,617 INFO:     Epoch: 11
2022-12-05 22:38:25,411 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4322748573666269, 'Total loss': 0.4322748573666269} | train loss {'Reaction outcome loss': 0.2778385915014209, 'Total loss': 0.2778385915014209}
2022-12-05 22:38:25,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:25,411 INFO:     Epoch: 12
2022-12-05 22:38:26,213 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43098704008893535, 'Total loss': 0.43098704008893535} | train loss {'Reaction outcome loss': 0.26617292138386744, 'Total loss': 0.26617292138386744}
2022-12-05 22:38:26,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:26,213 INFO:     Epoch: 13
2022-12-05 22:38:27,008 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4236205667257309, 'Total loss': 0.4236205667257309} | train loss {'Reaction outcome loss': 0.2546730837347556, 'Total loss': 0.2546730837347556}
2022-12-05 22:38:27,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:27,008 INFO:     Epoch: 14
2022-12-05 22:38:27,799 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4062862050804225, 'Total loss': 0.4062862050804225} | train loss {'Reaction outcome loss': 0.2481246654172333, 'Total loss': 0.2481246654172333}
2022-12-05 22:38:27,799 INFO:     Found new best model at epoch 14
2022-12-05 22:38:27,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:27,800 INFO:     Epoch: 15
2022-12-05 22:38:28,591 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4051347535780885, 'Total loss': 0.4051347535780885} | train loss {'Reaction outcome loss': 0.2405206835847728, 'Total loss': 0.2405206835847728}
2022-12-05 22:38:28,591 INFO:     Found new best model at epoch 15
2022-12-05 22:38:28,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:28,592 INFO:     Epoch: 16
2022-12-05 22:38:29,384 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.421712975949049, 'Total loss': 0.421712975949049} | train loss {'Reaction outcome loss': 0.2327538998151312, 'Total loss': 0.2327538998151312}
2022-12-05 22:38:29,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:29,384 INFO:     Epoch: 17
2022-12-05 22:38:30,179 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.411237952045419, 'Total loss': 0.411237952045419} | train loss {'Reaction outcome loss': 0.22673798635297893, 'Total loss': 0.22673798635297893}
2022-12-05 22:38:30,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:30,180 INFO:     Epoch: 18
2022-12-05 22:38:30,972 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40409859557720745, 'Total loss': 0.40409859557720745} | train loss {'Reaction outcome loss': 0.21778792241702274, 'Total loss': 0.21778792241702274}
2022-12-05 22:38:30,972 INFO:     Found new best model at epoch 18
2022-12-05 22:38:30,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:30,973 INFO:     Epoch: 19
2022-12-05 22:38:31,770 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4139825478196144, 'Total loss': 0.4139825478196144} | train loss {'Reaction outcome loss': 0.2151153051123327, 'Total loss': 0.2151153051123327}
2022-12-05 22:38:31,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:31,770 INFO:     Epoch: 20
2022-12-05 22:38:32,563 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4175844537940892, 'Total loss': 0.4175844537940892} | train loss {'Reaction outcome loss': 0.20761008759846492, 'Total loss': 0.20761008759846492}
2022-12-05 22:38:32,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:32,564 INFO:     Epoch: 21
2022-12-05 22:38:33,354 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41149058076553047, 'Total loss': 0.41149058076553047} | train loss {'Reaction outcome loss': 0.20145040876707251, 'Total loss': 0.20145040876707251}
2022-12-05 22:38:33,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:33,355 INFO:     Epoch: 22
2022-12-05 22:38:34,146 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44693965126167645, 'Total loss': 0.44693965126167645} | train loss {'Reaction outcome loss': 0.1955363821390332, 'Total loss': 0.1955363821390332}
2022-12-05 22:38:34,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:34,147 INFO:     Epoch: 23
2022-12-05 22:38:34,938 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4301659844138406, 'Total loss': 0.4301659844138406} | train loss {'Reaction outcome loss': 0.19216099662744268, 'Total loss': 0.19216099662744268}
2022-12-05 22:38:34,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:34,939 INFO:     Epoch: 24
2022-12-05 22:38:35,732 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41207456021485006, 'Total loss': 0.41207456021485006} | train loss {'Reaction outcome loss': 0.1905739700459704, 'Total loss': 0.1905739700459704}
2022-12-05 22:38:35,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:35,733 INFO:     Epoch: 25
2022-12-05 22:38:36,523 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42900983548977156, 'Total loss': 0.42900983548977156} | train loss {'Reaction outcome loss': 0.18517001979813283, 'Total loss': 0.18517001979813283}
2022-12-05 22:38:36,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:36,523 INFO:     Epoch: 26
2022-12-05 22:38:37,313 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42628188634460623, 'Total loss': 0.42628188634460623} | train loss {'Reaction outcome loss': 0.18095790722540447, 'Total loss': 0.18095790722540447}
2022-12-05 22:38:37,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:37,314 INFO:     Epoch: 27
2022-12-05 22:38:38,105 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.440491574477743, 'Total loss': 0.440491574477743} | train loss {'Reaction outcome loss': 0.17834442025240588, 'Total loss': 0.17834442025240588}
2022-12-05 22:38:38,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:38,106 INFO:     Epoch: 28
2022-12-05 22:38:38,897 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4209476101466201, 'Total loss': 0.4209476101466201} | train loss {'Reaction outcome loss': 0.17431532722346638, 'Total loss': 0.17431532722346638}
2022-12-05 22:38:38,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:38,898 INFO:     Epoch: 29
2022-12-05 22:38:39,689 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4380106348544359, 'Total loss': 0.4380106348544359} | train loss {'Reaction outcome loss': 0.17072687293497885, 'Total loss': 0.17072687293497885}
2022-12-05 22:38:39,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:39,690 INFO:     Epoch: 30
2022-12-05 22:38:40,486 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4402906501835043, 'Total loss': 0.4402906501835043} | train loss {'Reaction outcome loss': 0.16787253090617607, 'Total loss': 0.16787253090617607}
2022-12-05 22:38:40,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:40,487 INFO:     Epoch: 31
2022-12-05 22:38:41,280 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4500956592912024, 'Total loss': 0.4500956592912024} | train loss {'Reaction outcome loss': 0.1664337570722006, 'Total loss': 0.1664337570722006}
2022-12-05 22:38:41,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:41,280 INFO:     Epoch: 32
2022-12-05 22:38:42,072 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43343807993964717, 'Total loss': 0.43343807993964717} | train loss {'Reaction outcome loss': 0.1626896964043987, 'Total loss': 0.1626896964043987}
2022-12-05 22:38:42,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:42,073 INFO:     Epoch: 33
2022-12-05 22:38:42,867 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4583203379403461, 'Total loss': 0.4583203379403461} | train loss {'Reaction outcome loss': 0.16255992139328498, 'Total loss': 0.16255992139328498}
2022-12-05 22:38:42,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:42,867 INFO:     Epoch: 34
2022-12-05 22:38:43,661 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43300248377702455, 'Total loss': 0.43300248377702455} | train loss {'Reaction outcome loss': 0.1587045249206071, 'Total loss': 0.1587045249206071}
2022-12-05 22:38:43,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:43,661 INFO:     Epoch: 35
2022-12-05 22:38:44,453 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4557922567156228, 'Total loss': 0.4557922567156228} | train loss {'Reaction outcome loss': 0.15421647570875227, 'Total loss': 0.15421647570875227}
2022-12-05 22:38:44,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:44,453 INFO:     Epoch: 36
2022-12-05 22:38:45,248 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4448944665491581, 'Total loss': 0.4448944665491581} | train loss {'Reaction outcome loss': 0.15289021874112743, 'Total loss': 0.15289021874112743}
2022-12-05 22:38:45,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:45,248 INFO:     Epoch: 37
2022-12-05 22:38:46,047 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4607809373092922, 'Total loss': 0.4607809373092922} | train loss {'Reaction outcome loss': 0.1524430932134998, 'Total loss': 0.1524430932134998}
2022-12-05 22:38:46,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:46,048 INFO:     Epoch: 38
2022-12-05 22:38:46,841 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43026617067781364, 'Total loss': 0.43026617067781364} | train loss {'Reaction outcome loss': 0.14983025928008922, 'Total loss': 0.14983025928008922}
2022-12-05 22:38:46,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:46,842 INFO:     Epoch: 39
2022-12-05 22:38:47,633 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4566642829979008, 'Total loss': 0.4566642829979008} | train loss {'Reaction outcome loss': 0.1485709967661877, 'Total loss': 0.1485709967661877}
2022-12-05 22:38:47,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:47,633 INFO:     Epoch: 40
2022-12-05 22:38:48,426 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45007476481524383, 'Total loss': 0.45007476481524383} | train loss {'Reaction outcome loss': 0.14800034151697644, 'Total loss': 0.14800034151697644}
2022-12-05 22:38:48,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:48,427 INFO:     Epoch: 41
2022-12-05 22:38:49,224 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4597289745103229, 'Total loss': 0.4597289745103229} | train loss {'Reaction outcome loss': 0.14591666358161945, 'Total loss': 0.14591666358161945}
2022-12-05 22:38:49,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:49,226 INFO:     Epoch: 42
2022-12-05 22:38:50,022 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4453945207324895, 'Total loss': 0.4453945207324895} | train loss {'Reaction outcome loss': 0.14607851197372895, 'Total loss': 0.14607851197372895}
2022-12-05 22:38:50,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:50,022 INFO:     Epoch: 43
2022-12-05 22:38:50,818 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44494816864078696, 'Total loss': 0.44494816864078696} | train loss {'Reaction outcome loss': 0.14272255114450746, 'Total loss': 0.14272255114450746}
2022-12-05 22:38:50,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:50,819 INFO:     Epoch: 44
2022-12-05 22:38:51,612 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4518355815248056, 'Total loss': 0.4518355815248056} | train loss {'Reaction outcome loss': 0.1415856077278755, 'Total loss': 0.1415856077278755}
2022-12-05 22:38:51,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:51,612 INFO:     Epoch: 45
2022-12-05 22:38:52,404 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.44579300487583334, 'Total loss': 0.44579300487583334} | train loss {'Reaction outcome loss': 0.1397577853683306, 'Total loss': 0.1397577853683306}
2022-12-05 22:38:52,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:52,404 INFO:     Epoch: 46
2022-12-05 22:38:53,197 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45215492424639786, 'Total loss': 0.45215492424639786} | train loss {'Reaction outcome loss': 0.1375561865008607, 'Total loss': 0.1375561865008607}
2022-12-05 22:38:53,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:53,197 INFO:     Epoch: 47
2022-12-05 22:38:53,991 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4496520364826376, 'Total loss': 0.4496520364826376} | train loss {'Reaction outcome loss': 0.13547008083182938, 'Total loss': 0.13547008083182938}
2022-12-05 22:38:53,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:53,992 INFO:     Epoch: 48
2022-12-05 22:38:54,790 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47880627892234107, 'Total loss': 0.47880627892234107} | train loss {'Reaction outcome loss': 0.1371433805560275, 'Total loss': 0.1371433805560275}
2022-12-05 22:38:54,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:54,790 INFO:     Epoch: 49
2022-12-05 22:38:55,583 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4657858796417713, 'Total loss': 0.4657858796417713} | train loss {'Reaction outcome loss': 0.1357945045912448, 'Total loss': 0.1357945045912448}
2022-12-05 22:38:55,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:55,584 INFO:     Epoch: 50
2022-12-05 22:38:56,376 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46344765021719714, 'Total loss': 0.46344765021719714} | train loss {'Reaction outcome loss': 0.13675806451664896, 'Total loss': 0.13675806451664896}
2022-12-05 22:38:56,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:56,376 INFO:     Epoch: 51
2022-12-05 22:38:57,168 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4429501610046083, 'Total loss': 0.4429501610046083} | train loss {'Reaction outcome loss': 0.13405894571725202, 'Total loss': 0.13405894571725202}
2022-12-05 22:38:57,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:57,169 INFO:     Epoch: 52
2022-12-05 22:38:57,961 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4545137391171672, 'Total loss': 0.4545137391171672} | train loss {'Reaction outcome loss': 0.13241524789862485, 'Total loss': 0.13241524789862485}
2022-12-05 22:38:57,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:57,961 INFO:     Epoch: 53
2022-12-05 22:38:58,755 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44508588923649356, 'Total loss': 0.44508588923649356} | train loss {'Reaction outcome loss': 0.13141805509447443, 'Total loss': 0.13141805509447443}
2022-12-05 22:38:58,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:58,755 INFO:     Epoch: 54
2022-12-05 22:38:59,547 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43648282294584945, 'Total loss': 0.43648282294584945} | train loss {'Reaction outcome loss': 0.12936845375415013, 'Total loss': 0.12936845375415013}
2022-12-05 22:38:59,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:38:59,547 INFO:     Epoch: 55
2022-12-05 22:39:00,341 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.449132346145978, 'Total loss': 0.449132346145978} | train loss {'Reaction outcome loss': 0.13014362033608617, 'Total loss': 0.13014362033608617}
2022-12-05 22:39:00,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:00,341 INFO:     Epoch: 56
2022-12-05 22:39:01,135 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4503257481211966, 'Total loss': 0.4503257481211966} | train loss {'Reaction outcome loss': 0.12821940302240606, 'Total loss': 0.12821940302240606}
2022-12-05 22:39:01,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:01,135 INFO:     Epoch: 57
2022-12-05 22:39:01,926 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4718877720561894, 'Total loss': 0.4718877720561894} | train loss {'Reaction outcome loss': 0.12646583734194236, 'Total loss': 0.12646583734194236}
2022-12-05 22:39:01,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:01,927 INFO:     Epoch: 58
2022-12-05 22:39:02,725 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45904203165661206, 'Total loss': 0.45904203165661206} | train loss {'Reaction outcome loss': 0.12804122337577295, 'Total loss': 0.12804122337577295}
2022-12-05 22:39:02,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:02,725 INFO:     Epoch: 59
2022-12-05 22:39:03,519 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4578064622526819, 'Total loss': 0.4578064622526819} | train loss {'Reaction outcome loss': 0.12682192054558164, 'Total loss': 0.12682192054558164}
2022-12-05 22:39:03,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:03,520 INFO:     Epoch: 60
2022-12-05 22:39:04,313 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44813267852772365, 'Total loss': 0.44813267852772365} | train loss {'Reaction outcome loss': 0.12553450888669004, 'Total loss': 0.12553450888669004}
2022-12-05 22:39:04,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:04,314 INFO:     Epoch: 61
2022-12-05 22:39:05,106 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4497071040624922, 'Total loss': 0.4497071040624922} | train loss {'Reaction outcome loss': 0.12254739777774228, 'Total loss': 0.12254739777774228}
2022-12-05 22:39:05,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:05,106 INFO:     Epoch: 62
2022-12-05 22:39:05,900 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4712292995642532, 'Total loss': 0.4712292995642532} | train loss {'Reaction outcome loss': 0.1260798326028245, 'Total loss': 0.1260798326028245}
2022-12-05 22:39:05,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:05,900 INFO:     Epoch: 63
2022-12-05 22:39:06,693 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46617734737016936, 'Total loss': 0.46617734737016936} | train loss {'Reaction outcome loss': 0.12344788195451303, 'Total loss': 0.12344788195451303}
2022-12-05 22:39:06,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:06,693 INFO:     Epoch: 64
2022-12-05 22:39:07,485 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4742667956108397, 'Total loss': 0.4742667956108397} | train loss {'Reaction outcome loss': 0.12221024109012618, 'Total loss': 0.12221024109012618}
2022-12-05 22:39:07,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:07,485 INFO:     Epoch: 65
2022-12-05 22:39:08,276 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48028580810536037, 'Total loss': 0.48028580810536037} | train loss {'Reaction outcome loss': 0.12279523248423119, 'Total loss': 0.12279523248423119}
2022-12-05 22:39:08,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:08,277 INFO:     Epoch: 66
2022-12-05 22:39:09,068 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4806111001155593, 'Total loss': 0.4806111001155593} | train loss {'Reaction outcome loss': 0.12236570048393035, 'Total loss': 0.12236570048393035}
2022-12-05 22:39:09,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:09,068 INFO:     Epoch: 67
2022-12-05 22:39:09,859 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47260604121468286, 'Total loss': 0.47260604121468286} | train loss {'Reaction outcome loss': 0.12304588250663816, 'Total loss': 0.12304588250663816}
2022-12-05 22:39:09,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:09,860 INFO:     Epoch: 68
2022-12-05 22:39:10,651 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47061715986240993, 'Total loss': 0.47061715986240993} | train loss {'Reaction outcome loss': 0.11980855222791434, 'Total loss': 0.11980855222791434}
2022-12-05 22:39:10,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:10,651 INFO:     Epoch: 69
2022-12-05 22:39:11,443 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4487903744024648, 'Total loss': 0.4487903744024648} | train loss {'Reaction outcome loss': 0.12011978422120517, 'Total loss': 0.12011978422120517}
2022-12-05 22:39:11,443 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:11,443 INFO:     Epoch: 70
2022-12-05 22:39:12,234 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4821114709431475, 'Total loss': 0.4821114709431475} | train loss {'Reaction outcome loss': 0.1198383853979865, 'Total loss': 0.1198383853979865}
2022-12-05 22:39:12,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:12,234 INFO:     Epoch: 71
2022-12-05 22:39:13,026 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4548024565658786, 'Total loss': 0.4548024565658786} | train loss {'Reaction outcome loss': 0.12050225536662097, 'Total loss': 0.12050225536662097}
2022-12-05 22:39:13,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:13,026 INFO:     Epoch: 72
2022-12-05 22:39:13,816 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47602006183429196, 'Total loss': 0.47602006183429196} | train loss {'Reaction outcome loss': 0.11983980743252501, 'Total loss': 0.11983980743252501}
2022-12-05 22:39:13,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:13,817 INFO:     Epoch: 73
2022-12-05 22:39:14,607 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4754966615953229, 'Total loss': 0.4754966615953229} | train loss {'Reaction outcome loss': 0.11698831323990408, 'Total loss': 0.11698831323990408}
2022-12-05 22:39:14,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:14,607 INFO:     Epoch: 74
2022-12-05 22:39:15,398 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46828836879946967, 'Total loss': 0.46828836879946967} | train loss {'Reaction outcome loss': 0.11666599452419549, 'Total loss': 0.11666599452419549}
2022-12-05 22:39:15,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:15,399 INFO:     Epoch: 75
2022-12-05 22:39:16,192 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45852187512950465, 'Total loss': 0.45852187512950465} | train loss {'Reaction outcome loss': 0.11792457876156788, 'Total loss': 0.11792457876156788}
2022-12-05 22:39:16,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:16,192 INFO:     Epoch: 76
2022-12-05 22:39:16,983 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45838177153332665, 'Total loss': 0.45838177153332665} | train loss {'Reaction outcome loss': 0.11771687983098078, 'Total loss': 0.11771687983098078}
2022-12-05 22:39:16,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:16,983 INFO:     Epoch: 77
2022-12-05 22:39:17,773 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46688820751891896, 'Total loss': 0.46688820751891896} | train loss {'Reaction outcome loss': 0.11807150147018992, 'Total loss': 0.11807150147018992}
2022-12-05 22:39:17,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:17,773 INFO:     Epoch: 78
2022-12-05 22:39:18,563 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4669479148631746, 'Total loss': 0.4669479148631746} | train loss {'Reaction outcome loss': 0.11536712229479941, 'Total loss': 0.11536712229479941}
2022-12-05 22:39:18,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:18,564 INFO:     Epoch: 79
2022-12-05 22:39:19,354 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4803442152386362, 'Total loss': 0.4803442152386362} | train loss {'Reaction outcome loss': 0.11626779674267282, 'Total loss': 0.11626779674267282}
2022-12-05 22:39:19,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:19,354 INFO:     Epoch: 80
2022-12-05 22:39:20,145 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4703919362615455, 'Total loss': 0.4703919362615455} | train loss {'Reaction outcome loss': 0.11567209161894054, 'Total loss': 0.11567209161894054}
2022-12-05 22:39:20,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:20,146 INFO:     Epoch: 81
2022-12-05 22:39:20,937 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4702200529758226, 'Total loss': 0.4702200529758226} | train loss {'Reaction outcome loss': 0.1161988271058214, 'Total loss': 0.1161988271058214}
2022-12-05 22:39:20,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:20,937 INFO:     Epoch: 82
2022-12-05 22:39:21,728 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4793146164579825, 'Total loss': 0.4793146164579825} | train loss {'Reaction outcome loss': 0.11587317646386064, 'Total loss': 0.11587317646386064}
2022-12-05 22:39:21,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:21,728 INFO:     Epoch: 83
2022-12-05 22:39:22,518 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47072313116355374, 'Total loss': 0.47072313116355374} | train loss {'Reaction outcome loss': 0.11336004578945588, 'Total loss': 0.11336004578945588}
2022-12-05 22:39:22,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:22,519 INFO:     Epoch: 84
2022-12-05 22:39:23,312 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4695987840267745, 'Total loss': 0.4695987840267745} | train loss {'Reaction outcome loss': 0.11267639169735567, 'Total loss': 0.11267639169735567}
2022-12-05 22:39:23,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:23,312 INFO:     Epoch: 85
2022-12-05 22:39:24,104 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46658698232336476, 'Total loss': 0.46658698232336476} | train loss {'Reaction outcome loss': 0.11581026322531457, 'Total loss': 0.11581026322531457}
2022-12-05 22:39:24,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:24,104 INFO:     Epoch: 86
2022-12-05 22:39:24,897 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47296772863377223, 'Total loss': 0.47296772863377223} | train loss {'Reaction outcome loss': 0.11323898790822345, 'Total loss': 0.11323898790822345}
2022-12-05 22:39:24,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:24,897 INFO:     Epoch: 87
2022-12-05 22:39:25,689 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47137866812673485, 'Total loss': 0.47137866812673485} | train loss {'Reaction outcome loss': 0.11547941657505473, 'Total loss': 0.11547941657505473}
2022-12-05 22:39:25,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:25,689 INFO:     Epoch: 88
2022-12-05 22:39:26,483 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47444513033736835, 'Total loss': 0.47444513033736835} | train loss {'Reaction outcome loss': 0.11218844807649754, 'Total loss': 0.11218844807649754}
2022-12-05 22:39:26,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:26,484 INFO:     Epoch: 89
2022-12-05 22:39:27,276 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45706861262971704, 'Total loss': 0.45706861262971704} | train loss {'Reaction outcome loss': 0.11143558675765383, 'Total loss': 0.11143558675765383}
2022-12-05 22:39:27,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:27,276 INFO:     Epoch: 90
2022-12-05 22:39:28,067 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46346369182521646, 'Total loss': 0.46346369182521646} | train loss {'Reaction outcome loss': 0.11227714038473002, 'Total loss': 0.11227714038473002}
2022-12-05 22:39:28,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:28,067 INFO:     Epoch: 91
2022-12-05 22:39:28,856 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4716770193454894, 'Total loss': 0.4716770193454894} | train loss {'Reaction outcome loss': 0.11184025857673616, 'Total loss': 0.11184025857673616}
2022-12-05 22:39:28,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:28,856 INFO:     Epoch: 92
2022-12-05 22:39:29,646 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46318106150085275, 'Total loss': 0.46318106150085275} | train loss {'Reaction outcome loss': 0.1127928330734068, 'Total loss': 0.1127928330734068}
2022-12-05 22:39:29,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:29,647 INFO:     Epoch: 93
2022-12-05 22:39:30,439 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48190313611518254, 'Total loss': 0.48190313611518254} | train loss {'Reaction outcome loss': 0.11016482188917544, 'Total loss': 0.11016482188917544}
2022-12-05 22:39:30,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:30,439 INFO:     Epoch: 94
2022-12-05 22:39:31,228 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47231778502464294, 'Total loss': 0.47231778502464294} | train loss {'Reaction outcome loss': 0.11475659938415095, 'Total loss': 0.11475659938415095}
2022-12-05 22:39:31,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:31,228 INFO:     Epoch: 95
2022-12-05 22:39:32,010 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4576757601038976, 'Total loss': 0.4576757601038976} | train loss {'Reaction outcome loss': 0.11146556314613137, 'Total loss': 0.11146556314613137}
2022-12-05 22:39:32,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:32,010 INFO:     Epoch: 96
2022-12-05 22:39:32,792 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4582096389071508, 'Total loss': 0.4582096389071508} | train loss {'Reaction outcome loss': 0.10910743091787611, 'Total loss': 0.10910743091787611}
2022-12-05 22:39:32,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:32,792 INFO:     Epoch: 97
2022-12-05 22:39:33,574 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47588720951568, 'Total loss': 0.47588720951568} | train loss {'Reaction outcome loss': 0.10961984075529843, 'Total loss': 0.10961984075529843}
2022-12-05 22:39:33,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:33,574 INFO:     Epoch: 98
2022-12-05 22:39:34,355 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4865732269192284, 'Total loss': 0.4865732269192284} | train loss {'Reaction outcome loss': 0.10907110802221055, 'Total loss': 0.10907110802221055}
2022-12-05 22:39:34,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:34,356 INFO:     Epoch: 99
2022-12-05 22:39:35,137 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4643900137056004, 'Total loss': 0.4643900137056004} | train loss {'Reaction outcome loss': 0.11298542335173305, 'Total loss': 0.11298542335173305}
2022-12-05 22:39:35,138 INFO:     Best model found after epoch 19 of 100.
2022-12-05 22:39:35,138 INFO:   Done with stage: TRAINING
2022-12-05 22:39:35,138 INFO:   Starting stage: EVALUATION
2022-12-05 22:39:35,270 INFO:   Done with stage: EVALUATION
2022-12-05 22:39:35,270 INFO:   Leaving out SEQ value Fold_9
2022-12-05 22:39:35,282 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:39:35,283 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:39:35,920 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:39:35,920 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:39:35,990 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:39:35,990 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:39:35,990 INFO:     No hyperparam tuning for this model
2022-12-05 22:39:35,990 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:39:35,990 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:39:35,991 INFO:     None feature selector for col prot
2022-12-05 22:39:35,991 INFO:     None feature selector for col prot
2022-12-05 22:39:35,991 INFO:     None feature selector for col prot
2022-12-05 22:39:35,991 INFO:     None feature selector for col chem
2022-12-05 22:39:35,991 INFO:     None feature selector for col chem
2022-12-05 22:39:35,992 INFO:     None feature selector for col chem
2022-12-05 22:39:35,992 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:39:35,992 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:39:35,993 INFO:     Number of params in model 215821
2022-12-05 22:39:35,997 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:39:35,997 INFO:   Starting stage: TRAINING
2022-12-05 22:39:36,057 INFO:     Val loss before train {'Reaction outcome loss': 0.9519697712226347, 'Total loss': 0.9519697712226347}
2022-12-05 22:39:36,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:36,057 INFO:     Epoch: 0
2022-12-05 22:39:36,850 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5730210881341588, 'Total loss': 0.5730210881341588} | train loss {'Reaction outcome loss': 0.8048597132005999, 'Total loss': 0.8048597132005999}
2022-12-05 22:39:36,850 INFO:     Found new best model at epoch 0
2022-12-05 22:39:36,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:36,851 INFO:     Epoch: 1
2022-12-05 22:39:37,643 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48106776482679625, 'Total loss': 0.48106776482679625} | train loss {'Reaction outcome loss': 0.5522012565164797, 'Total loss': 0.5522012565164797}
2022-12-05 22:39:37,643 INFO:     Found new best model at epoch 1
2022-12-05 22:39:37,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:37,644 INFO:     Epoch: 2
2022-12-05 22:39:38,436 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.44951122863726184, 'Total loss': 0.44951122863726184} | train loss {'Reaction outcome loss': 0.4810171913235418, 'Total loss': 0.4810171913235418}
2022-12-05 22:39:38,436 INFO:     Found new best model at epoch 2
2022-12-05 22:39:38,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:38,437 INFO:     Epoch: 3
2022-12-05 22:39:39,230 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43820928274230525, 'Total loss': 0.43820928274230525} | train loss {'Reaction outcome loss': 0.4424370312762837, 'Total loss': 0.4424370312762837}
2022-12-05 22:39:39,231 INFO:     Found new best model at epoch 3
2022-12-05 22:39:39,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:39,232 INFO:     Epoch: 4
2022-12-05 22:39:40,032 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42289916425943375, 'Total loss': 0.42289916425943375} | train loss {'Reaction outcome loss': 0.4106095477097457, 'Total loss': 0.4106095477097457}
2022-12-05 22:39:40,032 INFO:     Found new best model at epoch 4
2022-12-05 22:39:40,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:40,033 INFO:     Epoch: 5
2022-12-05 22:39:40,827 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4180584753101522, 'Total loss': 0.4180584753101522} | train loss {'Reaction outcome loss': 0.38619663980939695, 'Total loss': 0.38619663980939695}
2022-12-05 22:39:40,827 INFO:     Found new best model at epoch 5
2022-12-05 22:39:40,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:40,828 INFO:     Epoch: 6
2022-12-05 22:39:41,621 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4133921522985805, 'Total loss': 0.4133921522985805} | train loss {'Reaction outcome loss': 0.3667155709117651, 'Total loss': 0.3667155709117651}
2022-12-05 22:39:41,621 INFO:     Found new best model at epoch 6
2022-12-05 22:39:41,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:41,622 INFO:     Epoch: 7
2022-12-05 22:39:42,414 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.3967565101656047, 'Total loss': 0.3967565101656047} | train loss {'Reaction outcome loss': 0.3492298715357338, 'Total loss': 0.3492298715357338}
2022-12-05 22:39:42,414 INFO:     Found new best model at epoch 7
2022-12-05 22:39:42,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:42,415 INFO:     Epoch: 8
2022-12-05 22:39:43,214 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39308489283377473, 'Total loss': 0.39308489283377473} | train loss {'Reaction outcome loss': 0.33324161283071, 'Total loss': 0.33324161283071}
2022-12-05 22:39:43,214 INFO:     Found new best model at epoch 8
2022-12-05 22:39:43,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:43,215 INFO:     Epoch: 9
2022-12-05 22:39:44,012 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3989317854019729, 'Total loss': 0.3989317854019729} | train loss {'Reaction outcome loss': 0.3188162816448077, 'Total loss': 0.3188162816448077}
2022-12-05 22:39:44,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:44,012 INFO:     Epoch: 10
2022-12-05 22:39:44,807 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.40921948376027023, 'Total loss': 0.40921948376027023} | train loss {'Reaction outcome loss': 0.30703930947328767, 'Total loss': 0.30703930947328767}
2022-12-05 22:39:44,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:44,807 INFO:     Epoch: 11
2022-12-05 22:39:45,600 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38687053305858915, 'Total loss': 0.38687053305858915} | train loss {'Reaction outcome loss': 0.2949762808669719, 'Total loss': 0.2949762808669719}
2022-12-05 22:39:45,600 INFO:     Found new best model at epoch 11
2022-12-05 22:39:45,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:45,601 INFO:     Epoch: 12
2022-12-05 22:39:46,395 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4017562243071469, 'Total loss': 0.4017562243071469} | train loss {'Reaction outcome loss': 0.28443101742455074, 'Total loss': 0.28443101742455074}
2022-12-05 22:39:46,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:46,396 INFO:     Epoch: 13
2022-12-05 22:39:47,191 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.39478715356778016, 'Total loss': 0.39478715356778016} | train loss {'Reaction outcome loss': 0.27690663504143875, 'Total loss': 0.27690663504143875}
2022-12-05 22:39:47,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:47,191 INFO:     Epoch: 14
2022-12-05 22:39:47,984 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4041064296933738, 'Total loss': 0.4041064296933738} | train loss {'Reaction outcome loss': 0.2654633970871087, 'Total loss': 0.2654633970871087}
2022-12-05 22:39:47,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:47,984 INFO:     Epoch: 15
2022-12-05 22:39:48,782 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40391185642643407, 'Total loss': 0.40391185642643407} | train loss {'Reaction outcome loss': 0.25861702192454566, 'Total loss': 0.25861702192454566}
2022-12-05 22:39:48,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:48,782 INFO:     Epoch: 16
2022-12-05 22:39:49,575 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3876499675891616, 'Total loss': 0.3876499675891616} | train loss {'Reaction outcome loss': 0.25000925922405814, 'Total loss': 0.25000925922405814}
2022-12-05 22:39:49,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:49,576 INFO:     Epoch: 17
2022-12-05 22:39:50,371 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3857770362360911, 'Total loss': 0.3857770362360911} | train loss {'Reaction outcome loss': 0.24251814658242848, 'Total loss': 0.24251814658242848}
2022-12-05 22:39:50,371 INFO:     Found new best model at epoch 17
2022-12-05 22:39:50,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:50,372 INFO:     Epoch: 18
2022-12-05 22:39:51,164 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3953237990764054, 'Total loss': 0.3953237990764054} | train loss {'Reaction outcome loss': 0.23862072612128912, 'Total loss': 0.23862072612128912}
2022-12-05 22:39:51,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:51,165 INFO:     Epoch: 19
2022-12-05 22:39:51,961 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38497823561457073, 'Total loss': 0.38497823561457073} | train loss {'Reaction outcome loss': 0.22960307626354118, 'Total loss': 0.22960307626354118}
2022-12-05 22:39:51,961 INFO:     Found new best model at epoch 19
2022-12-05 22:39:51,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:51,962 INFO:     Epoch: 20
2022-12-05 22:39:52,755 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38996047695929353, 'Total loss': 0.38996047695929353} | train loss {'Reaction outcome loss': 0.2246064770095531, 'Total loss': 0.2246064770095531}
2022-12-05 22:39:52,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:52,756 INFO:     Epoch: 21
2022-12-05 22:39:53,548 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3924597135998986, 'Total loss': 0.3924597135998986} | train loss {'Reaction outcome loss': 0.22095127522404637, 'Total loss': 0.22095127522404637}
2022-12-05 22:39:53,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:53,548 INFO:     Epoch: 22
2022-12-05 22:39:54,345 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40105014971711417, 'Total loss': 0.40105014971711417} | train loss {'Reaction outcome loss': 0.21597294587521784, 'Total loss': 0.21597294587521784}
2022-12-05 22:39:54,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:54,345 INFO:     Epoch: 23
2022-12-05 22:39:55,139 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4053330652585084, 'Total loss': 0.4053330652585084} | train loss {'Reaction outcome loss': 0.21112309707208507, 'Total loss': 0.21112309707208507}
2022-12-05 22:39:55,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:55,139 INFO:     Epoch: 24
2022-12-05 22:39:55,935 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4021161144429987, 'Total loss': 0.4021161144429987} | train loss {'Reaction outcome loss': 0.20776427514670837, 'Total loss': 0.20776427514670837}
2022-12-05 22:39:55,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:55,935 INFO:     Epoch: 25
2022-12-05 22:39:56,733 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41240780326453125, 'Total loss': 0.41240780326453125} | train loss {'Reaction outcome loss': 0.20317743956712225, 'Total loss': 0.20317743956712225}
2022-12-05 22:39:56,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:56,733 INFO:     Epoch: 26
2022-12-05 22:39:57,527 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4022443389350718, 'Total loss': 0.4022443389350718} | train loss {'Reaction outcome loss': 0.19787124936438857, 'Total loss': 0.19787124936438857}
2022-12-05 22:39:57,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:57,528 INFO:     Epoch: 27
2022-12-05 22:39:58,323 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44294802302663977, 'Total loss': 0.44294802302663977} | train loss {'Reaction outcome loss': 0.19447118159563792, 'Total loss': 0.19447118159563792}
2022-12-05 22:39:58,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:58,323 INFO:     Epoch: 28
2022-12-05 22:39:59,117 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4045019256459041, 'Total loss': 0.4045019256459041} | train loss {'Reaction outcome loss': 0.19221853380722384, 'Total loss': 0.19221853380722384}
2022-12-05 22:39:59,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:59,117 INFO:     Epoch: 29
2022-12-05 22:39:59,912 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40392011641101405, 'Total loss': 0.40392011641101405} | train loss {'Reaction outcome loss': 0.18768036960353773, 'Total loss': 0.18768036960353773}
2022-12-05 22:39:59,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:39:59,912 INFO:     Epoch: 30
2022-12-05 22:40:00,708 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4228495389900424, 'Total loss': 0.4228495389900424} | train loss {'Reaction outcome loss': 0.18486762151963287, 'Total loss': 0.18486762151963287}
2022-12-05 22:40:00,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:00,708 INFO:     Epoch: 31
2022-12-05 22:40:01,504 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42773759906942194, 'Total loss': 0.42773759906942194} | train loss {'Reaction outcome loss': 0.18492212983208797, 'Total loss': 0.18492212983208797}
2022-12-05 22:40:01,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:01,504 INFO:     Epoch: 32
2022-12-05 22:40:02,299 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.40175025774673984, 'Total loss': 0.40175025774673984} | train loss {'Reaction outcome loss': 0.18077303183775756, 'Total loss': 0.18077303183775756}
2022-12-05 22:40:02,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:02,299 INFO:     Epoch: 33
2022-12-05 22:40:03,094 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4055650014091622, 'Total loss': 0.4055650014091622} | train loss {'Reaction outcome loss': 0.17644494835798058, 'Total loss': 0.17644494835798058}
2022-12-05 22:40:03,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:03,094 INFO:     Epoch: 34
2022-12-05 22:40:03,890 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4193457673219117, 'Total loss': 0.4193457673219117} | train loss {'Reaction outcome loss': 0.17475262608739636, 'Total loss': 0.17475262608739636}
2022-12-05 22:40:03,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:03,890 INFO:     Epoch: 35
2022-12-05 22:40:04,686 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4077368691902269, 'Total loss': 0.4077368691902269} | train loss {'Reaction outcome loss': 0.1746319566793259, 'Total loss': 0.1746319566793259}
2022-12-05 22:40:04,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:04,686 INFO:     Epoch: 36
2022-12-05 22:40:05,481 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4131518724289807, 'Total loss': 0.4131518724289807} | train loss {'Reaction outcome loss': 0.17197115590134937, 'Total loss': 0.17197115590134937}
2022-12-05 22:40:05,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:05,481 INFO:     Epoch: 37
2022-12-05 22:40:06,277 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43357926166870375, 'Total loss': 0.43357926166870375} | train loss {'Reaction outcome loss': 0.16865158816348882, 'Total loss': 0.16865158816348882}
2022-12-05 22:40:06,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:06,277 INFO:     Epoch: 38
2022-12-05 22:40:07,071 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41023072837428615, 'Total loss': 0.41023072837428615} | train loss {'Reaction outcome loss': 0.16787796662819962, 'Total loss': 0.16787796662819962}
2022-12-05 22:40:07,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:07,071 INFO:     Epoch: 39
2022-12-05 22:40:07,866 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41254831274802034, 'Total loss': 0.41254831274802034} | train loss {'Reaction outcome loss': 0.16591551514612812, 'Total loss': 0.16591551514612812}
2022-12-05 22:40:07,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:07,867 INFO:     Epoch: 40
2022-12-05 22:40:08,661 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4243049807846546, 'Total loss': 0.4243049807846546} | train loss {'Reaction outcome loss': 0.1626672318708452, 'Total loss': 0.1626672318708452}
2022-12-05 22:40:08,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:08,661 INFO:     Epoch: 41
2022-12-05 22:40:09,454 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4315943027084524, 'Total loss': 0.4315943027084524} | train loss {'Reaction outcome loss': 0.16154299297880742, 'Total loss': 0.16154299297880742}
2022-12-05 22:40:09,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:09,455 INFO:     Epoch: 42
2022-12-05 22:40:10,249 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4228280857205391, 'Total loss': 0.4228280857205391} | train loss {'Reaction outcome loss': 0.15723149069104222, 'Total loss': 0.15723149069104222}
2022-12-05 22:40:10,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:10,250 INFO:     Epoch: 43
2022-12-05 22:40:11,051 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41715210024267435, 'Total loss': 0.41715210024267435} | train loss {'Reaction outcome loss': 0.15736534269226174, 'Total loss': 0.15736534269226174}
2022-12-05 22:40:11,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:11,051 INFO:     Epoch: 44
2022-12-05 22:40:11,846 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4066417130472308, 'Total loss': 0.4066417130472308} | train loss {'Reaction outcome loss': 0.1575201139635136, 'Total loss': 0.1575201139635136}
2022-12-05 22:40:11,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:11,846 INFO:     Epoch: 45
2022-12-05 22:40:12,646 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43060960281978955, 'Total loss': 0.43060960281978955} | train loss {'Reaction outcome loss': 0.154836947556525, 'Total loss': 0.154836947556525}
2022-12-05 22:40:12,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:12,646 INFO:     Epoch: 46
2022-12-05 22:40:13,439 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4073757984760133, 'Total loss': 0.4073757984760133} | train loss {'Reaction outcome loss': 0.15507740721166616, 'Total loss': 0.15507740721166616}
2022-12-05 22:40:13,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:13,440 INFO:     Epoch: 47
2022-12-05 22:40:14,236 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.434236425567757, 'Total loss': 0.434236425567757} | train loss {'Reaction outcome loss': 0.15065793394892207, 'Total loss': 0.15065793394892207}
2022-12-05 22:40:14,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:14,236 INFO:     Epoch: 48
2022-12-05 22:40:15,030 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41730007546191866, 'Total loss': 0.41730007546191866} | train loss {'Reaction outcome loss': 0.15123800472957233, 'Total loss': 0.15123800472957233}
2022-12-05 22:40:15,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:15,031 INFO:     Epoch: 49
2022-12-05 22:40:15,827 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43054344301873987, 'Total loss': 0.43054344301873987} | train loss {'Reaction outcome loss': 0.14788498711817327, 'Total loss': 0.14788498711817327}
2022-12-05 22:40:15,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:15,827 INFO:     Epoch: 50
2022-12-05 22:40:16,621 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42133881795135414, 'Total loss': 0.42133881795135414} | train loss {'Reaction outcome loss': 0.14441379990744135, 'Total loss': 0.14441379990744135}
2022-12-05 22:40:16,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:16,621 INFO:     Epoch: 51
2022-12-05 22:40:17,414 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40233885835517536, 'Total loss': 0.40233885835517536} | train loss {'Reaction outcome loss': 0.14767996248819173, 'Total loss': 0.14767996248819173}
2022-12-05 22:40:17,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:17,414 INFO:     Epoch: 52
2022-12-05 22:40:18,212 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40543853931806306, 'Total loss': 0.40543853931806306} | train loss {'Reaction outcome loss': 0.14640167170023966, 'Total loss': 0.14640167170023966}
2022-12-05 22:40:18,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:18,212 INFO:     Epoch: 53
2022-12-05 22:40:19,005 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.424445214765993, 'Total loss': 0.424445214765993} | train loss {'Reaction outcome loss': 0.14683473162773636, 'Total loss': 0.14683473162773636}
2022-12-05 22:40:19,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:19,005 INFO:     Epoch: 54
2022-12-05 22:40:19,800 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42783890512179246, 'Total loss': 0.42783890512179246} | train loss {'Reaction outcome loss': 0.14511870400559518, 'Total loss': 0.14511870400559518}
2022-12-05 22:40:19,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:19,801 INFO:     Epoch: 55
2022-12-05 22:40:20,598 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43073881993239577, 'Total loss': 0.43073881993239577} | train loss {'Reaction outcome loss': 0.14333986501104287, 'Total loss': 0.14333986501104287}
2022-12-05 22:40:20,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:20,598 INFO:     Epoch: 56
2022-12-05 22:40:21,390 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4265470602972941, 'Total loss': 0.4265470602972941} | train loss {'Reaction outcome loss': 0.13914947668766423, 'Total loss': 0.13914947668766423}
2022-12-05 22:40:21,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:21,390 INFO:     Epoch: 57
2022-12-05 22:40:22,188 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43755222924730997, 'Total loss': 0.43755222924730997} | train loss {'Reaction outcome loss': 0.14093660509904787, 'Total loss': 0.14093660509904787}
2022-12-05 22:40:22,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:22,190 INFO:     Epoch: 58
2022-12-05 22:40:22,986 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4237831182439219, 'Total loss': 0.4237831182439219} | train loss {'Reaction outcome loss': 0.14214767559784494, 'Total loss': 0.14214767559784494}
2022-12-05 22:40:22,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:22,986 INFO:     Epoch: 59
2022-12-05 22:40:23,777 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44127355397424917, 'Total loss': 0.44127355397424917} | train loss {'Reaction outcome loss': 0.13820884716434165, 'Total loss': 0.13820884716434165}
2022-12-05 22:40:23,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:23,777 INFO:     Epoch: 60
2022-12-05 22:40:24,571 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4174075143581087, 'Total loss': 0.4174075143581087} | train loss {'Reaction outcome loss': 0.14062359322974038, 'Total loss': 0.14062359322974038}
2022-12-05 22:40:24,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:24,572 INFO:     Epoch: 61
2022-12-05 22:40:25,366 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4210989786819978, 'Total loss': 0.4210989786819978} | train loss {'Reaction outcome loss': 0.13454064364064364, 'Total loss': 0.13454064364064364}
2022-12-05 22:40:25,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:25,366 INFO:     Epoch: 62
2022-12-05 22:40:26,160 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4249946486882188, 'Total loss': 0.4249946486882188} | train loss {'Reaction outcome loss': 0.13602400928615563, 'Total loss': 0.13602400928615563}
2022-12-05 22:40:26,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:26,160 INFO:     Epoch: 63
2022-12-05 22:40:26,952 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4213962683623487, 'Total loss': 0.4213962683623487} | train loss {'Reaction outcome loss': 0.13835025861889363, 'Total loss': 0.13835025861889363}
2022-12-05 22:40:26,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:26,952 INFO:     Epoch: 64
2022-12-05 22:40:27,743 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43279699253087694, 'Total loss': 0.43279699253087694} | train loss {'Reaction outcome loss': 0.13467468261989135, 'Total loss': 0.13467468261989135}
2022-12-05 22:40:27,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:27,743 INFO:     Epoch: 65
2022-12-05 22:40:28,535 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4032326327128844, 'Total loss': 0.4032326327128844} | train loss {'Reaction outcome loss': 0.13534657193362834, 'Total loss': 0.13534657193362834}
2022-12-05 22:40:28,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:28,536 INFO:     Epoch: 66
2022-12-05 22:40:29,326 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42895045842636714, 'Total loss': 0.42895045842636714} | train loss {'Reaction outcome loss': 0.13085186572354887, 'Total loss': 0.13085186572354887}
2022-12-05 22:40:29,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:29,327 INFO:     Epoch: 67
2022-12-05 22:40:30,120 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4232460968196392, 'Total loss': 0.4232460968196392} | train loss {'Reaction outcome loss': 0.13296989099903694, 'Total loss': 0.13296989099903694}
2022-12-05 22:40:30,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:30,121 INFO:     Epoch: 68
2022-12-05 22:40:30,915 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4242688607085835, 'Total loss': 0.4242688607085835} | train loss {'Reaction outcome loss': 0.12978723685767862, 'Total loss': 0.12978723685767862}
2022-12-05 22:40:30,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:30,915 INFO:     Epoch: 69
2022-12-05 22:40:31,712 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41851805624636734, 'Total loss': 0.41851805624636734} | train loss {'Reaction outcome loss': 0.13212218319606636, 'Total loss': 0.13212218319606636}
2022-12-05 22:40:31,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:31,712 INFO:     Epoch: 70
2022-12-05 22:40:32,507 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4270074362443252, 'Total loss': 0.4270074362443252} | train loss {'Reaction outcome loss': 0.13074822114750503, 'Total loss': 0.13074822114750503}
2022-12-05 22:40:32,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:32,507 INFO:     Epoch: 71
2022-12-05 22:40:33,298 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4338918612761931, 'Total loss': 0.4338918612761931} | train loss {'Reaction outcome loss': 0.1315697275887003, 'Total loss': 0.1315697275887003}
2022-12-05 22:40:33,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:33,298 INFO:     Epoch: 72
2022-12-05 22:40:34,092 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.423481321470304, 'Total loss': 0.423481321470304} | train loss {'Reaction outcome loss': 0.12923763734814261, 'Total loss': 0.12923763734814261}
2022-12-05 22:40:34,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:34,092 INFO:     Epoch: 73
2022-12-05 22:40:34,883 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42504643073136156, 'Total loss': 0.42504643073136156} | train loss {'Reaction outcome loss': 0.12987370955036773, 'Total loss': 0.12987370955036773}
2022-12-05 22:40:34,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:34,883 INFO:     Epoch: 74
2022-12-05 22:40:35,674 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41701633076776157, 'Total loss': 0.41701633076776157} | train loss {'Reaction outcome loss': 0.1277811661542904, 'Total loss': 0.1277811661542904}
2022-12-05 22:40:35,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:35,675 INFO:     Epoch: 75
2022-12-05 22:40:36,467 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4157960648563775, 'Total loss': 0.4157960648563775} | train loss {'Reaction outcome loss': 0.125660083678198, 'Total loss': 0.125660083678198}
2022-12-05 22:40:36,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:36,467 INFO:     Epoch: 76
2022-12-05 22:40:37,259 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4412592263384299, 'Total loss': 0.4412592263384299} | train loss {'Reaction outcome loss': 0.1269569404107789, 'Total loss': 0.1269569404107789}
2022-12-05 22:40:37,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:37,259 INFO:     Epoch: 77
2022-12-05 22:40:38,051 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4332390935583548, 'Total loss': 0.4332390935583548} | train loss {'Reaction outcome loss': 0.12581828512221335, 'Total loss': 0.12581828512221335}
2022-12-05 22:40:38,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:38,051 INFO:     Epoch: 78
2022-12-05 22:40:38,847 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4337275211106647, 'Total loss': 0.4337275211106647} | train loss {'Reaction outcome loss': 0.12560134311582172, 'Total loss': 0.12560134311582172}
2022-12-05 22:40:38,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:38,847 INFO:     Epoch: 79
2022-12-05 22:40:39,639 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4257385581731796, 'Total loss': 0.4257385581731796} | train loss {'Reaction outcome loss': 0.12341264634197878, 'Total loss': 0.12341264634197878}
2022-12-05 22:40:39,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:39,639 INFO:     Epoch: 80
2022-12-05 22:40:40,435 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4317042991857637, 'Total loss': 0.4317042991857637} | train loss {'Reaction outcome loss': 0.1237750705444224, 'Total loss': 0.1237750705444224}
2022-12-05 22:40:40,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:40,436 INFO:     Epoch: 81
2022-12-05 22:40:41,227 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4259776125916026, 'Total loss': 0.4259776125916026} | train loss {'Reaction outcome loss': 0.12480770088657137, 'Total loss': 0.12480770088657137}
2022-12-05 22:40:41,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:41,228 INFO:     Epoch: 82
2022-12-05 22:40:42,019 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43531071801077237, 'Total loss': 0.43531071801077237} | train loss {'Reaction outcome loss': 0.1246382289400865, 'Total loss': 0.1246382289400865}
2022-12-05 22:40:42,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:42,019 INFO:     Epoch: 83
2022-12-05 22:40:42,814 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46071217920292507, 'Total loss': 0.46071217920292507} | train loss {'Reaction outcome loss': 0.1262319953173339, 'Total loss': 0.1262319953173339}
2022-12-05 22:40:42,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:42,814 INFO:     Epoch: 84
2022-12-05 22:40:43,607 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4434569538994269, 'Total loss': 0.4434569538994269} | train loss {'Reaction outcome loss': 0.12411071908765382, 'Total loss': 0.12411071908765382}
2022-12-05 22:40:43,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:43,608 INFO:     Epoch: 85
2022-12-05 22:40:44,399 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.424618141556328, 'Total loss': 0.424618141556328} | train loss {'Reaction outcome loss': 0.12264940087803669, 'Total loss': 0.12264940087803669}
2022-12-05 22:40:44,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:44,399 INFO:     Epoch: 86
2022-12-05 22:40:45,193 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4352695100348104, 'Total loss': 0.4352695100348104} | train loss {'Reaction outcome loss': 0.12502921481556709, 'Total loss': 0.12502921481556709}
2022-12-05 22:40:45,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:45,193 INFO:     Epoch: 87
2022-12-05 22:40:45,987 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44668745825236494, 'Total loss': 0.44668745825236494} | train loss {'Reaction outcome loss': 0.1243561979142889, 'Total loss': 0.1243561979142889}
2022-12-05 22:40:45,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:45,987 INFO:     Epoch: 88
2022-12-05 22:40:46,779 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43440596098926937, 'Total loss': 0.43440596098926937} | train loss {'Reaction outcome loss': 0.12259172513374998, 'Total loss': 0.12259172513374998}
2022-12-05 22:40:46,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:46,780 INFO:     Epoch: 89
2022-12-05 22:40:47,572 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41719051552089775, 'Total loss': 0.41719051552089775} | train loss {'Reaction outcome loss': 0.11995875047174312, 'Total loss': 0.11995875047174312}
2022-12-05 22:40:47,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:47,573 INFO:     Epoch: 90
2022-12-05 22:40:48,372 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.465357337824323, 'Total loss': 0.465357337824323} | train loss {'Reaction outcome loss': 0.12035320947817978, 'Total loss': 0.12035320947817978}
2022-12-05 22:40:48,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:48,372 INFO:     Epoch: 91
2022-12-05 22:40:49,164 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43360575525598094, 'Total loss': 0.43360575525598094} | train loss {'Reaction outcome loss': 0.11982989453169848, 'Total loss': 0.11982989453169848}
2022-12-05 22:40:49,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:49,164 INFO:     Epoch: 92
2022-12-05 22:40:49,962 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4277567487548698, 'Total loss': 0.4277567487548698} | train loss {'Reaction outcome loss': 0.12078298645980295, 'Total loss': 0.12078298645980295}
2022-12-05 22:40:49,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:49,963 INFO:     Epoch: 93
2022-12-05 22:40:50,757 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4322660868479447, 'Total loss': 0.4322660868479447} | train loss {'Reaction outcome loss': 0.11804712412600976, 'Total loss': 0.11804712412600976}
2022-12-05 22:40:50,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:50,757 INFO:     Epoch: 94
2022-12-05 22:40:51,547 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4240145158361305, 'Total loss': 0.4240145158361305} | train loss {'Reaction outcome loss': 0.12056372890384087, 'Total loss': 0.12056372890384087}
2022-12-05 22:40:51,547 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:51,547 INFO:     Epoch: 95
2022-12-05 22:40:52,341 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42869358272715047, 'Total loss': 0.42869358272715047} | train loss {'Reaction outcome loss': 0.11873300454669422, 'Total loss': 0.11873300454669422}
2022-12-05 22:40:52,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:52,341 INFO:     Epoch: 96
2022-12-05 22:40:53,133 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4377949105745012, 'Total loss': 0.4377949105745012} | train loss {'Reaction outcome loss': 0.11796817694970917, 'Total loss': 0.11796817694970917}
2022-12-05 22:40:53,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:53,134 INFO:     Epoch: 97
2022-12-05 22:40:53,924 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.433306137946519, 'Total loss': 0.433306137946519} | train loss {'Reaction outcome loss': 0.11875919558318151, 'Total loss': 0.11875919558318151}
2022-12-05 22:40:53,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:53,924 INFO:     Epoch: 98
2022-12-05 22:40:54,716 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42216775397008116, 'Total loss': 0.42216775397008116} | train loss {'Reaction outcome loss': 0.11927327644004818, 'Total loss': 0.11927327644004818}
2022-12-05 22:40:54,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-05 22:40:54,716 INFO:     Epoch: 99
2022-12-05 22:40:55,508 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42584116384387016, 'Total loss': 0.42584116384387016} | train loss {'Reaction outcome loss': 0.1197597123795159, 'Total loss': 0.1197597123795159}
2022-12-05 22:40:55,508 INFO:     Best model found after epoch 20 of 100.
2022-12-05 22:40:55,508 INFO:   Done with stage: TRAINING
2022-12-05 22:40:55,508 INFO:   Starting stage: EVALUATION
2022-12-05 22:40:55,627 INFO:   Done with stage: EVALUATION
2022-12-05 22:40:55,627 INFO: Done with stage: RUNNING SPLITS
2022-12-05 22:40:55,628 INFO: Starting stage: COMPUTE METRICS
2022-12-05 22:40:56,792 INFO: Done with stage: COMPUTE METRICS
2022-12-05 22:40:56,792 INFO: Starting stage: EXPORT RESULTS
2022-12-05 22:40:56,809 INFO:   Final results averaged over 50 folds: 
2022-12-05 22:40:56,812 INFO:   
                   mae  neg-spearman      rmse  spearman
dataset_split                                          
test           0.1745           NaN  0.304727       NaN
2022-12-05 22:40:58,470 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-05 22:40:58,476 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-05 22:40:58,477 DEBUG:   interactive is False
2022-12-05 22:40:58,477 DEBUG:   platform is linux
2022-12-05 22:40:58,478 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-05 22:40:58,649 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-05 22:40:58,651 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-05 22:40:59,086 DEBUG:   Loaded backend agg version unknown.
2022-12-05 22:40:59,088 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 22:40:59,088 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,088 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,089 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 22:40:59,090 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 22:40:59,091 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,091 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 22:40:59,127 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-05 22:40:59,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,128 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,129 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,130 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 22:40:59,130 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,130 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,130 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,130 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 22:40:59,130 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,130 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 22:40:59,138 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,139 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,140 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 22:40:59,141 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 22:40:59,142 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 22:40:59,497 INFO: Done with stage: EXPORT RESULTS
2022-12-05 22:40:59,497 INFO: Starting stage: SAVE MODEL
2022-12-05 22:40:59,564 INFO: Done with stage: SAVE MODEL
2022-12-05 22:40:59,564 INFO: Wall time for program:  4027.89 seconds
